[
    {
        "filename": "MAPREDUCE-6633.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput": {
                "code_before_change": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set<TaskAttemptID> remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput<K,V> mapOutput = null;\n    TaskAttemptID mapId = null;\n    long decompressedLength = -1;\n    long compressedLength = -1;\n    \n    try {\n      long startTime = Time.monotonicNow();\n      int forReduce = -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header = new ShuffleHeader();\n        header.readFields(input);\n        mapId = TaskAttemptID.forName(header.mapId);\n        compressedLength = header.compressedLength;\n        decompressedLength = header.uncompressedLength;\n        forReduce = header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don't know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is = input;\n      is = CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -= CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -= CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput = merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput == null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime = Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime = 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              startTime, endTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      if (mapOutput != null) {\n        mapOutput.abort();\n      }\n\n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId == null || mapOutput == null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId == null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
                "code_after_change": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set<TaskAttemptID> remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput<K,V> mapOutput = null;\n    TaskAttemptID mapId = null;\n    long decompressedLength = -1;\n    long compressedLength = -1;\n    \n    try {\n      long startTime = Time.monotonicNow();\n      int forReduce = -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header = new ShuffleHeader();\n        header.readFields(input);\n        mapId = TaskAttemptID.forName(header.mapId);\n        compressedLength = header.compressedLength;\n        decompressedLength = header.uncompressedLength;\n        forReduce = header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don't know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is = input;\n      is = CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -= CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -= CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput = merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput == null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError | Exception e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime = Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime = 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              startTime, endTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      if (mapOutput != null) {\n        mapOutput.abort();\n      }\n\n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId == null || mapOutput == null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId == null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": ""
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as an ArrayIndexOutOfBoundsException in the LzoDecompressor, which is related to the decompression process but not the exact root cause in the ground truth method. Therefore, it is classified as 'Partial' with 'Buggy Method' as the sub-category. The fix suggestion involves implementing a retry mechanism in the Application Master, which is an alternative approach to the developer's fix of handling exceptions in the Fetcher.copyMapOutput method. The problem location identification is 'Precise' as the report mentions 'Fetcher.copyMapOutput', which is the ground truth method. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6577.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.YARNRunner.createApplicationSubmissionContext": {
                "code_before_change": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId = resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability = recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability = \" + capability);\n\n    // Setup LocalResources\n    Map<String, LocalResource> localResources =\n        new HashMap<String, LocalResource>();\n\n    Path jobConfPath = new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir = ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) != null) {\n      Path jobJarPath = new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc = createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern = conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob = new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List<String> vargs = new ArrayList<String>(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir =\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir=\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions = conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions = conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams = jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams != null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector<String> vargsFinal = new Vector<String>(8);\n    // Final command\n    StringBuilder mergedCommand = new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map<String, String> environment = new HashMap<String, String>();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map<ApplicationAccessType, String> acls\n        = new HashMap<ApplicationAccessType, String>(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer =\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection<String> tagsFromConf =\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext =\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID = null;\n    try {\n      reservationID =\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg =\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID != null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression = conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null != amNodelabelExpression\n        && amNodelabelExpression.trim().length() != 0) {\n      ResourceRequest amResourceRequest =\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf != null && !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet<String>(tagsFromConf));\n    }\n\n    String jobPriority = jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority != null) {\n      int iPriority;\n      try {\n        iPriority = TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority = Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
                "code_after_change": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId = resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability = recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability = \" + capability);\n\n    // Setup LocalResources\n    Map<String, LocalResource> localResources =\n        new HashMap<String, LocalResource>();\n\n    Path jobConfPath = new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir = ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) != null) {\n      Path jobJarPath = new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc = createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern = conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob = new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List<String> vargs = new ArrayList<String>(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir =\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir=\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions = conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions = conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams = jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams != null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector<String> vargsFinal = new Vector<String>(8);\n    // Final command\n    StringBuilder mergedCommand = new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map<String, String> environment = new HashMap<String, String>();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory in front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n            MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map<ApplicationAccessType, String> acls\n        = new HashMap<ApplicationAccessType, String>(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer =\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection<String> tagsFromConf =\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext =\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID = null;\n    try {\n      reservationID =\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg =\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID != null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf != null && !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet<String>(tagsFromConf));\n    }\n\n    return appContext;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the absence of 'LD_LIBRARY_PATH' in the environment variables, which is related to the issue but not the exact root cause in the ground truth method. The report points to methods like 'Lz4Codec.getCompressorType' and 'MapTask.runOldMapper', which are involved in the error but not where the fix was made, hence 'Buggy Method'. The fix suggestion to include 'LD_LIBRARY_PATH' is preventive as it mitigates the issue by ensuring the environment is correctly set up, but it doesn't match the developer's fix. The problem location is identified in methods where the error occurs, but not the ground truth method, hence 'Buggy Method'. There is no wrong information as the report accurately describes the issue context."
        }
    },
    {
        "filename": "MAPREDUCE-5137.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.webapp.TaskPage.render": {
                "code_before_change": "    protected void render(Block html) {\n      if (!isValidRequest()) {\n        html.\n          h2($(TITLE));\n        return;\n      }\n      html.\n      table(\"#attempts\").\n        thead().\n          tr().\n            th(\".id\", \"Attempt\").\n            th(\".progress\", \"Progress\").\n            th(\".state\", \"State\").\n            th(\".node\", \"Node\").\n            th(\".logs\", \"Logs\").\n            th(\".tsh\", \"Started\").\n            th(\".tsh\", \"Finished\").\n            th(\".tsh\", \"Elapsed\").\n            th(\".note\", \"Note\")._()._();\n      // Write all the data into a JavaScript array of arrays for JQuery\n      // DataTables to display\n      StringBuilder attemptsTableData = new StringBuilder(\"[\\n\");\n\n      for (TaskAttempt attempt : getTaskAttempts()) {\n        TaskAttemptInfo ta = new TaskAttemptInfo(attempt, true);\n        String progress = percent(ta.getProgress() / 100);\n\n        String nodeHttpAddr = ta.getNode();\n        String diag = ta.getNote() == null ? \"\" : ta.getNote();\n        attemptsTableData.append(\"[\\\"\")\n        .append(ta.getId()).append(\"\\\",\\\"\")\n        .append(progress).append(\"\\\",\\\"\")\n        .append(ta.getState().toString()).append(\"\\\",\\\"\")\n\n        .append(nodeHttpAddr == null ? \"N/A\" :\n          \"<a class='nodelink' href='\" + HttpConfig.getSchemePrefix() + nodeHttpAddr + \"'>\"\n          + nodeHttpAddr + \"</a>\")\n        .append(\"\\\",\\\"\")\n\n        .append(ta.getAssignedContainerId() == null ? \"N/A\" :\n          \"<a class='logslink' href='\" + url(HttpConfig.getSchemePrefix(), nodeHttpAddr, \"node\"\n            , \"containerlogs\", ta.getAssignedContainerIdStr(), app.getJob()\n            .getUserName()) + \"'>logs</a>\")\n          .append(\"\\\",\\\"\")\n\n        .append(ta.getStartTime()).append(\"\\\",\\\"\")\n        .append(ta.getFinishTime()).append(\"\\\",\\\"\")\n        .append(ta.getElapsedTime()).append(\"\\\",\\\"\")\n        .append(StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(\n          diag))).append(\"\\\"],\\n\");\n      }\n      //Remove the last comma and close off the array of arrays\n      if(attemptsTableData.charAt(attemptsTableData.length() - 2) == ',') {\n        attemptsTableData.delete(attemptsTableData.length()-2, attemptsTableData.length()-1);\n      }\n      attemptsTableData.append(\"]\");\n      html.script().$type(\"text/javascript\").\n      _(\"var attemptsTableData=\" + attemptsTableData)._();\n    }",
                "code_after_change": "    protected void render(Block html) {\n      if (!isValidRequest()) {\n        html.\n          h2($(TITLE));\n        return;\n      }\n      TBODY<TABLE<Hamlet>> tbody = html.\n      table(\"#attempts\").\n        thead().\n          tr().\n            th(\".id\", \"Attempt\").\n            th(\".progress\", \"Progress\").\n            th(\".state\", \"State\").\n            th(\".node\", \"Node\").\n            th(\".logs\", \"Logs\").\n            th(\".tsh\", \"Started\").\n            th(\".tsh\", \"Finished\").\n            th(\".tsh\", \"Elapsed\").\n            th(\".note\", \"Note\")._()._().\n      tbody();\n      // Write all the data into a JavaScript array of arrays for JQuery\n      // DataTables to display\n      StringBuilder attemptsTableData = new StringBuilder(\"[\\n\");\n\n      for (TaskAttempt attempt : getTaskAttempts()) {\n        TaskAttemptInfo ta = new TaskAttemptInfo(attempt, true);\n        String progress = percent(ta.getProgress() / 100);\n\n        String nodeHttpAddr = ta.getNode();\n        String diag = ta.getNote() == null ? \"\" : ta.getNote();\n        attemptsTableData.append(\"[\\\"\")\n        .append(ta.getId()).append(\"\\\",\\\"\")\n        .append(progress).append(\"\\\",\\\"\")\n        .append(ta.getState().toString()).append(\"\\\",\\\"\")\n\n        .append(nodeHttpAddr == null ? \"N/A\" :\n          \"<a class='nodelink' href='\" + HttpConfig.getSchemePrefix() + nodeHttpAddr + \"'>\"\n          + nodeHttpAddr + \"</a>\")\n        .append(\"\\\",\\\"\")\n\n        .append(ta.getAssignedContainerId() == null ? \"N/A\" :\n          \"<a class='logslink' href='\" + url(HttpConfig.getSchemePrefix(), nodeHttpAddr, \"node\"\n            , \"containerlogs\", ta.getAssignedContainerIdStr(), app.getJob()\n            .getUserName()) + \"'>logs</a>\")\n          .append(\"\\\",\\\"\")\n\n        .append(ta.getStartTime()).append(\"\\\",\\\"\")\n        .append(ta.getFinishTime()).append(\"\\\",\\\"\")\n        .append(ta.getElapsedTime()).append(\"\\\",\\\"\")\n        .append(StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(\n          diag))).append(\"\\\"],\\n\");\n      }\n      //Remove the last comma and close off the array of arrays\n      if(attemptsTableData.charAt(attemptsTableData.length() - 2) == ',') {\n        attemptsTableData.delete(attemptsTableData.length()-2, attemptsTableData.length()-1);\n      }\n      attemptsTableData.append(\"]\");\n      html.script().$type(\"text/javascript\").\n      _(\"var attemptsTableData=\" + attemptsTableData)._();\n\n      tbody._()._();\n\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The root cause identification is partial because the bug report identifies a NotFoundException related to task retrieval, which is in the shared stack trace context with the ground truth method. The fix suggestion is preventive as it suggests checking the task ID validity and implementing error handling, which would mitigate the issue but does not match the actual code change. The problem location identification is partial because the methods mentioned in the problem_location field are part of the stack trace but not the ground truth method. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4008.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.getQueueUserAclInfo": {
                "code_before_change": "    public List<QueueUserACLInfo> getQueueUserAclInfo(\n        UserGroupInformation unused) {\n      QueueUserACLInfo queueUserAclInfo = \n        recordFactory.newRecordInstance(QueueUserACLInfo.class);\n      queueUserAclInfo.setQueueName(DEFAULT_QUEUE_NAME);\n      queueUserAclInfo.setUserAcls(Arrays.asList(QueueACL.values()));\n      return Collections.singletonList(queueUserAclInfo);\n    }",
                "code_after_change": "    public List<QueueUserACLInfo> getQueueUserAclInfo(\n        UserGroupInformation unused) {\n      QueueUserACLInfo queueUserAclInfo = \n        recordFactory.newRecordInstance(QueueUserACLInfo.class);\n      queueUserAclInfo.setQueueName(DEFAULT_QUEUE_NAME);\n      queueUserAclInfo.setUserAcls(Arrays.asList(QueueACL.values()));\n      return Collections.singletonList(queueUserAclInfo);\n    }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.reinitialize": {
                "code_before_change": "  public synchronized void reinitialize(Configuration conf,\n      ContainerTokenSecretManager containerTokenSecretManager, \n      RMContext rmContext) \n  throws IOException \n  {\n    setConf(conf);\n    if (!this.initialized) {\n      this.containerTokenSecretManager = containerTokenSecretManager;\n      this.rmContext = rmContext;\n      this.minimumAllocation = \n        Resources.createResource(conf.getInt(MINIMUM_ALLOCATION, MINIMUM_MEMORY));\n      this.maximumAllocation = \n        Resources.createResource(conf.getInt(MAXIMUM_ALLOCATION, MAXIMUM_MEMORY));\n      this.initialized = true;\n    }\n  }",
                "code_after_change": "  public synchronized void reinitialize(Configuration conf,\n      ContainerTokenSecretManager containerTokenSecretManager, \n      RMContext rmContext) \n  throws IOException \n  {\n    setConf(conf);\n    if (!this.initialized) {\n      this.containerTokenSecretManager = containerTokenSecretManager;\n      this.rmContext = rmContext;\n      this.minimumAllocation = \n        Resources.createResource(conf.getInt(MINIMUM_ALLOCATION, MINIMUM_MEMORY));\n      this.maximumAllocation = \n        Resources.createResource(conf.getInt(MAXIMUM_ALLOCATION, MAXIMUM_MEMORY));\n      this.metrics = QueueMetrics.forQueue(DEFAULT_QUEUE_NAME, null, false,\n          conf);\n      this.activeUsersManager = new ActiveUsersManager(metrics);\n      this.initialized = true;\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the MBean for QueueMetrics being registered multiple times, which is related to the stack trace context but not the exact ground truth methods. The fix suggestion to modify the MBeans.register method to check for existing MBeans is preventive, as it would mitigate the issue but does not match the actual fix in the ground truth methods. The problem location identification is partial because it mentions methods in the stack trace context but not the exact ground truth methods. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6259.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processEventForTimelineServer": {
                "code_before_change": "  private void processEventForTimelineServer(HistoryEvent event, JobId jobId,\n          long timestamp) {\n    TimelineEvent tEvent = new TimelineEvent();\n    tEvent.setEventType(event.getEventType().name().toUpperCase());\n    tEvent.setTimestamp(timestamp);\n    TimelineEntity tEntity = new TimelineEntity();\n\n    switch (event.getEventType()) {\n      case JOB_SUBMITTED:\n        JobSubmittedEvent jse =\n            (JobSubmittedEvent) event;\n        tEvent.addEventInfo(\"SUBMIT_TIME\", jse.getSubmitTime());\n        tEvent.addEventInfo(\"QUEUE_NAME\", jse.getJobQueueName());\n        tEvent.addEventInfo(\"JOB_NAME\", jse.getJobName());\n        tEvent.addEventInfo(\"USER_NAME\", jse.getUserName());\n        tEvent.addEventInfo(\"JOB_CONF_PATH\", jse.getJobConfPath());\n        tEvent.addEventInfo(\"ACLS\", jse.getJobAcls());\n        tEvent.addEventInfo(\"JOB_QUEUE_NAME\", jse.getJobQueueName());\n        tEvent.addEventInfo(\"WORKLFOW_ID\", jse.getWorkflowId());\n        tEvent.addEventInfo(\"WORKFLOW_NAME\", jse.getWorkflowName());\n        tEvent.addEventInfo(\"WORKFLOW_NAME_NAME\", jse.getWorkflowNodeName());\n        tEvent.addEventInfo(\"WORKFLOW_ADJACENCIES\",\n                jse.getWorkflowAdjacencies());\n        tEvent.addEventInfo(\"WORKFLOW_TAGS\", jse.getWorkflowTags());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_STATUS_CHANGED:\n        JobStatusChangedEvent jsce = (JobStatusChangedEvent) event;\n        tEvent.addEventInfo(\"STATUS\", jsce.getStatus());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_INFO_CHANGED:\n        JobInfoChangeEvent jice = (JobInfoChangeEvent) event;\n        tEvent.addEventInfo(\"SUBMIT_TIME\", jice.getSubmitTime());\n        tEvent.addEventInfo(\"LAUNCH_TIME\", jice.getLaunchTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_INITED:\n        JobInitedEvent jie = (JobInitedEvent) event;\n        tEvent.addEventInfo(\"START_TIME\", jie.getLaunchTime());\n        tEvent.addEventInfo(\"STATUS\", jie.getStatus());\n        tEvent.addEventInfo(\"TOTAL_MAPS\", jie.getTotalMaps());\n        tEvent.addEventInfo(\"TOTAL_REDUCES\", jie.getTotalReduces());\n        tEvent.addEventInfo(\"UBERIZED\", jie.getUberized());\n        tEntity.setStartTime(jie.getLaunchTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_PRIORITY_CHANGED:\n        JobPriorityChangeEvent jpce = (JobPriorityChangeEvent) event;\n        tEvent.addEventInfo(\"PRIORITY\", jpce.getPriority().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_QUEUE_CHANGED:\n        JobQueueChangeEvent jqe = (JobQueueChangeEvent) event;\n        tEvent.addEventInfo(\"QUEUE_NAMES\", jqe.getJobQueueName());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_FAILED:\n      case JOB_KILLED:\n      case JOB_ERROR:\n        JobUnsuccessfulCompletionEvent juce =\n              (JobUnsuccessfulCompletionEvent) event;\n        tEvent.addEventInfo(\"FINISH_TIME\", juce.getFinishTime());\n        tEvent.addEventInfo(\"NUM_MAPS\", juce.getFinishedMaps());\n        tEvent.addEventInfo(\"NUM_REDUCES\", juce.getFinishedReduces());\n        tEvent.addEventInfo(\"JOB_STATUS\", juce.getStatus());\n        tEvent.addEventInfo(\"DIAGNOSTICS\", juce.getDiagnostics());\n        tEvent.addEventInfo(\"FINISHED_MAPS\", juce.getFinishedMaps());\n        tEvent.addEventInfo(\"FINISHED_REDUCES\", juce.getFinishedReduces());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_FINISHED:\n        JobFinishedEvent jfe = (JobFinishedEvent) event;\n        tEvent.addEventInfo(\"FINISH_TIME\", jfe.getFinishTime());\n        tEvent.addEventInfo(\"NUM_MAPS\", jfe.getFinishedMaps());\n        tEvent.addEventInfo(\"NUM_REDUCES\", jfe.getFinishedReduces());\n        tEvent.addEventInfo(\"FAILED_MAPS\", jfe.getFailedMaps());\n        tEvent.addEventInfo(\"FAILED_REDUCES\", jfe.getFailedReduces());\n        tEvent.addEventInfo(\"FINISHED_MAPS\", jfe.getFinishedMaps());\n        tEvent.addEventInfo(\"FINISHED_REDUCES\", jfe.getFinishedReduces());\n        tEvent.addEventInfo(\"MAP_COUNTERS_GROUPS\",\n                countersToJSON(jfe.getTotalCounters()));\n        tEvent.addEventInfo(\"REDUCE_COUNTERS_GROUPS\",\n                countersToJSON(jfe.getReduceCounters()));\n        tEvent.addEventInfo(\"TOTAL_COUNTERS_GROUPS\",\n                countersToJSON(jfe.getTotalCounters()));\n        tEvent.addEventInfo(\"JOB_STATUS\", JobState.SUCCEEDED.toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case TASK_STARTED:\n        TaskStartedEvent tse = (TaskStartedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tse.getTaskType().toString());\n        tEvent.addEventInfo(\"START_TIME\", tse.getStartTime());\n        tEvent.addEventInfo(\"SPLIT_LOCATIONS\", tse.getSplitLocations());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tse.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case TASK_FAILED:\n        TaskFailedEvent tfe = (TaskFailedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tfe.getTaskType().toString());\n        tEvent.addEventInfo(\"STATUS\", TaskStatus.State.FAILED.toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", tfe.getFinishTime());\n        tEvent.addEventInfo(\"ERROR\", tfe.getError());\n        tEvent.addEventInfo(\"FAILED_ATTEMPT_ID\",\n                tfe.getFailedAttemptID() == null ?\n                \"\" : tfe.getFailedAttemptID().toString());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tfe.getCounters()));\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tfe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case TASK_UPDATED:\n        TaskUpdatedEvent tue = (TaskUpdatedEvent) event;\n        tEvent.addEventInfo(\"FINISH_TIME\", tue.getFinishTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tue.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case TASK_FINISHED:\n        TaskFinishedEvent tfe2 = (TaskFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tfe2.getTaskType().toString());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tfe2.getCounters()));\n        tEvent.addEventInfo(\"FINISH_TIME\", tfe2.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", TaskStatus.State.SUCCEEDED.toString());\n        tEvent.addEventInfo(\"SUCCESSFUL_TASK_ATTEMPT_ID\",\n            tfe2.getSuccessfulTaskAttemptId() == null ?\n            \"\" : tfe2.getSuccessfulTaskAttemptId().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tfe2.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case MAP_ATTEMPT_STARTED:\n      case CLEANUP_ATTEMPT_STARTED:\n      case REDUCE_ATTEMPT_STARTED:\n      case SETUP_ATTEMPT_STARTED:\n        TaskAttemptStartedEvent tase = (TaskAttemptStartedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tase.getTaskType().toString());\n        tEvent.addEventInfo(\"TASK_ATTEMPT_ID\",\n            tase.getTaskAttemptId().toString());\n        tEvent.addEventInfo(\"START_TIME\", tase.getStartTime());\n        tEvent.addEventInfo(\"HTTP_PORT\", tase.getHttpPort());\n        tEvent.addEventInfo(\"TRACKER_NAME\", tase.getTrackerName());\n        tEvent.addEventInfo(\"TASK_TYPE\", tase.getTaskType().toString());\n        tEvent.addEventInfo(\"SHUFFLE_PORT\", tase.getShufflePort());\n        tEvent.addEventInfo(\"CONTAINER_ID\", tase.getContainerId() == null ?\n            \"\" : tase.getContainerId().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tase.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case MAP_ATTEMPT_FAILED:\n      case CLEANUP_ATTEMPT_FAILED:\n      case REDUCE_ATTEMPT_FAILED:\n      case SETUP_ATTEMPT_FAILED:\n      case MAP_ATTEMPT_KILLED:\n      case CLEANUP_ATTEMPT_KILLED:\n      case REDUCE_ATTEMPT_KILLED:\n      case SETUP_ATTEMPT_KILLED:\n        TaskAttemptUnsuccessfulCompletionEvent tauce =\n                (TaskAttemptUnsuccessfulCompletionEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tauce.getTaskType().toString());\n        tEvent.addEventInfo(\"TASK_ATTEMPT_ID\",\n            tauce.getTaskAttemptId() == null ?\n            \"\" : tauce.getTaskAttemptId().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"ERROR\", tauce.getError());\n        tEvent.addEventInfo(\"STATUS\", tauce.getTaskStatus());\n        tEvent.addEventInfo(\"HOSTNAME\", tauce.getHostname());\n        tEvent.addEventInfo(\"PORT\", tauce.getPort());\n        tEvent.addEventInfo(\"RACK_NAME\", tauce.getRackName());\n        tEvent.addEventInfo(\"SHUFFLE_FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"SORT_FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"MAP_FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tauce.getCounters()));\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tauce.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case MAP_ATTEMPT_FINISHED:\n        MapAttemptFinishedEvent mafe = (MapAttemptFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", mafe.getTaskType().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", mafe.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", mafe.getTaskStatus());\n        tEvent.addEventInfo(\"STATE\", mafe.getState());\n        tEvent.addEventInfo(\"MAP_FINISH_TIME\", mafe.getMapFinishTime());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(mafe.getCounters()));\n        tEvent.addEventInfo(\"HOSTNAME\", mafe.getHostname());\n        tEvent.addEventInfo(\"PORT\", mafe.getPort());\n        tEvent.addEventInfo(\"RACK_NAME\", mafe.getRackName());\n        tEvent.addEventInfo(\"ATTEMPT_ID\", mafe.getAttemptId() == null ?\n            \"\" : mafe.getAttemptId().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(mafe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case REDUCE_ATTEMPT_FINISHED:\n        ReduceAttemptFinishedEvent rafe = (ReduceAttemptFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", rafe.getTaskType().toString());\n        tEvent.addEventInfo(\"ATTEMPT_ID\", rafe.getAttemptId() == null ?\n            \"\" : rafe.getAttemptId().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", rafe.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", rafe.getTaskStatus());\n        tEvent.addEventInfo(\"STATE\", rafe.getState());\n        tEvent.addEventInfo(\"SHUFFLE_FINISH_TIME\", rafe.getShuffleFinishTime());\n        tEvent.addEventInfo(\"SORT_FINISH_TIME\", rafe.getSortFinishTime());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(rafe.getCounters()));\n        tEvent.addEventInfo(\"HOSTNAME\", rafe.getHostname());\n        tEvent.addEventInfo(\"PORT\", rafe.getPort());\n        tEvent.addEventInfo(\"RACK_NAME\", rafe.getRackName());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(rafe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case SETUP_ATTEMPT_FINISHED:\n      case CLEANUP_ATTEMPT_FINISHED:\n        TaskAttemptFinishedEvent tafe = (TaskAttemptFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tafe.getTaskType().toString());\n        tEvent.addEventInfo(\"ATTEMPT_ID\", tafe.getAttemptId() == null ?\n            \"\" : tafe.getAttemptId().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", tafe.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", tafe.getTaskStatus());\n        tEvent.addEventInfo(\"STATE\", tafe.getState());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tafe.getCounters()));\n        tEvent.addEventInfo(\"HOSTNAME\", tafe.getHostname());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tafe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case AM_STARTED:\n        AMStartedEvent ase = (AMStartedEvent) event;\n        tEvent.addEventInfo(\"APPLICATION_ATTEMPT_ID\",\n                ase.getAppAttemptId() == null ?\n                \"\" : ase.getAppAttemptId().toString());\n        tEvent.addEventInfo(\"CONTAINER_ID\", ase.getContainerId() == null ?\n                \"\" : ase.getContainerId().toString());\n        tEvent.addEventInfo(\"NODE_MANAGER_HOST\", ase.getNodeManagerHost());\n        tEvent.addEventInfo(\"NODE_MANAGER_PORT\", ase.getNodeManagerPort());\n        tEvent.addEventInfo(\"NODE_MANAGER_HTTP_PORT\",\n                ase.getNodeManagerHttpPort());\n        tEvent.addEventInfo(\"START_TIME\", ase.getStartTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      default:\n        break;\n    }\n\n    try {\n      timelineClient.putEntities(tEntity);\n    } catch (IOException ex) {\n      LOG.error(\"Error putting entity \" + tEntity.getEntityId() + \" to Timeline\"\n      + \"Server\", ex);\n    } catch (YarnException ex) {\n      LOG.error(\"Error putting entity \" + tEntity.getEntityId() + \" to Timeline\"\n      + \"Server\", ex);\n    }\n  }",
                "code_after_change": "  private void processEventForTimelineServer(HistoryEvent event, JobId jobId,\n          long timestamp) {\n    TimelineEvent tEvent = new TimelineEvent();\n    tEvent.setEventType(StringUtils.toUpperCase(event.getEventType().name()));\n    tEvent.setTimestamp(timestamp);\n    TimelineEntity tEntity = new TimelineEntity();\n\n    switch (event.getEventType()) {\n      case JOB_SUBMITTED:\n        JobSubmittedEvent jse =\n            (JobSubmittedEvent) event;\n        tEvent.addEventInfo(\"SUBMIT_TIME\", jse.getSubmitTime());\n        tEvent.addEventInfo(\"QUEUE_NAME\", jse.getJobQueueName());\n        tEvent.addEventInfo(\"JOB_NAME\", jse.getJobName());\n        tEvent.addEventInfo(\"USER_NAME\", jse.getUserName());\n        tEvent.addEventInfo(\"JOB_CONF_PATH\", jse.getJobConfPath());\n        tEvent.addEventInfo(\"ACLS\", jse.getJobAcls());\n        tEvent.addEventInfo(\"JOB_QUEUE_NAME\", jse.getJobQueueName());\n        tEvent.addEventInfo(\"WORKLFOW_ID\", jse.getWorkflowId());\n        tEvent.addEventInfo(\"WORKFLOW_NAME\", jse.getWorkflowName());\n        tEvent.addEventInfo(\"WORKFLOW_NAME_NAME\", jse.getWorkflowNodeName());\n        tEvent.addEventInfo(\"WORKFLOW_ADJACENCIES\",\n                jse.getWorkflowAdjacencies());\n        tEvent.addEventInfo(\"WORKFLOW_TAGS\", jse.getWorkflowTags());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_STATUS_CHANGED:\n        JobStatusChangedEvent jsce = (JobStatusChangedEvent) event;\n        tEvent.addEventInfo(\"STATUS\", jsce.getStatus());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_INFO_CHANGED:\n        JobInfoChangeEvent jice = (JobInfoChangeEvent) event;\n        tEvent.addEventInfo(\"SUBMIT_TIME\", jice.getSubmitTime());\n        tEvent.addEventInfo(\"LAUNCH_TIME\", jice.getLaunchTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_INITED:\n        JobInitedEvent jie = (JobInitedEvent) event;\n        tEvent.addEventInfo(\"START_TIME\", jie.getLaunchTime());\n        tEvent.addEventInfo(\"STATUS\", jie.getStatus());\n        tEvent.addEventInfo(\"TOTAL_MAPS\", jie.getTotalMaps());\n        tEvent.addEventInfo(\"TOTAL_REDUCES\", jie.getTotalReduces());\n        tEvent.addEventInfo(\"UBERIZED\", jie.getUberized());\n        tEntity.setStartTime(jie.getLaunchTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_PRIORITY_CHANGED:\n        JobPriorityChangeEvent jpce = (JobPriorityChangeEvent) event;\n        tEvent.addEventInfo(\"PRIORITY\", jpce.getPriority().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_QUEUE_CHANGED:\n        JobQueueChangeEvent jqe = (JobQueueChangeEvent) event;\n        tEvent.addEventInfo(\"QUEUE_NAMES\", jqe.getJobQueueName());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_FAILED:\n      case JOB_KILLED:\n      case JOB_ERROR:\n        JobUnsuccessfulCompletionEvent juce =\n              (JobUnsuccessfulCompletionEvent) event;\n        tEvent.addEventInfo(\"FINISH_TIME\", juce.getFinishTime());\n        tEvent.addEventInfo(\"NUM_MAPS\", juce.getFinishedMaps());\n        tEvent.addEventInfo(\"NUM_REDUCES\", juce.getFinishedReduces());\n        tEvent.addEventInfo(\"JOB_STATUS\", juce.getStatus());\n        tEvent.addEventInfo(\"DIAGNOSTICS\", juce.getDiagnostics());\n        tEvent.addEventInfo(\"FINISHED_MAPS\", juce.getFinishedMaps());\n        tEvent.addEventInfo(\"FINISHED_REDUCES\", juce.getFinishedReduces());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case JOB_FINISHED:\n        JobFinishedEvent jfe = (JobFinishedEvent) event;\n        tEvent.addEventInfo(\"FINISH_TIME\", jfe.getFinishTime());\n        tEvent.addEventInfo(\"NUM_MAPS\", jfe.getFinishedMaps());\n        tEvent.addEventInfo(\"NUM_REDUCES\", jfe.getFinishedReduces());\n        tEvent.addEventInfo(\"FAILED_MAPS\", jfe.getFailedMaps());\n        tEvent.addEventInfo(\"FAILED_REDUCES\", jfe.getFailedReduces());\n        tEvent.addEventInfo(\"FINISHED_MAPS\", jfe.getFinishedMaps());\n        tEvent.addEventInfo(\"FINISHED_REDUCES\", jfe.getFinishedReduces());\n        tEvent.addEventInfo(\"MAP_COUNTERS_GROUPS\",\n                countersToJSON(jfe.getTotalCounters()));\n        tEvent.addEventInfo(\"REDUCE_COUNTERS_GROUPS\",\n                countersToJSON(jfe.getReduceCounters()));\n        tEvent.addEventInfo(\"TOTAL_COUNTERS_GROUPS\",\n                countersToJSON(jfe.getTotalCounters()));\n        tEvent.addEventInfo(\"JOB_STATUS\", JobState.SUCCEEDED.toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      case TASK_STARTED:\n        TaskStartedEvent tse = (TaskStartedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tse.getTaskType().toString());\n        tEvent.addEventInfo(\"START_TIME\", tse.getStartTime());\n        tEvent.addEventInfo(\"SPLIT_LOCATIONS\", tse.getSplitLocations());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tse.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case TASK_FAILED:\n        TaskFailedEvent tfe = (TaskFailedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tfe.getTaskType().toString());\n        tEvent.addEventInfo(\"STATUS\", TaskStatus.State.FAILED.toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", tfe.getFinishTime());\n        tEvent.addEventInfo(\"ERROR\", tfe.getError());\n        tEvent.addEventInfo(\"FAILED_ATTEMPT_ID\",\n                tfe.getFailedAttemptID() == null ?\n                \"\" : tfe.getFailedAttemptID().toString());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tfe.getCounters()));\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tfe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case TASK_UPDATED:\n        TaskUpdatedEvent tue = (TaskUpdatedEvent) event;\n        tEvent.addEventInfo(\"FINISH_TIME\", tue.getFinishTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tue.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case TASK_FINISHED:\n        TaskFinishedEvent tfe2 = (TaskFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tfe2.getTaskType().toString());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tfe2.getCounters()));\n        tEvent.addEventInfo(\"FINISH_TIME\", tfe2.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", TaskStatus.State.SUCCEEDED.toString());\n        tEvent.addEventInfo(\"SUCCESSFUL_TASK_ATTEMPT_ID\",\n            tfe2.getSuccessfulTaskAttemptId() == null ?\n            \"\" : tfe2.getSuccessfulTaskAttemptId().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tfe2.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case MAP_ATTEMPT_STARTED:\n      case CLEANUP_ATTEMPT_STARTED:\n      case REDUCE_ATTEMPT_STARTED:\n      case SETUP_ATTEMPT_STARTED:\n        TaskAttemptStartedEvent tase = (TaskAttemptStartedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tase.getTaskType().toString());\n        tEvent.addEventInfo(\"TASK_ATTEMPT_ID\",\n            tase.getTaskAttemptId().toString());\n        tEvent.addEventInfo(\"START_TIME\", tase.getStartTime());\n        tEvent.addEventInfo(\"HTTP_PORT\", tase.getHttpPort());\n        tEvent.addEventInfo(\"TRACKER_NAME\", tase.getTrackerName());\n        tEvent.addEventInfo(\"TASK_TYPE\", tase.getTaskType().toString());\n        tEvent.addEventInfo(\"SHUFFLE_PORT\", tase.getShufflePort());\n        tEvent.addEventInfo(\"CONTAINER_ID\", tase.getContainerId() == null ?\n            \"\" : tase.getContainerId().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tase.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case MAP_ATTEMPT_FAILED:\n      case CLEANUP_ATTEMPT_FAILED:\n      case REDUCE_ATTEMPT_FAILED:\n      case SETUP_ATTEMPT_FAILED:\n      case MAP_ATTEMPT_KILLED:\n      case CLEANUP_ATTEMPT_KILLED:\n      case REDUCE_ATTEMPT_KILLED:\n      case SETUP_ATTEMPT_KILLED:\n        TaskAttemptUnsuccessfulCompletionEvent tauce =\n                (TaskAttemptUnsuccessfulCompletionEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tauce.getTaskType().toString());\n        tEvent.addEventInfo(\"TASK_ATTEMPT_ID\",\n            tauce.getTaskAttemptId() == null ?\n            \"\" : tauce.getTaskAttemptId().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"ERROR\", tauce.getError());\n        tEvent.addEventInfo(\"STATUS\", tauce.getTaskStatus());\n        tEvent.addEventInfo(\"HOSTNAME\", tauce.getHostname());\n        tEvent.addEventInfo(\"PORT\", tauce.getPort());\n        tEvent.addEventInfo(\"RACK_NAME\", tauce.getRackName());\n        tEvent.addEventInfo(\"SHUFFLE_FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"SORT_FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"MAP_FINISH_TIME\", tauce.getFinishTime());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tauce.getCounters()));\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tauce.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case MAP_ATTEMPT_FINISHED:\n        MapAttemptFinishedEvent mafe = (MapAttemptFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", mafe.getTaskType().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", mafe.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", mafe.getTaskStatus());\n        tEvent.addEventInfo(\"STATE\", mafe.getState());\n        tEvent.addEventInfo(\"MAP_FINISH_TIME\", mafe.getMapFinishTime());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(mafe.getCounters()));\n        tEvent.addEventInfo(\"HOSTNAME\", mafe.getHostname());\n        tEvent.addEventInfo(\"PORT\", mafe.getPort());\n        tEvent.addEventInfo(\"RACK_NAME\", mafe.getRackName());\n        tEvent.addEventInfo(\"ATTEMPT_ID\", mafe.getAttemptId() == null ?\n            \"\" : mafe.getAttemptId().toString());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(mafe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case REDUCE_ATTEMPT_FINISHED:\n        ReduceAttemptFinishedEvent rafe = (ReduceAttemptFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", rafe.getTaskType().toString());\n        tEvent.addEventInfo(\"ATTEMPT_ID\", rafe.getAttemptId() == null ?\n            \"\" : rafe.getAttemptId().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", rafe.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", rafe.getTaskStatus());\n        tEvent.addEventInfo(\"STATE\", rafe.getState());\n        tEvent.addEventInfo(\"SHUFFLE_FINISH_TIME\", rafe.getShuffleFinishTime());\n        tEvent.addEventInfo(\"SORT_FINISH_TIME\", rafe.getSortFinishTime());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(rafe.getCounters()));\n        tEvent.addEventInfo(\"HOSTNAME\", rafe.getHostname());\n        tEvent.addEventInfo(\"PORT\", rafe.getPort());\n        tEvent.addEventInfo(\"RACK_NAME\", rafe.getRackName());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(rafe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case SETUP_ATTEMPT_FINISHED:\n      case CLEANUP_ATTEMPT_FINISHED:\n        TaskAttemptFinishedEvent tafe = (TaskAttemptFinishedEvent) event;\n        tEvent.addEventInfo(\"TASK_TYPE\", tafe.getTaskType().toString());\n        tEvent.addEventInfo(\"ATTEMPT_ID\", tafe.getAttemptId() == null ?\n            \"\" : tafe.getAttemptId().toString());\n        tEvent.addEventInfo(\"FINISH_TIME\", tafe.getFinishTime());\n        tEvent.addEventInfo(\"STATUS\", tafe.getTaskStatus());\n        tEvent.addEventInfo(\"STATE\", tafe.getState());\n        tEvent.addEventInfo(\"COUNTERS_GROUPS\",\n                countersToJSON(tafe.getCounters()));\n        tEvent.addEventInfo(\"HOSTNAME\", tafe.getHostname());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(tafe.getTaskId().toString());\n        tEntity.setEntityType(MAPREDUCE_TASK_ENTITY_TYPE);\n        tEntity.addRelatedEntity(MAPREDUCE_JOB_ENTITY_TYPE, jobId.toString());\n        break;\n      case AM_STARTED:\n        AMStartedEvent ase = (AMStartedEvent) event;\n        tEvent.addEventInfo(\"APPLICATION_ATTEMPT_ID\",\n                ase.getAppAttemptId() == null ?\n                \"\" : ase.getAppAttemptId().toString());\n        tEvent.addEventInfo(\"CONTAINER_ID\", ase.getContainerId() == null ?\n                \"\" : ase.getContainerId().toString());\n        tEvent.addEventInfo(\"NODE_MANAGER_HOST\", ase.getNodeManagerHost());\n        tEvent.addEventInfo(\"NODE_MANAGER_PORT\", ase.getNodeManagerPort());\n        tEvent.addEventInfo(\"NODE_MANAGER_HTTP_PORT\",\n                ase.getNodeManagerHttpPort());\n        tEvent.addEventInfo(\"START_TIME\", ase.getStartTime());\n        tEvent.addEventInfo(\"SUBMIT_TIME\", ase.getSubmitTime());\n        tEntity.addEvent(tEvent);\n        tEntity.setEntityId(jobId.toString());\n        tEntity.setEntityType(MAPREDUCE_JOB_ENTITY_TYPE);\n        break;\n      default:\n        break;\n    }\n\n    try {\n      timelineClient.putEntities(tEntity);\n    } catch (IOException ex) {\n      LOG.error(\"Error putting entity \" + tEntity.getEntityId() + \" to Timeline\"\n      + \"Server\", ex);\n    } catch (YarnException ex) {\n      LOG.error(\"Error putting entity \" + tEntity.getEntityId() + \" to Timeline\"\n      + \"Server\", ex);\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart": {
                "code_before_change": "    protected void serviceStart() throws Exception {\n      if (job.isUber()) {\n        MRApps.setupDistributedCacheLocal(getConfig());\n        this.containerAllocator = new LocalContainerAllocator(\n            this.clientService, this.context, nmHost, nmPort, nmHttpPort\n            , containerID);\n      } else {\n        this.containerAllocator = new RMContainerAllocator(\n            this.clientService, this.context, preemptionPolicy);\n      }\n      ((Service)this.containerAllocator).init(getConfig());\n      ((Service)this.containerAllocator).start();\n      super.serviceStart();\n    }",
                "code_after_change": "    protected void serviceStart() throws Exception {\n      if (job.isUber()) {\n        MRApps.setupDistributedCacheLocal(getConfig());\n        this.containerAllocator = new LocalContainerAllocator(\n            this.clientService, this.context, nmHost, nmPort, nmHttpPort\n            , containerID);\n      } else {\n        this.containerAllocator = new RMContainerAllocator(\n            this.clientService, this.context);\n      }\n      ((Service)this.containerAllocator).init(getConfig());\n      ((Service)this.containerAllocator).start();\n      super.serviceStart();\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.getForcedJobStateOnShutDown": {
                "code_before_change": "  public String getForcedJobStateOnShutDown() {\n    return this.forcedJobStateOnShutDown;\n  }",
                "code_after_change": "  public String getForcedJobStateOnShutDown() {\n    return this.forcedJobStateOnShutDown;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.setupEventWriter": {
                "code_before_change": "  protected void setupEventWriter(JobId jobId, String forcedJobStateOnShutDown)\n      throws IOException {\n    if (stagingDirPath == null) {\n      LOG.error(\"Log Directory is null, returning\");\n      throw new IOException(\"Missing Log Directory for History\");\n    }\n\n    MetaInfo oldFi = fileMap.get(jobId);\n    Configuration conf = getConfig();\n\n    // TODO Ideally this should be written out to the job dir\n    // (.staging/jobid/files - RecoveryService will need to be patched)\n    Path historyFile = JobHistoryUtils.getStagingJobHistoryFile(\n        stagingDirPath, jobId, startCount);\n    String user = UserGroupInformation.getCurrentUser().getShortUserName();\n    if (user == null) {\n      throw new IOException(\n          \"User is null while setting up jobhistory eventwriter\");\n    }\n\n    String jobName = context.getJob(jobId).getName();\n    EventWriter writer = (oldFi == null) ? null : oldFi.writer;\n \n    Path logDirConfPath =\n        JobHistoryUtils.getStagingConfFile(stagingDirPath, jobId, startCount);\n    if (writer == null) {\n      try {\n        writer = createEventWriter(historyFile);\n        LOG.info(\"Event Writer setup for JobId: \" + jobId + \", File: \"\n            + historyFile);\n      } catch (IOException ioe) {\n        LOG.info(\"Could not create log file: [\" + historyFile + \"] + for job \"\n            + \"[\" + jobName + \"]\");\n        throw ioe;\n      }\n      \n      //Write out conf only if the writer isn't already setup.\n      if (conf != null) {\n        // TODO Ideally this should be written out to the job dir\n        // (.staging/jobid/files - RecoveryService will need to be patched)\n        FSDataOutputStream jobFileOut = null;\n        try {\n          if (logDirConfPath != null) {\n            jobFileOut = stagingDirFS.create(logDirConfPath, true);\n            conf.writeXml(jobFileOut);\n            jobFileOut.close();\n          }\n        } catch (IOException e) {\n          LOG.info(\"Failed to write the job configuration file\", e);\n          throw e;\n        }\n      }\n    }\n\n    String queueName = JobConf.DEFAULT_QUEUE_NAME;\n    if (conf != null) {\n      queueName = conf.get(MRJobConfig.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME);\n    }\n\n    MetaInfo fi = new MetaInfo(historyFile, logDirConfPath, writer,\n        user, jobName, jobId, forcedJobStateOnShutDown, queueName);\n    fi.getJobSummary().setJobId(jobId);\n    fileMap.put(jobId, fi);\n  }",
                "code_after_change": "  protected void setupEventWriter(JobId jobId, AMStartedEvent amStartedEvent)\n      throws IOException {\n    if (stagingDirPath == null) {\n      LOG.error(\"Log Directory is null, returning\");\n      throw new IOException(\"Missing Log Directory for History\");\n    }\n\n    MetaInfo oldFi = fileMap.get(jobId);\n    Configuration conf = getConfig();\n\n    // TODO Ideally this should be written out to the job dir\n    // (.staging/jobid/files - RecoveryService will need to be patched)\n    Path historyFile = JobHistoryUtils.getStagingJobHistoryFile(\n        stagingDirPath, jobId, startCount);\n    String user = UserGroupInformation.getCurrentUser().getShortUserName();\n    if (user == null) {\n      throw new IOException(\n          \"User is null while setting up jobhistory eventwriter\");\n    }\n\n    String jobName = context.getJob(jobId).getName();\n    EventWriter writer = (oldFi == null) ? null : oldFi.writer;\n \n    Path logDirConfPath =\n        JobHistoryUtils.getStagingConfFile(stagingDirPath, jobId, startCount);\n    if (writer == null) {\n      try {\n        writer = createEventWriter(historyFile);\n        LOG.info(\"Event Writer setup for JobId: \" + jobId + \", File: \"\n            + historyFile);\n      } catch (IOException ioe) {\n        LOG.info(\"Could not create log file: [\" + historyFile + \"] + for job \"\n            + \"[\" + jobName + \"]\");\n        throw ioe;\n      }\n      \n      //Write out conf only if the writer isn't already setup.\n      if (conf != null) {\n        // TODO Ideally this should be written out to the job dir\n        // (.staging/jobid/files - RecoveryService will need to be patched)\n        FSDataOutputStream jobFileOut = null;\n        try {\n          if (logDirConfPath != null) {\n            jobFileOut = stagingDirFS.create(logDirConfPath, true);\n            conf.writeXml(jobFileOut);\n            jobFileOut.close();\n          }\n        } catch (IOException e) {\n          LOG.info(\"Failed to write the job configuration file\", e);\n          throw e;\n        }\n      }\n    }\n\n    String queueName = JobConf.DEFAULT_QUEUE_NAME;\n    if (conf != null) {\n      queueName = conf.get(MRJobConfig.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME);\n    }\n\n    MetaInfo fi = new MetaInfo(historyFile, logDirConfPath, writer,\n        user, jobName, jobId, amStartedEvent.getForcedJobStateOnShutDown(),\n        queueName);\n    fi.getJobSummary().setJobId(jobId);\n    fi.getJobSummary().setJobLaunchTime(amStartedEvent.getStartTime());\n    fi.getJobSummary().setJobSubmitTime(amStartedEvent.getSubmitTime());\n    fi.getJobIndexInfo().setJobStartTime(amStartedEvent.getStartTime());\n    fi.getJobIndexInfo().setSubmitTime(amStartedEvent.getSubmitTime());\n    fileMap.put(jobId, fi);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent": {
                "code_before_change": "  public void handleEvent(JobHistoryEvent event) {\n    synchronized (lock) {\n\n      // If this is JobSubmitted Event, setup the writer\n      if (event.getHistoryEvent().getEventType() == EventType.AM_STARTED) {\n        try {\n          AMStartedEvent amStartedEvent =\n              (AMStartedEvent) event.getHistoryEvent();\n          setupEventWriter(event.getJobID(),\n              amStartedEvent.getForcedJobStateOnShutDown());\n        } catch (IOException ioe) {\n          LOG.error(\"Error JobHistoryEventHandler in handleEvent: \" + event,\n              ioe);\n          throw new YarnRuntimeException(ioe);\n        }\n      }\n\n      // For all events\n      // (1) Write it out\n      // (2) Process it for JobSummary\n      // (3) Process it for ATS (if enabled)\n      MetaInfo mi = fileMap.get(event.getJobID());\n      try {\n        HistoryEvent historyEvent = event.getHistoryEvent();\n        if (! (historyEvent instanceof NormalizedResourceEvent)) {\n          mi.writeEvent(historyEvent);\n        }\n        processEventForJobSummary(event.getHistoryEvent(), mi.getJobSummary(),\n            event.getJobID());\n        if (timelineClient != null) {\n          processEventForTimelineServer(historyEvent, event.getJobID(),\n              event.getTimestamp());\n        }\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"In HistoryEventHandler \"\n              + event.getHistoryEvent().getEventType());\n        }\n      } catch (IOException e) {\n        LOG.error(\"Error writing History Event: \" + event.getHistoryEvent(),\n            e);\n        throw new YarnRuntimeException(e);\n      }\n\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_SUBMITTED) {\n        JobSubmittedEvent jobSubmittedEvent =\n            (JobSubmittedEvent) event.getHistoryEvent();\n        mi.getJobIndexInfo().setSubmitTime(jobSubmittedEvent.getSubmitTime());\n        mi.getJobIndexInfo().setQueueName(jobSubmittedEvent.getJobQueueName());\n      }\n      //initialize the launchTime in the JobIndexInfo of MetaInfo\n      if(event.getHistoryEvent().getEventType() == EventType.JOB_INITED ){\n        JobInitedEvent jie = (JobInitedEvent) event.getHistoryEvent();\n        mi.getJobIndexInfo().setJobStartTime(jie.getLaunchTime());\n      }\n      \n      if (event.getHistoryEvent().getEventType() == EventType.JOB_QUEUE_CHANGED) {\n        JobQueueChangeEvent jQueueEvent =\n            (JobQueueChangeEvent) event.getHistoryEvent();\n        mi.getJobIndexInfo().setQueueName(jQueueEvent.getJobQueueName());\n      }\n\n      // If this is JobFinishedEvent, close the writer and setup the job-index\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_FINISHED) {\n        try {\n          JobFinishedEvent jFinishedEvent =\n              (JobFinishedEvent) event.getHistoryEvent();\n          mi.getJobIndexInfo().setFinishTime(jFinishedEvent.getFinishTime());\n          mi.getJobIndexInfo().setNumMaps(jFinishedEvent.getFinishedMaps());\n          mi.getJobIndexInfo().setNumReduces(\n              jFinishedEvent.getFinishedReduces());\n          mi.getJobIndexInfo().setJobStatus(JobState.SUCCEEDED.toString());\n          closeEventWriter(event.getJobID());\n          processDoneFiles(event.getJobID());\n        } catch (IOException e) {\n          throw new YarnRuntimeException(e);\n        }\n      }\n      // In case of JOB_ERROR, only process all the Done files(e.g. job\n      // summary, job history file etc.) if it is last AM retry.\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_ERROR) {\n        try {\n          JobUnsuccessfulCompletionEvent jucEvent =\n              (JobUnsuccessfulCompletionEvent) event.getHistoryEvent();\n          mi.getJobIndexInfo().setFinishTime(jucEvent.getFinishTime());\n          mi.getJobIndexInfo().setNumMaps(jucEvent.getFinishedMaps());\n          mi.getJobIndexInfo().setNumReduces(jucEvent.getFinishedReduces());\n          mi.getJobIndexInfo().setJobStatus(jucEvent.getStatus());\n          closeEventWriter(event.getJobID());\n          if(context.isLastAMRetry())\n            processDoneFiles(event.getJobID());\n        } catch (IOException e) {\n          throw new YarnRuntimeException(e);\n        }\n      }\n\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_FAILED\n          || event.getHistoryEvent().getEventType() == EventType.JOB_KILLED) {\n        try {\n          JobUnsuccessfulCompletionEvent jucEvent = \n              (JobUnsuccessfulCompletionEvent) event\n              .getHistoryEvent();\n          mi.getJobIndexInfo().setFinishTime(jucEvent.getFinishTime());\n          mi.getJobIndexInfo().setNumMaps(jucEvent.getFinishedMaps());\n          mi.getJobIndexInfo().setNumReduces(jucEvent.getFinishedReduces());\n          mi.getJobIndexInfo().setJobStatus(jucEvent.getStatus());\n          closeEventWriter(event.getJobID());\n          processDoneFiles(event.getJobID());\n        } catch (IOException e) {\n          throw new YarnRuntimeException(e);\n        }\n      }\n    }\n  }",
                "code_after_change": "  public void handleEvent(JobHistoryEvent event) {\n    synchronized (lock) {\n\n      // If this is JobSubmitted Event, setup the writer\n      if (event.getHistoryEvent().getEventType() == EventType.AM_STARTED) {\n        try {\n          AMStartedEvent amStartedEvent =\n              (AMStartedEvent) event.getHistoryEvent();\n          setupEventWriter(event.getJobID(), amStartedEvent);\n        } catch (IOException ioe) {\n          LOG.error(\"Error JobHistoryEventHandler in handleEvent: \" + event,\n              ioe);\n          throw new YarnRuntimeException(ioe);\n        }\n      }\n\n      // For all events\n      // (1) Write it out\n      // (2) Process it for JobSummary\n      // (3) Process it for ATS (if enabled)\n      MetaInfo mi = fileMap.get(event.getJobID());\n      try {\n        HistoryEvent historyEvent = event.getHistoryEvent();\n        if (! (historyEvent instanceof NormalizedResourceEvent)) {\n          mi.writeEvent(historyEvent);\n        }\n        processEventForJobSummary(event.getHistoryEvent(), mi.getJobSummary(),\n            event.getJobID());\n        if (timelineClient != null) {\n          processEventForTimelineServer(historyEvent, event.getJobID(),\n              event.getTimestamp());\n        }\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"In HistoryEventHandler \"\n              + event.getHistoryEvent().getEventType());\n        }\n      } catch (IOException e) {\n        LOG.error(\"Error writing History Event: \" + event.getHistoryEvent(),\n            e);\n        throw new YarnRuntimeException(e);\n      }\n\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_SUBMITTED) {\n        JobSubmittedEvent jobSubmittedEvent =\n            (JobSubmittedEvent) event.getHistoryEvent();\n        mi.getJobIndexInfo().setSubmitTime(jobSubmittedEvent.getSubmitTime());\n        mi.getJobIndexInfo().setQueueName(jobSubmittedEvent.getJobQueueName());\n      }\n      //initialize the launchTime in the JobIndexInfo of MetaInfo\n      if(event.getHistoryEvent().getEventType() == EventType.JOB_INITED ){\n        JobInitedEvent jie = (JobInitedEvent) event.getHistoryEvent();\n        mi.getJobIndexInfo().setJobStartTime(jie.getLaunchTime());\n      }\n      \n      if (event.getHistoryEvent().getEventType() == EventType.JOB_QUEUE_CHANGED) {\n        JobQueueChangeEvent jQueueEvent =\n            (JobQueueChangeEvent) event.getHistoryEvent();\n        mi.getJobIndexInfo().setQueueName(jQueueEvent.getJobQueueName());\n      }\n\n      // If this is JobFinishedEvent, close the writer and setup the job-index\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_FINISHED) {\n        try {\n          JobFinishedEvent jFinishedEvent =\n              (JobFinishedEvent) event.getHistoryEvent();\n          mi.getJobIndexInfo().setFinishTime(jFinishedEvent.getFinishTime());\n          mi.getJobIndexInfo().setNumMaps(jFinishedEvent.getFinishedMaps());\n          mi.getJobIndexInfo().setNumReduces(\n              jFinishedEvent.getFinishedReduces());\n          mi.getJobIndexInfo().setJobStatus(JobState.SUCCEEDED.toString());\n          closeEventWriter(event.getJobID());\n          processDoneFiles(event.getJobID());\n        } catch (IOException e) {\n          throw new YarnRuntimeException(e);\n        }\n      }\n      // In case of JOB_ERROR, only process all the Done files(e.g. job\n      // summary, job history file etc.) if it is last AM retry.\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_ERROR) {\n        try {\n          JobUnsuccessfulCompletionEvent jucEvent =\n              (JobUnsuccessfulCompletionEvent) event.getHistoryEvent();\n          mi.getJobIndexInfo().setFinishTime(jucEvent.getFinishTime());\n          mi.getJobIndexInfo().setNumMaps(jucEvent.getFinishedMaps());\n          mi.getJobIndexInfo().setNumReduces(jucEvent.getFinishedReduces());\n          mi.getJobIndexInfo().setJobStatus(jucEvent.getStatus());\n          closeEventWriter(event.getJobID());\n          if(context.isLastAMRetry())\n            processDoneFiles(event.getJobID());\n        } catch (IOException e) {\n          throw new YarnRuntimeException(e);\n        }\n      }\n\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_FAILED\n          || event.getHistoryEvent().getEventType() == EventType.JOB_KILLED) {\n        try {\n          JobUnsuccessfulCompletionEvent jucEvent = \n              (JobUnsuccessfulCompletionEvent) event\n              .getHistoryEvent();\n          mi.getJobIndexInfo().setFinishTime(jucEvent.getFinishTime());\n          mi.getJobIndexInfo().setNumMaps(jucEvent.getFinishedMaps());\n          mi.getJobIndexInfo().setNumReduces(jucEvent.getFinishedReduces());\n          mi.getJobIndexInfo().setJobStatus(jucEvent.getStatus());\n          closeEventWriter(event.getJobID());\n          processDoneFiles(event.getJobID());\n        } catch (IOException e) {\n          throw new YarnRuntimeException(e);\n        }\n      }\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.createEventWriter": {
                "code_before_change": "  protected EventWriter createEventWriter(Path historyFilePath)\n      throws IOException {\n    FSDataOutputStream out = stagingDirFS.create(historyFilePath, true);\n    return new EventWriter(out);\n  }",
                "code_after_change": "  protected EventWriter createEventWriter(Path historyFilePath)\n      throws IOException {\n    FSDataOutputStream out = stagingDirFS.create(historyFilePath, true);\n    return new EventWriter(out);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent.AMStartedEvent": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the job submit time not being updated due to an IOException in JobImpl#setup, which is a closely related method but not the exact ground truth method where the fix was applied. Therefore, it is classified as 'Partial' under 'Buggy Method'. The fix suggestion involves implementing error handling in JobImpl#setup, which is preventive as it aims to mitigate the issue by ensuring the job submit time is updated even if an IOException occurs. The problem location identification mentions JobImpl#setup, which is the method where the error occurred but not where the actual fix was made, thus classified as 'Partial' under 'Buggy Method'. There is no wrong information in the bug report as all statements are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3333.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine.invoke": {
                "code_before_change": "    public Object invoke(Object proxy, Method method, Object[] args)\n        throws Throwable {\n      long startTime = 0;\n      if (LOG.isDebugEnabled()) {\n        startTime = System.currentTimeMillis();\n      }\n\n      ProtoSpecificRpcRequest rpcRequest = constructRpcRequest(method, args);\n      ProtoSpecificResponseWritable val = null;\n      try {\n        val = (ProtoSpecificResponseWritable) client.call(\n            new ProtoSpecificRequestWritable(rpcRequest), remoteId);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      \n      ProtoSpecificRpcResponse response = val.message;\n   \n      if (LOG.isDebugEnabled()) {\n        long callTime = System.currentTimeMillis() - startTime;\n        LOG.debug(\"Call: \" + method.getName() + \" \" + callTime);\n      }\n \n      if (response.hasIsError() && response.getIsError() == true) {\n        YarnRemoteExceptionPBImpl exception = new YarnRemoteExceptionPBImpl(response.getException());\n        exception.fillInStackTrace();\n        ServiceException se = new ServiceException(exception);\n        throw se;\n      }\n      \n      Message prototype = null;\n      try {\n        prototype = getReturnProtoType(method);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      Message actualReturnMessage = prototype.newBuilderForType()\n          .mergeFrom(response.getResponseProto()).build();\n      return actualReturnMessage;\n    }",
                "code_after_change": "    public Object invoke(Object proxy, Method method, Object[] args)\n        throws Throwable {\n      long startTime = 0;\n      if (LOG.isDebugEnabled()) {\n        startTime = System.currentTimeMillis();\n      }\n\n      ProtoSpecificRpcRequest rpcRequest = constructRpcRequest(method, args);\n      ProtoSpecificResponseWritable val = null;\n      try {\n        val = (ProtoSpecificResponseWritable) client.call(\n            new ProtoSpecificRequestWritable(rpcRequest), remoteId);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      \n      ProtoSpecificRpcResponse response = val.message;\n   \n      if (LOG.isDebugEnabled()) {\n        long callTime = System.currentTimeMillis() - startTime;\n        LOG.debug(\"Call: \" + method.getName() + \" \" + callTime);\n      }\n \n      if (response.hasIsError() && response.getIsError() == true) {\n        YarnRemoteExceptionPBImpl exception = new YarnRemoteExceptionPBImpl(response.getException());\n        exception.fillInStackTrace();\n        ServiceException se = new ServiceException(exception);\n        throw se;\n      }\n      \n      Message prototype = null;\n      try {\n        prototype = getReturnProtoType(method);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      Message actualReturnMessage = prototype.newBuilderForType()\n          .mergeFrom(response.getResponseProto()).build();\n      return actualReturnMessage;\n    }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC.getProxy": {
                "code_before_change": "  public Object getProxy(Class protocol, InetSocketAddress addr,\n      Configuration conf) {\n    LOG.info(\"Creating a HadoopYarnProtoRpc proxy for protocol \" + protocol);\n    return RpcFactoryProvider.getClientFactory(conf).getClient(protocol, 1,\n        addr, conf);\n  }",
                "code_after_change": "  public Object getProxy(Class protocol, InetSocketAddress addr,\n      Configuration conf) {\n    LOG.info(\"Creating a HadoopYarnProtoRpc proxy for protocol \" + protocol);\n    return RpcFactoryProvider.getClientFactory(conf).getClient(protocol, 1,\n        addr, conf);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.HadoopYarnRPC.getProxy": {
                "code_before_change": "  public Object getProxy(Class protocol, InetSocketAddress addr,\n      Configuration conf) {\n    LOG.info(\"Creating a HadoopYarnRpc proxy for protocol \" + protocol);\n    RPC.setProtocolEngine(conf, protocol, AvroSpecificRpcEngine.class);\n    try {\n      return RPC.getProxy(protocol, 1, addr, conf);\n    } catch (IOException e) {\n      throw new YarnException(e);\n    }\n  }",
                "code_after_change": "  public Object getProxy(Class protocol, InetSocketAddress addr,\n      Configuration conf) {\n    LOG.info(\"Creating a HadoopYarnRpc proxy for protocol \" + protocol);\n    RPC.setProtocolEngine(conf, protocol, AvroSpecificRpcEngine.class);\n    try {\n      return RPC.getProxy(protocol, 1, addr, conf);\n    } catch (IOException e) {\n      throw new YarnException(e);\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy": {
                "code_before_change": "  protected ContainerManager getCMProxy(ContainerId containerID,\n      final String containerManagerBindAddr, ContainerToken containerToken)\n      throws IOException {\n\n    UserGroupInformation user = UserGroupInformation.getCurrentUser();\n\n    synchronized (this.clientCache) {\n\n      if (this.clientCache.containsKey(containerID)) {\n        return this.clientCache.get(containerID);\n      }\n\n      this.allNodes.add(containerManagerBindAddr);\n\n      if (UserGroupInformation.isSecurityEnabled()) {\n        Token<ContainerTokenIdentifier> token = new Token<ContainerTokenIdentifier>(\n            containerToken.getIdentifier().array(), containerToken\n                .getPassword().array(), new Text(containerToken.getKind()),\n            new Text(containerToken.getService()));\n        // the user in createRemoteUser in this context has to be ContainerID\n        user = UserGroupInformation.createRemoteUser(containerID.toString());\n        user.addToken(token);\n      }\n\n      ContainerManager proxy = user\n          .doAs(new PrivilegedAction<ContainerManager>() {\n            @Override\n            public ContainerManager run() {\n              YarnRPC rpc = YarnRPC.create(getConfig());\n              return (ContainerManager) rpc.getProxy(ContainerManager.class,\n                  NetUtils.createSocketAddr(containerManagerBindAddr),\n                  getConfig());\n            }\n          });\n      this.clientCache.put(containerID, proxy);\n      return proxy;\n    }\n  }",
                "code_after_change": "  protected ContainerManager getCMProxy(ContainerId containerID,\n      final String containerManagerBindAddr, ContainerToken containerToken)\n      throws IOException {\n\n    UserGroupInformation user = UserGroupInformation.getCurrentUser();\n\n    this.allNodes.add(containerManagerBindAddr);\n\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Token<ContainerTokenIdentifier> token = new Token<ContainerTokenIdentifier>(\n          containerToken.getIdentifier().array(), containerToken\n              .getPassword().array(), new Text(containerToken.getKind()),\n          new Text(containerToken.getService()));\n      // the user in createRemoteUser in this context has to be ContainerID\n      user = UserGroupInformation.createRemoteUser(containerID.toString());\n      user.addToken(token);\n    }\n\n    ContainerManager proxy = user\n        .doAs(new PrivilegedAction<ContainerManager>() {\n          @Override\n          public ContainerManager run() {\n            return (ContainerManager) rpc.getProxy(ContainerManager.class,\n                NetUtils.createSocketAddr(containerManagerBindAddr),\n                getConfig());\n          }\n        });\n    return proxy;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.ContainerManagerPBClientImpl": {
                "code_before_change": [],
                "code_after_change": []
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.factories.impl.pb.RpcClientFactoryPBImpl.getClient": {
                "code_before_change": "  public Object getClient(Class<?> protocol, long clientVersion, InetSocketAddress addr, Configuration conf) throws YarnException {\n   \n    Constructor<?> constructor = cache.get(protocol);\n    if (constructor == null) {\n      Class<?> pbClazz = null;\n      try {\n        pbClazz = localConf.getClassByName(getPBImplClassName(protocol));\n      } catch (ClassNotFoundException e) {\n        throw new YarnException(\"Failed to load class: [\"\n            + getPBImplClassName(protocol) + \"]\", e);\n      }\n      try {\n        constructor = pbClazz.getConstructor(Long.TYPE, InetSocketAddress.class, Configuration.class);\n        constructor.setAccessible(true);\n        cache.putIfAbsent(protocol, constructor);\n      } catch (NoSuchMethodException e) {\n        throw new YarnException(\"Could not find constructor with params: \" + Long.TYPE + \", \" + InetSocketAddress.class + \", \" + Configuration.class, e);\n      }\n    }\n    try {\n      Object retObject = constructor.newInstance(clientVersion, addr, conf);\n      return retObject;\n    } catch (InvocationTargetException e) {\n      throw new YarnException(e);\n    } catch (IllegalAccessException e) {\n      throw new YarnException(e);\n    } catch (InstantiationException e) {\n      throw new YarnException(e);\n    }\n  }",
                "code_after_change": "  public Object getClient(Class<?> protocol, long clientVersion, InetSocketAddress addr, Configuration conf) throws YarnException {\n   \n    Constructor<?> constructor = cache.get(protocol);\n    if (constructor == null) {\n      Class<?> pbClazz = null;\n      try {\n        pbClazz = localConf.getClassByName(getPBImplClassName(protocol));\n      } catch (ClassNotFoundException e) {\n        throw new YarnException(\"Failed to load class: [\"\n            + getPBImplClassName(protocol) + \"]\", e);\n      }\n      try {\n        constructor = pbClazz.getConstructor(Long.TYPE, InetSocketAddress.class, Configuration.class);\n        constructor.setAccessible(true);\n        cache.putIfAbsent(protocol, constructor);\n      } catch (NoSuchMethodException e) {\n        throw new YarnException(\"Could not find constructor with params: \" + Long.TYPE + \", \" + InetSocketAddress.class + \", \" + Configuration.class, e);\n      }\n    }\n    try {\n      Object retObject = constructor.newInstance(clientVersion, addr, conf);\n      return retObject;\n    } catch (InvocationTargetException e) {\n      throw new YarnException(e);\n    } catch (IllegalAccessException e) {\n      throw new YarnException(e);\n    } catch (InstantiationException e) {\n      throw new YarnException(e);\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.run": {
                "code_before_change": "      public void run() {\n        ContainerLauncherEvent event = null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event = eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize = launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven't reached the\n          // maximum limit yet.\n          if (poolSize != limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn't need to be.\n            int numNodes = allNodes.size();\n            int idealPoolSize = Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize <= idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize = idealPoolSize + INITIAL_POOL_SIZE;\n              LOG.info(\"Setting ContainerLauncher pool size to \"\n                  + newPoolSize);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }",
                "code_after_change": "      public void run() {\n        ContainerLauncherEvent event = null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event = eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n\n          int poolSize = launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven't reached the\n          // maximum limit yet.\n          if (poolSize != limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn't need to be.\n            int numNodes = allNodes.size();\n            int idealPoolSize = Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize <= idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize = idealPoolSize + INITIAL_POOL_SIZE;\n              LOG.info(\"Setting ContainerLauncher pool size to \"\n                  + newPoolSize);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(new EventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the OutOfMemoryError due to the inability to create new native threads, which is related to resource exhaustion. This is mentioned in the stack trace context but not directly in the ground truth methods, hence 'Partial' with 'Shared Stack Trace Context'. The fix suggestion involves increasing memory allocation and reviewing thread limits, which are preventive measures to mitigate the issue. The problem location mentions methods in the stack trace context but not the exact ground truth methods, so it is 'Partial' with 'Shared Stack Trace Context'. There is no wrong information as all details are relevant to the bug context."
        }
    },
    {
        "filename": "MAPREDUCE-7059.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.JobResourceUploader.validateFilePath": {
                "code_before_change": "  private String validateFilePath(String file, Configuration conf)\n      throws IOException {\n    if (file == null) {\n      return null;\n    }\n    if (file.isEmpty()) {\n      throw new IllegalArgumentException(\"File name can't be empty string\");\n    }\n    String finalPath;\n    URI pathURI;\n    try {\n      pathURI = new URI(file);\n    } catch (URISyntaxException e) {\n      throw new IllegalArgumentException(e);\n    }\n    Path path = new Path(pathURI);\n    FileSystem localFs = FileSystem.getLocal(conf);\n    if (pathURI.getScheme() == null) {\n      // default to the local file system\n      // check if the file exists or not first\n      localFs.getFileStatus(path);\n      finalPath =\n          path.makeQualified(localFs.getUri(), localFs.getWorkingDirectory())\n              .toString();\n    } else {\n      // check if the file exists in this file system\n      // we need to recreate this filesystem object to copy\n      // these files to the file system ResourceManager is running\n      // on.\n      FileSystem fs = path.getFileSystem(conf);\n      fs.getFileStatus(path);\n      finalPath =\n          path.makeQualified(fs.getUri(), fs.getWorkingDirectory()).toString();\n    }\n    return finalPath;\n  }",
                "code_after_change": "  private String validateFilePath(String file, Configuration conf)\n      throws IOException {\n    if (file == null) {\n      return null;\n    }\n    if (file.isEmpty()) {\n      throw new IllegalArgumentException(\"File name can't be empty string\");\n    }\n    String finalPath;\n    URI pathURI;\n    try {\n      pathURI = new URI(file);\n    } catch (URISyntaxException e) {\n      throw new IllegalArgumentException(e);\n    }\n    Path path = new Path(pathURI);\n    FileSystem localFs = FileSystem.getLocal(conf);\n    if (pathURI.getScheme() == null) {\n      // default to the local file system\n      // check if the file exists or not first\n      localFs.getFileStatus(path);\n      finalPath =\n          path.makeQualified(localFs.getUri(), localFs.getWorkingDirectory())\n              .toString();\n    } else {\n      // check if the file exists in this file system\n      // we need to recreate this filesystem object to copy\n      // these files to the file system ResourceManager is running\n      // on.\n      FileSystem fs = path.getFileSystem(conf);\n      fs.getFileStatus(path);\n      finalPath =\n          path.makeQualified(fs.getUri(), fs.getWorkingDirectory()).toString();\n    }\n    return finalPath;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal": {
                "code_before_change": "  private void uploadResourcesInternal(Job job, Path submitJobDir)\n      throws IOException {\n    Configuration conf = job.getConfiguration();\n    short replication =\n        (short) conf.getInt(Job.SUBMIT_REPLICATION,\n            Job.DEFAULT_SUBMIT_REPLICATION);\n\n    if (!(conf.getBoolean(Job.USED_GENERIC_PARSER, false))) {\n      LOG.warn(\"Hadoop command-line option parsing not performed. \"\n          + \"Implement the Tool interface and execute your application \"\n          + \"with ToolRunner to remedy this.\");\n    }\n\n    //\n    // Figure out what fs the JobTracker is using. Copy the\n    // job to it, under a temporary name. This allows DFS to work,\n    // and under the local fs also provides UNIX-like object loading\n    // semantics. (that is, if the job file is deleted right after\n    // submission, we can still run the submission to completion)\n    //\n\n    // Create a number of filenames in the JobTracker's fs namespace\n    LOG.debug(\"default FileSystem: \" + jtFs.getUri());\n    if (jtFs.exists(submitJobDir)) {\n      throw new IOException(\"Not submitting job. Job directory \" + submitJobDir\n          + \" already exists!! This is unexpected.Please check what's there in\"\n          + \" that directory\");\n    }\n    // Create the submission directory for the MapReduce job.\n    submitJobDir = jtFs.makeQualified(submitJobDir);\n    submitJobDir = new Path(submitJobDir.toUri().getPath());\n    FsPermission mapredSysPerms =\n        new FsPermission(JobSubmissionFiles.JOB_DIR_PERMISSION);\n    mkdirs(jtFs, submitJobDir, mapredSysPerms);\n\n    if (!conf.getBoolean(MRJobConfig.MR_AM_STAGING_DIR_ERASURECODING_ENABLED,\n        MRJobConfig.DEFAULT_MR_AM_STAGING_ERASURECODING_ENABLED)) {\n      disableErasureCodingForPath(jtFs, submitJobDir);\n    }\n\n    // Get the resources that have been added via command line arguments in the\n    // GenericOptionsParser (i.e. files, libjars, archives).\n    Collection<String> files = conf.getStringCollection(\"tmpfiles\");\n    Collection<String> libjars = conf.getStringCollection(\"tmpjars\");\n    Collection<String> archives = conf.getStringCollection(\"tmparchives\");\n    String jobJar = job.getJar();\n\n    // Merge resources that have been programmatically specified for the shared\n    // cache via the Job API.\n    files.addAll(conf.getStringCollection(MRJobConfig.FILES_FOR_SHARED_CACHE));\n    libjars.addAll(conf.getStringCollection(\n            MRJobConfig.FILES_FOR_CLASSPATH_AND_SHARED_CACHE));\n    archives.addAll(conf\n        .getStringCollection(MRJobConfig.ARCHIVES_FOR_SHARED_CACHE));\n\n\n    Map<URI, FileStatus> statCache = new HashMap<URI, FileStatus>();\n    checkLocalizationLimits(conf, files, libjars, archives, jobJar, statCache);\n\n    Map<String, Boolean> fileSCUploadPolicies =\n        new LinkedHashMap<String, Boolean>();\n    Map<String, Boolean> archiveSCUploadPolicies =\n        new LinkedHashMap<String, Boolean>();\n\n    uploadFiles(job, files, submitJobDir, mapredSysPerms, replication,\n        fileSCUploadPolicies, statCache);\n    uploadLibJars(job, libjars, submitJobDir, mapredSysPerms, replication,\n        fileSCUploadPolicies, statCache);\n    uploadArchives(job, archives, submitJobDir, mapredSysPerms, replication,\n        archiveSCUploadPolicies, statCache);\n    uploadJobJar(job, jobJar, submitJobDir, replication, statCache);\n    addLog4jToDistributedCache(job, submitJobDir);\n\n    // Note, we do not consider resources in the distributed cache for the\n    // shared cache at this time. Only resources specified via the\n    // GenericOptionsParser or the jobjar.\n    Job.setFileSharedCacheUploadPolicies(conf, fileSCUploadPolicies);\n    Job.setArchiveSharedCacheUploadPolicies(conf, archiveSCUploadPolicies);\n\n    // set the timestamps of the archives and files\n    // set the public/private visibility of the archives and files\n    ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(conf,\n        statCache);\n    // get DelegationToken for cached file\n    ClientDistributedCacheManager.getDelegationTokens(conf,\n        job.getCredentials());\n  }",
                "code_after_change": "  private void uploadResourcesInternal(Job job, Path submitJobDir)\n      throws IOException {\n    Configuration conf = job.getConfiguration();\n    short replication =\n        (short) conf.getInt(Job.SUBMIT_REPLICATION,\n            Job.DEFAULT_SUBMIT_REPLICATION);\n\n    if (!(conf.getBoolean(Job.USED_GENERIC_PARSER, false))) {\n      LOG.warn(\"Hadoop command-line option parsing not performed. \"\n          + \"Implement the Tool interface and execute your application \"\n          + \"with ToolRunner to remedy this.\");\n    }\n\n    //\n    // Figure out what fs the JobTracker is using. Copy the\n    // job to it, under a temporary name. This allows DFS to work,\n    // and under the local fs also provides UNIX-like object loading\n    // semantics. (that is, if the job file is deleted right after\n    // submission, we can still run the submission to completion)\n    //\n\n    // Create a number of filenames in the JobTracker's fs namespace\n    LOG.debug(\"default FileSystem: \" + jtFs.getUri());\n    if (jtFs.exists(submitJobDir)) {\n      throw new IOException(\"Not submitting job. Job directory \" + submitJobDir\n          + \" already exists!! This is unexpected.Please check what's there in\"\n          + \" that directory\");\n    }\n    // Create the submission directory for the MapReduce job.\n    submitJobDir = jtFs.makeQualified(submitJobDir);\n    submitJobDir = new Path(submitJobDir.toUri().getPath());\n    FsPermission mapredSysPerms =\n        new FsPermission(JobSubmissionFiles.JOB_DIR_PERMISSION);\n    mkdirs(jtFs, submitJobDir, mapredSysPerms);\n\n    if (!conf.getBoolean(MRJobConfig.MR_AM_STAGING_DIR_ERASURECODING_ENABLED,\n        MRJobConfig.DEFAULT_MR_AM_STAGING_ERASURECODING_ENABLED)) {\n      disableErasureCodingForPath(submitJobDir);\n    }\n\n    // Get the resources that have been added via command line arguments in the\n    // GenericOptionsParser (i.e. files, libjars, archives).\n    Collection<String> files = conf.getStringCollection(\"tmpfiles\");\n    Collection<String> libjars = conf.getStringCollection(\"tmpjars\");\n    Collection<String> archives = conf.getStringCollection(\"tmparchives\");\n    String jobJar = job.getJar();\n\n    // Merge resources that have been programmatically specified for the shared\n    // cache via the Job API.\n    files.addAll(conf.getStringCollection(MRJobConfig.FILES_FOR_SHARED_CACHE));\n    libjars.addAll(conf.getStringCollection(\n            MRJobConfig.FILES_FOR_CLASSPATH_AND_SHARED_CACHE));\n    archives.addAll(conf\n        .getStringCollection(MRJobConfig.ARCHIVES_FOR_SHARED_CACHE));\n\n\n    Map<URI, FileStatus> statCache = new HashMap<URI, FileStatus>();\n    checkLocalizationLimits(conf, files, libjars, archives, jobJar, statCache);\n\n    Map<String, Boolean> fileSCUploadPolicies =\n        new LinkedHashMap<String, Boolean>();\n    Map<String, Boolean> archiveSCUploadPolicies =\n        new LinkedHashMap<String, Boolean>();\n\n    uploadFiles(job, files, submitJobDir, mapredSysPerms, replication,\n        fileSCUploadPolicies, statCache);\n    uploadLibJars(job, libjars, submitJobDir, mapredSysPerms, replication,\n        fileSCUploadPolicies, statCache);\n    uploadArchives(job, archives, submitJobDir, mapredSysPerms, replication,\n        archiveSCUploadPolicies, statCache);\n    uploadJobJar(job, jobJar, submitJobDir, replication, statCache);\n    addLog4jToDistributedCache(job, submitJobDir);\n\n    // Note, we do not consider resources in the distributed cache for the\n    // shared cache at this time. Only resources specified via the\n    // GenericOptionsParser or the jobjar.\n    Job.setFileSharedCacheUploadPolicies(conf, fileSCUploadPolicies);\n    Job.setArchiveSharedCacheUploadPolicies(conf, archiveSCUploadPolicies);\n\n    // set the timestamps of the archives and files\n    // set the public/private visibility of the archives and files\n    ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(conf,\n        statCache);\n    // get DelegationToken for cached file\n    ClientDistributedCacheManager.getDelegationTokens(conf,\n        job.getCredentials());\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the invocation of the setErasureCodingPolicy method, which is not available in the HDFS 2.8 server. This is related to the method where the error occurred (JobResourceUploader.disableErasureCodingForPath) but not where the actual fix was made (JobResourceUploader.uploadResourcesInternal). Thus, it is classified as 'Partial' under 'Buggy Method'. The fix suggestion to catch the RpcNoSuchMethodException and log a warning is an alternative approach to the developer's fix, which involved removing the call to disableErasureCodingForPath. The problem location identification points to methods in the JobResourceUploader class, which is where the error occurred, but not the exact ground truth methods, hence 'Partial' under 'Buggy Method'. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4843.json",
        "code_diff": {
            "src.mapred.org.apache.hadoop.mapred.JobLocalizer.JobLocalizer": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Missing",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the non-thread-safe nature of the JobLocalizer, which aligns with the ground truth method 'JobLocalizer'. The fix suggestion is an alternative fix because it suggests implementing synchronization mechanisms or using separate configuration instances, which are valid approaches but not necessarily the exact developer's fix. The problem location identification is missing because the methods mentioned in the 'problem_location' field are not from the ground truth list, and the report does not directly mention the 'JobLocalizer' method. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5028.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.MapTask.resetSpill": {
                "code_before_change": "    private void resetSpill() {\n      final int e = equator;\n      bufstart = bufend = e;\n      final int aligned = e - (e % METASIZE);\n      // set start/end to point to first meta record\n      kvstart = kvend =\n        ((aligned - METASIZE + kvbuffer.length) % kvbuffer.length) / 4;\n      if (LOG.isInfoEnabled()) {\n        LOG.info(\"(RESET) equator \" + e + \" kv \" + kvstart + \"(\" +\n          (kvstart * 4) + \")\" + \" kvi \" + kvindex + \"(\" + (kvindex * 4) + \")\");\n      }\n    }",
                "code_after_change": "    private void resetSpill() {\n      final int e = equator;\n      bufstart = bufend = e;\n      final int aligned = e - (e % METASIZE);\n      // set start/end to point to first meta record\n      // Cast one of the operands to long to avoid integer overflow\n      kvstart = kvend = (int)\n        (((long)aligned - METASIZE + kvbuffer.length) % kvbuffer.length) / 4;\n      LOG.info(\"(RESET) equator \" + e + \" kv \" + kvstart + \"(\" +\n        (kvstart * 4) + \")\" + \" kvi \" + kvindex + \"(\" + (kvindex * 4) + \")\");\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.InMemoryReader": {
                "code_before_change": [],
                "code_after_change": []
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.MapTask.setEquator": {
                "code_before_change": "    private void setEquator(int pos) {\n      equator = pos;\n      // set index prior to first entry, aligned at meta boundary\n      final int aligned = pos - (pos % METASIZE);\n      kvindex =\n        ((aligned - METASIZE + kvbuffer.length) % kvbuffer.length) / 4;\n      if (LOG.isInfoEnabled()) {\n        LOG.info(\"(EQUATOR) \" + pos + \" kvi \" + kvindex +\n            \"(\" + (kvindex * 4) + \")\");\n      }\n    }",
                "code_after_change": "    private void setEquator(int pos) {\n      equator = pos;\n      // set index prior to first entry, aligned at meta boundary\n      final int aligned = pos - (pos % METASIZE);\n      // Cast one of the operands to long to avoid integer overflow\n      kvindex = (int)\n        (((long)aligned - METASIZE + kvbuffer.length) % kvbuffer.length) / 4;\n      LOG.info(\"(EQUATOR) \" + pos + \" kvi \" + kvindex +\n          \"(\" + (kvindex * 4) + \")\");\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.ReduceContextImpl.next": {
                "code_before_change": "    public VALUEIN next() {\n      if (inReset) {\n        try {\n          if (backupStore.hasNext()) {\n            backupStore.next();\n            DataInputBuffer next = backupStore.nextValue();\n            buffer.reset(next.getData(), next.getPosition(), next.getLength());\n            value = valueDeserializer.deserialize(value);\n            return value;\n          } else {\n            inReset = false;\n            backupStore.exitResetMode();\n            if (clearMarkFlag) {\n              clearMarkFlag = false;\n              isMarked = false;\n            }\n          }\n        } catch (IOException e) {\n          e.printStackTrace();\n          throw new RuntimeException(\"next value iterator failed\", e);\n        }\n      } \n\n      // if this is the first record, we don't need to advance\n      if (firstValue) {\n        firstValue = false;\n        return value;\n      }\n      // if this isn't the first record and the next key is different, they\n      // can't advance it here.\n      if (!nextKeyIsSame) {\n        throw new NoSuchElementException(\"iterate past last value\");\n      }\n      // otherwise, go to the next key/value pair\n      try {\n        nextKeyValue();\n        return value;\n      } catch (IOException ie) {\n        throw new RuntimeException(\"next value iterator failed\", ie);\n      } catch (InterruptedException ie) {\n        // this is bad, but we can't modify the exception list of java.util\n        throw new RuntimeException(\"next value iterator interrupted\", ie);        \n      }\n    }",
                "code_after_change": "    public VALUEIN next() {\n      if (inReset) {\n        try {\n          if (backupStore.hasNext()) {\n            backupStore.next();\n            DataInputBuffer next = backupStore.nextValue();\n            buffer.reset(next.getData(), next.getPosition(), next.getLength()\n                - next.getPosition());\n            value = valueDeserializer.deserialize(value);\n            return value;\n          } else {\n            inReset = false;\n            backupStore.exitResetMode();\n            if (clearMarkFlag) {\n              clearMarkFlag = false;\n              isMarked = false;\n            }\n          }\n        } catch (IOException e) {\n          e.printStackTrace();\n          throw new RuntimeException(\"next value iterator failed\", e);\n        }\n      } \n\n      // if this is the first record, we don't need to advance\n      if (firstValue) {\n        firstValue = false;\n        return value;\n      }\n      // if this isn't the first record and the next key is different, they\n      // can't advance it here.\n      if (!nextKeyIsSame) {\n        throw new NoSuchElementException(\"iterate past last value\");\n      }\n      // otherwise, go to the next key/value pair\n      try {\n        nextKeyValue();\n        return value;\n      } catch (IOException ie) {\n        throw new RuntimeException(\"next value iterator failed\", ie);\n      } catch (InterruptedException ie) {\n        // this is bad, but we can't modify the exception list of java.util\n        throw new RuntimeException(\"next value iterator interrupted\", ie);        \n      }\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue": {
                "code_before_change": "  public boolean nextKeyValue() throws IOException, InterruptedException {\n    if (!hasMore) {\n      key = null;\n      value = null;\n      return false;\n    }\n    firstValue = !nextKeyIsSame;\n    DataInputBuffer nextKey = input.getKey();\n    currentRawKey.set(nextKey.getData(), nextKey.getPosition(), \n                      nextKey.getLength() - nextKey.getPosition());\n    buffer.reset(currentRawKey.getBytes(), 0, currentRawKey.getLength());\n    key = keyDeserializer.deserialize(key);\n    DataInputBuffer nextVal = input.getValue();\n    buffer.reset(nextVal.getData(), nextVal.getPosition(), nextVal.getLength());\n    value = valueDeserializer.deserialize(value);\n\n    currentKeyLength = nextKey.getLength() - nextKey.getPosition();\n    currentValueLength = nextVal.getLength() - nextVal.getPosition();\n\n    if (isMarked) {\n      backupStore.write(nextKey, nextVal);\n    }\n\n    hasMore = input.next();\n    if (hasMore) {\n      nextKey = input.getKey();\n      nextKeyIsSame = comparator.compare(currentRawKey.getBytes(), 0, \n                                     currentRawKey.getLength(),\n                                     nextKey.getData(),\n                                     nextKey.getPosition(),\n                                     nextKey.getLength() - nextKey.getPosition()\n                                         ) == 0;\n    } else {\n      nextKeyIsSame = false;\n    }\n    inputValueCounter.increment(1);\n    return true;\n  }",
                "code_after_change": "  public boolean nextKeyValue() throws IOException, InterruptedException {\n    if (!hasMore) {\n      key = null;\n      value = null;\n      return false;\n    }\n    firstValue = !nextKeyIsSame;\n    DataInputBuffer nextKey = input.getKey();\n    currentRawKey.set(nextKey.getData(), nextKey.getPosition(), \n                      nextKey.getLength() - nextKey.getPosition());\n    buffer.reset(currentRawKey.getBytes(), 0, currentRawKey.getLength());\n    key = keyDeserializer.deserialize(key);\n    DataInputBuffer nextVal = input.getValue();\n    buffer.reset(nextVal.getData(), nextVal.getPosition(), nextVal.getLength()\n        - nextVal.getPosition());\n    value = valueDeserializer.deserialize(value);\n\n    currentKeyLength = nextKey.getLength() - nextKey.getPosition();\n    currentValueLength = nextVal.getLength() - nextVal.getPosition();\n\n    if (isMarked) {\n      backupStore.write(nextKey, nextVal);\n    }\n\n    hasMore = input.next();\n    if (hasMore) {\n      nextKey = input.getKey();\n      nextKeyIsSame = comparator.compare(currentRawKey.getBytes(), 0, \n                                     currentRawKey.getLength(),\n                                     nextKey.getData(),\n                                     nextKey.getPosition(),\n                                     nextKey.getLength() - nextKey.getPosition()\n                                         ) == 0;\n    } else {\n      nextKeyIsSame = false;\n    }\n    inputValueCounter.increment(1);\n    return true;\n  }"
            },
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.DataInputBuffer.getData": {
                "code_before_change": "    public byte[] getData() { return buf; }",
                "code_after_change": "    public byte[] getData() { return buf; }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies an EOFException during the reading of data from the output buffer, which is related to the ground truth methods as they involve buffer management and data reading. However, it does not precisely identify the root cause in the ground truth methods but is related through the shared stack trace context. The fix suggestion to reduce 'io.sort.mb' is preventive as it addresses the buffer overflow issue indirectly by managing memory allocation, which could prevent the bug. The problem location mentions methods like 'MapOutputBuffer.collect' and 'IntWritable.readFields', which are in the shared stack trace context but not the exact ground truth methods. There is no wrong information as the report accurately describes the issue and its context."
        }
    },
    {
        "filename": "MAPREDUCE-4300.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.validateInputParam": {
                "code_before_change": "  private static void validateInputParam(String value, String param)\n      throws IOException {\n    if (value == null) {\n      String msg = param + \" is null\";\n      LOG.error(msg);\n      throw new IOException(msg);\n    }\n  }",
                "code_after_change": "  private static void validateInputParam(String value, String param)\n      throws IOException {\n    if (value == null) {\n      String msg = param + \" is null\";\n      LOG.error(msg);\n      throw new IOException(msg);\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.getClientService": {
                "code_before_change": "  public HistoryClientService getClientService() {\n    return this.clientService;\n  }",
                "code_after_change": "  public HistoryClientService getClientService() {\n    return this.clientService;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.createStatus": {
                "code_before_change": "  private LocalizerStatus createStatus() throws InterruptedException {\n    final List<LocalResourceStatus> currentResources =\n      new ArrayList<LocalResourceStatus>();\n    // TODO: Synchronization??\n    for (Iterator<LocalResource> i = pendingResources.keySet().iterator();\n         i.hasNext();) {\n      LocalResource rsrc = i.next();\n      LocalResourceStatus stat =\n        recordFactory.newRecordInstance(LocalResourceStatus.class);\n      stat.setResource(rsrc);\n      Future<Path> fPath = pendingResources.get(rsrc);\n      if (fPath.isDone()) {\n        try {\n          Path localPath = fPath.get();\n          stat.setLocalPath(\n              ConverterUtils.getYarnUrlFromPath(localPath));\n          stat.setLocalSize(\n              FileUtil.getDU(new File(localPath.getParent().toUri())));\n          stat.setStatus(ResourceStatusType.FETCH_SUCCESS);\n        } catch (ExecutionException e) {\n          stat.setStatus(ResourceStatusType.FETCH_FAILURE);\n          stat.setException(RPCUtil.getRemoteException(e.getCause()));\n        } catch (CancellationException e) {\n          stat.setStatus(ResourceStatusType.FETCH_FAILURE);\n          stat.setException(RPCUtil.getRemoteException(e));\n        }\n        // TODO shouldn't remove until ACK\n        i.remove();\n      } else {\n        stat.setStatus(ResourceStatusType.FETCH_PENDING);\n      }\n      currentResources.add(stat);\n    }\n    LocalizerStatus status =\n      recordFactory.newRecordInstance(LocalizerStatus.class);\n    status.setLocalizerId(localizerId);\n    status.addAllResources(currentResources);\n    return status;\n  }",
                "code_after_change": "  private LocalizerStatus createStatus() throws InterruptedException {\n    final List<LocalResourceStatus> currentResources =\n      new ArrayList<LocalResourceStatus>();\n    // TODO: Synchronization??\n    for (Iterator<LocalResource> i = pendingResources.keySet().iterator();\n         i.hasNext();) {\n      LocalResource rsrc = i.next();\n      LocalResourceStatus stat =\n        recordFactory.newRecordInstance(LocalResourceStatus.class);\n      stat.setResource(rsrc);\n      Future<Path> fPath = pendingResources.get(rsrc);\n      if (fPath.isDone()) {\n        try {\n          Path localPath = fPath.get();\n          stat.setLocalPath(\n              ConverterUtils.getYarnUrlFromPath(localPath));\n          stat.setLocalSize(\n              FileUtil.getDU(new File(localPath.getParent().toUri())));\n          stat.setStatus(ResourceStatusType.FETCH_SUCCESS);\n        } catch (ExecutionException e) {\n          stat.setStatus(ResourceStatusType.FETCH_FAILURE);\n          stat.setException(RPCUtil.getRemoteException(e.getCause()));\n        } catch (CancellationException e) {\n          stat.setStatus(ResourceStatusType.FETCH_FAILURE);\n          stat.setException(RPCUtil.getRemoteException(e));\n        }\n        // TODO shouldn't remove until ACK\n        i.remove();\n      } else {\n        stat.setStatus(ResourceStatusType.FETCH_PENDING);\n      }\n      currentResources.add(stat);\n    }\n    LocalizerStatus status =\n      recordFactory.newRecordInstance(LocalizerStatus.class);\n    status.setLocalizerId(localizerId);\n    status.addAllResources(currentResources);\n    return status;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer.doSecureLogin": {
                "code_before_change": "  protected void doSecureLogin(Configuration conf) throws IOException {\n    SecurityUtil.login(conf, YarnConfiguration.PROXY_KEYTAB,\n        YarnConfiguration.PROXY_PRINCIPAL);\n  }",
                "code_after_change": "  protected void doSecureLogin(Configuration conf) throws IOException {\n    SecurityUtil.login(conf, YarnConfiguration.PROXY_KEYTAB,\n        YarnConfiguration.PROXY_PRINCIPAL);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": {
                "code_before_change": "  public void recover(RMState state) throws Exception {\n    resourceTracker.recover(state);\n    scheduler.recover(state);\n  }",
                "code_after_change": "  public void recover(RMState state) throws Exception {\n    resourceTracker.recover(state);\n    scheduler.recover(state);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNewNodeManager": {
                "code_before_change": "  NodeManager createNewNodeManager() {\n    return new NodeManager();\n  }",
                "code_after_change": "  NodeManager createNewNodeManager() {\n    return new NodeManager();\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as excessive memory usage during speculative task scheduling and data processing, particularly in the DefaultSpeculator and response processing threads. This is not the precise root cause, as it does not directly mention any of the ground truth methods, but it is related to the methods in the stack trace, hence classified as 'Partial' with 'Shared Stack Trace Context'. The fix suggestion to increase heap size and optimize speculative execution logic is preventive, as it aims to mitigate the memory issue. The problem location mentions methods related to the stack trace but not the ground truth methods, so it is 'Partial' with 'Shared Stack Trace Context'. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3241.json",
        "code_diff": {
            "hadoop-mapreduce-project.src.tools.org.apache.hadoop.tools.rumen.JobBuilder.process": {
                "code_before_change": "  public void process(HistoryEvent event) {\n    if (finalized) {\n      throw new IllegalStateException(\n          \"JobBuilder.process(HistoryEvent event) called after LoggedJob built\");\n    }\n\n    // these are in lexicographical order by class name.\n    if (event instanceof JobFinishedEvent) {\n      processJobFinishedEvent((JobFinishedEvent) event);\n    } else if (event instanceof JobInfoChangeEvent) {\n      processJobInfoChangeEvent((JobInfoChangeEvent) event);\n    } else if (event instanceof JobInitedEvent) {\n      processJobInitedEvent((JobInitedEvent) event);\n    } else if (event instanceof JobPriorityChangeEvent) {\n      processJobPriorityChangeEvent((JobPriorityChangeEvent) event);\n    } else if (event instanceof JobStatusChangedEvent) {\n      processJobStatusChangedEvent((JobStatusChangedEvent) event);\n    } else if (event instanceof JobSubmittedEvent) {\n      processJobSubmittedEvent((JobSubmittedEvent) event);\n    } else if (event instanceof JobUnsuccessfulCompletionEvent) {\n      processJobUnsuccessfulCompletionEvent((JobUnsuccessfulCompletionEvent) event);\n    } else if (event instanceof MapAttemptFinishedEvent) {\n      processMapAttemptFinishedEvent((MapAttemptFinishedEvent) event);\n    } else if (event instanceof ReduceAttemptFinishedEvent) {\n      processReduceAttemptFinishedEvent((ReduceAttemptFinishedEvent) event);\n    } else if (event instanceof TaskAttemptFinishedEvent) {\n      processTaskAttemptFinishedEvent((TaskAttemptFinishedEvent) event);\n    } else if (event instanceof TaskAttemptStartedEvent) {\n      processTaskAttemptStartedEvent((TaskAttemptStartedEvent) event);\n    } else if (event instanceof TaskAttemptUnsuccessfulCompletionEvent) {\n      processTaskAttemptUnsuccessfulCompletionEvent((TaskAttemptUnsuccessfulCompletionEvent) event);\n    } else if (event instanceof TaskFailedEvent) {\n      processTaskFailedEvent((TaskFailedEvent) event);\n    } else if (event instanceof TaskFinishedEvent) {\n      processTaskFinishedEvent((TaskFinishedEvent) event);\n    } else if (event instanceof TaskStartedEvent) {\n      processTaskStartedEvent((TaskStartedEvent) event);\n    } else if (event instanceof TaskUpdatedEvent) {\n      processTaskUpdatedEvent((TaskUpdatedEvent) event);\n    } else\n      throw new IllegalArgumentException(\n          \"JobBuilder.process(HistoryEvent): unknown event type\");\n  }",
                "code_after_change": "  public void process(HistoryEvent event) {\n    if (finalized) {\n      throw new IllegalStateException(\n          \"JobBuilder.process(HistoryEvent event) called after LoggedJob built\");\n    }\n\n    // these are in lexicographical order by class name.\n    if (event instanceof AMStartedEvent) {\n      // ignore this event as Rumen currently doesnt need this event\n      //TODO Enhance Rumen to process this event and capture restarts\n      return;\n    } else if (event instanceof JobFinishedEvent) {\n      processJobFinishedEvent((JobFinishedEvent) event);\n    } else if (event instanceof JobInfoChangeEvent) {\n      processJobInfoChangeEvent((JobInfoChangeEvent) event);\n    } else if (event instanceof JobInitedEvent) {\n      processJobInitedEvent((JobInitedEvent) event);\n    } else if (event instanceof JobPriorityChangeEvent) {\n      processJobPriorityChangeEvent((JobPriorityChangeEvent) event);\n    } else if (event instanceof JobStatusChangedEvent) {\n      processJobStatusChangedEvent((JobStatusChangedEvent) event);\n    } else if (event instanceof JobSubmittedEvent) {\n      processJobSubmittedEvent((JobSubmittedEvent) event);\n    } else if (event instanceof JobUnsuccessfulCompletionEvent) {\n      processJobUnsuccessfulCompletionEvent((JobUnsuccessfulCompletionEvent) event);\n    } else if (event instanceof MapAttemptFinishedEvent) {\n      processMapAttemptFinishedEvent((MapAttemptFinishedEvent) event);\n    } else if (event instanceof ReduceAttemptFinishedEvent) {\n      processReduceAttemptFinishedEvent((ReduceAttemptFinishedEvent) event);\n    } else if (event instanceof TaskAttemptFinishedEvent) {\n      processTaskAttemptFinishedEvent((TaskAttemptFinishedEvent) event);\n    } else if (event instanceof TaskAttemptStartedEvent) {\n      processTaskAttemptStartedEvent((TaskAttemptStartedEvent) event);\n    } else if (event instanceof TaskAttemptUnsuccessfulCompletionEvent) {\n      processTaskAttemptUnsuccessfulCompletionEvent((TaskAttemptUnsuccessfulCompletionEvent) event);\n    } else if (event instanceof TaskFailedEvent) {\n      processTaskFailedEvent((TaskFailedEvent) event);\n    } else if (event instanceof TaskFinishedEvent) {\n      processTaskFinishedEvent((TaskFinishedEvent) event);\n    } else if (event instanceof TaskStartedEvent) {\n      processTaskStartedEvent((TaskStartedEvent) event);\n    } else if (event instanceof TaskUpdatedEvent) {\n      processTaskUpdatedEvent((TaskUpdatedEvent) event);\n    } else\n      throw new IllegalArgumentException(\n          \"JobBuilder.process(HistoryEvent): unknown event type\");\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the JobBuilder.process method attempting to process an unknown event type, which matches the ground truth method. The fix suggestion to implement error handling in the JobBuilder.process method aligns with the developer's fix, which involves handling an unrecognized event type. The problem location is precisely identified as the JobBuilder.process method, which is part of the ground truth. There is no wrong information in the bug report as all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6002.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.Task.setWriteSkipRecs": {
                "code_before_change": "  protected void setWriteSkipRecs(boolean writeSkipRecs) {\n    this.writeSkipRecs = writeSkipRecs;\n  }",
                "code_after_change": "  protected void setWriteSkipRecs(boolean writeSkipRecs) {\n    this.writeSkipRecs = writeSkipRecs;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.YarnChild.run": {
                "code_before_change": "      public TaskUmbilicalProtocol run() throws Exception {\n        return (TaskUmbilicalProtocol)RPC.getProxy(TaskUmbilicalProtocol.class,\n            TaskUmbilicalProtocol.versionID, address, job);\n      }",
                "code_after_change": "      public TaskUmbilicalProtocol run() throws Exception {\n        return (TaskUmbilicalProtocol)RPC.getProxy(TaskUmbilicalProtocol.class,\n            TaskUmbilicalProtocol.versionID, address, job);\n      }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.LocalContainerLauncher.runSubtask": {
                "code_before_change": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map<TaskAttemptID, MapOutputFile> localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID =\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf = new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType == TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM's local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs = StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType == TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map = (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps == numMapTasks) {\n            doneWithMaps = true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn't send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce = (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task != null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause = throwable.getCause();\n        String cause = (tCause == null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }",
                "code_after_change": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map<TaskAttemptID, MapOutputFile> localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID =\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf = new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType == TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM's local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs = StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType == TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map = (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps == numMapTasks) {\n            doneWithMaps = true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn't send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce = (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          umbilical.fsError(classicAttemptID, e.getMessage());\n        }\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task != null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(throwable));\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          Throwable tCause = throwable.getCause();\n          String cause =\n              (tCause == null) ? throwable.getMessage() : StringUtils\n                  .stringifyException(tCause);\n          umbilical.fatalError(classicAttemptID, cause);\n        }\n        throw new RuntimeException();\n      }\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the issue with the premature closure of the FileSystem during the shutdown process, which is related to the IOException being thrown. However, it points to the method 'MapTask.getSplitDetails' as the location of the problem, which is not where the actual fix was made. This method is where the error occurs, but not where the fix was applied, hence 'Buggy Method' is the sub-category for both root cause and problem location identification. The fix suggestion is preventive as it suggests checking if the FileSystem is shutting down before attempting to read from it, which aligns with the developer's fix of checking the shutdown status before reporting errors. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6452.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-common.src.main.java.org.apache.hadoop.mapred.LocalJobRunner.Job": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the NullPointerException occurring in the CryptoOutputStream constructor, which is a method where the error manifests but not where the fix was made. This places it in the 'Buggy Method' sub-category for both root cause and problem location identification. The fix suggestion is preventive as it suggests ensuring configurations are set correctly, which would prevent the issue from occurring. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6649.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.CompletedJob.loadAllTasks": {
                "code_before_change": "  private void loadAllTasks() {\n    if (tasksLoaded.get()) {\n      return;\n    }\n    tasksLock.lock();\n    try {\n      if (tasksLoaded.get()) {\n        return;\n      }\n      for (Map.Entry<TaskID, TaskInfo> entry : jobInfo.getAllTasks().entrySet()) {\n        TaskId yarnTaskID = TypeConverter.toYarn(entry.getKey());\n        TaskInfo taskInfo = entry.getValue();\n        Task task = new CompletedTask(yarnTaskID, taskInfo);\n        tasks.put(yarnTaskID, task);\n        if (task.getType() == TaskType.MAP) {\n          mapTasks.put(task.getID(), task);\n        } else if (task.getType() == TaskType.REDUCE) {\n          reduceTasks.put(task.getID(), task);\n        }\n      }\n      tasksLoaded.set(true);\n    } finally {\n      tasksLock.unlock();\n    }\n  }",
                "code_after_change": "  private void loadAllTasks() {\n    if (tasksLoaded.get()) {\n      return;\n    }\n    tasksLock.lock();\n    try {\n      if (tasksLoaded.get()) {\n        return;\n      }\n      for (Map.Entry<TaskID, TaskInfo> entry : jobInfo.getAllTasks().entrySet()) {\n        TaskId yarnTaskID = TypeConverter.toYarn(entry.getKey());\n        TaskInfo taskInfo = entry.getValue();\n        Task task = new CompletedTask(yarnTaskID, taskInfo);\n        tasks.put(yarnTaskID, task);\n        if (task.getType() == TaskType.MAP) {\n          mapTasks.put(task.getID(), task);\n        } else if (task.getType() == TaskType.REDUCE) {\n          reduceTasks.put(task.getID(), task);\n        }\n      }\n      tasksLoaded.set(true);\n    } finally {\n      tasksLock.unlock();\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.CompletedJob.loadFullHistoryData": {
                "code_before_change": "  protected synchronized void loadFullHistoryData(boolean loadTasks,\n      Path historyFileAbsolute) throws IOException {\n    LOG.info(\"Loading history file: [\" + historyFileAbsolute + \"]\");\n    if (this.jobInfo != null) {\n      return;\n    }\n    \n    if (historyFileAbsolute != null) {\n      JobHistoryParser parser = null;\n      try {\n        final FileSystem fs = historyFileAbsolute.getFileSystem(conf);\n        parser = new JobHistoryParser(fs, historyFileAbsolute);\n        final Path jobConfPath = new Path(historyFileAbsolute.getParent(),\n            JobHistoryUtils.getIntermediateConfFileName(jobId));\n        final Configuration conf = new Configuration();\n        try {\n          conf.addResource(fs.open(jobConfPath), jobConfPath.toString());\n          Limits.reset(conf);\n        } catch (FileNotFoundException fnf) {\n          if (LOG.isWarnEnabled()) {\n            LOG.warn(\"Missing job conf in history\", fnf);\n          }\n        }\n        this.jobInfo = parser.parse();\n      } catch (IOException e) {\n        throw new YarnRuntimeException(\"Could not load history file \"\n            + historyFileAbsolute, e);\n      }\n      IOException parseException = parser.getParseException(); \n      if (parseException != null) {\n        throw new YarnRuntimeException(\n            \"Could not parse history file \" + historyFileAbsolute, \n            parseException);\n      }\n    } else {\n      throw new IOException(\"History file not found\");\n    }\n    if (loadTasks) {\n      loadAllTasks();\n      LOG.info(\"TaskInfo loaded\");\n    }    \n  }",
                "code_after_change": "  protected synchronized void loadFullHistoryData(boolean loadTasks,\n      Path historyFileAbsolute) throws IOException {\n    LOG.info(\"Loading history file: [\" + historyFileAbsolute + \"]\");\n    if (this.jobInfo != null) {\n      return;\n    }\n    \n    if (historyFileAbsolute != null) {\n      JobHistoryParser parser = null;\n      try {\n        final FileSystem fs = historyFileAbsolute.getFileSystem(conf);\n        parser = createJobHistoryParser(historyFileAbsolute);\n        final Path jobConfPath = new Path(historyFileAbsolute.getParent(),\n            JobHistoryUtils.getIntermediateConfFileName(jobId));\n        final Configuration conf = new Configuration();\n        try {\n          conf.addResource(fs.open(jobConfPath), jobConfPath.toString());\n          Limits.reset(conf);\n        } catch (FileNotFoundException fnf) {\n          if (LOG.isWarnEnabled()) {\n            LOG.warn(\"Missing job conf in history\", fnf);\n          }\n        }\n        this.jobInfo = parser.parse();\n      } catch (IOException e) {\n        throw new YarnRuntimeException(\"Could not load history file \"\n            + historyFileAbsolute, e);\n      }\n      IOException parseException = parser.getParseException(); \n      if (parseException != null) {\n        throw new YarnRuntimeException(\n            \"Could not parse history file \" + historyFileAbsolute, \n            parseException);\n      }\n    } else {\n      throw new IOException(\"History file not found\");\n    }\n    if (loadTasks) {\n      loadAllTasks();\n      LOG.info(\"TaskInfo loaded\");\n    }    \n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.CompletedJob.constructJobReport": {
                "code_before_change": "  private void constructJobReport() {\n    report = Records.newRecord(JobReport.class);\n    report.setJobId(jobId);\n    report.setJobState(JobState.valueOf(jobInfo.getJobStatus()));\n    report.setSubmitTime(jobInfo.getSubmitTime());\n    report.setStartTime(jobInfo.getLaunchTime());\n    report.setFinishTime(jobInfo.getFinishTime());\n    report.setJobName(jobInfo.getJobname());\n    report.setUser(jobInfo.getUsername());\n\n    if ( getTotalMaps() == 0 ) {\n      report.setMapProgress(1.0f);\n    } else {\n      report.setMapProgress((float) getCompletedMaps() / getTotalMaps());\n    }\n    if ( getTotalReduces() == 0 ) {\n      report.setReduceProgress(1.0f);\n    } else {\n      report.setReduceProgress((float) getCompletedReduces() / getTotalReduces());\n    }\n\n    report.setJobFile(getConfFile().toString());\n    String historyUrl = \"N/A\";\n    try {\n      historyUrl =\n          MRWebAppUtil.getApplicationWebURLOnJHSWithScheme(conf,\n              jobId.getAppId());\n    } catch (UnknownHostException e) {\n        LOG.error(\"Problem determining local host: \" + e.getMessage());\n    }\n    report.setTrackingUrl(historyUrl);\n    report.setAMInfos(getAMInfos());\n    report.setIsUber(isUber());\n    report.setHistoryFile(info.getHistoryFile().toString());\n  }",
                "code_after_change": "  private void constructJobReport() {\n    report = Records.newRecord(JobReport.class);\n    report.setJobId(jobId);\n    report.setJobState(JobState.valueOf(jobInfo.getJobStatus()));\n    report.setSubmitTime(jobInfo.getSubmitTime());\n    report.setStartTime(jobInfo.getLaunchTime());\n    report.setFinishTime(jobInfo.getFinishTime());\n    report.setJobName(jobInfo.getJobname());\n    report.setUser(jobInfo.getUsername());\n    report.setDiagnostics(jobInfo.getErrorInfo());\n\n    if ( getTotalMaps() == 0 ) {\n      report.setMapProgress(1.0f);\n    } else {\n      report.setMapProgress((float) getCompletedMaps() / getTotalMaps());\n    }\n    if ( getTotalReduces() == 0 ) {\n      report.setReduceProgress(1.0f);\n    } else {\n      report.setReduceProgress((float) getCompletedReduces() / getTotalReduces());\n    }\n\n    report.setJobFile(getConfFile().toString());\n    String historyUrl = \"N/A\";\n    try {\n      historyUrl =\n          MRWebAppUtil.getApplicationWebURLOnJHSWithScheme(conf,\n              jobId.getAppId());\n    } catch (UnknownHostException e) {\n        LOG.error(\"Problem determining local host: \" + e.getMessage());\n    }\n    report.setTrackingUrl(historyUrl);\n    report.setAMInfos(getAMInfos());\n    report.setIsUber(isUber());\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the issue in the Shell class's runCommand method, which is not part of the ground truth methods but is mentioned in the stack trace, indicating a shared context. The fix suggestion to improve error handling and logging in the runCommand method is preventive, as it would help diagnose similar issues but does not match the actual fix in the ground truth methods. The problem location is also identified in the Shell class, which is related to the stack trace context but not the ground truth methods. There is no incorrect information in the bug report."
        }
    },
    {
        "filename": "MAPREDUCE-4048.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.webapp.AppController.attempts": {
                "code_before_change": "  public void attempts() {\n    try {\n      requireJob();\n    }\n    catch (Exception e) {\n      renderText(e.getMessage());\n      return;\n    }\n    if (app.getJob() != null) {\n      try {\n        String taskType = $(TASK_TYPE);\n        if (taskType.isEmpty()) {\n          throw new RuntimeException(\"missing task-type.\");\n        }\n        String attemptState = $(ATTEMPT_STATE);\n        if (attemptState.isEmpty()) {\n          throw new RuntimeException(\"missing attempt-state.\");\n        }\n        setTitle(join(attemptState, \" \",\n            MRApps.taskType(taskType).toString(), \" attempts in \", $(JOB_ID)));\n\n        render(attemptsPage());\n      } catch (Exception e) {\n        badRequest(e.getMessage());\n      }\n    }\n  }",
                "code_after_change": "  public void attempts() {\n    try {\n      requireJob();\n    }\n    catch (Exception e) {\n      renderText(e.getMessage());\n      return;\n    }\n    if (app.getJob() != null) {\n      try {\n        String taskType = $(TASK_TYPE);\n        if (taskType.isEmpty()) {\n          throw new RuntimeException(\"missing task-type.\");\n        }\n        String attemptState = $(ATTEMPT_STATE);\n        if (attemptState.isEmpty()) {\n          throw new RuntimeException(\"missing attempt-state.\");\n        }\n        setTitle(join(attemptState, \" \",\n            MRApps.taskType(taskType).toString(), \" attempts in \", $(JOB_ID)));\n\n        render(attemptsPage());\n      } catch (Exception e) {\n        LOG.error(\"Failed to render attempts page with task type : \"\n            + $(TASK_TYPE) + \" for job id : \" + $(JOB_ID), e);\n        badRequest(e.getMessage());\n      }\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.webapp.AppController.tasks": {
                "code_before_change": "  public void tasks() {\n    try {\n      requireJob();\n    }\n    catch (Exception e) {\n      renderText(e.getMessage());\n      return;\n    }\n    if (app.getJob() != null) {\n      try {\n        String tt = $(TASK_TYPE);\n        tt = tt.isEmpty() ? \"All\" : StringUtils.capitalize(MRApps.taskType(tt).\n            toString().toLowerCase(Locale.US));\n        setTitle(join(tt, \" Tasks for \", $(JOB_ID)));\n      } catch (Exception e) {\n        badRequest(e.getMessage());\n      }\n    }\n    render(tasksPage());\n  }",
                "code_after_change": "  public void tasks() {\n    try {\n      requireJob();\n    }\n    catch (Exception e) {\n      renderText(e.getMessage());\n      return;\n    }\n    if (app.getJob() != null) {\n      try {\n        String tt = $(TASK_TYPE);\n        tt = tt.isEmpty() ? \"All\" : StringUtils.capitalize(MRApps.taskType(tt).\n            toString().toLowerCase(Locale.US));\n        setTitle(join(tt, \" Tasks for \", $(JOB_ID)));\n      } catch (Exception e) {\n        LOG.error(\"Failed to render tasks page with task type : \"\n            + $(TASK_TYPE) + \" for job id : \" + $(JOB_ID), e);\n        badRequest(e.getMessage());\n      }\n    }\n    render(tasksPage());\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.webapp.AppController.conf": {
                "code_before_change": "  public void conf() {\n    requireJob();\n    try {\n      requireJob();\n    }\n    catch (Exception e) {\n      renderText(e.getMessage());\n      return;\n    }\n    render(confPage());\n  }",
                "code_after_change": "  public void conf() {\n    requireJob();\n    try {\n      requireJob();\n    }\n    catch (Exception e) {\n      renderText(e.getMessage());\n      return;\n    }\n    render(confPage());\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.webapp.AppController.badRequest": {
                "code_before_change": "  void badRequest(String s) {\n    setStatus(HttpServletResponse.SC_BAD_REQUEST);\n    setTitle(join(\"Bad request: \", s));\n  }",
                "code_after_change": "  void badRequest(String s) {\n    setStatus(HttpServletResponse.SC_BAD_REQUEST);\n    String title = \"Bad request: \";\n    setTitle((s != null) ? join(title, s) : title);\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as missing parameters in the AppController.attempts method, which matches the ground truth. The fix suggestion in the report is correct as it aligns with the developer's fix by suggesting checks for null or empty parameters. The problem location is also precise, as it directly mentions the AppController.attempts method, which is part of the ground truth methods. There is no wrong information in the bug report; all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5198.json",
        "code_diff": {
            "src.mapred.org.apache.hadoop.mapred.LinuxTaskController.createLogDir": {
                "code_before_change": [],
                "code_after_change": "  public void createLogDir(TaskAttemptID taskID,\n                           boolean isCleanup) throws IOException {\n    // Log dirs are created during attempt dir creation when running the task\n  }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.purgeJob": {
                "code_before_change": [],
                "code_after_change": "  synchronized void purgeJob(KillJobAction action) throws IOException {\n    JobID jobId = action.getJobID();\n    LOG.info(\"Received 'KillJobAction' for job: \" + jobId);\n    RunningJob rjob = null;\n    synchronized (runningJobs) {\n      rjob = runningJobs.get(jobId);\n    }\n      \n    if (rjob == null) {\n      LOG.warn(\"Unknown job \" + jobId + \" being deleted.\");\n    } else {\n      synchronized (rjob) {\n        // decrement the reference counts for the items this job references\n        rjob.distCacheMgr.release();\n        // Add this tips of this job to queue of tasks to be purged \n        for (TaskInProgress tip : rjob.tasks) {\n          tip.jobHasFinished(false, false);\n          Task t = tip.getTask();\n          if (t.isMapTask()) {\n            indexCache.removeMap(tip.getTask().getTaskID().toString());\n          }\n        }\n        // Delete the job directory for this  \n        // task if the job is done/failed\n        if (!rjob.keepJobFiles) {\n          removeJobFiles(rjob.ugi.getShortUserName(), rjob.getJobID());\n        }\n        // add job to user log manager\n        long now = System.currentTimeMillis();\n        JobCompletedEvent jca = new JobCompletedEvent(rjob\n            .getJobID(), now, UserLogCleaner.getUserlogRetainHours(rjob\n            .getJobConf()));\n        getUserLogManager().addLogEvent(jca);\n\n        // Remove this job \n        rjob.tasks.clear();\n        // Close all FileSystems for this job\n        try {\n          FileSystem.closeAllForUGI(rjob.getUGI());\n        } catch (IOException ie) {\n          LOG.warn(\"Ignoring exception \" + StringUtils.stringifyException(ie) + \n              \" while closing FileSystem for \" + rjob.getUGI());\n        }\n      }\n    }\n\n    synchronized(runningJobs) {\n      runningJobs.remove(jobId);\n    }\n    getJobTokenSecretManager().removeTokenForJob(jobId.toString());  \n    distributedCacheManager.removeTaskDistributedCacheManager(jobId);\n  }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.mapOutputLost": {
                "code_before_change": [],
                "code_after_change": "    private synchronized void mapOutputLost(String failure\n                                           ) throws IOException {\n      if (taskStatus.getRunState() == TaskStatus.State.COMMIT_PENDING || \n          taskStatus.getRunState() == TaskStatus.State.SUCCEEDED) {\n        // change status to failure\n        LOG.info(\"Reporting output lost:\"+task.getTaskID());\n        taskStatus.setRunState(TaskStatus.State.FAILED);\n        taskStatus.setProgress(0.0f);\n        reportDiagnosticInfo(\"Map output lost, rescheduling: \" + \n                             failure);\n        runningTasks.put(task.getTaskID(), this);\n        mapTotal++;\n      } else {\n        LOG.warn(\"Output already reported lost:\"+task.getTaskID());\n      }\n    }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.cleanup": {
                "code_before_change": [],
                "code_after_change": "    void cleanup(boolean ttReInit, boolean needCleanup) throws IOException {\n      TaskAttemptID taskId = task.getTaskID();\n      LOG.debug(\"Cleaning up \" + taskId);\n\n\n      synchronized (TaskTracker.this) {\n        if (needCleanup) {\n          // see if tasks data structure is holding this tip.\n          // tasks could hold the tip for cleanup attempt, if cleanup attempt \n          // got launched before this method.\n          if (tasks.get(taskId) == this) {\n            tasks.remove(taskId);\n          }\n        }\n        synchronized (this){\n          if (alwaysKeepTaskFiles ||\n              (taskStatus.getRunState() == TaskStatus.State.FAILED && \n               keepFailedTaskFiles)) {\n            return;\n          }\n        }\n      }\n      synchronized (this) {\n        // localJobConf could be null if localization has not happened\n        // then no cleanup will be required.\n        if (localJobConf == null) {\n          return;\n        }\n        try {\n          // TT re-initialization sequence: no need to cleanup, TT will cleanup\n          if (!ttReInit) {\n            removeTaskFiles(needCleanup);\n          }\n        } catch (Throwable ie) {\n          LOG.info(\"Error cleaning up task runner: \"\n              + StringUtils.stringifyException(ie));\n        }\n      }\n    }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.close": {
                "code_before_change": [],
                "code_after_change": "  public synchronized void close() throws IOException, InterruptedException {\n    //\n    // Kill running tasks.  Do this in a 2nd vector, called 'tasksToClose',\n    // because calling jobHasFinished() may result in an edit to 'tasks'.\n    //\n    TreeMap<TaskAttemptID, TaskInProgress> tasksToClose =\n      new TreeMap<TaskAttemptID, TaskInProgress>();\n    tasksToClose.putAll(tasks);\n    for (TaskInProgress tip : tasksToClose.values()) {\n      tip.jobHasFinished(true, false);\n    }\n    \n    this.running = false;\n\n    // Clear local storage\n    cleanupStorage();\n        \n    // Shutdown the fetcher thread\n    this.mapEventsFetcher.interrupt();\n    \n    //stop the launchers\n    this.mapLauncher.interrupt();\n    this.reduceLauncher.interrupt();\n\n    this.distributedCacheManager.stopCleanupThread();\n    jvmManager.stop();\n    \n    // shutdown RPC connections\n    RPC.stopProxy(jobClient);\n\n    // wait for the fetcher thread to exit\n    for (boolean done = false; !done; ) {\n      try {\n        this.mapEventsFetcher.join();\n        done = true;\n      } catch (InterruptedException e) {\n      }\n    }\n    \n    if (taskReportServer != null) {\n      taskReportServer.stop();\n      taskReportServer = null;\n    }\n    if (healthChecker != null) {\n      //stop node health checker service\n      healthChecker.stop();\n      healthChecker = null;\n    }\n    if (jettyBugMonitor != null) {\n      jettyBugMonitor.shutdown();\n      jettyBugMonitor = null;\n    }\n  }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.run": {
                "code_before_change": [],
                "code_after_change": "    public void run() {\n      while (true) {\n        try {\n          taskCleanUp();\n        } catch (Throwable except) {\n          LOG.warn(StringUtils.stringifyException(except));\n        }\n      }\n    }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.jobHasFinished": {
                "code_before_change": [],
                "code_after_change": "    public void jobHasFinished(boolean ttReInit, boolean wasFailure) \n        throws IOException {\n      // Kill the task if it is still running\n      synchronized(this){\n        if (getRunState() == TaskStatus.State.RUNNING ||\n            getRunState() == TaskStatus.State.UNASSIGNED ||\n            getRunState() == TaskStatus.State.COMMIT_PENDING ||\n            isCleaningup()) {\n          try {\n            kill(wasFailure);\n          } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted while killing \" +\n                getTask().getTaskID(), e);\n          }\n        }\n      }\n      \n      // Cleanup on the finished task\n      cleanup(ttReInit, true);\n    }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.purgeTask": {
                "code_before_change": [],
                "code_after_change": "  private void purgeTask(TaskInProgress tip, boolean wasFailure) \n  throws IOException {\n    if (tip != null) {\n      LOG.info(\"About to purge task: \" + tip.getTask().getTaskID());\n        \n      // Remove the task from running jobs, \n      // removing the job if it's the last task\n      removeTaskFromJob(tip.getTask().getJobID(), tip);\n      tip.jobHasFinished(false, wasFailure);\n      if (tip.getTask().isMapTask()) {\n        indexCache.removeMap(tip.getTask().getTaskID().toString());\n      }\n    }\n  }"
            },
            "src.mapred.org.apache.hadoop.mapred.TaskTracker.taskFinished": {
                "code_before_change": [],
                "code_after_change": "    public void taskFinished() {\n      long start = System.currentTimeMillis();\n\n      //\n      // Wait until task reports as done.  If it hasn't reported in,\n      // wait for a second and try again.\n      //\n      while (!done && (System.currentTimeMillis() - start < WAIT_FOR_DONE)) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n        }\n      }\n\n      //\n      // Change state to success or failure, depending on whether\n      // task was 'done' before terminating\n      //\n      boolean needCleanup = false;\n      synchronized (this) {\n        // Remove the task from MemoryManager, if the task SUCCEEDED or FAILED.\n        // KILLED tasks are removed in method kill(), because Kill \n        // would result in launching a cleanup attempt before \n        // TaskRunner returns; if remove happens here, it would remove\n        // wrong task from memory manager.\n        if (done || !wasKilled) {\n          removeFromMemoryManager(task.getTaskID());\n        }\n        if (!done) {\n          if (!wasKilled) {\n            taskFailures++;\n            setTaskFailState(true);\n            // call the script here for the failed tasks.\n            if (debugCommand != null) {\n              String taskStdout =\"\";\n              String taskStderr =\"\";\n              String taskSyslog =\"\";\n              String jobConf = task.getJobFile();\n              try {\n                Map<LogName, LogFileDetail> allFilesDetails = TaskLog\n                    .getAllLogsFileDetails(task.getTaskID(), task\n                        .isTaskCleanupTask());\n                // get task's stdout file\n                taskStdout =\n                    TaskLog.getRealTaskLogFilePath(\n                        allFilesDetails.get(LogName.STDOUT).location,\n                        LogName.STDOUT);\n                // get task's stderr file\n                taskStderr =\n                    TaskLog.getRealTaskLogFilePath(\n                        allFilesDetails.get(LogName.STDERR).location,\n                        LogName.STDERR);\n                // get task's syslog file\n                taskSyslog =\n                    TaskLog.getRealTaskLogFilePath(\n                        allFilesDetails.get(LogName.SYSLOG).location,\n                        LogName.SYSLOG);\n              } catch(IOException e){\n                LOG.warn(\"Exception finding task's stdout/err/syslog files\");\n              }\n              File workDir = null;\n              try {\n                workDir =\n                    new File(lDirAlloc.getLocalPathToRead(\n                        TaskTracker.getLocalTaskDir(task.getUser(), task\n                            .getJobID().toString(), task.getTaskID()\n                            .toString(), task.isTaskCleanupTask())\n                            + Path.SEPARATOR + MRConstants.WORKDIR,\n                        localJobConf).toString());\n              } catch (IOException e) {\n                LOG.warn(\"Working Directory of the task \" + task.getTaskID() +\n                                \" doesnt exist. Caught exception \" +\n                          StringUtils.stringifyException(e));\n              }\n              // Build the command  \n              File stdout = TaskLog.getTaskLogFile(task.getTaskID(), task\n                  .isTaskCleanupTask(), TaskLog.LogName.DEBUGOUT);\n              // add pipes program as argument if it exists.\n              String program =\"\";\n              String executable = Submitter.getExecutable(localJobConf);\n              if ( executable != null) {\n            \ttry {\n            \t  program = new URI(executable).getFragment();\n            \t} catch (URISyntaxException ur) {\n            \t  LOG.warn(\"Problem in the URI fragment for pipes executable\");\n            \t}\t  \n              }\n              String [] debug = debugCommand.split(\" \");\n              Vector<String> vargs = new Vector<String>();\n              for (String component : debug) {\n                vargs.add(component);\n              }\n              vargs.add(taskStdout);\n              vargs.add(taskStderr);\n              vargs.add(taskSyslog);\n              vargs.add(jobConf);\n              vargs.add(program);\n              try {\n                List<String>  wrappedCommand = TaskLog.captureDebugOut\n                                                          (vargs, stdout);\n                // run the script.\n                try {\n                  runScript(wrappedCommand, workDir);\n                } catch (IOException ioe) {\n                  LOG.warn(\"runScript failed with: \" + StringUtils.\n                                                      stringifyException(ioe));\n                }\n              } catch(IOException e) {\n                LOG.warn(\"Error in preparing wrapped debug command\");\n              }\n\n              // add all lines of debug out to diagnostics\n              try {\n                int num = localJobConf.getInt(\"mapred.debug.out.lines\", -1);\n                addDiagnostics(FileUtil.makeShellPath(stdout),num,\"DEBUG OUT\");\n              } catch(IOException ioe) {\n                LOG.warn(\"Exception in add diagnostics!\");\n              }\n\n              // Debug-command is run. Do the post-debug-script-exit debug-logs\n              // processing. Truncate the logs.\n              JvmFinishedEvent jvmFinished = new JvmFinishedEvent(new JVMInfo(\n                  TaskLog.getAttemptDir(task.getTaskID(), task\n                      .isTaskCleanupTask()), Arrays.asList(task)));\n              getUserLogManager().addLogEvent(jvmFinished);\n            }\n          }\n          taskStatus.setProgress(0.0f);\n        }\n        this.taskStatus.setFinishTime(System.currentTimeMillis());\n        needCleanup = (taskStatus.getRunState() == TaskStatus.State.FAILED || \n                taskStatus.getRunState() == TaskStatus.State.FAILED_UNCLEAN ||\n                taskStatus.getRunState() == TaskStatus.State.KILLED_UNCLEAN || \n                taskStatus.getRunState() == TaskStatus.State.KILLED);\n      }\n\n      //\n      // If the task has failed, or if the task was killAndCleanup()'ed,\n      // we should clean up right away.  We only wait to cleanup\n      // if the task succeeded, and its results might be useful\n      // later on to downstream job processing.\n      //\n      if (needCleanup) {\n        removeTaskFromJob(task.getJobID(), this);\n      }\n      try {\n        cleanup(false, needCleanup);\n      } catch (IOException ie) {\n      }\n\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies a race condition leading to a ClosedChannelException, which is related to the ground truth methods in the TaskTracker class, but it does not precisely identify the root cause in the specific ground truth methods. The suggested fix involves synchronization mechanisms and checks, which are alternative approaches to the actual fixes made in the ground truth methods. The problem location mentions methods in the stack trace context, but not the exact ground truth methods. There is no incorrect information in the bug report."
        }
    },
    {
        "filename": "MAPREDUCE-7028.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.TaskAttemptListenerImpl.setCheckpointID": {
                "code_before_change": "  public void setCheckpointID(TaskID taskId, TaskCheckpointID cid) {\n    TaskId tid = TypeConverter.toYarn(taskId);\n    preemptionPolicy.setCheckpointID(tid, cid);\n  }",
                "code_after_change": "  public void setCheckpointID(TaskID taskId, TaskCheckpointID cid) {\n    TaskId tid = TypeConverter.toYarn(taskId);\n    preemptionPolicy.setCheckpointID(tid, cid);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.TaskAttemptListenerImpl.coalesceStatusUpdate": {
                "code_before_change": "  private void coalesceStatusUpdate(TaskAttemptId yarnAttemptID,\n      TaskAttemptStatus taskAttemptStatus,\n      AtomicReference<TaskAttemptStatus> lastStatusRef) {\n    boolean asyncUpdatedNeeded = false;\n    TaskAttemptStatus lastStatus = lastStatusRef.get();\n\n    if (lastStatus == null) {\n      lastStatusRef.set(taskAttemptStatus);\n      asyncUpdatedNeeded = true;\n    } else {\n      List<TaskAttemptId> oldFetchFailedMaps =\n          taskAttemptStatus.fetchFailedMaps;\n\n      // merge fetchFailedMaps from the previous update\n      if (lastStatus.fetchFailedMaps != null) {\n        if (taskAttemptStatus.fetchFailedMaps == null) {\n          taskAttemptStatus.fetchFailedMaps = lastStatus.fetchFailedMaps;\n        } else {\n          taskAttemptStatus.fetchFailedMaps.addAll(lastStatus.fetchFailedMaps);\n        }\n      }\n\n      if (!lastStatusRef.compareAndSet(lastStatus, taskAttemptStatus)) {\n        // update failed - async dispatcher has processed it in the meantime\n        taskAttemptStatus.fetchFailedMaps = oldFetchFailedMaps;\n        lastStatusRef.set(taskAttemptStatus);\n        asyncUpdatedNeeded = true;\n      }\n    }\n\n    if (asyncUpdatedNeeded) {\n      context.getEventHandler().handle(\n          new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n              lastStatusRef));\n    }\n  }",
                "code_after_change": "  private void coalesceStatusUpdate(TaskAttemptId yarnAttemptID,\n      TaskAttemptStatus taskAttemptStatus,\n      AtomicReference<TaskAttemptStatus> lastStatusRef) {\n    List<TaskAttemptId> fetchFailedMaps = taskAttemptStatus.fetchFailedMaps;\n    TaskAttemptStatus lastStatus = null;\n    boolean done = false;\n    while (!done) {\n      lastStatus = lastStatusRef.get();\n      if (lastStatus != null && lastStatus.fetchFailedMaps != null) {\n        // merge fetchFailedMaps from the previous update\n        if (taskAttemptStatus.fetchFailedMaps == null) {\n          taskAttemptStatus.fetchFailedMaps = lastStatus.fetchFailedMaps;\n        } else {\n          taskAttemptStatus.fetchFailedMaps =\n              new ArrayList<>(lastStatus.fetchFailedMaps.size() +\n                  fetchFailedMaps.size());\n          taskAttemptStatus.fetchFailedMaps.addAll(\n              lastStatus.fetchFailedMaps);\n          taskAttemptStatus.fetchFailedMaps.addAll(\n              fetchFailedMaps);\n        }\n      }\n\n      // lastStatusRef may be changed by either the AsyncDispatcher when\n      // it processes the update, or by another IPC server handler\n      done = lastStatusRef.compareAndSet(lastStatus, taskAttemptStatus);\n      if (!done) {\n        LOG.info(\"TaskAttempt \" + yarnAttemptID +\n            \": lastStatusRef changed by another thread, retrying...\");\n        // let's revert taskAttemptStatus.fetchFailedMaps\n        taskAttemptStatus.fetchFailedMaps = fetchFailedMaps;\n      }\n    }\n\n    boolean asyncUpdatedNeeded = (lastStatus == null);\n    if (asyncUpdatedNeeded) {\n      context.getEventHandler().handle(\n          new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n              lastStatusRef));\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a race condition in the TaskAttemptImpl.handle method, which is mentioned in the stack trace but is not the ground truth method. Therefore, it is classified as 'Partial' with 'Shared Stack Trace Context'. The fix suggestion involves implementing synchronization mechanisms, which is preventive as it addresses the race condition but does not match the developer's fix. The problem location is identified as TaskAttemptImpl.handle, which is in the stack trace but not the ground truth, so it is 'Partial' with 'Shared Stack Trace Context'. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3790.json",
        "code_diff": {
            "hadoop-tools.hadoop-streaming.src.main.java.org.apache.hadoop.streaming.PipeMapRed.mapRedFinished": {
                "code_before_change": "  public void mapRedFinished() {\n    try {\n      if (!doPipe_) {\n        LOG.info(\"mapRedFinished\");\n        return;\n      }\n      try {\n        if (clientOut_ != null) {\n          clientOut_.flush();\n          clientOut_.close();\n        }\n        waitOutputThreads();\n      } catch (IOException io) {\n        LOG.warn(io);\n      }\n      if (sim != null) sim.destroy();\n      LOG.info(\"mapRedFinished\");\n    } catch (RuntimeException e) {\n      LOG.info(\"PipeMapRed failed!\", e);\n      throw e;\n    }\n  }",
                "code_after_change": "  public void mapRedFinished() {\n    try {\n      if (!doPipe_) {\n        LOG.info(\"mapRedFinished\");\n        return;\n      }\n      if (clientOut_ != null) {\n        try {\n          clientOut_.flush();\n          clientOut_.close();\n        } catch (IOException io) {\n          LOG.warn(io);\n        }\n      }\n      try {\n        waitOutputThreads();\n      } catch (IOException io) {\n        LOG.warn(io);\n      }\n      if (sim != null) sim.destroy();\n      LOG.info(\"mapRedFinished\");\n    } catch (RuntimeException e) {\n      LOG.info(\"PipeMapRed failed!\", e);\n      throw e;\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the PipeMapRed.mapRedFinished() method, which is consistent with the ground truth method. The fix suggestion in the bug report matches the developer's fix, as it suggests modifying the mapRedFinished() method to handle IOExceptions properly and wait for output threads to complete, which aligns with the changes made in the 'after' code. The problem location is also precisely identified, as the report mentions the PipeMapRed.mapRedFinished method, which is part of the ground truth. There is no wrong information in the bug report; all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6357.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.write": {
                "code_before_change": "    public void write(Object key, Object value) \n        throws IOException, InterruptedException {\n      context.getCounter(COUNTERS_GROUP, counterName).increment(1);\n      writer.write(key, value);\n    }",
                "code_after_change": "    public void write(Object key, Object value) \n        throws IOException, InterruptedException {\n      context.getCounter(COUNTERS_GROUP, counterName).increment(1);\n      writer.write(key, value);\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the use of an absolute path in the MultipleOutputs.write() method, which is consistent with the ground truth method. The fix suggestion is preventive, as it suggests updating the documentation to warn about the implications of using absolute paths, which would mitigate the issue. The problem location identification is precise, as it correctly mentions the MultipleOutputs.write method, which is part of the ground truth. There is no wrong information in the bug report, as all details are relevant and accurate."
        }
    },
    {
        "filename": "MAPREDUCE-6091.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ClientServiceDelegate.getProxy": {
                "code_before_change": "  private MRClientProtocol getProxy() throws IOException {\n    if (realProxy != null) {\n      return realProxy;\n    }\n    \n    // Possibly allow nulls through the PB tunnel, otherwise deal with an exception\n    // and redirect to the history server.\n    ApplicationReport application = null;\n    try {\n      application = rm.getApplicationReport(appId);\n    } catch (YarnException e2) {\n      throw new IOException(e2);\n    }\n    if (application != null) {\n      trackingUrl = application.getTrackingUrl();\n    }\n    InetSocketAddress serviceAddr = null;\n    while (application == null\n        || YarnApplicationState.RUNNING == application\n            .getYarnApplicationState()) {\n      if (application == null) {\n        LOG.info(\"Could not get Job info from RM for job \" + jobId\n            + \". Redirecting to job history server.\");\n        return checkAndGetHSProxy(null, JobState.NEW);\n      }\n      try {\n        if (application.getHost() == null || \"\".equals(application.getHost())) {\n          LOG.debug(\"AM not assigned to Job. Waiting to get the AM ...\");\n          Thread.sleep(2000);\n\n          LOG.debug(\"Application state is \" + application.getYarnApplicationState());\n          application = rm.getApplicationReport(appId);\n          continue;\n        } else if (UNAVAILABLE.equals(application.getHost())) {\n          if (!amAclDisabledStatusLogged) {\n            LOG.info(\"Job \" + jobId + \" is running, but the host is unknown.\"\n                + \" Verify user has VIEW_JOB access.\");\n            amAclDisabledStatusLogged = true;\n          }\n          return getNotRunningJob(application, JobState.RUNNING);\n        }\n        if(!conf.getBoolean(MRJobConfig.JOB_AM_ACCESS_DISABLED, false)) {\n          UserGroupInformation newUgi = UserGroupInformation.createRemoteUser(\n              UserGroupInformation.getCurrentUser().getUserName());\n          serviceAddr = NetUtils.createSocketAddrForHost(\n              application.getHost(), application.getRpcPort());\n          if (UserGroupInformation.isSecurityEnabled()) {\n            org.apache.hadoop.yarn.api.records.Token clientToAMToken =\n                application.getClientToAMToken();\n            Token<ClientToAMTokenIdentifier> token =\n                ConverterUtils.convertFromYarn(clientToAMToken, serviceAddr);\n            newUgi.addToken(token);\n          }\n          LOG.debug(\"Connecting to \" + serviceAddr);\n          final InetSocketAddress finalServiceAddr = serviceAddr;\n          realProxy = newUgi.doAs(new PrivilegedExceptionAction<MRClientProtocol>() {\n            @Override\n            public MRClientProtocol run() throws IOException {\n              return instantiateAMProxy(finalServiceAddr);\n            }\n          });\n        } else {\n          if (!amAclDisabledStatusLogged) {\n            LOG.info(\"Network ACL closed to AM for job \" + jobId\n                + \". Not going to try to reach the AM.\");\n            amAclDisabledStatusLogged = true;\n          }\n          return getNotRunningJob(null, JobState.RUNNING);\n        }\n        return realProxy;\n      } catch (IOException e) {\n        //possibly the AM has crashed\n        //there may be some time before AM is restarted\n        //keep retrying by getting the address from RM\n        LOG.info(\"Could not connect to \" + serviceAddr +\n        \". Waiting for getting the latest AM address...\");\n        try {\n          Thread.sleep(2000);\n        } catch (InterruptedException e1) {\n          LOG.warn(\"getProxy() call interruped\", e1);\n          throw new YarnRuntimeException(e1);\n        }\n        try {\n          application = rm.getApplicationReport(appId);\n        } catch (YarnException e1) {\n          throw new IOException(e1);\n        }\n        if (application == null) {\n          LOG.info(\"Could not get Job info from RM for job \" + jobId\n              + \". Redirecting to job history server.\");\n          return checkAndGetHSProxy(null, JobState.RUNNING);\n        }\n      } catch (InterruptedException e) {\n        LOG.warn(\"getProxy() call interruped\", e);\n        throw new YarnRuntimeException(e);\n      } catch (YarnException e) {\n        throw new IOException(e);\n      }\n    }\n\n    /** we just want to return if its allocating, so that we don't\n     * block on it. This is to be able to return job status\n     * on an allocating Application.\n     */\n    String user = application.getUser();\n    if (user == null) {\n      throw new IOException(\"User is not set in the application report\");\n    }\n    if (application.getYarnApplicationState() == YarnApplicationState.NEW\n        || application.getYarnApplicationState() ==\n            YarnApplicationState.NEW_SAVING\n        || application.getYarnApplicationState() == YarnApplicationState.SUBMITTED\n        || application.getYarnApplicationState() == YarnApplicationState.ACCEPTED) {\n      realProxy = null;\n      return getNotRunningJob(application, JobState.NEW);\n    }\n\n    if (application.getYarnApplicationState() == YarnApplicationState.FAILED) {\n      realProxy = null;\n      return getNotRunningJob(application, JobState.FAILED);\n    }\n\n    if (application.getYarnApplicationState() == YarnApplicationState.KILLED) {\n      realProxy = null;\n      return getNotRunningJob(application, JobState.KILLED);\n    }\n\n    //History server can serve a job only if application\n    //succeeded.\n    if (application.getYarnApplicationState() == YarnApplicationState.FINISHED) {\n      LOG.info(\"Application state is completed. FinalApplicationStatus=\"\n          + application.getFinalApplicationStatus().toString()\n          + \". Redirecting to job history server\");\n      realProxy = checkAndGetHSProxy(application, JobState.SUCCEEDED);\n    }\n    return realProxy;\n  }",
                "code_after_change": "  private MRClientProtocol getProxy() throws IOException {\n    if (realProxy != null) {\n      return realProxy;\n    }\n    \n    // Possibly allow nulls through the PB tunnel, otherwise deal with an exception\n    // and redirect to the history server.\n    ApplicationReport application = null;\n    try {\n      application = rm.getApplicationReport(appId);\n    } catch (ApplicationNotFoundException e) {\n      application = null;\n    } catch (YarnException e2) {\n      throw new IOException(e2);\n    }\n    if (application != null) {\n      trackingUrl = application.getTrackingUrl();\n    }\n    InetSocketAddress serviceAddr = null;\n    while (application == null\n        || YarnApplicationState.RUNNING == application\n            .getYarnApplicationState()) {\n      if (application == null) {\n        LOG.info(\"Could not get Job info from RM for job \" + jobId\n            + \". Redirecting to job history server.\");\n        return checkAndGetHSProxy(null, JobState.NEW);\n      }\n      try {\n        if (application.getHost() == null || \"\".equals(application.getHost())) {\n          LOG.debug(\"AM not assigned to Job. Waiting to get the AM ...\");\n          Thread.sleep(2000);\n\n          LOG.debug(\"Application state is \" + application.getYarnApplicationState());\n          application = rm.getApplicationReport(appId);\n          continue;\n        } else if (UNAVAILABLE.equals(application.getHost())) {\n          if (!amAclDisabledStatusLogged) {\n            LOG.info(\"Job \" + jobId + \" is running, but the host is unknown.\"\n                + \" Verify user has VIEW_JOB access.\");\n            amAclDisabledStatusLogged = true;\n          }\n          return getNotRunningJob(application, JobState.RUNNING);\n        }\n        if(!conf.getBoolean(MRJobConfig.JOB_AM_ACCESS_DISABLED, false)) {\n          UserGroupInformation newUgi = UserGroupInformation.createRemoteUser(\n              UserGroupInformation.getCurrentUser().getUserName());\n          serviceAddr = NetUtils.createSocketAddrForHost(\n              application.getHost(), application.getRpcPort());\n          if (UserGroupInformation.isSecurityEnabled()) {\n            org.apache.hadoop.yarn.api.records.Token clientToAMToken =\n                application.getClientToAMToken();\n            Token<ClientToAMTokenIdentifier> token =\n                ConverterUtils.convertFromYarn(clientToAMToken, serviceAddr);\n            newUgi.addToken(token);\n          }\n          LOG.debug(\"Connecting to \" + serviceAddr);\n          final InetSocketAddress finalServiceAddr = serviceAddr;\n          realProxy = newUgi.doAs(new PrivilegedExceptionAction<MRClientProtocol>() {\n            @Override\n            public MRClientProtocol run() throws IOException {\n              return instantiateAMProxy(finalServiceAddr);\n            }\n          });\n        } else {\n          if (!amAclDisabledStatusLogged) {\n            LOG.info(\"Network ACL closed to AM for job \" + jobId\n                + \". Not going to try to reach the AM.\");\n            amAclDisabledStatusLogged = true;\n          }\n          return getNotRunningJob(null, JobState.RUNNING);\n        }\n        return realProxy;\n      } catch (IOException e) {\n        //possibly the AM has crashed\n        //there may be some time before AM is restarted\n        //keep retrying by getting the address from RM\n        LOG.info(\"Could not connect to \" + serviceAddr +\n        \". Waiting for getting the latest AM address...\");\n        try {\n          Thread.sleep(2000);\n        } catch (InterruptedException e1) {\n          LOG.warn(\"getProxy() call interruped\", e1);\n          throw new YarnRuntimeException(e1);\n        }\n        try {\n          application = rm.getApplicationReport(appId);\n        } catch (YarnException e1) {\n          throw new IOException(e1);\n        }\n        if (application == null) {\n          LOG.info(\"Could not get Job info from RM for job \" + jobId\n              + \". Redirecting to job history server.\");\n          return checkAndGetHSProxy(null, JobState.RUNNING);\n        }\n      } catch (InterruptedException e) {\n        LOG.warn(\"getProxy() call interruped\", e);\n        throw new YarnRuntimeException(e);\n      } catch (YarnException e) {\n        throw new IOException(e);\n      }\n    }\n\n    /** we just want to return if its allocating, so that we don't\n     * block on it. This is to be able to return job status\n     * on an allocating Application.\n     */\n    String user = application.getUser();\n    if (user == null) {\n      throw new IOException(\"User is not set in the application report\");\n    }\n    if (application.getYarnApplicationState() == YarnApplicationState.NEW\n        || application.getYarnApplicationState() ==\n            YarnApplicationState.NEW_SAVING\n        || application.getYarnApplicationState() == YarnApplicationState.SUBMITTED\n        || application.getYarnApplicationState() == YarnApplicationState.ACCEPTED) {\n      realProxy = null;\n      return getNotRunningJob(application, JobState.NEW);\n    }\n\n    if (application.getYarnApplicationState() == YarnApplicationState.FAILED) {\n      realProxy = null;\n      return getNotRunningJob(application, JobState.FAILED);\n    }\n\n    if (application.getYarnApplicationState() == YarnApplicationState.KILLED) {\n      realProxy = null;\n      return getNotRunningJob(application, JobState.KILLED);\n    }\n\n    //History server can serve a job only if application\n    //succeeded.\n    if (application.getYarnApplicationState() == YarnApplicationState.FINISHED) {\n      LOG.info(\"Application state is completed. FinalApplicationStatus=\"\n          + application.getFinalApplicationStatus().toString()\n          + \". Redirecting to job history server\");\n      realProxy = checkAndGetHSProxy(application, JobState.SUCCEEDED);\n    }\n    return realProxy;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a change in behavior of the ClientRMService, which is related to the issue but not the exact root cause in the ground truth method. The report suggests modifying the ClientServiceDelegate to check the job history server, which is an alternative fix to the actual change made in the getProxy method. The problem location mentions YARNRunner.getJobStatus and ClientServiceDelegate.getJobStatus, which are related to the issue but not the exact ground truth method. There is no wrong information in the bug report as it accurately describes the problem and its context."
        }
    },
    {
        "filename": "MAPREDUCE-4825.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.finished": {
                "code_before_change": "  JobStateInternal finished(JobStateInternal finalState) {\n    if (getInternalState() == JobStateInternal.RUNNING) {\n      metrics.endRunningJob(this);\n    }\n    if (finishTime == 0) setFinishTime();\n    eventHandler.handle(new JobFinishEvent(jobId));\n\n    switch (finalState) {\n      case KILLED:\n        metrics.killedJob(this);\n        break;\n      case FAILED:\n        metrics.failedJob(this);\n        break;\n      case SUCCEEDED:\n        metrics.completedJob(this);\n        break;\n      default:\n        throw new IllegalArgumentException(\"Illegal job state: \" + finalState);\n    }\n    return finalState;\n  }",
                "code_after_change": "  JobStateInternal finished(JobStateInternal finalState) {\n    if (getInternalState() == JobStateInternal.RUNNING) {\n      metrics.endRunningJob(this);\n    }\n    if (finishTime == 0) setFinishTime();\n    eventHandler.handle(new JobFinishEvent(jobId));\n\n    switch (finalState) {\n      case KILLED:\n        metrics.killedJob(this);\n        break;\n      case ERROR:\n      case FAILED:\n        metrics.failedJob(this);\n        break;\n      case SUCCEEDED:\n        metrics.completedJob(this);\n        break;\n      default:\n        throw new IllegalArgumentException(\"Illegal job state: \" + finalState);\n    }\n    return finalState;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the JobImpl.finished method not handling the ERROR state, which matches the ground truth method. The fix suggestion in the report is to modify the JobImpl.finished method to handle the ERROR state, which aligns with the developer's actual fix of adding a case for ERROR in the switch statement. The problem location is precisely identified as the JobImpl.finished method, which is part of the ground truth. There is no wrong information in the bug report as all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3319.json",
        "code_diff": {
            "src.examples.org.apache.hadoop.examples.MultiFileWordCount.run": {
                "code_before_change": [],
                "code_after_change": "  public int run(String[] args) throws Exception {\n\n    if(args.length < 2) {\n      printUsage();\n      return 1;\n    }\n\n    JobConf job = new JobConf(getConf(), MultiFileWordCount.class);\n    job.setJobName(\"MultiFileWordCount\");\n\n    //set the InputFormat of the job to our InputFormat\n    job.setInputFormat(MyInputFormat.class);\n    \n    // the keys are words (strings)\n    job.setOutputKeyClass(Text.class);\n    // the values are counts (ints)\n    job.setOutputValueClass(LongWritable.class);\n\n    //use the defined mapper\n    job.setMapperClass(MapClass.class);\n    //use the WordCount Reducer\n    job.setCombinerClass(LongSumReducer.class);\n    job.setReducerClass(LongSumReducer.class);\n\n    FileInputFormat.addInputPaths(job, args[0]);\n    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n\n    JobClient.runJob(job);\n    \n    return 0;\n  }"
            },
            "src.examples.org.apache.hadoop.examples.MultiFileWordCount.createValue": {
                "code_before_change": [],
                "code_after_change": "    public Text createValue() {\n      return new Text();\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a mismatch between expected LongWritable and provided IntWritable values in the LongSumReducer, which is a buggy method but not where the actual fix was made. The fix suggestion to modify the input data or use a different reducer is an alternative fix, as the actual fix involved setting the output value class to LongWritable in the MultiFileWordCount.run method. The problem location mentions LongSumReducer.reduce, which is the buggy method but not the ground truth method where the fix was applied. There is no wrong information in the bug report as it accurately describes the issue and provides a valid alternative solution."
        }
    },
    {
        "filename": "MAPREDUCE-6361.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.updateStatus": {
                "code_before_change": "  private synchronized void updateStatus(String individualProgress) {\n    int mapsDone = totalMaps - remainingMaps;\n    long totalCopyMillis = copyTimeTracker.getCopyMillis();\n    if (totalCopyMillis == 0) totalCopyMillis = 1;\n    float bytesPerMillis = (float) totalBytesShuffledTillNow / totalCopyMillis;\n    float transferRate = bytesPerMillis * BYTES_PER_MILLIS_TO_MBS;\n    progress.set((float) mapsDone / totalMaps);\n    String statusString = mapsDone + \" / \" + totalMaps + \" copied.\";\n    status.setStateString(statusString);\n\n    if (individualProgress != null) {\n      progress.setStatus(individualProgress + \" Aggregated copy rate(\" + \n          mapsDone + \" of \" + totalMaps + \" at \" + \n      mbpsFormat.format(transferRate) + \" MB/s)\");\n    } else {\n      progress.setStatus(\"copy(\" + mapsDone + \" of \" + totalMaps + \" at \"\n          + mbpsFormat.format(transferRate) + \" MB/s)\");\n    }\n  }",
                "code_after_change": "  private synchronized void updateStatus(String individualProgress) {\n    int mapsDone = totalMaps - remainingMaps;\n    long totalCopyMillis = copyTimeTracker.getCopyMillis();\n    if (totalCopyMillis == 0) totalCopyMillis = 1;\n    float bytesPerMillis = (float) totalBytesShuffledTillNow / totalCopyMillis;\n    float transferRate = bytesPerMillis * BYTES_PER_MILLIS_TO_MBS;\n    progress.set((float) mapsDone / totalMaps);\n    String statusString = mapsDone + \" / \" + totalMaps + \" copied.\";\n    status.setStateString(statusString);\n\n    if (individualProgress != null) {\n      progress.setStatus(individualProgress + \" Aggregated copy rate(\" + \n          mapsDone + \" of \" + totalMaps + \" at \" + \n      mbpsFormat.format(transferRate) + \" MB/s)\");\n    } else {\n      progress.setStatus(\"copy(\" + mapsDone + \" of \" + totalMaps + \" at \"\n          + mbpsFormat.format(transferRate) + \" MB/s)\");\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed": {
                "code_before_change": "  public synchronized void copyFailed(TaskAttemptID mapId, MapHost host,\n      boolean readError, boolean connectExcpt) {\n    host.penalize();\n    int failures = 1;\n    if (failureCounts.containsKey(mapId)) {\n      IntWritable x = failureCounts.get(mapId);\n      x.set(x.get() + 1);\n      failures = x.get();\n    } else {\n      failureCounts.put(mapId, new IntWritable(1));\n    }\n    String hostname = host.getHostName();\n    //report failure if already retried maxHostFailures times\n    boolean hostFail = hostFailures.get(hostname).get() > getMaxHostFailures() ? true : false;\n    \n    if (failures >= abortFailureLimit) {\n      try {\n        throw new IOException(failures + \" failures downloading \" + mapId);\n      } catch (IOException ie) {\n        reporter.reportException(ie);\n      }\n    }\n\n    checkAndInformMRAppMaster(failures, mapId, readError, connectExcpt,\n        hostFail);\n\n    checkReducerHealth();\n\n    long delay = (long) (INITIAL_PENALTY *\n        Math.pow(PENALTY_GROWTH_RATE, failures));\n    if (delay > maxDelay) {\n      delay = maxDelay;\n    }\n\n    penalties.add(new Penalty(host, delay));\n\n    failedShuffleCounter.increment(1);\n  }",
                "code_after_change": "  public synchronized void copyFailed(TaskAttemptID mapId, MapHost host,\n      boolean readError, boolean connectExcpt) {\n    host.penalize();\n    int failures = 1;\n    if (failureCounts.containsKey(mapId)) {\n      IntWritable x = failureCounts.get(mapId);\n      x.set(x.get() + 1);\n      failures = x.get();\n    } else {\n      failureCounts.put(mapId, new IntWritable(1));\n    }\n    String hostname = host.getHostName();\n    IntWritable hostFailedNum = hostFailures.get(hostname);\n    // MAPREDUCE-6361: hostname could get cleanup from hostFailures in another\n    // thread with copySucceeded.\n    // In this case, add back hostname to hostFailures to get rid of NPE issue.\n    if (hostFailedNum == null) {\n      hostFailures.put(hostname, new IntWritable(1));\n    }\n    //report failure if already retried maxHostFailures times\n    boolean hostFail = hostFailures.get(hostname).get() >\n        getMaxHostFailures() ? true : false;\n\n    if (failures >= abortFailureLimit) {\n      try {\n        throw new IOException(failures + \" failures downloading \" + mapId);\n      } catch (IOException ie) {\n        reporter.reportException(ie);\n      }\n    }\n\n    checkAndInformMRAppMaster(failures, mapId, readError, connectExcpt,\n        hostFail);\n\n    checkReducerHealth();\n\n    long delay = (long) (INITIAL_PENALTY *\n        Math.pow(PENALTY_GROWTH_RATE, failures));\n    if (delay > maxDelay) {\n      delay = maxDelay;\n    }\n\n    penalties.add(new Penalty(host, delay));\n\n    failedShuffleCounter.increment(1);\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report accurately identifies the root cause as a race condition between the `copySucceeded()` and `copyFailed()` methods, which is consistent with the ground truth method `ShuffleSchedulerImpl.copyFailed`. The fix suggestion to implement proper synchronization mechanisms matches the developer's fix, which involved adding checks to handle concurrent modifications. The problem location is precisely identified as it mentions `ShuffleSchedulerImpl.copyFailed`, which is a ground truth method. There is no wrong information in the bug report as all details are consistent with the provided ground truth and source code."
        }
    },
    {
        "filename": "MAPREDUCE-4848.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.createJobFinishEventHandler": {
                "code_before_change": "  protected EventHandler<JobFinishEvent> createJobFinishEventHandler() {\n    return new JobFinishEventHandler();\n  }",
                "code_after_change": "  protected EventHandler<JobFinishEvent> createJobFinishEventHandler() {\n    return new JobFinishEventHandler();\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a ClassCastException in the OutputCommitter's recoverTask method, which is mentioned in the stack trace but not the ground truth method. Therefore, it is classified as 'Partial' with 'Shared Stack Trace Context'. The fix suggestion involves modifying the recoverTask method, which is an alternative approach to the developer's fix, as the actual fix was in a different method. The problem location is also 'Partial' with 'Shared Stack Trace Context' because it mentions methods in the stack trace but not the ground truth method. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3226.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.reduce.Fetcher.Fetcher": {
                "code_before_change": [],
                "code_after_change": []
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run": {
                "code_before_change": "  public void run() {\n    int failures = 0;\n    LOG.info(reduce + \" Thread started: \" + getName());\n    \n    try {\n      while (true) {\n        try {\n          int numNewMaps = getMapCompletionEvents();\n          failures = 0;\n          if (numNewMaps > 0) {\n            LOG.info(reduce + \": \" + \"Got \" + numNewMaps + \" new map-outputs\");\n          }\n          LOG.debug(\"GetMapEventsThread about to sleep for \" + SLEEP_TIME);\n          Thread.sleep(SLEEP_TIME);\n        } catch (IOException ie) {\n          LOG.info(\"Exception in getting events\", ie);\n          // check to see whether to abort\n          if (++failures >= MAX_RETRIES) {\n            throw new IOException(\"too many failures downloading events\", ie);\n          }\n          // sleep for a bit\n          Thread.sleep(RETRY_PERIOD);\n        }\n      }\n    } catch (InterruptedException e) {\n      return;\n    } catch (Throwable t) {\n      exceptionReporter.reportException(t);\n      return;\n    }\n  }",
                "code_after_change": "  public void run() {\n    int failures = 0;\n    LOG.info(reduce + \" Thread started: \" + getName());\n    \n    try {\n      while (true && !Thread.currentThread().isInterrupted()) {\n        try {\n          int numNewMaps = getMapCompletionEvents();\n          failures = 0;\n          if (numNewMaps > 0) {\n            LOG.info(reduce + \": \" + \"Got \" + numNewMaps + \" new map-outputs\");\n          }\n          LOG.debug(\"GetMapEventsThread about to sleep for \" + SLEEP_TIME);\n          if (!Thread.currentThread().isInterrupted()) {\n            Thread.sleep(SLEEP_TIME);\n          }\n        } catch (IOException ie) {\n          LOG.info(\"Exception in getting events\", ie);\n          // check to see whether to abort\n          if (++failures >= MAX_RETRIES) {\n            throw new IOException(\"too many failures downloading events\", ie);\n          }\n          // sleep for a bit\n          if (!Thread.currentThread().isInterrupted()) {\n            Thread.sleep(RETRY_PERIOD);\n          }\n        }\n      }\n    } catch (InterruptedException e) {\n      return;\n    } catch (Throwable t) {\n      exceptionReporter.reportException(t);\n      return;\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as being related to the 'EventFetcher.run' method, which is part of the ground truth methods. The fix suggestion in the bug report matches the developer's fix, which involves handling thread interruptions to prevent the thread from entering a sleep state indefinitely. The problem location is also precisely identified, as the 'EventFetcher.run' method is explicitly mentioned in the 'problem_location' field. There is no wrong information in the bug report; all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3932.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.KillTasksTransition": {
                "code_before_change": [],
                "code_after_change": []
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.TaskCleanupTransition": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as improper handling of task attempts when resources are zero, which is related to the TaskAttemptImpl.handle method. However, the actual fix was made in TaskCleanupTransition and KillTasksTransition methods, making it a 'Buggy Method' identification. The fix suggestion to add checks for resource availability is preventive, as it would mitigate the issue but does not match the developer's fix. The problem location mentions TaskAttemptImpl.handle, which is where the error occurs but not where the fix was applied, thus 'Buggy Method'. There is no wrong information in the report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4062.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.init": {
                "code_before_change": "  public synchronized void init(Configuration config) {\n    Configuration conf = new Configuration(config);\n    conf.setInt(\n        CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,\n        0);\n    this.limitOnPoolSize = conf.getInt(\n        MRJobConfig.MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT,\n        MRJobConfig.DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT);\n    LOG.info(\"Upper limit on the thread pool size is \" + this.limitOnPoolSize);\n    this.nmTimeOut = conf.getInt(ContainerLauncher.MR_AM_NM_COMMAND_TIMEOUT,\n        ContainerLauncher.DEFAULT_NM_COMMAND_TIMEOUT);\n    this.rpc = createYarnRPC(conf);\n    super.init(conf);\n  }",
                "code_after_change": "  public synchronized void init(Configuration config) {\n    Configuration conf = new Configuration(config);\n    conf.setInt(\n        CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,\n        0);\n    this.limitOnPoolSize = conf.getInt(\n        MRJobConfig.MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT,\n        MRJobConfig.DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT);\n    LOG.info(\"Upper limit on the thread pool size is \" + this.limitOnPoolSize);\n    this.rpc = createYarnRPC(conf);\n    super.init(conf);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.kill": {
                "code_before_change": "    public synchronized void kill(ContainerLauncherEvent event) {\n      if(this.state == ContainerState.PREP) {\n        this.state = ContainerState.KILLED_BEFORE_LAUNCH;\n      } else {\n        CommandTimerTask timerTask = new CommandTimerTask(Thread\n            .currentThread(), event);\n\n        final String containerManagerBindAddr = event.getContainerMgrAddress();\n        ContainerId containerID = event.getContainerID();\n        ContainerToken containerToken = event.getContainerToken();\n        TaskAttemptId taskAttemptID = event.getTaskAttemptID();\n        LOG.info(\"KILLING \" + taskAttemptID);\n        commandTimer.schedule(timerTask, nmTimeOut);\n\n        ContainerManager proxy = null;\n        try {\n          proxy = getCMProxy(containerID, containerManagerBindAddr,\n              containerToken);\n\n          if (Thread.interrupted()) {\n            // The timer canceled the command in the mean while. No need to\n            // return, send cleaned up event anyways.\n            LOG.info(\"Stop-container for \" + event.getContainerID()\n                + \" got interrupted.\");\n          } else {\n            // kill the remote container if already launched\n            StopContainerRequest stopRequest = Records\n              .newRecord(StopContainerRequest.class);\n            stopRequest.setContainerId(event.getContainerID());\n            proxy.stopContainer(stopRequest);\n          }\n        } catch (Throwable t) {\n\n          if (Thread.interrupted()) {\n            // The timer canceled the command in the mean while, clear the\n            // interrupt flag\n            LOG.info(\"Stop-container for \" + event.getContainerID()\n                + \" got interrupted.\");\n          }\n\n          // ignore the cleanup failure\n          String message = \"cleanup failed for container \"\n            + event.getContainerID() + \" : \"\n            + StringUtils.stringifyException(t);\n          context.getEventHandler().handle(\n            new TaskAttemptDiagnosticsUpdateEvent(taskAttemptID, message));\n          LOG.warn(message);\n        } finally {\n          timerTask.cancel();\n          if (Thread.interrupted()) {\n            LOG.info(\"Stop-container for \" + event.getContainerID()\n                + \" got interrupted.\");\n            // ignore the cleanup failure\n            context.getEventHandler().handle(\n              new TaskAttemptDiagnosticsUpdateEvent(taskAttemptID,\n                \"cleanup failed for container \" + event.getContainerID()));\n          }\n          if (proxy != null) {\n            ContainerLauncherImpl.this.rpc.stopProxy(proxy, getConfig());\n          }\n        }\n        this.state = ContainerState.DONE;\n      }\n      // after killing, send killed event to task attempt\n      context.getEventHandler().handle(\n          new TaskAttemptEvent(event.getTaskAttemptID(),\n              TaskAttemptEventType.TA_CONTAINER_CLEANED));\n    }",
                "code_after_change": "    public synchronized void kill(ContainerLauncherEvent event) {\n      if(this.state == ContainerState.PREP) {\n        this.state = ContainerState.KILLED_BEFORE_LAUNCH;\n      } else {\n        final String containerManagerBindAddr = event.getContainerMgrAddress();\n        ContainerId containerID = event.getContainerID();\n        ContainerToken containerToken = event.getContainerToken();\n        TaskAttemptId taskAttemptID = event.getTaskAttemptID();\n        LOG.info(\"KILLING \" + taskAttemptID);\n\n        ContainerManager proxy = null;\n        try {\n          proxy = getCMProxy(containerID, containerManagerBindAddr,\n              containerToken);\n\n            // kill the remote container if already launched\n            StopContainerRequest stopRequest = Records\n              .newRecord(StopContainerRequest.class);\n            stopRequest.setContainerId(event.getContainerID());\n            proxy.stopContainer(stopRequest);\n\n        } catch (Throwable t) {\n\n          // ignore the cleanup failure\n          String message = \"cleanup failed for container \"\n            + event.getContainerID() + \" : \"\n            + StringUtils.stringifyException(t);\n          context.getEventHandler().handle(\n            new TaskAttemptDiagnosticsUpdateEvent(taskAttemptID, message));\n          LOG.warn(message);\n        } finally {\n          if (proxy != null) {\n            ContainerLauncherImpl.this.rpc.stopProxy(proxy, getConfig());\n          }\n        }\n        this.state = ContainerState.DONE;\n      }\n      // after killing, send killed event to task attempt\n      context.getEventHandler().handle(\n          new TaskAttemptEvent(event.getTaskAttemptID(),\n              TaskAttemptEventType.TA_CONTAINER_CLEANED));\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.launch": {
                "code_before_change": "    public synchronized void launch(ContainerRemoteLaunchEvent event) {\n      TaskAttemptId taskAttemptID = event.getTaskAttemptID();\n      LOG.info(\"Launching \" + taskAttemptID);\n      if(this.state == ContainerState.KILLED_BEFORE_LAUNCH) {\n        state = ContainerState.DONE;\n        sendContainerLaunchFailedMsg(taskAttemptID, \n            \"Container was killed before it was launched\");\n        return;\n      }\n      CommandTimerTask timerTask = new CommandTimerTask(Thread\n          .currentThread(), event);\n      \n      final String containerManagerBindAddr = event.getContainerMgrAddress();\n      ContainerId containerID = event.getContainerID();\n      ContainerToken containerToken = event.getContainerToken();\n\n      ContainerManager proxy = null;\n      try {\n        commandTimer.schedule(timerTask, nmTimeOut);\n\n        proxy = getCMProxy(containerID, containerManagerBindAddr,\n            containerToken);\n\n        // Interrupted during getProxy, but that didn't throw exception\n        if (Thread.interrupted()) {\n          // The timer canceled the command in the mean while.\n          String message = \"Container launch failed for \" + containerID\n              + \" : Start-container for \" + event.getContainerID()\n              + \" got interrupted. Returning.\";\n          this.state = ContainerState.FAILED;\n          sendContainerLaunchFailedMsg(taskAttemptID, message);\n          return;\n        }\n        // Construct the actual Container\n        ContainerLaunchContext containerLaunchContext =\n          event.getContainer();\n\n        // Now launch the actual container\n        StartContainerRequest startRequest = Records\n          .newRecord(StartContainerRequest.class);\n        startRequest.setContainerLaunchContext(containerLaunchContext);\n        StartContainerResponse response = proxy.startContainer(startRequest);\n\n        // container started properly. Stop the timer\n        timerTask.cancel();\n        if (Thread.interrupted()) {\n          // The timer canceled the command in the mean while, but\n          // startContainer didn't throw exception\n          String message = \"Container launch failed for \" + containerID\n              + \" : Start-container for \" + event.getContainerID()\n              + \" got interrupted. Returning.\";\n          this.state = ContainerState.FAILED;\n          sendContainerLaunchFailedMsg(taskAttemptID, message);\n          return;\n        }\n\n        ByteBuffer portInfo = response\n          .getServiceResponse(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID);\n        int port = -1;\n        if(portInfo != null) {\n          port = ShuffleHandler.deserializeMetaData(portInfo);\n        }\n        LOG.info(\"Shuffle port returned by ContainerManager for \"\n            + taskAttemptID + \" : \" + port);\n\n        if(port < 0) {\n          this.state = ContainerState.FAILED;\n          throw new IllegalStateException(\"Invalid shuffle port number \"\n              + port + \" returned for \" + taskAttemptID);\n        }\n\n        // after launching, send launched event to task attempt to move\n        // it from ASSIGNED to RUNNING state\n        context.getEventHandler().handle(\n            new TaskAttemptContainerLaunchedEvent(taskAttemptID, port));\n        this.state = ContainerState.RUNNING;\n      } catch (Throwable t) {\n        if (Thread.interrupted()) {\n          // The timer canceled the command in the mean while.\n          LOG.info(\"Start-container for \" + event.getContainerID()\n              + \" got interrupted.\");\n        }\n        String message = \"Container launch failed for \" + containerID + \" : \"\n            + StringUtils.stringifyException(t);\n        this.state = ContainerState.FAILED;\n        sendContainerLaunchFailedMsg(taskAttemptID, message);\n      } finally {\n        timerTask.cancel();\n        if (proxy != null) {\n          ContainerLauncherImpl.this.rpc.stopProxy(proxy, getConfig());\n        }\n      }\n    }",
                "code_after_change": "    public synchronized void launch(ContainerRemoteLaunchEvent event) {\n      TaskAttemptId taskAttemptID = event.getTaskAttemptID();\n      LOG.info(\"Launching \" + taskAttemptID);\n      if(this.state == ContainerState.KILLED_BEFORE_LAUNCH) {\n        state = ContainerState.DONE;\n        sendContainerLaunchFailedMsg(taskAttemptID, \n            \"Container was killed before it was launched\");\n        return;\n      }\n      \n\n      final String containerManagerBindAddr = event.getContainerMgrAddress();\n      ContainerId containerID = event.getContainerID();\n      ContainerToken containerToken = event.getContainerToken();\n\n      ContainerManager proxy = null;\n      try {\n\n        proxy = getCMProxy(containerID, containerManagerBindAddr,\n            containerToken);\n\n        // Construct the actual Container\n        ContainerLaunchContext containerLaunchContext =\n          event.getContainer();\n\n        // Now launch the actual container\n        StartContainerRequest startRequest = Records\n          .newRecord(StartContainerRequest.class);\n        startRequest.setContainerLaunchContext(containerLaunchContext);\n        StartContainerResponse response = proxy.startContainer(startRequest);\n\n        ByteBuffer portInfo = response\n          .getServiceResponse(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID);\n        int port = -1;\n        if(portInfo != null) {\n          port = ShuffleHandler.deserializeMetaData(portInfo);\n        }\n        LOG.info(\"Shuffle port returned by ContainerManager for \"\n            + taskAttemptID + \" : \" + port);\n\n        if(port < 0) {\n          this.state = ContainerState.FAILED;\n          throw new IllegalStateException(\"Invalid shuffle port number \"\n              + port + \" returned for \" + taskAttemptID);\n        }\n\n        // after launching, send launched event to task attempt to move\n        // it from ASSIGNED to RUNNING state\n        context.getEventHandler().handle(\n            new TaskAttemptContainerLaunchedEvent(taskAttemptID, port));\n        this.state = ContainerState.RUNNING;\n      } catch (Throwable t) {\n        String message = \"Container launch failed for \" + containerID + \" : \"\n            + StringUtils.stringifyException(t);\n        this.state = ContainerState.FAILED;\n        sendContainerLaunchFailedMsg(taskAttemptID, message);\n      } finally {\n        if (proxy != null) {\n          ContainerLauncherImpl.this.rpc.stopProxy(proxy, getConfig());\n        }\n      }\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.run": {
                "code_before_change": "      public void run() {\n        ContainerLauncherEvent event = null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event = eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          int poolSize = launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven't reached the\n          // maximum limit yet.\n          if (poolSize != limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn't need to be.\n            int numNodes = allNodes.size();\n            int idealPoolSize = Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize < idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize = Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }",
                "code_after_change": "      public void run() {\n        ContainerLauncherEvent event = null;\n        while (!Thread.currentThread().isInterrupted()) {\n          try {\n            event = eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return;\n          }\n          int poolSize = launcherPool.getCorePoolSize();\n\n          // See if we need up the pool size only if haven't reached the\n          // maximum limit yet.\n          if (poolSize != limitOnPoolSize) {\n\n            // nodes where containers will run at *this* point of time. This is\n            // *not* the cluster size and doesn't need to be.\n            int numNodes = allNodes.size();\n            int idealPoolSize = Math.min(limitOnPoolSize, numNodes);\n\n            if (poolSize < idealPoolSize) {\n              // Bump up the pool size to idealPoolSize+INITIAL_POOL_SIZE, the\n              // later is just a buffer so we are not always increasing the\n              // pool-size\n              int newPoolSize = Math.min(limitOnPoolSize, idealPoolSize\n                  + INITIAL_POOL_SIZE);\n              LOG.info(\"Setting ContainerLauncher pool size to \" + newPoolSize\n                  + \" as number-of-nodes to talk to is \" + numNodes);\n              launcherPool.setCorePoolSize(newPoolSize);\n            }\n          }\n\n          // the events from the queue are handled in parallel\n          // using a thread pool\n          launcherPool.execute(createEventProcessor(event));\n\n          // TODO: Group launching of multiple containers to a single\n          // NodeManager into a single connection\n        }\n      }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the AM launcher thread waiting indefinitely due to lack of error handling and timeout mechanisms, which is related to the methods in the stack trace but not the exact ground truth methods. The fix suggestion involves adding a timeout and retry mechanism, which is an alternative approach to the developer's fix that involved changes in the ContainerLauncherImpl methods. The problem location mentions methods in the stack trace, which are related but not the exact ground truth methods. There is no wrong information as the report accurately describes the issue and provides a plausible solution."
        }
    },
    {
        "filename": "MAPREDUCE-3066.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.NodeStatusUpdaterImpl": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as an improperly configured 'yarn.resourcemanager.resource-tracker.address', which leads to a failure in creating a socket address in the NetUtils.createSocketAddr method. This is related to the ground truth method NodeStatusUpdaterImpl, but it points to the method where the error occurred, not where the actual fix was made, hence 'Partial' with 'Buggy Method'. The fix suggestion is preventive as it suggests correcting the configuration to prevent the error. The problem location identification is also 'Partial' with 'Buggy Method' because it mentions NodeStatusUpdaterImpl.start, which is related to the error but not the exact method where the fix was applied. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3123.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.symlink": {
                "code_before_change": "    public ShellScriptBuilder symlink(Path src, String dst) throws IOException {\n      return symlink(src, new Path(dst));\n    }",
                "code_after_change": "    public ShellScriptBuilder symlink(Path src, String dst) throws IOException {\n      return symlink(src, new Path(dst));\n    }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.sanitizeEnv": {
                "code_before_change": "  public void sanitizeEnv(Map<String, String> environment, \n      Path pwd, List<Path> appDirs) {\n    /**\n     * Non-modifiable environment variables\n     */\n    \n    putEnvIfNotNull(environment, Environment.USER.name(), container.getUser());\n    \n    putEnvIfNotNull(environment, \n        Environment.LOGNAME.name(),container.getUser());\n    \n    putEnvIfNotNull(environment, \n        Environment.HOME.name(),\n        conf.get(\n            YarnConfiguration.NM_USER_HOME_DIR, \n            YarnConfiguration.DEFAULT_NM_USER_HOME_DIR\n            )\n        );\n    \n    putEnvIfNotNull(environment, Environment.PWD.name(), pwd.toString());\n    \n    putEnvIfNotNull(environment, \n        Environment.HADOOP_CONF_DIR.name(), \n        System.getenv(Environment.HADOOP_CONF_DIR.name())\n        );\n    \n    putEnvIfNotNull(environment, \n        ApplicationConstants.LOCAL_DIR_ENV, \n        StringUtils.join(\",\", appDirs)\n        );\n\n    if (!Shell.WINDOWS) {\n      environment.put(\"JVM_PID\", \"$$\");\n    }\n\n    /**\n     * Modifiable environment variables\n     */\n    \n    putEnvIfAbsent(environment, Environment.JAVA_HOME.name());\n    putEnvIfAbsent(environment, Environment.HADOOP_COMMON_HOME.name());\n    putEnvIfAbsent(environment, Environment.HADOOP_HDFS_HOME.name());\n    putEnvIfAbsent(environment, Environment.YARN_HOME.name());\n\n  }",
                "code_after_change": "  public void sanitizeEnv(Map<String, String> environment, \n      Path pwd, List<Path> appDirs) {\n    /**\n     * Non-modifiable environment variables\n     */\n    \n    putEnvIfNotNull(environment, Environment.USER.name(), container.getUser());\n    \n    putEnvIfNotNull(environment, \n        Environment.LOGNAME.name(),container.getUser());\n    \n    putEnvIfNotNull(environment, \n        Environment.HOME.name(),\n        conf.get(\n            YarnConfiguration.NM_USER_HOME_DIR, \n            YarnConfiguration.DEFAULT_NM_USER_HOME_DIR\n            )\n        );\n    \n    putEnvIfNotNull(environment, Environment.PWD.name(), pwd.toString());\n    \n    putEnvIfNotNull(environment, \n        Environment.HADOOP_CONF_DIR.name(), \n        System.getenv(Environment.HADOOP_CONF_DIR.name())\n        );\n    \n    putEnvIfNotNull(environment, \n        ApplicationConstants.LOCAL_DIR_ENV, \n        StringUtils.join(\",\", appDirs)\n        );\n\n    if (!Shell.WINDOWS) {\n      environment.put(\"JVM_PID\", \"$$\");\n    }\n\n    /**\n     * Modifiable environment variables\n     */\n    \n    putEnvIfAbsent(environment, Environment.JAVA_HOME.name());\n    putEnvIfAbsent(environment, Environment.HADOOP_COMMON_HOME.name());\n    putEnvIfAbsent(environment, Environment.HADOOP_HDFS_HOME.name());\n    putEnvIfAbsent(environment, Environment.YARN_HOME.name());\n\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the presence of special characters in symbolic link names causing a syntax error in the shell command executed in task.sh. This is related to the ground truth methods as they deal with environment sanitization and symlink creation, but the report does not precisely identify these methods. The fix suggestion to sanitize symbolic link names or modify the shell command to handle special characters is preventive, as it would mitigate the issue. The problem location mentions methods like Shell.runCommand and LinuxContainerExecutor.launchContainer, which are in the shared stack trace context with the ground truth methods. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6439.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources": {
                "code_before_change": "  private List<Container> getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom =\n        getAvailableResources() == null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response = makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime = System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new YarnRuntimeException(\n        \"Resource Manager doesn't recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID = 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime >= retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom =\n        getAvailableResources() == null ? Resources.none()\n            : getAvailableResources();\n    List<Container> newContainers = response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() != null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() != null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List<ContainerStatus> finishedContainers = response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq = response.getPreemptionMessage();\n    if (preemptReq != null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() > 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule = true;\n      if (LOG.isDebugEnabled() && !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom=\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID = assignedRequests.get(cont.getContainerId());\n      if (attemptID == null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics = StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
                "code_after_change": "  private List<Container> getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom =\n        getAvailableResources() == null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response = makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime = System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn't recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID = 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime >= retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom =\n        getAvailableResources() == null ? Resources.none()\n            : getAvailableResources();\n    List<Container> newContainers = response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() != null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() != null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List<ContainerStatus> finishedContainers = response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() > 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule = true;\n      if (LOG.isDebugEnabled() && !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom=\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID = assignedRequests.get(cont.getContainerId());\n      if (attemptID == null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics = StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStop": {
                "code_before_change": "  protected void serviceStop() throws Exception {\n    if (stopped.getAndSet(true)) {\n      // return if already stopped\n      return;\n    }\n    if (allocatorThread != null) {\n      allocatorThread.interrupt();\n      try {\n        allocatorThread.join();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"InterruptedException while stopping\", ie);\n      }\n    }\n    if (isApplicationMasterRegistered && shouldUnregister) {\n      unregister();\n    }\n    super.serviceStop();\n  }",
                "code_after_change": "  protected void serviceStop() throws Exception {\n    if (stopped.getAndSet(true)) {\n      // return if already stopped\n      return;\n    }\n    if (allocatorThread != null) {\n      allocatorThread.interrupt();\n      try {\n        allocatorThread.join();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"InterruptedException while stopping\", ie);\n      }\n    }\n    if (isApplicationMasterRegistered && shouldUnregister) {\n      unregister();\n    }\n    super.serviceStop();\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as improper handling of InterruptedExceptions during communication between the Application Master and Resource Manager. This is related to the ground truth methods as they are involved in resource management and communication, but the exact root cause is not identified in the ground truth methods. The fix suggestion is preventive as it suggests implementing better exception handling to manage InterruptedExceptions, which would mitigate the issue. The problem location identification is partial because the methods mentioned in the problem_location field are part of the stack trace context but do not directly match the ground truth methods. There is no wrong information in the bug report as all statements are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4490.json",
        "code_diff": {
            "src.mapred.org.apache.hadoop.mapred.LinuxTaskController.launchTask": {
                "code_before_change": [],
                "code_after_change": "  public int launchTask(String user, \n                                  String jobId,\n                                  String attemptId,\n                                  List<String> setup,\n                                  List<String> jvmArguments,\n                                  File currentWorkDirectory,\n                                  String stdout,\n                                  String stderr) throws IOException {\n\n    ShellCommandExecutor shExec = null;\n    try {\n      FileSystem rawFs = FileSystem.getLocal(getConf()).getRaw();\n      long logSize = 0; //TODO MAPREDUCE-1100\n      // get the JVM command line.\n      String cmdLine = \n        TaskLog.buildCommandLine(setup, jvmArguments,\n            new File(stdout), new File(stderr), logSize, true);\n\n      // write the command to a file in the\n      // task specific cache directory\n      Path p = new Path(allocator.getLocalPathForWrite(\n          TaskTracker.getPrivateDirTaskScriptLocation(user, jobId, attemptId),\n          getConf()), COMMAND_FILE);\n      String commandFile = writeCommand(cmdLine, rawFs, p); \n\n      String[] command = \n        new String[]{taskControllerExe, \n          user,\n          localStorage.getDirsString(),\n          Integer.toString(Commands.LAUNCH_TASK_JVM.getValue()),\n          jobId,\n          attemptId,\n          currentWorkDirectory.toString(),\n          commandFile};\n      shExec = new ShellCommandExecutor(command);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"launchTask: \" + Arrays.toString(command));\n      }\n      shExec.execute();\n    } catch (Exception e) {\n      if (shExec == null) {\n        return -1;\n      }\n      int exitCode = shExec.getExitCode();\n      LOG.warn(\"Exit code from task is : \" + exitCode);\n      // 143 (SIGTERM) and 137 (SIGKILL) exit codes means the task was\n      // terminated/killed forcefully. In all other cases, log the\n      // task-controller output\n      if (exitCode != 143 && exitCode != 137) {\n        LOG.warn(\"Exception thrown while launching task JVM : \"\n            + StringUtils.stringifyException(e));\n        LOG.info(\"Output from LinuxTaskController's launchTaskJVM follows:\");\n        logOutput(shExec.getOutput());\n      }\n      return exitCode;\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Output from LinuxTaskController's launchTask follows:\");\n      logOutput(shExec.getOutput());\n    }\n    return 0;\n  }"
            },
            "src.mapred.org.apache.hadoop.mapred.LinuxTaskController.initializeJob": {
                "code_before_change": [],
                "code_after_change": "  public void initializeJob(String user, String jobid, Path credentials,\n                            Path jobConf, TaskUmbilicalProtocol taskTracker,\n                            InetSocketAddress ttAddr\n                            ) throws IOException {\n    jobUserMap.put(jobid, user);\n\n    List<String> command = new ArrayList<String>(\n      Arrays.asList(taskControllerExe, \n                    user,\n                    localStorage.getDirsString(),\n                    Integer.toString(Commands.INITIALIZE_JOB.getValue()),\n                    jobid,\n                    credentials.toUri().getPath().toString(),\n                    jobConf.toUri().getPath().toString()));\n    File jvm =                                  // use same jvm as parent\n      new File(new File(System.getProperty(\"java.home\"), \"bin\"), \"java\");\n    command.add(jvm.toString());\n    command.add(\"-classpath\");\n    command.add(System.getProperty(\"java.class.path\"));\n    command.add(\"-Dhadoop.log.dir=\" + TaskLog.getBaseLogDir());\n    command.add(\"-Dhadoop.root.logger=INFO,console\");\n    command.add(\"-Djava.library.path=\" +\n                System.getProperty(\"java.library.path\"));\n    command.add(JobLocalizer.class.getName());  // main of JobLocalizer\n    command.add(user);\n    command.add(jobid);\n    // add the task tracker's reporting address\n    command.add(ttAddr.getHostName());\n    command.add(Integer.toString(ttAddr.getPort()));\n    String[] commandArray = command.toArray(new String[0]);\n    ShellCommandExecutor shExec = new ShellCommandExecutor(commandArray);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"initializeJob: \" + Arrays.toString(commandArray));\n    }\n    try {\n      shExec.execute();\n      if (LOG.isDebugEnabled()) {\n        logOutput(shExec.getOutput());\n      }\n    } catch (ExitCodeException e) {\n      int exitCode = shExec.getExitCode();\n      logOutput(shExec.getOutput());\n      throw new IOException(\"Job initialization failed (\" + exitCode + \n          \") with output: \" + shExec.getOutput(), e);\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the LinuxTaskController not creating userlog directories for each task, which is related to the issue but not the exact root cause in the ground truth methods. The report suggests modifying the LinuxTaskController#createLogDir method, which is an alternative fix to the actual changes made in the ground truth methods. The problem location mentions methods like TaskLog.writeToIndexFile and SecureIOUtils.createForWrite, which are involved in the error but not where the fix was applied, thus categorized as 'Buggy Method'. There is no wrong information as the report accurately describes the problem context and behavior."
        }
    },
    {
        "filename": "MAPREDUCE-3744.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.LogDumper.dumpAContainerLogs": {
                "code_before_change": "  private int dumpAContainerLogs(String containerIdStr,\n      AggregatedLogFormat.LogReader reader, DataOutputStream out)\n      throws IOException {\n    DataInputStream valueStream;\n    LogKey key = new LogKey();\n    valueStream = reader.next(key);\n\n    while (valueStream != null && !key.toString().equals(containerIdStr)) {\n      // Next container\n      key = new LogKey();\n      valueStream = reader.next(key);\n    }\n\n    if (valueStream == null) {\n      System.out.println(\"Logs for container \" + containerIdStr\n          + \" are not present in this log-file.\");\n      return -1;\n    }\n\n    while (true) {\n      try {\n        LogReader.readAContainerLogsForALogType(valueStream, out);\n      } catch (EOFException eof) {\n        break;\n      }\n    }\n    return 0;\n  }",
                "code_after_change": "  private int dumpAContainerLogs(String containerIdStr,\n      AggregatedLogFormat.LogReader reader, DataOutputStream out)\n      throws IOException {\n    DataInputStream valueStream;\n    LogKey key = new LogKey();\n    valueStream = reader.next(key);\n\n    while (valueStream != null && !key.toString().equals(containerIdStr)) {\n      // Next container\n      key = new LogKey();\n      valueStream = reader.next(key);\n    }\n\n    if (valueStream == null) {\n      System.out.println(\"Logs for container \" + containerIdStr\n          + \" are not present in this log-file.\");\n      return -1;\n    }\n\n    while (true) {\n      try {\n        LogReader.readAContainerLogsForALogType(valueStream, out);\n      } catch (EOFException eof) {\n        break;\n      }\n    }\n    return 0;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.LogDumper.run": {
                "code_before_change": "  public int run(String[] args) throws Exception {\n\n    Options opts = new Options();\n    opts.addOption(APPLICATION_ID_OPTION, true, \"ApplicationId\");\n    opts.addOption(CONTAINER_ID_OPTION, true, \"ContainerId\");\n    opts.addOption(NODE_ADDRESS_OPTION, true, \"NodeAddress\");\n    opts.addOption(APP_OWNER_OPTION, true, \"AppOwner\");\n\n    if (args.length < 1) {\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      return -1;\n    }\n\n    CommandLineParser parser = new GnuParser();\n    String appIdStr = null;\n    String containerIdStr = null;\n    String nodeAddress = null;\n    String appOwner = null;\n    try {\n      CommandLine commandLine = parser.parse(opts, args, true);\n      appIdStr = commandLine.getOptionValue(APPLICATION_ID_OPTION);\n      containerIdStr = commandLine.getOptionValue(CONTAINER_ID_OPTION);\n      nodeAddress = commandLine.getOptionValue(NODE_ADDRESS_OPTION);\n      appOwner = commandLine.getOptionValue(APP_OWNER_OPTION);\n    } catch (ParseException e) {\n      System.out.println(\"options parsing failed: \" + e.getMessage());\n\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      return -1;\n    }\n\n    if (appIdStr == null) {\n      System.out.println(\"ApplicationId cannot be null!\");\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      return -1;\n    }\n\n    RecordFactory recordFactory =\n        RecordFactoryProvider.getRecordFactory(getConf());\n    ApplicationId appId =\n        ConverterUtils.toApplicationId(recordFactory, appIdStr);\n\n    DataOutputStream out = new DataOutputStream(System.out);\n\n    if (appOwner == null || appOwner.isEmpty()) {\n      appOwner = UserGroupInformation.getCurrentUser().getShortUserName();\n    }\n    if (containerIdStr == null && nodeAddress == null) {\n      dumpAllContainersLogs(appId, appOwner, out);\n    } else if ((containerIdStr == null && nodeAddress != null)\n        || (containerIdStr != null && nodeAddress == null)) {\n      System.out.println(\"ContainerId or NodeAddress cannot be null!\");\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      return -1;\n    } else {\n      Path remoteRootLogDir =\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n      AggregatedLogFormat.LogReader reader =\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationUtils.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir,\n                  appId,\n                  appOwner,\n                  ConverterUtils.toNodeId(nodeAddress),\n                  getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_SUFFIX,\n                      YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX)));\n      return dumpAContainerLogs(containerIdStr, reader, out);\n    }\n\n    return 0;\n  }",
                "code_after_change": "  public int run(String[] args) throws Exception {\n\n    Options opts = new Options();\n    opts.addOption(APPLICATION_ID_OPTION, true, \"ApplicationId\");\n    opts.addOption(CONTAINER_ID_OPTION, true, \"ContainerId\");\n    opts.addOption(NODE_ADDRESS_OPTION, true, \"NodeAddress\");\n    opts.addOption(APP_OWNER_OPTION, true, \"AppOwner\");\n\n    if (args.length < 1) {\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      return -1;\n    }\n\n    CommandLineParser parser = new GnuParser();\n    String appIdStr = null;\n    String containerIdStr = null;\n    String nodeAddress = null;\n    String appOwner = null;\n    try {\n      CommandLine commandLine = parser.parse(opts, args, true);\n      appIdStr = commandLine.getOptionValue(APPLICATION_ID_OPTION);\n      containerIdStr = commandLine.getOptionValue(CONTAINER_ID_OPTION);\n      nodeAddress = commandLine.getOptionValue(NODE_ADDRESS_OPTION);\n      appOwner = commandLine.getOptionValue(APP_OWNER_OPTION);\n    } catch (ParseException e) {\n      System.out.println(\"options parsing failed: \" + e.getMessage());\n\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      return -1;\n    }\n\n    if (appIdStr == null) {\n      System.out.println(\"ApplicationId cannot be null!\");\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      return -1;\n    }\n\n    RecordFactory recordFactory =\n        RecordFactoryProvider.getRecordFactory(getConf());\n    ApplicationId appId =\n        ConverterUtils.toApplicationId(recordFactory, appIdStr);\n\n    DataOutputStream out = new DataOutputStream(System.out);\n\n    if (appOwner == null || appOwner.isEmpty()) {\n      appOwner = UserGroupInformation.getCurrentUser().getShortUserName();\n    }\n    int resultCode = 0;\n    if (containerIdStr == null && nodeAddress == null) {\n      resultCode = dumpAllContainersLogs(appId, appOwner, out);\n    } else if ((containerIdStr == null && nodeAddress != null)\n        || (containerIdStr != null && nodeAddress == null)) {\n      System.out.println(\"ContainerId or NodeAddress cannot be null!\");\n      HelpFormatter formatter = new HelpFormatter();\n      formatter.printHelp(\"general options are: \", opts);\n      resultCode = -1;\n    } else {\n      Path remoteRootLogDir =\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n      AggregatedLogFormat.LogReader reader =\n          new AggregatedLogFormat.LogReader(getConf(),\n              LogAggregationUtils.getRemoteNodeLogFileForApp(\n                  remoteRootLogDir,\n                  appId,\n                  appOwner,\n                  ConverterUtils.toNodeId(nodeAddress),\n                  LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf())));\n      resultCode = dumpAContainerLogs(containerIdStr, reader, out);\n    }\n\n    return resultCode;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.tools.CLI.run": {
                "code_before_change": "  public int run(String[] argv) throws Exception {\n    int exitCode = -1;\n    if (argv.length < 1) {\n      displayUsage(\"\");\n      return exitCode;\n    }    \n    // process arguments\n    String cmd = argv[0];\n    String submitJobFile = null;\n    String jobid = null;\n    String taskid = null;\n    String historyFile = null;\n    String counterGroupName = null;\n    String counterName = null;\n    JobPriority jp = null;\n    String taskType = null;\n    String taskState = null;\n    int fromEvent = 0;\n    int nEvents = 0;\n    boolean getStatus = false;\n    boolean getCounter = false;\n    boolean killJob = false;\n    boolean listEvents = false;\n    boolean viewHistory = false;\n    boolean viewAllHistory = false;\n    boolean listJobs = false;\n    boolean listAllJobs = false;\n    boolean listActiveTrackers = false;\n    boolean listBlacklistedTrackers = false;\n    boolean displayTasks = false;\n    boolean killTask = false;\n    boolean failTask = false;\n    boolean setJobPriority = false;\n    boolean logs = false;\n\n    if (\"-submit\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      submitJobFile = argv[1];\n    } else if (\"-status\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      getStatus = true;\n    } else if(\"-counter\".equals(cmd)) {\n      if (argv.length != 4) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      getCounter = true;\n      jobid = argv[1];\n      counterGroupName = argv[2];\n      counterName = argv[3];\n    } else if (\"-kill\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      killJob = true;\n    } else if (\"-set-priority\".equals(cmd)) {\n      if (argv.length != 3) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      try {\n        jp = JobPriority.valueOf(argv[2]); \n      } catch (IllegalArgumentException iae) {\n        LOG.info(iae);\n        displayUsage(cmd);\n        return exitCode;\n      }\n      setJobPriority = true; \n    } else if (\"-events\".equals(cmd)) {\n      if (argv.length != 4) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      fromEvent = Integer.parseInt(argv[2]);\n      nEvents = Integer.parseInt(argv[3]);\n      listEvents = true;\n    } else if (\"-history\".equals(cmd)) {\n      if (argv.length != 2 && !(argv.length == 3 && \"all\".equals(argv[1]))) {\n         displayUsage(cmd);\n         return exitCode;\n      }\n      viewHistory = true;\n      if (argv.length == 3 && \"all\".equals(argv[1])) {\n        viewAllHistory = true;\n        historyFile = argv[2];\n      } else {\n        historyFile = argv[1];\n      }\n    } else if (\"-list\".equals(cmd)) {\n      if (argv.length != 1 && !(argv.length == 2 && \"all\".equals(argv[1]))) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      if (argv.length == 2 && \"all\".equals(argv[1])) {\n        listAllJobs = true;\n      } else {\n        listJobs = true;\n      }\n    } else if(\"-kill-task\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      killTask = true;\n      taskid = argv[1];\n    } else if(\"-fail-task\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      failTask = true;\n      taskid = argv[1];\n    } else if (\"-list-active-trackers\".equals(cmd)) {\n      if (argv.length != 1) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      listActiveTrackers = true;\n    } else if (\"-list-blacklisted-trackers\".equals(cmd)) {\n      if (argv.length != 1) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      listBlacklistedTrackers = true;\n    } else if (\"-list-attempt-ids\".equals(cmd)) {\n      if (argv.length != 4) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      taskType = argv[2];\n      taskState = argv[3];\n      displayTasks = true;\n    } else if (\"-logs\".equals(cmd)) {\n      if (argv.length == 2 || argv.length ==3) {\n        logs = true;\n        jobid = argv[1];\n        if (argv.length == 3) {\n          taskid = argv[2];\n        }  else {\n          taskid = null;\n        }\n      } else {\n        displayUsage(cmd);\n        return exitCode;\n      }\n    } else {\n      displayUsage(cmd);\n      return exitCode;\n    }\n\n    // initialize cluster\n    cluster = new Cluster(getConf());\n        \n    // Submit the request\n    try {\n      if (submitJobFile != null) {\n        Job job = Job.getInstance(new JobConf(submitJobFile));\n        job.submit();\n        System.out.println(\"Created job \" + job.getJobID());\n        exitCode = 0;\n      } else if (getStatus) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          Counters counters = job.getCounters();\n          System.out.println();\n          System.out.println(job);\n          if (counters != null) {\n            System.out.println(counters);\n          } else {\n            System.out.println(\"Counters not available. Job is retired.\");\n          }\n          exitCode = 0;\n        }\n      } else if (getCounter) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          Counters counters = job.getCounters();\n          if (counters == null) {\n            System.out.println(\"Counters not available for retired job \" + \n            jobid);\n            exitCode = -1;\n          } else {\n            System.out.println(getCounter(counters,\n              counterGroupName, counterName));\n            exitCode = 0;\n          }\n        }\n      } else if (killJob) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          job.killJob();\n          System.out.println(\"Killed job \" + jobid);\n          exitCode = 0;\n        }\n      } else if (setJobPriority) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          job.setPriority(jp);\n          System.out.println(\"Changed job priority.\");\n          exitCode = 0;\n        } \n      } else if (viewHistory) {\n        viewHistory(historyFile, viewAllHistory);\n        exitCode = 0;\n      } else if (listEvents) {\n        listEvents(cluster.getJob(JobID.forName(jobid)), fromEvent, nEvents);\n        exitCode = 0;\n      } else if (listJobs) {\n        listJobs(cluster);\n        exitCode = 0;\n      } else if (listAllJobs) {\n        listAllJobs(cluster);\n        exitCode = 0;\n      } else if (listActiveTrackers) {\n        listActiveTrackers(cluster);\n        exitCode = 0;\n      } else if (listBlacklistedTrackers) {\n        listBlacklistedTrackers(cluster);\n        exitCode = 0;\n      } else if (displayTasks) {\n        displayTasks(cluster.getJob(JobID.forName(jobid)), taskType, taskState);\n      } else if(killTask) {\n        TaskAttemptID taskID = TaskAttemptID.forName(taskid);\n        Job job = cluster.getJob(taskID.getJobID());\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else if (job.killTask(taskID)) {\n          System.out.println(\"Killed task \" + taskid);\n          exitCode = 0;\n        } else {\n          System.out.println(\"Could not kill task \" + taskid);\n          exitCode = -1;\n        }\n      } else if(failTask) {\n        TaskAttemptID taskID = TaskAttemptID.forName(taskid);\n        Job job = cluster.getJob(taskID.getJobID());\n        if (job == null) {\n            System.out.println(\"Could not find job \" + jobid);\n        } else if(job.failTask(taskID)) {\n          System.out.println(\"Killed task \" + taskID + \" by failing it\");\n          exitCode = 0;\n        } else {\n          System.out.println(\"Could not fail task \" + taskid);\n          exitCode = -1;\n        }\n      } else if (logs) {\n        try {\n        JobID jobID = JobID.forName(jobid);\n        TaskAttemptID taskAttemptID = TaskAttemptID.forName(taskid);\n        LogParams logParams = cluster.getLogParams(jobID, taskAttemptID);\n        LogDumper logDumper = new LogDumper();\n        logDumper.setConf(getConf());\n        logDumper.dumpAContainersLogs(logParams.getApplicationId(),\n            logParams.getContainerId(), logParams.getNodeId(),\n            logParams.getOwner());\n        } catch (IOException e) {\n          if (e instanceof RemoteException) {\n            throw e;\n          } \n          System.out.println(e.getMessage());\n        }\n      }\n    } catch (RemoteException re) {\n      IOException unwrappedException = re.unwrapRemoteException();\n      if (unwrappedException instanceof AccessControlException) {\n        System.out.println(unwrappedException.getMessage());\n      } else {\n        throw re;\n      }\n    } finally {\n      cluster.close();\n    }\n    return exitCode;\n  }",
                "code_after_change": "  public int run(String[] argv) throws Exception {\n    int exitCode = -1;\n    if (argv.length < 1) {\n      displayUsage(\"\");\n      return exitCode;\n    }    \n    // process arguments\n    String cmd = argv[0];\n    String submitJobFile = null;\n    String jobid = null;\n    String taskid = null;\n    String historyFile = null;\n    String counterGroupName = null;\n    String counterName = null;\n    JobPriority jp = null;\n    String taskType = null;\n    String taskState = null;\n    int fromEvent = 0;\n    int nEvents = 0;\n    boolean getStatus = false;\n    boolean getCounter = false;\n    boolean killJob = false;\n    boolean listEvents = false;\n    boolean viewHistory = false;\n    boolean viewAllHistory = false;\n    boolean listJobs = false;\n    boolean listAllJobs = false;\n    boolean listActiveTrackers = false;\n    boolean listBlacklistedTrackers = false;\n    boolean displayTasks = false;\n    boolean killTask = false;\n    boolean failTask = false;\n    boolean setJobPriority = false;\n    boolean logs = false;\n\n    if (\"-submit\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      submitJobFile = argv[1];\n    } else if (\"-status\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      getStatus = true;\n    } else if(\"-counter\".equals(cmd)) {\n      if (argv.length != 4) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      getCounter = true;\n      jobid = argv[1];\n      counterGroupName = argv[2];\n      counterName = argv[3];\n    } else if (\"-kill\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      killJob = true;\n    } else if (\"-set-priority\".equals(cmd)) {\n      if (argv.length != 3) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      try {\n        jp = JobPriority.valueOf(argv[2]); \n      } catch (IllegalArgumentException iae) {\n        LOG.info(iae);\n        displayUsage(cmd);\n        return exitCode;\n      }\n      setJobPriority = true; \n    } else if (\"-events\".equals(cmd)) {\n      if (argv.length != 4) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      fromEvent = Integer.parseInt(argv[2]);\n      nEvents = Integer.parseInt(argv[3]);\n      listEvents = true;\n    } else if (\"-history\".equals(cmd)) {\n      if (argv.length != 2 && !(argv.length == 3 && \"all\".equals(argv[1]))) {\n         displayUsage(cmd);\n         return exitCode;\n      }\n      viewHistory = true;\n      if (argv.length == 3 && \"all\".equals(argv[1])) {\n        viewAllHistory = true;\n        historyFile = argv[2];\n      } else {\n        historyFile = argv[1];\n      }\n    } else if (\"-list\".equals(cmd)) {\n      if (argv.length != 1 && !(argv.length == 2 && \"all\".equals(argv[1]))) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      if (argv.length == 2 && \"all\".equals(argv[1])) {\n        listAllJobs = true;\n      } else {\n        listJobs = true;\n      }\n    } else if(\"-kill-task\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      killTask = true;\n      taskid = argv[1];\n    } else if(\"-fail-task\".equals(cmd)) {\n      if (argv.length != 2) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      failTask = true;\n      taskid = argv[1];\n    } else if (\"-list-active-trackers\".equals(cmd)) {\n      if (argv.length != 1) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      listActiveTrackers = true;\n    } else if (\"-list-blacklisted-trackers\".equals(cmd)) {\n      if (argv.length != 1) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      listBlacklistedTrackers = true;\n    } else if (\"-list-attempt-ids\".equals(cmd)) {\n      if (argv.length != 4) {\n        displayUsage(cmd);\n        return exitCode;\n      }\n      jobid = argv[1];\n      taskType = argv[2];\n      taskState = argv[3];\n      displayTasks = true;\n    } else if (\"-logs\".equals(cmd)) {\n      if (argv.length == 2 || argv.length ==3) {\n        logs = true;\n        jobid = argv[1];\n        if (argv.length == 3) {\n          taskid = argv[2];\n        }  else {\n          taskid = null;\n        }\n      } else {\n        displayUsage(cmd);\n        return exitCode;\n      }\n    } else {\n      displayUsage(cmd);\n      return exitCode;\n    }\n\n    // initialize cluster\n    cluster = new Cluster(getConf());\n        \n    // Submit the request\n    try {\n      if (submitJobFile != null) {\n        Job job = Job.getInstance(new JobConf(submitJobFile));\n        job.submit();\n        System.out.println(\"Created job \" + job.getJobID());\n        exitCode = 0;\n      } else if (getStatus) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          Counters counters = job.getCounters();\n          System.out.println();\n          System.out.println(job);\n          if (counters != null) {\n            System.out.println(counters);\n          } else {\n            System.out.println(\"Counters not available. Job is retired.\");\n          }\n          exitCode = 0;\n        }\n      } else if (getCounter) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          Counters counters = job.getCounters();\n          if (counters == null) {\n            System.out.println(\"Counters not available for retired job \" + \n            jobid);\n            exitCode = -1;\n          } else {\n            System.out.println(getCounter(counters,\n              counterGroupName, counterName));\n            exitCode = 0;\n          }\n        }\n      } else if (killJob) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          job.killJob();\n          System.out.println(\"Killed job \" + jobid);\n          exitCode = 0;\n        }\n      } else if (setJobPriority) {\n        Job job = cluster.getJob(JobID.forName(jobid));\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else {\n          job.setPriority(jp);\n          System.out.println(\"Changed job priority.\");\n          exitCode = 0;\n        } \n      } else if (viewHistory) {\n        viewHistory(historyFile, viewAllHistory);\n        exitCode = 0;\n      } else if (listEvents) {\n        listEvents(cluster.getJob(JobID.forName(jobid)), fromEvent, nEvents);\n        exitCode = 0;\n      } else if (listJobs) {\n        listJobs(cluster);\n        exitCode = 0;\n      } else if (listAllJobs) {\n        listAllJobs(cluster);\n        exitCode = 0;\n      } else if (listActiveTrackers) {\n        listActiveTrackers(cluster);\n        exitCode = 0;\n      } else if (listBlacklistedTrackers) {\n        listBlacklistedTrackers(cluster);\n        exitCode = 0;\n      } else if (displayTasks) {\n        displayTasks(cluster.getJob(JobID.forName(jobid)), taskType, taskState);\n      } else if(killTask) {\n        TaskAttemptID taskID = TaskAttemptID.forName(taskid);\n        Job job = cluster.getJob(taskID.getJobID());\n        if (job == null) {\n          System.out.println(\"Could not find job \" + jobid);\n        } else if (job.killTask(taskID)) {\n          System.out.println(\"Killed task \" + taskid);\n          exitCode = 0;\n        } else {\n          System.out.println(\"Could not kill task \" + taskid);\n          exitCode = -1;\n        }\n      } else if(failTask) {\n        TaskAttemptID taskID = TaskAttemptID.forName(taskid);\n        Job job = cluster.getJob(taskID.getJobID());\n        if (job == null) {\n            System.out.println(\"Could not find job \" + jobid);\n        } else if(job.failTask(taskID)) {\n          System.out.println(\"Killed task \" + taskID + \" by failing it\");\n          exitCode = 0;\n        } else {\n          System.out.println(\"Could not fail task \" + taskid);\n          exitCode = -1;\n        }\n      } else if (logs) {\n        try {\n        JobID jobID = JobID.forName(jobid);\n        TaskAttemptID taskAttemptID = TaskAttemptID.forName(taskid);\n        LogParams logParams = cluster.getLogParams(jobID, taskAttemptID);\n        LogDumper logDumper = new LogDumper();\n        logDumper.setConf(getConf());\n        exitCode = logDumper.dumpAContainersLogs(logParams.getApplicationId(),\n            logParams.getContainerId(), logParams.getNodeId(),\n            logParams.getOwner());\n        } catch (IOException e) {\n          if (e instanceof RemoteException) {\n            throw e;\n          } \n          System.out.println(e.getMessage());\n        }\n      }\n    } catch (RemoteException re) {\n      IOException unwrappedException = re.unwrapRemoteException();\n      if (unwrappedException instanceof AccessControlException) {\n        System.out.println(unwrappedException.getMessage());\n      } else {\n        throw re;\n      }\n    } finally {\n      cluster.close();\n    }\n    return exitCode;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.LogDumper.dumpAllContainersLogs": {
                "code_before_change": "  private void dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir =\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user = appOwner;\n    String logDirSuffix =\n        getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX);\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir =\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator<FileStatus> nodeFiles =\n        FileContext.getFileContext().listStatus(remoteAppLogDir);\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile = nodeFiles.next();\n      AggregatedLogFormat.LogReader reader =\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key = new LogKey();\n        valueStream = reader.next(key);\n\n        while (valueStream != null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key = new LogKey();\n          valueStream = reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n  }",
                "code_after_change": "  private int dumpAllContainersLogs(ApplicationId appId, String appOwner,\n      DataOutputStream out) throws IOException {\n    Path remoteRootLogDir =\n        new Path(getConf().get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,\n            YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\n    String user = appOwner;\n    String logDirSuffix =\n        LogAggregationUtils.getRemoteNodeLogDirSuffix(getConf());\n    //TODO Change this to get a list of files from the LAS.\n    Path remoteAppLogDir =\n        LogAggregationUtils.getRemoteAppLogDir(remoteRootLogDir, appId, user,\n            logDirSuffix);\n    RemoteIterator<FileStatus> nodeFiles;\n    try {\n      nodeFiles = FileContext.getFileContext().listStatus(remoteAppLogDir);\n    } catch (FileNotFoundException fnf) {\n      System.out.println(\"Logs not available at \"\n          + remoteAppLogDir.toString());\n      System.out.println(\n          \"Log aggregation has not completed or is not enabled.\");\n      return -1;\n    }\n    while (nodeFiles.hasNext()) {\n      FileStatus thisNodeFile = nodeFiles.next();\n      AggregatedLogFormat.LogReader reader =\n          new AggregatedLogFormat.LogReader(getConf(),\n              new Path(remoteAppLogDir, thisNodeFile.getPath().getName()));\n      try {\n\n        DataInputStream valueStream;\n        LogKey key = new LogKey();\n        valueStream = reader.next(key);\n\n        while (valueStream != null) {\n          while (true) {\n            try {\n              LogReader.readAContainerLogsForALogType(valueStream, out);\n            } catch (EOFException eof) {\n              break;\n            }\n          }\n\n          // Next container\n          key = new LogKey();\n          valueStream = reader.next(key);\n        }\n      } finally {\n        reader.close();\n      }\n    }\n    return 0;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a misconfiguration or issue with log aggregation, which is related to the methods where the error occurred but not where the actual fix was made. This aligns with the 'Buggy Method' sub-category. The fix suggestion to check the configuration of log aggregation settings in YARN is preventive, as it aims to prevent the issue from occurring. The problem location identification is precise because the 'problem_location' field mentions 'LogDumper.dumpAllContainersLogs' and 'LogDumper.run', which are in the ground truth list. There is no wrong information in the bug report as all statements are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3053.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine.call": {
                "code_before_change": "  public Object[] call(Method method, Object[][] params,\n      InetSocketAddress[] addrs, UserGroupInformation ticket, Configuration conf)\n      throws IOException, InterruptedException {\n    throw new UnsupportedOperationException();\n  }",
                "code_after_change": "  public Object[] call(Method method, Object[][] params,\n      InetSocketAddress[] addrs, UserGroupInformation ticket, Configuration conf)\n      throws IOException, InterruptedException {\n    throw new UnsupportedOperationException();\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl.transition": {
                "code_before_change": "    public void transition(RMNodeImpl rmNode, RMNodeEvent event) {\n      rmNode.finishedApplications.add(((\n          RMNodeCleanAppEvent) event).getAppId());\n    }",
                "code_after_change": "    public void transition(RMNodeImpl rmNode, RMNodeEvent event) {\n      rmNode.finishedApplications.add(((\n          RMNodeCleanAppEvent) event).getAppId());\n    }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl.getNodeHealthStatus": {
                "code_before_change": "  public NodeHealthStatus getNodeHealthStatus() {\n    this.readLock.lock();\n\n    try {\n      return this.nodeHealthStatus;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
                "code_after_change": "  public NodeHealthStatus getNodeHealthStatus() {\n    this.readLock.lock();\n\n    try {\n      return this.nodeHealthStatus;\n    } finally {\n      this.readLock.unlock();\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl.RMNodeImpl": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies a NullPointerException during the registration process, which is related to the ground truth methods as they are part of the stack trace context. However, it does not precisely identify the root cause in the ground truth methods. The fix suggestion is preventive as it suggests setting valid values for parameters, which would prevent the error. The problem location is partially identified as it mentions methods in the stack trace context but not the exact ground truth methods. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5884.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.cancelDelegationToken": {
                "code_before_change": "    public CancelDelegationTokenResponse cancelDelegationToken(\n        CancelDelegationTokenRequest request) throws IOException {\n        if (!isAllowedDelegationTokenOp()) {\n          throw new IOException(\n              \"Delegation Token can be cancelled only with kerberos authentication\");\n        }\n\n        org.apache.hadoop.yarn.api.records.Token protoToken = request.getDelegationToken();\n        Token<MRDelegationTokenIdentifier> token =\n            new Token<MRDelegationTokenIdentifier>(\n                protoToken.getIdentifier().array(), protoToken.getPassword()\n                    .array(), new Text(protoToken.getKind()), new Text(\n                    protoToken.getService()));\n\n        String user = UserGroupInformation.getCurrentUser().getShortUserName();\n        jhsDTSecretManager.cancelToken(token, user);\n        return Records.newRecord(CancelDelegationTokenResponse.class);\n    }",
                "code_after_change": "    public CancelDelegationTokenResponse cancelDelegationToken(\n        CancelDelegationTokenRequest request) throws IOException {\n        if (!isAllowedDelegationTokenOp()) {\n          throw new IOException(\n              \"Delegation Token can be cancelled only with kerberos authentication\");\n        }\n\n        org.apache.hadoop.yarn.api.records.Token protoToken = request.getDelegationToken();\n        Token<MRDelegationTokenIdentifier> token =\n            new Token<MRDelegationTokenIdentifier>(\n                protoToken.getIdentifier().array(), protoToken.getPassword()\n                    .array(), new Text(protoToken.getKind()), new Text(\n                    protoToken.getService()));\n\n        String user = UserGroupInformation.getCurrentUser().getUserName();\n        jhsDTSecretManager.cancelToken(token, user);\n        return Records.newRecord(CancelDelegationTokenResponse.class);\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Direct Caller/Callee"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Direct Caller/Callee"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as an inconsistency in the user name format used for authorization checks in the `cancelToken` method of `AbstractDelegationTokenSecretManager`, which is a direct callee of the ground truth method `HistoryClientService.cancelDelegationToken`. The fix suggestion in the bug report suggests modifying the authorization check to compare both the short name and the full principal name, which is an alternative fix to the developer's change of using `getUserName()` instead of `getShortUserName()`. The problem location mentions `AbstractDelegationTokenSecretManager.cancelToken`, which is a direct callee of the ground truth method. There is no wrong information in the bug report as all statements are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3706.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink": {
                "code_before_change": "  private static void proxyLink(HttpServletRequest req, \n      HttpServletResponse resp, URI link,Cookie c) throws IOException {\n    org.apache.commons.httpclient.URI uri = \n      new org.apache.commons.httpclient.URI(link.toString(), false);\n    HttpClient client = new HttpClient();\n    HttpMethod method = new GetMethod(uri.getEscapedURI());\n\n    @SuppressWarnings(\"unchecked\")\n    Enumeration<String> names = req.getHeaderNames();\n    while(names.hasMoreElements()) {\n      String name = names.nextElement();\n      if(passThroughHeaders.contains(name)) {\n        String value = req.getHeader(name);\n        LOG.debug(\"REQ HEADER: \"+name+\" : \"+value);\n        method.setRequestHeader(name, value);\n      }\n    }\n\n    String user = req.getRemoteUser();\n    if(user != null && !user.isEmpty()) {\n      method.setRequestHeader(\"Cookie\",PROXY_USER_COOKIE_NAME+\"=\"+\n          URLEncoder.encode(user, \"ASCII\"));\n    }\n    OutputStream out = resp.getOutputStream();\n    try {\n      resp.setStatus(client.executeMethod(method));\n      for(Header header : method.getResponseHeaders()) {\n        resp.setHeader(header.getName(), header.getValue());\n      }\n      if(c != null) {\n        resp.addCookie(c);\n      }\n      InputStream in = method.getResponseBodyAsStream();\n      if(in != null) {\n        IOUtils.copyBytes(in, out, 4096, true);\n      }\n    } finally {\n      method.releaseConnection();\n    }\n  }",
                "code_after_change": "  private static void proxyLink(HttpServletRequest req, \n      HttpServletResponse resp, URI link,Cookie c) throws IOException {\n    org.apache.commons.httpclient.URI uri = \n      new org.apache.commons.httpclient.URI(link.toString(), false);\n    HttpClientParams params = new HttpClientParams();\n    params.setCookiePolicy(CookiePolicy.BROWSER_COMPATIBILITY);\n    params.setBooleanParameter(HttpClientParams.ALLOW_CIRCULAR_REDIRECTS, true);\n    HttpClient client = new HttpClient(params);\n    HttpMethod method = new GetMethod(uri.getEscapedURI());\n\n    @SuppressWarnings(\"unchecked\")\n    Enumeration<String> names = req.getHeaderNames();\n    while(names.hasMoreElements()) {\n      String name = names.nextElement();\n      if(passThroughHeaders.contains(name)) {\n        String value = req.getHeader(name);\n        LOG.debug(\"REQ HEADER: \"+name+\" : \"+value);\n        method.setRequestHeader(name, value);\n      }\n    }\n\n    String user = req.getRemoteUser();\n    if(user != null && !user.isEmpty()) {\n      method.setRequestHeader(\"Cookie\",PROXY_USER_COOKIE_NAME+\"=\"+\n          URLEncoder.encode(user, \"ASCII\"));\n    }\n    OutputStream out = resp.getOutputStream();\n    try {\n      resp.setStatus(client.executeMethod(method));\n      for(Header header : method.getResponseHeaders()) {\n        resp.setHeader(header.getName(), header.getValue());\n      }\n      if(c != null) {\n        resp.addCookie(c);\n      }\n      InputStream in = method.getResponseBodyAsStream();\n      if(in != null) {\n        IOUtils.copyBytes(in, out, 4096, true);\n      }\n    } finally {\n      method.releaseConnection();\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as a circular redirect occurring in the 'proxyLink' method of the 'WebAppProxyServlet' class, which matches the ground truth method. The fix suggestion in the bug report involves adding a check to prevent circular redirects, which is an alternative fix to the developer's solution of allowing circular redirects by setting a parameter. The problem location is precisely identified as the 'proxyLink' method in the 'WebAppProxyServlet' class, which matches the ground truth. There is no wrong information in the bug report as all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3931.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-api.src.main.java.org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl.convertToProtoFormat": {
                "code_before_change": "  private LocalResourceTypeProto convertToProtoFormat(LocalResourceType e) {\n    return ProtoUtils.convertToProtoFormat(e);\n  }",
                "code_after_change": "  private LocalResourceTypeProto convertToProtoFormat(LocalResourceType e) {\n    return ProtoUtils.convertToProtoFormat(e);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-api.src.main.java.org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl.getResource": {
                "code_before_change": "  public URL getResource() {\n    LocalResourceProtoOrBuilder p = viaProto ? proto : builder;\n    if (this.url != null) {\n      return this.url;\n    }\n    if (!p.hasResource()) {\n      return null;\n    }\n    this.url = convertFromProtoFormat(p.getResource());\n    return this.url;\n  }",
                "code_after_change": "  public synchronized URL getResource() {\n    LocalResourceProtoOrBuilder p = viaProto ? proto : builder;\n    if (this.url != null) {\n      return this.url;\n    }\n    if (!p.hasResource()) {\n      return null;\n    }\n    this.url = convertFromProtoFormat(p.getResource());\n    return this.url;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-api.src.main.java.org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl.getVisibility": {
                "code_before_change": "  public LocalResourceVisibility getVisibility() {\n    LocalResourceProtoOrBuilder p = viaProto ? proto : builder;\n    if (!p.hasVisibility()) {\n      return null;\n    }\n    return convertFromProtoFormat(p.getVisibility());\n  }",
                "code_after_change": "  public synchronized LocalResourceVisibility getVisibility() {\n    LocalResourceProtoOrBuilder p = viaProto ? proto : builder;\n    if (!p.hasVisibility()) {\n      return null;\n    }\n    return convertFromProtoFormat(p.getVisibility());\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-api.src.main.java.org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl.LocalResourcePBImpl": {
                "code_before_change": [],
                "code_after_change": []
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-api.src.main.java.org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl.setType": {
                "code_before_change": "  public void setType(LocalResourceType type) {\n    maybeInitBuilder();\n    if (type == null) {\n      builder.clearType();\n      return;\n    }\n    builder.setType(convertToProtoFormat(type));\n  }",
                "code_after_change": "  public synchronized void setType(LocalResourceType type) {\n    maybeInitBuilder();\n    if (type == null) {\n      builder.clearType();\n      return;\n    }\n    builder.setType(convertToProtoFormat(type));\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-api.src.main.java.org.apache.hadoop.yarn.api.records.impl.pb.LocalResourcePBImpl.getType": {
                "code_before_change": "  public LocalResourceType getType() {\n    LocalResourceProtoOrBuilder p = viaProto ? proto : builder;\n    if (!p.hasType()) {\n      return null;\n    }\n    return convertFromProtoFormat(p.getType());\n  }",
                "code_after_change": "  public synchronized LocalResourceType getType() {\n    LocalResourceProtoOrBuilder p = viaProto ? proto : builder;\n    if (!p.hasType()) {\n      return null;\n    }\n    return convertFromProtoFormat(p.getType());\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a mismatch in timestamps during resource download, which is related to the stack trace context but not the exact ground truth methods. The fix suggestion is preventive, as it suggests checking timestamps before downloading, which would mitigate the issue. The problem location mentions methods in the stack trace context but not the exact ground truth methods. There is no wrong information in the bug report, as all details are relevant to the described issue."
        }
    },
    {
        "filename": "MAPREDUCE-4467.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.IndexCache.getIndexInformation": {
                "code_before_change": "  public IndexRecord getIndexInformation(String mapId, int reduce,\n                                         Path fileName, String expectedIndexOwner)\n    throws IOException {\n\n    IndexInformation info = cache.get(mapId);\n\n    if (info == null) {\n      info = readIndexFileToCache(fileName, mapId, expectedIndexOwner);\n    } else {\n      while (isUnderConstruction(info)) {\n        try {\n          // In case the entry is ready after the above check but\n          // before the following wait, we do timed wait.\n          info.wait(200);\n        } catch (InterruptedException e) {\n          throw new IOException(\"Interrupted waiting for construction\", e);\n        }\n      }\n      LOG.debug(\"IndexCache HIT: MapId \" + mapId + \" found\");\n    }\n\n    if (info.mapSpillRecord.size() == 0 ||\n        info.mapSpillRecord.size() <= reduce) {\n      throw new IOException(\"Invalid request \" +\n        \" Map Id = \" + mapId + \" Reducer = \" + reduce +\n        \" Index Info Length = \" + info.mapSpillRecord.size());\n    }\n    return info.mapSpillRecord.getIndex(reduce);\n  }",
                "code_after_change": "  public IndexRecord getIndexInformation(String mapId, int reduce,\n                                         Path fileName, String expectedIndexOwner)\n    throws IOException {\n\n    IndexInformation info = cache.get(mapId);\n\n    if (info == null) {\n      info = readIndexFileToCache(fileName, mapId, expectedIndexOwner);\n    } else {\n      synchronized(info) {\n        while (isUnderConstruction(info)) {\n          try {\n            info.wait();\n          } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted waiting for construction\", e);\n          }\n        }\n      }\n      LOG.debug(\"IndexCache HIT: MapId \" + mapId + \" found\");\n    }\n\n    if (info.mapSpillRecord.size() == 0 ||\n        info.mapSpillRecord.size() <= reduce) {\n      throw new IOException(\"Invalid request \" +\n        \" Map Id = \" + mapId + \" Reducer = \" + reduce +\n        \" Index Info Length = \" + info.mapSpillRecord.size());\n    }\n    return info.mapSpillRecord.getIndex(reduce);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.IndexCache.readIndexFileToCache": {
                "code_before_change": "  private IndexInformation readIndexFileToCache(Path indexFileName,\n                                                String mapId,\n                                                String expectedIndexOwner)\n    throws IOException {\n    IndexInformation info;\n    IndexInformation newInd = new IndexInformation();\n    if ((info = cache.putIfAbsent(mapId, newInd)) != null) {\n      while (isUnderConstruction(info)) {\n        try {\n          // In case the entry is ready after the above check but\n          // before the following wait, we do timed wait.\n          info.wait(200);\n        } catch (InterruptedException e) {\n          throw new IOException(\"Interrupted waiting for construction\", e);\n        }\n      }\n      LOG.debug(\"IndexCache HIT: MapId \" + mapId + \" found\");\n      return info;\n    }\n    LOG.debug(\"IndexCache MISS: MapId \" + mapId + \" not found\") ;\n    SpillRecord tmp = null;\n    try { \n      tmp = new SpillRecord(indexFileName, conf, expectedIndexOwner);\n    } catch (Throwable e) { \n      tmp = new SpillRecord(0);\n      cache.remove(mapId);\n      throw new IOException(\"Error Reading IndexFile\", e);\n    } finally { \n      synchronized (newInd) { \n        newInd.mapSpillRecord = tmp;\n        newInd.notifyAll();\n      } \n    } \n    queue.add(mapId);\n    \n    if (totalMemoryUsed.addAndGet(newInd.getSize()) > totalMemoryAllowed) {\n      freeIndexInformation();\n    }\n    return newInd;\n  }",
                "code_after_change": "  private IndexInformation readIndexFileToCache(Path indexFileName,\n                                                String mapId,\n                                                String expectedIndexOwner)\n    throws IOException {\n    IndexInformation info;\n    IndexInformation newInd = new IndexInformation();\n    if ((info = cache.putIfAbsent(mapId, newInd)) != null) {\n      synchronized(info) {\n        while (isUnderConstruction(info)) {\n          try {\n            info.wait();\n          } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted waiting for construction\", e);\n          }\n        }\n      }\n      LOG.debug(\"IndexCache HIT: MapId \" + mapId + \" found\");\n      return info;\n    }\n    LOG.debug(\"IndexCache MISS: MapId \" + mapId + \" not found\") ;\n    SpillRecord tmp = null;\n    try { \n      tmp = new SpillRecord(indexFileName, conf, expectedIndexOwner);\n    } catch (Throwable e) { \n      tmp = new SpillRecord(0);\n      cache.remove(mapId);\n      throw new IOException(\"Error Reading IndexFile\", e);\n    } finally { \n      synchronized (newInd) { \n        newInd.mapSpillRecord = tmp;\n        newInd.notifyAll();\n      } \n    } \n    queue.add(mapId);\n    \n    if (totalMemoryUsed.addAndGet(newInd.getSize()) > totalMemoryAllowed) {\n      freeIndexInformation();\n    }\n    return newInd;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the absence of synchronization around the 'info.wait()' call in the 'getIndexInformation' method of the 'IndexCache' class, which matches the ground truth method. The fix suggestion to reintroduce the 'synchronized' keyword is correct and matches the developer's fix. The problem location is precisely identified as the 'IndexCache.getIndexInformation' method, which is part of the ground truth methods. There is no wrong information in the bug report as all details are consistent with the context of the bug and the provided ground truth."
        }
    },
    {
        "filename": "MAPREDUCE-3463.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService.RecoveryService": {
                "code_before_change": [],
                "code_after_change": []
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": {
                "code_before_change": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n        + event.toString());\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      eventDispatchers.get(type).handle(event);\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread. Exiting..\", t);\n      System.exit(-1);\n    }\n  }",
                "code_after_change": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n        + event.toString());\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      eventDispatchers.get(type).handle(event);\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread. Exiting..\", t);\n      if (exitOnDispatchException) {\n        System.exit(-1);\n      }\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService.parse": {
                "code_before_change": "  private void parse() throws IOException {\n    // TODO: parse history file based on startCount\n    String jobName = \n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId()).toString();\n    String jobhistoryDir = JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(getConfig());\n    FSDataInputStream in = null;\n    Path historyFile = null;\n    Path histDirPath = FileContext.getFileContext(getConfig()).makeQualified(\n        new Path(jobhistoryDir));\n    FileContext fc = FileContext.getFileContext(histDirPath.toUri(),\n        getConfig());\n    //read the previous history file\n    historyFile = fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n        histDirPath, jobName, (applicationAttemptId.getAttemptId() - 1)));          \n    in = fc.open(historyFile);\n    JobHistoryParser parser = new JobHistoryParser(in);\n    jobInfo = parser.parse();\n    Map<org.apache.hadoop.mapreduce.TaskID, TaskInfo> taskInfos = jobInfo\n        .getAllTasks();\n    for (TaskInfo taskInfo : taskInfos.values()) {\n      if (TaskState.SUCCEEDED.toString().equals(taskInfo.getTaskStatus())) {\n        completedTasks\n            .put(TypeConverter.toYarn(taskInfo.getTaskId()), taskInfo);\n        LOG.info(\"Read from history task \"\n            + TypeConverter.toYarn(taskInfo.getTaskId()));\n      }\n    }\n    LOG.info(\"Read completed tasks from history \"\n        + completedTasks.size());\n  }",
                "code_after_change": "  private void parse() throws IOException {\n    // TODO: parse history file based on startCount\n    String jobName = \n        TypeConverter.fromYarn(applicationAttemptId.getApplicationId()).toString();\n    String jobhistoryDir = JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(getConfig());\n    FSDataInputStream in = null;\n    Path historyFile = null;\n    Path histDirPath = FileContext.getFileContext(getConfig()).makeQualified(\n        new Path(jobhistoryDir));\n    FileContext fc = FileContext.getFileContext(histDirPath.toUri(),\n        getConfig());\n    //read the previous history file\n    historyFile = fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(\n        histDirPath, jobName, (applicationAttemptId.getAttemptId() - 1)));          \n    in = fc.open(historyFile);\n    JobHistoryParser parser = new JobHistoryParser(in);\n    jobInfo = parser.parse();\n    Map<org.apache.hadoop.mapreduce.TaskID, TaskInfo> taskInfos = jobInfo\n        .getAllTasks();\n    for (TaskInfo taskInfo : taskInfos.values()) {\n      if (TaskState.SUCCEEDED.toString().equals(taskInfo.getTaskStatus())) {\n        completedTasks\n            .put(TypeConverter.toYarn(taskInfo.getTaskId()), taskInfo);\n        LOG.info(\"Read from history task \"\n            + TypeConverter.toYarn(taskInfo.getTaskId()));\n      }\n    }\n    LOG.info(\"Read completed tasks from history \"\n        + completedTasks.size());\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService.getTaskAttemptInfo": {
                "code_before_change": "  private TaskAttemptInfo getTaskAttemptInfo(TaskAttemptId id) {\n    TaskInfo taskInfo = completedTasks.get(id.getTaskId());\n    return taskInfo.getAllTaskAttempts().get(TypeConverter.fromYarn(id));\n  }",
                "code_after_change": "  private TaskAttemptInfo getTaskAttemptInfo(TaskAttemptId id) {\n    TaskInfo taskInfo = completedTasks.get(id.getTaskId());\n    return taskInfo.getAllTaskAttempts().get(TypeConverter.fromYarn(id));\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.createJobFinishEventHandler": {
                "code_before_change": "  protected EventHandler<JobFinishEvent> createJobFinishEventHandler() {\n    return new JobFinishEventHandler();\n  }",
                "code_after_change": "  protected EventHandler<JobFinishEvent> createJobFinishEventHandler() {\n    return new JobFinishEventHandler();\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService.sendAssignedEvent": {
                "code_before_change": "    private void sendAssignedEvent(TaskAttemptId yarnAttemptID,\n        TaskAttemptInfo attemptInfo) {\n      LOG.info(\"Sending assigned event to \" + yarnAttemptID);\n      ContainerId cId = attemptInfo.getContainerId();\n\n      NodeId nodeId = ConverterUtils.toNodeId(attemptInfo.getHostname());\n      // Resource/Priority/ApplicationACLs are only needed while launching the\n      // container on an NM, these are already completed tasks, so setting them\n      // to null\n      Container container = BuilderUtils.newContainer(cId, nodeId,\n          attemptInfo.getTrackerName() + \":\" + attemptInfo.getHttpPort(),\n          null, null, null);\n      actualHandler.handle(new TaskAttemptContainerAssignedEvent(yarnAttemptID,\n          container, null));\n    }",
                "code_after_change": "    private void sendAssignedEvent(TaskAttemptId yarnAttemptID,\n        TaskAttemptInfo attemptInfo) {\n      LOG.info(\"Sending assigned event to \" + yarnAttemptID);\n      ContainerId cId = attemptInfo.getContainerId();\n\n      NodeId nodeId =\n          ConverterUtils.toNodeId(attemptInfo.getHostname() + \":\"\n              + attemptInfo.getPort());\n      // Resource/Priority/ApplicationACLs are only needed while launching the\n      // container on an NM, these are already completed tasks, so setting them\n      // to null\n      Container container = BuilderUtils.newContainer(cId, nodeId,\n          attemptInfo.getTrackerName() + \":\" + attemptInfo.getHttpPort(),\n          null, null, null);\n      actualHandler.handle(new TaskAttemptContainerAssignedEvent(yarnAttemptID,\n          container, null));\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.init": {
                "code_before_change": "  public void init(final Configuration conf) {\n\n    downloadTokensAndSetupUGI(conf);\n\n    context = new RunningAppContext(conf);\n\n    // Job name is the same as the app name util we support DAG of jobs\n    // for an app later\n    appName = conf.get(MRJobConfig.JOB_NAME, \"<missing app name>\");\n\n    conf.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, appAttemptID.getAttemptId());\n     \n    newApiCommitter = false;\n    jobId = MRBuilderUtils.newJobId(appAttemptID.getApplicationId(),\n        appAttemptID.getApplicationId().getId());\n    int numReduceTasks = conf.getInt(MRJobConfig.NUM_REDUCES, 0);\n    if ((numReduceTasks > 0 && \n        conf.getBoolean(\"mapred.reducer.new-api\", false)) ||\n          (numReduceTasks == 0 && \n           conf.getBoolean(\"mapred.mapper.new-api\", false)))  {\n      newApiCommitter = true;\n      LOG.info(\"Using mapred newApiCommitter.\");\n    }\n\n    committer = createOutputCommitter(conf);\n    boolean recoveryEnabled = conf.getBoolean(\n        MRJobConfig.MR_AM_JOB_RECOVERY_ENABLE, true);\n    boolean recoverySupportedByCommitter = committer.isRecoverySupported();\n    if (recoveryEnabled && recoverySupportedByCommitter\n        && appAttemptID.getAttemptId() > 1) {\n      LOG.info(\"Recovery is enabled. \"\n          + \"Will try to recover from previous life on best effort basis.\");\n      recoveryServ = new RecoveryService(appAttemptID, clock, \n          committer);\n      addIfService(recoveryServ);\n      dispatcher = recoveryServ.getDispatcher();\n      clock = recoveryServ.getClock();\n      inRecovery = true;\n    } else {\n      LOG.info(\"Not starting RecoveryService: recoveryEnabled: \"\n          + recoveryEnabled + \" recoverySupportedByCommitter: \"\n          + recoverySupportedByCommitter + \" ApplicationAttemptID: \"\n          + appAttemptID.getAttemptId());\n      dispatcher = new AsyncDispatcher();\n      addIfService(dispatcher);\n    }\n\n    //service to handle requests to TaskUmbilicalProtocol\n    taskAttemptListener = createTaskAttemptListener(context);\n    addIfService(taskAttemptListener);\n\n    //service to do the task cleanup\n    taskCleaner = createTaskCleaner(context);\n    addIfService(taskCleaner);\n\n    //service to handle requests from JobClient\n    clientService = createClientService(context);\n    addIfService(clientService);\n\n    //service to log job history events\n    EventHandler<JobHistoryEvent> historyService = \n        createJobHistoryHandler(context);\n    dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,\n        historyService);\n\n    this.jobEventDispatcher = new JobEventDispatcher();\n\n    //register the event dispatchers\n    dispatcher.register(JobEventType.class, jobEventDispatcher);\n    dispatcher.register(TaskEventType.class, new TaskEventDispatcher());\n    dispatcher.register(TaskAttemptEventType.class, \n        new TaskAttemptEventDispatcher());\n    dispatcher.register(TaskCleaner.EventType.class, taskCleaner);\n    \n    if (conf.getBoolean(MRJobConfig.MAP_SPECULATIVE, false)\n        || conf.getBoolean(MRJobConfig.REDUCE_SPECULATIVE, false)) {\n      //optional service to speculate on task attempts' progress\n      speculator = createSpeculator(conf, context);\n      addIfService(speculator);\n    }\n\n    dispatcher.register(Speculator.EventType.class,\n        new SpeculatorEventDispatcher(conf));\n\n    // service to allocate containers from RM (if non-uber) or to fake it (uber)\n    containerAllocator = createContainerAllocator(clientService, context);\n    addIfService(containerAllocator);\n    dispatcher.register(ContainerAllocator.EventType.class, containerAllocator);\n\n    // corresponding service to launch allocated containers via NodeManager\n    containerLauncher = createContainerLauncher(context);\n    addIfService(containerLauncher);\n    dispatcher.register(ContainerLauncher.EventType.class, containerLauncher);\n\n    // Add the JobHistoryEventHandler last so that it is properly stopped first.\n    // This will guarantee that all history-events are flushed before AM goes\n    // ahead with shutdown.\n    // Note: Even though JobHistoryEventHandler is started last, if any\n    // component creates a JobHistoryEvent in the meanwhile, it will be just be\n    // queued inside the JobHistoryEventHandler \n    addIfService(historyService);\n\n    super.init(conf);\n  } // end of init()",
                "code_after_change": "  public void init(final Configuration conf) {\n\n    downloadTokensAndSetupUGI(conf);\n\n    context = new RunningAppContext(conf);\n\n    // Job name is the same as the app name util we support DAG of jobs\n    // for an app later\n    appName = conf.get(MRJobConfig.JOB_NAME, \"<missing app name>\");\n\n    conf.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, appAttemptID.getAttemptId());\n     \n    newApiCommitter = false;\n    jobId = MRBuilderUtils.newJobId(appAttemptID.getApplicationId(),\n        appAttemptID.getApplicationId().getId());\n    int numReduceTasks = conf.getInt(MRJobConfig.NUM_REDUCES, 0);\n    if ((numReduceTasks > 0 && \n        conf.getBoolean(\"mapred.reducer.new-api\", false)) ||\n          (numReduceTasks == 0 && \n           conf.getBoolean(\"mapred.mapper.new-api\", false)))  {\n      newApiCommitter = true;\n      LOG.info(\"Using mapred newApiCommitter.\");\n    }\n\n    committer = createOutputCommitter(conf);\n    boolean recoveryEnabled = conf.getBoolean(\n        MRJobConfig.MR_AM_JOB_RECOVERY_ENABLE, true);\n    boolean recoverySupportedByCommitter = committer.isRecoverySupported();\n    if (recoveryEnabled && recoverySupportedByCommitter\n        && appAttemptID.getAttemptId() > 1) {\n      LOG.info(\"Recovery is enabled. \"\n          + \"Will try to recover from previous life on best effort basis.\");\n      recoveryServ = createRecoveryService(context);\n      addIfService(recoveryServ);\n      dispatcher = recoveryServ.getDispatcher();\n      clock = recoveryServ.getClock();\n      inRecovery = true;\n    } else {\n      LOG.info(\"Not starting RecoveryService: recoveryEnabled: \"\n          + recoveryEnabled + \" recoverySupportedByCommitter: \"\n          + recoverySupportedByCommitter + \" ApplicationAttemptID: \"\n          + appAttemptID.getAttemptId());\n      dispatcher = new AsyncDispatcher();\n      addIfService(dispatcher);\n    }\n\n    //service to handle requests to TaskUmbilicalProtocol\n    taskAttemptListener = createTaskAttemptListener(context);\n    addIfService(taskAttemptListener);\n\n    //service to do the task cleanup\n    taskCleaner = createTaskCleaner(context);\n    addIfService(taskCleaner);\n\n    //service to handle requests from JobClient\n    clientService = createClientService(context);\n    addIfService(clientService);\n\n    //service to log job history events\n    EventHandler<JobHistoryEvent> historyService = \n        createJobHistoryHandler(context);\n    dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,\n        historyService);\n\n    this.jobEventDispatcher = new JobEventDispatcher();\n\n    //register the event dispatchers\n    dispatcher.register(JobEventType.class, jobEventDispatcher);\n    dispatcher.register(TaskEventType.class, new TaskEventDispatcher());\n    dispatcher.register(TaskAttemptEventType.class, \n        new TaskAttemptEventDispatcher());\n    dispatcher.register(TaskCleaner.EventType.class, taskCleaner);\n    \n    if (conf.getBoolean(MRJobConfig.MAP_SPECULATIVE, false)\n        || conf.getBoolean(MRJobConfig.REDUCE_SPECULATIVE, false)) {\n      //optional service to speculate on task attempts' progress\n      speculator = createSpeculator(conf, context);\n      addIfService(speculator);\n    }\n\n    dispatcher.register(Speculator.EventType.class,\n        new SpeculatorEventDispatcher(conf));\n\n    // service to allocate containers from RM (if non-uber) or to fake it (uber)\n    containerAllocator = createContainerAllocator(clientService, context);\n    addIfService(containerAllocator);\n    dispatcher.register(ContainerAllocator.EventType.class, containerAllocator);\n\n    // corresponding service to launch allocated containers via NodeManager\n    containerLauncher = createContainerLauncher(context);\n    addIfService(containerLauncher);\n    dispatcher.register(ContainerLauncher.EventType.class, containerLauncher);\n\n    // Add the JobHistoryEventHandler last so that it is properly stopped first.\n    // This will guarantee that all history-events are flushed before AM goes\n    // ahead with shutdown.\n    // Note: Even though JobHistoryEventHandler is started last, if any\n    // component creates a JobHistoryEvent in the meanwhile, it will be just be\n    // queued inside the JobHistoryEventHandler \n    addIfService(historyService);\n\n    super.init(conf);\n  } // end of init()"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as an IllegalArgumentException thrown by the ConverterUtils.toNodeId method, which is directly related to the ground truth method RecoveryService.sendAssignedEvent. The fix suggestion is an alternative fix because it suggests adding validation checks for the NodeId format, which is different from the actual fix but would likely resolve the issue. The problem location identification is precise as it mentions the method RecoveryService.sendAssignedEvent, which is in the ground truth list. There is no wrong information in the bug report as all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4164.json",
        "code_diff": {
            "mapreduce.src.java.org.apache.hadoop.mapred.Task.startCommunicationThread": {
                "code_before_change": [],
                "code_after_change": "    public void startCommunicationThread() {\n      if (pingThread == null) {\n        pingThread = new Thread(this, \"communication thread\");\n        pingThread.setDaemon(true);\n        pingThread.start();\n      }\n    }"
            },
            "mapreduce.src.java.org.apache.hadoop.mapred.Task.run": {
                "code_before_change": [],
                "code_after_change": "  public abstract void run(JobConf job, TaskUmbilicalProtocol umbilical)\n    throws IOException, ClassNotFoundException, InterruptedException;\n\n\n  /** Return an approprate thread runner for this task. \n   * @param tip TODO*/\n  public abstract TaskRunner createRunner(TaskTracker tracker, \n      TaskTracker.TaskInProgress tip) throws IOException;\n\n  /** The number of milliseconds between progress reports. */\n  public static final int PROGRESS_INTERVAL = 3000;\n\n  private transient Progress taskProgress = new Progress();\n\n  // Current counters\n  private transient Counters counters = new Counters();\n\n  /* flag to track whether task is done */\n  private AtomicBoolean taskDone = new AtomicBoolean(false);\n  \n  public abstract boolean isMapTask();\n\n  public Progress getProgress() { return taskProgress; }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the interruption of the thread responsible for sending the task's completion status, which is related to the stack trace context but not the exact ground truth methods. The fix suggestion is preventive, as it suggests ensuring that interruptions do not occur during critical communication phases, which would mitigate the issue. The problem location identification is partial, as it mentions methods in the stack trace context but not the exact ground truth methods. There is no wrong information in the bug report, as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4774.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.KillTasksTransition": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the issue in the 'JobImpl.handle' method, which is where the error occurs, but not where the actual fix was made ('KillTasksTransition'). Therefore, it is classified as 'Partial' under 'Buggy Method' for both root cause and problem location identification. The fix suggestion involves adding a check in the 'JobImpl.handle' method to prevent processing events in the FAILED state, which is a preventive measure to avoid the error. There is no incorrect information in the bug report, as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3005.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.getNode": {
                "code_before_change": "  private SchedulerNode getNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }",
                "code_after_change": "  private SchedulerNode getNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.assignNodeLocalContainers": {
                "code_before_change": "  private int assignNodeLocalContainers(SchedulerNode node, \n      SchedulerApp application, Priority priority) {\n    int assignedContainers = 0;\n    ResourceRequest request = \n      application.getResourceRequest(priority, node.getRMNode().getNodeAddress());\n    if (request != null) {\n      int assignableContainers = \n        Math.min(\n            getMaxAllocatableContainers(application, priority, node, \n                NodeType.NODE_LOCAL), \n                request.getNumContainers());\n      assignedContainers = \n        assignContainer(node, application, priority, \n            assignableContainers, request, NodeType.NODE_LOCAL);\n    }\n    return assignedContainers;\n  }",
                "code_after_change": "  private int assignNodeLocalContainers(SchedulerNode node, \n      SchedulerApp application, Priority priority) {\n    int assignedContainers = 0;\n    ResourceRequest request = \n      application.getResourceRequest(priority, node.getRMNode().getNodeAddress());\n    if (request != null) {\n      // Don't allocate on this node if we don't need containers on this rack\n      ResourceRequest rackRequest =\n          application.getResourceRequest(priority, \n              node.getRMNode().getRackName());\n      if (rackRequest == null || rackRequest.getNumContainers() <= 0) {\n        return 0;\n      }\n      \n      int assignableContainers = \n        Math.min(\n            getMaxAllocatableContainers(application, priority, node, \n                NodeType.NODE_LOCAL), \n                request.getNumContainers());\n      assignedContainers = \n        assignContainer(node, application, priority, \n            assignableContainers, request, NodeType.NODE_LOCAL);\n    }\n    return assignedContainers;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.assignRackLocalContainers": {
                "code_before_change": "  private int assignRackLocalContainers(SchedulerNode node, \n      SchedulerApp application, Priority priority) {\n    int assignedContainers = 0;\n    ResourceRequest request = \n      application.getResourceRequest(priority, node.getRMNode().getRackName());\n    if (request != null) {\n      int assignableContainers = \n        Math.min(\n            getMaxAllocatableContainers(application, priority, node, \n                NodeType.RACK_LOCAL), \n                request.getNumContainers());\n      assignedContainers = \n        assignContainer(node, application, priority, \n            assignableContainers, request, NodeType.RACK_LOCAL);\n    }\n    return assignedContainers;\n  }",
                "code_after_change": "  private int assignRackLocalContainers(SchedulerNode node, \n      SchedulerApp application, Priority priority) {\n    int assignedContainers = 0;\n    ResourceRequest request = \n      application.getResourceRequest(priority, node.getRMNode().getRackName());\n    if (request != null) {\n      // Don't allocate on this rack if the application doens't need containers\n      ResourceRequest offSwitchRequest =\n          application.getResourceRequest(priority, SchedulerNode.ANY);\n      if (offSwitchRequest.getNumContainers() <= 0) {\n        return 0;\n      }\n      \n      int assignableContainers = \n        Math.min(\n            getMaxAllocatableContainers(application, priority, node, \n                NodeType.RACK_LOCAL), \n                request.getNumContainers());\n      assignedContainers = \n        assignContainer(node, application, priority, \n            assignableContainers, request, NodeType.RACK_LOCAL);\n    }\n    return assignedContainers;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.canAssign": {
                "code_before_change": "  boolean canAssign(SchedulerApp application, Priority priority, \n      SchedulerNode node, NodeType type, RMContainer reservedContainer) {\n\n    // Reserved... \n    if (reservedContainer != null) {\n      return true;\n    }\n    \n    // Clearly we need containers for this application...\n    if (type == NodeType.OFF_SWITCH) {\n      // 'Delay' off-switch\n      ResourceRequest offSwitchRequest = \n          application.getResourceRequest(priority, RMNode.ANY);\n      long missedOpportunities = application.getSchedulingOpportunities(priority);\n      long requiredContainers = offSwitchRequest.getNumContainers(); \n      \n      float localityWaitFactor = \n        application.getLocalityWaitFactor(priority, \n            scheduler.getNumClusterNodes());\n      \n      return ((requiredContainers * localityWaitFactor) < missedOpportunities);\n    }\n\n    // Check if we need containers on this rack \n    ResourceRequest rackLocalRequest = \n      application.getResourceRequest(priority, node.getRackName());\n    if (type == NodeType.RACK_LOCAL) {\n      if (rackLocalRequest == null) {\n        return false;\n      } else {\n        return rackLocalRequest.getNumContainers() > 0;      \n      }\n    }\n\n    // Check if we need containers on this host\n    if (type == NodeType.NODE_LOCAL) {\n      // First: Do we need containers on this rack?\n      if (rackLocalRequest != null && rackLocalRequest.getNumContainers() == 0) {\n        return false;\n      }\n      \n      // Now check if we need containers on this host...\n      ResourceRequest nodeLocalRequest = \n        application.getResourceRequest(priority, node.getHostName());\n      if (nodeLocalRequest != null) {\n        return nodeLocalRequest.getNumContainers() > 0;\n      }\n    }\n\n    return false;\n  }",
                "code_after_change": "  boolean canAssign(SchedulerApp application, Priority priority, \n      SchedulerNode node, NodeType type, RMContainer reservedContainer) {\n\n    // Reserved... \n    if (reservedContainer != null) {\n      return true;\n    }\n    \n    // Clearly we need containers for this application...\n    if (type == NodeType.OFF_SWITCH) {\n      // 'Delay' off-switch\n      ResourceRequest offSwitchRequest = \n          application.getResourceRequest(priority, RMNode.ANY);\n      long missedOpportunities = application.getSchedulingOpportunities(priority);\n      long requiredContainers = offSwitchRequest.getNumContainers(); \n      \n      float localityWaitFactor = \n        application.getLocalityWaitFactor(priority, \n            scheduler.getNumClusterNodes());\n      \n      return ((requiredContainers * localityWaitFactor) < missedOpportunities);\n    }\n\n    // Check if we need containers on this rack \n    ResourceRequest rackLocalRequest = \n      application.getResourceRequest(priority, node.getRackName());\n    if (rackLocalRequest == null || rackLocalRequest.getNumContainers() <= 0) {\n      return false;\n    }\n      \n    // If we are here, we do need containers on this rack for RACK_LOCAL req\n    if (type == NodeType.RACK_LOCAL) {\n      return true;\n    }\n\n    // Check if we need containers on this host\n    if (type == NodeType.NODE_LOCAL) {\n      // Now check if we need containers on this host...\n      ResourceRequest nodeLocalRequest = \n        application.getResourceRequest(priority, node.getHostName());\n      if (nodeLocalRequest != null) {\n        return nodeLocalRequest.getNumContainers() > 0;\n      }\n    }\n\n    return false;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a NullPointerException in the method AppSchedulingInfo.allocateNodeLocal, which is not a ground truth method but is mentioned in the stack trace, hence 'Partial' with 'Shared Stack Trace Context'. The fix suggestion involves adding null checks, which is preventive as it would mitigate the NPE but does not match the actual fix. The problem location is also 'Partial' with 'Shared Stack Trace Context' as it mentions methods in the stack trace but not the ground truth methods. There is no wrong information as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6895.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notifyURLOnce": {
                "code_before_change": "  protected boolean notifyURLOnce() {\n    boolean success = false;\n    try {\n      Log.getLog().info(\"Job end notification trying \" + urlToNotify);\n      HttpURLConnection conn =\n        (HttpURLConnection) urlToNotify.openConnection(proxyToUse);\n      conn.setConnectTimeout(timeout);\n      conn.setReadTimeout(timeout);\n      conn.setAllowUserInteraction(false);\n      if(conn.getResponseCode() != HttpURLConnection.HTTP_OK) {\n        Log.getLog().warn(\"Job end notification to \" + urlToNotify\n            + \" failed with code: \" + conn.getResponseCode() + \" and message \\\"\"\n            + conn.getResponseMessage() + \"\\\"\");\n      }\n      else {\n        success = true;\n        Log.getLog().info(\"Job end notification to \" + urlToNotify\n            + \" succeeded\");\n      }\n    } catch(IOException ioe) {\n      Log.getLog().warn(\"Job end notification to \" + urlToNotify + \" failed\",\n          ioe);\n    }\n    return success;\n  }",
                "code_after_change": "  protected boolean notifyURLOnce() {\n    boolean success = false;\n    try {\n      Log.info(\"Job end notification trying \" + urlToNotify);\n      HttpURLConnection conn =\n        (HttpURLConnection) urlToNotify.openConnection(proxyToUse);\n      conn.setConnectTimeout(timeout);\n      conn.setReadTimeout(timeout);\n      conn.setAllowUserInteraction(false);\n      if(conn.getResponseCode() != HttpURLConnection.HTTP_OK) {\n        Log.warn(\"Job end notification to \" + urlToNotify +\" failed with code: \"\n        + conn.getResponseCode() + \" and message \\\"\" + conn.getResponseMessage()\n        +\"\\\"\");\n      }\n      else {\n        success = true;\n        Log.info(\"Job end notification to \" + urlToNotify + \" succeeded\");\n      }\n    } catch(IOException ioe) {\n      Log.warn(\"Job end notification to \" + urlToNotify + \" failed\", ioe);\n    }\n    return success;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob": {
                "code_before_change": "  public void shutDownJob() {\n    // job has finished\n    // this is the only job, so shut down the Appmaster\n    // note in a workflow scenario, this may lead to creation of a new\n    // job (FIXME?)\n\n    try {\n      //if isLastAMRetry comes as true, should never set it to false\n      if ( !isLastAMRetry){\n        if (((JobImpl)job).getInternalState() != JobStateInternal.REBOOT) {\n          LOG.info(\"Job finished cleanly, recording last MRAppMaster retry\");\n          isLastAMRetry = true;\n        }\n      }\n      notifyIsLastAMRetry(isLastAMRetry);\n      // Stop all services\n      // This will also send the final report to the ResourceManager\n      LOG.info(\"Calling stop for all the services\");\n      MRAppMaster.this.stop();\n\n      if (isLastAMRetry) {\n        // Send job-end notification when it is safe to report termination to\n        // users and it is the last AM retry\n        if (getConfig().get(MRJobConfig.MR_JOB_END_NOTIFICATION_URL) != null) {\n          try {\n            LOG.info(\"Job end notification started for jobID : \"\n                + job.getReport().getJobId());\n            JobEndNotifier notifier = new JobEndNotifier();\n            notifier.setConf(getConfig());\n            JobReport report = job.getReport();\n            // If unregistration fails, the final state is unavailable. However,\n            // at the last AM Retry, the client will finally be notified FAILED\n            // from RM, so we should let users know FAILED via notifier as well\n            if (!context.hasSuccessfullyUnregistered()) {\n              report.setJobState(JobState.FAILED);\n            }\n            notifier.notify(report);\n          } catch (InterruptedException ie) {\n            LOG.warn(\"Job end notification interrupted for jobID : \"\n                + job.getReport().getJobId(), ie);\n          }\n        }\n      }\n\n      try {\n        Thread.sleep(5000);\n      } catch (InterruptedException e) {\n        e.printStackTrace();\n      }\n      clientService.stop();\n    } catch (Throwable t) {\n      LOG.warn(\"Graceful stop failed. Exiting.. \", t);\n      exitMRAppMaster(1, t);\n    }\n    exitMRAppMaster(0, null);\n  }",
                "code_after_change": "  public void shutDownJob() {\n    // job has finished\n    // this is the only job, so shut down the Appmaster\n    // note in a workflow scenario, this may lead to creation of a new\n    // job (FIXME?)\n\n    JobEndNotifier notifier = null;\n    if (getConfig().get(MRJobConfig.MR_JOB_END_NOTIFICATION_URL) != null) {\n      notifier = new JobEndNotifier();\n      notifier.setConf(getConfig());\n    }\n\n    try {\n      //if isLastAMRetry comes as true, should never set it to false\n      if ( !isLastAMRetry){\n        if (((JobImpl)job).getInternalState() != JobStateInternal.REBOOT) {\n          LOG.info(\"Job finished cleanly, recording last MRAppMaster retry\");\n          isLastAMRetry = true;\n        }\n      }\n      notifyIsLastAMRetry(isLastAMRetry);\n      // Stop all services\n      // This will also send the final report to the ResourceManager\n      LOG.info(\"Calling stop for all the services\");\n      MRAppMaster.this.stop();\n\n      if (isLastAMRetry && notifier != null) {\n        // Send job-end notification when it is safe to report termination to\n        // users and it is the last AM retry\n        sendJobEndNotify(notifier);\n        notifier = null;\n      }\n\n      try {\n        Thread.sleep(5000);\n      } catch (InterruptedException e) {\n        e.printStackTrace();\n      }\n      clientService.stop();\n    } catch (Throwable t) {\n      LOG.warn(\"Graceful stop failed. Exiting.. \", t);\n      exitMRAppMaster(1, t);\n    } finally {\n      if (isLastAMRetry && notifier != null) {\n        sendJobEndNotify(notifier);\n      }\n    }\n    exitMRAppMaster(0, null);\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a ClosedChannelException in the JobHistoryEventHandler, which is a method where the error occurred but not where the actual fix was made. The actual fix was made in MRAppMaster.shutDownJob and JobEndNotifier.notifyURLOnce. The fix suggestion to ensure the output stream is open before writing is preventive, as it would mitigate the issue but does not match the developer's fix. The problem location mentions JobHistoryEventHandler.handleEvent and MRAppMaster.shutDownJob, which are related to the error but not the precise location of the fix. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4451.json",
        "code_diff": {
            "src.contrib.fairscheduler.src.java.org.apache.hadoop.mapred.FairScheduler.terminate": {
                "code_before_change": [],
                "code_after_change": "  public void terminate() throws IOException {\n    if (eventLog != null)\n      eventLog.log(\"SHUTDOWN\");\n    running = false;\n    jobInitializer.terminate();\n    if (jobListener != null)\n      taskTrackerManager.removeJobInProgressListener(jobListener);\n    if (eventLog != null)\n      eventLog.shutdown();\n    if (metricsUpdater != null) {\n      MetricsContext context = MetricsUtil.getContext(\"fairscheduler\");\n      context.unregisterUpdater(metricsUpdater);\n      metricsUpdater = null;\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as an issue with the UserGroupInformation (UGI) instance not having a valid Kerberos ticket, which is related to the stack trace context but not the exact ground truth method. The fix suggestion involves modifying the UGI usage, which is an alternative approach to resolving the issue. The problem location mentions methods in the stack trace context but not the exact ground truth method. There is no wrong information in the bug report as it accurately describes the problem and its context."
        }
    },
    {
        "filename": "MAPREDUCE-4144.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignOffSwitchContainers": {
                "code_before_change": "  private Resource assignOffSwitchContainers(Resource clusterResource, SchedulerNode node, \n      SchedulerApp application, Priority priority, \n      RMContainer reservedContainer) {\n    ResourceRequest request = \n      application.getResourceRequest(priority, RMNode.ANY);\n    if (request != null) {\n      if (canAssign(application, priority, node, NodeType.OFF_SWITCH, \n          reservedContainer)) {\n        return assignContainer(clusterResource, node, application, priority, request, \n            NodeType.OFF_SWITCH, reservedContainer);\n      }\n    }\n    \n    return Resources.none();\n  }",
                "code_after_change": "  private Resource assignOffSwitchContainers(Resource clusterResource, SchedulerNode node, \n      SchedulerApp application, Priority priority, \n      RMContainer reservedContainer) {\n    ResourceRequest request = \n      application.getResourceRequest(priority, RMNode.ANY);\n    if (request != null) {\n      if (canAssign(application, priority, node, NodeType.OFF_SWITCH, \n          reservedContainer)) {\n        return assignContainer(clusterResource, node, application, priority, request, \n            NodeType.OFF_SWITCH, reservedContainer);\n      }\n    }\n    \n    return Resources.none();\n  }"
            },
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.canAssign": {
                "code_before_change": "  boolean canAssign(SchedulerApp application, Priority priority, \n      SchedulerNode node, NodeType type, RMContainer reservedContainer) {\n\n    // Reserved... \n    if (reservedContainer != null) {\n      return true;\n    }\n    \n    // Clearly we need containers for this application...\n    if (type == NodeType.OFF_SWITCH) {\n      // 'Delay' off-switch\n      ResourceRequest offSwitchRequest = \n          application.getResourceRequest(priority, RMNode.ANY);\n      long missedOpportunities = application.getSchedulingOpportunities(priority);\n      long requiredContainers = offSwitchRequest.getNumContainers(); \n      \n      float localityWaitFactor = \n        application.getLocalityWaitFactor(priority, \n            scheduler.getNumClusterNodes());\n      \n      return ((requiredContainers * localityWaitFactor) < missedOpportunities);\n    }\n\n    // Check if we need containers on this rack \n    ResourceRequest rackLocalRequest = \n      application.getResourceRequest(priority, node.getRackName());\n    if (rackLocalRequest == null || rackLocalRequest.getNumContainers() <= 0) {\n      return false;\n    }\n      \n    // If we are here, we do need containers on this rack for RACK_LOCAL req\n    if (type == NodeType.RACK_LOCAL) {\n      return true;\n    }\n\n    // Check if we need containers on this host\n    if (type == NodeType.NODE_LOCAL) {\n      // Now check if we need containers on this host...\n      ResourceRequest nodeLocalRequest = \n        application.getResourceRequest(priority, node.getHostName());\n      if (nodeLocalRequest != null) {\n        return nodeLocalRequest.getNumContainers() > 0;\n      }\n    }\n\n    return false;\n  }",
                "code_after_change": "  boolean canAssign(SchedulerApp application, Priority priority, \n      SchedulerNode node, NodeType type, RMContainer reservedContainer) {\n\n    // Clearly we need containers for this application...\n    if (type == NodeType.OFF_SWITCH) {\n      if (reservedContainer != null) {\n        return true;\n      }\n\n      // 'Delay' off-switch\n      ResourceRequest offSwitchRequest = \n          application.getResourceRequest(priority, RMNode.ANY);\n      long missedOpportunities = application.getSchedulingOpportunities(priority);\n      long requiredContainers = offSwitchRequest.getNumContainers(); \n      \n      float localityWaitFactor = \n        application.getLocalityWaitFactor(priority, \n            scheduler.getNumClusterNodes());\n      \n      return ((requiredContainers * localityWaitFactor) < missedOpportunities);\n    }\n\n    // Check if we need containers on this rack \n    ResourceRequest rackLocalRequest = \n      application.getResourceRequest(priority, node.getRackName());\n    if (rackLocalRequest == null || rackLocalRequest.getNumContainers() <= 0) {\n      return false;\n    }\n      \n    // If we are here, we do need containers on this rack for RACK_LOCAL req\n    if (type == NodeType.RACK_LOCAL) {\n      return true;\n    }\n\n    // Check if we need containers on this host\n    if (type == NodeType.NODE_LOCAL) {\n      // Now check if we need containers on this host...\n      ResourceRequest nodeLocalRequest = \n        application.getResourceRequest(priority, node.getHostName());\n      if (nodeLocalRequest != null) {\n        return nodeLocalRequest.getNumContainers() > 0;\n      }\n    }\n\n    return false;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a NullPointerException in the AppSchedulingInfo.allocateNodeLocal method, which is not the exact root cause but is part of the shared stack trace context with the ground truth methods. The fix suggestion involves adding null checks, which is preventive as it would mitigate the NPE but does not match the developer's fix. The problem location is identified as AppSchedulingInfo.allocateNodeLocal, which is part of the shared stack trace context but not the precise ground truth method. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5924.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.KilledTransition": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as an invalid state transition in the 'TaskAttemptImpl' class, specifically in the 'handle' method. This is not the exact ground truth method but is closely related as it is the method where the error occurs, hence classified as 'Partial' under 'Buggy Method'. The fix suggestion involves adding a check to prevent invalid state transitions, which is a preventive measure to mitigate the bug. The problem location is identified as 'TaskAttemptImpl.handle', which is the method where the error occurs, but not where the actual fix was made, thus 'Partial' under 'Buggy Method'. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3649.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notifyURLOnce": {
                "code_before_change": "  protected boolean notifyURLOnce() {\n    boolean success = false;\n    try {\n      Log.info(\"Job end notification trying \" + urlToNotify);\n      URLConnection conn = urlToNotify.openConnection();\n      conn.setConnectTimeout(5*1000);\n      conn.setReadTimeout(5*1000);\n      conn.setAllowUserInteraction(false);\n      InputStream is = conn.getInputStream();\n      conn.getContent();\n      is.close();\n      success = true;\n      Log.info(\"Job end notification to \" + urlToNotify + \" succeeded\");\n    } catch(IOException ioe) {\n      Log.warn(\"Job end notification to \" + urlToNotify + \" failed\", ioe);\n    }\n    return success;\n  }",
                "code_after_change": "  protected boolean notifyURLOnce() {\n    boolean success = false;\n    try {\n      Log.info(\"Job end notification trying \" + urlToNotify);\n      HttpURLConnection conn = (HttpURLConnection) urlToNotify.openConnection();\n      conn.setConnectTimeout(5*1000);\n      conn.setReadTimeout(5*1000);\n      conn.setAllowUserInteraction(false);\n      if(conn.getResponseCode() != HttpURLConnection.HTTP_OK) {\n        Log.warn(\"Job end notification to \" + urlToNotify +\" failed with code: \"\n        + conn.getResponseCode() + \" and message \\\"\" + conn.getResponseMessage()\n        +\"\\\"\");\n      }\n      else {\n        success = true;\n        Log.info(\"Job end notification to \" + urlToNotify + \" succeeded\");\n      }\n    } catch(IOException ioe) {\n      Log.warn(\"Job end notification to \" + urlToNotify + \" failed\", ioe);\n    }\n    return success;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the absence of a content-type in the response, which is directly related to the ground truth method 'JobEndNotifier.notifyURLOnce'. The fix suggestion is preventive as it suggests adding error handling for missing content-type, which aligns with the developer's fix of checking the response code but does not match it exactly. The problem location identification is precise as it mentions the 'JobEndNotifier.notifyURLOnce' method, which is the ground truth method. There is no wrong information in the bug report as all details are relevant and accurate."
        }
    },
    {
        "filename": "MAPREDUCE-4102.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.getCounters": {
                "code_before_change": "  private void getCounters(AppContext ctx) {\n    JobId jobID = null;\n    TaskId taskID = null;\n    String tid = $(TASK_ID);\n    if (!tid.isEmpty()) {\n      taskID = MRApps.toTaskID(tid);\n      jobID = taskID.getJobId();\n    } else {\n      String jid = $(JOB_ID);\n      if (jid != null && !jid.isEmpty()) {\n        jobID = MRApps.toJobID(jid);\n      }\n    }\n    if (jobID == null) {\n      return;\n    }\n    job = ctx.getJob(jobID);\n    if (job == null) {\n      return;\n    }\n    if (taskID != null) {\n      task = job.getTask(taskID);\n      if (task == null) {\n        return;\n      }\n      total = task.getCounters();\n      return;\n    }\n    // Get all types of counters\n    Map<TaskId, Task> tasks = job.getTasks();\n    total = job.getAllCounters();\n    map = new Counters();\n    reduce = new Counters();\n    for (Task t : tasks.values()) {\n      Counters counters = t.getCounters();\n      switch (t.getType()) {\n        case MAP:     map.incrAllCounters(counters);     break;\n        case REDUCE:  reduce.incrAllCounters(counters);  break;\n      }\n    }\n  }",
                "code_after_change": "  private void getCounters(AppContext ctx) {\n    JobId jobID = null;\n    TaskId taskID = null;\n    String tid = $(TASK_ID);\n    if (!tid.isEmpty()) {\n      taskID = MRApps.toTaskID(tid);\n      jobID = taskID.getJobId();\n    } else {\n      String jid = $(JOB_ID);\n      if (jid != null && !jid.isEmpty()) {\n        jobID = MRApps.toJobID(jid);\n      }\n    }\n    if (jobID == null) {\n      return;\n    }\n    job = ctx.getJob(jobID);\n    if (job == null) {\n      return;\n    }\n    if (taskID != null) {\n      task = job.getTask(taskID);\n      if (task == null) {\n        return;\n      }\n      total = task.getCounters();\n      return;\n    }\n    // Get all types of counters\n    Map<TaskId, Task> tasks = job.getTasks();\n    total = job.getAllCounters();\n    boolean needTotalCounters = false;\n    if (total == null) {\n      total = new Counters();\n      needTotalCounters = true;\n    }\n    map = new Counters();\n    reduce = new Counters();\n    for (Task t : tasks.values()) {\n      Counters counters = t.getCounters();\n      if (counters == null) {\n        continue;\n      }\n      switch (t.getType()) {\n        case MAP:     map.incrAllCounters(counters);     break;\n        case REDUCE:  reduce.incrAllCounters(counters);  break;\n      }\n      if (needTotalCounters) {\n        total.incrAllCounters(counters);\n      }\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobCounterInfo.getCounters": {
                "code_before_change": "  private void getCounters(AppContext ctx, Job job) {\n    total = new Counters();\n    if (job == null) {\n      return;\n    }\n    map = new Counters();\n    reduce = new Counters();\n    // Get all types of counters\n    Map<TaskId, Task> tasks = job.getTasks();\n    for (Task t : tasks.values()) {\n      Counters counters = t.getCounters();\n      total.incrAllCounters(counters);\n      switch (t.getType()) {\n      case MAP:\n        map.incrAllCounters(counters);\n        break;\n      case REDUCE:\n        reduce.incrAllCounters(counters);\n        break;\n      }\n    }\n  }",
                "code_after_change": "  private void getCounters(AppContext ctx, Job job) {\n    total = new Counters();\n    if (job == null) {\n      return;\n    }\n    map = new Counters();\n    reduce = new Counters();\n    // Get all types of counters\n    Map<TaskId, Task> tasks = job.getTasks();\n    for (Task t : tasks.values()) {\n      Counters counters = t.getCounters();\n      if (counters == null) {\n        continue;\n      }\n      total.incrAllCounters(counters);\n      switch (t.getType()) {\n      case MAP:\n        map.incrAllCounters(counters);\n        break;\n      case REDUCE:\n        reduce.incrAllCounters(counters);\n        break;\n      }\n    }\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a NullPointerException in the 'incrAllCounters' method of the AbstractCounters class, which is a method where the error occurred but not where the actual fix was made, hence 'Partial' and 'Buggy Method'. The fix suggestion in the report matches the developer's fix by suggesting a check for null counters in the 'getCounters' method, so it is 'Correct'. The problem location is 'Precise' as it mentions the 'getCounters' method in the CountersBlock class, which is a ground truth method. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6353.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.ResourceCalculatorUtils.divideAndCeil": {
                "code_before_change": "  public static int divideAndCeil(int a, int b) {\n    if (b == 0) {\n      return 0;\n    }\n    return (a + (b - 1)) / b;\n  }",
                "code_after_change": "  public static int divideAndCeil(int a, int b) {\n    if (b == 0) {\n      return 0;\n    }\n    return (a + (b - 1)) / b;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.ResourceCalculatorUtils.divideAndCeilContainers": {
                "code_before_change": "  public static int divideAndCeilContainers(Resource required, Resource factor,\n      EnumSet<SchedulerResourceTypes> resourceTypes) {\n    if (resourceTypes.contains(SchedulerResourceTypes.CPU)) {\n      return Math.max(divideAndCeil(required.getMemory(), factor.getMemory()),\n        divideAndCeil(required.getVirtualCores(), factor.getVirtualCores()));\n    }\n    return divideAndCeil(required.getMemory(), factor.getMemory());\n  }",
                "code_after_change": "  public static int divideAndCeilContainers(Resource required, Resource factor,\n      EnumSet<SchedulerResourceTypes> resourceTypes) {\n    if (resourceTypes.contains(SchedulerResourceTypes.CPU)) {\n      return Math.max(divideAndCeil(required.getMemory(), factor.getMemory()),\n        divideAndCeil(required.getVirtualCores(), factor.getVirtualCores()));\n    }\n    return divideAndCeil(required.getMemory(), factor.getMemory());\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the method 'ResourceCalculatorUtils.computeAvailableContainers' as the location of the division by zero error, which is where the error occurs but not where the actual fix was made. The ground truth methods are 'divideAndCeil' and 'divideAndCeilContainers', which are not mentioned in the bug report. Therefore, the root cause identification and problem location identification are classified as 'Partial' with the sub-category 'Buggy Method'. The fix suggestion in the bug report suggests adding a check for zero virtual cores, which is a preventive measure to avoid the division by zero error, but it does not match the developer's fix. There is no wrong information in the bug report as all the details provided are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6492.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.createJobCounterUpdateEventTAKilled": {
                "code_before_change": "  private static JobCounterUpdateEvent createJobCounterUpdateEventTAKilled(\n      TaskAttemptImpl taskAttempt, boolean taskAlreadyCompleted) {\n    TaskType taskType = taskAttempt.getID().getTaskId().getTaskType();\n    JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskAttempt.getID().getTaskId().getJobId());\n    \n    if (taskType == TaskType.MAP) {\n      jce.addCounterUpdate(JobCounter.NUM_KILLED_MAPS, 1);\n    } else {\n      jce.addCounterUpdate(JobCounter.NUM_KILLED_REDUCES, 1);\n    }\n    if (!taskAlreadyCompleted) {\n      updateMillisCounters(jce, taskAttempt);\n    }\n    return jce;\n  }  ",
                "code_after_change": "  private static JobCounterUpdateEvent createJobCounterUpdateEventTAKilled(\n      TaskAttemptImpl taskAttempt, boolean taskAlreadyCompleted) {\n    TaskType taskType = taskAttempt.getID().getTaskId().getTaskType();\n    JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskAttempt.getID().getTaskId().getJobId());\n    \n    if (taskType == TaskType.MAP) {\n      jce.addCounterUpdate(JobCounter.NUM_KILLED_MAPS, 1);\n    } else {\n      jce.addCounterUpdate(JobCounter.NUM_KILLED_REDUCES, 1);\n    }\n    if (!taskAlreadyCompleted) {\n      updateMillisCounters(jce, taskAttempt);\n    }\n    return jce;\n  }  "
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.sendJHStartEventForAssignedFailTask": {
                "code_before_change": "  private static void\n      sendJHStartEventForAssignedFailTask(TaskAttemptImpl taskAttempt) {\n    TaskAttemptContainerLaunchedEvent event;\n    taskAttempt.launchTime = taskAttempt.clock.getTime();\n\n    InetSocketAddress nodeHttpInetAddr =\n        NetUtils.createSocketAddr(taskAttempt.container.getNodeHttpAddress());\n    taskAttempt.trackerName = nodeHttpInetAddr.getHostName();\n    taskAttempt.httpPort = nodeHttpInetAddr.getPort();\n    taskAttempt.sendLaunchedEvents();\n  }",
                "code_after_change": "  private static void\n      sendJHStartEventForAssignedFailTask(TaskAttemptImpl taskAttempt) {\n    if (null == taskAttempt.container) {\n      return;\n    }\n    taskAttempt.launchTime = taskAttempt.clock.getTime();\n\n    InetSocketAddress nodeHttpInetAddr =\n        NetUtils.createSocketAddr(taskAttempt.container.getNodeHttpAddress());\n    taskAttempt.trackerName = nodeHttpInetAddr.getHostName();\n    taskAttempt.httpPort = nodeHttpInetAddr.getPort();\n    taskAttempt.sendLaunchedEvents();\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause of the NullPointerException in the method `sendJHStartEventForAssignedFailTask`, which is one of the ground truth methods. The fix suggestion provided in the bug report matches the developer's fix, which involves adding a null check for the `container` object in the `sendJHStartEventForAssignedFailTask` method. The problem location is also precisely identified as it mentions the method `sendJHStartEventForAssignedFailTask`, which is in the ground truth list. There is no wrong information in the bug report as all the details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5744.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.preemptReduce": {
                "code_before_change": "    void preemptReduce(int toPreempt) {\n      List<TaskAttemptId> reduceList = new ArrayList<TaskAttemptId>\n        (reduces.keySet());\n      //sort reduces on progress\n      Collections.sort(reduceList,\n          new Comparator<TaskAttemptId>() {\n        @Override\n        public int compare(TaskAttemptId o1, TaskAttemptId o2) {\n          float p = getJob().getTask(o1.getTaskId()).getAttempt(o1).getProgress() -\n              getJob().getTask(o2.getTaskId()).getAttempt(o2).getProgress();\n          return p >= 0 ? 1 : -1;\n        }\n      });\n      \n      for (int i = 0; i < toPreempt && reduceList.size() > 0; i++) {\n        TaskAttemptId id = reduceList.remove(0);//remove the one on top\n        LOG.info(\"Preempting \" + id);\n        preemptionWaitingReduces.add(id);\n        eventHandler.handle(new TaskAttemptEvent(id, TaskAttemptEventType.TA_KILL));\n      }\n    }",
                "code_after_change": "    void preemptReduce(int toPreempt) {\n      List<TaskAttemptId> reduceList = new ArrayList<TaskAttemptId>\n        (reduces.keySet());\n      //sort reduces on progress\n      Collections.sort(reduceList,\n          new Comparator<TaskAttemptId>() {\n        @Override\n        public int compare(TaskAttemptId o1, TaskAttemptId o2) {\n          return Float.compare(\n              getJob().getTask(o1.getTaskId()).getAttempt(o1).getProgress(),\n              getJob().getTask(o2.getTaskId()).getAttempt(o2).getProgress());\n        }\n      });\n      \n      for (int i = 0; i < toPreempt && reduceList.size() > 0; i++) {\n        TaskAttemptId id = reduceList.remove(0);//remove the one on top\n        LOG.info(\"Preempting \" + id);\n        preemptionWaitingReduces.add(id);\n        eventHandler.handle(new TaskAttemptEvent(id, TaskAttemptEventType.TA_KILL));\n      }\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the comparator in the preemptReduce() method not adhering to the Comparator contract, which matches the ground truth method. The fix suggestion is correct as it aligns with the developer's fix, which involves correcting the comparator implementation. The problem location is precisely identified as it mentions the RMContainerAllocator$AssignedRequests.preemptReduce method, which is the ground truth method. There is no wrong information in the bug report as all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3583.json",
        "code_diff": {
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.getProcessTree": {
                "code_before_change": [],
                "code_after_change": "  public ProcfsBasedProcessTree getProcessTree() {\n    if (!pid.equals(deadPid)) {\n      // Get the list of processes\n      List<String> processList = getProcessList();\n\n      Map<String, ProcessInfo> allProcessInfo = new HashMap<String, ProcessInfo>();\n      \n      // cache the processTree to get the age for processes\n      Map<String, ProcessInfo> oldProcs = \n              new HashMap<String, ProcessInfo>(processTree);\n      processTree.clear();\n\n      ProcessInfo me = null;\n      for (String proc : processList) {\n        // Get information for each process\n        ProcessInfo pInfo = new ProcessInfo(proc);\n        if (constructProcessInfo(pInfo, procfsDir) != null) {\n          allProcessInfo.put(proc, pInfo);\n          if (proc.equals(this.pid)) {\n            me = pInfo; // cache 'me'\n            processTree.put(proc, pInfo);\n          }\n        }\n      }\n\n      if (me == null) {\n        return this; \n      }\n\n      // Add each process to its parent.\n      for (Map.Entry<String, ProcessInfo> entry : allProcessInfo.entrySet()) {\n        String pID = entry.getKey();\n        if (!pID.equals(\"1\")) {\n          ProcessInfo pInfo = entry.getValue();\n          ProcessInfo parentPInfo = allProcessInfo.get(pInfo.getPpid());\n          if (parentPInfo != null) {\n            parentPInfo.addChild(pInfo);\n          }\n        }\n      }\n\n      // now start constructing the process-tree\n      LinkedList<ProcessInfo> pInfoQueue = new LinkedList<ProcessInfo>();\n      pInfoQueue.addAll(me.getChildren());\n      while (!pInfoQueue.isEmpty()) {\n        ProcessInfo pInfo = pInfoQueue.remove();\n        if (!processTree.containsKey(pInfo.getPid())) {\n          processTree.put(pInfo.getPid(), pInfo);\n        }\n        pInfoQueue.addAll(pInfo.getChildren());\n      }\n\n      // update age values and compute the number of jiffies since last update\n      for (Map.Entry<String, ProcessInfo> procs : processTree.entrySet()) {\n        ProcessInfo oldInfo = oldProcs.get(procs.getKey());\n        if (procs.getValue() != null) {\n          procs.getValue().updateJiffy(oldInfo);\n          if (oldInfo != null) {\n            procs.getValue().updateAge(oldInfo);  \n          }\n        }\n      }\n\n      if (LOG.isDebugEnabled()) {\n        // Log.debug the ProcfsBasedProcessTree\n        LOG.debug(this.toString());\n      }\n    }\n    return this;\n  }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.getPgrpId": {
                "code_before_change": [],
                "code_after_change": "    public Integer getPgrpId() {\n      return pgrpId;\n    }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.isAnyProcessInTreeAlive": {
                "code_before_change": [],
                "code_after_change": "  public boolean isAnyProcessInTreeAlive() {\n    for (String pId : processTree.keySet()) {\n      if (isAlive(pId)) {\n        return true;\n      }\n    }\n    return false;\n  }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.toString": {
                "code_before_change": [],
                "code_after_change": "  public String toString() {\n    StringBuffer pTree = new StringBuffer(\"[ \");\n    for (String p : processTree.keySet()) {\n      pTree.append(p);\n      pTree.append(\" \");\n    }\n    return pTree.substring(0, pTree.length()) + \"]\";\n  }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.isAvailable": {
                "code_before_change": [],
                "code_after_change": "  public static boolean isAvailable() {\n    try {\n      String osName = System.getProperty(\"os.name\");\n      if (!osName.startsWith(\"Linux\")) {\n        LOG.info(\"ProcfsBasedProcessTree currently is supported only on \"\n            + \"Linux.\");\n        return false;\n      }\n    } catch (SecurityException se) {\n      LOG.warn(\"Failed to get Operating System name. \" + se);\n      return false;\n    }\n    return true;\n  }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.isAlive": {
                "code_before_change": [],
                "code_after_change": "  public boolean isAlive() {\n    if (pid.equals(deadPid)) {\n      return false;\n    } else {\n      return isAlive(pid);\n    }\n  }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.constructProcessInfo": {
                "code_before_change": [],
                "code_after_change": "  private static ProcessInfo constructProcessInfo(ProcessInfo pinfo, \n                                                    String procfsDir) {\n    ProcessInfo ret = null;\n    // Read \"procfsDir/<pid>/stat\" file\n    BufferedReader in = null;\n    FileReader fReader = null;\n    try {\n      File pidDir = new File(procfsDir, pinfo.getPid());\n      fReader = new FileReader(new File(pidDir, PROCFS_STAT_FILE));\n      in = new BufferedReader(fReader);\n    } catch (FileNotFoundException f) {\n      // The process vanished in the interim!\n      return ret;\n    }\n\n    ret = pinfo;\n    try {\n      String str = in.readLine(); // only one line\n      Matcher m = PROCFS_STAT_FILE_FORMAT.matcher(str);\n      boolean mat = m.find();\n      if (mat) {\n        // Set (name) (ppid) (pgrpId) (session) (utime) (stime) (vsize) (rss)\n         pinfo.updateProcessInfo(m.group(2), m.group(3),\n                 Integer.parseInt(m.group(4)), Integer.parseInt(m.group(5)),\n                 Long.parseLong(m.group(7)), new BigInteger(m.group(8)),\n                 Long.parseLong(m.group(10)), Long.parseLong(m.group(11)));\n      }\n    } catch (IOException io) {\n      LOG.warn(\"Error reading the stream \" + io);\n      ret = null;\n    } finally {\n      // Close the streams\n      try {\n        fReader.close();\n        try {\n          in.close();\n        } catch (IOException i) {\n          LOG.warn(\"Error closing the stream \" + in);\n        }\n      } catch (IOException i) {\n        LOG.warn(\"Error closing the stream \" + fReader);\n      }\n    }\n\n    return ret;\n  }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.getCmdLine": {
                "code_before_change": [],
                "code_after_change": "    public String getCmdLine(String procfsDir) {\n      String ret = \"N/A\";\n      if (pid == null) {\n        return ret;\n      }\n      BufferedReader in = null;\n      FileReader fReader = null;\n      try {\n        fReader =\n            new FileReader(new File(new File(procfsDir, pid),\n                PROCFS_CMDLINE_FILE));\n      } catch (FileNotFoundException f) {\n        // The process vanished in the interim!\n        return ret;\n      }\n\n      in = new BufferedReader(fReader);\n\n      try {\n        ret = in.readLine(); // only one line\n        ret = ret.replace('\\0', ' '); // Replace each null char with a space\n        if (ret.equals(\"\")) {\n          // The cmdline might be empty because the process is swapped out or is\n          // a zombie.\n          ret = \"N/A\";\n        }\n      } catch (IOException io) {\n        LOG.warn(\"Error reading the stream \" + io);\n        ret = \"N/A\";\n      } finally {\n        // Close the streams\n        try {\n          fReader.close();\n          try {\n            in.close();\n          } catch (IOException i) {\n            LOG.warn(\"Error closing the stream \" + in);\n          }\n        } catch (IOException i) {\n          LOG.warn(\"Error closing the stream \" + fReader);\n        }\n      }\n\n      return ret;\n    }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.getAge": {
                "code_before_change": [],
                "code_after_change": "    public int getAge() {\n      return age;\n    }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.updateProcessInfo": {
                "code_before_change": [],
                "code_after_change": "    public void updateProcessInfo(String name, String ppid, Integer pgrpId,\n        Integer sessionId, Long utime, BigInteger stime, Long vmem, Long rssmem) {\n      this.name = name;\n      this.ppid = ppid;\n      this.pgrpId = pgrpId;\n      this.sessionId = sessionId;\n      this.utime = utime;\n      this.stime = stime;\n      this.vmem = vmem;\n      this.rssmemPage = rssmem;\n    }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.getUtime": {
                "code_before_change": [],
                "code_after_change": "    public Long getUtime() {\n      return utime;\n    }"
            },
            "src.core.org.apache.hadoop.util.ProcfsBasedProcessTree.getCumulativeCpuTime": {
                "code_before_change": [],
                "code_after_change": "  public long getCumulativeCpuTime() {\n    if (JIFFY_LENGTH_IN_MILLIS < 0) {\n      return 0;\n    }\n    long incJiffies = 0;\n    for (ProcessInfo p : processTree.values()) {\n      if (p != null) {\n        incJiffies += p.dtime;\n      }\n    }\n    cpuTime += incJiffies * JIFFY_LENGTH_IN_MILLIS;\n    return cpuTime;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the attempt to parse a 64-bit unsigned integer as a signed long in the method 'constructProcessInfo', which is a ground truth method. The fix suggestion to change the data structure from a long to a String is an alternative fix that would resolve the issue, although the developer's fix involved modifying the 'updateProcessInfo' method to accept a String for ppid. The problem location is precisely identified as it mentions 'constructProcessInfo', which is a ground truth method. There is no wrong information in the bug report as all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6410.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer.serviceInit": {
                "code_before_change": "  public void serviceInit(Configuration conf) throws Exception {\n    RPC.setProtocolEngine(conf, RefreshUserMappingsProtocolPB.class,\n        ProtobufRpcEngine.class);\n\n    RefreshUserMappingsProtocolServerSideTranslatorPB refreshUserMappingXlator = new RefreshUserMappingsProtocolServerSideTranslatorPB(\n        this);\n    BlockingService refreshUserMappingService = RefreshUserMappingsProtocolService\n        .newReflectiveBlockingService(refreshUserMappingXlator);\n\n    GetUserMappingsProtocolServerSideTranslatorPB getUserMappingXlator = new GetUserMappingsProtocolServerSideTranslatorPB(\n        this);\n    BlockingService getUserMappingService = GetUserMappingsProtocolService\n        .newReflectiveBlockingService(getUserMappingXlator);\n\n    HSAdminRefreshProtocolServerSideTranslatorPB refreshHSAdminProtocolXlator = new HSAdminRefreshProtocolServerSideTranslatorPB(\n        this);\n    BlockingService refreshHSAdminProtocolService = HSAdminRefreshProtocolService\n        .newReflectiveBlockingService(refreshHSAdminProtocolXlator);\n\n    WritableRpcEngine.ensureInitialized();\n\n    clientRpcAddress = conf.getSocketAddr(\n        JHAdminConfig.MR_HISTORY_BIND_HOST,\n        JHAdminConfig.JHS_ADMIN_ADDRESS,\n        JHAdminConfig.DEFAULT_JHS_ADMIN_ADDRESS,\n        JHAdminConfig.DEFAULT_JHS_ADMIN_PORT);\n    clientRpcServer = new RPC.Builder(conf)\n        .setProtocol(RefreshUserMappingsProtocolPB.class)\n        .setInstance(refreshUserMappingService)\n        .setBindAddress(clientRpcAddress.getHostName())\n        .setPort(clientRpcAddress.getPort()).setVerbose(false).build();\n\n    addProtocol(conf, GetUserMappingsProtocolPB.class, getUserMappingService);\n    addProtocol(conf, HSAdminRefreshProtocolPB.class,\n        refreshHSAdminProtocolService);\n\n    // Enable service authorization?\n    if (conf.getBoolean(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n        false)) {\n      clientRpcServer.refreshServiceAcl(conf, new ClientHSPolicyProvider());\n    }\n\n    adminAcl = new AccessControlList(conf.get(JHAdminConfig.JHS_ADMIN_ACL,\n        JHAdminConfig.DEFAULT_JHS_ADMIN_ACL));\n\n  }",
                "code_after_change": "  public void serviceInit(Configuration conf) throws Exception {\n    RPC.setProtocolEngine(conf, RefreshUserMappingsProtocolPB.class,\n        ProtobufRpcEngine.class);\n\n    RefreshUserMappingsProtocolServerSideTranslatorPB refreshUserMappingXlator = new RefreshUserMappingsProtocolServerSideTranslatorPB(\n        this);\n    BlockingService refreshUserMappingService = RefreshUserMappingsProtocolService\n        .newReflectiveBlockingService(refreshUserMappingXlator);\n\n    GetUserMappingsProtocolServerSideTranslatorPB getUserMappingXlator = new GetUserMappingsProtocolServerSideTranslatorPB(\n        this);\n    BlockingService getUserMappingService = GetUserMappingsProtocolService\n        .newReflectiveBlockingService(getUserMappingXlator);\n\n    HSAdminRefreshProtocolServerSideTranslatorPB refreshHSAdminProtocolXlator = new HSAdminRefreshProtocolServerSideTranslatorPB(\n        this);\n    BlockingService refreshHSAdminProtocolService = HSAdminRefreshProtocolService\n        .newReflectiveBlockingService(refreshHSAdminProtocolXlator);\n\n    WritableRpcEngine.ensureInitialized();\n\n    clientRpcAddress = conf.getSocketAddr(\n        JHAdminConfig.MR_HISTORY_BIND_HOST,\n        JHAdminConfig.JHS_ADMIN_ADDRESS,\n        JHAdminConfig.DEFAULT_JHS_ADMIN_ADDRESS,\n        JHAdminConfig.DEFAULT_JHS_ADMIN_PORT);\n    clientRpcServer = new RPC.Builder(conf)\n        .setProtocol(RefreshUserMappingsProtocolPB.class)\n        .setInstance(refreshUserMappingService)\n        .setBindAddress(clientRpcAddress.getHostName())\n        .setPort(clientRpcAddress.getPort()).setVerbose(false).build();\n\n    addProtocol(conf, GetUserMappingsProtocolPB.class, getUserMappingService);\n    addProtocol(conf, HSAdminRefreshProtocolPB.class,\n        refreshHSAdminProtocolService);\n\n    // Enable service authorization?\n    if (conf.getBoolean(\n        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n        false)) {\n      clientRpcServer.refreshServiceAcl(conf, new ClientHSPolicyProvider());\n    }\n\n    adminAcl = new AccessControlList(conf.get(JHAdminConfig.JHS_ADMIN_ACL,\n        JHAdminConfig.DEFAULT_JHS_ADMIN_ACL));\n\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer.refreshLoadedJobCache": {
                "code_before_change": "  public void refreshLoadedJobCache() throws IOException {\n    UserGroupInformation user = checkAcls(\"refreshLoadedJobCache\");\n\n    try {\n      jobHistoryService.refreshLoadedJobCache();\n    } catch (UnsupportedOperationException e) {\n      HSAuditLogger.logFailure(user.getShortUserName(),\n          \"refreshLoadedJobCache\", adminAcl.toString(), HISTORY_ADMIN_SERVER,\n          e.getMessage());\n      throw e;\n    }\n    HSAuditLogger.logSuccess(user.getShortUserName(), \"refreshLoadedJobCache\",\n        HISTORY_ADMIN_SERVER);\n  }",
                "code_after_change": "  public void refreshLoadedJobCache() throws IOException {\n    UserGroupInformation user = checkAcls(\"refreshLoadedJobCache\");\n\n    try {\n      jobHistoryService.refreshLoadedJobCache();\n    } catch (UnsupportedOperationException e) {\n      HSAuditLogger.logFailure(user.getShortUserName(),\n          \"refreshLoadedJobCache\", adminAcl.toString(), HISTORY_ADMIN_SERVER,\n          e.getMessage());\n      throw e;\n    }\n    HSAuditLogger.logSuccess(user.getShortUserName(), \"refreshLoadedJobCache\",\n        HISTORY_ADMIN_SERVER);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer.run": {
                "code_before_change": [],
                "code_after_change": "        public Void run() throws IOException {\n          aggLogDelService.refreshLogRetentionSettings();\n          return null;\n        }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Shared Stack Trace Context"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the failure to obtain valid Kerberos credentials as the root cause, which is related to the secure communication issue but does not precisely point to the ground truth methods. The methods mentioned in the problem location are part of the stack trace, indicating a shared context but not the exact location of the fix. The fix suggestion involves ensuring valid Kerberos credentials, which is a preventive measure to avoid the issue. There is no incorrect information in the bug report."
        }
    },
    {
        "filename": "MAPREDUCE-6693.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-common.src.main.java.org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.trimURLEncodedString": {
                "code_before_change": "  private static String trimURLEncodedString(\n      String encodedString, int limitLength) {\n    assert(limitLength >= 0) : \"limitLength should be positive integer\";\n\n    if (encodedString.length() < limitLength) {\n      return encodedString;\n    }\n\n    int index = 0;\n    int increase = 0;\n    byte[] strBytes = encodedString.getBytes(UTF_8);\n\n    // calculate effective character length based on UTF-8 specification.\n    // The size of a character coded in UTF-8 should be 4-byte at most.\n    // See RFC3629\n    while (true) {\n      byte b = strBytes[index];\n      if (b == '%') {\n        byte minuend1 = strBytes[index + 1];\n        byte subtrahend1 = (byte)(Character.isDigit(\n            minuend1) ? '0' : 'A' - 10);\n        byte minuend2 = strBytes[index + 2];\n        byte subtrahend2 = (byte)(Character.isDigit(\n            minuend2) ? '0' : 'A' - 10);\n        int initialHex =\n            ((Character.toUpperCase(minuend1) - subtrahend1) << 4) +\n            (Character.toUpperCase(minuend2) - subtrahend2);\n\n        if (0x00 <= initialHex && initialHex <= 0x7F) {\n          // For 1-byte UTF-8 characters\n          increase = 3;\n        } else if (0xC2 <= initialHex && initialHex <= 0xDF) {\n          // For 2-byte UTF-8 characters\n          increase = 6;\n        } else if (0xE0 <= initialHex && initialHex <= 0xEF) {\n          // For 3-byte UTF-8 characters\n          increase = 9;\n        } else {\n          // For 4-byte UTF-8 characters\n          increase = 12;\n        }\n      } else {\n        increase = 1;\n      }\n      if (index + increase > limitLength) {\n        break;\n      } else {\n        index += increase;\n      }\n    }\n\n    return encodedString.substring(0, index);\n  }",
                "code_after_change": "  private static String trimURLEncodedString(\n      String encodedString, int limitLength) {\n    assert(limitLength >= 0) : \"limitLength should be positive integer\";\n\n    if (encodedString.length() <= limitLength) {\n      return encodedString;\n    }\n\n    int index = 0;\n    int increase = 0;\n    byte[] strBytes = encodedString.getBytes(UTF_8);\n\n    // calculate effective character length based on UTF-8 specification.\n    // The size of a character coded in UTF-8 should be 4-byte at most.\n    // See RFC3629\n    while (true) {\n      byte b = strBytes[index];\n      if (b == '%') {\n        byte minuend1 = strBytes[index + 1];\n        byte subtrahend1 = (byte)(Character.isDigit(\n            minuend1) ? '0' : 'A' - 10);\n        byte minuend2 = strBytes[index + 2];\n        byte subtrahend2 = (byte)(Character.isDigit(\n            minuend2) ? '0' : 'A' - 10);\n        int initialHex =\n            ((Character.toUpperCase(minuend1) - subtrahend1) << 4) +\n            (Character.toUpperCase(minuend2) - subtrahend2);\n\n        if (0x00 <= initialHex && initialHex <= 0x7F) {\n          // For 1-byte UTF-8 characters\n          increase = 3;\n        } else if (0xC2 <= initialHex && initialHex <= 0xDF) {\n          // For 2-byte UTF-8 characters\n          increase = 6;\n        } else if (0xE0 <= initialHex && initialHex <= 0xEF) {\n          // For 3-byte UTF-8 characters\n          increase = 9;\n        } else {\n          // For 4-byte UTF-8 characters\n          increase = 12;\n        }\n      } else {\n        increase = 1;\n      }\n      if (index + increase > limitLength) {\n        break;\n      } else {\n        index += increase;\n      }\n    }\n\n    return encodedString.substring(0, index);\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as being in the 'trimURLEncodedString' method, which matches the ground truth method. The fix suggestion in the report is correct as it aligns with the developer's fix, which involves adjusting the condition to handle cases where the encoded string length is equal to the limit. The problem location is also precisely identified, as the 'problem_location' field includes the 'trimURLEncodedString' method, which is the ground truth method. There is no wrong information in the bug report; all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5912.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.Task.calculateOutputSize": {
                "code_before_change": "   private long calculateOutputSize() throws IOException {\n    if (!isMapOrReduce()) {\n      return -1;\n    }\n\n    if (isMapTask() && conf.getNumReduceTasks() > 0) {\n      try {\n        Path mapOutput =  mapOutputFile.getOutputFile();\n        FileSystem fs = mapOutput.getFileSystem(conf);\n        return fs.getFileStatus(mapOutput).getLen();\n      } catch (IOException e) {\n        LOG.warn (\"Could not find output size \" , e);\n      }\n    }\n    return -1;\n  }",
                "code_after_change": "   private long calculateOutputSize() throws IOException {\n    if (!isMapOrReduce()) {\n      return -1;\n    }\n\n    if (isMapTask() && conf.getNumReduceTasks() > 0) {\n      try {\n        Path mapOutput =  mapOutputFile.getOutputFile();\n        FileSystem localFS = FileSystem.getLocal(conf);\n        return localFS.getFileStatus(mapOutput).getLen();\n      } catch (IOException e) {\n        LOG.warn (\"Could not find output size \" , e);\n      }\n    }\n    return -1;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the method `calculateOutputSize` using the wrong filesystem, which matches the ground truth method. The fix suggestion is correct as it aligns with the developer's fix, which involves using the local filesystem for local paths. The problem location is also precise, as it directly mentions the method `Task.calculateOutputSize`, which is the ground truth method. There is no wrong information in the bug report; all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5952.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.LocalContainerLauncher.runSubtask": {
                "code_before_change": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map<TaskAttemptID, MapOutputFile> localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID =\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf = new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType == TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM's local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs = StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType == TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map = (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps == numMapTasks) {\n            doneWithMaps = true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn't send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce = (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task != null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause = throwable.getCause();\n        String cause = (tCause == null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }",
                "code_after_change": "    private void runSubtask(org.apache.hadoop.mapred.Task task,\n                            final TaskType taskType,\n                            TaskAttemptId attemptID,\n                            final int numMapTasks,\n                            boolean renameOutputs,\n                            Map<TaskAttemptID, MapOutputFile> localMapFiles)\n    throws RuntimeException, IOException {\n      org.apache.hadoop.mapred.TaskAttemptID classicAttemptID =\n          TypeConverter.fromYarn(attemptID);\n\n      try {\n        JobConf conf = new JobConf(getConfig());\n        conf.set(JobContext.TASK_ID, task.getTaskID().toString());\n        conf.set(JobContext.TASK_ATTEMPT_ID, classicAttemptID.toString());\n        conf.setBoolean(JobContext.TASK_ISMAP, (taskType == TaskType.MAP));\n        conf.setInt(JobContext.TASK_PARTITION, task.getPartition());\n        conf.set(JobContext.ID, task.getJobID().toString());\n\n        // Use the AM's local dir env to generate the intermediate step \n        // output files\n        String[] localSysDirs = StringUtils.getTrimmedStrings(\n            System.getenv(Environment.LOCAL_DIRS.name()));\n        conf.setStrings(MRConfig.LOCAL_DIR, localSysDirs);\n        LOG.info(MRConfig.LOCAL_DIR + \" for uber task: \"\n            + conf.get(MRConfig.LOCAL_DIR));\n\n        // mark this as an uberized subtask so it can set task counter\n        // (longer-term/FIXME:  could redefine as job counter and send\n        // \"JobCounterEvent\" to JobImpl on [successful] completion of subtask;\n        // will need new Job state-machine transition and JobImpl jobCounters\n        // map to handle)\n        conf.setBoolean(\"mapreduce.task.uberized\", true);\n\n        // META-FIXME: do we want the extra sanity-checking (doneWithMaps,\n        // etc.), or just assume/hope the state machine(s) and uber-AM work\n        // as expected?\n        if (taskType == TaskType.MAP) {\n          if (doneWithMaps) {\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a map task (\"\n                      + attemptID + \"), but should be finished with maps\");\n            throw new RuntimeException();\n          }\n\n          MapTask map = (MapTask)task;\n          map.setConf(conf);\n\n          map.run(conf, umbilical);\n\n          if (renameOutputs) {\n            MapOutputFile renamed = renameMapOutputForReduce(conf, attemptID,\n                map.getMapOutputFile());\n            localMapFiles.put(classicAttemptID, renamed);\n          }\n          relocalize();\n\n          if (++finishedSubMaps == numMapTasks) {\n            doneWithMaps = true;\n          }\n\n        } else /* TaskType.REDUCE */ {\n\n          if (!doneWithMaps) {\n            // check if event-queue empty?  whole idea of counting maps vs. \n            // checking event queue is a tad wacky...but could enforce ordering\n            // (assuming no \"lost events\") at LocalMRAppMaster [CURRENT BUG(?): \n            // doesn't send reduce event until maps all done]\n            LOG.error(\"CONTAINER_REMOTE_LAUNCH contains a reduce task (\"\n                      + attemptID + \"), but not yet finished with maps\");\n            throw new RuntimeException();\n          }\n\n          // a.k.a. \"mapreduce.jobtracker.address\" in LocalJobRunner:\n          // set framework name to local to make task local\n          conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n          conf.set(MRConfig.MASTER_ADDRESS, \"local\");  // bypass shuffle\n\n          ReduceTask reduce = (ReduceTask)task;\n          reduce.setLocalMapFiles(localMapFiles);\n          reduce.setConf(conf);          \n\n          reduce.run(conf, umbilical);\n          relocalize();\n        }\n\n      } catch (FSError e) {\n        LOG.fatal(\"FSError from child\", e);\n        // umbilical:  MRAppMaster creates (taskAttemptListener), passes to us\n        umbilical.fsError(classicAttemptID, e.getMessage());\n        throw new RuntimeException();\n\n      } catch (Exception exception) {\n        LOG.warn(\"Exception running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(exception));\n        try {\n          if (task != null) {\n            // do cleanup for the task\n            task.taskCleanup(umbilical);\n          }\n        } catch (Exception e) {\n          LOG.info(\"Exception cleaning up: \"\n              + StringUtils.stringifyException(e));\n        }\n        // Report back any failures, for diagnostic purposes\n        umbilical.reportDiagnosticInfo(classicAttemptID, \n            StringUtils.stringifyException(exception));\n        throw new RuntimeException();\n\n      } catch (Throwable throwable) {\n        LOG.fatal(\"Error running local (uberized) 'child' : \"\n            + StringUtils.stringifyException(throwable));\n        Throwable tCause = throwable.getCause();\n        String cause = (tCause == null)\n            ? throwable.getMessage()\n                : StringUtils.stringifyException(tCause);\n            umbilical.fatalError(classicAttemptID, cause);\n        throw new RuntimeException();\n      }\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.LocalContainerLauncher.relocalize": {
                "code_before_change": "    private void relocalize() {\n      File[] curLocalFiles = curDir.listFiles();\n      for (int j = 0; j < curLocalFiles.length; ++j) {\n        if (!localizedFiles.contains(curLocalFiles[j])) {\n          // found one that wasn't there before:  delete it\n          boolean deleted = false;\n          try {\n            if (curFC != null) {\n              // this is recursive, unlike File delete():\n              deleted = curFC.delete(new Path(curLocalFiles[j].getName()),true);\n            }\n          } catch (IOException e) {\n            deleted = false;\n          }\n          if (!deleted) {\n            LOG.warn(\"Unable to delete unexpected local file/dir \"\n                + curLocalFiles[j].getName() + \": insufficient permissions?\");\n          }\n        }\n      }\n    }",
                "code_after_change": "    private void relocalize() {\n      File[] curLocalFiles = curDir.listFiles();\n      for (int j = 0; j < curLocalFiles.length; ++j) {\n        if (!localizedFiles.contains(curLocalFiles[j])) {\n          // found one that wasn't there before:  delete it\n          boolean deleted = false;\n          try {\n            if (curFC != null) {\n              // this is recursive, unlike File delete():\n              deleted = curFC.delete(new Path(curLocalFiles[j].getName()),true);\n            }\n          } catch (IOException e) {\n            deleted = false;\n          }\n          if (!deleted) {\n            LOG.warn(\"Unable to delete unexpected local file/dir \"\n                + curLocalFiles[j].getName() + \": insufficient permissions?\");\n          }\n        }\n      }\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the method 'renameMapOutputForReduce' as the location of the issue, which is where the error occurs, but not where the actual fix was made. Therefore, it is classified as 'Partial' under 'Buggy Method' for both root cause identification and problem location identification. The fix suggestion in the bug report suggests updating the 'renameMapOutputForReduce' method to handle multiple output directories, which is an alternative approach to resolving the issue, as the actual fix was made in 'runSubtask' and 'relocalize' methods. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3306.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.transition": {
                "code_before_change": "    public void transition(ApplicationImpl app, ApplicationEvent event) {\n      ApplicationInitEvent initEvent = (ApplicationInitEvent)event;\n      app.aclsManager.addApplication(app.getAppId(), initEvent\n          .getApplicationACLs());\n      app.dispatcher.getEventHandler().handle(\n          new ApplicationLocalizationEvent(\n              LocalizationEventType.INIT_APPLICATION_RESOURCES, app));\n    }",
                "code_after_change": "    public void transition(ApplicationImpl app, ApplicationEvent event) {\n      ApplicationInitEvent initEvent = (ApplicationInitEvent)event;\n      app.applicationACLs = initEvent.getApplicationACLs();\n      app.aclsManager.addApplication(app.getAppId(), app.applicationACLs);\n      app.dispatcher.getEventHandler().handle(\n          new ApplicationLocalizationEvent(\n              LocalizationEventType.INIT_APPLICATION_RESOURCES, app));\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as a NoSuchElementException in the AsyncDispatcher, which is related to the issue but not the exact root cause in the ground truth method. It points to the method where the error occurred, but not where the actual fix was made, hence 'Buggy Method'. The fix suggestion involves adding checks to prevent the error, which is preventive but not the exact fix applied by the developer. The problem location mentions methods related to the issue but not the exact ground truth method, again pointing to the 'Buggy Method'. There is no wrong information as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-6554.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.jobhistory.EventReader.EventReader": {
                "code_before_change": [],
                "code_after_change": []
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapreduce.jobhistory.EventReader.init": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Direct Caller/Callee"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Direct Caller/Callee"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the `getPreviousJobHistoryStream` method returning a null stream, which is then passed to `JobHistoryParser`. This is a direct caller of the `EventReader` constructor, where the actual fix was made, hence 'Partial' with 'Direct Caller/Callee'. The fix suggestion involves adding null checks, which is preventive as it would mitigate the bug by preventing null streams from causing issues. The problem location mentions `MRAppMaster.parsePreviousJobHistory` and `JobHistoryParser.parse`, which are direct callers of the ground truth method `EventReader.EventReader`, thus 'Partial' with 'Direct Caller/Callee'. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4457.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.transition": {
                "code_before_change": "    public JobState transition(JobImpl job, JobEvent event) {\n      job.metrics.submittedJob(job);\n      job.metrics.preparingJob(job);\n      try {\n        setup(job);\n        job.fs = job.getFileSystem(job.conf);\n\n        //log to job history\n        JobSubmittedEvent jse = new JobSubmittedEvent(job.oldJobId,\n              job.conf.get(MRJobConfig.JOB_NAME, \"test\"), \n            job.conf.get(MRJobConfig.USER_NAME, \"mapred\"),\n            job.appSubmitTime,\n            job.remoteJobConfFile.toString(),\n            job.jobACLs, job.queueName);\n        job.eventHandler.handle(new JobHistoryEvent(job.jobId, jse));\n        //TODO JH Verify jobACLs, UserName via UGI?\n\n        TaskSplitMetaInfo[] taskSplitMetaInfo = createSplits(job, job.jobId);\n        job.numMapTasks = taskSplitMetaInfo.length;\n        job.numReduceTasks = job.conf.getInt(MRJobConfig.NUM_REDUCES, 0);\n\n        if (job.numMapTasks == 0 && job.numReduceTasks == 0) {\n          job.addDiagnostic(\"No of maps and reduces are 0 \" + job.jobId);\n        } else if (job.numMapTasks == 0) {\n          job.reduceWeight = 0.9f;\n        } else if (job.numReduceTasks == 0) {\n          job.mapWeight = 0.9f;\n        } else {\n          job.mapWeight = job.reduceWeight = 0.45f;\n        }\n\n        checkTaskLimits();\n\n        if (job.newApiCommitter) {\n          job.jobContext = new JobContextImpl(job.conf,\n              job.oldJobId);\n        } else {\n          job.jobContext = new org.apache.hadoop.mapred.JobContextImpl(\n              job.conf, job.oldJobId);\n        }\n        \n        long inputLength = 0;\n        for (int i = 0; i < job.numMapTasks; ++i) {\n          inputLength += taskSplitMetaInfo[i].getInputDataLength();\n        }\n\n        job.makeUberDecision(inputLength);\n        \n        job.taskAttemptCompletionEvents =\n            new ArrayList<TaskAttemptCompletionEvent>(\n                job.numMapTasks + job.numReduceTasks + 10);\n\n        job.allowedMapFailuresPercent =\n            job.conf.getInt(MRJobConfig.MAP_FAILURES_MAX_PERCENT, 0);\n        job.allowedReduceFailuresPercent =\n            job.conf.getInt(MRJobConfig.REDUCE_FAILURES_MAXPERCENT, 0);\n\n        // do the setup\n        job.committer.setupJob(job.jobContext);\n        job.setupProgress = 1.0f;\n\n        // create the Tasks but don't start them yet\n        createMapTasks(job, inputLength, taskSplitMetaInfo);\n        createReduceTasks(job);\n\n        job.metrics.endPreparingJob(job);\n        return JobState.INITED;\n        //TODO XXX Should JobInitedEvent be generated here (instead of in StartTransition)\n\n      } catch (IOException e) {\n        LOG.warn(\"Job init failed\", e);\n        job.addDiagnostic(\"Job init failed : \"\n            + StringUtils.stringifyException(e));\n        job.abortJob(org.apache.hadoop.mapreduce.JobStatus.State.FAILED);\n        job.metrics.endPreparingJob(job);\n        return job.finished(JobState.FAILED);\n      }\n    }",
                "code_after_change": "    public JobState transition(JobImpl job, JobEvent event) {\n      job.metrics.submittedJob(job);\n      job.metrics.preparingJob(job);\n      try {\n        setup(job);\n        job.fs = job.getFileSystem(job.conf);\n\n        //log to job history\n        JobSubmittedEvent jse = new JobSubmittedEvent(job.oldJobId,\n              job.conf.get(MRJobConfig.JOB_NAME, \"test\"), \n            job.conf.get(MRJobConfig.USER_NAME, \"mapred\"),\n            job.appSubmitTime,\n            job.remoteJobConfFile.toString(),\n            job.jobACLs, job.queueName);\n        job.eventHandler.handle(new JobHistoryEvent(job.jobId, jse));\n        //TODO JH Verify jobACLs, UserName via UGI?\n\n        TaskSplitMetaInfo[] taskSplitMetaInfo = createSplits(job, job.jobId);\n        job.numMapTasks = taskSplitMetaInfo.length;\n        job.numReduceTasks = job.conf.getInt(MRJobConfig.NUM_REDUCES, 0);\n\n        if (job.numMapTasks == 0 && job.numReduceTasks == 0) {\n          job.addDiagnostic(\"No of maps and reduces are 0 \" + job.jobId);\n        } else if (job.numMapTasks == 0) {\n          job.reduceWeight = 0.9f;\n        } else if (job.numReduceTasks == 0) {\n          job.mapWeight = 0.9f;\n        } else {\n          job.mapWeight = job.reduceWeight = 0.45f;\n        }\n\n        checkTaskLimits();\n\n        if (job.newApiCommitter) {\n          job.jobContext = new JobContextImpl(job.conf,\n              job.oldJobId);\n        } else {\n          job.jobContext = new org.apache.hadoop.mapred.JobContextImpl(\n              job.conf, job.oldJobId);\n        }\n        \n        long inputLength = 0;\n        for (int i = 0; i < job.numMapTasks; ++i) {\n          inputLength += taskSplitMetaInfo[i].getInputDataLength();\n        }\n\n        job.makeUberDecision(inputLength);\n        \n        job.taskAttemptCompletionEvents =\n            new ArrayList<TaskAttemptCompletionEvent>(\n                job.numMapTasks + job.numReduceTasks + 10);\n\n        job.allowedMapFailuresPercent =\n            job.conf.getInt(MRJobConfig.MAP_FAILURES_MAX_PERCENT, 0);\n        job.allowedReduceFailuresPercent =\n            job.conf.getInt(MRJobConfig.REDUCE_FAILURES_MAXPERCENT, 0);\n\n        // do the setup\n        job.committer.setupJob(job.jobContext);\n        job.setupProgress = 1.0f;\n\n        // create the Tasks but don't start them yet\n        createMapTasks(job, inputLength, taskSplitMetaInfo);\n        createReduceTasks(job);\n\n        job.metrics.endPreparingJob(job);\n        return JobState.INITED;\n        //TODO XXX Should JobInitedEvent be generated here (instead of in StartTransition)\n\n      } catch (IOException e) {\n        LOG.warn(\"Job init failed\", e);\n        job.addDiagnostic(\"Job init failed : \"\n            + StringUtils.stringifyException(e));\n        job.abortJob(org.apache.hadoop.mapreduce.JobStatus.State.FAILED);\n        job.metrics.endPreparingJob(job);\n        return job.finished(JobState.FAILED);\n      }\n    }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.TaskCleanupTransition": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the handling of multiple TA_TOO_MANY_FETCH_FAILURE events in the TaskAttemptImpl.handle method, which is where the error occurs but not where the actual fix was made. Thus, it is classified as 'Partial' under 'Buggy Method'. The fix suggestion to add a condition in TaskAttemptImpl.handle to check if the current state is FAILED is preventive, as it would mitigate the issue by preventing the invalid state transition. The problem location is identified as TaskAttemptImpl.handle, which is the method where the error occurs, but not where the actual fix was made, so it is 'Partial' under 'Buggy Method'. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-2716.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ResourceMgrDelegate.getAllJobs": {
                "code_before_change": [],
                "code_after_change": "  public JobStatus[] getAllJobs() throws IOException, InterruptedException {\n    GetAllApplicationsRequest request =\n      recordFactory.newRecordInstance(GetAllApplicationsRequest.class);\n    GetAllApplicationsResponse response = \n      applicationsManager.getAllApplications(request);\n    return TypeConverter.fromYarnApps(response.getApplicationList(), this.conf);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ResourceMgrDelegate.getQueue": {
                "code_before_change": [],
                "code_after_change": "  public QueueInfo getQueue(String queueName) throws IOException,\n  InterruptedException {\n    GetQueueInfoRequest request = \n      getQueueInfoRequest(queueName, true, false, false); \n      recordFactory.newRecordInstance(GetQueueInfoRequest.class);\n    return TypeConverter.fromYarn(\n        applicationsManager.getQueueInfo(request).getQueueInfo(), this.conf);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-common.src.main.java.org.apache.hadoop.mapreduce.TypeConverter.toYarn": {
                "code_before_change": [],
                "code_after_change": "  public static JobId toYarn(org.apache.hadoop.mapreduce.JobID id) {\n    JobId jobId = recordFactory.newRecordInstance(JobId.class);\n    jobId.setId(id.getId()); //currently there is 1-1 mapping between appid and jobid\n    \n    ApplicationId appId = recordFactory.newRecordInstance(ApplicationId.class);\n    appId.setId(id.getId());\n    appId.setClusterTimestamp(toClusterTimeStamp(id.getJtIdentifier()));\n    jobId.setAppId(appId);\n    return jobId;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-common.src.main.java.org.apache.hadoop.mapreduce.TypeConverter.fromYarnNodes": {
                "code_before_change": [],
                "code_after_change": "  public static TaskTrackerInfo[] fromYarnNodes(List<NodeReport> nodes) {\n    List<TaskTrackerInfo> taskTrackers = new ArrayList<TaskTrackerInfo>();\n    for (NodeReport node : nodes) {\n      taskTrackers.add(fromYarn(node));\n    }\n    return taskTrackers.toArray(new TaskTrackerInfo[nodes.size()]);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ResourceMgrDelegate.getChildQueues": {
                "code_before_change": [],
                "code_after_change": "  private void getChildQueues(org.apache.hadoop.yarn.api.records.QueueInfo parent, \n      List<org.apache.hadoop.yarn.api.records.QueueInfo> queues) {\n    List<org.apache.hadoop.yarn.api.records.QueueInfo> childQueues = \n      parent.getChildQueues();\n\n    for (org.apache.hadoop.yarn.api.records.QueueInfo child : childQueues) {\n      queues.add(child);\n      getChildQueues(child, queues);\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ResourceMgrDelegate.getQueues": {
                "code_before_change": [],
                "code_after_change": "  public QueueInfo[] getQueues() throws IOException, InterruptedException {\n    List<org.apache.hadoop.yarn.api.records.QueueInfo> queues = \n      new ArrayList<org.apache.hadoop.yarn.api.records.QueueInfo>();\n\n    org.apache.hadoop.yarn.api.records.QueueInfo rootQueue = \n      applicationsManager.getQueueInfo(\n          getQueueInfoRequest(ROOT, false, true, true)).getQueueInfo();\n    getChildQueues(rootQueue, queues);\n\n    return TypeConverter.fromYarnQueueInfo(queues, this.conf);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ResourceMgrDelegate.getRootQueues": {
                "code_before_change": [],
                "code_after_change": "  public QueueInfo[] getRootQueues() throws IOException, InterruptedException {\n    List<org.apache.hadoop.yarn.api.records.QueueInfo> queues = \n      new ArrayList<org.apache.hadoop.yarn.api.records.QueueInfo>();\n\n    org.apache.hadoop.yarn.api.records.QueueInfo rootQueue = \n      applicationsManager.getQueueInfo(\n          getQueueInfoRequest(ROOT, false, true, false)).getQueueInfo();\n    getChildQueues(rootQueue, queues);\n\n    return TypeConverter.fromYarnQueueInfo(queues, this.conf);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-common.src.main.java.org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobReportPBImpl.setFinishTime": {
                "code_before_change": [],
                "code_after_change": "  public void setFinishTime(long finishTime) {\n    maybeInitBuilder();\n    builder.setFinishTime((finishTime));\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getReport": {
                "code_before_change": [],
                "code_after_change": "  public JobReport getReport() {\n    readLock.lock();\n    try {\n      JobReport report = recordFactory.newRecordInstance(JobReport.class);\n      report.setJobId(jobId);\n      report.setJobState(getState());\n      \n      // TODO - Fix to correctly setup report and to check state\n      if (report.getJobState() == JobState.NEW) {\n        return report;\n      }\n      \n      report.setStartTime(startTime);\n      report.setFinishTime(finishTime);\n      report.setSetupProgress(setupProgress);\n      report.setCleanupProgress(cleanupProgress);\n      report.setMapProgress(computeProgress(mapTasks));\n      report.setReduceProgress(computeProgress(reduceTasks));\n      report.setJobName(jobName);\n      report.setUser(username);\n\n      return report;\n    } finally {\n      readLock.unlock();\n    }\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ClientServiceDelegate.getProxy": {
                "code_before_change": [],
                "code_after_change": "  private MRClientProtocol getProxy() throws YarnRemoteException {\n    if (!forceRefresh && realProxy != null) {\n      return realProxy;\n    }\n      //TODO RM NPEs for unknown jobs. History may still be aware.\n    // Possibly allow nulls through the PB tunnel, otherwise deal with an exception\n    // and redirect to the history server.\n    ApplicationReport application = rm.getApplicationReport(appId);\n    String serviceAddr = null;\n    while (ApplicationState.RUNNING.equals(application.getState())) {\n      try {\n        if (application.getHost() == null || \"\".equals(application.getHost())) {\n          LOG.debug(\"AM not assigned to Job. Waiting to get the AM ...\");\n          Thread.sleep(2000);\n   \n          LOG.debug(\"Application state is \" + application.getState());\n          application = rm.getApplicationReport(appId);\n          continue;\n        }\n        serviceAddr = application.getHost() + \":\" + application.getRpcPort();\n        if (UserGroupInformation.isSecurityEnabled()) {\n          String clientTokenEncoded = application.getClientToken();\n          Token<ApplicationTokenIdentifier> clientToken =\n            new Token<ApplicationTokenIdentifier>();\n          clientToken.decodeFromUrlString(clientTokenEncoded);\n          clientToken.setService(new Text(application.getHost() + \":\"\n              + application.getRpcPort()));\n          UserGroupInformation.getCurrentUser().addToken(clientToken);\n        }\n        LOG.info(\"Tracking Url of JOB is \" + application.getTrackingUrl());\n        LOG.info(\"Connecting to \" + serviceAddr);\n        instantiateAMProxy(serviceAddr);\n        return realProxy;\n      } catch (Exception e) {\n        //possibly\n        //possibly the AM has crashed\n        //there may be some time before AM is restarted\n        //keep retrying by getting the address from RM\n        LOG.info(\"Could not connect to \" + serviceAddr + \n        \". Waiting for getting the latest AM address...\");\n        try {\n          Thread.sleep(2000);\n        } catch (InterruptedException e1) {\n        }\n        application = rm.getApplicationReport(appId);\n      }\n    }\n\n    /** we just want to return if its allocating, so that we don't\n     * block on it. This is to be able to return job status \n     * on an allocating Application.\n     */\n    \n    String user = application.getUser();\n    if (user == null) {\n      throw new YarnRemoteExceptionPBImpl(\"User is not set in the application report\");\n    }\n    if (application.getState() == ApplicationState.NEW ||\n        application.getState() == ApplicationState.SUBMITTED) {\n      realProxy = null;\n      return getNotRunningJob(user, JobState.NEW);\n    }\n    \n    if (application.getState() == ApplicationState.FAILED) {\n      realProxy = null;\n      return getNotRunningJob(user, JobState.FAILED);\n    }\n    \n    if (application.getState() == ApplicationState.KILLED) {\n      realProxy = null;\n      return getNotRunningJob(user, JobState.KILLED);\n    }\n    \n    //History server can serve a job only if application \n    //succeeded.\n    if (application.getState() == ApplicationState.SUCCEEDED) {\n      LOG.info(\"Application state is completed. \" +\n          \"Redirecting to job history server \" + serviceAddr);\n      realProxy = historyServerProxy;\n    }\n    return realProxy;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.NotRunningJob.getJobReport": {
                "code_before_change": [],
                "code_after_change": "  public GetJobReportResponse getJobReport(GetJobReportRequest request)\n      throws YarnRemoteException {\n    GetJobReportResponse resp = \n      recordFactory.newRecordInstance(GetJobReportResponse.class);\n    JobReport jobReport =\n      recordFactory.newRecordInstance(JobReport.class);\n    jobReport.setJobId(request.getJobId());\n    jobReport.setJobState(this.jobState);\n\n    jobReport.setUser(this.user);\n    // TODO: Add jobName & other job information that is available\n    resp.setJobReport(jobReport);\n    return resp;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-common.src.main.java.org.apache.hadoop.mapreduce.v2.util.MRApps.addToClassPath": {
                "code_before_change": [],
                "code_after_change": "  public static void addToClassPath(\n      Map<String, String> environment, String fileName) {\n    String classpath = environment.get(CLASSPATH);\n    if (classpath == null) {\n      classpath = fileName;\n    } else {\n      classpath = classpath + \":\" + fileName;\n    }\n    environment.put(CLASSPATH, classpath);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ClientServiceDelegate.getTaskDiagnostics": {
                "code_before_change": [],
                "code_after_change": "  String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0)\n      throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID = TypeConverter\n        .toYarn(arg0);\n    GetDiagnosticsRequest request = recordFactory\n        .newRecordInstance(GetDiagnosticsRequest.class);\n    request.setTaskAttemptId(attemptID);\n    List<String> list = ((GetDiagnosticsResponse) invoke(\"getDiagnostics\",\n        GetDiagnosticsRequest.class, request)).getDiagnosticsList();\n    String[] result = new String[list.size()];\n    int i = 0;\n    for (String c : list) {\n      result[i++] = c.toString();\n    }\n    return result;\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.CompletedJob.CompletedJob": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Same Class or Module"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Same Class or Module"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the jobFile being hardcoded to an empty string in TypeConverter.java, which is in the same class/module as the ground truth method TypeConverter.toYarn. The fix suggestion to modify TypeConverter.java to ensure the jobFile is set to a valid HDFS path is an alternative fix, as it addresses the issue but does not match the exact changes made in the ground truth methods. The problem location identification is partial, as it mentions TypeConverter.getJobFile, which is in the same class/module as the ground truth method TypeConverter.toYarn. There is no wrong information in the bug report, as all statements are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-4748.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.RetroactiveKilledTransition": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the issue as occurring in the 'TaskImpl.handle' method, which is where the error manifests, but not where the actual fix was made ('RetroactiveKilledTransition'). Therefore, it is classified as 'Partial' under 'Buggy Method' for both root cause and problem location identification. The fix suggestion is 'Preventive' as it suggests adding checks to prevent the transition, which would mitigate the issue. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-3062.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.init": {
                "code_before_change": "  public void init(Configuration conf) {\n    super.init(conf);\n    String bindAddress =\n      conf.get(YarnConfiguration.RM_ADMIN_ADDRESS,\n          YarnConfiguration.RM_ADMIN_ADDRESS);\n    masterServiceAddress =  NetUtils.createSocketAddr(bindAddress);\n    adminAcl = \n      new AccessControlList(\n          conf.get(YarnConfiguration.RM_ADMIN_ACL, YarnConfiguration.DEFAULT_RM_ADMIN_ACL));\n  }",
                "code_after_change": "  public void init(Configuration conf) {\n    super.init(conf);\n    String bindAddress =\n      conf.get(YarnConfiguration.RM_ADMIN_ADDRESS,\n          YarnConfiguration.DEFAULT_RM_ADMIN_ADDRESS);\n    masterServiceAddress =  NetUtils.createSocketAddr(bindAddress);\n    adminAcl = \n      new AccessControlList(\n          conf.get(YarnConfiguration.RM_ADMIN_ACL, YarnConfiguration.DEFAULT_RM_ADMIN_ACL));\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as an improperly configured address for 'yarn.resourcemanager.admin.address', which directly relates to the ground truth method 'AdminService.init'. The fix suggestion is preventive as it suggests ensuring the configuration is set correctly, which would prevent the bug. The problem location identification is partial because it mentions 'AdminService.init', which is the buggy method where the error occurs, but not where the actual fix was made. There is no wrong information in the bug report as all details are relevant and accurate."
        }
    },
    {
        "filename": "MAPREDUCE-5724.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit": {
                "code_before_change": "  protected void serviceInit(Configuration conf) throws Exception {\n    this.conf = conf;\n\n    int serialNumberLowDigits = 3;\n    serialNumberFormat = (\"%0\"\n        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS + serialNumberLowDigits)\n        + \"d\");\n\n    String doneDirPrefix = null;\n    doneDirPrefix = JobHistoryUtils\n        .getConfiguredHistoryServerDoneDirPrefix(conf);\n    try {\n      doneDirPrefixPath = FileContext.getFileContext(conf).makeQualified(\n          new Path(doneDirPrefix));\n      doneDirFc = FileContext.getFileContext(doneDirPrefixPath.toUri(), conf);\n      doneDirFc.setUMask(JobHistoryUtils.HISTORY_DONE_DIR_UMASK);\n      mkdir(doneDirFc, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_DONE_DIR_PERMISSION));\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Error creating done directory: [\"\n          + doneDirPrefixPath + \"]\", e);\n    }\n\n    String intermediateDoneDirPrefix = null;\n    intermediateDoneDirPrefix = JobHistoryUtils\n        .getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n    try {\n      intermediateDoneDirPath = FileContext.getFileContext(conf).makeQualified(\n          new Path(intermediateDoneDirPrefix));\n      intermediateDoneDirFc = FileContext.getFileContext(\n          intermediateDoneDirPath.toUri(), conf);\n      mkdir(intermediateDoneDirFc, intermediateDoneDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS.toShort()));\n    } catch (IOException e) {\n      LOG.info(\"error creating done directory on dfs \" + e);\n      throw new YarnRuntimeException(\"Error creating intermediate done directory: [\"\n          + intermediateDoneDirPath + \"]\", e);\n    }\n\n    this.aclsMgr = new JobACLsManager(conf);\n\n    maxHistoryAge = conf.getLong(JHAdminConfig.MR_HISTORY_MAX_AGE_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MAX_AGE);\n    \n    jobListCache = createJobListCache();\n\n    serialNumberIndex = new SerialNumberIndex(conf.getInt(\n        JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE,\n        JHAdminConfig.DEFAULT_MR_HISTORY_DATESTRING_CACHE_SIZE));\n\n    int numMoveThreads = conf.getInt(\n        JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_THREAD_COUNT);\n    ThreadFactory tf = new ThreadFactoryBuilder().setNameFormat(\n        \"MoveIntermediateToDone Thread #%d\").build();\n    moveToDoneExecutor = new ThreadPoolExecutor(numMoveThreads, numMoveThreads,\n        1, TimeUnit.HOURS, new LinkedBlockingQueue<Runnable>(), tf);\n\n    super.serviceInit(conf);\n  }",
                "code_after_change": "  protected void serviceInit(Configuration conf) throws Exception {\n    this.conf = conf;\n\n    int serialNumberLowDigits = 3;\n    serialNumberFormat = (\"%0\"\n        + (JobHistoryUtils.SERIAL_NUMBER_DIRECTORY_DIGITS + serialNumberLowDigits)\n        + \"d\");\n\n    long maxFSWaitTime = conf.getLong(\n        JHAdminConfig.MR_HISTORY_MAX_START_WAIT_TIME,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MAX_START_WAIT_TIME);\n    createHistoryDirs(new SystemClock(), 10 * 1000, maxFSWaitTime);\n\n    this.aclsMgr = new JobACLsManager(conf);\n\n    maxHistoryAge = conf.getLong(JHAdminConfig.MR_HISTORY_MAX_AGE_MS,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MAX_AGE);\n    \n    jobListCache = createJobListCache();\n\n    serialNumberIndex = new SerialNumberIndex(conf.getInt(\n        JHAdminConfig.MR_HISTORY_DATESTRING_CACHE_SIZE,\n        JHAdminConfig.DEFAULT_MR_HISTORY_DATESTRING_CACHE_SIZE));\n\n    int numMoveThreads = conf.getInt(\n        JHAdminConfig.MR_HISTORY_MOVE_THREAD_COUNT,\n        JHAdminConfig.DEFAULT_MR_HISTORY_MOVE_THREAD_COUNT);\n    ThreadFactory tf = new ThreadFactoryBuilder().setNameFormat(\n        \"MoveIntermediateToDone Thread #%d\").build();\n    moveToDoneExecutor = new ThreadPoolExecutor(numMoveThreads, numMoveThreads,\n        1, TimeUnit.HOURS, new LinkedBlockingQueue<Runnable>(), tf);\n\n    super.serviceInit(conf);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-hs.src.main.java.org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.loadConfFile": {
                "code_before_change": "    public synchronized Configuration loadConfFile() throws IOException {\n      FileContext fc = FileContext.getFileContext(confFile.toUri(), conf);\n      Configuration jobConf = new Configuration(false);\n      jobConf.addResource(fc.open(confFile), confFile.toString());\n      return jobConf;\n    }",
                "code_after_change": "    public synchronized Configuration loadConfFile() throws IOException {\n      FileContext fc = FileContext.getFileContext(confFile.toUri(), conf);\n      Configuration jobConf = new Configuration(false);\n      jobConf.addResource(fc.open(confFile), confFile.toString());\n      return jobConf;\n    }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the JobHistoryServer attempting to connect to HDFS when it is not running, which is related to the 'HistoryFileManager.serviceInit' method where the error occurs, but not where the actual fix was made. Thus, it is classified as 'Partial' under 'Buggy Method'. The fix suggestion is 'Preventive' as it suggests checking if HDFS is running before proceeding, which would prevent the error but does not match the developer's fix. The problem location identification is 'Partial' under 'Buggy Method' because it points to 'JobHistoryServer.serviceInit' and 'HistoryFileManager.serviceInit', which are related to the error but not where the actual fix was made. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5358.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.KillTasksTransition": {
                "code_before_change": [],
                "code_after_change": []
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Preventive",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the issue in the JobImpl.handle method, which is where the error occurs, but not where the actual fix was made (KillTasksTransition). Therefore, it is classified as 'Partial' under 'Buggy Method' for both root cause and problem location identification. The fix suggestion is 'Preventive' as it suggests adding checks to prevent the error, which aligns with the nature of the bug but does not match the actual fix. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5837.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.isChainJob": {
                "code_before_change": "  private boolean isChainJob(Configuration conf) {\n    boolean isChainJob = false;\n    try {\n      String mapClassName = conf.get(MRJobConfig.MAP_CLASS_ATTR);\n      if (mapClassName != null) {\n        Class<?> mapClass = Class.forName(mapClassName);\n        if (ChainMapper.class.isAssignableFrom(mapClass))\n          isChainJob = true;\n      }\n    } catch (ClassNotFoundException cnfe) {\n      // don't care; assume it's not derived from ChainMapper\n    }\n    try {\n      String reduceClassName = conf.get(MRJobConfig.REDUCE_CLASS_ATTR);\n      if (reduceClassName != null) {\n        Class<?> reduceClass = Class.forName(reduceClassName);\n        if (ChainReducer.class.isAssignableFrom(reduceClass))\n          isChainJob = true;\n      }\n    } catch (ClassNotFoundException cnfe) {\n      // don't care; assume it's not derived from ChainReducer\n    }\n    return isChainJob;\n  }",
                "code_after_change": "  private boolean isChainJob(Configuration conf) {\n    boolean isChainJob = false;\n    try {\n      String mapClassName = conf.get(MRJobConfig.MAP_CLASS_ATTR);\n      if (mapClassName != null) {\n        Class<?> mapClass = Class.forName(mapClassName);\n        if (ChainMapper.class.isAssignableFrom(mapClass))\n          isChainJob = true;\n      }\n    } catch (ClassNotFoundException cnfe) {\n      // don't care; assume it's not derived from ChainMapper\n    } catch (NoClassDefFoundError ignored) {\n    }\n    try {\n      String reduceClassName = conf.get(MRJobConfig.REDUCE_CLASS_ATTR);\n      if (reduceClassName != null) {\n        Class<?> reduceClass = Class.forName(reduceClassName);\n        if (ChainReducer.class.isAssignableFrom(reduceClass))\n          isChainJob = true;\n      }\n    } catch (ClassNotFoundException cnfe) {\n      // don't care; assume it's not derived from ChainReducer\n    } catch (NoClassDefFoundError ignored) {\n    }\n    return isChainJob;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "fix_suggestion": "Correct",
            "problem_location_identification": {
                "level": "Precise",
                "sub_category": null
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report precisely identifies the root cause as the unhandled NoClassDefError in the isChainJob method, which matches the ground truth method. The fix suggestion to catch NoClassDefError in the isChainJob method is correct and matches the developer's fix. The problem location identification is precise as it mentions the JobImpl.isChainJob method, which is the ground truth method. There is no wrong information in the bug report as all details are consistent with the context of the bug."
        }
    },
    {
        "filename": "MAPREDUCE-5088.json",
        "code_diff": {
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.JobClient.run": {
                "code_before_change": "        public Job run() throws IOException, ClassNotFoundException, \n          InterruptedException {\n          Job job = Job.getInstance(conf);\n          job.submit();\n          return job;\n        }",
                "code_after_change": "        public Job run() throws IOException, ClassNotFoundException, \n          InterruptedException {\n          Job job = Job.getInstance(conf);\n          job.submit();\n          return job;\n        }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.YARNRunner.getClusterMetrics": {
                "code_before_change": "  public ClusterMetrics getClusterMetrics() throws IOException,\n      InterruptedException {\n    return resMgrDelegate.getClusterMetrics();\n  }",
                "code_after_change": "  public ClusterMetrics getClusterMetrics() throws IOException,\n      InterruptedException {\n    return resMgrDelegate.getClusterMetrics();\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-core.src.main.java.org.apache.hadoop.mapred.JobClient.submitJob": {
                "code_before_change": "  public RunningJob submitJob(String jobFile) throws FileNotFoundException, \n                                                     InvalidJobConfException, \n                                                     IOException {\n    // Load in the submitted job details\n    JobConf job = new JobConf(jobFile);\n    return submitJob(job);\n  }",
                "code_after_change": "  public RunningJob submitJob(String jobFile) throws FileNotFoundException, \n                                                     InvalidJobConfException, \n                                                     IOException {\n    // Load in the submitted job details\n    JobConf job = new JobConf(jobFile);\n    return submitJob(job);\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.YARNRunner.getTaskTrackerExpiryInterval": {
                "code_before_change": "  public long getTaskTrackerExpiryInterval() throws IOException,\n      InterruptedException {\n    return resMgrDelegate.getTaskTrackerExpiryInterval();\n  }",
                "code_after_change": "  public long getTaskTrackerExpiryInterval() throws IOException,\n      InterruptedException {\n    return resMgrDelegate.getTaskTrackerExpiryInterval();\n  }"
            },
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-jobclient.src.main.java.org.apache.hadoop.mapred.ResourceMgrDelegate.getClusterMetrics": {
                "code_before_change": "  public ClusterMetrics getClusterMetrics() throws IOException,\n      InterruptedException {\n    YarnClusterMetrics metrics = super.getYarnClusterMetrics();\n    ClusterMetrics oldMetrics = new ClusterMetrics(1, 1, 1, 1, 1, 1, \n        metrics.getNumNodeManagers() * 10, metrics.getNumNodeManagers() * 2, 1,\n        metrics.getNumNodeManagers(), 0, 0);\n    return oldMetrics;\n  }",
                "code_after_change": "  public ClusterMetrics getClusterMetrics() throws IOException,\n      InterruptedException {\n    YarnClusterMetrics metrics = super.getYarnClusterMetrics();\n    ClusterMetrics oldMetrics = new ClusterMetrics(1, 1, 1, 1, 1, 1, \n        metrics.getNumNodeManagers() * 10, metrics.getNumNodeManagers() * 2, 1,\n        metrics.getNumNodeManagers(), 0, 0);\n    return oldMetrics;\n  }"
            }
        },
        "llm_judgement": {
            "root_cause_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "fix_suggestion": "Alternative Fix",
            "problem_location_identification": {
                "level": "Partial",
                "sub_category": "Buggy Method"
            },
            "wrong_information": "No",
            "explanation_of_judgement": "The bug report identifies the root cause as the 'renewer' field not being set in the GetDelegationTokenRequest, which is related to the method YARNRunner.getDelegationTokenFromHS. This method is not in the ground truth list but is closely related as it deals with delegation tokens, making it a 'Buggy Method'. The fix suggestion involves ensuring the 'renewer' field is set correctly, which is an alternative fix to the actual changes made in the ground truth methods. The problem location mentions YARNRunner.getDelegationTokenFromHS, which is where the error occurs, but not where the actual fix was made, thus it is categorized as 'Buggy Method'. There is no wrong information in the bug report as all details are relevant to the context of the bug."
        }
    }
]