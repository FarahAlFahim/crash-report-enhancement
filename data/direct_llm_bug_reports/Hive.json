[
    {
        "filename": "HIVE-10992.json",
        "creation_time": "2015-06-12T19:52:35.000+0000",
        "bug_report": {
            "Title": "WebHCat should not create delegation tokens when Kerberos is not enabled",
            "Description": "The `TempletonControllerJob.run()` method is incorrectly creating delegation tokens even when Kerberos security is not enabled. This behavior leads to issues for long-running jobs submitted via WebHCat, as the created tokens can be automatically canceled after a certain period, resulting in errors when the child jobs attempt to access these tokens. The method should check if security is enabled using `UserGroupInformation.isSecurityEnabled()` before creating any delegation tokens.",
            "StackTrace": [
                "2015-05-25 20:49:38,026 WARN [main] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (owner=btbig3, renewer=mr token, realUser=hdp, issueDate=1432399326562, maxDate=1433004126562, sequenceNumber=3, masterKeyId=4) can't be found in cache",
                "2015-05-25 20:49:38,058 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: Exception occurred while finding child jobs",
                "at org.apache.hadoop.mapred.WebHCatJTShim23.getYarnChildJobs(WebHCatJTShim23.java:204)",
                "at org.apache.hadoop.mapred.WebHCatJTShim23.killJobs(WebHCatJTShim23.java:158)",
                "at org.apache.hive.hcatalog.templeton.tool.LaunchMapper.killLauncherChildJobs(LaunchMapper.java:156)",
                "at org.apache.hive.hcatalog.templeton.tool.LaunchMapper.startJob(LaunchMapper.java:124)",
                "at org.apache.hive.hcatalog.templeton.tool.LaunchMapper.run(LaunchMapper.java:261)",
                "at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)"
            ],
            "RootCause": "The root cause of the issue is that the `TempletonControllerJob.run()` method is creating delegation tokens without checking if Kerberos security is enabled, leading to invalid tokens being used for long-running jobs.",
            "StepsToReproduce": [
                "1. Submit a long-running job via WebHCat without Kerberos security enabled.",
                "2. Wait for more than 24 hours for the job to run.",
                "3. Observe the logs for warnings related to invalid tokens."
            ],
            "ExpectedBehavior": "The system should not create delegation tokens when Kerberos is not enabled, preventing any issues related to token expiration and invalidation.",
            "ObservedBehavior": "The system creates delegation tokens even when Kerberos is not enabled, leading to errors when the child jobs attempt to use these tokens after they have been invalidated.",
            "Suggestions": "Implement a check in the `TempletonControllerJob.run()` method to verify if Kerberos security is enabled using `UserGroupInformation.isSecurityEnabled()` before creating any delegation tokens.",
            "problem_location": {
                "files": [
                    "hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/LaunchMapper.java"
                ],
                "classes": [
                    "org.apache.hive.hcatalog.templeton.tool.LaunchMapper"
                ],
                "methods": [
                    "LaunchMapper.startJob",
                    "LaunchMapper.killLauncherChildJobs"
                ]
            },
            "possible_fix": "In the `TempletonControllerJob.run()` method, add a condition to check if `UserGroupInformation.isSecurityEnabled()` is true before creating the delegation token. If it is false, skip the token creation logic."
        }
    },
    {
        "filename": "HIVE-16450.json",
        "creation_time": "2017-04-14T13:59:12.000+0000",
        "bug_report": {
            "Title": "Some metastore operations are not retried even with desired underlying exceptions",
            "Description": "The issue arises in the RetryingHMSHandler class where operations are expected to retry when a MetaException is caused by either JDOException or NucleusException. However, in the ObjectStore class, many instances throw a new MetaException without the original cause, leading to missed retries for certain exceptions. For example, a JDOException that occurs during the retrieval of table column statistics is not retried due to this behavior.",
            "StackTrace": [
                "2017-04-04 17:28:21,602 ERROR metastore.ObjectStore (ObjectStore.java:getMTableColumnStatistics(6555)) - Error retrieving statistics via jdo",
                "javax.jdo.JDOException: Exception thrown when executing query",
                "at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:596)",
                "at org.datanucleus.api.jdo.JDOQuery.executeWithArray(JDOQuery.java:321)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getMTableColumnStatistics(ObjectStore.java:6546)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getTableColumnStatisticsInternal(ObjectStore.java:6594)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getTableColumnStatistics(ObjectStore.java:6588)",
                "at org.apache.hadoop.hive.metastore.HiveAlterHandler.alterTableUpdateTableColumnStats(HiveAlterHandler.java:787)",
                "at org.apache.hadoop.hive.metastore.HiveAlterHandler.alterTable(HiveAlterHandler.java:247)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table_core(HiveMetaStore.java:3809)"
            ],
            "RootCause": "The root cause of the issue is that the ObjectStore class is throwing new MetaExceptions without preserving the original cause, which prevents the RetryingHMSHandler from recognizing and retrying operations that should be retried when encountering JDOException or NucleusException.",
            "StepsToReproduce": [
                "Trigger a metastore operation that results in a JDOException.",
                "Observe that the operation does not retry as expected."
            ],
            "ExpectedBehavior": "The system should retry metastore operations when a JDOException or NucleusException is encountered, as these exceptions are expected to be retried according to the logic in RetryingHMSHandler.",
            "ObservedBehavior": "Metastore operations that encounter JDOException or NucleusException do not retry, leading to failures that could have been resolved with a retry.",
            "Suggestions": "Modify the ObjectStore class to ensure that when throwing a new MetaException, the original cause is preserved. This can be done by passing the original exception as a cause to the new MetaException.",
            "problem_location": {
                "files": [
                    "ObjectStore.java",
                    "HiveAlterHandler.java",
                    "RetryingHMSHandler.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.ObjectStore",
                    "org.apache.hadoop.hive.metastore.HiveAlterHandler",
                    "org.apache.hadoop.hive.metastore.RetryingHMSHandler"
                ],
                "methods": [
                    "ObjectStore.getMTableColumnStatistics",
                    "HiveAlterHandler.alterTableUpdateTableColumnStats",
                    "RetryingHMSHandler.invokeInternal"
                ]
            },
            "possible_fix": "In the ObjectStore class, modify the methods that throw new MetaException to include the original exception as a cause. For example, change 'throw new MetaException(msg)' to 'throw new MetaException(msg, originalException)'. This will allow the RetryingHMSHandler to properly identify the cause and trigger retries."
        }
    },
    {
        "filename": "HIVE-6389.json",
        "creation_time": "2014-02-07T01:33:32.000+0000",
        "bug_report": {
            "Title": "LazyBinaryColumnarSerDe-based RCFile tables break when looking up elements in null-maps.",
            "Description": "When querying RCFile tables that utilize LazyBinaryColumnarSerDe, look-ups into map-columns containing null values result in a ClassCastException. Specifically, the error occurs when attempting to cast an Integer to a Text object during the serialization process. This issue arises when the map or the lookup key is null, leading to a failure in processing the row correctly.",
            "StackTrace": [
                "2014-02-05 21:50:25,050 FATAL mr.ExecMapper (ExecMapper.java:map(194)) - org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"id\":null,\"mymap\":null,\"isnull\":null}",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:534)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:177)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:429)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:235)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:744)",
                "Caused by: java.lang.ClassCastException: java.lang.Integer cannot be cast to org.apache.hadoop.io.Text",
                "at org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector.getPrimitiveWritableObject(WritableStringObjectInspector.java:41)",
                "at org.apache.hadoop.hive.serde2.lazy.LazyUtils.writePrimitiveUTF8(LazyUtils.java:226)",
                "at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serialize(LazySimpleSerDe.java:486)",
                "at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serializeField(LazySimpleSerDe.java:439)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:560)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:790)",
                "at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:790)",
                "at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:790)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:524)"
            ],
            "RootCause": "The root cause of the issue is that the LazyBinaryMapOI does not handle null values correctly. When either the map or the lookup key is null, it leads to a ClassCastException when trying to cast an Integer to a Text object during serialization.",
            "StepsToReproduce": [
                "Create an RCFile table using LazyBinaryColumnarSerDe.",
                "Insert a row with a map-column that contains null values.",
                "Execute a query that attempts to look up a key in the null map, e.g., `SELECT mymap['1024'] FROM mytable;`."
            ],
            "ExpectedBehavior": "The system should return null or a default value when looking up keys in a map-column that contains null values, without throwing an exception.",
            "ObservedBehavior": "The system throws a ClassCastException when attempting to process rows with null values in map-columns.",
            "Suggestions": "Modify the LazyBinaryMapOI to return null when either the map or the lookup key is null. Ensure that this behavior is consistent across all data types handled by the serializer.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecMapper.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java",
                    "serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableStringObjectInspector.java",
                    "serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazySimpleSerDe.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.ExecMapper",
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector",
                    "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"
                ],
                "methods": [
                    "ExecMapper.map",
                    "MapOperator.process",
                    "WritableStringObjectInspector.getPrimitiveWritableObject",
                    "LazySimpleSerDe.serialize"
                ]
            },
            "possible_fix": "In the LazyBinaryMapOI implementation, add checks to return null if the map or the lookup key is null. This can be done by modifying the getPrimitiveWritableObject method in WritableStringObjectInspector to handle null cases appropriately."
        }
    },
    {
        "filename": "HIVE-2372.json",
        "creation_time": "2011-08-12T09:07:34.000+0000",
        "bug_report": {
            "Title": "java.io.IOException: error=7, Argument list too long",
            "Description": "The issue arises when executing a large query with a Perl reducer in a Hive job. The reducer fails due to the environment variable size exceeding the limit imposed by the Linux kernel. Specifically, the variable 'mapred.input.dir' is excessively large, leading to the 'Argument list too long' error when the ScriptOperator attempts to initialize the Perl process.",
            "StackTrace": [
                "org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:256)",
                "org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:468)",
                "org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:416)",
                "org.apache.hadoop.mapred.Child$4.run(Child.java:268)",
                "java.security.AccessController.doPrivileged(Native Method)",
                "javax.security.auth.Subject.doAs(Subject.java:396)",
                "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)",
                "org.apache.hadoop.mapred.Child.main(Child.java:262)",
                "org.apache.hadoop.hive.ql.exec.ScriptOperator.processOp(ScriptOperator.java:320)",
                "org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:471)",
                "org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:744)",
                "org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84)",
                "org.apache.hadoop.hive.ql.exec.ExtractOperator.processOp(ExtractOperator.java:45)"
            ],
            "RootCause": "The root cause of the issue is the excessive size of the environment variable 'mapred.input.dir', which exceeds the maximum allowed size for environment variables in Linux (132KB). This is due to the large number of input directories being passed to the reducer.",
            "StepsToReproduce": [
                "Execute a Hive query with a large number of partitions and input directories.",
                "Ensure that the query uses a Perl reducer.",
                "Observe the reducer's failure with the 'Argument list too long' error."
            ],
            "ExpectedBehavior": "The reducer should execute successfully without exceeding the environment variable size limits.",
            "ObservedBehavior": "The reducer fails with a java.io.IOException indicating that the argument list is too long, preventing the Perl script from executing.",
            "Suggestions": "Consider reducing the number of input directories or modifying the way input directories are passed to the reducer to avoid exceeding the environment variable size limit. Alternatively, upgrading the kernel may help, but it does not resolve the fundamental issue of environment variable size limits.",
            "problem_location": {
                "files": [
                    "ScriptOperator.java",
                    "ExecReducer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.ScriptOperator",
                    "org.apache.hadoop.hive.ql.exec.ExecReducer"
                ],
                "methods": [
                    "ScriptOperator.processOp",
                    "ExecReducer.reduce"
                ]
            },
            "possible_fix": "Refactor the way input directories are handled in the ScriptOperator to avoid passing large environment variables. For example, consider using a configuration file or a different method of passing parameters to the Perl script."
        }
    },
    {
        "filename": "HIVE-2958.json",
        "creation_time": "2012-04-17T15:02:38.000+0000",
        "bug_report": {
            "Title": "GROUP BY causing ClassCastException [LazyDioInteger cannot be cast LazyInteger]",
            "Description": "A ClassCastException occurs when executing a GROUP BY query on the 'tim_hbase_occurrence' table. The issue arises specifically when the query attempts to group by the 'data_resource_id' column, which is of type LazyDioInteger. The error indicates that the system is trying to cast a LazyDioInteger to a LazyInteger, which is not allowed. This problem is likely due to the way the data is being deserialized and processed in the Hive framework.",
            "StackTrace": [
                "org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"id\":1444,\"scientific_name\":null,\"data_resource_id\":1081}",
                "Caused by: java.lang.ClassCastException: org.apache.hadoop.hive.serde2.lazydio.LazyDioInteger cannot be cast to org.apache.hadoop.hive.serde2.lazy.LazyInteger",
                "at org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyIntObjectInspector.copyObject(LazyIntObjectInspector.java:43)",
                "at org.apache.hadoop.hive.ql.exec.GroupByOperator.processHashAggr(GroupByOperator.java:750)",
                "at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:737)"
            ],
            "RootCause": "The root cause of the issue is a ClassCastException that occurs when the system attempts to cast a LazyDioInteger to a LazyInteger during the GROUP BY operation. This indicates a mismatch in the expected data types during the aggregation process.",
            "StepsToReproduce": [
                "Create the external table 'tim_hbase_occurrence' with the specified schema.",
                "Insert data into the table, ensuring that 'data_resource_id' contains LazyDioInteger values.",
                "Execute the query: SELECT data_resource_id, count(*) FROM tim_hbase_occurrence GROUP BY data_resource_id."
            ],
            "ExpectedBehavior": "The query should return the count of occurrences grouped by 'data_resource_id' without any errors.",
            "ObservedBehavior": "The query fails with a ClassCastException, preventing the expected results from being returned.",
            "Suggestions": "Consider modifying the data type of 'data_resource_id' to ensure compatibility with the expected LazyInteger type. Alternatively, update the deserialization logic to handle LazyDioInteger correctly.",
            "problem_location": {
                "files": [
                    "MapOperator.java",
                    "GroupByOperator.java",
                    "LazyIntObjectInspector.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.GroupByOperator",
                    "org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyIntObjectInspector"
                ],
                "methods": [
                    "MapOperator.process",
                    "GroupByOperator.processOp",
                    "LazyIntObjectInspector.copyObject"
                ]
            },
            "possible_fix": "To resolve the issue, ensure that the 'data_resource_id' column is defined as an integer type compatible with LazyInteger. Alternatively, modify the copyObject method in LazyIntObjectInspector to handle LazyDioInteger appropriately, or adjust the deserialization process in the MapOperator to ensure that the correct type is used."
        }
    },
    {
        "filename": "HIVE-13392.json",
        "creation_time": "2016-03-30T22:32:50.000+0000",
        "bug_report": {
            "Title": "Disable Speculative Execution for ACID Compactor",
            "Description": "The ACID Compactor in the Hadoop framework is currently not configured to handle speculative execution, which can lead to file lease conflicts when multiple tasks attempt to create the same file simultaneously. This issue arises because speculative execution is enabled by default, causing multiple instances of the same task to run concurrently. When one task holds a lease on a file, another task attempting to create the same file will fail with an AlreadyBeingCreatedException. To resolve this, speculative execution should be disabled for both mappers and reducers in the JobConf settings.",
            "StackTrace": [
                "2016-02-08 22:56:38,256 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to CREATE_FILE /apps/hive/warehouse/service_logs_v2/ds=2016-01-20/_tmp_6cf08b9f-c2e2-4182-bc81-e032801b147f/base_13858600/bucket_00004 for DFSClient_attempt_1454628390210_27756_m_000001_1_131224698_1 on 172.18.129.12 because this file lease is currently owned by DFSClient_attempt_1454628390210_27756_m_000001_0_-2027182532_1 on 172.18.129.18",
                "at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:2937)",
                "at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2562)",
                "at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2451)",
                "at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2335)",
                "at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:688)",
                "at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:397)",
                "at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)",
                "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)",
                "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)",
                "at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2151)"
            ],
            "RootCause": "Speculative execution is enabled by default, causing multiple tasks to attempt to create the same file concurrently, leading to lease conflicts.",
            "StepsToReproduce": [
                "Set up a Hadoop job with speculative execution enabled.",
                "Run the ACID Compactor job.",
                "Observe the logs for lease conflict errors."
            ],
            "ExpectedBehavior": "The ACID Compactor should successfully create files without encountering lease conflicts.",
            "ObservedBehavior": "The job fails with an AlreadyBeingCreatedException due to multiple tasks trying to create the same file.",
            "Suggestions": "Disable speculative execution for the job by setting mapred.map.tasks.speculative.execution and mapred.reduce.tasks.speculative.execution to false. Consider implementing a mechanism where each task writes to a directory with a unique UUID to avoid conflicts in the future.",
            "problem_location": {
                "files": [],
                "classes": [],
                "methods": []
            },
            "possible_fix": "In the JobConf settings, add the following lines to disable speculative execution:\n\n```\njobConf.setBoolean('mapred.map.tasks.speculative.execution', false);\njobConf.setBoolean('mapred.reduce.tasks.speculative.execution', false);\n```\n\nAdditionally, consider modifying the task output directory to include a UUID to ensure unique file creation."
        }
    },
    {
        "filename": "HIVE-11301.json",
        "creation_time": "2015-07-18T00:41:40.000+0000",
        "bug_report": {
            "Title": "Thrift Metastore Issue When Getting Stats Results in Disconnect",
            "Description": "The issue arises when the Thrift metastore encounters a protocol exception due to an unset required field 'colStats' in the AggrStats structure. This leads to a failure in processing the message, resulting in a disconnect. The client then attempts to reconnect, but the connection is lost, causing the CLI to hang indefinitely while retrying.",
            "StackTrace": [
                "2015-07-17 20:32:27,795 ERROR [pool-3-thread-150]: server.TThreadPoolServer (TThreadPoolServer.java:run(294)) - Thrift error occurred during processing of message.",
                "org.apache.thrift.protocol.TProtocolException: Required field 'colStats' is unset! Struct:AggrStats(colStats:null, partsFound:0)",
                "at org.apache.hadoop.hive.metastore.api.AggrStats.validate(AggrStats.java:389)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_aggr_stats_for_result.validate(ThriftHiveMetastore.java)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_aggr_stats_for_result$get_aggr_stats_for_resultStandardScheme.write(ThriftHiveMetastore.java)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:53)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:187)",
                "org.apache.thrift.transport.TTransportException",
                "at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)"
            ],
            "RootCause": "The root cause of the issue is that the 'colStats' field in the AggrStats structure is not being set properly before it is sent over the Thrift protocol, leading to a TProtocolException.",
            "StepsToReproduce": [
                "Attempt to retrieve aggregate column statistics from the metastore using the HiveMetaStoreClient.",
                "Ensure that the required column statistics are not available or are improperly set.",
                "Observe the resulting disconnect and the CLI hanging during retries."
            ],
            "ExpectedBehavior": "The system should successfully retrieve aggregate column statistics without throwing exceptions or causing disconnections.",
            "ObservedBehavior": "The system throws a TProtocolException due to an unset required field, leading to a disconnect and the CLI hanging while retrying the connection.",
            "Suggestions": "Ensure that the 'colStats' field is properly populated before sending the AggrStats structure. Implement additional validation checks to prevent sending incomplete data.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/TUGIBasedProcessor.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                    "org.apache.hadoop.hive.metastore.TUGIBasedProcessor"
                ],
                "methods": [
                    "HiveMetaStoreClient.getAggrColStatsFor",
                    "TUGIBasedProcessor.process"
                ]
            },
            "possible_fix": "In the method 'getAggrColStatsFor' of the HiveMetaStoreClient, ensure that the 'colStats' field is set correctly before returning the AggrStats object. Additionally, add validation in the 'collectStatistics' method to handle cases where column statistics are not available."
        }
    },
    {
        "filename": "HIVE-11028.json",
        "creation_time": "2015-06-16T23:03:38.000+0000",
        "bug_report": {
            "Title": "Tez: table self join and join with another table fails with IndexOutOfBoundsException",
            "Description": "The issue arises when executing a self join on the table 'tez_self_join1' and joining it with 'tez_self_join2'. The query fails with an IndexOutOfBoundsException, indicating that the code is attempting to access an index in a list that is out of bounds. This typically occurs when the expected data structure is empty or not properly initialized, leading to an attempt to access an element that does not exist.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0",
                "at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:171)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:137)",
                "at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:324)",
                "at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:176)",
                "at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:168)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)",
                "at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:168)",
                "at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:163)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:744)"
            ],
            "RootCause": "The root cause of the IndexOutOfBoundsException is likely due to the join operation not producing any results, leading to an empty list being accessed in the StandardStructObjectInspector. Specifically, the method 'getJoinOutputObjectInspector' is trying to access the first element of a list that is empty.",
            "StepsToReproduce": [
                "Create table 'tez_self_join1' with columns (id1, id2, id3) and insert sample data.",
                "Create table 'tez_self_join2' with column (id1) and insert sample data.",
                "Execute the provided SQL query that performs a self join on 'tez_self_join1' and joins it with 'tez_self_join2'."
            ],
            "ExpectedBehavior": "The query should return the expected results from the join operation without throwing any exceptions.",
            "ObservedBehavior": "The query fails with an IndexOutOfBoundsException, indicating that the join operation did not produce any results.",
            "Suggestions": "Ensure that the join conditions are valid and that the tables contain the expected data. Additionally, add checks to handle cases where the result set is empty before attempting to access elements in the list.",
            "problem_location": {
                "files": [
                    "TezProcessor.java",
                    "CommonJoinOperator.java",
                    "StandardStructObjectInspector.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.tez.TezProcessor",
                    "org.apache.hadoop.hive.ql.exec.CommonJoinOperator",
                    "org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector"
                ],
                "methods": [
                    "TezProcessor.initializeAndRunProcessor",
                    "CommonJoinOperator.getJoinOutputObjectInspector",
                    "StandardStructObjectInspector.init"
                ]
            },
            "possible_fix": "In the 'getJoinOutputObjectInspector' method, add a check to ensure that the list of object inspectors is not empty before attempting to access its elements. For example:\n\nif (structFieldObjectInspectors.isEmpty()) {\n    throw new HiveException(\"No valid object inspectors available for join output.\");\n}"
        }
    },
    {
        "filename": "HIVE-14380.json",
        "creation_time": "2016-07-29T00:14:58.000+0000",
        "bug_report": {
            "Title": "Queries on tables with remote HDFS paths fail in 'encryption' checks.",
            "Description": "When querying tables with remote HDFS paths, the system throws an IAException indicating it cannot determine if the specified HDFS path is encrypted. This occurs because the current HDFS configuration is used instead of the configuration corresponding to the path being checked. The issue arises in the `SessionState.getHdfsEncryptionShim()` method, where the `FileSystem` instance is created using the session configuration, leading to a mismatch in expected HDFS paths.",
            "StackTrace": [
                "2016-07-26 01:16:27,471 ERROR parse.CalcitePlanner (SemanticAnalyzer.java:getMetaData(1867)) - org.apache.hadoop.hive.ql.metadata.HiveException: Unable to determine if hdfs://foo.ygrid.yahoo.com:8020/projects/my_db/my_table is encrypted: java.lang.IllegalArgumentException: Wrong FS: hdfs://foo.ygrid.yahoo.com:8020/projects/my_db/my_table, expected: hdfs://bar.ygrid.yahoo.com:8020",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.isPathEncrypted(SemanticAnalyzer.java:2204)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getStrongestEncryptedTablePath(SemanticAnalyzer.java:2274)"
            ],
            "RootCause": "The root cause of the issue is that the `FileSystem` instance is created using the session configuration instead of the configuration corresponding to the specific HDFS path being checked. This leads to a mismatch in the expected filesystem, causing the encryption check to fail.",
            "StepsToReproduce": [
                "1. Set up a Hive table with a remote HDFS path that is encrypted.",
                "2. Attempt to query the table.",
                "3. Observe the IAException indicating the inability to determine if the path is encrypted."
            ],
            "ExpectedBehavior": "The system should correctly determine if the specified HDFS path is encrypted and allow the query to proceed without errors.",
            "ObservedBehavior": "The system throws an IAException indicating it cannot determine if the HDFS path is encrypted due to a mismatch in the expected filesystem.",
            "Suggestions": "Modify the `SessionState.getHdfsEncryptionShim()` method to fetch the `FileSystem` instance corresponding to the path being checked instead of using the session configuration.",
            "problem_location": {
                "files": [
                    "SessionState.java",
                    "SemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.SemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.metadata.SessionState"
                ],
                "methods": [
                    "SessionState.getHdfsEncryptionShim",
                    "SemanticAnalyzer.isPathEncrypted",
                    "SemanticAnalyzer.getStrongestEncryptedTablePath"
                ]
            },
            "possible_fix": "In the `SessionState.getHdfsEncryptionShim()` method, replace the line `FileSystem fs = FileSystem.get(sessionConf);` with `FileSystem fs = FileSystem.get(path.toUri(), sessionConf);` where `path` is the HDFS path being checked for encryption."
        }
    },
    {
        "filename": "HIVE-7799.json",
        "creation_time": "2014-08-20T09:45:21.000+0000",
        "bug_report": {
            "Title": "TRANSFORM failed in transform_ppr1.q[Spark Branch]",
            "Description": "A NullPointerException occurs during the execution of a Spark job when attempting to read from a RowContainer that has already been read from. This misuse of RowContainer leads to an invalid state, causing the task to fail. The issue arises specifically in the HiveKVResultCache class, where the next() method is called on an iterator that is not in a valid state due to prior reads.",
            "StackTrace": [
                "2014-08-20 01:14:36,594 ERROR executor.Executor (Logging.scala:logError(96)) - Exception in task 0.0 in stage 1.0 (TID 0)",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.spark.HiveKVResultCache.next(HiveKVResultCache.java:113)",
                "at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.next(HiveBaseFunctionResultList.java:124)",
                "at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.next(HiveBaseFunctionResultList.java:82)",
                "at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:42)",
                "at scala.collection.Iterator$class.foreach(Iterator.scala:727)",
                "at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)",
                "at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.java:65)",
                "at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)",
                "at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)",
                "at org.apache.spark.scheduler.Task.run(Task.scala:54)",
                "at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:199)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:722)"
            ],
            "RootCause": "The root cause of the issue is the misuse of RowContainer, which does not allow writing after a read operation has occurred. This leads to a NullPointerException when the next() method is called on an iterator that is in an invalid state.",
            "StepsToReproduce": [
                "Run a Spark job that involves transforming data using Hive.",
                "Ensure that the transformation involves reading from a RowContainer.",
                "Attempt to read from the RowContainer after it has already been read from."
            ],
            "ExpectedBehavior": "The Spark job should execute successfully without throwing a NullPointerException, allowing for proper data transformation.",
            "ObservedBehavior": "The Spark job fails with a NullPointerException due to the misuse of RowContainer, leading to an invalid state during data reading.",
            "Suggestions": "Review the usage of RowContainer in the HiveKVResultCache class to ensure that it is not being read from after a write operation. Implement checks to prevent this misuse.",
            "problem_location": {
                "files": [
                    "HiveKVResultCache.java",
                    "HiveBaseFunctionResultList.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.spark.HiveKVResultCache",
                    "org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList"
                ],
                "methods": [
                    "HiveKVResultCache.next",
                    "HiveBaseFunctionResultList$ResultIterator.next"
                ]
            },
            "possible_fix": "Modify the implementation of the next() method in HiveKVResultCache to check if the RowContainer has already been read from. If it has, throw an appropriate exception or handle the state to prevent further reads."
        }
    },
    {
        "filename": "HIVE-6537.json",
        "creation_time": "2014-03-03T18:57:44.000+0000",
        "bug_report": {
            "Title": "NullPointerException when loading hashtable for MapJoin directly",
            "Description": "A NullPointerException is thrown during the execution of the MapJoinOperator when attempting to load a hashtable. The error occurs specifically in the load method of HashTableLoader, indicating that the tables being filled are null. This suggests that the initialization of the tables is not being executed as expected, likely due to the cleanUpInputFileChangedOp method not calling loadHashTable under certain conditions.",
            "StackTrace": [
                "2014-02-20 23:33:15,743 FATAL [main] org.apache.hadoop.hive.ql.exec.mr.ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.mr.HashTableLoader.load(HashTableLoader.java:103)",
                "at org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:149)",
                "at org.apache.hadoop.hive.ql.exec.MapJoinOperator.cleanUpInputFileChangedOp(MapJoinOperator.java:164)",
                "at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1026)",
                "at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1030)",
                "at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1030)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:489)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:177)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:396)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)",
                "Caused by: java.lang.NullPointerException",
                "at java.util.Arrays.fill(Arrays.java:2685)",
                "at org.apache.hadoop.hive.ql.exec.mr.HashTableLoader.loadDirectly(HashTableLoader.java:155)",
                "at org.apache.hadoop.hive.ql.exec.mr.HashTableLoader.load(HashTableLoader.java:81)"
            ],
            "RootCause": "The root cause of the NullPointerException is that the tables array in the HashTableLoader is not initialized before it is accessed in the load method. This is likely due to the loadHashTable method not being called when expected, particularly when the input file has changed.",
            "StepsToReproduce": [
                "Set up a MapJoin operation in Hive.",
                "Run the operation with input files that trigger the cleanUpInputFileChanged method.",
                "Observe the logs for the NullPointerException."
            ],
            "ExpectedBehavior": "The hashtable should be loaded successfully without throwing a NullPointerException, allowing the MapJoin operation to complete as expected.",
            "ObservedBehavior": "A NullPointerException is thrown, indicating that the tables array is null when attempting to fill it in the load method.",
            "Suggestions": "Ensure that the loadHashTable method is called appropriately in all scenarios where the input file changes. Additionally, add null checks for the tables array before attempting to fill it.",
            "problem_location": {
                "files": [
                    "HashTableLoader.java",
                    "MapJoinOperator.java",
                    "Operator.java",
                    "MapOperator.java",
                    "ExecMapper.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.HashTableLoader",
                    "org.apache.hadoop.hive.ql.exec.MapJoinOperator",
                    "org.apache.hadoop.hive.ql.exec.Operator",
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.mr.ExecMapper"
                ],
                "methods": [
                    "HashTableLoader.load",
                    "MapJoinOperator.loadHashTable",
                    "MapJoinOperator.cleanUpInputFileChangedOp",
                    "Operator.cleanUpInputFileChanged",
                    "MapOperator.process"
                ]
            },
            "possible_fix": "In the loadHashTable method, ensure that the tables are initialized before they are used. Add a check to call the initializeOp method if the tables are null. For example:\n\nif (mapJoinTables == null) {\n    initializeOp();\n}\n\nThis will ensure that the tables are set up correctly before any operations are performed on them."
        }
    },
    {
        "filename": "HIVE-13691.json",
        "creation_time": "2016-05-04T23:40:03.000+0000",
        "bug_report": {
            "Title": "No record with CQ_ID=0 found in COMPACTION_QUEUE",
            "Description": "The system encounters an IllegalStateException indicating that no record with CQ_ID=0 exists in the COMPACTION_QUEUE. This issue arises after a timeout occurs while attempting to retrieve table partitions, leading to a failure in marking the compaction as completed. The root of the problem is that the system does not handle the scenario where a compaction entry is not created in the COMPACTION_QUEUE, which prevents the system from logging the failure in the COMPLETED_COMPACTIONS table.",
            "StackTrace": [
                "2016-04-29 18:49:31,594 ERROR [Thread-11]: compactor.Initiator (Initiator.java:run(141)) - Caught exception while trying to determine if we should compact id:0,dbname:default,tableName:service_logs_v2,parName:ds=2016-04-21,state:^@,type:null,runAs:null,tooManyAborts:false,highestTxnId:0.  Marking clean to avoid repeated failures, MetaException(message:Timeout when executing method: getTable)",
                "Caused by: org.apache.hadoop.hive.metastore.DeadlineException: Timeout when executing method: getTable",
                "2016-04-29 18:49:31,595 ERROR [Thread-11]: compactor.Initiator (Initiator.java:run(154)) - Initiator loop caught unexpected exception this time through the loop: java.lang.IllegalStateException: No record with CQ_ID=0 found in COMPACTION_QUEUE",
                "at org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler.markFailed(CompactionTxnHandler.java:861)",
                "at org.apache.hadoop.hive.ql.txn.compactor.Initiator.run(Initiator.java:144)"
            ],
            "RootCause": "The root cause of the issue is that the system fails to create an entry in the COMPACTION_QUEUE for the compaction operation, which leads to an IllegalStateException when trying to mark the compaction as failed. This failure is triggered by a timeout while executing the getTable method, which prevents the retrieval of necessary partition information.",
            "StepsToReproduce": [
                "Trigger a compaction operation with a valid CQ_ID.",
                "Ensure that the operation times out while trying to retrieve table partitions.",
                "Observe the logs for the IllegalStateException indicating no record found in COMPACTION_QUEUE."
            ],
            "ExpectedBehavior": "The system should log a failure in the COMPLETED_COMPACTIONS table even if the compaction entry was never created in the COMPACTION_QUEUE.",
            "ObservedBehavior": "The system throws an IllegalStateException stating that no record with CQ_ID=0 was found in the COMPACTION_QUEUE, preventing proper logging of the compaction failure.",
            "Suggestions": "Implement a check to ensure that if a compaction fails due to a timeout, an entry is still created in the COMPLETED_COMPACTIONS table to log the failure. Additionally, consider improving the timeout handling mechanism to prevent premature timeouts.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/txn/CompactionTxnHandler.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler",
                    "org.apache.hadoop.hive.ql.txn.compactor.Initiator"
                ],
                "methods": [
                    "CompactionTxnHandler.markFailed",
                    "Initiator.run"
                ]
            },
            "possible_fix": "In the markFailed method of CompactionTxnHandler, add logic to insert a record into the COMPLETED_COMPACTIONS table even if the CQ_ID is not found in the COMPACTION_QUEUE. This can be done by modifying the catch block for the SQLException to handle the case where no record is found and still log the failure appropriately."
        }
    },
    {
        "filename": "HIVE-17758.json",
        "creation_time": "2017-10-10T12:33:52.000+0000",
        "bug_report": {
            "Title": "NOTIFICATION_SEQUENCE_LOCK_RETRY_SLEEP_INTERVAL.defaultLongVal is -1",
            "Description": "The introduction of retry logic in HIVE-16886 has led to a situation where the default value for the retry interval is not properly initialized. Specifically, the field {{NOTIFICATION_SEQUENCE_LOCK_RETRY_SLEEP_INTERVAL.defaultLongVal}} is being read as -1, which is not a valid timeout value. This results in an IllegalArgumentException when the system attempts to use this negative value in a sleep operation during the retry mechanism.",
            "StackTrace": [
                "2017-10-10 11:22:37,638 ERROR [load-dynamic-partitions-12]: metastore.ObjectStore (ObjectStore.java:addNotificationEvent(7444)) - could not get lock for update",
                "java.lang.IllegalArgumentException: timeout value is negative",
                "at java.lang.Thread.sleep(Native Method)",
                "at org.apache.hadoop.hive.metastore.ObjectStore$RetryingExecutor.run(ObjectStore.java:7407)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.lockForUpdate(ObjectStore.java:7361)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:7424)",
                "at sun.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:498)"
            ],
            "RootCause": "The root cause of the issue is that the default value for the retry interval is not being loaded correctly into the configuration field, resulting in a negative timeout value being used in the retry logic.",
            "StepsToReproduce": [
                "Configure the Hive metastore with the default retry interval.",
                "Trigger an operation that requires a lock for update in the ObjectStore.",
                "Observe the logs for the IllegalArgumentException related to the negative timeout value."
            ],
            "ExpectedBehavior": "The system should use a valid positive timeout value for the retry interval, allowing the retry logic to function correctly without throwing exceptions.",
            "ObservedBehavior": "The system throws an IllegalArgumentException due to a negative timeout value when attempting to sleep during the retry process.",
            "Suggestions": "Ensure that the default value for NOTIFICATION_SEQUENCE_LOCK_RETRY_SLEEP_INTERVAL is properly initialized and loaded into the configuration. Consider adding validation to check for negative values before using them in sleep operations.",
            "problem_location": {
                "files": [
                    "ObjectStore.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.ObjectStore"
                ],
                "methods": [
                    "ObjectStore.lockForUpdate",
                    "ObjectStore.addNotificationEvent"
                ]
            },
            "possible_fix": "In the HiveConf class, ensure that the default value for NOTIFICATION_SEQUENCE_LOCK_RETRY_SLEEP_INTERVAL is set to a valid positive integer. Additionally, add a check in the RetryingExecutor to validate the timeout value before using it in Thread.sleep()."
        }
    },
    {
        "filename": "HIVE-14898.json",
        "creation_time": "2016-10-06T00:02:36.000+0000",
        "bug_report": {
            "Title": "HS2 shouldn't log callstack for an empty auth header error",
            "Description": "When the client does not send an authorization header, HiveServer2 (HS2) logs an error with a stack trace, which is unnecessary since this is an expected condition that results in a 401 Unauthorized response. The logging of the stack trace for this scenario clutters the logs and does not provide useful information.",
            "StackTrace": [
                "2016-10-05 15:32:02,408 ERROR [HiveServer2-HttpHandler-Pool: Thread-199]: thrift.ThriftHttpServlet (ThriftHttpServlet.java:doKerberosAuth(169)) - Failed to authenticate with hive/_HOST kerberos principal",
                "2016-10-05 15:32:02,408 ERROR [HiveServer2-HttpHandler-Pool: Thread-199]: thrift.ThriftHttpServlet (ThriftHttpServlet.java:doPost(104)) - Error: ",
                "org.apache.hive.service.auth.HttpAuthenticationException: java.lang.reflect.UndeclaredThrowableException",
                "at org.apache.hive.service.cli.thrift.ThriftHttpServlet.doKerberosAuth(ThriftHttpServlet.java:170)",
                "at org.apache.hive.service.cli.thrift.ThriftHttpServlet.doPost(ThriftHttpServlet.java:83)",
                "at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)",
                "at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)",
                "at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:565)",
                "at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:479)",
                "at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:225)",
                "at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1031)",
                "at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:406)",
                "at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:186)",
                "at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:965)",
                "at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117)",
                "at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:111)",
                "at org.eclipse.jetty.server.Server.handle(Server.java:349)",
                "at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:449)",
                "at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:925)",
                "at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:952)",
                "at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)",
                "at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:76)",
                "at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:609)",
                "at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:45)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)",
                "Caused by: java.lang.reflect.UndeclaredThrowableException",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1686)",
                "at org.apache.hive.service.cli.thrift.ThriftHttpServlet.doKerberosAuth(ThriftHttpServlet.java:167)",
                "... 23 more",
                "Caused by: org.apache.hive.service.auth.HttpAuthenticationException: Authorization header received from the client is empty.",
                "at org.apache.hive.service.cli.thrift.ThriftHttpServlet.getAuthHeader(ThriftHttpServlet.java:311)",
                "at org.apache.hive.service.cli.thrift.ThriftHttpServlet.access$100(ThriftHttpServlet.java:59)",
                "at org.apache.hive.service.cli.thrift.ThriftHttpServlet$HttpKerberosServerAction.run(ThriftHttpServlet.java:212)",
                "at org.apache.hive.service.cli.thrift.ThriftHttpServlet$HttpKerberosServerAction.run(ThriftHttpServlet.java:175)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)",
                "... 24 more"
            ],
            "RootCause": "The root cause of the issue is that the method getAuthHeader in ThriftHttpServlet throws an HttpAuthenticationException when the Authorization header is empty. This exception is logged in the doPost method, which results in unnecessary stack traces being logged for an expected condition.",
            "StepsToReproduce": [
                "Send a request to HS2 without an Authorization header.",
                "Observe the logs for the error messages and stack traces."
            ],
            "ExpectedBehavior": "HS2 should return a 401 Unauthorized response without logging a stack trace for the empty Authorization header.",
            "ObservedBehavior": "HS2 logs an error with a stack trace when the Authorization header is empty, which is unnecessary for this expected condition.",
            "Suggestions": "Modify the error handling in the doPost method to avoid logging the stack trace for expected authentication failures, such as an empty Authorization header.",
            "problem_location": {
                "files": [
                    "service/src/java/org/apache/hive/service/cli/thrift/ThriftHttpServlet.java"
                ],
                "classes": [
                    "org.apache.hive.service.cli.thrift.ThriftHttpServlet"
                ],
                "methods": [
                    "doPost",
                    "getAuthHeader"
                ]
            },
            "possible_fix": "In the doPost method, modify the catch block for HttpAuthenticationException to log a warning instead of an error, and avoid logging the stack trace. For example:\n\n```java\ncatch (HttpAuthenticationException e) {\n    LOG.warn(\"Authentication Error: \" + e.getMessage());\n    response.setStatus(HttpServletResponse.SC_UNAUTHORIZED);\n    if(isKerberosAuthMode(authType)) {\n        response.addHeader(HttpAuthUtils.WWW_AUTHENTICATE, HttpAuthUtils.NEGOTIATE);\n    }\n    response.getWriter().println(\"Authentication Error: \" + e.getMessage());\n}\n```"
        }
    },
    {
        "filename": "HIVE-5546.json",
        "creation_time": "2013-10-15T15:06:59.000+0000",
        "bug_report": {
            "Title": "A change in ORCInputFormat made by HIVE-4113 was reverted by HIVE-5391",
            "Description": "The issue arises from the handling of the 'includedColumnIds' in the OrcInputFormat class. When 'includedColumnIds' is an empty list, the system should not attempt to read any columns. However, the current implementation in the 'findIncludedColumns' method incorrectly assumes that an empty string for 'includedStr' means all columns should be read, leading to excessive memory usage and ultimately causing a Java OutOfMemoryError.",
            "StackTrace": [
                "java.lang.OutOfMemoryError: Java heap space",
                "at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.<init>(MapTask.java:949)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)",
                "at org.apache.hadoop.mapred.Child$4.run(Child.java:255)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)",
                "at org.apache.hadoop.mapred.Child.main(Child.java:249)"
            ],
            "RootCause": "The root cause of the issue is the incorrect handling of the 'includedStr' parameter in the 'findIncludedColumns' method of the OrcInputFormat class. An empty string is treated as a signal to read all columns, which is not the intended behavior when 'includedColumnIds' is empty.",
            "StepsToReproduce": [
                "Set up a Hive environment with ORC file format.",
                "Create a table with ORC storage and ensure that the 'includedColumnIds' is set to an empty list.",
                "Run a query that triggers the OrcInputFormat to process the table.",
                "Observe the OutOfMemoryError in the logs."
            ],
            "ExpectedBehavior": "When 'includedColumnIds' is an empty list, the OrcInputFormat should not attempt to read any columns, preventing excessive memory usage.",
            "ObservedBehavior": "The system attempts to read all columns when 'includedStr' is an empty string, leading to a Java OutOfMemoryError.",
            "Suggestions": "Modify the 'findIncludedColumns' method to correctly handle the case when 'includedStr' is an empty string, ensuring it does not default to reading all columns.",
            "problem_location": {
                "files": [
                    "OrcInputFormat.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat"
                ],
                "methods": [
                    "OrcInputFormat.findIncludedColumns"
                ]
            },
            "possible_fix": "In the 'findIncludedColumns' method, update the condition to check for an empty list of 'includedColumnIds' and return null or an appropriate value instead of assuming all columns should be read. Example code change:\n\nif (includedColumnIds.isEmpty() || includedStr == null || includedStr.trim().length() == 0) {\n    return null;\n}"
        }
    },
    {
        "filename": "HIVE-7557.json",
        "creation_time": "2014-07-30T19:25:12.000+0000",
        "bug_report": {
            "Title": "When reduce is vectorized, dynpart_sort_opt_vectorization.q under Tez fails",
            "Description": "The issue arises when the reduce operation is vectorized in the Tez execution engine, leading to a ClassCastException. Specifically, the system attempts to cast a DoubleColumnVector to a LongColumnVector, which is not valid. This occurs during the processing of vector batches, particularly when the VectorExpressionWriterLong is invoked to write values from the vectorized row batch.",
            "StackTrace": [
                "Container released by application, AttemptID:attempt_1406747677386_0003_2_00_000000_2",
                "Error: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing vector batch (tag=0) [Error getting row data with exception java.lang.ClassCastException: org.apache.hadoop.hive.ql.exec.vector.DoubleColumnVector cannot be cast to org.apache.hadoop.hive.ql.exec.vector.LongColumnVector",
                "at org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpressionWriterFactory$VectorExpressionWriterLong.writeValue(VectorExpressionWriterFactory.java:168)",
                "at org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch.toString(VectorizedRowBatch.java:159)",
                "at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.processVectors(ReduceRecordProcessor.java:481)",
                "at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.processRows(ReduceRecordProcessor.java:371)",
                "at org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor.run(ReduceRecordProcessor.java:291)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:165)",
                "at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:307)",
                "at org.apache.hadoop.mapred.YarnTezDagChild$5.run(YarnTezDagChild.java:562)"
            ],
            "RootCause": "The root cause of the issue is a ClassCastException occurring when the system attempts to cast a DoubleColumnVector to a LongColumnVector during the processing of vectorized data in the ReduceRecordProcessor.",
            "StepsToReproduce": [
                "Enable vectorization for the reduce operation in Tez.",
                "Run the dynpart_sort_opt_vectorization.q query.",
                "Observe the failure in the execution logs."
            ],
            "ExpectedBehavior": "The reduce operation should process the vectorized data without any casting errors, successfully completing the query execution.",
            "ObservedBehavior": "The execution fails with a ClassCastException, indicating that a DoubleColumnVector cannot be cast to a LongColumnVector.",
            "Suggestions": "Review the data types being processed in the vectorized operations. Ensure that the correct column types are being used and that there are no mismatches between expected and actual data types.",
            "problem_location": {
                "files": [
                    "VectorExpressionWriterFactory.java",
                    "VectorizedRowBatch.java",
                    "ReduceRecordProcessor.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpressionWriterFactory",
                    "org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch",
                    "org.apache.hadoop.hive.ql.exec.tez.ReduceRecordProcessor"
                ],
                "methods": [
                    "VectorExpressionWriterFactory$VectorExpressionWriterLong.writeValue",
                    "VectorizedRowBatch.toString",
                    "ReduceRecordProcessor.processVectors",
                    "ReduceRecordProcessor.processRows"
                ]
            },
            "possible_fix": "To resolve the issue, ensure that the data types of the columns being processed match the expected types in the vectorized operations. This may involve modifying the query to cast or convert the data types appropriately before processing."
        }
    },
    {
        "filename": "HIVE-1712.json",
        "creation_time": "2010-10-14T17:17:44.000+0000",
        "bug_report": {
            "Title": "Migrating metadata from derby to mysql thrown NullPointerException",
            "Description": "During the migration of metadata from Derby to MySQL, a NullPointerException is thrown when executing a Hive query that previously worked in Derby. The issue arises when the Hive metastore attempts to retrieve the schema for a table that may not have been properly initialized or populated after the migration. This results in a failure to access the necessary metadata, leading to the exception.",
            "StackTrace": [
                "2010-10-16 08:57:30,140 ERROR metadata.Hive (Hive.java:getTable(395)) - java.lang.NullPointerException",
                "at java.util.Hashtable.put(Hashtable.java:394)",
                "at java.util.Hashtable.putAll(Hashtable.java:466)",
                "at org.apache.hadoop.hive.metastore.MetaStoreUtils.getSchema(MetaStoreUtils.java:520)",
                "at org.apache.hadoop.hive.metastore.MetaStoreUtils.getSchema(MetaStoreUtils.java:489)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:381)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:333)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getMetaData(SemanticAnalyzer.java:683)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:5200)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:105)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:275)",
                "at org.apache.hadoop.hive.ql.Driver.runCommand(Driver.java:320)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:312)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:123)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:181)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:287)"
            ],
            "RootCause": "The root cause of the NullPointerException is likely due to the absence of required metadata for the table in the Hive metastore after migrating from Derby to MySQL. Specifically, the schema retrieval process fails because the parameters or properties expected to be present in the StorageDescriptor are null or not properly initialized.",
            "StepsToReproduce": [
                "1. Export data from Derby to CSV.",
                "2. Load the CSV data into MySQL.",
                "3. Execute a Hive query that references the migrated table."
            ],
            "ExpectedBehavior": "The Hive query should execute successfully and return the expected results without throwing any exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown when attempting to retrieve the table schema, indicating that the necessary metadata is not available.",
            "Suggestions": "Ensure that the metadata for the migrated tables is correctly populated in the Hive metastore. This may involve verifying the schema and properties of the tables after migration and ensuring that all required fields are initialized.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.MetaStoreUtils",
                    "org.apache.hadoop.hive.ql.metadata.Hive",
                    "org.apache.hadoop.hive.ql.parse.SemanticAnalyzer"
                ],
                "methods": [
                    "MetaStoreUtils.getSchema",
                    "Hive.getTable",
                    "SemanticAnalyzer.getMetaData"
                ]
            },
            "possible_fix": "To fix the issue, ensure that the migration process correctly populates the StorageDescriptor and its parameters in the Hive metastore. This may involve adding checks to verify that all required fields are initialized before attempting to access them in the getSchema method."
        }
    },
    {
        "filename": "HIVE-12608.json",
        "creation_time": "2015-12-07T21:26:01.000+0000",
        "bug_report": {
            "Title": "Parquet Schema Evolution doesn't work when a column is dropped from array<struct<>>",
            "Description": "The issue arises when attempting to drop a column from an array of structs in a Parquet table. The system throws a RuntimeException indicating that it cannot find the dropped field, which suggests that the schema evolution process is not handling the removal of fields correctly. This is evident from the stack trace where the HiveStructConverter fails to locate the field 'c2' after it has been dropped from the schema.",
            "StackTrace": [
                "2015-12-07 11:47:28,503 ERROR [main]: CliDriver (SessionState.java:printError(921)) - Failed with exception java.io.IOException:java.lang.RuntimeException: cannot find field c2 in [c1]",
                "java.io.IOException: java.lang.RuntimeException: cannot find field c2 in [c1]",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:507)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:414)",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:138)",
                "at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1655)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:227)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:159)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:370)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:305)",
                "at org.apache.hadoop.hive.cli.QTestUtil.executeClientInternal(QTestUtil.java:1029)",
                "at org.apache.hadoop.hive.cli.QTestUtil.executeClient(QTestUtil.java:1003)",
                "at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:139)",
                "at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parquet_type_promotion(TestCliDriver.java:123)"
            ],
            "RootCause": "The root cause of the issue is that the HiveStructConverter is unable to find the field 'c2' after it has been dropped from the schema. This indicates that the schema evolution logic does not properly update the internal representation of the struct fields when a column is removed.",
            "StepsToReproduce": [
                "1. Create a table with an array of structs using the provided SQL.",
                "2. Insert a record into the table.",
                "3. Attempt to alter the table to drop a column from the array of structs.",
                "4. Select from the table to trigger the error."
            ],
            "ExpectedBehavior": "The system should successfully execute the SELECT statement after dropping the column, returning the remaining fields without errors.",
            "ObservedBehavior": "The system throws a RuntimeException indicating that it cannot find the dropped field 'c2', leading to a failure in fetching the results.",
            "Suggestions": "Review the schema evolution logic in the HiveStructConverter and ensure that it correctly updates the internal field mappings when a column is dropped. Consider adding checks to handle cases where fields are no longer present in the schema.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveStructConverter.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.io.parquet.convert.HiveStructConverter",
                    "org.apache.hadoop.hive.ql.exec.FetchOperator"
                ],
                "methods": [
                    "HiveStructConverter.getStructFieldTypeInfo",
                    "FetchOperator.getNextRow"
                ]
            },
            "possible_fix": "In the HiveStructConverter class, modify the getStructFieldTypeInfo method to handle cases where fields have been dropped from the schema. Ensure that the method does not throw an exception if the requested field is not found, but instead returns a null or a default value."
        }
    },
    {
        "filename": "HIVE-17774.json",
        "creation_time": "2017-10-11T20:02:01.000+0000",
        "bug_report": {
            "Title": "Compaction may start with 0 splits and fail",
            "Description": "The compaction process is initiated even when there are no delta directories to process, leading to a MapReduce job submission with zero splits. This results in a failure due to the absence of input files, specifically a FileNotFoundException when attempting to commit the job. The system should prevent the initiation of a compaction job when there are no splits available.",
            "StackTrace": [
                "2017-09-26 10:36:01,979 INFO  [...]: compactor.CompactorMR (CompactorMR.java:launchCompactionJob(295)) - Submitting MINOR compaction job ....",
                "2017-09-26 10:36:02,350 INFO  [...]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(198)) - number of splits:0",
                "2017-09-26 10:36:08,637 INFO  [...]: mapreduce.Job (Job.java:monitorAndPrintJob(1380)) - Job job_1503950256860_15982 failed with state FAILED due to: No of maps and reduces are 0 job_1503950256860_15982",
                "Job commit failed: java.io.FileNotFoundException: File .../hello_acid/load_date=2016-03-03/_tmp_a95346ad-bd89-4e66-9b05-e60fdfa11858 does not exist.",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:904)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:113)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:966)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:962)",
                "at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:962)",
                "at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorOutputCommitter.commitJob(CompactorMR.java:776)",
                "at org.apache.hadoop.mapred.OutputCommitter.commitJob(OutputCommitter.java:291)",
                "at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.handleJobCommit(CommitterEventHandler.java:285)",
                "at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.run(CommitterEventHandler.java:237)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The compaction job is initiated without checking if there are any splits available, leading to a job submission with zero splits and subsequent failure due to missing input files.",
            "StepsToReproduce": [
                "1. Ensure there are no delta directories available for compaction.",
                "2. Trigger the compaction process.",
                "3. Observe the logs for job submission and failure."
            ],
            "ExpectedBehavior": "The system should not initiate a compaction job when there are no splits available, preventing any job submission and subsequent errors.",
            "ObservedBehavior": "The system attempts to submit a compaction job with zero splits, resulting in a FileNotFoundException due to the absence of input files.",
            "Suggestions": "Implement a check before initiating the compaction job to ensure that there are available splits. If no splits are present, skip the job submission.",
            "problem_location": {
                "files": [
                    "CompactorMR.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.txn.compactor.CompactorMR"
                ],
                "methods": [
                    "CompactorMR.launchCompactionJob"
                ]
            },
            "possible_fix": "In the 'launchCompactionJob' method of 'CompactorMR.java', add a condition to check if the number of splits is greater than zero before proceeding with job submission. If the number of splits is zero, log a warning and return early."
        }
    },
    {
        "filename": "HIVE-14564.json",
        "creation_time": "2016-08-18T00:11:34.000+0000",
        "bug_report": {
            "Title": "Column Pruning generates out of order columns in SelectOperator which cause ArrayIndexOutOfBoundsException.",
            "Description": "The issue arises from the column pruning process in the SelectOperator, which leads to an incorrect order of columns during serialization and deserialization. This mismatch causes an ArrayIndexOutOfBoundsException when the system attempts to access fields in the deserialized data structure that do not exist due to the altered column order. The problem is exacerbated when the LazyBinarySerDe is used, as it relies on the order of columns being consistent between jobs.",
            "StackTrace": [
                "org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:507)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:170)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)",
                "Caused by: java.lang.ArrayIndexOutOfBoundsException",
                "at java.lang.System.arraycopy(Native Method)",
                "at org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryString.init(LazyBinaryString.java:48)",
                "at org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryStruct.uncheckedGetField(LazyBinaryStruct.java:264)",
                "at org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryStruct.getField(LazyBinaryStruct.java:201)",
                "at org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryStructObjectInspector.getStructFieldData(LazyBinaryStructObjectInspector.java:64)",
                "at org.apache.hadoop.hive.ql.exec.ExprNodeColumnEvaluator._evaluate(ExprNodeColumnEvaluator.java:94)",
                "at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:77)",
                "at org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator.evaluate(ExprNodeEvaluator.java:65)",
                "at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.makeValueWritable(ReduceSinkOperator.java:550)",
                "at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:377)"
            ],
            "RootCause": "The root cause of the issue is the mismatch in the order of columns during serialization and deserialization due to column pruning in the SelectOperator. This leads to an ArrayIndexOutOfBoundsException when accessing fields in the deserialized data structure.",
            "StepsToReproduce": [
                "1. Execute a MapReduce job that uses column pruning in the SelectOperator.",
                "2. Ensure that the output of this job is used as input for another MapReduce job.",
                "3. Observe the execution of the second job, which should trigger the ArrayIndexOutOfBoundsException."
            ],
            "ExpectedBehavior": "The system should correctly serialize and deserialize the data without any exceptions, maintaining the integrity of the column order across MapReduce jobs.",
            "ObservedBehavior": "An ArrayIndexOutOfBoundsException is thrown during the execution of the second MapReduce job due to the incorrect order of columns.",
            "Suggestions": "Review the column pruning logic in the SelectOperator to ensure that the order of columns is preserved during serialization. Consider implementing checks to validate the column order before deserialization.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecMapper.java",
                    "serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryStruct.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/ReduceSinkOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeColumnEvaluator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeEvaluator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.ExecMapper",
                    "org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryStruct",
                    "org.apache.hadoop.hive.ql.exec.ReduceSinkOperator",
                    "org.apache.hadoop.hive.ql.exec.ExprNodeColumnEvaluator",
                    "org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator"
                ],
                "methods": [
                    "ExecMapper.map",
                    "LazyBinaryStruct.getField",
                    "ReduceSinkOperator.makeValueWritable",
                    "ExprNodeColumnEvaluator._evaluate",
                    "ExprNodeEvaluator.evaluate"
                ]
            },
            "possible_fix": "To fix the issue, ensure that the column order is consistent during serialization and deserialization. This may involve modifying the ColumnPrunerSelectProc to maintain the original order of columns or implementing a validation step before deserialization to check for column order consistency."
        }
    },
    {
        "filename": "HIVE-3651.json",
        "creation_time": "2012-11-01T23:31:20.000+0000",
        "bug_report": {
            "Title": "BucketMapJoin Tests Fail with Hadoop 0.23",
            "Description": "The Hive job fails during execution due to a missing hashtable file in the specified directory. The error indicates that the MapJoin operation cannot find the required file, leading to a RuntimeException. This issue arises when the ExecMapper attempts to process input data but encounters a missing output file that is expected to be generated during the MapJoin operation.",
            "StackTrace": [
                "2012-11-01 15:51:20,253 WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(479)) - job_local_0001",
                "java.lang.Exception: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: /home/prasadm/repos/apache/hive-patches/build/ql/scratchdir/local/hive_2012-11-01_15-51-06_176_6704298995984162430/-local-10003/HashTable-Stage-1/MapJoin-b-11-srcbucket21.txt.hashtable (No such file or directory)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:400)",
                "Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: /home/prasadm/repos/apache/hive-patches/build/ql/scratchdir/local/hive_2012-11-01_15-51-06_176_6704298995984162430/-local-10003/HashTable-Stage-1/MapJoin-b-11-srcbucket21.txt.hashtable (No such file or directory)",
                "at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:161)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:399)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:334)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:232)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:166)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)",
                "at java.lang.Thread.run(Thread.java:679)"
            ],
            "RootCause": "The root cause of the issue is that the expected hashtable file for the MapJoin operation is not being created or is being deleted before it can be accessed, resulting in a 'No such file or directory' error.",
            "StepsToReproduce": [
                "Set up a Hive environment with Hadoop 0.23.",
                "Run a MapJoin query that requires the generation of a hashtable.",
                "Check the specified directory for the existence of the hashtable file after the job execution."
            ],
            "ExpectedBehavior": "The MapJoin operation should successfully create the hashtable file in the specified directory, allowing the job to complete without errors.",
            "ObservedBehavior": "The job fails with a RuntimeException indicating that the hashtable file cannot be found, leading to a failure in the MapJoin operation.",
            "Suggestions": "Investigate the logic that generates the hashtable file during the MapJoin operation. Ensure that the file is created successfully and is not deleted prematurely. Additionally, check for any permission issues that may prevent file creation.",
            "problem_location": {
                "files": [
                    "ExecMapper.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.ExecMapper"
                ],
                "methods": [
                    "ExecMapper.map"
                ]
            },
            "possible_fix": "Review the implementation of the map method in ExecMapper to ensure that the hashtable file is created correctly. Add error handling to check for file existence before attempting to access it, and log detailed information if the file is missing."
        }
    },
    {
        "filename": "HIVE-5199.json",
        "creation_time": "2013-09-03T20:40:29.000+0000",
        "bug_report": {
            "Title": "Custom SerDe containing a nonSettable complex data type row object inspector throws cast exception with HIVE 0.11",
            "Description": "The issue arises from a ClassCastException when using a custom SerDe with a non-settable complex data type in Hive 0.11. The problem is due to changes introduced in HIVE-3833, which did not properly handle the conversion of nested complex data types that extend nonSettableObjectInspector to a settableObjectInspector type. This leads to an attempt to cast a ProtoMapObjectInspector to a SettableMapObjectInspector, resulting in a ClassCastException during the execution of FetchOperator and MapOperator.",
            "StackTrace": [
                "java.io.IOException: java.lang.ClassCastException: com.skype.data.whaleshark.hadoop.hive.proto.ProtoMapObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.SettableMapObjectInspector",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:544)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:488)",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:136)",
                "at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1412)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:271)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:756)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)",
                "Caused by: java.lang.ClassCastException: com.skype.data.whaleshark.hadoop.hive.proto.ProtoMapObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.SettableMapObjectInspector",
                "at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.getConverter(ObjectInspectorConverters.java:144)",
                "at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$StructConverter.<init>(ObjectInspectorConverters.java:307)",
                "at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.getConverter(ObjectInspectorConverters.java:138)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getRecordReader(FetchOperator.java:406)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:508)"
            ],
            "RootCause": "The root cause of the issue is the failure to convert a non-settable complex data type to a settable type in the ObjectInspectorConverters, leading to a ClassCastException when the system attempts to cast the incompatible types.",
            "StepsToReproduce": [
                "Create a partitioned table with different custom SerDes for the partition and the table.",
                "Ensure that the table-level SerDe has a settable data type and the partition-level SerDe has a non-settable data type.",
                "Execute a query that involves fetching data from this partitioned table."
            ],
            "ExpectedBehavior": "The system should correctly handle the conversion of complex data types between settable and non-settable object inspectors without throwing a ClassCastException.",
            "ObservedBehavior": "The system throws a ClassCastException when attempting to cast a ProtoMapObjectInspector to a SettableMapObjectInspector during data fetching.",
            "Suggestions": "Review the implementation of ObjectInspectorConverters to ensure proper handling of non-settable complex data types. Consider adding checks or conversions to prevent casting errors.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java",
                    "serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.FetchOperator",
                    "org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters"
                ],
                "methods": [
                    "FetchOperator.getRecordReader",
                    "FetchOperator.getNextRow",
                    "ObjectInspectorConverters.getConverter"
                ]
            },
            "possible_fix": "Modify the ObjectInspectorConverters.getConverter method to handle cases where the inputOI is a non-settable type and ensure that it does not attempt to cast it to a settable type. This may involve creating a new converter that can handle non-settable types appropriately."
        }
    },
    {
        "filename": "HIVE-17368.json",
        "creation_time": "2017-08-22T01:27:32.000+0000",
        "bug_report": {
            "Title": "DBTokenStore fails to connect in Kerberos enabled remote HMS environment",
            "Description": "In environments where the Hive Metastore (HMS) is secured with Kerberos and running remotely, the DBTokenStore fails to connect when attempting to retrieve a delegation token. This occurs because the HS2 Thrift API call to GetDelegationToken cannot establish a transport connection to HMS due to the user (e.g., 'Joe') not being Kerberos-enabled. The issue arises when Oozie submits a job on behalf of a user, creating a proxy UGI with Hive, but the DBTokenStore uses server HiveConf instead of sessionConf, leading to authentication failures.",
            "StackTrace": [
                "2017-08-21T18:07:19,644 ERROR [HiveServer2-Handler-Pool: Thread-61] transport.TSaslTransport: SASL negotiation failure",
                "javax.security.sasl.SaslException: GSS initiate failed",
                "Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)",
                "2017-08-17 11:45:13,655 ERROR org.apache.thrift.server.TThreadPoolServer: [pool-7-thread-34]: Error occurred during processing of message.",
                "java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: DIGEST-MD5: IO error acquiring password"
            ],
            "RootCause": "The root cause of the issue is that the DBTokenStore is using the server HiveConf instead of the sessionConf, which leads to the failure in establishing a Kerberos-secured transport connection to the HMS when the user is not Kerberos-enabled.",
            "StepsToReproduce": [
                "1. Set up a remote Hive Metastore (HMS) secured with Kerberos.",
                "2. Configure DBTokenStore as the token store.",
                "3. Submit a job using Oozie on behalf of a non-Kerberos-enabled user.",
                "4. Attempt to retrieve a delegation token using the GetDelegationToken API."
            ],
            "ExpectedBehavior": "The system should successfully retrieve a delegation token for the user, allowing Oozie to interact with the HMS without authentication issues.",
            "ObservedBehavior": "The system fails to retrieve the delegation token, resulting in a SASL negotiation failure and an inability to connect to the HMS.",
            "Suggestions": "Modify the DBTokenStore to utilize the sessionConf for establishing the transport connection to the HMS instead of the server HiveConf. This will ensure that the correct user credentials are used for Kerberos authentication.",
            "problem_location": {
                "files": [
                    "shims.common.src.main.java.org.apache.hadoop.hive.thrift.DBTokenStore.java",
                    "service.src.java.org.apache.hive.service.cli.session.HiveSessionProxy.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.thrift.DBTokenStore",
                    "org.apache.hive.service.cli.session.HiveSessionProxy"
                ],
                "methods": [
                    "DBTokenStore.addToken",
                    "HiveSessionProxy.invoke"
                ]
            },
            "possible_fix": "In the DBTokenStore class, modify the addToken method to use sessionConf instead of server HiveConf when establishing the transport connection to the HMS. This can be done by passing the sessionConf to the method that creates the HMSClient instance."
        }
    },
    {
        "filename": "HIVE-4233.json",
        "creation_time": "2013-03-26T13:02:20.000+0000",
        "bug_report": {
            "Title": "The TGT gotten from class 'CLIService' should be renewed on time",
            "Description": "When the HiveServer2 has been running for more than 7 days, attempts to connect using the Beeline shell result in authentication failures due to expired Kerberos tickets. The logs indicate that the failure is caused by an invalid ticket, which suggests that the Ticket Granting Ticket (TGT) is not being renewed as expected. The current implementation does not schedule a timer for TGT renewal, leading to this issue.",
            "StackTrace": [
                "2013-03-26 11:55:20,932 ERROR hive.ql.metadata.Hive: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                "at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1084)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:51)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:61)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2140)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2151)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getDelegationToken(Hive.java:2275)",
                "at org.apache.hive.service.cli.CLIService.getDelegationTokenFromMetaStore(CLIService.java:358)",
                "at org.apache.hive.service.cli.thrift.ThriftCLIService.OpenSession(ThriftCLIService.java:127)",
                "at org.apache.hive.service.cli.thrift.TCLIService$Processor$OpenSession.getResult(TCLIService.java:1073)",
                "at org.apache.hive.service.cli.thrift.TCLIService$Processor$OpenSession.getResult(TCLIService.java:1058)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge20S.java:565)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)",
                "at java.lang.Thread.run(Thread.java:662)",
                "Caused by: java.lang.reflect.InvocationTargetException",
                "at sun.reflect.GeneratedConstructorAccessor52.newInstance(Unknown Source)",
                "at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)",
                "at sun.reflect.Constructor.newInstance(Constructor.java:513)",
                "at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1082)",
                "... 16 more",
                "Caused by: java.lang.IllegalStateException: This ticket is no longer valid",
                "at javax.security.auth.kerberos.KerberosTicket.toString(KerberosTicket.java:601)",
                "at java.lang.String.valueOf(String.java:2826)",
                "at java.lang.StringBuilder.append(StringBuilder.java:115)",
                "at sun.security.jgss.krb5.SubjectComber.findAux(SubjectComber.java:120)",
                "at sun.security.jgss.krb5.SubjectComber.find(SubjectComber.java:41)",
                "at sun.security.jgss.krb5.Krb5Util.getTicket(Krb5Util.java:130)",
                "at sun.security.jgss.krb5.Krb5InitCredential$1.run(Krb5InitCredential.java:328)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.kerberos.KerberosTicket.getTgt(KerberosTicket.java:601)",
                "at javax.security.auth.kerberos.KerberosTicket.getInstance(KerberosTicket.java:601)",
                "at javax.security.auth.kerberos.KerberosTicket.getInstance(KerberosTicket.java:601)",
                "at org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport.open(TUGIAssumingTransport.java:49)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:277)",
                "... 20 more"
            ],
            "RootCause": "The root cause of the issue is that the Ticket Granting Ticket (TGT) is not being renewed, leading to authentication failures when the TGT expires after 7 days.",
            "StepsToReproduce": [
                "Start HiveServer2 and let it run for more than 7 days.",
                "Use Beeline shell to connect to HiveServer2.",
                "Attempt to perform any operation."
            ],
            "ExpectedBehavior": "The connection to HiveServer2 should succeed, and operations should be performed without authentication errors.",
            "ObservedBehavior": "All operations fail due to Kerberos authentication failure, indicating that the TGT is no longer valid.",
            "Suggestions": "Implement a mechanism to renew the TGT periodically to prevent it from expiring. This could involve scheduling a timer in the HiveAuthFactory.loginFromKeytab method to handle TGT renewal.",
            "problem_location": {
                "files": [
                    "service/src/java/org/apache/hive/service/cli/CLIService.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java"
                ],
                "classes": [
                    "org.apache.hive.service.cli.CLIService",
                    "org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                    "org.apache.hadoop.hive.metastore.MetaStoreUtils"
                ],
                "methods": [
                    "CLIService.getDelegationTokenFromMetaStore",
                    "Hive.createMetaStoreClient",
                    "Hive.getDelegationToken",
                    "HiveMetaStoreClient.open"
                ]
            },
            "possible_fix": "Add a scheduled task in the HiveAuthFactory.loginFromKeytab method to renew the TGT before it expires. This could be done using a Timer or ScheduledExecutorService to periodically call the renewal method."
        }
    },
    {
        "filename": "HIVE-14303.json",
        "creation_time": "2016-07-21T03:16:20.000+0000",
        "bug_report": {
            "Title": "CommonJoinOperator.checkAndGenObject should return directly to avoid NPE if ExecReducer.close is called twice.",
            "Description": "The method CommonJoinOperator.checkAndGenObject is not handling the scenario where ExecReducer.close is called multiple times, leading to a NullPointerException (NPE). This occurs because the first call to reducer.close() clears the storage array, and subsequent calls attempt to access this cleared storage, resulting in an NPE. The method should return early after calling CommonJoinOperator.closeOp to prevent this issue.",
            "StackTrace": [
                "Error: java.lang.RuntimeException: Hive Runtime Error while closing operators: null",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.close(ExecReducer.java:296)",
                "at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:244)",
                "at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:459)",
                "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.checkAndGenObject(CommonJoinOperator.java:718)",
                "at org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:256)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.close(ExecReducer.java:284)"
            ],
            "RootCause": "The root cause of the NPE is that the storage array is cleared by the first call to reducer.close(), and subsequent calls attempt to access this cleared storage, leading to a NullPointerException.",
            "StepsToReproduce": [
                "1. Trigger a scenario where ExecReducer.close() is called multiple times.",
                "2. Observe the logs for the NPE occurring in CommonJoinOperator.checkAndGenObject."
            ],
            "ExpectedBehavior": "The system should handle multiple calls to ExecReducer.close() gracefully without throwing a NullPointerException.",
            "ObservedBehavior": "The system throws a NullPointerException when ExecReducer.close() is called multiple times, hiding the original exception.",
            "Suggestions": "Implement a check in CommonJoinOperator.checkAndGenObject to return early if the operator has already been closed, preventing access to cleared storage.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/CommonJoinOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/JoinOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.ExecReducer",
                    "org.apache.hadoop.hive.ql.exec.CommonJoinOperator",
                    "org.apache.hadoop.hive.ql.exec.JoinOperator"
                ],
                "methods": [
                    "ExecReducer.close",
                    "CommonJoinOperator.checkAndGenObject",
                    "JoinOperator.endGroup"
                ]
            },
            "possible_fix": "In the checkAndGenObject method, add a check to see if the operator has already been closed before proceeding with the logic that accesses the storage array. For example:\n\n```java\nif (isClosed) {\n    return;\n}\n```"
        }
    },
    {
        "filename": "HIVE-19248.json",
        "creation_time": "2018-04-19T17:45:21.000+0000",
        "bug_report": {
            "Title": "REPL LOAD couldn't copy file from source CM path and also doesn't throw error if file copy fails.",
            "Description": "The issue arises during the Hive replication process, where Hadoop's distcp is used to copy files from the primary warehouse to the replica warehouse. If the HDFS block size differs between the source and destination clusters, it leads to file copy failures without proper error reporting. The current implementation does not handle these failures correctly, resulting in a false success message from REPL LOAD even when the distcp job fails. The root cause is related to the handling of checksum mismatches and the lack of error propagation in the file copy process.",
            "StackTrace": [
                "2018-04-09 14:32:06,690 ERROR [main] org.apache.hadoop.tools.mapred.CopyMapper: Failure in copying hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 to hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/000259_0",
                "java.io.IOException: File copy failed: hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 --> hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/000259_0",
                "at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:299)",
                "at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:266)",
                "at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:52)",
                "at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)",
                "at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:170)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1869)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:164)",
                "Caused by: java.io.IOException: Couldn't run retriable-command: Copying hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 to hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/000259_0",
                "at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)",
                "at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:296)",
                "... 10 more",
                "Caused by: java.io.IOException: Check-sum mismatch between hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 and hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/.distcp.tmp.attempt_1522833620762_4416_m_000000_0. Source and target differ in block-size. Use -pb to preserve block-sizes during copy. Alternatively, skip checksum-checks altogether, using -skipCrc. (NOTE: By skipping checksums, one runs the risk of masking data-corruption during file-transfer.)",
                "at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.compareCheckSums(RetriableFileCopyCommand.java:212)",
                "at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:130)",
                "at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)",
                "at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)",
                "... 11 more"
            ],
            "RootCause": "The root cause of the issue is the failure to handle checksum mismatches during file copying due to differing HDFS block sizes between source and destination clusters. Additionally, the error handling in the CopyUtils.doCopyRetry method does not propagate errors correctly when file copy attempts fail.",
            "StepsToReproduce": [
                "Set up two HDFS clusters with different block sizes.",
                "Attempt to replicate a Hive table using REPL LOAD.",
                "Observe the logs for any file copy failures and check the success message returned by REPL LOAD."
            ],
            "ExpectedBehavior": "The REPL LOAD operation should accurately reflect the success or failure of the file copy process, throwing an error if any file copy fails.",
            "ObservedBehavior": "REPL LOAD returns a success message even when the distcp job fails due to file copy issues.",
            "Suggestions": "Implement error handling in the CopyUtils.doCopyRetry method to throw an error if file copy fails after maximum attempts. Additionally, ensure that the replication process checks for checksum mismatches and handles them appropriately, possibly by preserving block sizes during copy or skipping checksum checks with caution.",
            "problem_location": {
                "files": [
                    "CopyMapper.java",
                    "RetriableFileCopyCommand.java"
                ],
                "classes": [
                    "org.apache.hadoop.tools.mapred.CopyMapper",
                    "org.apache.hadoop.tools.mapred.RetriableFileCopyCommand"
                ],
                "methods": [
                    "CopyMapper.copyFileWithRetry",
                    "RetriableFileCopyCommand.compareCheckSums"
                ]
            },
            "possible_fix": "Modify the CopyUtils.doCopyRetry method to throw an IOException if the maximum number of copy attempts is reached without success. Additionally, update the distcp command to include the -pb option to preserve block sizes or provide an option to skip checksum checks with a warning about potential data corruption."
        }
    },
    {
        "filename": "HIVE-7167.json",
        "creation_time": "2014-06-02T18:13:36.000+0000",
        "bug_report": {
            "Title": "Hive Metastore fails to start with SQLServerException",
            "Description": "The Hive Metastore fails to start when both HiveServer2 (using an embedded metastore) and HiveServer (using a remote metastore) are initiated simultaneously. This results in a connection error when attempting to launch the Hive CLI, indicating that the metastore service is running but cannot be accessed. The root cause appears to be a connection refusal when the HiveMetaStoreClient attempts to connect to the metastore server.",
            "StackTrace": [
                "Exception in thread \"main\" java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                "at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:347)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:625)",
                "Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                "at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1413)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:62)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2444)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2456)",
                "Caused by: MetaException(message:Could not connect to meta store using any of the URIs provided. Most recent failure: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused: connect",
                "at org.apache.thrift.transport.TSocket.open(TSocket.java:185)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:336)"
            ],
            "RootCause": "The root cause of the issue is a connection refusal when the HiveMetaStoreClient attempts to connect to the metastore server. This is likely due to both HiveServer2 and HiveServer trying to access the metastore simultaneously, leading to a race condition or resource contention.",
            "StepsToReproduce": [
                "Start HiveServer2 with an embedded metastore.",
                "Start HiveServer with a remote metastore.",
                "Attempt to launch the Hive CLI."
            ],
            "ExpectedBehavior": "The Hive CLI should successfully connect to the metastore and allow for normal operations without any connection errors.",
            "ObservedBehavior": "The Hive CLI fails to connect to the metastore, resulting in a connection error and preventing any further operations.",
            "Suggestions": "Consider implementing a retry mechanism with exponential backoff for the metastore connection attempts. Additionally, ensure that the metastore service is fully initialized before allowing HiveServer2 and HiveServer to start.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.MetaStoreUtils",
                    "org.apache.hadoop.hive.metastore.RetryingMetaStoreClient",
                    "org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                    "org.apache.hadoop.hive.ql.metadata.Hive",
                    "org.apache.hadoop.hive.ql.session.SessionState"
                ],
                "methods": [
                    "MetaStoreUtils.newInstance",
                    "RetryingMetaStoreClient.getProxy",
                    "Hive.createMetaStoreClient",
                    "Hive.getMSC",
                    "HiveMetaStoreClient.open"
                ]
            },
            "possible_fix": "Implement a connection retry mechanism in the HiveMetaStoreClient.open() method to handle connection refusals more gracefully. For example, add a loop that retries the connection with a delay between attempts, and log the connection attempts for better debugging."
        }
    },
    {
        "filename": "HIVE-12360.json",
        "creation_time": "2015-11-06T18:04:00.000+0000",
        "bug_report": {
            "Title": "Bad seek in uncompressed ORC with predicate pushdown",
            "Description": "An IOException occurs when attempting to read from an uncompressed ORC file with predicate pushdown enabled. The error message indicates that a seek operation is attempting to access an index (4613) that is outside the bounds of the available data. This issue arises specifically when the Hive optimization for index filtering is enabled, leading to an invalid seek operation during data retrieval.",
            "StackTrace": [
                "java.io.IOException: java.lang.IllegalArgumentException: Seek in index to 4613 is outside of the data",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:508)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:415)",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:140)",
                "at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1672)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:736)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)",
                "Caused by: java.lang.IllegalArgumentException: Seek in index to 4613 is outside of the data",
                "at org.apache.hadoop.hive.ql.io.orc.InStream$UncompressedStream.seek(InStream.java:139)",
                "at org.apache.hadoop.hive.ql.io.orc.InStream$UncompressedStream.read(InStream.java:87)",
                "at com.google.protobuf.CodedInputStream.refillBuffer(CodedInputStream.java:737)",
                "at org.apache.hadoop.hive.ql.io.orc.MetadataReader.readRowIndex(MetadataReader.java:88)",
                "at org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl.readRowIndex(RecordReaderImpl.java:1166)"
            ],
            "RootCause": "The root cause of the issue is that the index being accessed (4613) is beyond the actual number of rows available in the uncompressed ORC file. This is likely due to incorrect handling of row indices when predicate pushdown is enabled, leading to an invalid seek operation.",
            "StepsToReproduce": [
                "1. Create an uncompressed ORC file.",
                "2. Enable predicate pushdown in Hive settings.",
                "3. Execute a query that triggers the fetch operation on the ORC file."
            ],
            "ExpectedBehavior": "The system should successfully read the data from the ORC file without throwing an IOException, even with predicate pushdown enabled.",
            "ObservedBehavior": "An IOException is thrown indicating that a seek operation is attempting to access an index that is outside the bounds of the data.",
            "Suggestions": "Review the implementation of index handling in the FetchOperator and RecordReader classes. Ensure that the row indices are correctly calculated and that the seek operations do not exceed the available data range.",
            "problem_location": {
                "files": [
                    "FetchOperator.java",
                    "RecordReaderImpl.java",
                    "MetadataReader.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.FetchOperator",
                    "org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl",
                    "org.apache.hadoop.hive.ql.io.orc.MetadataReader"
                ],
                "methods": [
                    "FetchOperator.getNextRow",
                    "RecordReaderImpl.readRowIndex",
                    "MetadataReader.readRowIndex"
                ]
            },
            "possible_fix": "In the RecordReaderImpl class, ensure that the row index calculations take into account the actual number of rows in the ORC file. Modify the seek method to validate the index before performing the seek operation to prevent accessing out-of-bounds indices."
        }
    },
    {
        "filename": "HIVE-13160.json",
        "creation_time": "2016-02-26T00:02:11.000+0000",
        "bug_report": {
            "Title": "HS2 unable to load UDFs on startup when HMS is not ready",
            "Description": "The HiveServer2 (HS2) fails to load User Defined Functions (UDFs) during startup if the Hive Metastore (HMS) is not ready. The logs indicate repeated attempts to connect to the metastore, which ultimately fail, leading to a RuntimeException when trying to instantiate the SessionHiveMetaStoreClient. This results in HS2 being unable to register functions, causing them to be unavailable for use. The current implementation does not allow HS2 to enter a servicing state without a ready function list, which is undesirable. A potential solution could involve deferring the loading of the function list until a Hive session is created, rather than at HS2 startup.",
            "StackTrace": [
                "java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient",
                "at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1492)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:64)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:74)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2915)",
                "java.lang.NullPointerException",
                "at org.apache.hive.service.server.HiveServer2.stop(HiveServer2.java:283)",
                "at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:351)"
            ],
            "RootCause": "The root cause of the issue is that HS2 attempts to connect to the HMS before it is ready, leading to repeated connection failures and ultimately a RuntimeException when trying to instantiate the SessionHiveMetaStoreClient. This prevents HS2 from registering UDFs, resulting in them being unavailable.",
            "StepsToReproduce": [
                "Start HiveServer2 (HS2) while the Hive Metastore (HMS) is not running.",
                "Observe the logs for connection attempts to the HMS.",
                "Note the RuntimeException indicating failure to instantiate the SessionHiveMetaStoreClient."
            ],
            "ExpectedBehavior": "HS2 should not enter a servicing state until the function list is ready. Alternatively, HS2 could load the function list when each Hive session is created, ensuring that functions are available when needed.",
            "ObservedBehavior": "HS2 fails to register any functions and enters a state where it cannot serve requests due to the unavailability of UDFs.",
            "Suggestions": "Implement a mechanism to check the readiness of the HMS before HS2 attempts to register functions. Consider loading the function list on a per-session basis rather than at startup, possibly with caching for performance.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java",
                    "service/src/java/org/apache/hive/service/server/HiveServer2.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.MetaStoreUtils",
                    "org.apache.hadoop.hive.metastore.RetryingMetaStoreClient",
                    "org.apache.hive.service.server.HiveServer2"
                ],
                "methods": [
                    "MetaStoreUtils.newInstance",
                    "RetryingMetaStoreClient.getProxy",
                    "Hive.createMetaStoreClient",
                    "HiveServer2.stop",
                    "HiveServer2.startHiveServer2"
                ]
            },
            "possible_fix": "Modify the HiveServer2 startup process to check the readiness of the Hive Metastore before attempting to register functions. Additionally, refactor the function loading mechanism to load functions on a per-session basis, potentially caching them for performance."
        }
    },
    {
        "filename": "HIVE-12008.json",
        "creation_time": "2015-10-01T19:26:46.000+0000",
        "bug_report": {
            "Title": "Hive queries failing when using count(*) on column in view",
            "Description": "The issue arises when executing a Hive query that uses count(*) on a view containing the get_json_object() UDF, lateral views, and unions. The query fails with a RuntimeException indicating an error in configuring the object, specifically during the initialization of the map operator. This problem seems to be related to how the prunelist is handled when selecting all columns from a table, leading to an IndexOutOfBoundsException.",
            "StackTrace": [
                "2015-10-27 17:51:33,742 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: Error in configuring object",
                "at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109)",
                "at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75)",
                "at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:449)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)",
                "Caused by: java.lang.reflect.InvocationTargetException",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106)",
                "Caused by: java.lang.RuntimeException: Map operator initialization failed",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:147)",
                "Caused by: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1",
                "at java.util.ArrayList.rangeCheck(ArrayList.java:635)",
                "at java.util.ArrayList.get(ArrayList.java:411)"
            ],
            "RootCause": "The root cause of the issue is an IndexOutOfBoundsException occurring during the initialization of the map operator in the ExecMapper class. This is likely due to an empty prunelist when selecting all columns from a table, which leads to incorrect calculations of the parent's prunelist.",
            "StepsToReproduce": [
                "Create a Hive view that includes the get_json_object() UDF.",
                "Use lateral views and unions in the view definition.",
                "Execute a query using count(*) on the view.",
                "Observe the error in the logs."
            ],
            "ExpectedBehavior": "The query should execute successfully and return the correct count of rows from the view without any runtime exceptions.",
            "ObservedBehavior": "The query fails with a RuntimeException indicating an error in configuring the object, specifically during the initialization of the map operator.",
            "Suggestions": "Review the handling of prunelists in the ExecMapper class, particularly when all columns are selected. Ensure that the prunelist is correctly populated to avoid IndexOutOfBoundsExceptions.",
            "problem_location": {
                "files": [
                    "ExecMapper.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.ExecMapper"
                ],
                "methods": [
                    "ExecMapper.configure"
                ]
            },
            "possible_fix": "In the ExecMapper.configure method, add a check to ensure that the prunelist is not empty before attempting to access its elements. This could involve modifying the logic that populates the prunelist when all columns are selected."
        }
    },
    {
        "filename": "HIVE-6205.json",
        "creation_time": "2014-01-15T07:34:15.000+0000",
        "bug_report": {
            "Title": "NullPointerException when altering table partition column",
            "Description": "When attempting to alter a table's partition column using the command 'alter table alter_coltype partition column (dt int);', a NullPointerException (NPE) is thrown during the authorization process. This occurs in the 'doAuthorization' method of the Driver class, indicating that the operation for TOK_ALTERTABLE_ALTERPARTS is not defined, leading to an unhandled null reference.",
            "StackTrace": [
                "2014-01-15 15:53:40,364 ERROR ql.Driver (SessionState.java:printError(457)) - FAILED: NullPointerException null",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.Driver.doAuthorization(Driver.java:599)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:479)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:340)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:996)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1039)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:932)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:922)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:268)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:220)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:424)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:792)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:686)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:625)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:197)"
            ],
            "RootCause": "The root cause of the NullPointerException is likely due to the 'doAuthorization' method being called without a properly initialized or valid operation context, particularly when handling the TOK_ALTERTABLE_ALTERPARTS operation, which is not defined in the authorization logic.",
            "StepsToReproduce": [
                "1. Execute the command 'alter table alter_coltype partition column (dt int);'",
                "2. Observe the error message and stack trace indicating a NullPointerException."
            ],
            "ExpectedBehavior": "The system should successfully alter the table's partition column without throwing an exception, and the operation should be authorized correctly.",
            "ObservedBehavior": "The system throws a NullPointerException during the authorization process, preventing the alteration of the table's partition column.",
            "Suggestions": "Review the authorization logic in the 'doAuthorization' method to ensure that all operations, including TOK_ALTERTABLE_ALTERPARTS, are properly handled. Implement checks to prevent null references and ensure that the operation context is valid before proceeding with authorization.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/Driver.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.Driver"
                ],
                "methods": [
                    "Driver.doAuthorization",
                    "Driver.compile",
                    "Driver.runInternal"
                ]
            },
            "possible_fix": "In the 'doAuthorization' method, add checks to ensure that the operation being processed is valid and initialized before proceeding with authorization. For example, add a condition to handle cases where the operation is TOK_ALTERTABLE_ALTERPARTS and ensure that the necessary context is set up correctly."
        }
    },
    {
        "filename": "HIVE-15309.json",
        "creation_time": "2016-11-29T21:56:28.000+0000",
        "bug_report": {
            "Title": "RemoteException(java.io.FileNotFoundException): File does not exist... _flush_length",
            "Description": "The method OrcAcidUtils.getLastFlushLength() fails to check for the existence of a file before attempting to access it, leading to a FileNotFoundException. This results in unnecessary and confusing logging messages that can mislead users regarding the state of the system.",
            "StackTrace": [
                "org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /domains/adl/rrslog/data_history/rrslog/rslog/hot/server_date=2016-08-19/delta_0005913_0005913/bucket_00023_flush_length",
                "at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)",
                "at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)",
                "at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1860)",
                "at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1831)",
                "at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1744)",
                "at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:693)",
                "at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:373)",
                "at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)",
                "at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)",
                "at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)",
                "at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2313)",
                "at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2309)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)",
                "at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2307)",
                "at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1552)",
                "at org.apache.hadoop.ipc.Client.call(Client.java:1496)",
                "at org.apache.hadoop.ipc.Client.call(Client.java:1396)",
                "at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1236)",
                "at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1223)",
                "at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1211)",
                "at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:309)",
                "at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:274)",
                "at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:266)",
                "at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1536)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:330)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:326)",
                "at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:326)",
                "at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:782)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.getLastFlushLength(OrcRawRecordMerger.java:513)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.<init>(OrcRawRecordMerger.java:460)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:1525)",
                "at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:631)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)"
            ],
            "RootCause": "The method OrcAcidUtils.getLastFlushLength() does not verify if the file exists before attempting to access it, leading to a FileNotFoundException.",
            "StepsToReproduce": [
                "Attempt to access the flush length of a non-existent file using OrcAcidUtils.getLastFlushLength()",
                "Observe the resulting FileNotFoundException in the logs."
            ],
            "ExpectedBehavior": "The system should check for the existence of the file before attempting to access it, and handle the situation gracefully without throwing an exception.",
            "ObservedBehavior": "The system throws a FileNotFoundException, resulting in confusing log messages and potential misinterpretation of the system's state.",
            "Suggestions": "Implement a file existence check in OrcAcidUtils.getLastFlushLength() before attempting to access the file.",
            "problem_location": {
                "files": [
                    "OrcInputFormat.java",
                    "OrcRawRecordMerger.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat",
                    "org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger"
                ],
                "methods": [
                    "OrcInputFormat.getRawReader",
                    "OrcRawRecordMerger.getLastFlushLength"
                ]
            },
            "possible_fix": "Add a check for file existence in the getLastFlushLength() method. For example:\n\nif (!fileExists(filePath)) {\n    LOG.warn(\"File does not exist: \" + filePath);\n    return 0; // or appropriate default value\n}"
        }
    },
    {
        "filename": "HIVE-10808.json",
        "creation_time": "2015-05-23T02:24:16.000+0000",
        "bug_report": {
            "Title": "Inner join on Null throwing Cast Exception",
            "Description": "The issue arises when executing an inner join on a table where one of the columns being joined may contain null values. The join condition attempts to cast a NullStructSerDeObjectInspector to a PrimitiveObjectInspector, which results in a ClassCastException. This indicates that the object inspector for the null structure is not compatible with the expected primitive type, leading to a failure in the map operator initialization.",
            "StackTrace": [
                "java.lang.RuntimeException: Error in configuring object",
                "at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109)",
                "at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75)",
                "at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:446)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)",
                "Caused by: java.lang.reflect.InvocationTargetException",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106)",
                "Caused by: java.lang.RuntimeException: Map operator initialization failed",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:157)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassCastException: org.apache.hadoop.hive.serde2.NullStructSerDe$NullStructSerDeObjectInspector cannot be cast to org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.getConvertedOI(MapOperator.java:334)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:352)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.configure(ExecMapper.java:126)"
            ],
            "RootCause": "The root cause of the issue is a ClassCastException occurring when the system attempts to cast a NullStructSerDeObjectInspector to a PrimitiveObjectInspector during the initialization of the map operator. This happens because the join condition involves null values, which are not handled correctly by the current object inspector.",
            "StepsToReproduce": [
                "Create a table 'tab1' with columns including 'x', 'col1', 'col2', 'col3', and 'col4'.",
                "Insert rows into 'tab1' where some rows have null values in the 'x' column.",
                "Execute the provided SQL query that performs an inner join on 'tab1' using the 'x' column."
            ],
            "ExpectedBehavior": "The query should execute successfully and return the expected results without throwing any exceptions.",
            "ObservedBehavior": "The query fails with a ClassCastException during the execution of the inner join due to null values in the 'x' column.",
            "Suggestions": "Ensure that the object inspectors are correctly set up to handle null values. Consider adding checks for null values before performing the join or modifying the object inspector to accommodate null structures.",
            "problem_location": {
                "files": [
                    "serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecMapper.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils",
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.mr.ExecMapper"
                ],
                "methods": [
                    "ObjectInspectorUtils.hasAllFieldsSettable",
                    "MapOperator.setChildren",
                    "ExecMapper.configure",
                    "MapOperator.getConvertedOI"
                ]
            },
            "possible_fix": "Modify the MapOperator's getConvertedOI method to handle cases where the input ObjectInspector is a NullStructSerDeObjectInspector. This could involve adding a check to return a suitable default or a settable object inspector when encountering null structures."
        }
    },
    {
        "filename": "HIVE-18429.json",
        "creation_time": "2018-01-10T20:45:15.000+0000",
        "bug_report": {
            "Title": "Compaction should handle a case when it produces no output",
            "Description": "The compaction process fails to create the temporary location for output when both input deltas (delta_8_8 and delta_9_9) are empty. This results in a failure during the commit phase of the MapReduce job, as the expected temporary location does not exist. The absence of this location leads to a FileNotFoundException when the system attempts to list the contents of a non-existent directory. This issue can prevent further compaction from occurring if the number of empty deltas exceeds the configured maximum, leading to potential data management problems.",
            "StackTrace": [
                "2017-12-27 17:19:28,850 ERROR CommitterEvent Processor #1 org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Could not commit job",
                "java.io.FileNotFoundException: File hdfs://OTCHaaS/apps/hive/warehouse/momi.db/sensor_data/babyid=5911806ebf69640100004257/_tmp_b4c5a3f3-44e5-4d45-86af-5b773bf0fc96 does not exist.",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:923)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:114)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:985)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:981)",
                "at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:992)",
                "at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorOutputCommitter.commitJob(CompactorMR.java:785)",
                "at org.apache.hadoop.mapred.OutputCommitter.commitJob(OutputCommitter.java:291)",
                "at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.handleJobCommit(CommitterEventHandler.java:285)",
                "at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.run(CommitterEventHandler.java:237)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The compaction process does not create a temporary output directory when there are no input deltas, leading to a FileNotFoundException during the commit phase.",
            "StepsToReproduce": [
                "1. Start with empty delta_8_8 and delta_9_9.",
                "2. Trigger the compaction process.",
                "3. Observe the logs for errors related to the temporary output location."
            ],
            "ExpectedBehavior": "The compaction process should create a temporary output directory even when the input deltas are empty, allowing the commit phase to complete successfully.",
            "ObservedBehavior": "The compaction process fails with a FileNotFoundException because the temporary output directory does not exist.",
            "Suggestions": "Modify the compaction logic to ensure that a temporary output directory is created even when there are no input deltas. This could involve creating an empty delta file or a placeholder directory.",
            "problem_location": {
                "files": [
                    "CompactorMR.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.txn.compactor.CompactorMR"
                ],
                "methods": [
                    "CompactorOutputCommitter.commitJob"
                ]
            },
            "possible_fix": "In the CompactorMR class, within the compaction logic, add a check to create a temporary output directory if no input deltas are present. This can be done by adding a method to create an empty file or directory at the expected tmpLocation before proceeding to the commit phase."
        }
    },
    {
        "filename": "HIVE-10776.json",
        "creation_time": "2015-05-21T00:56:28.000+0000",
        "bug_report": {
            "Title": "Schema on insert for bucketed tables throwing NullPointerException",
            "Description": "When executing Hive schema on insert queries with 'select *', a NullPointerException is thrown. This occurs specifically during the generation of the reduce sink plan in the SemanticAnalyzer, indicating that there may be an issue with how the input or destination table properties are being handled, particularly in relation to bucketing and sorting.",
            "StackTrace": [
                "2015-05-15 19:29:01,278 ERROR [main]: ql.Driver (SessionState.java:printError(957)) - FAILED: NullPointerException null",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genReduceSinkPlan(SemanticAnalyzer.java:7257)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBucketingSortingDest(SemanticAnalyzer.java:6100)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6271)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:8972)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:8863)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9708)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9601)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:10037)",
                "at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:323)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10048)",
                "at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:207)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:227)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:424)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:311)",
                "at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:409)",
                "at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:425)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:714)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.util.RunJar.run(RunJar.java:221)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:136)"
            ],
            "RootCause": "The NullPointerException is likely caused by an attempt to access properties of the destination table or input operator that are not properly initialized or are null. This can occur if the bucketing or sorting properties are not set correctly for the destination table, leading to a failure in the genReduceSinkPlan method.",
            "StepsToReproduce": [
                "Set hive.support.concurrency=true;",
                "Set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;",
                "Set hive.enforce.bucketing=true;",
                "Drop table if exists studenttab10k;",
                "Create table studenttab10k (age int, name varchar(50), gpa decimal(3,2));",
                "Insert into studenttab10k values(1,'foo', 1.1), (2,'bar', 2.3), (3,'baz', 3.1);",
                "Drop table if exists student_acid;",
                "Create table student_acid (age int, name varchar(50), gpa decimal(3,2), grade int) clustered by (age) into 2 buckets stored as orc tblproperties ('transactional'='true');",
                "Insert into student_acid(name, age, gpa) select * from studenttab10k;"
            ],
            "ExpectedBehavior": "The insert operation should successfully copy data from the source table to the destination bucketed table without throwing any exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown during the execution of the insert statement, causing the operation to fail.",
            "Suggestions": "Ensure that the destination table is properly defined with all necessary properties set, particularly for bucketing and sorting. Review the implementation of the genBucketingSortingDest and genReduceSinkPlan methods to handle null cases more gracefully.",
            "problem_location": {
                "files": [
                    "SemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.SemanticAnalyzer"
                ],
                "methods": [
                    "genBucketingSortingDest",
                    "genReduceSinkPlan"
                ]
            },
            "possible_fix": "In the genBucketingSortingDest method, add checks to ensure that the destination table and its properties are not null before proceeding with the logic. Additionally, in the genReduceSinkPlan method, validate the input operator and its associated properties to prevent null dereferences."
        }
    },
    {
        "filename": "HIVE-6301.json",
        "creation_time": "2014-01-24T01:42:18.000+0000",
        "bug_report": {
            "Title": "get_json_object throws java.lang.IllegalStateException: No match found exception.",
            "Description": "The issue arises when the method 'extract' in the UDFJson class attempts to access a group from a Matcher object without first confirming that a match was found. Specifically, the method calls 'mKey.group(1)' without checking if 'mKey.matches()' returned true, leading to an IllegalStateException when no match is found. This bug persists in the latest version of the codebase.",
            "StackTrace": [
                "2014-01-23 11:08:19,869 FATAL ExecReducer: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to execute method public org.apache.hadoop.io.Text org.apache.hadoop.hive.ql.udf.UDFJson.evaluate(java.lang.String,java.lang.String)  on object org.apache.hadoop.hive.ql.udf.UDFJson@c7056d5 of class org.apache.hadoop.hive.ql.udf.UDFJson with arguments {{ .... }:java.lang.String, $.6:java.lang.String} of size 2",
                "Caused by: java.lang.IllegalStateException: No match found",
                "at java.util.regex.Matcher.group(Matcher.java:468)",
                "at org.apache.hadoop.hive.ql.udf.UDFJson.extract(UDFJson.java:190)",
                "at org.apache.hadoop.hive.ql.udf.UDFJson.evaluate(UDFJson.java:154)"
            ],
            "RootCause": "The root cause of the issue is that the code attempts to access a group from a Matcher object without verifying that a match was found, specifically in the 'extract' method of the UDFJson class.",
            "StepsToReproduce": [
                "1. Execute a query that uses the get_json_object function with a JSON string and a path that does not match the expected pattern.",
                "2. Observe the exception thrown in the logs."
            ],
            "ExpectedBehavior": "The system should return null or a default value when the path does not match the expected pattern, without throwing an exception.",
            "ObservedBehavior": "The system throws a java.lang.IllegalStateException indicating that no match was found when attempting to access a group from the Matcher.",
            "Suggestions": "Implement a check to ensure that a match was found before accessing groups from the Matcher object. This can be done by moving the call to 'mKey.group(1)' inside the conditional block that checks 'mKey.matches()'.",
            "problem_location": {
                "files": [
                    "UDFJson.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.udf.UDFJson"
                ],
                "methods": [
                    "UDFJson.evaluate",
                    "UDFJson.extract"
                ]
            },
            "possible_fix": "In the 'extract' method, modify the code to check if 'mKey.matches()' is true before calling 'mKey.group(1)'. For example:\n\nif (mKey.matches()) {\n    mKeyGroup1 = mKey.group(1);\n} else {\n    return null;\n}"
        }
    },
    {
        "filename": "HIVE-8295.json",
        "creation_time": "2014-09-29T21:16:32.000+0000",
        "bug_report": {
            "Title": "Add batch retrieve partition objects for metastore direct sql",
            "Description": "The current implementation of partition object retrieval in the MetastoreDirectSql class constructs partition objects by first fetching partition IDs. This approach fails when the number of matching partition IDs exceeds 1000, leading to an SQL syntax error due to Oracle's limitation on the maximum number of expressions in a list. The error is logged as a JDODataStoreException, which indicates that the SQL query could not be executed successfully. To resolve this issue, a batch retrieval mechanism should be implemented to handle cases where the number of partition IDs exceeds this limit, thereby improving performance and reducing memory usage.",
            "StackTrace": [
                "2014-09-29 19:30:02,942 DEBUG [pool-1-thread-1] metastore.MetaStoreDirectSql (MetaStoreDirectSql.java:timingTrace(604)) - Direct SQL query in 122.085893ms + 13.048901ms, the query is [select \"PARTITIONS\".\"PART_ID\" from \"PARTITIONS\"  inner join \"TBLS\" on \"PARTITIONS\".\"TBL_ID\" = \"TBLS\".\"TBL_ID\"     and \"TBLS\".\"TBL_NAME\" = ?   inner join \"DBS\" on \"TBLS\".\"DB_ID\" = \"DBS\".\"DB_ID\"      and \"DBS\".\"NAME\" = ? inner join \"PARTITION_KEY_VALS\" \"FILTER2\" on \"FILTER2\".\"PART_ID\" = \"PARTITIONS\".\"PART_ID\" and \"FILTER2\".\"INTEGER_IDX\" = 2 where ((\"FILTER2\".\"PART_KEY_VAL\" = ?))]",
                "2014-09-29 19:30:02,949 ERROR [pool-1-thread-1] metastore.ObjectStore (ObjectStore.java:handleDirectSqlError(2248)) - Direct SQL failed, falling back to ORM",
                "javax.jdo.JDODataStoreException: Error executing SQL query \"select \"PARTITIONS\".\"PART_ID\", \"SDS\".\"SD_ID\", \"SDS\".\"CD_ID\", \"SERDES\".\"SERDE_ID\", \"PARTITIONS\".\"CREATE_TIME\", \"PARTITIONS\".\"LAST_ACCESS_TIME\", \"SDS\".\"INPUT_FORMAT\", \"SDS\".\"IS_COMPRESSED\", \"SDS\".\"IS_STOREDASSUBDIRECTORIES\", \"SDS\".\"LOCATION\", \"SDS\".\"NUM_BUCKETS\", \"SDS\".\"OUTPUT_FORMAT\", \"SERDES\".\"NAME\", \"SERDES\".\"SLIB\" from \"PARTITIONS\"  left outer join \"SDS\" on \"PARTITIONS\".\"SD_ID\" = \"SDS\".\"SD_ID\"   left outer join \"SERDES\" on \"SDS\".\"SERDE_ID\" = \"SERDES\".\"SERDE_ID\" where \"PART_ID\" in (136,140,143,147,152,156,160,163,167,171,174,180,185,191,196,198,203,208,212,217...\n) order by \"PART_NAME\" asc\".",
                "at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:422)",
                "at org.datanucleus.api.jdo.JDOQuery.executeWithArray(JDOQuery.java:321)",
                "at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:331)",
                "at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilter(MetaStoreDirectSql.java:211)",
                "at org.apache.hadoop.hive.metastore.ObjectStore$3.getSqlResult(ObjectStore.java:1920)",
                "at org.apache.hadoop.hive.metastore.ObjectStore$3.getSqlResult(ObjectStore.java:1914)",
                "at org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.run(ObjectStore.java:2213)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByExprInternal(ObjectStore.java:1914)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByExpr(ObjectStore.java:1887)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98)",
                "at com.sun.proxy.$Proxy8.getPartitionsByExpr(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_partitions_by_expr(HiveMetaStore.java:3800)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions_by_expr.getResult(ThriftHiveMetastore.java:9366)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions_by_expr.getResult(ThriftHiveMetastore.java:9350)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge20S.java:617)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge20S.java:613)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1637)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge20S.java:613)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run_aroundBody0(TThreadPoolServer.java:206)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run_aroundBody1$advice(TThreadPoolServer.java:101)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:1)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)",
                "NestedThrowablesStackTrace:",
                "java.sql.SQLSyntaxErrorException: ORA-01795: maximum number of expressions in a list is 1000"
            ],
            "RootCause": "The root cause of the issue is the SQL query generated in the getPartitionsViaSqlFilterInternal method, which attempts to retrieve partition IDs using an 'IN' clause that exceeds Oracle's limit of 1000 expressions. This results in a SQLSyntaxErrorException.",
            "StepsToReproduce": [
                "1. Set up a Hive metastore with a table that has more than 1000 partitions.",
                "2. Execute a query that filters partitions using a condition that matches more than 1000 partition IDs.",
                "3. Observe the error in the logs indicating that the direct SQL query has failed."
            ],
            "ExpectedBehavior": "The system should retrieve partition objects without exceeding the SQL expression limit, either by batching the requests or using an alternative method to fetch the data.",
            "ObservedBehavior": "The system fails to execute the SQL query when the number of partition IDs exceeds 1000, resulting in a JDODataStoreException and falling back to ORM.",
            "Suggestions": "Implement a batching mechanism to retrieve partition IDs in groups of 1000 or fewer. This can be done by modifying the getPartitionsViaSqlFilterInternal method to split the partition ID retrieval into multiple queries if the number of IDs exceeds the limit.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.MetaStoreDirectSql",
                    "org.apache.hadoop.hive.metastore.ObjectStore"
                ],
                "methods": [
                    "MetaStoreDirectSql.getPartitionsViaSqlFilterInternal",
                    "ObjectStore.getPartitionsByExprInternal"
                ]
            },
            "possible_fix": "Modify the getPartitionsViaSqlFilterInternal method to check the size of the partition IDs list and split it into batches of 1000 or fewer. For example:\n\n```java\nif (partIds.size() > 1000) {\n    List<String> batches = Lists.partition(partIds, 1000);\n    for (List<String> batch : batches) {\n        // Execute the query for each batch\n    }\n} else {\n    // Execute the query normally\n}\n```"
        }
    },
    {
        "filename": "HIVE-8915.json",
        "creation_time": "2014-11-19T19:40:17.000+0000",
        "bug_report": {
            "Title": "Log file explosion due to non-existence of COMPACTION_QUEUE table",
            "Description": "The issue arises when the Hive metastore attempts to access the COMPACTION_QUEUE table during startup, which does not exist in the database. This leads to an endless loop of error logging, causing the log file to grow excessively large. The system should implement a mechanism to handle this error gracefully, either by introducing a delay before retrying or by failing the startup process if the required table is missing.",
            "StackTrace": [
                "2014-11-19 01:44:57,654 ERROR compactor.Cleaner (Cleaner.java:run(143)) - Caught an exception in the main loop of compactor cleaner, MetaException(message:Unable to connect to transaction database com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'hive.COMPACTION_QUEUE' doesn't exist",
                "at sun.reflect.GeneratedConstructorAccessor20.newInstance(Unknown Source)",
                "at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)",
                "at java.lang.reflect.Constructor.newInstance(Constructor.java:513)",
                "at com.mysql.jdbc.Util.handleNewInstance(Util.java:411)",
                "at com.mysql.jdbc.Util.getInstance(Util.java:386)",
                "at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1052)",
                "at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3597)",
                "at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3529)",
                "at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1990)",
                "at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2151)",
                "at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2619)",
                "at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2569)",
                "at com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1524)",
                "at com.jolbox.bonecp.StatementHandle.executeQuery(StatementHandle.java:464)",
                "at org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler.findReadyToClean(CompactionTxnHandler.java:266)",
                "at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.run(Cleaner.java:86)"
            ],
            "RootCause": "The root cause of the issue is the absence of the COMPACTION_QUEUE table in the Hive metastore database, which leads to a SQL exception when the system attempts to query it during startup.",
            "StepsToReproduce": [
                "Set up a fresh Hive installation without executing the hive-txn-schema-0.14.0.mysql.sql script to create necessary database tables.",
                "Start the Hive metastore service.",
                "Observe the log file for repeated error messages related to the missing COMPACTION_QUEUE table."
            ],
            "ExpectedBehavior": "The Hive metastore should either successfully start without errors or provide a clear error message indicating that the required database tables are missing, without entering an endless loop of error logging.",
            "ObservedBehavior": "The Hive metastore enters an endless loop of error logging due to the missing COMPACTION_QUEUE table, causing the log file to grow excessively large.",
            "Suggestions": "Implement a check during the metastore startup to verify the existence of required tables. If the COMPACTION_QUEUE table is missing, log a clear error message and terminate the startup process instead of entering a retry loop.",
            "problem_location": {
                "files": [
                    "CompactionTxnHandler.java",
                    "Cleaner.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler",
                    "org.apache.hadoop.hive.ql.txn.compactor.Cleaner"
                ],
                "methods": [
                    "CompactionTxnHandler.findReadyToClean",
                    "Cleaner.run"
                ]
            },
            "possible_fix": "In the findReadyToClean method of CompactionTxnHandler, add a check for the existence of the COMPACTION_QUEUE table before executing the query. If the table does not exist, throw a MetaException with a clear message and prevent further execution."
        }
    },
    {
        "filename": "HIVE-7249.json",
        "creation_time": "2014-06-18T00:09:42.000+0000",
        "bug_report": {
            "Title": "HiveTxnManager.closeTxnManager() throws if called after commitTxn()",
            "Description": "The issue arises when the method closeTxnManager() is called after commitTxn(). The expected behavior is that after committing a transaction, all associated locks should be released, and closeTxnManager() should not throw an exception. However, the current implementation does not properly track the state of locks after a transaction is committed, leading to a NoSuchLockException when attempting to unlock a lock that has already been released.",
            "StackTrace": [
                "2014-06-17 15:54:40,804 ERROR metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(143)) - NoSuchLockException(message:No such lock: 1)",
                "at org.apache.hadoop.hive.metastore.txn.TxnHandler.heartbeatLock(TxnHandler.java:1407)",
                "at org.apache.hadoop.hive.metastore.txn.TxnHandler.unlock(TxnHandler.java:477)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.unlock(HiveMetaStore.java:4817)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)",
                "at com.sun.proxy.$Proxy14.unlock(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.unlock(HiveMetaStoreClient.java:1598)",
                "at org.apache.hadoop.hive.ql.lockmgr.DbLockManager.unlock(DbLockManager.java:110)",
                "at org.apache.hadoop.hive.ql.lockmgr.DbLockManager.close(DbLockManager.java:162)",
                "at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.destruct(DbTxnManager.java:300)",
                "at org.apache.hadoop.hive.ql.lockmgr.HiveTxnManagerImpl.closeTxnManager(HiveTxnManagerImpl.java:39)",
                "at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.closeTxnManager(DbTxnManager.java:43)",
                "at org.apache.hive.hcatalog.mapreduce.TransactionContext.cleanup(TransactionContext.java:327)",
                "at org.apache.hive.hcatalog.mapreduce.TransactionContext.onCommitJob(TransactionContext.java:142)",
                "at org.apache.hive.hcatalog.mapreduce.OutputCommitterContainer.commitJob(OutputCommitterContainer.java:61)",
                "at org.apache.hive.hcatalog.mapreduce.FileOutputCommitterContainer.commitJob(FileOutputCommitterContainer.java:251)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:537)"
            ],
            "RootCause": "The root cause of the issue is that the lock management system does not properly update the state of locks after a transaction is committed. Specifically, the unlock method is called on a lock that has already been released, resulting in a NoSuchLockException.",
            "StepsToReproduce": [
                "1. Open a transaction using openTxn().",
                "2. Acquire locks for a query (e.g., INSERT INTO T PARTITION(p) SELECT * FROM T).",
                "3. Call commitTxn() to commit the transaction.",
                "4. Call closeTxnManager() to close the transaction manager."
            ],
            "ExpectedBehavior": "After calling commitTxn(), the locks associated with the transaction should be released, and calling closeTxnManager() should not throw any exceptions.",
            "ObservedBehavior": "Calling closeTxnManager() after commitTxn() results in a NoSuchLockException, indicating that the lock cannot be found.",
            "Suggestions": "Review the implementation of the lock management system to ensure that locks are properly released and their state is updated after a transaction is committed. Consider adding checks to prevent unlock calls on already released locks.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbLockManager.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.txn.TxnHandler",
                    "org.apache.hadoop.hive.ql.lockmgr.DbLockManager",
                    "org.apache.hadoop.hive.ql.lockmgr.DbTxnManager",
                    "org.apache.hadoop.hive.metastore.HiveMetaStoreClient"
                ],
                "methods": [
                    "TxnHandler.unlock",
                    "DbLockManager.unlock",
                    "DbTxnManager.destruct",
                    "HiveMetaStoreClient.unlock"
                ]
            },
            "possible_fix": "In the unlock method of TxnHandler, ensure that the state of the lock is checked before attempting to unlock it. If the lock has already been released, handle this case gracefully without throwing an exception. Additionally, ensure that the lock state is updated correctly in the commitTxn method."
        }
    },
    {
        "filename": "HIVE-11540.json",
        "creation_time": "2015-08-12T23:12:18.000+0000",
        "bug_report": {
            "Title": "Too many delta files during Compaction - OOM",
            "Description": "The system encounters an OutOfMemoryError during the compaction process of delta files in Hive when handling a high volume of records (20 million per day). The compaction process fails to complete due to excessive memory consumption, leading to a backlog of delta files that need to be cleaned up. This issue arises despite having multiple compactors running at different intervals, indicating that the current configuration is insufficient to handle the load.",
            "StackTrace": [
                "2015-08-12 15:05:01,197 FATAL [main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.OutOfMemoryError: Direct buffer memory",
                "2015-08-12 15:36:18,443 ERROR [upladevhwd04v.researchnow.com-18]: compactor.Worker (Worker.java:run(176)) - Caught exception while trying to compact weblogs.vop_hs.dt=15-08-12. Marking clean to avoid repeated failures, java.io.IOException: Job failed!",
                "at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:865)",
                "at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:186)",
                "at org.apache.hadoop.hive.ql.txn.compactor.Worker$1.run(Worker.java:169)"
            ],
            "RootCause": "The OutOfMemoryError is caused by the compactor attempting to process too many delta files simultaneously without sufficient memory allocation. The compaction job fails due to the high number of delta files and the memory constraints of the system.",
            "StepsToReproduce": [
                "Stream 20 million records to Kafka and Flume using a Hive sink.",
                "Configure 5 compactors to run at intervals of 30 minutes, 5 minutes, and 5 seconds.",
                "Monitor the compaction process and observe the memory usage."
            ],
            "ExpectedBehavior": "The compaction process should complete successfully without running out of memory, effectively cleaning up delta files and maintaining performance.",
            "ObservedBehavior": "The compaction process fails with an OutOfMemoryError, leading to a backlog of delta files that are not cleaned up.",
            "Suggestions": "Consider increasing the memory allocation for the compactor tasks. Additionally, evaluate the compaction frequency and the number of concurrent compactors to better match the workload. Implementing a more efficient delta file management strategy may also help.",
            "problem_location": {
                "files": [
                    "CompactorMR.java",
                    "Worker.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.txn.compactor.CompactorMR",
                    "org.apache.hadoop.hive.ql.txn.compactor.Worker"
                ],
                "methods": [
                    "CompactorMR.run",
                    "Worker.run"
                ]
            },
            "possible_fix": "Increase the memory allocation for the compactor tasks in the configuration settings. For example, adjust the Yarn memory settings to allow for more direct buffer memory. Additionally, consider optimizing the compaction logic to handle fewer delta files at a time or implement a batching mechanism."
        }
    },
    {
        "filename": "HIVE-15755.json",
        "creation_time": "2017-01-30T20:48:25.000+0000",
        "bug_report": {
            "Title": "NullPointerException on invalid table name in ON clause of Merge statement",
            "Description": "A NullPointerException occurs when an invalid table name is specified in the ON clause of a MERGE statement. This happens because the system attempts to access a table that does not exist, leading to a failure in the semantic analysis phase of the query compilation. The error is triggered specifically in the `getPredicate` method of the `OnClauseAnalyzer` class, which fails to handle the case where the table name is invalid.",
            "StackTrace": [
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer$OnClauseAnalyzer.getPredicate(UpdateDeleteSemanticAnalyzer.java:1143)",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer$OnClauseAnalyzer.access$400(UpdateDeleteSemanticAnalyzer.java:1049)",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.handleInsert(UpdateDeleteSemanticAnalyzer.java:1025)",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeMerge(UpdateDeleteSemanticAnalyzer.java:660)",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:80)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:230)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:465)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:321)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1221)",
                "at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1215)"
            ],
            "RootCause": "The root cause of the NullPointerException is the attempt to access a non-existent table in the ON clause of the MERGE statement, which is not properly validated before being processed.",
            "StepsToReproduce": [
                "1. Create a source table: `create table src (col1 int, col2 int);`",
                "2. Create a target table: `create table trgt (tcol1 int, tcol2 int);`",
                "3. Insert a row into the source table: `insert into src values (1, 232);`",
                "4. Execute a MERGE statement with an invalid table name in the ON clause: `merge into trgt using (select * from src) sub on sub.col1 = invalidtablename.tcol1 when not matched then insert values (sub.col1, sub.col2);`"
            ],
            "ExpectedBehavior": "The system should validate the table names in the ON clause and return a meaningful error message indicating that the specified table does not exist, rather than throwing a NullPointerException.",
            "ObservedBehavior": "The system throws a NullPointerException when an invalid table name is specified in the ON clause of the MERGE statement.",
            "Suggestions": "Implement validation checks for table names in the ON clause before processing the MERGE statement. This can be done by adding a method to verify the existence of the tables involved in the query.",
            "problem_location": {
                "files": [
                    "UpdateDeleteSemanticAnalyzer.java",
                    "BaseSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer"
                ],
                "methods": [
                    "UpdateDeleteSemanticAnalyzer.analyzeMerge",
                    "BaseSemanticAnalyzer.analyze"
                ]
            },
            "possible_fix": "Add a validation step in the `analyzeMerge` method to check if the target and source tables exist before proceeding with the analysis. If a table does not exist, throw a SemanticException with a clear error message."
        }
    },
    {
        "filename": "HIVE-9390.json",
        "creation_time": "2015-01-15T18:50:32.000+0000",
        "bug_report": {
            "Title": "Enhance retry logic wrt DB access in TxnHandler",
            "Description": "The system encounters a timeout error when attempting to retrieve a JDBC connection from the connection pool, leading to a failure in executing database transactions. This issue arises specifically in the `TxnHandler.getDbConn` method, where the connection retrieval process fails due to a read timeout. The retry logic in place does not adequately handle this scenario, resulting in unhandled exceptions that propagate up the call stack.",
            "StackTrace": [
                "2015-01-13 16:09:21,148 ERROR metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(141)) - org.apache.thrift.TException: MetaException(message:Unable to get jdbc connection from pool, Read timed out)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_open_txns(HiveMetaStore.java:5324)",
                "at org.apache.hadoop.hive.metastore.txn.TxnHandler.getOpenTxns(TxnHandler.java:196)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:102)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90)",
                "at org.apache.hadoop.hive.ql.lockmgr.DbTxnManager.getValidTxns(DbTxnManager.java:289)",
                "at org.apache.hadoop.hive.ql.Driver.recordValidTxns(Driver.java:882)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:399)",
                "at org.apache.hadoop.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:100)",
                "at org.apache.hadoop.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:171)"
            ],
            "RootCause": "The root cause of the issue is a read timeout when attempting to obtain a JDBC connection from the connection pool in the `TxnHandler.getDbConn` method. This indicates that the connection pool may be exhausted or misconfigured, leading to failures in establishing new connections.",
            "StepsToReproduce": [
                "1. Configure the database connection pool with a low maximum connection limit.",
                "2. Execute multiple concurrent transactions that require database access.",
                "3. Observe the logs for timeout errors related to JDBC connection retrieval."
            ],
            "ExpectedBehavior": "The system should successfully retrieve a JDBC connection from the pool and handle any connection timeouts gracefully, allowing for retries without failing the transaction.",
            "ObservedBehavior": "The system fails to retrieve a JDBC connection, resulting in a read timeout error and subsequent failure of the transaction processing.",
            "Suggestions": "Increase the maximum number of connections in the connection pool configuration. Implement enhanced retry logic in the `TxnHandler.getDbConn` method to handle connection timeouts more effectively, possibly by introducing exponential backoff for retries.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.txn.TxnHandler",
                    "org.apache.hadoop.hive.metastore.RetryingHMSHandler"
                ],
                "methods": [
                    "TxnHandler.getDbConn",
                    "RetryingHMSHandler.invoke"
                ]
            },
            "possible_fix": "In the `TxnHandler.getDbConn` method, implement a retry mechanism that includes exponential backoff for connection attempts. For example:\n\n```java\nprotected Connection getDbConn(int isolationLevel) throws MetaException {\n    int attempts = 0;\n    while (attempts < MAX_RETRIES) {\n        try {\n            Connection dbConn = connPool.getConnection();\n            dbConn.setAutoCommit(false);\n            dbConn.setTransactionIsolation(isolationLevel);\n            return dbConn;\n        } catch (SQLException e) {\n            attempts++;\n            if (attempts >= MAX_RETRIES) {\n                String msg = \"Unable to get jdbc connection from pool, \" + e.getMessage();\n                throw new MetaException(msg);\n            }\n            Thread.sleep((long) Math.pow(2, attempts) * 1000); // Exponential backoff\n        }\n    }\n    throw new MetaException(\"Max retries reached for getting DB connection\");\n}\n```"
        }
    },
    {
        "filename": "HIVE-7623.json",
        "creation_time": "2014-08-05T23:58:27.000+0000",
        "bug_report": {
            "Title": "Hive partition rename fails if filesystem cache is disabled",
            "Description": "The issue arises when attempting to rename a partition in Hive while the filesystem cache is disabled. The operation fails with an InvalidOperationException indicating that the new location is on a different filesystem than the old location. This behavior is similar to a previously reported issue (HIVE-3815). The root cause is related to the comparison of filesystem objects using '!=' instead of a proper method to check if they are the same filesystem.",
            "StackTrace": [
                "2014-08-05 21:46:14,522 ERROR [pool-3-thread-1]: metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(143)) - InvalidOperationException(message:table new location hdfs://hadoop-namenode:8020/user/hive/warehouse/sample_logs/XX=AA/YY=123 is on a different file system than the old location hdfs://hadoop-namenode:8020/user/hive/warehouse/sample_logs/XX=AA/YY=456. This operation is not supported)",
                "at org.apache.hadoop.hive.metastore.HiveAlterHandler.alterPartition(HiveAlterHandler.java:361)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.rename_partition(HiveMetaStore.java:2629)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.rename_partition(HiveMetaStore.java:2602)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:622)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)",
                "at com.sun.proxy.$Proxy5.rename_partition(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$rename_partition.getResult(ThriftHiveMetastore.java:9057)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$rename_partition.getResult(ThriftHiveMetastore.java:9041)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:416)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)"
            ],
            "RootCause": "The root cause of the issue is the use of '!=' to compare filesystem objects in the HiveAlterHandler class, which does not correctly determine if two paths are on the same filesystem.",
            "StepsToReproduce": [
                "Set fs.hdfs.impl.disable.cache=true and fs.file.impl.disable.cache=true.",
                "Attempt to rename a partition in Hive using the alterPartition method.",
                "Observe the InvalidOperationException indicating different filesystems."
            ],
            "ExpectedBehavior": "The partition should be renamed successfully without any errors, regardless of the filesystem cache settings.",
            "ObservedBehavior": "An InvalidOperationException is thrown, indicating that the new location is on a different filesystem than the old location.",
            "Suggestions": "Modify the comparison of filesystem objects in the HiveAlterHandler class to use a method that correctly checks if two paths belong to the same filesystem.",
            "problem_location": {
                "files": [
                    "HiveAlterHandler.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.HiveAlterHandler"
                ],
                "methods": [
                    "alterPartition"
                ]
            },
            "possible_fix": "Change the comparison from 'if (srcFs != destFs)' to 'if (!srcFs.equals(destFs))' in the alterPartition method to ensure proper filesystem comparison."
        }
    },
    {
        "filename": "HIVE-15997.json",
        "creation_time": "2017-02-21T16:49:46.000+0000",
        "bug_report": {
            "Title": "Resource leaks when query is cancelled",
            "Description": "When a query is cancelled, there are potential resource leaks related to file system operations and ZooKeeper locks. The logs indicate that the system fails to properly release resources, leading to warnings about unremoved scratch directories and failed lock releases. This can result in resource exhaustion and degraded performance over time.",
            "StackTrace": [
                "2017-02-02 06:23:25,410 WARN hive.ql.Context: [HiveServer2-Background-Pool: Thread-61]: Error Removing Scratch: java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: \"ychencdh511t-1.vpc.cloudera.com/172.26.11.50\"; destination host is: \"ychencdh511t-1.vpc.cloudera.com\":8020;",
                "at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)",
                "at org.apache.hadoop.ipc.Client.call(Client.java:1476)",
                "at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:535)",
                "at org.apache.hadoop.hive.ql.Context.removeScratchDir(Context.java:405)",
                "at org.apache.hadoop.hive.ql.Context.clear(Context.java:541)",
                "at org.apache.hadoop.hive.ql.Driver.releaseContext(Driver.java:2109)",
                "at org.apache.hadoop.hive.ql.Driver.closeInProcess(Driver.java:2150)",
                "at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:237)",
                "at org.apache.hive.service.cli.operation.SQLOperation.access$300(SQLOperation.java:88)",
                "at org.apache.hive.service.cli.operation.SQLOperation$3$1.run(SQLOperation.java:293)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the resource leaks is the failure to properly handle the cancellation of queries, which leads to unhandled exceptions during the cleanup process. Specifically, the `removeScratchDir` and `releaseLocks` methods do not adequately manage the state when a query is interrupted, resulting in resources not being released.",
            "StepsToReproduce": [
                "1. Start a long-running query in the Hive environment.",
                "2. Cancel the query before it completes.",
                "3. Observe the logs for warnings about resource leaks."
            ],
            "ExpectedBehavior": "Upon cancelling a query, all associated resources, including scratch directories and locks, should be properly released without any warnings or errors in the logs.",
            "ObservedBehavior": "When a query is cancelled, warnings are logged indicating that scratch directories could not be removed and that ZooKeeper locks could not be released, leading to potential resource leaks.",
            "Suggestions": "Implement proper exception handling in the `removeScratchDir` and `releaseLocks` methods to ensure that resources are released even when a query is interrupted. Additionally, consider adding checks to ensure that resources are not attempted to be released if they are already in a closed or cancelled state.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/Context.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/Driver.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.Context",
                    "org.apache.hadoop.hive.ql.Driver",
                    "org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager"
                ],
                "methods": [
                    "Context.removeScratchDir",
                    "Context.clear",
                    "Driver.releaseContext",
                    "ZooKeeperHiveLockManager.releaseLocks"
                ]
            },
            "possible_fix": "In the `Context.clear` method, ensure that the `removeScratchDir` method is called within a try-catch block that handles `IOException` properly. In the `ZooKeeperHiveLockManager.releaseLocks` method, add checks to ensure that locks are only released if they are in a valid state. Additionally, modify the `Driver.closeInProcess` method to ensure that resources are released even when interrupted."
        }
    },
    {
        "filename": "HIVE-7009.json",
        "creation_time": "2014-05-02T20:50:24.000+0000",
        "bug_report": {
            "Title": "HIVE_USER_INSTALL_DIR could not be set to non-HDFS filesystem",
            "Description": "The current implementation in DagUtils.java enforces that the user path obtained from HIVE_USER_INSTALL_DIR must be an HDFS path. This restriction prevents the execution of Hive+Tez jobs on non-HDFS filesystems, such as WASB. The method getDefaultDestDir checks if the filesystem of the user path is an instance of DistributedFileSystem, and throws an IOException if it is not, leading to failures when attempting to run jobs on non-HDFS filesystems.",
            "StackTrace": [
                "2014-05-01 00:21:39,847 ERROR exec.Task (TezTask.java:execute(192)) - Failed to execute tez graph.",
                "java.io.IOException: wasb://hdi31-chuanliu@clhdistorage.blob.core.windows.net/user is not a hdfs uri",
                "at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getDefaultDestDir(DagUtils.java:662)",
                "at org.apache.hadoop.hive.ql.exec.tez.DagUtils.getHiveJarDirectory(DagUtils.java:759)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.createJarLocalResource(TezSessionState.java:321)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:159)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:154)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1504)"
            ],
            "RootCause": "The root cause of the issue is the enforced check in the getDefaultDestDir method, which requires the filesystem of the user path to be a DistributedFileSystem (HDFS). This check does not allow for the use of alternative filesystems like WASB.",
            "StepsToReproduce": [
                "Set the HIVE_USER_INSTALL_DIR to a non-HDFS filesystem (e.g., WASB).",
                "Attempt to run a Hive+Tez job that utilizes this configuration.",
                "Observe the IOException indicating that the URI is not an HDFS URI."
            ],
            "ExpectedBehavior": "The system should allow Hive+Tez jobs to run on non-HDFS filesystems without throwing an IOException.",
            "ObservedBehavior": "An IOException is thrown stating that the provided URI is not an HDFS URI, preventing the job from executing.",
            "Suggestions": "Modify the getDefaultDestDir method to allow for non-HDFS filesystems by removing the check for DistributedFileSystem or by implementing a more flexible filesystem handling mechanism.",
            "problem_location": {
                "files": [
                    "DagUtils.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.tez.DagUtils"
                ],
                "methods": [
                    "getDefaultDestDir"
                ]
            },
            "possible_fix": "In DagUtils.java, modify the getDefaultDestDir method to allow for non-HDFS filesystems. For example, replace the check for DistributedFileSystem with a more general check that accommodates other filesystem types."
        }
    },
    {
        "filename": "HIVE-2031.json",
        "creation_time": "2011-03-08T11:38:53.000+0000",
        "bug_report": {
            "Title": "Improve Exception Message for Partition Load Failure",
            "Description": "When attempting to load data into a partitioned table with two partitions by specifying only one partition in the load statement, the system fails and logs a generic exception message indicating that the specified partition was not found. This lack of clarity makes it difficult to trace the root cause of the issue. The exception thrown is a SemanticException, which occurs during the semantic analysis phase of the load command execution.",
            "StackTrace": [
                "org.apache.hadoop.hive.ql.parse.SemanticException: line 1:91 Partition not found '21Oct'",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec.<init>(BaseSemanticAnalyzer.java:685)",
                "at org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer.analyzeInternal(LoadSemanticAnalyzer.java:196)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:238)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:340)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:736)",
                "at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:151)",
                "at org.apache.hadoop.hive.service.ThriftHive$Processor$execute.process(ThriftHive.java:764)",
                "at org.apache.hadoop.hive.service.ThriftHive$Processor.process(ThriftHive.java:742)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)",
                "at java.lang.Thread.run(Thread.java:619)"
            ],
            "RootCause": "The root cause of the issue is that the load command is attempting to load data into a partition that does not exist. The system should provide a more descriptive error message that indicates which partition is missing and possibly suggest checking the available partitions in the table.",
            "StepsToReproduce": [
                "1. Create a partitioned table with two partitions.",
                "2. Attempt to load data into the table by specifying only one of the partitions in the load statement.",
                "3. Observe the exception message logged."
            ],
            "ExpectedBehavior": "The system should either successfully load the data into the specified partition or provide a clear and informative error message indicating that the specified partition does not exist.",
            "ObservedBehavior": "The system throws a SemanticException with a generic message stating that the partition was not found, making it difficult to understand the underlying issue.",
            "Suggestions": "Enhance the exception handling in the LoadSemanticAnalyzer to provide more detailed error messages that include the name of the missing partition and a suggestion to check the existing partitions.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer"
                ],
                "methods": [
                    "LoadSemanticAnalyzer.analyzeInternal",
                    "BaseSemanticAnalyzer$tableSpec.<init>"
                ]
            },
            "possible_fix": "In the analyzeInternal method of LoadSemanticAnalyzer, modify the exception handling to include the name of the partition that was not found. For example, change the line that throws the SemanticException to: \n\nthrow new SemanticException(\"Partition not found: '\" + partitionName + \"'. Please check the available partitions.\");"
        }
    },
    {
        "filename": "HIVE-4018.json",
        "creation_time": "2013-02-13T09:02:20.000+0000",
        "bug_report": {
            "Title": "MapJoin failing with Distributed Cache error",
            "Description": "The issue occurs when executing a star join query after the changes introduced in HIVE-3784. The system fails with a Distributed Cache error, specifically an EOFException, indicating that the system is unable to load the necessary data from the distributed cache. This is likely due to an issue in the loadHashTable method of the MapJoinOperator, which is responsible for loading the hash table from the distributed cache. The error suggests that the expected data is not available or is corrupted.",
            "StackTrace": [
                "2013-02-13 08:36:04,584 ERROR org.apache.hadoop.hive.ql.exec.MapJoinOperator: Load Distributed Cache Error",
                "2013-02-13 08:36:04,585 FATAL ExecMapper: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.EOFException",
                "at org.apache.hadoop.hive.ql.exec.MapJoinOperator.loadHashTable(MapJoinOperator.java:189)",
                "at org.apache.hadoop.hive.ql.exec.MapJoinOperator.cleanUpInputFileChangedOp(MapJoinOperator.java:203)",
                "at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1421)",
                "at org.apache.hadoop.hive.ql.exec.Operator.cleanUpInputFileChanged(Operator.java:1425)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:614)",
                "at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:144)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:391)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325)",
                "at org.apache.hadoop.mapred.Child$4.run(Child.java:266)"
            ],
            "RootCause": "The root cause of the issue is likely due to the loadHashTable method in the MapJoinOperator, which attempts to load data from the distributed cache but encounters an EOFException, indicating that the expected data is not available or is corrupted.",
            "StepsToReproduce": [
                "1. Set up a Hive environment with the necessary configurations.",
                "2. Execute a star join query that utilizes the MapJoinOperator.",
                "3. Observe the logs for the Distributed Cache error and EOFException."
            ],
            "ExpectedBehavior": "The MapJoinOperator should successfully load the hash table from the distributed cache without encountering any errors, allowing the star join query to execute correctly.",
            "ObservedBehavior": "The MapJoinOperator fails to load the hash table from the distributed cache, resulting in a Distributed Cache error and an EOFException, causing the star join query to fail.",
            "Suggestions": "Investigate the integrity of the data being loaded from the distributed cache. Ensure that the data is correctly written and accessible. Additionally, consider adding error handling in the loadHashTable method to provide more informative logging and potentially recover from transient issues.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/ExecMapper.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.MapJoinOperator",
                    "org.apache.hadoop.hive.ql.exec.Operator",
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.ExecMapper"
                ],
                "methods": [
                    "MapJoinOperator.loadHashTable",
                    "MapJoinOperator.cleanUpInputFileChangedOp",
                    "Operator.cleanUpInputFileChanged",
                    "MapOperator.process",
                    "ExecMapper.map"
                ]
            },
            "possible_fix": "In the loadHashTable method, add additional checks to verify the integrity of the data being loaded from the distributed cache. Implement logging to capture the state of the data before attempting to load it, and handle EOFExceptions more gracefully to provide clearer feedback on the nature of the failure."
        }
    },
    {
        "filename": "HIVE-11255.json",
        "creation_time": "2015-07-14T15:39:11.000+0000",
        "bug_report": {
            "Title": "get_table_objects_by_name() in HiveMetaStore.java needs to retrieve table objects in multiple batches",
            "Description": "The method get_table_objects_by_name() in HiveMetaStore.java currently attempts to retrieve all table objects for a given database in a single query. This approach leads to a SQLSyntaxErrorException in Oracle databases when the number of tables exceeds 1000, as Oracle imposes a limit on the number of expressions in a list. To resolve this, the method should be modified to split the list of table names into smaller batches, similar to the implementation used in the drop database operation.",
            "StackTrace": [
                "javax.jdo.JDOException: Exception thrown when executing query",
                "at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:596)",
                "at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:275)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getTableObjectsByName(ObjectStore.java:945)",
                "at sun.reflect.GeneratedMethodAccessor73.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:108)",
                "at com.sun.proxy.$Proxy0.getTableObjectsByName(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table_objects_by_name(HiveMetaStore.java:1618)",
                "at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:106)",
                "at com.sun.proxy.$Proxy5.get_table_objects_by_name(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_table_objects_by_name.getResult(ThriftHiveMetastore.java:8172)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_table_objects_by_name.getResult(ThriftHiveMetastore.java:8156)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)",
                "at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:502)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:244)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The method getTableObjectsByName() attempts to retrieve all table objects in a single query, exceeding Oracle's limit of 1000 expressions in a list, resulting in a SQLSyntaxErrorException.",
            "StepsToReproduce": [
                "1. Create a database with more than 1000 tables.",
                "2. Call the get_table_objects_by_name() method with the database name and the list of all table names."
            ],
            "ExpectedBehavior": "The method should successfully retrieve the table objects without exceeding the maximum number of expressions in a list, ideally by batching the requests.",
            "ObservedBehavior": "The method throws a SQLSyntaxErrorException due to exceeding the maximum number of expressions in a list when querying the database.",
            "Suggestions": "Implement batching in the get_table_objects_by_name() method to split the list of table names into smaller sublists, each containing no more than 1000 entries.",
            "problem_location": {
                "files": [
                    "HiveMetaStore.java",
                    "ObjectStore.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.HiveMetaStore",
                    "org.apache.hadoop.hive.metastore.ObjectStore"
                ],
                "methods": [
                    "get_table_objects_by_name",
                    "getTableObjectsByName"
                ]
            },
            "possible_fix": "Modify the getTableObjectsByName() method to process the list of table names in batches. For example:\n\npublic List<Table> getTableObjectsByName(String db, List<String> tbl_names) throws MetaException, UnknownDBException {\n    List<Table> tables = new ArrayList<>();\n    int batchSize = 1000;\n    for (int i = 0; i < tbl_names.size(); i += batchSize) {\n        List<String> batch = tbl_names.subList(i, Math.min(i + batchSize, tbl_names.size()));\n        // Execute the query for the current batch\n        // Add results to tables list\n    }\n    return tables;\n}"
        }
    },
    {
        "filename": "HIVE-10151.json",
        "creation_time": "2015-03-31T00:17:22.000+0000",
        "bug_report": {
            "Title": "Insert into A select from B fails with Acid tables when bucketed the same way",
            "Description": "The issue arises when performing an insert operation from one Acid table to another, both of which are bucketed identically. The BucketingSortingReduceSinkOptimizer utilizes BucketizedHiveInputFormat, which bypasses the ORC merge logic during read operations. This leads to the generation of bucket files instead of the expected table directory, causing the ORC processing to fail. Specifically, the error occurs when the system attempts to parse a delta file that does not conform to the expected naming convention, resulting in a RuntimeException.",
            "StackTrace": [
                "java.lang.RuntimeException: serious problem",
                "at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1021)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getSplits(OrcInputFormat.java:1048)",
                "at org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat.getSplits(BucketizedHiveInputFormat.java:141)",
                "at org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:624)",
                "at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:492)",
                "at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1296)",
                "at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1293)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)",
                "at org.apache.hadoop.mapreduce.Job.submit(Job.java:1293)",
                "at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:562)",
                "at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:557)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)",
                "at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:557)",
                "at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:548)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:430)",
                "at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:137)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1650)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1409)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1192)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)",
                "at org.apache.hadoop.hive.ql.TestTxnCommands2.runStatementOnDriver(TestTxnCommands2.java:225)",
                "at org.apache.hadoop.hive.ql.TestTxnCommands2.testDeleteIn2(TestTxnCommands2.java:148)"
            ],
            "RootCause": "The root cause of the issue is that the delta file generated during the insert operation does not conform to the expected naming convention, specifically it does not start with 'base_', leading to an IllegalArgumentException when the system attempts to parse it.",
            "StepsToReproduce": [
                "Create two Acid tables with identical bucketing configurations.",
                "Insert data into the first Acid table.",
                "Attempt to insert data from the first Acid table into the second Acid table using an insert statement."
            ],
            "ExpectedBehavior": "The insert operation should successfully copy data from one Acid table to another without errors.",
            "ObservedBehavior": "The operation fails with a RuntimeException indicating a serious problem due to an invalid delta file name.",
            "Suggestions": "Ensure that the delta files generated during the insert operation conform to the expected naming conventions. This may involve modifying the logic in the OrcInputFormat or AcidUtils to handle cases where the delta files do not start with 'base_'.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/io/OrcInputFormat.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/BucketizedHiveInputFormat.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.io.OrcInputFormat",
                    "org.apache.hadoop.hive.ql.io.AcidUtils",
                    "org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat"
                ],
                "methods": [
                    "OrcInputFormat.generateSplitsInfo",
                    "AcidUtils.parseBase",
                    "BucketizedHiveInputFormat.getSplits"
                ]
            },
            "possible_fix": "Modify the parseBase method in AcidUtils to handle cases where the delta file does not start with 'base_'. Additionally, ensure that the logic in OrcInputFormat correctly generates splits for bucketed Acid tables."
        }
    },
    {
        "filename": "HIVE-13546.json",
        "creation_time": "2016-04-19T07:43:42.000+0000",
        "bug_report": {
            "Title": "Patch for HIVE-12893 is broken in branch-1",
            "Description": "The SQL query fails during execution due to an IndexOutOfBoundsException when attempting to access partition values in the dynamic partitioning process. The error occurs because the list of partition values is empty, leading to an attempt to access an index that does not exist.",
            "StackTrace": [
                "2016-04-19 15:15:35,252 FATAL [main] ExecReducer: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":null},\"value\":{\"_col0\":null,\"_col1\":5588,\"_col2\":170300,\"_col3\":null,\"_col4\":756,\"_col5\":91384,\"_col6\":16,\"_col7\":null,\"_col8\":855582,\"_col9\":28,\"_col10\":null,\"_col11\":48.83,\"_col12\":null,\"_col13\":0.0,\"_col14\":null,\"_col15\":899.64,\"_col16\":null,\"_col17\":6.14,\"_col18\":0.0,\"_col19\":null,\"_col20\":null,\"_col21\":null,\"_col22\":null}}",
                "Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0",
                "at java.util.ArrayList.rangeCheck(ArrayList.java:653)",
                "at java.util.ArrayList.get(ArrayList.java:429)",
                "at org.apache.hadoop.hive.common.FileUtils.makePartName(FileUtils.java:151)",
                "at org.apache.hadoop.hive.common.FileUtils.makePartName(FileUtils.java:131)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.getDynPartDirectory(FileSinkOperator.java:1003)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.getDynOutPaths(FileSinkOperator.java:919)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:713)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:244)"
            ],
            "RootCause": "The root cause of the issue is that the dynamic partitioning logic is attempting to access partition values from an empty list, which results in an IndexOutOfBoundsException.",
            "StepsToReproduce": [
                "Set the necessary Hive configuration parameters as specified in the original report.",
                "Run the provided SQL query that attempts to insert data into the 'store_sales' table with dynamic partitioning enabled.",
                "Observe the error in the logs indicating the IndexOutOfBoundsException."
            ],
            "ExpectedBehavior": "The SQL query should execute successfully, inserting data into the 'store_sales' table with the specified dynamic partitions.",
            "ObservedBehavior": "The SQL query fails with an IndexOutOfBoundsException, preventing data from being inserted into the table.",
            "Suggestions": "Ensure that the list of dynamic partition values is populated correctly before attempting to access its elements. Add checks to handle cases where the list may be empty.",
            "problem_location": {
                "files": [
                    "common/src/java/org/apache/hadoop/hive/common/FileUtils.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.common.FileUtils",
                    "org.apache.hadoop.hive.ql.exec.FileSinkOperator",
                    "org.apache.hadoop.hive.ql.exec.mr.ExecReducer"
                ],
                "methods": [
                    "FileUtils.makePartName",
                    "FileSinkOperator.getDynOutPaths",
                    "ExecReducer.reduce"
                ]
            },
            "possible_fix": "In the method 'getDynPartDirectory' of 'FileSinkOperator', add a check to ensure that the 'row' list is not empty before calling 'FileUtils.makePartName'. If it is empty, handle the case appropriately, possibly by throwing a descriptive exception or skipping the processing."
        }
    },
    {
        "filename": "HIVE-7049.json",
        "creation_time": "2014-05-12T21:46:48.000+0000",
        "bug_report": {
            "Title": "Unable to deserialize AVRO data when file schema and record schema are different and nullable",
            "Description": "The issue arises when the file schema and record schema are not aligned, particularly when the record schema is nullable while the file schema is not. This discrepancy leads to an AvroRuntimeException during deserialization, as the system fails to recognize the union type expected for nullable records. The code snippet in question checks only if the record schema is nullable without validating the file schema, which is crucial for proper deserialization.",
            "StackTrace": [
                "org.apache.avro.AvroRuntimeException: Not a union: \"string\"",
                "at org.apache.avro.Schema.getTypes(Schema.java:272)",
                "at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.deserializeNullableUnion(AvroDeserializer.java:275)",
                "at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.worker(AvroDeserializer.java:205)",
                "at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.workerBase(AvroDeserializer.java:188)",
                "at org.apache.hadoop.hive.serde2.avro.AvroDeserializer.deserialize(AvroDeserializer.java:174)",
                "at org.apache.hadoop.hive.serde2.avro.TestAvroDeserializer.verifyNullableType(TestAvroDeserializer.java:487)",
                "at org.apache.hadoop.hive.serde2.avro.TestAvroDeserializer.canDeserializeNullableTypes(TestAvroDeserializer.java:407)"
            ],
            "RootCause": "The root cause of the issue is that the deserialization logic does not account for the case where the file schema is not nullable while the record schema is. Specifically, the method 'worker' does not validate the file schema when processing nullable types, leading to an exception when the expected union type is not found.",
            "StepsToReproduce": [
                "Create an AVRO file with a schema that is not nullable (e.g., 'string').",
                "Create a record schema that is nullable (e.g., ['null', 'string']).",
                "Attempt to deserialize the AVRO file using the record schema."
            ],
            "ExpectedBehavior": "The system should successfully deserialize the AVRO data without throwing an exception, correctly handling the nullable record schema against the non-nullable file schema.",
            "ObservedBehavior": "The system throws an AvroRuntimeException indicating that the provided schema is not a union, which prevents successful deserialization.",
            "Suggestions": "Modify the deserialization logic to check both the record schema and the file schema for nullability. If the file schema is not nullable, handle the deserialization accordingly to avoid exceptions.",
            "problem_location": {
                "files": [
                    "AvroDeserializer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.serde2.avro.AvroDeserializer"
                ],
                "methods": [
                    "worker",
                    "deserializeNullableUnion"
                ]
            },
            "possible_fix": "In the 'worker' method, add a check for the file schema's nullability before calling 'deserializeNullableUnion'. If the file schema is not nullable, handle the deserialization differently to ensure compatibility with the record schema."
        }
    },
    {
        "filename": "HIVE-9755.json",
        "creation_time": "2015-02-23T20:50:43.000+0000",
        "bug_report": {
            "Title": "Hive built-in 'ngram' UDAF fails when a mapper has no matches.",
            "Description": "The issue arises when executing a Hive query that utilizes the 'ngram' UDAF on a dataset where the input column contains null values. The error occurs during the aggregation phase, specifically when the 'n' parameter is evaluated, leading to a mismatch between expected and actual values. This results in a HiveException being thrown, indicating that the UDAF cannot process the null values correctly.",
            "StackTrace": [
                "org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{},\"value\":{\"_col0\":[\"0\",\"0\",\"0\",\"0\"]},\"alias\":0}",
                "at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:258)",
                "at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:506)",
                "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:447)",
                "at org.apache.hadoop.mapred.Child$4.run(Child.java:268)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:396)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)",
                "at org.apache.hadoop.mapred.Child.main(Child.java:262)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: GenericUDAFnGramEvaluator: mismatch in value for 'n', which usually is caused by a non-constant expression. Found '0' and '1'.",
                "at org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams$GenericUDAFnGramEvaluator.merge(GenericUDAFnGrams.java:242)",
                "at org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator.aggregate(GenericUDAFEvaluator.java:142)",
                "at org.apache.hadoop.hive.ql.exec.GroupByOperator.updateAggregations(GroupByOperator.java:658)",
                "at org.apache.hadoop.hive.ql.exec.GroupByOperator.processAggr(GroupByOperator.java:911)",
                "at org.apache.hadoop.hive.ql.exec.GroupByOperator.processKey(GroupByOperator.java:753)",
                "at org.apache.hadoop.hive.ql.exec.GroupByOperator.processOp(GroupByOperator.java:819)",
                "at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:474)",
                "at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:249)"
            ],
            "RootCause": "The root cause of the issue is the handling of null values in the input data when using the 'ngram' UDAF. The UDAF expects a constant value for 'n', but encounters a null, leading to a mismatch error during aggregation.",
            "StepsToReproduce": [
                "Create a Hive table 'ngramtest' with columns 'col1' (int) and 'col3' (string).",
                "Insert a row with 'col1' = 0 and 'col3' = null.",
                "Execute the query: SELECT explode(ngrams(sentences(lower(t.col3)), 3, 10)) as x FROM (SELECT col3 FROM ngramtest WHERE col1=0) t;"
            ],
            "ExpectedBehavior": "The query should return an empty result set or handle the null value gracefully without throwing an exception.",
            "ObservedBehavior": "The query throws a HiveException indicating a mismatch in the value for 'n' due to the presence of null values in the input data.",
            "Suggestions": "Implement null checks in the UDAF to handle cases where input values are null. Ensure that the aggregation logic can gracefully skip or handle null values without causing exceptions.",
            "problem_location": {
                "files": [
                    "GroupByOperator.java",
                    "GenericUDAFEvaluator.java",
                    "GenericUDAFnGrams.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.GroupByOperator",
                    "org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator",
                    "org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams"
                ],
                "methods": [
                    "GroupByOperator.updateAggregations",
                    "GroupByOperator.processAggr",
                    "GenericUDAFnGrams$GenericUDAFnGramEvaluator.merge"
                ]
            },
            "possible_fix": "Modify the 'merge' method in 'GenericUDAFnGrams$GenericUDAFnGramEvaluator' to include null checks for the input parameters. If a null is encountered, either skip the aggregation for that row or handle it in a way that does not cause a mismatch error."
        }
    },
    {
        "filename": "HIVE-19130.json",
        "creation_time": "2018-04-09T10:18:33.000+0000",
        "bug_report": {
            "Title": "NPE is thrown when REPL LOAD applied drop partition event.",
            "Description": "During incremental replication, a NullPointerException (NPE) occurs when executing a REPL LOAD operation on the second batch of events after a DROP_PARTITION event. The issue arises when the system attempts to access a table that has already been dropped, leading to a failure in retrieving the necessary metadata for the partitions.",
            "StackTrace": [
                "2018-04-05 16:20:36,531 ERROR [HiveServer2-Background-Pool: Thread-107044]: metadata.Hive (Hive.java:getTable(1219)) - Table catalog_sales_new not found: new5_tpcds_real_bin_partitioned_orc_1000.catalog_sales_new table not found",
                "2018-04-05 16:20:36,538 ERROR [HiveServer2-Background-Pool: Thread-107044]: exec.DDLTask (DDLTask.java:failed(540)) - org.apache.hadoop.hive.ql.metadata.HiveException",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getPartitionsByExpr(Hive.java:2613)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.dropPartitions(DDLTask.java:4008)"
            ],
            "RootCause": "The NPE is caused by the attempt to access a table that has been dropped, which results in a failure to retrieve its partitions. Specifically, the method getPartitionsByExpr is called on a null reference due to the table not being found.",
            "StepsToReproduce": [
                "1. Create a table t1.",
                "2. Add a partition to t1.",
                "3. Drop the partition from t1.",
                "4. Drop the table t1.",
                "5. Attempt to perform a REPL LOAD operation that includes dropping the partition again."
            ],
            "ExpectedBehavior": "The system should handle the dropping of partitions and tables gracefully without throwing a NullPointerException, even if the table has already been dropped.",
            "ObservedBehavior": "A NullPointerException is thrown when attempting to access partitions of a table that has already been dropped during the REPL LOAD operation.",
            "Suggestions": "Implement a check to verify if the table exists before attempting to access its partitions. This can prevent the NPE from occurring when the table is not found.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.metadata.Hive",
                    "org.apache.hadoop.hive.ql.exec.DDLTask"
                ],
                "methods": [
                    "Hive.getPartitionsByExpr",
                    "DDLTask.dropPartitions"
                ]
            },
            "possible_fix": "In the dropPartitions method of DDLTask, add a check to ensure that the table exists before calling getPartitionsByExpr. For example:\n\nif (db.getTable(tbl.getTableName()) != null) {\n    db.getPartitionsByExpr(tbl, partSpec.getPartSpec(), conf, partitions);\n} else {\n    // Handle the case where the table does not exist\n}"
        }
    },
    {
        "filename": "HIVE-13090.json",
        "creation_time": "2016-02-18T21:58:48.000+0000",
        "bug_report": {
            "Title": "Hive metastore crashes on NPE with ZooKeeperTokenStore",
            "Description": "The Hive metastore is experiencing a crash due to a NullPointerException (NPE) occurring in the ZooKeeperTokenStore when attempting to decode a delegation token. This issue arises during the removal of expired tokens, where the token bytes retrieved from ZooKeeper are null, leading to a failure in the decoding process.",
            "StackTrace": [
                "ERROR [Thread[Thread-6,5,main]]: thrift.TokenStoreDelegationTokenSecretManager (TokenStoreDelegationTokenSecretManager.java:run(331)) - ExpiredTokenRemover thread received unexpected exception. org.apache.hadoop.hive.thrift.DelegationTokenStore$TokenStoreException: Failed to decode token",
                "org.apache.hadoop.hive.thrift.DelegationTokenStore$TokenStoreException: Failed to decode token",
                "at org.apache.hadoop.hive.thrift.ZooKeeperTokenStore.getToken(ZooKeeperTokenStore.java:401)",
                "at org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager.removeExpiredTokens(TokenStoreDelegationTokenSecretManager.java:256)",
                "at org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager$ExpiredTokenRemover.run(TokenStoreDelegationTokenSecretManager.java:319)",
                "Caused by: java.lang.NullPointerException",
                "at java.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106)",
                "at org.apache.hadoop.security.token.delegation.HiveDelegationTokenSupport.decodeDelegationTokenInformation(HiveDelegationTokenSupport.java:53)",
                "at org.apache.hadoop.hive.thrift.ZooKeeperTokenStore.getToken(ZooKeeperTokenStore.java:399)"
            ],
            "RootCause": "The root cause of the issue is that the tokenBytes retrieved from ZooKeeper are null, which leads to a NullPointerException when attempting to create a ByteArrayInputStream in the decodeDelegationTokenInformation method.",
            "StepsToReproduce": [
                "1. Start the Hive metastore service.",
                "2. Ensure that there are expired delegation tokens in the token store.",
                "3. Trigger the removal of expired tokens, which invokes the getToken method in ZooKeeperTokenStore."
            ],
            "ExpectedBehavior": "The Hive metastore should successfully remove expired tokens without crashing, and the expired token removal process should handle null token bytes gracefully.",
            "ObservedBehavior": "The Hive metastore crashes with a NullPointerException when attempting to decode a null token byte array during the removal of expired tokens.",
            "Suggestions": "Implement a null check for the tokenBytes before attempting to decode them in the getToken method. If tokenBytes is null, handle the situation appropriately by logging an error and skipping the decoding process.",
            "problem_location": {
                "files": [
                    "shims.common.src.main.java.org.apache.hadoop.hive.thrift.ZooKeeperTokenStore.java",
                    "shims.common.src.main.java.org.apache.hadoop.security.token.delegation.HiveDelegationTokenSupport.java",
                    "shims.common.src.main.java.org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.thrift.ZooKeeperTokenStore",
                    "org.apache.hadoop.security.token.delegation.HiveDelegationTokenSupport",
                    "org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager"
                ],
                "methods": [
                    "ZooKeeperTokenStore.getToken",
                    "HiveDelegationTokenSupport.decodeDelegationTokenInformation",
                    "TokenStoreDelegationTokenSecretManager.removeExpiredTokens"
                ]
            },
            "possible_fix": "In the getToken method of ZooKeeperTokenStore, add a null check for tokenBytes before creating the ByteArrayInputStream. For example:\n\npublic DelegationTokenInformation getToken(DelegationTokenIdentifier tokenIdentifier) {\n    byte[] tokenBytes = zkGetData(getTokenPath(tokenIdentifier));\n    if (tokenBytes == null) {\n        throw new TokenStoreException(\"Token bytes are null for token identifier: \" + tokenIdentifier);\n    }\n    try {\n        return HiveDelegationTokenSupport.decodeDelegationTokenInformation(tokenBytes);\n    } catch (Exception ex) {\n        throw new TokenStoreException(\"Failed to decode token\", ex);\n    }\n}"
        }
    },
    {
        "filename": "HIVE-5664.json",
        "creation_time": "2013-10-28T03:50:29.000+0000",
        "bug_report": {
            "Title": "Drop cascade database fails when the db has any tables with indexes",
            "Description": "When attempting to drop a database that contains tables with indexes, the operation fails with an error indicating that the database does not exist. This occurs because the drop operation attempts to access an index table that has not been properly created or is not recognized in the metastore, leading to a NoSuchObjectException.",
            "StackTrace": [
                "FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: db2",
                "Caused by: NoSuchObjectException(message:db2.tab1_indx table not found)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_table(HiveMetaStore.java:1376)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:890)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:660)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropDatabase(HiveMetaStoreClient.java:546)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.dropDatabase(Hive.java:284)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.dropDatabase(DDLTask.java:3470)"
            ],
            "RootCause": "The root cause of the issue is that the drop database operation is trying to drop an index table that does not exist in the metastore, leading to a NoSuchObjectException. This happens because the index table was not created successfully or was not registered properly.",
            "StepsToReproduce": [
                "1. Create a new database using CREATE DATABASE db2;",
                "2. Use the database with USE db2;",
                "3. Create a table with an index using CREATE TABLE tab1 (id int, name string);",
                "4. Create an index on the table using CREATE INDEX idx1 ON TABLE tab1(id) as 'COMPACT' with DEFERRED REBUILD IN TABLE tab1_indx;",
                "5. Attempt to drop the database using DROP DATABASE db2 CASCADE;"
            ],
            "ExpectedBehavior": "The database should be dropped successfully along with all its tables and indexes without any errors.",
            "ObservedBehavior": "The drop database operation fails with an error indicating that the database does not exist, specifically due to a missing index table.",
            "Suggestions": "Ensure that the index table is created and registered correctly in the metastore before attempting to drop the database. Additionally, modify the drop database logic to handle cases where index tables may not exist.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                    "org.apache.hadoop.hive.ql.exec.DDLTask"
                ],
                "methods": [
                    "HiveMetaStoreClient.dropDatabase",
                    "DDLTask.dropDatabase"
                ]
            },
            "possible_fix": "In the dropDatabase method of HiveMetaStoreClient, add a check to ensure that the index tables exist before attempting to drop them. If they do not exist, log a warning instead of throwing an exception. This can prevent the drop operation from failing when indexes are not found."
        }
    },
    {
        "filename": "HIVE-15778.json",
        "creation_time": "2017-02-01T04:20:12.000+0000",
        "bug_report": {
            "Title": "DROP INDEX (non-existent) throws NPE when using DbNotificationListener",
            "Description": "When attempting to execute a DROP INDEX command on a non-existent index, a NullPointerException (NPE) is thrown. This occurs because the control flow does not properly handle the case where the index does not exist, leading to an attempt to create a JSONDropIndexMessage with a null index variable.",
            "StackTrace": [
                "java.lang.NullPointerException",
                "at org.apache.hive.hcatalog.messaging.json.JSONDropIndexMessage.<init>(JSONDropIndexMessage.java:46)",
                "at org.apache.hive.hcatalog.messaging.json.JSONMessageFactory.buildDropIndexMessage(JSONMessageFactory.java:159)",
                "at org.apache.hive.hcatalog.listener.DbNotificationListener.onDropIndex(DbNotificationListener.java:280)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_index_by_name_core(HiveMetaStore.java:4469)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_index_by_name(HiveMetaStore.java:4396)"
            ],
            "RootCause": "The root cause of the NullPointerException is that the index variable is not set when the DROP INDEX command is executed on a non-existent index. This leads to a failure when trying to create a JSONDropIndexMessage, which expects a valid index object.",
            "StepsToReproduce": [
                "1. Execute the command: DROP INDEX IF EXISTS vamsee1 ON sample_07;",
                "2. Observe the logs for a NullPointerException."
            ],
            "ExpectedBehavior": "The system should handle the case of a non-existent index gracefully, without throwing a NullPointerException.",
            "ObservedBehavior": "A NullPointerException is thrown when trying to create a JSONDropIndexMessage for a non-existent index.",
            "Suggestions": "Implement a check in the HiveMetaStore to ensure that the index exists before attempting to create a notification event for the drop index operation.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java",
                    "hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONDropIndexMessage.java",
                    "hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/DbNotificationListener.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler",
                    "org.apache.hive.hcatalog.messaging.json.JSONDropIndexMessage",
                    "org.apache.hive.hcatalog.listener.DbNotificationListener"
                ],
                "methods": [
                    "HiveMetaStore$HMSHandler.drop_index_by_name",
                    "DbNotificationListener.onDropIndex",
                    "JSONMessageFactory.buildDropIndexMessage"
                ]
            },
            "possible_fix": "In the method HiveMetaStore$HMSHandler.drop_index_by_name, add a check to verify if the index exists before proceeding to create a drop index event. If the index does not exist, return a meaningful error message instead of proceeding to the notification listener."
        }
    },
    {
        "filename": "HIVE-8386.json",
        "creation_time": "2014-10-07T22:30:12.000+0000",
        "bug_report": {
            "Title": "HCAT API Call Case Sensitivity Issue in Struct Column Fields",
            "Description": "The HCAT API is failing to recognize field names in a case-sensitive manner when verifying the schema of a target table. Specifically, the API throws a RuntimeException indicating that it cannot find the field 'givenName' when it is provided in lowercase as 'givenname'. This issue arises from the way field names are processed in the StructTypeInfo class, which converts field names to lowercase for comparison, leading to mismatches when the original case is not preserved.",
            "StackTrace": [
                "java.lang.RuntimeException: cannot find field givenName(lowercase form: givenname) in [givenName, surname, middleName, gender, age, isGivenNameLowerCase, isGivenNameUpperCase, isPrimary, isSurnameLowerCase, isSurnameUpperCase]",
                "at org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo.getStructFieldTypeInfo(StructTypeInfo.java:109)",
                "at org.apache.hive.hcatalog.data.schema.HCatSchemaUtils.constructHCatSchema(HCatSchemaUtils.java:154)",
                "at org.apache.hive.hcatalog.data.schema.HCatSchemaUtils.getHCatSchema(HCatSchemaUtils.java:165)",
                "at org.apache.hive.hcatalog.data.schema.HCatSchemaUtils.getHCatFieldSchema(HCatSchemaUtils.java:127)",
                "at org.apache.hive.hcatalog.data.schema.HCatSchemaUtils.getHCatFieldSchema(HCatSchemaUtils.java:115)",
                "at org.apache.hive.hcatalog.api.HCatTable.<init>(HCatTable.java:59)",
                "at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getTable(HCatClientHMSImpl.java:157)",
                "at org.apache.falcon.catalog.HiveCatalogService.tableExists(HiveCatalogService.java:143)",
                "at org.apache.falcon.entity.parser.FeedEntityParser.validateStorageExists(FeedEntityParser.java:367)",
                "at org.apache.falcon.entity.parser.FeedEntityParser.validateFeedStorage(FeedEntityParser.java:309)",
                "at org.apache.falcon.entity.parser.FeedEntityParser.validate(FeedEntityParser.java:79)",
                "at org.apache.falcon.entity.parser.FeedEntityParser.validate(FeedEntityParser.java:54)",
                "at org.apache.falcon.resource.AbstractEntityManager.validate(AbstractEntityManager.java:364)",
                "at org.apache.falcon.resource.AbstractEntityManager.submitInternal(AbstractEntityManager.java:331)",
                "at org.apache.falcon.resource.AbstractEntityManager.submit(AbstractEntityManager.java:153)",
                "at org.apache.falcon.resource.ConfigSyncService.submit(ConfigSyncService.java:44)"
            ],
            "RootCause": "The root cause of the issue is the case sensitivity in field name comparisons within the StructTypeInfo class. The method getStructFieldTypeInfo converts the field name to lowercase before checking for its existence in the list of field names, which leads to a failure when the original case is not matched.",
            "StepsToReproduce": [
                "1. Create a struct with fields including 'givenName'.",
                "2. Attempt to access the field using a lowercase name 'givenname' through the HCAT API.",
                "3. Observe the RuntimeException indicating the field cannot be found."
            ],
            "ExpectedBehavior": "The HCAT API should correctly identify fields regardless of the case used in the field name.",
            "ObservedBehavior": "The API throws a RuntimeException stating it cannot find the field when the case does not match the original definition.",
            "Suggestions": "Modify the getStructFieldTypeInfo method to perform a case-insensitive search for field names, or ensure that the API calls consistently use the correct case for field names.",
            "problem_location": {
                "files": [
                    "hcatalog.core.src.main.java.org.apache.hive.hcatalog.data.schema.HCatSchemaUtils.java",
                    "serde.src.java.org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo.java"
                ],
                "classes": [
                    "org.apache.hive.hcatalog.data.schema.HCatSchemaUtils",
                    "org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo"
                ],
                "methods": [
                    "HCatSchemaUtils.constructHCatSchema",
                    "HCatSchemaUtils.getHCatFieldSchema",
                    "StructTypeInfo.getStructFieldTypeInfo"
                ]
            },
            "possible_fix": "In the StructTypeInfo.getStructFieldTypeInfo method, modify the field name comparison to be case-insensitive. For example, replace the line that checks equality with a case-insensitive comparison: \n\nif (fieldLowerCase.equalsIgnoreCase(allStructFieldNames.get(i))) {\n    return allStructFieldTypeInfos.get(i);\n}"
        }
    },
    {
        "filename": "HIVE-14714.json",
        "creation_time": "2016-09-07T15:46:07.000+0000",
        "bug_report": {
            "Title": "Avoid misleading 'java.io.IOException: Stream closed' when shutting down HoS",
            "Description": "When executing Hive commands with Spark and subsequently finishing the Beeline session or switching the execution engine, an IOException occurs. This issue manifests when using Ctrl-D to end the session, as well as when using commands like '!quit' or 'set hive.execution.engine=mr;'. The logs indicate that the Spark client is timing out while shutting down the remote driver, leading to an attempt to read from a closed stream, which results in the IOException.",
            "StackTrace": [
                "java.io.IOException: Stream closed",
                "at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)",
                "at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)",
                "at java.io.BufferedInputStream.read(BufferedInputStream.java:334)",
                "at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:283)",
                "at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:325)",
                "at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:177)",
                "at java.io.InputStreamReader.read(InputStreamReader.java:184)",
                "at java.io.BufferedReader.fill(BufferedReader.java:154)",
                "at java.io.BufferedReader.readLine(BufferedReader.java:317)",
                "at java.io.BufferedReader.readLine(BufferedReader.java:382)",
                "at org.apache.hive.spark.client.SparkClientImpl$Redirector.run(SparkClientImpl.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the IOException is that the Spark client attempts to read from a BufferedInputStream that has already been closed during the shutdown process of the remote driver. This occurs when the session is terminated abruptly, leading to an attempt to access resources that are no longer available.",
            "StepsToReproduce": [
                "1. Start a Beeline session and execute a Hive command using Spark.",
                "2. Attempt to finish the session using Ctrl-D.",
                "3. Alternatively, use the commands '!quit' or 'set hive.execution.engine=mr;'.",
                "4. Observe the logs for the IOException."
            ],
            "ExpectedBehavior": "The session should terminate gracefully without throwing an IOException, and all resources should be released properly.",
            "ObservedBehavior": "An IOException is thrown with the message 'Stream closed' when attempting to read from a closed stream during session termination.",
            "Suggestions": "Implement proper handling of the shutdown process to ensure that all streams are closed before attempting to read from them. Additionally, consider adding checks to prevent read operations on closed streams.",
            "problem_location": {
                "files": [
                    "SparkClientImpl.java"
                ],
                "classes": [
                    "org.apache.hive.spark.client.SparkClientImpl"
                ],
                "methods": [
                    "SparkClientImpl$Redirector.run"
                ]
            },
            "possible_fix": "In the 'SparkClientImpl$Redirector.run' method, add a check to ensure that the input stream is open before attempting to read from it. This can be done by wrapping the read operations in a try-catch block and handling the IOException gracefully."
        }
    },
    {
        "filename": "HIVE-5428.json",
        "creation_time": "2013-10-02T20:46:10.000+0000",
        "bug_report": {
            "Title": "Direct SQL check fails during tests",
            "Description": "The issue arises when running tests with the command `ant test -Dtestcase=TestCliDriver -Dqfile=udf_case.q -Dtest.silent=false`. The logs indicate that the initialization of the ObjectStore fails due to a missing database table 'DBS'. This leads to a SQL syntax error when the system attempts to execute a self-test query. The root cause appears to be related to the order of initialization and the state of the database.",
            "StackTrace": [
                "javax.jdo.JDODataStoreException: Error executing SQL query \"select \"DB_ID\" from \"DBS\"\".",
                "at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOJDOHelper.java:451)",
                "at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:230)",
                "at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.<init>(MetaStoreDirectSql.java:108)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:249)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:220)",
                "at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)",
                "at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)",
                "at org.apache.hadoop.hive.metastore.RetryingRawStore.<init>(RetryingRawStore.java:62)",
                "at org.apache.hadoop.hive.metastore.RetryingRawStore.getProxy(RetryingRawStore.java:71)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:418)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:405)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:444)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:329)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.<init>(HiveMetaStore.java:289)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:54)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:59)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore.newHMSHandler(HiveMetaStore.java:4084)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:126)",
                "at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)",
                "at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)",
                "at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)",
                "at java.lang.reflect.Constructor.newInstance(Constructor.java:526)",
                "at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1211)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:62)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2404)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2415)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:871)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:853)",
                "at org.apache.hadoop.hive.ql.QTestUtil.cleanUp(QTestUtil.java:534)",
                "at org.apache.hadoop.hive.cli.TestCliDriver.<clinit>(TestCliDriver.java:44)",
                "at java.lang.Class.forName0(Native Method)",
                "at java.lang.Class.forName(Class.java:190)",
                "at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:374)",
                "at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1060)",
                "at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:911)"
            ],
            "RootCause": "The root cause of the issue is that the database table 'DBS' does not exist when the system attempts to execute a SQL query during the initialization of the MetaStoreDirectSql class. This indicates that the database setup is incomplete or not properly initialized before the tests are run.",
            "StepsToReproduce": [
                "Run the command: ant test -Dtestcase=TestCliDriver -Dqfile=udf_case.q -Dtest.silent=false",
                "Check the logs for SQL execution errors related to the 'DBS' table."
            ],
            "ExpectedBehavior": "The system should successfully execute the SQL query and initialize the MetaStore without errors, allowing the tests to run successfully.",
            "ObservedBehavior": "The system fails to execute the SQL query due to the absence of the 'DBS' table, resulting in a JDODataStoreException.",
            "Suggestions": "Ensure that the database is properly initialized and that the 'DBS' table is created before running the tests. This may involve checking the database setup scripts or initialization logic.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.ObjectStore",
                    "org.apache.hadoop.hive.metastore.MetaStoreDirectSql",
                    "org.apache.hadoop.hive.ql.metadata.Hive"
                ],
                "methods": [
                    "ObjectStore.initialize",
                    "MetaStoreDirectSql.<init>",
                    "Hive.createMetaStoreClient"
                ]
            },
            "possible_fix": "To fix the issue, ensure that the database schema is correctly set up before running the tests. This may involve adding a step in the test setup to create the necessary tables, including 'DBS', or modifying the initialization order to ensure that the database is ready before any SQL queries are executed."
        }
    },
    {
        "filename": "HIVE-12567.json",
        "creation_time": "2015-12-02T16:38:52.000+0000",
        "bug_report": {
            "Title": "Enhance TxnHandler retry logic to handle ORA-08176",
            "Description": "The system encounters an ORA-08176 error, indicating a consistent read failure due to rollback data not being available. This occurs when the TxnHandler attempts to acquire locks from the metastore, leading to a LockException. The current implementation does not adequately handle this specific SQL exception, resulting in transaction failures without retries.",
            "StackTrace": [
                "FAILED: Error in acquiring locks: Error communicating with the metastore",
                "org.apache.hadoop.hive.ql.lockmgr.LockException: Error communicating with the metastore",
                "Caused by: MetaException(message:Unable to update transaction database java.sql.SQLException: ORA-08176: consistent read failure; rollback data not available"
            ],
            "RootCause": "The root cause of the issue is the lack of retry logic in the TxnHandler when encountering the ORA-08176 error during lock acquisition. The current implementation does not retry the transaction, leading to failures when the database cannot provide the necessary rollback data.",
            "StepsToReproduce": [
                "1. Initiate a transaction that requires acquiring locks on the metastore.",
                "2. Simulate a scenario where the database returns an ORA-08176 error during the lock acquisition process.",
                "3. Observe the failure in acquiring locks without any retry attempts."
            ],
            "ExpectedBehavior": "The system should retry acquiring locks when encountering an ORA-08176 error, allowing for successful transaction completion despite temporary database inconsistencies.",
            "ObservedBehavior": "The system fails to acquire locks and throws a LockException without attempting to retry the transaction, resulting in an error message and transaction rollback.",
            "Suggestions": "Implement retry logic in the TxnHandler's lock acquisition method to handle ORA-08176 errors gracefully. This could involve wrapping the lock acquisition logic in a retry mechanism that attempts to reacquire locks a specified number of times before failing.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/lockmgr/DbTxnManager.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.txn.TxnHandler",
                    "org.apache.hadoop.hive.ql.lockmgr.DbTxnManager"
                ],
                "methods": [
                    "TxnHandler.lock",
                    "DbTxnManager.acquireLocks"
                ]
            },
            "possible_fix": "In the TxnHandler.lock method, add a retry mechanism that catches SQLException for ORA-08176 and retries the lock acquisition a limited number of times before throwing an exception. Example code snippet:\n\ntry {\n    // Attempt to acquire lock\n} catch (SQLException e) {\n    if (e.getMessage().contains(\"ORA-08176\")) {\n        // Implement retry logic here\n    }\n    throw e; // rethrow if not ORA-08176\n}"
        }
    },
    {
        "filename": "HIVE-6984.json",
        "creation_time": "2014-04-28T23:08:43.000+0000",
        "bug_report": {
            "Title": "Analyzing partitioned table with NULL values for the partition column failed with NPE",
            "Description": "When attempting to analyze a partitioned table that contains NULL values in the partition column, a NullPointerException (NPE) is thrown. This occurs during the statistics gathering phase of the analysis, specifically when processing rows that have NULL values for the partition column. The issue arises because the code does not handle NULL values appropriately, leading to a failure in the gatherStats method of the TableScanOperator.",
            "StackTrace": [
                "java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"name\":\"6666666666666666666\",\"age\":null,\"raw__data__size\":19}",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:195)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:417)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:332)",
                "at org.apache.hadoop.mapred.Child$4.run(Child.java:268)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1499)",
                "at org.apache.hadoop.mapred.Child.main(Child.java:262)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"name\":\"6666666666666666666\",\"age\":null,\"raw__data__size\":19}",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:549)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:177)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:417)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:332)",
                "at org.apache.hadoop.mapred.Child$4.run(Child.java:268)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1499)",
                "at org.apache.hadoop.mapred.Child.main(Child.java:262)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.TableScanOperator.gatherStats(TableScanOperator.java:149)",
                "at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:90)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:539)"
            ],
            "RootCause": "The root cause of the issue is that the gatherStats method in the TableScanOperator does not handle NULL values in the partition column correctly, leading to a NullPointerException when it attempts to process rows with NULL values.",
            "StepsToReproduce": [
                "Create a table 'test2' with some rows containing NULL values in the partition column.",
                "Create a partitioned table 'test3' based on the 'age' column.",
                "Insert data from 'test2' into 'test3' while partitioning by 'age'.",
                "Run the command 'ANALYZE TABLE test3 PARTITION(age) COMPUTE STATISTICS'."
            ],
            "ExpectedBehavior": "The system should successfully compute statistics for the partitioned table without throwing any exceptions, even when NULL values are present in the partition column.",
            "ObservedBehavior": "The system throws a NullPointerException when attempting to analyze the partitioned table with NULL values in the partition column.",
            "Suggestions": "Implement a check in the gatherStats method to handle NULL values in the partition column gracefully, ensuring that the statistics gathering process can continue without errors.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecMapper.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.TableScanOperator",
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.mr.ExecMapper"
                ],
                "methods": [
                    "TableScanOperator.gatherStats",
                    "TableScanOperator.processOp",
                    "MapOperator.process",
                    "ExecMapper.map"
                ]
            },
            "possible_fix": "In the gatherStats method of TableScanOperator, add a check for NULL values in the partition column before attempting to process them. For example:\n\nif (row == null || partitionColumnValue == null) {\n    // Handle NULL case appropriately, possibly skipping stats gathering for this row.\n    return;\n}"
        }
    },
    {
        "filename": "HIVE-10736.json",
        "creation_time": "2015-05-18T03:25:45.000+0000",
        "bug_report": {
            "Title": "HiveServer2 shutdown of cached tez app-masters is not clean",
            "Description": "During the shutdown process of HiveServer2, a ConcurrentModificationException is thrown when attempting to stop the TezSessionPoolManager. This occurs because the method iterates over a collection of open Tez sessions while they may be concurrently modified, leading to an inconsistent state and failure to clean up the app masters properly.",
            "StackTrace": [
                "java.util.ConcurrentModificationException",
                "at java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:966)",
                "at java.util.LinkedList$ListItr.next(LinkedList.java:888)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.stop(TezSessionPoolManager.java:187)",
                "at org.apache.hive.service.server.HiveServer2.stop(HiveServer2.java:320)",
                "at org.apache.hive.service.server.HiveServer2$1.run(HiveServer2.java:107)"
            ],
            "RootCause": "The ConcurrentModificationException is caused by iterating over the list of open Tez sessions while they may be modified by other threads, leading to a race condition.",
            "StepsToReproduce": [
                "Start HiveServer2 with active Tez sessions.",
                "Trigger the shutdown process of HiveServer2.",
                "Observe the logs for ConcurrentModificationException during the shutdown."
            ],
            "ExpectedBehavior": "The shutdown process of HiveServer2 should complete without errors, and all Tez sessions should be cleaned up properly.",
            "ObservedBehavior": "The shutdown process throws a ConcurrentModificationException, preventing proper cleanup of Tez sessions.",
            "Suggestions": "Implement synchronization mechanisms or use a copy of the session list to avoid concurrent modifications during iteration.",
            "problem_location": {
                "files": [
                    "TezSessionPoolManager.java",
                    "HiveServer2.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager",
                    "org.apache.hive.service.server.HiveServer2"
                ],
                "methods": [
                    "TezSessionPoolManager.stop",
                    "HiveServer2.stop"
                ]
            },
            "possible_fix": "In the TezSessionPoolManager.stop method, replace the for-each loop with a synchronized block or use a copy of the session list to prevent ConcurrentModificationException. For example:\n\npublic void stop() throws Exception {\n    if ((sessionPool == null) || (this.inited == false)) {\n        return;\n    }\n\n    List<TezSessionState> sessions;\n    synchronized (TezSessionState.class) {\n        sessions = new ArrayList<>(TezSessionState.getOpenSessions());\n    }\n    for (TezSessionState sessionState : sessions) {\n        if (sessionState.isDefault()) {\n            sessionState.close(false);\n        }\n    }\n}"
        }
    },
    {
        "filename": "HIVE-7710.json",
        "creation_time": "2014-08-13T10:46:32.000+0000",
        "bug_report": {
            "Title": "Rename table across database might fail",
            "Description": "The issue arises when attempting to rename a table from one database to another using the SQL statement 'ALTER TABLE d1.t1 RENAME TO d2.t2'. If a table with the new name 'd2.t2' already exists, the operation fails due to a SQLIntegrityConstraintViolationException, indicating a duplicate key violation in the unique constraint 'UNIQUETABLE' on the 'TBLS' table. This occurs because the system does not check for the existence of the target table before attempting the rename operation.",
            "StackTrace": [
                "2014-08-13 03:32:40,512 ERROR Datastore.Persist (Log4JLogger.java:error(115)) - Update of object \"org.apache.hadoop.hive.metastore.model.MTable@729c5167\" using statement \"UPDATE TBLS SET TBL_NAME=? WHERE TBL_ID=?\" failed : java.sql.SQLIntegrityConstraintViolationException: The statement was aborted because it would have caused a duplicate key value in a unique or primary key constraint or unique index identified by 'UNIQUETABLE' defined on 'TBLS'.",
                "at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)",
                "at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeUpdate(Unknown Source)",
                "at com.jolbox.bonecp.PreparedStatementHandle.executeUpdate(PreparedStatementHandle.java:205)",
                "at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeUpdate(ParamLoggingPreparedStatement.java:399)",
                "at org.datanucleus.store.rdbms.SQLController.executeStatementUpdate(SQLController.java:439)",
                "at org.datanucleus.store.rdbms.request.UpdateRequest.execute(UpdateRequest.java:374)",
                "at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.updateTable(RDBMSPersistenceHandler.java:417)",
                "at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.updateObject(RDBMSPersistenceHandler.java:390)",
                "at org.datanucleus.state.JDOStateManager.flush(JDOStateManager.java:5027)",
                "at org.datanucleus.flush.FlushOrdered.execute(FlushOrdered.java:106)",
                "at org.datanucleus.ExecutionContextImpl.flushInternal(ExecutionContextImpl.java:4119)",
                "at org.datanucleus.ExecutionContextThreadedImpl.flushInternal(ExecutionContextThreadedImpl.java:450)",
                "at org.datanucleus.ExecutionContextImpl.markDirty(ExecutionContextImpl.java:3879)",
                "at org.datanucleus.state.JDOStateManager.postWriteField(JDOStateManager.java:4815)",
                "at org.datanucleus.state.JDOStateManager.replaceField(JDOStateManager.java:3356)",
                "at org.datanucleus.state.JDOStateManager.updateField(JDOStateManager.java:2018)",
                "at org.datanucleus.state.JDOStateManager.setStringField(JDOStateManager.java:1791)",
                "at org.apache.hadoop.hive.metastore.model.MStorageDescriptor.jdoSetlocation(MStorageDescriptor.java)",
                "at org.apache.hadoop.hive.metastore.model.MStorageDescriptor.setLocation(MStorageDescriptor.java:88)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.copyMSD(ObjectStore.java:2699)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.alterTable(ObjectStore.java:2572)",
                "at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:98)",
                "at com.sun.proxy.$Proxy6.alterTable(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveAlterHandler.alterTable(HiveAlterHandler.java:205)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table_with_environment_context(HiveMetaStore.java:2771)",
                "at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:105)",
                "at com.sun.proxy.$Proxy8.alter_table_with_environment_context(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.alter_table(HiveMetaStoreClient.java:293)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.alter_table(HiveMetaStoreClient.java:288)",
                "at sun.reflect.GeneratedMethodAccessor18.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.alter_table(SessionHiveMetaStoreClient.java:201)",
                "at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.alter_table(SessionHiveMetaStoreClient.java:201)",
                "at sun.reflect.GeneratedMethodAccessor18.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.alterTable(Hive.java:404)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.alterTable(DDLTask.java:3542)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:318)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:161)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1538)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1305)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1118)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:942)"
            ],
            "RootCause": "The root cause of the issue is the lack of a check for the existence of the target table before executing the rename operation. This leads to a violation of the unique constraint on the table names in the metastore.",
            "StepsToReproduce": [
                "1. Create a table in database d1 with the name t1.",
                "2. Create another table in database d2 with the name t2.",
                "3. Execute the SQL command: ALTER TABLE d1.t1 RENAME TO d2.t2.",
                "4. Observe the error indicating a duplicate key violation."
            ],
            "ExpectedBehavior": "The system should check if the target table name already exists before attempting to rename the source table. If it does exist, an appropriate error message should be returned without attempting the rename operation.",
            "ObservedBehavior": "The system throws a SQLIntegrityConstraintViolationException due to an attempt to rename a table to a name that already exists in the target database.",
            "Suggestions": "Implement a check in the alterTable method to verify if the target table name already exists before proceeding with the rename operation. If it exists, throw an InvalidOperationException with a clear message indicating the conflict.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveAlterHandler.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.HiveAlterHandler",
                    "org.apache.hadoop.hive.metastore.ObjectStore"
                ],
                "methods": [
                    "HiveAlterHandler.alterTable",
                    "ObjectStore.alterTable"
                ]
            },
            "possible_fix": "In the 'alterTable' method of 'HiveAlterHandler', add a check to see if the new table name already exists in the target database before executing the rename operation. If it does exist, throw an InvalidOperationException with a message like 'Table <new_table_name> already exists in database <target_database>'."
        }
    },
    {
        "filename": "HIVE-8735.json",
        "creation_time": "2014-11-04T22:20:02.000+0000",
        "bug_report": {
            "Title": "Statistics update can fail due to long paths",
            "Description": "The system encounters a truncation error when attempting to publish statistics with a file path that exceeds the maximum allowed length for a VARCHAR field in the database. Specifically, the error occurs when the file path exceeds 255 characters, leading to a SQLDataException during the execution of the publishStat method in JDBCStatsPublisher.",
            "StackTrace": [
                "2014-11-04 01:34:38,610 ERROR jdbc.JDBCStatsPublisher (JDBCStatsPublisher.java:publishStat(198)) - Error during publishing statistics.",
                "java.sql.SQLDataException: A truncation error was encountered trying to shrink VARCHAR 'pfile:/grid/0/jenkins/workspace/UT-hive-champlain-common/sub&' to length 255.",
                "at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)",
                "at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)",
                "at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeUpdate(Unknown Source)",
                "at org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher$2.run(JDBCStatsPublisher.java:147)",
                "at org.apache.hadoop.hive.ql.exec.Utilities.executeWithRetry(Utilities.java:2910)",
                "at org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher.publishStat(JDBCStatsPublisher.java:160)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.publishStats(FileSinkOperator.java:1153)"
            ],
            "RootCause": "The root cause of the issue is that the file path being published exceeds the maximum length of 255 characters for a VARCHAR field in the database, resulting in a SQLDataException due to truncation.",
            "StepsToReproduce": [
                "1. Create a file path that exceeds 255 characters.",
                "2. Attempt to publish statistics using the JDBCStatsPublisher.",
                "3. Observe the SQLDataException in the logs."
            ],
            "ExpectedBehavior": "The system should successfully publish statistics without encountering truncation errors, regardless of the length of the file path.",
            "ObservedBehavior": "The system fails to publish statistics and throws a SQLDataException due to a truncation error when the file path exceeds 255 characters.",
            "Suggestions": "Consider modifying the database schema to allow for longer VARCHAR lengths or implement logic to truncate or hash long file paths before publishing them.",
            "problem_location": {
                "files": [
                    "JDBCStatsPublisher.java",
                    "FileSinkOperator.java",
                    "Utilities.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher",
                    "org.apache.hadoop.hive.ql.exec.FileSinkOperator",
                    "org.apache.hadoop.hive.ql.exec.Utilities"
                ],
                "methods": [
                    "JDBCStatsPublisher.publishStat",
                    "FileSinkOperator.publishStats",
                    "Utilities.executeWithRetry"
                ]
            },
            "possible_fix": "Modify the publishStat method in JDBCStatsPublisher to check the length of the fileID before attempting to set it in the PreparedStatement. If it exceeds 255 characters, either truncate it or hash it to fit within the limit."
        }
    },
    {
        "filename": "HIVE-13209.json",
        "creation_time": "2016-03-04T21:39:50.000+0000",
        "bug_report": {
            "Title": "metastore get_delegation_token fails with null ip address",
            "Description": "The issue arises when the `get_delegation_token` method in the Hive Metastore fails due to a null IP address being passed, which leads to an unauthorized connection error. This problem was introduced after changes made in HIVE-13169, which may have altered how IP addresses are handled or retrieved in the context of delegation tokens.",
            "StackTrace": [
                "2016-03-03 07:45:31,055 ERROR [pool-6-thread-22]: metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(159)) - MetaException(message:Unauthorized connection for super-user: HTTP/<hostname@realm> from IP null)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_delegation_token(HiveMetaStore.java:5290)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)",
                "at com.sun.proxy.$Proxy16.get_delegation_token(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_delegation_token.getResult(ThriftHiveMetastore.java:11492)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_delegation_token.getResult(ThriftHiveMetastore.java:11476)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:551)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:546)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:546)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is that the IP address is being resolved to null when attempting to retrieve the delegation token, likely due to changes in the handling of user authentication or network configuration in the recent updates.",
            "StepsToReproduce": [
                "1. Set up the Hive Metastore environment with the latest changes from HIVE-13169.",
                "2. Attempt to call the get_delegation_token method as a super-user.",
                "3. Observe the error message indicating an unauthorized connection from IP null."
            ],
            "ExpectedBehavior": "The system should successfully retrieve the delegation token for the super-user without any errors related to IP address resolution.",
            "ObservedBehavior": "The system fails to retrieve the delegation token, resulting in an unauthorized connection error due to a null IP address.",
            "Suggestions": "Investigate the changes made in HIVE-13169 to identify how IP address resolution is affected. Ensure that the IP address is correctly retrieved and passed to the get_delegation_token method.",
            "problem_location": {
                "files": [
                    "RetryingHMSHandler.java",
                    "HiveMetaStore.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.RetryingHMSHandler",
                    "org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler"
                ],
                "methods": [
                    "RetryingHMSHandler.invoke",
                    "HiveMetaStore$HMSHandler.get_delegation_token"
                ]
            },
            "possible_fix": "Review the logic in the get_delegation_token method to ensure that the IP address is being correctly set and passed. Consider adding checks to handle cases where the IP address may be null and implement fallback mechanisms to prevent unauthorized access errors."
        }
    },
    {
        "filename": "HIVE-13065.json",
        "creation_time": "2016-02-16T21:11:31.000+0000",
        "bug_report": {
            "Title": "Hive throws NPE when writing map type data to a HBase backed table",
            "Description": "The issue occurs when attempting to write a map type column containing NULL values to a HBase backed Hive table. The serialization process fails due to a NullPointerException (NPE) when the system tries to handle the NULL value in the map. This is particularly problematic in the HBaseSerDe class during the serialization of the map values.",
            "StackTrace": [
                "2016-02-15 02:26:33,225 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{},\"value\":{\"_col0\":1,\"_col1\":{\"abcd\":null}}}",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:265)",
                "at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)",
                "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{},\"value\":{\"_col0\":1,\"_col1\":{\"abcd\":null}}}",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:253)",
                "Caused by: org.apache.hadoop.hive.serde2.SerDeException: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.serde2.lazy.LazyUtils.writePrimitiveUTF8(LazyUtils.java:221)",
                "at org.apache.hadoop.hive.hbase.HBaseRowSerializer.serialize(HBaseRowSerializer.java:236)",
                "at org.apache.hadoop.hive.hbase.HBaseRowSerializer.serializeField(HBaseRowSerializer.java:194)",
                "at org.apache.hadoop.hive.hbase.HBaseSerDe.serialize(HBaseSerDe.java:286)"
            ],
            "RootCause": "The root cause of the issue is that the serialization method in HBaseSerDe does not handle NULL values in map type columns properly, leading to a NullPointerException when attempting to serialize a NULL value.",
            "StepsToReproduce": [
                "1) Create a HBase backed Hive table with a map type column.",
                "2) Insert data into the table where the map type column contains NULL values.",
                "3) Execute the insert query and observe the failure."
            ],
            "ExpectedBehavior": "The system should handle NULL values in map type columns gracefully, either by skipping them or by serializing them in a way that does not cause an exception.",
            "ObservedBehavior": "The system throws a NullPointerException during the serialization process when it encounters a NULL value in the map type column.",
            "Suggestions": "Implement a check in the serialization logic to handle NULL values in map types appropriately, ensuring that they do not cause a NullPointerException.",
            "problem_location": {
                "files": [
                    "hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseSerDe.java",
                    "hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseRowSerializer.java",
                    "serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.hbase.HBaseSerDe",
                    "org.apache.hadoop.hive.hbase.HBaseRowSerializer",
                    "org.apache.hadoop.hive.serde2.lazy.LazyUtils"
                ],
                "methods": [
                    "HBaseSerDe.serialize",
                    "HBaseRowSerializer.serialize",
                    "LazyUtils.writePrimitiveUTF8"
                ]
            },
            "possible_fix": "In the HBaseRowSerializer.serializeField method, add a check for NULL values before attempting to serialize them. For example:\n\nif (value == null) {\n    // Handle NULL value appropriately, e.g., skip serialization or write a default value\n    return;\n}"
        }
    },
    {
        "filename": "HIVE-11470.json",
        "creation_time": "2015-08-05T18:45:26.000+0000",
        "bug_report": {
            "Title": "NPE in DynamicPartFileRecordWriterContainer on null part-keys.",
            "Description": "A NullPointerException (NPE) occurs in the DynamicPartitionFileRecordWriterContainer when attempting to partition data using HCatStorer, specifically when the dynamic partition key is null. The issue arises because the method getLocalFileWriter in DynamicPartitionFileRecordWriterContainer does not handle null values properly when fetching the local file writer instance. This leads to an attempt to call toString() on a null value, resulting in an NPE.",
            "StackTrace": [
                "2015-07-30 23:59:59,627 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: java.lang.NullPointerException",
                "at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.runPipeline(PigGenericMapReduce.java:473)",
                "at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.processOnePackageOutput(PigGenericMapReduce.java:436)",
                "at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.reduce(PigGenericMapReduce.java:416)",
                "at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.reduce(PigGenericMapReduce.java:256)",
                "at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)",
                "at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)",
                "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer.getLocalFileWriter(DynamicPartitionFileRecordWriterContainer.java:141)",
                "at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:110)",
                "at org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer.write(FileRecordWriterContainer.java:54)",
                "at org.apache.hive.hcatalog.pig.HCatBaseStorer.putNext(HCatBaseStorer.java:309)",
                "at org.apache.hive.hcatalog.pig.HCatStorer.putNext(HCatStorer.java:61)",
                "at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:139)",
                "at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputFormat$PigRecordWriter.write(PigOutputFormat.java:98)",
                "at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)",
                "at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)",
                "at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)",
                "at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Reduce.runPipeline(PigGenericMapReduce.java:471)"
            ],
            "RootCause": "The root cause of the NPE is the lack of null checks in the getLocalFileWriter method of DynamicPartitionFileRecordWriterContainer. When a null value is encountered in the dynamic partition keys, the code attempts to call toString() on it, leading to the exception.",
            "StepsToReproduce": [
                "1. Set up a data partitioning job using HCatStorer.",
                "2. Ensure that one of the dynamic partition keys is null.",
                "3. Execute the job and observe the NPE in the logs."
            ],
            "ExpectedBehavior": "The system should handle null dynamic partition keys gracefully, either by substituting them with a default value or by skipping the write operation without throwing an exception.",
            "ObservedBehavior": "The system throws a NullPointerException when attempting to process a null dynamic partition key, causing the job to fail.",
            "Suggestions": "Implement a null check in the getLocalFileWriter method to handle null dynamic partition keys. Substitute null values with a default partition key such as '__HIVE_DEFAULT_PARTITION__'.",
            "problem_location": {
                "files": [
                    "hcatalog.core/src/main/java/org/apache/hive/hcatalog/mapreduce/DynamicPartitionFileRecordWriterContainer.java",
                    "hcatalog.core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileRecordWriterContainer.java"
                ],
                "classes": [
                    "org.apache.hive.hcatalog.mapreduce.DynamicPartitionFileRecordWriterContainer",
                    "org.apache.hive.hcatalog.mapreduce.FileRecordWriterContainer"
                ],
                "methods": [
                    "DynamicPartitionFileRecordWriterContainer.getLocalFileWriter",
                    "FileRecordWriterContainer.write"
                ]
            },
            "possible_fix": "In the getLocalFileWriter method, add a null check for the dynamic partition values. If a value is null, substitute it with '__HIVE_DEFAULT_PARTITION__'. Example code change:\n\nList<String> dynamicPartValues = new ArrayList<String>();\nfor (Integer colToAppend : dynamicPartCols) {\n    String partValue = value.get(colToAppend);\n    dynamicPartValues.add(partValue != null ? partValue.toString() : \"__HIVE_DEFAULT_PARTITION__\");\n}"
        }
    },
    {
        "filename": "HIVE-12476.json",
        "creation_time": "2015-11-20T03:30:18.000+0000",
        "bug_report": {
            "Title": "Metastore NPE on Oracle with Direct SQL",
            "Description": "A NullPointerException (NPE) occurs in the Hive Metastore when using Direct SQL mode, particularly during the serialization of Partition and StorageDescriptor objects. This issue appears to be related to missing or null parameters in the SerDeInfo or StorageDescriptor, which are critical for the serialization process. The stack trace indicates that the error arises when attempting to write a string in the TBinaryProtocol, suggesting that one of the expected fields is not properly initialized.",
            "StackTrace": [
                "2015-11-19 18:08:33,841 ERROR [pool-5-thread-2]: server.TThreadPoolServer (TThreadPoolServer.java:run(296)) - Error occurred during processing of message.",
                "java.lang.NullPointerException",
                "at org.apache.thrift.protocol.TBinaryProtocol.writeString(TBinaryProtocol.java:200)",
                "at org.apache.hadoop.hive.metastore.api.SerDeInfo$SerDeInfoStandardScheme.write(SerDeInfo.java:579)",
                "at org.apache.hadoop.hive.metastore.api.SerDeInfo$SerDeInfoStandardScheme.write(SerDeInfo.java:501)",
                "at org.apache.hadoop.hive.metastore.api.SerDeInfo.write(SerDeInfo.java:439)",
                "at org.apache.hadoop.hive.metastore.api.StorageDescriptor$StorageDescriptorStandardScheme.write(StorageDescriptor.java:1490)",
                "at org.apache.hadoop.hive.metastore.api.StorageDescriptor$StorageDescriptorStandardScheme.write(StorageDescriptor.java:1288)",
                "at org.apache.hadoop.hive.metastore.api.StorageDescriptor.write(StorageDescriptor.java:1154)",
                "at org.apache.hadoop.hive.metastore.api.Partition$PartitionStandardScheme.write(Partition.java:1072)",
                "at org.apache.hadoop.hive.metastore.api.Partition$PartitionStandardScheme.write(Partition.java:929)",
                "at org.apache.hadoop.hive.metastore.api.Partition.write(Partition.java:825)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partitions_result$get_partitions_resultStandardScheme.write(ThriftHiveMetastore.java:64470)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partitions_result$get_partitions_resultStandardScheme.write(ThriftHiveMetastore.java:64402)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partitions_result.write(ThriftHiveMetastore.java:64340)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:53)",
                "at org.apache.thrift.TBaseProcessor.process(ProcessFunction.java:39)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:681)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:676)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:676)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the NullPointerException is likely due to uninitialized or null fields in the SerDeInfo or StorageDescriptor objects, which are being serialized during the processing of Hive metastore requests.",
            "StepsToReproduce": [
                "1. Configure Hive to use Direct SQL mode with Oracle.",
                "2. Attempt to retrieve partitions from a table that has a StorageDescriptor with missing SerDeInfo parameters.",
                "3. Observe the NullPointerException in the logs."
            ],
            "ExpectedBehavior": "The Hive Metastore should successfully serialize and return the requested partitions without throwing a NullPointerException.",
            "ObservedBehavior": "A NullPointerException is thrown during the serialization process, preventing the retrieval of partitions.",
            "Suggestions": "Ensure that all required fields in the SerDeInfo and StorageDescriptor are properly initialized before serialization. Implement null checks and default values where necessary.",
            "problem_location": {
                "files": [
                    "SerDeInfo.java",
                    "StorageDescriptor.java",
                    "Partition.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.api.SerDeInfo",
                    "org.apache.hadoop.hive.metastore.api.StorageDescriptor",
                    "org.apache.hadoop.hive.metastore.api.Partition"
                ],
                "methods": [
                    "SerDeInfo.write",
                    "StorageDescriptor.write",
                    "Partition.write"
                ]
            },
            "possible_fix": "Add null checks in the write methods of SerDeInfo, StorageDescriptor, and Partition classes to handle cases where required fields are not initialized. For example, in the SerDeInfo.write method, check if the 'name' field is null before attempting to write it to the protocol."
        }
    },
    {
        "filename": "HIVE-10559.json",
        "creation_time": "2015-04-30T21:12:40.000+0000",
        "bug_report": {
            "Title": "IndexOutOfBoundsException with RemoveDynamicPruningBySize",
            "Description": "An IndexOutOfBoundsException occurs when attempting to access an element at index 0 of an empty ArrayList in the RemoveDynamicPruningBySize class. This issue arises during the optimization phase of query execution when the expected data size exceeds the configured limit, leading to an attempt to process a non-existent child operator.",
            "StackTrace": [
                "java.lang.IndexOutOfBoundsException: Index: 0, Size: 0",
                "at java.util.ArrayList.rangeCheck(ArrayList.java:635)",
                "at java.util.ArrayList.get(ArrayList.java:411)",
                "at org.apache.hadoop.hive.ql.optimizer.RemoveDynamicPruningBySize.process(RemoveDynamicPruningBySize.java:61)",
                "at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:95)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:79)",
                "at org.apache.hadoop.hive.ql.lib.ForwardWalker.walk(ForwardWalker.java:77)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:110)",
                "at org.apache.hadoop.hive.ql.parse.TezCompiler.runStatsDependentOptimizations(TezCompiler.java:281)"
            ],
            "RootCause": "The root cause of the IndexOutOfBoundsException is that the code attempts to access the first child of an operator that has no children, resulting in an empty ArrayList being accessed.",
            "StepsToReproduce": [
                "Run the script that triggers the optimization phase in the Hive query execution.",
                "Ensure that the data size exceeds the configured limit for dynamic partition pruning."
            ],
            "ExpectedBehavior": "The system should handle cases where there are no child operators gracefully, without throwing an IndexOutOfBoundsException.",
            "ObservedBehavior": "The system throws an IndexOutOfBoundsException when trying to access the first child of an operator that has no children.",
            "Suggestions": "Implement a check to ensure that the operator has children before attempting to access them. This can prevent the IndexOutOfBoundsException from occurring.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/optimizer/RemoveDynamicPruningBySize.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/lib/DefaultRuleDispatcher.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.optimizer.RemoveDynamicPruningBySize",
                    "org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher"
                ],
                "methods": [
                    "RemoveDynamicPruningBySize.process",
                    "DefaultRuleDispatcher.dispatch"
                ]
            },
            "possible_fix": "In the process method of RemoveDynamicPruningBySize, add a check to ensure that the operator has children before accessing them. For example:\n\nif (!curr.getChildOperators().isEmpty()) {\n    // Proceed with accessing child operators\n} else {\n    // Handle the case where there are no child operators\n}"
        }
    },
    {
        "filename": "HIVE-9721.json",
        "creation_time": "2015-02-19T06:56:17.000+0000",
        "bug_report": {
            "Title": "Hadoop23Shims.setFullFileStatus should check for null",
            "Description": "The method `Hadoop23Shims.setFullFileStatus` is encountering a `NullPointerException` when it attempts to set the full file status for a file system that does not support ACLs. This occurs because the method does not check for null values before proceeding with operations that assume valid input. The stack trace indicates that the error originates from the `setFullFileStatus` method, which is called during the execution of a Hive query that involves creating directories and managing file statuses.",
            "StackTrace": [
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.shims.Hadoop23Shims.setFullFileStatus(Hadoop23Shims.java:668)",
                "at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:527)",
                "at org.apache.hadoop.hive.ql.Context.getStagingDir(Context.java:234)",
                "at org.apache.hadoop.hive.ql.Context.getExtTmpPathRelTo(Context.java:424)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genFileSinkPlan(SemanticAnalyzer.java:6290)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPostGroupByBodyPlan(SemanticAnalyzer.java:9069)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:8961)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9807)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9700)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genOPTree(SemanticAnalyzer.java:10136)",
                "at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genOPTree(CalcitePlanner.java:284)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10147)",
                "at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:190)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:222)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:421)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:307)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1112)",
                "at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1106)",
                "at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:101)",
                "at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:172)",
                "at org.apache.hive.service.cli.operation.Operation.run(Operation.java:257)",
                "at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:379)",
                "at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:366)",
                "at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:271)",
                "at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:415)"
            ],
            "RootCause": "The `NullPointerException` occurs because the `setFullFileStatus` method does not handle null values appropriately, leading to an attempt to dereference a null object.",
            "StepsToReproduce": [
                "Set up a Hive environment with a file system that does not support ACLs.",
                "Execute a Hive query that involves creating directories or managing file statuses.",
                "Observe the logs for the `NullPointerException` originating from `Hadoop23Shims.setFullFileStatus`."
            ],
            "ExpectedBehavior": "The system should gracefully handle cases where the file system does not support ACLs, without throwing a `NullPointerException`. It should either skip setting the full file status or provide a meaningful error message.",
            "ObservedBehavior": "The system throws a `NullPointerException` when attempting to set the full file status for a file system that does not support ACLs.",
            "Suggestions": "Implement null checks in the `setFullFileStatus` method to ensure that it does not attempt to dereference null objects. Additionally, consider logging a warning or error message when the file system does not support ACLs.",
            "problem_location": {
                "files": [
                    "Hadoop23Shims.java",
                    "FileUtils.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.shims.Hadoop23Shims",
                    "org.apache.hadoop.hive.common.FileUtils"
                ],
                "methods": [
                    "Hadoop23Shims.setFullFileStatus",
                    "FileUtils.mkdir"
                ]
            },
            "possible_fix": "In the `Hadoop23Shims.setFullFileStatus` method, add a null check for the parameters before proceeding with the logic. For example:\n\n```java\nif (fullFileStatus == null || fs == null) {\n    LOG.warn(\"Cannot set full file status: fullFileStatus or file system is null\");\n    return;\n}\n```"
        }
    },
    {
        "filename": "HIVE-4216.json",
        "creation_time": "2013-03-21T20:53:24.000+0000",
        "bug_report": {
            "Title": "TestHBaseMinimrCliDriver throws weird error with HBase 0.94.5 and Hadoop 23 and test is stuck infinitely",
            "Description": "After upgrading to Hadoop 23 and HBase 0.94.5, the TestHBaseMinimrCliDriver fails during execution. The test hangs indefinitely after the reducer phase of a query, which is supposed to insert data into the 'hbsort' table. The failure occurs due to a NullPointerException when attempting to write records to HFiles, indicating that the configuration for the HFile path may not be set correctly.",
            "StackTrace": [
                "13-03-20 16:26:48,942 FATAL [IPC Server handler 17 on 55996] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1363821864968_0003_r_000002_0 - exited : java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{\"reducesinkkey0\":\"val_200\"},\"value\":{\"_col0\":\"val_200\",\"_col1\":\"200\",\"_col2\":\"201.0\"},\"alias\":0}",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.io.HiveFileFormatUtils.getHiveRecordWriter(HiveFileFormatUtils.java:237)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.createBucketFiles(FileSinkOperator.java:477)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:525)",
                "at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:268)"
            ],
            "RootCause": "The root cause of the issue is a NullPointerException occurring in the method 'getHiveRecordWriter' of 'HiveFileFormatUtils'. This is likely due to the 'HFILE_FAMILY_PATH' property not being set in the table properties, which is required to determine the target location for HFiles.",
            "StepsToReproduce": [
                "Upgrade to Hadoop 23 and HBase 0.94.5.",
                "Set the following properties in 'hbase_bulk.m':",
                "set mapreduce.totalorderpartitioner.naturalorder=false;",
                "set mapreduce.totalorderpartitioner.path=/tmp/hbpartition.lst;",
                "Run the TestHBaseMinimrCliDriver."
            ],
            "ExpectedBehavior": "The test should complete successfully without hanging, and the data should be inserted into the 'hbsort' table without errors.",
            "ObservedBehavior": "The test hangs indefinitely during the reducer phase, and a NullPointerException is thrown, indicating a failure to write records to HFiles.",
            "Suggestions": "Ensure that the 'HFILE_FAMILY_PATH' property is set correctly in the table properties before running the test. Additionally, check the configuration for the output path to ensure it is valid.",
            "problem_location": {
                "files": [
                    "hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHFileOutputFormat.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/HiveFileFormatUtils.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/ExecReducer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.hbase.HiveHFileOutputFormat",
                    "org.apache.hadoop.hive.ql.io.HiveFileFormatUtils",
                    "org.apache.hadoop.hive.ql.exec.ExecReducer"
                ],
                "methods": [
                    "HiveHFileOutputFormat.getHiveRecordWriter",
                    "HiveFileFormatUtils.getRecordWriter",
                    "ExecReducer.reduce"
                ]
            },
            "possible_fix": "In the 'getHiveRecordWriter' method of 'HiveHFileOutputFormat', add a check to ensure that 'HFILE_FAMILY_PATH' is set in the properties before proceeding. If it is not set, throw a more descriptive exception to guide the user in setting the required configuration."
        }
    },
    {
        "filename": "HIVE-13836.json",
        "creation_time": "2016-05-24T22:37:59.000+0000",
        "bug_report": {
            "Title": "DbNotifications giving an error = Invalid state. Transaction has already started",
            "Description": "The error occurs when multiple threads attempt to execute DDL queries concurrently using the pyhs2 client, leading to a situation where the transaction state is invalid. Specifically, the method `openTransaction` in the `ObjectStore` class is called multiple times without properly managing the transaction state, resulting in the `NucleusTransactionException` being thrown. This indicates that a transaction was already active when another attempt to start a transaction was made.",
            "StackTrace": [
                "2016-05-04 17:49:26,226 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler: [pool-4-thread-194]: HMSHandler Fatal error: Invalid state. Transaction has already started",
                "org.datanucleus.transaction.NucleusTransactionException: Invalid state. Transaction has already started",
                "at org.datanucleus.transaction.TransactionManager.begin(TransactionManager.java:47)",
                "at org.datanucleus.TransactionImpl.begin(TransactionImpl.java:131)",
                "at org.datanucleus.api.jdo.JDOTransaction.internalBegin(JDOTransaction.java:88)",
                "at org.datanucleus.api.jdo.JDOTransaction.begin(JDOTransaction.java:80)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.openTransaction(ObjectStore.java:463)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.addNotificationEvent(ObjectStore.java:7522)",
                "at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)",
                "at com.sun.proxy.$Proxy10.addNotificationEvent(Unknown Source)",
                "at org.apache.hive.hcatalog.listener.DbNotificationListener.enqueue(DbNotificationListener.java:261)",
                "at org.apache.hive.hcatalog.listener.DbNotificationListener.onCreateTable(DbNotificationListener.java:123)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_core(HiveMetaStore.java:1483)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_with_environment_context(HiveMetaStore.java:1502)",
                "at sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:138)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:99)",
                "at com.sun.proxy.$Proxy14.create_table_with_environment_context(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_with_environment_context.getResult(ThriftHiveMetastore.java:9267)"
            ],
            "RootCause": "The root cause of the issue is that the `openTransaction` method in the `ObjectStore` class is being called multiple times concurrently without proper management of the transaction state, leading to an invalid transaction state.",
            "StepsToReproduce": [
                "1. Use the pyhs2 Python client to create multiple connections to Hive.",
                "2. Execute DDL queries concurrently from multiple threads (e.g., 8 threads).",
                "3. Observe the error message indicating an invalid transaction state."
            ],
            "ExpectedBehavior": "The system should handle concurrent DDL operations without throwing an error related to transaction state.",
            "ObservedBehavior": "The system throws an error indicating that a transaction has already started when multiple threads attempt to open a transaction concurrently.",
            "Suggestions": "Implement proper synchronization mechanisms to ensure that transactions are managed correctly when accessed by multiple threads. Consider using a thread-safe approach to manage the transaction state.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java",
                    "hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/DbNotificationListener.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.ObjectStore",
                    "org.apache.hive.hcatalog.listener.DbNotificationListener"
                ],
                "methods": [
                    "ObjectStore.openTransaction",
                    "ObjectStore.addNotificationEvent",
                    "DbNotificationListener.enqueue",
                    "DbNotificationListener.onCreateTable"
                ]
            },
            "possible_fix": "To fix the issue, modify the `openTransaction` method in the `ObjectStore` class to ensure that it can handle multiple concurrent calls safely. This may involve using synchronization mechanisms such as locks or semaphores to manage access to the transaction state."
        }
    },
    {
        "filename": "HIVE-9873.json",
        "creation_time": "2015-03-05T17:35:33.000+0000",
        "bug_report": {
            "Title": "Hive on MR throws DeprecatedParquetHiveInput exception",
            "Description": "The application throws a DeprecatedParquetHiveInput exception when attempting to read data after modifying column information via the projectionPusher.pushProjectionsAndFilters method. The exception indicates a mismatch in the expected size of the data object being read, which leads to an IOException. This occurs because the metadata regarding the columns is not updated correctly until after the call to projectionPusher.pushProjectionsAndFilters, resulting in an empty read schema being passed to Parquet, which in turn causes all records to be null.",
            "StackTrace": [
                "2015-02-26 15:56:40,275 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: java.io.IOException: java.io.IOException: DeprecatedParquetHiveInput : size of object differs. Value size :  23, Current Object size : 29",
                "at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderNextException(HiveIOExceptionHandlerChain.java:121)",
                "at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderNextException(HiveIOExceptionHandlerUtil.java:77)",
                "at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.doNextWithExceptionHandler(HadoopShimsSecure.java:226)",
                "at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.next(HadoopShimsSecure.java:136)",
                "at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:199)",
                "at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:185)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)",
                "Caused by: java.io.IOException: java.io.IOException: DeprecatedParquetHiveInput : size of object differs. Value size :  23, Current Object size : 29",
                "at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderNextException(HiveIOExceptionHandlerChain.java:121)",
                "at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderNextException(HiveIOExceptionHandlerUtil.java:77)",
                "at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:355)",
                "at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:105)",
                "at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:41)",
                "at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.next(HiveContextAwareRecordReader.java:116)",
                "at org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader.doNextWithExceptionHandler(HadoopShimsSecure.java:224)",
                "... 11 more",
                "Caused by: java.io.IOException: DeprecatedParquetHiveInput : size of object differs. Value size :  23, Current Object size : 29",
                "at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.next(ParquetRecordReaderWrapper.java:199)",
                "at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.next(ParquetRecordReaderWrapper.java:52)",
                "at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:350)",
                "... 15 more"
            ],
            "RootCause": "The root cause of the issue is that the metadata regarding the columns is not updated correctly until after the call to projectionPusher.pushProjectionsAndFilters. This results in an empty read schema being passed to the Parquet reader, leading to the size mismatch error.",
            "StepsToReproduce": [
                "1. Modify the column information in the Hive table.",
                "2. Call projectionPusher.pushProjectionsAndFilters.",
                "3. Attempt to read data from the modified table."
            ],
            "ExpectedBehavior": "The system should read the data correctly without throwing an exception, reflecting the updated column information.",
            "ObservedBehavior": "The system throws a DeprecatedParquetHiveInput exception indicating a size mismatch in the data being read.",
            "Suggestions": "Ensure that the metadata is updated correctly after calling projectionPusher.pushProjectionsAndFilters and before any read operations are performed.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java",
                    "shims/common/src/main/java/org/apache/hadoop/hive/io/HiveIOExceptionHandlerUtil.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveRecordReader.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/HiveContextAwareRecordReader.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper",
                    "org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil",
                    "org.apache.hadoop.hive.ql.io.CombineHiveRecordReader",
                    "org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader"
                ],
                "methods": [
                    "ParquetRecordReaderWrapper.next",
                    "HiveIOExceptionHandlerUtil.handleRecordReaderNextException",
                    "CombineHiveRecordReader.doNext",
                    "HiveContextAwareRecordReader.next"
                ]
            },
            "possible_fix": "Update the code to ensure that the configuration object returned from projectionPusher.pushProjectionsAndFilters is used in subsequent read operations. This may involve modifying the initialization of the realReader to utilize the updated metadata."
        }
    },
    {
        "filename": "HIVE-13174.json",
        "creation_time": "2016-02-26T23:34:36.000+0000",
        "bug_report": {
            "Title": "Remove Vectorizer noise in logs",
            "Description": "The current implementation of the Vectorizer logs stack traces when it fails to vectorize expressions involving binary types. This behavior clutters the logs and should be modified to either log a simple message or change the log level to debug to reduce noise. The root cause of the issue is that the method `getConstantVectorExpression` in `VectorizationContext` throws a `HiveException` when it encounters a binary type, which is not supported for vectorization.",
            "StackTrace": [
                "2015-10-12 12:34:23,922 INFO  [main]: physical.Vectorizer (Vectorizer.java:validateExprNodeDesc(1249)) - Failed to vectorize",
                "org.apache.hadoop.hive.ql.metadata.HiveException: No vector argument type for type name binary",
                "at org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.getConstantVectorExpression(VectorizationContext.java:872)",
                "at org.apache.hadoop.hive.ql.exec.vector.VectorizationContext.getVectorExpression(VectorizationContext.java:443)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.validateExprNodeDesc(Vectorizer.java:1243)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.validateExprNodeDesc(Vectorizer.java:1234)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.validateSelectOperator(Vectorizer.java:1100)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.validateMapWorkOperator(Vectorizer.java:911)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$MapWorkValidationNodeProcessor.process(Vectorizer.java:581)",
                "at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:95)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:133)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:110)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$VectorizationDispatcher.validateMapWork(Vectorizer.java:412)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$VectorizationDispatcher.convertMapWork(Vectorizer.java:355)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer$VectorizationDispatcher.dispatch(Vectorizer.java:330)",
                "at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.dispatch(TaskGraphWalker.java:111)",
                "at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.walk(TaskGraphWalker.java:180)",
                "at org.apache.hadoop.hive.ql.lib.TaskGraphWalker.startWalking(TaskGraphWalker.java:125)",
                "at org.apache.hadoop.hive.ql.optimizer.physical.Vectorizer.resolve(Vectorizer.java:890)",
                "at org.apache.hadoop.hive.ql.parse.TezCompiler.optimizeTaskPlan(TezCompiler.java:469)",
                "at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:227)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10188)",
                "at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:211)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:227)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:424)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)",
                "at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:409)",
                "at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:425)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:714)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.util.RunJar.run(RunJar.java:221)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:136)"
            ],
            "RootCause": "The method `getConstantVectorExpression` in `VectorizationContext` throws a `HiveException` when it encounters a binary type, which is not supported for vectorization. This results in excessive logging of stack traces.",
            "StepsToReproduce": [
                "Create a Hive table with a binary column.",
                "Run a query that involves vectorization on this table.",
                "Observe the logs for stack traces related to vectorization failures."
            ],
            "ExpectedBehavior": "The system should log a simple message indicating that vectorization failed for unsupported types without cluttering the logs with stack traces.",
            "ObservedBehavior": "The logs are filled with stack traces indicating failures to vectorize binary types, leading to excessive noise.",
            "Suggestions": "Modify the logging level for vectorization failures involving unsupported types to debug or log a simple message instead of the full stack trace.",
            "problem_location": {
                "files": [
                    "VectorizationContext.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.vector.VectorizationContext"
                ],
                "methods": [
                    "VectorizationContext.getConstantVectorExpression",
                    "VectorizationContext.getVectorExpression"
                ]
            },
            "possible_fix": "In the `getConstantVectorExpression` method, instead of throwing a `HiveException`, log a warning message and return null or handle the case gracefully to avoid logging the stack trace."
        }
    },
    {
        "filename": "HIVE-5431.json",
        "creation_time": "2013-10-03T03:35:44.000+0000",
        "bug_report": {
            "Title": "PassthroughOutputFormat SH changes causes IllegalArgumentException",
            "Description": "The recent changes introduced by HIVE-4331 added a new key 'hive.passthrough.storagehandler.of' that is only set during storage handler writes. However, the method PlanUtils.configureJobPropertiesForStorageHandler attempts to set this key for both read and write operations, leading to an IllegalArgumentException when reading from a table that has not been written to. This occurs because the key's value is null during read operations, which violates the requirement that property values must not be null.",
            "StackTrace": [
                "2013-09-30 16:20:01,989 ERROR CliDriver (SessionState.java:printError(419)) - Failed with exception java.io.IOException:java.lang.IllegalArgumentException: Property value must not be null",
                "java.io.IOException: java.lang.IllegalArgumentException: Property value must not be null",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:551)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:489)",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:136)",
                "at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1471)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:271)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:348)",
                "at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:446)",
                "at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:456)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:737)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:212)",
                "Caused by: java.lang.IllegalArgumentException: Property value must not be null",
                "at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)",
                "at org.apache.hadoop.conf.Configuration.set(Configuration.java:810)",
                "at org.apache.hadoop.conf.Configuration.set(Configuration.java:792)",
                "at org.apache.hadoop.hive.ql.exec.Utilities.copyTableJobPropertiesToConf(Utilities.java:1826)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getRecordReader(FetchOperator.java:380)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:515)"
            ],
            "RootCause": "The root cause of the issue is that the new property 'hive.passthrough.storagehandler.of' is not set during read operations, leading to a null value being passed to the Configuration.set() method, which throws an IllegalArgumentException.",
            "StepsToReproduce": [
                "Create a Hive query (.q) that only reads data from an HBase table without any prior write operations.",
                "Execute the query and observe the exception thrown."
            ],
            "ExpectedBehavior": "The system should successfully read data from the HBase table without throwing an IllegalArgumentException.",
            "ObservedBehavior": "An IllegalArgumentException is thrown indicating that the property value must not be null when attempting to read data from the HBase table.",
            "Suggestions": "Modify the PlanUtils.configureJobPropertiesForStorageHandler method to check if the property 'hive.passthrough.storagehandler.of' is set before attempting to add it to jobProperties for read operations.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/Driver.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.Utilities",
                    "org.apache.hadoop.hive.ql.exec.FetchOperator",
                    "org.apache.hadoop.hive.ql.Driver"
                ],
                "methods": [
                    "Utilities.copyTableJobPropertiesToConf",
                    "FetchOperator.getNextRow",
                    "Driver.getResults"
                ]
            },
            "possible_fix": "In the method Utilities.copyTableJobPropertiesToConf, add a check to ensure that the property 'hive.passthrough.storagehandler.of' is only set if it is not null. For example:\n\nif (jobProperties.containsKey(\"hive.passthrough.storagehandler.of\") && jobProperties.get(\"hive.passthrough.storagehandler.of\") != null) {\n    job.set(\"hive.passthrough.storagehandler.of\", jobProperties.get(\"hive.passthrough.storagehandler.of\"));\n}"
        }
    },
    {
        "filename": "HIVE-13115.json",
        "creation_time": "2016-02-22T21:43:32.000+0000",
        "bug_report": {
            "Title": "MetaStore Direct SQL getPartitions call fail when the columns schemas for a partition are null",
            "Description": "The issue arises when the MetaStoreDirectSql.getPartitions method is called, leading to a failure in executing the SQL query due to a null column descriptor ID (SDS.CD_ID). This occurs specifically when a new partition is added without setting the column level schemas, which results in an exception being thrown. The ORM layer does not throw an exception for null column descriptors, making the behavior inconsistent between the direct SQL and ORM paths.",
            "StackTrace": [
                "2016-02-11 00:00:19,002 DEBUG metastore.MetaStoreDirectSql (MetaStoreDirectSql.java:timingTrace(602)) - Direct SQL query in 5.842372ms + 1.066728ms, the query is [select \"PARTITIONS\".\"PART_ID\" from \"PARTITIONS\"  inner join \"TBLS\" on \"PARTITIONS\".\"TBL_ID\" = \"TBLS\".\"TBL_ID\"     and \"TBLS\".\"TBL_NAME\" = ?   inner join \"DBS\" on \"TBLS\".\"DB_ID\" = \"DBS\".\"DB_ID\"      and \"DBS\".\"NAME\" = ?  order by \"PART_NAME\" asc]",
                "2016-02-11 00:00:19,021 ERROR metastore.ObjectStore (ObjectStore.java:handleDirectSqlError(2243)) - Direct SQL failed, falling back to ORM",
                "MetaException(message:Unexpected null for one of the IDs, SD 6437, column null, serde 6437 for a non- view)",
                "at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:360)",
                "at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitions(MetaStoreDirectSql.java:224)",
                "at org.apache.hadoop.hive.metastore.ObjectStore$1.getSqlResult(ObjectStore.java:1563)",
                "at org.apache.hadoop.hive.metastore.ObjectStore$1.getSqlResult(ObjectStore.java:1559)",
                "at org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.run(ObjectStore.java:2208)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsInternal(ObjectStore.java:1570)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getPartitions(ObjectStore.java:1553)",
                "at sun.reflect.GeneratedMethodAccessor43.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:483)",
                "at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:108)",
                "at com.sun.proxy.$Proxy5.getPartitions(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_partitions(HiveMetaStore.java:2526)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions.getResult(ThriftHiveMetastore.java:8747)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions.getResult(ThriftHiveMetastore.java:8731)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge20S.java:617)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge20S.java:613)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1591)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge20S.java:613)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is that the Direct SQL query fails when the column descriptor ID (SDS.CD_ID) is null, which occurs when a partition is created without setting the column level schemas. This inconsistency between the Direct SQL and ORM handling of null values leads to the exception being thrown.",
            "StepsToReproduce": [
                "1. Use the MetaStoreClient API to add a new partition without setting column level schemas.",
                "2. Call the getPartitions method on the MetaStoreDirectSql class.",
                "3. Observe the exception being thrown due to the null column descriptor ID."
            ],
            "ExpectedBehavior": "The system should handle null column descriptor IDs gracefully, either by returning an empty result or by not throwing an exception.",
            "ObservedBehavior": "The system throws a MetaException when the column descriptor ID is null, causing the Direct SQL call to fail and fall back to ORM.",
            "Suggestions": "To resolve this issue, it is recommended to make the Direct SQL code path and the ORM code path consistent in handling null column descriptor IDs. This could involve modifying the Direct SQL logic to not fail on null values, similar to the ORM behavior.",
            "problem_location": {
                "files": [
                    "MetaStoreDirectSql.java",
                    "ObjectStore.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.MetaStoreDirectSql",
                    "org.apache.hadoop.hive.metastore.ObjectStore"
                ],
                "methods": [
                    "MetaStoreDirectSql.getPartitionsViaSqlFilterInternal",
                    "MetaStoreDirectSql.getPartitions",
                    "ObjectStore.getPartitionsInternal"
                ]
            },
            "possible_fix": "Modify the getPartitionsViaSqlFilterInternal method in MetaStoreDirectSql to handle null column descriptor IDs without throwing an exception. This could involve adding a check for null values and returning a default value or an empty list instead."
        }
    },
    {
        "filename": "HIVE-4723.json",
        "creation_time": "2013-06-12T20:37:55.000+0000",
        "bug_report": {
            "Title": "DDLSemanticAnalyzer.addTablePartsOutputs eats several exceptions",
            "Description": "The method `addTablePartsOutputs` in `DDLSemanticAnalyzer` is not handling exceptions properly when attempting to retrieve partitions for a non-partitioned table. This leads to a NullPointerException (NPE) when the method tries to access an empty list of partitions, which is not being checked after the exception is caught.",
            "StackTrace": [
                "2013-06-09 16:36:12,628 ERROR parse.DDLSemanticAnalyzer (DDLSemanticAnalyzer.java:addTablePartsOutputs(2899)) - Got HiveException during obtaining list of partitions",
                "2013-06-09 16:36:12,628 ERROR ql.Driver (SessionState.java:printError(383)) - FAILED: NullPointerException null",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.addTablePartsOutputs(DDLSemanticAnalyzer.java:2912)",
                "at org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.addTablePartsOutputs(DDLSemanticAnalyzer.java:2877)",
                "at org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.analyzeAlterTableArchive(DDLSemanticAnalyzer.java:2730)",
                "at org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.analyzeInternal(DDLSemanticAnalyzer.java:316)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:277)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:433)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:337)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:902)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:782)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:156)"
            ],
            "RootCause": "The root cause of the issue is that the method `addTablePartsOutputs` does not check if the list of partitions is empty after catching a HiveException. This results in a NullPointerException when the code attempts to access elements from an empty list.",
            "StepsToReproduce": [
                "Attempt to archive a partition on a non-partitioned table using the Hive command.",
                "Observe the error messages and the resulting NullPointerException."
            ],
            "ExpectedBehavior": "The system should provide a clear error message indicating that the operation cannot be performed on a non-partitioned table without resulting in a NullPointerException.",
            "ObservedBehavior": "The system throws a NullPointerException after logging a HiveException, indicating that an exception was not handled properly.",
            "Suggestions": "Implement a check for the `parts` list after the HiveException is caught to ensure it is not empty before proceeding. If it is empty, throw a more informative exception or handle the case gracefully.",
            "problem_location": {
                "files": [
                    "DDLSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer"
                ],
                "methods": [
                    "addTablePartsOutputs"
                ]
            },
            "possible_fix": "In the `addTablePartsOutputs` method, after catching the HiveException, check if `parts` is null or empty before proceeding. If it is empty, throw a SemanticException with a clear message indicating that the table is not partitioned."
        }
    },
    {
        "filename": "HIVE-15686.json",
        "creation_time": "2017-01-20T22:29:36.000+0000",
        "bug_report": {
            "Title": "Partitions on Remote HDFS break encryption-zone checks",
            "Description": "The issue arises when attempting to drop partitions from a Hive table that are located on a remote HDFS path. The system throws an IllegalArgumentException indicating a mismatch between the expected and actual file system paths. This occurs because the encryption zone checks are not correctly handling paths that are not local, leading to the failure of the operation.",
            "StackTrace": [
                "2015-12-09 19:26:14,997 ERROR [pool-4-thread-1476] server.TThreadPoolServer (TThreadPoolServer.java:run_aroundBody0(305)) - Error occurred during processing of message.",
                "java.lang.IllegalArgumentException: Wrong FS: hdfs://remote-cluster-nn1.myth.net:8020/dbs/mythdb/myth_table/dt=20170120, expected: hdfs://local-cluster-n1.myth.net:8020",
                "at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.getEZForPath(DistributedFileSystem.java:1985)",
                "at org.apache.hadoop.hdfs.client.HdfsAdmin.getEncryptionZoneForPath(HdfsAdmin.java:262)",
                "at org.apache.hadoop.hive.shims.Hadoop23Shims$HdfsEncryptionShim.isPathEncrypted(Hadoop23Shims.java:1290)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.checkTrashPurgeCombination(HiveMetaStore.java:1746)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_partitions_req(HiveMetaStore.java:2974)",
                "at sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:483)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)",
                "at com.sun.proxy.$Proxy5.drop_partitions_req(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_partitions_req.getResult(ThriftHiveMetastore.java:10005)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$drop_partitions_req.getResult(ThriftHiveMetastore.java:9989)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.thrift.TBaseProcessor.process(ProcessFunction.java:39)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$2.run(HadoopThriftAuthBridge.java:767)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$2.run(HadoopThriftAuthBridge.java:763)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:763)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run_aroundBody0(TThreadPoolServer.java:285)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run_aroundBody1$advice(TThreadPoolServer.java:101)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:1)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is that the encryption zone checks in the Hive metastore are not correctly handling paths that are located on a remote HDFS cluster. The system expects a local HDFS path but receives a remote one, leading to an IllegalArgumentException.",
            "StepsToReproduce": [
                "1. Create a Hive table with partitions on a remote HDFS path.",
                "2. Attempt to drop one of the partitions using the Hive metastore.",
                "3. Observe the IllegalArgumentException indicating a wrong file system."
            ],
            "ExpectedBehavior": "The system should correctly handle encryption zone checks for partitions located on remote HDFS paths without throwing an exception.",
            "ObservedBehavior": "The system throws an IllegalArgumentException indicating a mismatch between the expected and actual file system paths when trying to drop partitions on remote HDFS.",
            "Suggestions": "Modify the encryption zone check logic to accommodate remote HDFS paths. Ensure that the system can correctly identify and handle encryption zones for both local and remote file systems.",
            "problem_location": {
                "files": [
                    "Hadoop23Shims.java",
                    "HiveMetaStore.java",
                    "FileSystem.java",
                    "DistributedFileSystem.java",
                    "HdfsAdmin.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.shims.Hadoop23Shims$HdfsEncryptionShim",
                    "org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler",
                    "org.apache.hadoop.fs.FileSystem",
                    "org.apache.hadoop.hdfs.DistributedFileSystem",
                    "org.apache.hadoop.hdfs.client.HdfsAdmin"
                ],
                "methods": [
                    "Hadoop23Shims$HdfsEncryptionShim.isPathEncrypted",
                    "HiveMetaStore$HMSHandler.checkTrashPurgeCombination",
                    "HiveMetaStore$HMSHandler.drop_partitions_req",
                    "FileSystem.checkPath",
                    "DistributedFileSystem.getEZForPath"
                ]
            },
            "possible_fix": "Update the method 'isPathEncrypted' in 'Hadoop23Shims.java' to include logic that checks for remote HDFS paths and retrieves the correct encryption zone accordingly. Additionally, ensure that 'checkPath' in 'FileSystem.java' can handle remote paths without throwing an exception."
        }
    },
    {
        "filename": "HIVE-4975.json",
        "creation_time": "2013-08-01T16:21:38.000+0000",
        "bug_report": {
            "Title": "Reading ORC file throws exception after adding new column",
            "Description": "After adding a new column 'd' to an existing table with three columns (a, b, c), executing a HiveQL query to select the new column results in a runtime exception. The error indicates an ArrayIndexOutOfBoundsException, suggesting that the system is trying to access an index that does not exist in the data structure, likely due to the new column not being properly integrated into the existing data schema.",
            "StackTrace": [
                "java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row [Error getting row data with exception java.lang.ArrayIndexOutOfBoundsException: 4",
                "at org.apache.hadoop.hive.ql.io.orc.OrcStruct$OrcStructInspector.getStructFieldData(OrcStruct.java:206)",
                "at org.apache.hadoop.hive.serde2.objectinspector.UnionStructObjectInspector.getStructFieldData(UnionStructObjectInspector.java:128)",
                "at org.apache.hadoop.hive.serde2.SerDeUtils.buildJSONString(SerDeUtils.java:371)",
                "at org.apache.hadoop.hive.serde2.SerDeUtils.getJSONString(SerDeUtils.java:236)",
                "at org.apache.hadoop.hive.serde2.SerDeUtils.getJSONString(SerDeUtils.java:222)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:665)",
                "at org.apache.hadoop.hive.ql.exec.ExecMapper.map(ExecMapper.java:144)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)",
                "at org.apache.hadoop.mapred.Child$4.run(Child.java:255)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:396)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1083)",
                "at org.apache.hadoop.mapred.Child.main(Child.java:249)"
            ],
            "RootCause": "The root cause of the issue is an ArrayIndexOutOfBoundsException occurring in the OrcStructInspector when trying to access the newly added column 'd'. This suggests that the internal representation of the data structure does not account for the new column, leading to an attempt to access an index that exceeds the current size of the data array.",
            "StepsToReproduce": [
                "Create a table with three columns: a (string), b (string), c (string).",
                "Alter the table to add a new column d (string) using the command: ALTER TABLE table ADD COLUMNS (d string).",
                "Execute the HiveQL query: SELECT d FROM table."
            ],
            "ExpectedBehavior": "The query should return the new column 'd' without any exceptions.",
            "ObservedBehavior": "The query throws a runtime exception indicating an ArrayIndexOutOfBoundsException.",
            "Suggestions": "Ensure that the data structure used to represent the ORC file is updated to include the new column. This may involve modifying the OrcStructInspector to correctly handle the new column during data retrieval.",
            "problem_location": {
                "files": [
                    "org/apache/hadoop/hive/ql/exec/TableScanOperator.java",
                    "org/apache/hadoop/hive/serde2/objectinspector/UnionStructObjectInspector.java",
                    "org/apache/hadoop/hive/serde2/SerDeUtils.java",
                    "org/apache/hadoop/hive/ql/exec/SelectOperator.java",
                    "org/apache/hadoop/hive/ql/exec/MapOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.TableScanOperator",
                    "org.apache.hadoop.hive.serde2.objectinspector.UnionStructObjectInspector",
                    "org.apache.hadoop.hive.serde2.SerDeUtils",
                    "org.apache.hadoop.hive.ql.exec.SelectOperator",
                    "org.apache.hadoop.hive.ql.exec.MapOperator"
                ],
                "methods": [
                    "TableScanOperator.processOp",
                    "UnionStructObjectInspector.getStructFieldData",
                    "SerDeUtils.buildJSONString",
                    "SelectOperator.processOp",
                    "MapOperator.process"
                ]
            },
            "possible_fix": "Modify the OrcStructInspector to ensure that it correctly accounts for the new column 'd' when accessing data. This may involve updating the logic in the getStructFieldData method to handle cases where the number of fields has changed."
        }
    },
    {
        "filename": "HIVE-10538.json",
        "creation_time": "2015-04-29T20:06:38.000+0000",
        "bug_report": {
            "Title": "Fix NPE in FileSinkOperator from hashcode mismatch",
            "Description": "A Null Pointer Exception (NPE) occurs in the FileSinkOperator when processing rows from a join operation involving bucketed tables with multiFileSpray enabled. The issue arises specifically when the method findWriterOffset attempts to compute a hash code for a null object, leading to the NPE. This can happen if the partition evaluation returns null for any of the evaluated objects, which is not handled properly in the current implementation.",
            "StackTrace": [
                "2015-04-29 12:54:12,841 FATAL [pool-110-thread-1]: ExecReducer (ExecReducer.java:reduce(255)) - org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row (tag=0) {\"key\":{},\"value\":{\"_col0\":\"113\",\"_col1\":\"val_113\"}}",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:244)",
                "at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)",
                "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.findWriterOffset(FileSinkOperator.java:819)",
                "at org.apache.hadoop.hive.ql.exec.FileSinkOperator.process(FileSinkOperator.java:747)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:837)",
                "at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:88)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:235)"
            ],
            "RootCause": "The root cause of the NPE is that the findWriterOffset method in FileSinkOperator does not handle null values returned from partitionEval, leading to a null dereference when calculating the hash code.",
            "StepsToReproduce": [
                "Set hive.enforce.bucketing = true",
                "Set hive.exec.reducers.max = 20",
                "Create bucketed tables: bucket_a, bucket_b, and bucket_ab",
                "Insert data into bucket_a and bucket_b",
                "Run the insert overwrite query that joins bucket_a and bucket_b and distributes by key"
            ],
            "ExpectedBehavior": "The system should process the join operation without throwing a Null Pointer Exception, successfully writing the output to the specified bucketed table.",
            "ObservedBehavior": "The system throws a Null Pointer Exception during the processing of the join operation, causing the job to fail.",
            "Suggestions": "Implement null checks in the findWriterOffset method to handle cases where partitionEval returns null. Ensure that the method can gracefully handle such scenarios without throwing an NPE.",
            "problem_location": {
                "files": [
                    "FileSinkOperator.java",
                    "ExecReducer.java",
                    "SelectOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.FileSinkOperator",
                    "org.apache.hadoop.hive.ql.exec.mr.ExecReducer",
                    "org.apache.hadoop.hive.ql.exec.SelectOperator"
                ],
                "methods": [
                    "FileSinkOperator.findWriterOffset",
                    "FileSinkOperator.process",
                    "ExecReducer.reduce",
                    "SelectOperator.process"
                ]
            },
            "possible_fix": "In the findWriterOffset method, add null checks for the evaluated objects before computing the hash code. For example:\n\nprivate int findWriterOffset(Object row) throws HiveException {\n    if (!multiFileSpray) {\n        return 0;\n    } else {\n        int keyHashCode = 0;\n        for (int i = 0; i < partitionEval.length; i++) {\n            Object o = partitionEval[i].evaluate(row);\n            if (o != null) {\n                keyHashCode = keyHashCode * 31 + ObjectInspectorUtils.hashCode(o, partitionObjectInspectors[i]);\n            }\n        }\n        key.setHashCode(keyHashCode);\n        int bucketNum = prtner.getBucket(key, null, totalFiles);\n        return bucketMap.get(bucketNum);\n    }\n}"
        }
    },
    {
        "filename": "HIVE-11902.json",
        "creation_time": "2015-09-21T16:12:37.000+0000",
        "bug_report": {
            "Title": "Abort txn cleanup thread throws SyntaxErrorException",
            "Description": "The DeadTxnReaper encounters a SQL syntax error when attempting to abort transactions due to an empty list of transaction IDs. Specifically, the method `abortTxns` in `TxnHandler` constructs a SQL query that results in invalid syntax when the `txnids` list is empty, leading to a `MySQLSyntaxErrorException`. The problematic query generated is `delete from HIVE_LOCKS where hl_txnid in ();`, which is not valid SQL.",
            "StackTrace": [
                "2015-09-21 05:23:38,148 WARN  [DeadTxnReaper-0]: txn.TxnHandler (TxnHandler.java:performTimeOuts(1876)) - Aborting timedout transactions failed due to You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ')' at line 1(SQLState=42000,ErrorCode=1064)",
                "com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ')' at line 1",
                "at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)",
                "at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)",
                "at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)",
                "at java.lang.reflect.Constructor.newInstance(Constructor.java:526)",
                "at com.mysql.jdbc.Util.handleNewInstance(Util.java:377)",
                "at com.mysql.jdbc.Util.getInstance(Util.java:360)",
                "at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:978)",
                "at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3887)",
                "at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3823)",
                "at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2435)",
                "at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2582)",
                "at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2526)",
                "at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1618)",
                "at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1549)",
                "at com.jolbox.bonecp.StatementHandle.executeUpdate(StatementHandle.java:497)",
                "at org.apache.hadoop.hive.metastore.txn.TxnHandler.abortTxns(TxnHandler.java:1275)",
                "at org.apache.hadoop.hive.metastore.txn.TxnHandler.performTimeOuts(TxnHandler.java:1866)",
                "at org.apache.hadoop.hive.ql.txn.AcidHouseKeeperService$TimedoutTxnReaper.run(AcidHouseKeeperService.java:87)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledFutureTask.java:178)",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is that the `abortTxns` method does not handle the case where the `txnids` list is empty, resulting in an invalid SQL query being generated.",
            "StepsToReproduce": [
                "1. Trigger the DeadTxnReaper to run.",
                "2. Ensure that there are no active transactions to abort, resulting in an empty list of transaction IDs.",
                "3. Observe the logs for the SQL syntax error."
            ],
            "ExpectedBehavior": "The system should handle the case of an empty transaction ID list gracefully, either by skipping the SQL execution or by generating a valid SQL statement.",
            "ObservedBehavior": "The system throws a `MySQLSyntaxErrorException` due to an invalid SQL query generated when the transaction ID list is empty.",
            "Suggestions": "Implement a check in the `abortTxns` method to return early if the `txnids` list is empty, preventing the construction of an invalid SQL query.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.txn.TxnHandler"
                ],
                "methods": [
                    "abortTxns",
                    "performTimeOuts"
                ]
            },
            "possible_fix": "Add a check at the beginning of the `abortTxns` method to return 0 if `txnids` is empty:\n\n```java\nif (txnids.isEmpty()) {\n    return 0;\n}\n```"
        }
    },
    {
        "filename": "HIVE-18918.json",
        "creation_time": "2018-03-09T00:47:55.000+0000",
        "bug_report": {
            "Title": "Bad error message in CompactorMR.launchCompactionJob()",
            "Description": "The error message thrown when a major compaction job fails does not provide sufficient information for debugging. Specifically, it only indicates that the job failed without detailing the reason for the failure or any relevant context about the job or the data being processed.",
            "StackTrace": [
                "java.io.IOException: Major compactor job failed for jobName! Hadoop JobId: rj.getID()",
                "at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.launchCompactionJob(CompactorMR.java:314)",
                "at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:269)",
                "at org.apache.hadoop.hive.ql.txn.compactor.Worker$1.run(Worker.java:175)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1869)",
                "at org.apache.hadoop.hive.ql.txn.compactor.Worker.run(Worker.java:172)"
            ],
            "RootCause": "The root cause of the issue is that the error message generated in the 'launchCompactionJob' method does not include specific details about the failure, such as the reason for the failure or the state of the job, making it difficult to diagnose the problem.",
            "StepsToReproduce": [
                "Trigger a major compaction job on a Hive table with known issues (e.g., corrupted data or misconfiguration).",
                "Observe the error message generated when the job fails."
            ],
            "ExpectedBehavior": "The system should provide a detailed error message that includes the reason for the failure, the job name, and any relevant context that can help in diagnosing the issue.",
            "ObservedBehavior": "The system throws a generic IOException indicating that the major compactor job failed without providing useful information for debugging.",
            "Suggestions": "Enhance the error message in the 'launchCompactionJob' method to include more context about the failure, such as the specific error encountered during the job execution and the state of the data being processed.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.txn.compactor.CompactorMR",
                    "org.apache.hadoop.hive.ql.txn.compactor.Worker"
                ],
                "methods": [
                    "CompactorMR.launchCompactionJob",
                    "CompactorMR.run",
                    "Worker.run"
                ]
            },
            "possible_fix": "Modify the error handling in the 'launchCompactionJob' method to include additional context in the IOException. For example, update the line that throws the exception to include the specific error message from the job or any relevant state information that can aid in debugging."
        }
    },
    {
        "filename": "HIVE-8107.json",
        "creation_time": "2014-09-15T19:49:09.000+0000",
        "bug_report": {
            "Title": "Bad error message for non-existent table in update and delete",
            "Description": "When executing an update or delete command on a non-existent table, the system produces a verbose error message that obscures the actual issue. The error message includes a stack trace that makes it difficult for users to identify the root cause of the problem. Instead, the system should provide a clearer, more concise error message that highlights the 'Table not found' issue at the top.",
            "StackTrace": [
                "2014-09-12 19:45:00,138 ERROR [main]: ql.Driver (SessionState.java:printError(824)) - FAILED: SemanticException [Error 10290]: Encountered parse error while parsing rewritten update or delete query",
                "org.apache.hadoop.hive.ql.parse.SemanticException: Encountered parse error while parsing rewritten update or delete query",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:130)",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeDelete(UpdateDeleteSemanticAnalyzer.java:97)",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:66)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:217)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:406)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:302)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1051)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1121)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:988)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:978)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:246)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:198)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:408)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:344)",
                "at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:441)",
                "at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:457)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:737)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.util.RunJar.run(RunJar.java:221)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:136)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.InvalidTableException: Table not found no_such_table",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1008)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:978)",
                "at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze(UpdateDeleteSemanticAnalyzer.java:128)"
            ],
            "RootCause": "The root cause of the issue is that the system attempts to access a table that does not exist, leading to an InvalidTableException. This exception is caught and wrapped in a more generic SemanticException, which is then logged with a verbose stack trace.",
            "StepsToReproduce": [
                "1. Execute the command: 'update no_such_table set x = 3;'",
                "2. Observe the error message produced by the system."
            ],
            "ExpectedBehavior": "The system should return a clear error message indicating that the specified table does not exist, without excessive stack trace information.",
            "ObservedBehavior": "The system produces a verbose error message that includes a stack trace, making it difficult to identify the actual issue of the non-existent table.",
            "Suggestions": "Refactor the error handling in the UpdateDeleteSemanticAnalyzer to prioritize the 'Table not found' message. Consider modifying the error message format to present the most relevant information first.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/UpdateDeleteSemanticAnalyzer.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.metadata.Hive",
                    "org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer"
                ],
                "methods": [
                    "UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze",
                    "Hive.getTable",
                    "BaseSemanticAnalyzer.analyze"
                ]
            },
            "possible_fix": "In the 'UpdateDeleteSemanticAnalyzer.reparseAndSuperAnalyze' method, modify the exception handling to check for 'InvalidTableException' and return a more user-friendly error message before wrapping it in a SemanticException. For example:\n\n```java\ntry {\n    mTable = db.getTable(tableName[0], tableName[1]);\n} catch (InvalidTableException e) {\n    throw new SemanticException(\"Table not found: \" + tableName[1]);\n}\n```"
        }
    },
    {
        "filename": "HIVE-1326.json",
        "creation_time": "2010-04-25T20:50:54.000+0000",
        "bug_report": {
            "Title": "RowContainer uses hard-coded '/tmp/' path for temporary files",
            "Description": "In the production Hadoop environment, the hard-coded '/tmp/' path used by the RowContainer class for temporary files is causing issues due to limited space. This results in an IOException when the partition fills up, leading to failures in processing large datasets. The RowContainer should utilize the configured Hadoop temporary path instead of the default '/tmp/' to avoid such issues.",
            "StackTrace": [
                "2010-04-25 12:05:28,155 FATAL ExecReducer: org.apache.hadoop.fs.FSError: java.io.IOException: No space left on device",
                "at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:199)",
                "at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)",
                "at java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)",
                "at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:49)",
                "at java.io.DataOutputStream.write(DataOutputStream.java:90)",
                "at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1013)",
                "at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat$1.write(HiveSequenceFileOutputFormat.java:70)",
                "at org.apache.hadoop.hive.ql.exec.persistence.RowContainer.spillBlock(RowContainer.java:343)",
                "at org.apache.hadoop.hive.ql.exec.persistence.RowContainer.add(RowContainer.java:163)",
                "at org.apache.hadoop.hive.ql.exec.JoinOperator.processOp(JoinOperator.java:118)",
                "at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:456)",
                "at org.apache.hadoop.hive.ql.exec.ExecReducer.reduce(ExecReducer.java:244)",
                "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:436)",
                "at org.apache.hadoop.mapred.Child.main(Child.main.java:158)"
            ],
            "RootCause": "The RowContainer class is using a hard-coded path '/tmp/' for creating temporary files, which can lead to insufficient space errors in environments where the /tmp/ directory is limited in size.",
            "StepsToReproduce": [
                "Set up a Hadoop environment with limited space in the /tmp/ directory.",
                "Run a query that utilizes the RowContainer class and generates a large number of temporary files.",
                "Observe the system behavior as it fills up the /tmp/ directory."
            ],
            "ExpectedBehavior": "The RowContainer should create temporary files in a configurable Hadoop temporary directory, preventing any space-related issues.",
            "ObservedBehavior": "The RowContainer creates temporary files in the hard-coded '/tmp/' directory, leading to 'No space left on device' errors during processing.",
            "Suggestions": "Modify the RowContainer class to use the configured Hadoop temporary path instead of the hard-coded '/tmp/' path.",
            "problem_location": {
                "files": [
                    "RowContainer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.persistence.RowContainer"
                ],
                "methods": [
                    "RowContainer.spillBlock",
                    "RowContainer.add"
                ]
            },
            "possible_fix": "Change the path used in RowContainer.spillBlock method from '/tmp/' to a configurable path obtained from Hadoop configuration settings. For example:\n\nString tempPath = conf.get(\"hadoop.tmp.dir\", \"/tmp/\");\nparentFile = new File(tempPath + '/' + parentId);"
        }
    },
    {
        "filename": "HIVE-11369.json",
        "creation_time": "2015-07-24T16:28:47.000+0000",
        "bug_report": {
            "Title": "Mapjoins in HiveServer2 fail when jmxremote is used",
            "Description": "The issue arises when the HiveServer2 is started with JMX options enabled, specifically the jmxremote settings in hive-env.sh. While the same configuration works in the CLI, it fails in HiveServer2, leading to an execution error during the processing of a MapJoin query. The logs indicate that the execution fails with an exit status of 1, which is not observed when the JMX options are removed.",
            "StackTrace": [
                "2015-07-24 17:19:28,499 ERROR [HiveServer2-Handler-Pool: Thread-22]: exec.Task (SessionState.java:printError(921)) - Execution failed with exit status: 1",
                "2015-07-24 17:19:28,518 ERROR [HiveServer2-Handler-Pool: Thread-22]: ql.Driver (SessionState.java:printError(921)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask",
                "2015-07-24 17:19:28,599 WARN  [HiveServer2-Handler-Pool: Thread-22]: security.UserGroupInformation (UserGroupInformation.java:doAs(1674)) - PriviledgedActionException as:hive (auth:SIMPLE) cause:org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask"
            ],
            "RootCause": "The root cause appears to be related to the interaction between the JMX settings and the execution environment of HiveServer2, which may be affecting the way MapJoin tasks are executed, leading to an unexpected exit status.",
            "StepsToReproduce": [
                "1. Set hive.auto.convert.join to true.",
                "2. Add the following JMX options to hive-env.sh: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=8009.",
                "3. Start HiveServer2.",
                "4. Execute a MapJoin query."
            ],
            "ExpectedBehavior": "The MapJoin query should execute successfully without errors when JMX options are enabled.",
            "ObservedBehavior": "The execution of the MapJoin query fails with an exit status of 1 when JMX options are enabled.",
            "Suggestions": "Investigate the interaction between JMX settings and the execution of MapJoin tasks in HiveServer2. Consider modifying the JMX configuration or the way HiveServer2 handles MapJoin tasks when JMX is enabled.",
            "problem_location": {
                "files": [
                    "service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java",
                    "service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java",
                    "service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java"
                ],
                "classes": [
                    "org.apache.hive.service.cli.session.HiveSessionImpl",
                    "org.apache.hive.service.cli.operation.SQLOperation",
                    "org.apache.hive.service.cli.thrift.ThriftCLIService"
                ],
                "methods": [
                    "HiveSessionImpl.executeStatementInternal",
                    "SQLOperation.runQuery",
                    "ThriftCLIService.ExecuteStatement"
                ]
            },
            "possible_fix": "Review the handling of JMX settings in HiveServer2, particularly in the context of MapJoin execution. It may be necessary to adjust the configuration or add error handling to manage the execution context when JMX is enabled."
        }
    },
    {
        "filename": "HIVE-9055.json",
        "creation_time": "2014-12-09T19:51:18.000+0000",
        "bug_report": {
            "Title": "Tez: union all followed by group by followed by another union all gives error",
            "Description": "Executing a Hive query that involves a union followed by a group by operation and another union results in an IndexOutOfBoundsException. The error occurs specifically when the query is run using the Tez execution engine, while it works correctly with the MapReduce engine. The issue arises from the handling of operator trees during the semantic analysis and task generation phases.",
            "StackTrace": [
                "ERROR ql.Driver (SessionState.java:printError(834)) - FAILED: IndexOutOfBoundsException Index: -1, Size: 1",
                "java.lang.IndexOutOfBoundsException: Index: -1, Size: 1",
                "at java.util.LinkedList.checkElementIndex(LinkedList.java:553)",
                "at java.util.LinkedList.get(LinkedList.java:474)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWork.process(GenTezWork.java:354)",
                "at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:94)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:87)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.startWalking(GenTezWorkWalker.java:69)",
                "at org.apache.hadoop.hive.ql.parse.TezCompiler.generateTaskTree(TezCompiler.java:368)",
                "at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:202)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10202)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:420)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:306)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1108)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1045)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1035)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:199)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:151)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:362)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:297)",
                "at org.apache.hadoop.hive.qtest.QTestUtil.executeClient(QTestUtil.java:834)",
                "at org.apache.hadoop.hive.cli.TestMiniTezCliDriver.runTest(TestMiniTezCliDriver.java:136)",
                "at org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_uniontez(TestMiniTezCliDriver.java:120)"
            ],
            "RootCause": "The root cause of the issue is an IndexOutOfBoundsException occurring in the GenTezWork.process method when processing the operator tree. This is likely due to incorrect handling of the union and group by operations in the context of the Tez execution engine, which leads to an invalid index being accessed in a linked list.",
            "StepsToReproduce": [
                "Set the Hive execution engine to Tez: set hive.execution.engine=tez;",
                "Execute the following query: select key from (select key from src union all select key from src) tab group by key union all select key from src;"
            ],
            "ExpectedBehavior": "The query should execute successfully and return the expected results without any errors.",
            "ObservedBehavior": "The query fails with an IndexOutOfBoundsException, indicating an issue with the processing of the operator tree in the Tez execution engine.",
            "Suggestions": "Review the implementation of the GenTezWork.process method to ensure that the operator tree is being processed correctly, especially in the context of union and group by operations. Consider adding checks to prevent accessing invalid indices in the linked list.",
            "problem_location": {
                "files": [
                    "GenTezWork.java",
                    "DefaultRuleDispatcher.java",
                    "GenTezWorkWalker.java",
                    "TaskCompiler.java",
                    "SemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.GenTezWork",
                    "org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher",
                    "org.apache.hadoop.hive.ql.parse.GenTezWorkWalker",
                    "org.apache.hadoop.hive.ql.parse.TaskCompiler",
                    "org.apache.hadoop.hive.ql.parse.SemanticAnalyzer"
                ],
                "methods": [
                    "GenTezWork.process",
                    "DefaultRuleDispatcher.dispatch",
                    "GenTezWorkWalker.walk",
                    "TaskCompiler.compile",
                    "SemanticAnalyzer.analyzeInternal"
                ]
            },
            "possible_fix": "In the GenTezWork.process method, add validation to ensure that the index being accessed in the linked list is within bounds. Additionally, review the logic for handling union and group by operations to ensure that they are correctly integrated into the operator tree."
        }
    },
    {
        "filename": "HIVE-13856.json",
        "creation_time": "2016-05-25T21:50:49.000+0000",
        "bug_report": {
            "Title": "Fetching transaction batches during ACID streaming against Hive Metastore using Oracle DB fails",
            "Description": "The system encounters a SQL syntax error when attempting to fetch transaction batches during ACID streaming against the Hive Metastore using an Oracle database. The error message indicates that the SQL command is not properly ended, specifically when trying to execute an INSERT statement that attempts to insert multiple rows at once. Oracle does not support this syntax, which leads to the failure of the transaction operation.",
            "StackTrace": [
                "2016-05-25 00:43:49,682 INFO  [pool-4-thread-5]: txn.TxnHandler (TxnHandler.java:checkRetryable(1585)) - Non-retryable error: ORA-00933: SQL command not properly ended",
                "2016-05-25 00:43:49,685 ERROR [pool-4-thread-5]: metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(159)) - MetaException(message:Unable to select from transaction database java.sql.SQLSyntaxErrorException: ORA-00933: SQL command not properly ended",
                "at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:440)",
                "at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:396)",
                "at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:837)",
                "at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:445)",
                "at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:191)",
                "at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:523)",
                "at oracle.jdbc.driver.T4CStatement.doOall8(T4CStatement.java:193)",
                "at oracle.jdbc.driver.T4CStatement.executeForRows(T4CStatement.java:999)",
                "at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1315)",
                "at oracle.jdbc.driver.OracleStatement.executeInternal(OracleStatement.java:1890)",
                "at oracle.jdbc.driver.OracleStatement.execute(OracleStatement.java:1855)",
                "at oracle.jdbc.driver.OracleStatementWrapper.execute(OracleStatementWrapper.java:304)",
                "at com.jolbox.bonecp.StatementHandle.execute(StatementHandle.java:254)",
                "at org.apache.hadoop.hive.metastore.txn.TxnHandler.openTxns(TxnHandler.java:429)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.open_txns(HiveMetaStore.java:5647)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)",
                "at com.sun.proxy.$Proxy15.open_txns(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$open_txns.getResult(ThriftHiveMetastore.java:11604)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$open_txns.getResult(ThriftHiveMetastore.java:11589)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is the attempt to execute an INSERT statement that tries to insert multiple rows at once, which is not supported by Oracle SQL syntax. The code constructs a query of the form 'INSERT INTO TXNS (...) VALUES (...), (...)', which leads to the ORA-00933 error.",
            "StepsToReproduce": [
                "Set up a Hive Metastore with an Oracle database.",
                "Attempt to fetch transaction batches using ACID streaming.",
                "Observe the error in the logs indicating a SQL syntax error."
            ],
            "ExpectedBehavior": "The system should successfully fetch transaction batches without encountering SQL syntax errors.",
            "ObservedBehavior": "The system fails to fetch transaction batches and logs an ORA-00933 SQL syntax error.",
            "Suggestions": "Refactor the SQL INSERT statement to either insert each row individually or use the 'INSERT ALL' syntax supported by Oracle.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.txn.TxnHandler",
                    "org.apache.hadoop.hive.metastore.RetryingHMSHandler"
                ],
                "methods": [
                    "TxnHandler.openTxns",
                    "RetryingHMSHandler.invoke"
                ]
            },
            "possible_fix": "Modify the 'openTxns' method in TxnHandler.java to construct the INSERT statement using 'INSERT ALL' or to execute individual INSERT statements for each transaction. For example, replace the current batch insert logic with a loop that executes a single INSERT statement for each transaction."
        }
    },
    {
        "filename": "HIVE-7374.json",
        "creation_time": "2014-07-09T16:02:15.000+0000",
        "bug_report": {
            "Title": "SHOW COMPACTIONS fail with remote metastore when there are no compactions",
            "Description": "When executing the 'show compactions' command in the CLI with a remote metastore and no compactions available, the system throws an error due to a missing required field in the response. The error indicates that the 'compacts' field is unset, leading to a TProtocolException during the processing of the response.",
            "StackTrace": [
                "FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. org.apache.thrift.transport.TTransportException",
                "2014-07-09 17:54:10,537 ERROR [pool-3-thread-20]: server.TThreadPoolServer (TThreadPoolServer.java:run(213)) - Thrift error occurred during processing of message.",
                "org.apache.thrift.protocol.TProtocolException: Required field 'compacts' is unset! Struct:ShowCompactResponse(compacts:null)",
                "at org.apache.hadoop.hive.metastore.api.ShowCompactResponse.validate(ShowCompactResponse.java:310)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result.validate(ThriftHiveMetastore.java)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result$show_compact_resultStandardScheme.write(ThriftHiveMetastore.java)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result$show_compact_resultStandardScheme.write(ThriftHiveMetastore.java)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$show_compact_result.write(ThriftHiveMetastore.java)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:53)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:103)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:744)"
            ],
            "RootCause": "The root cause of the issue is that the 'ShowCompactResponse' object does not properly handle the case when there are no compactions, resulting in the 'compacts' field being unset. This leads to a TProtocolException when the response is validated.",
            "StepsToReproduce": [
                "1. Set up a remote metastore.",
                "2. Ensure there are no compactions available.",
                "3. Execute the command 'show compactions' in the CLI."
            ],
            "ExpectedBehavior": "The system should return an empty list or a message indicating that there are no compactions available without throwing an error.",
            "ObservedBehavior": "The system throws a TProtocolException indicating that the required field 'compacts' is unset.",
            "Suggestions": "Implement a check in the 'ShowCompactResponse' class to handle cases where there are no compactions, ensuring that the 'compacts' field is set to an empty list instead of being null.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/api/ShowCompactResponse.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/TUGIBasedProcessor.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.api.ShowCompactResponse",
                    "org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore",
                    "org.apache.hadoop.hive.metastore.TUGIBasedProcessor"
                ],
                "methods": [
                    "ShowCompactResponse.validate",
                    "ThriftHiveMetastore$show_compact_result.validate",
                    "TUGIBasedProcessor.process"
                ]
            },
            "possible_fix": "In the 'ShowCompactResponse' class, modify the validate method to check if 'compacts' is null and set it to an empty list if it is. This will prevent the TProtocolException from being thrown when there are no compactions."
        }
    },
    {
        "filename": "HIVE-12206.json",
        "creation_time": "2015-10-17T00:30:22.000+0000",
        "bug_report": {
            "Title": "ClassNotFound Exception during query compilation with Tez and Union query and GenericUDFs",
            "Description": "The issue arises when executing a Hive query that utilizes a user-defined function (UDF) named 'myudf' defined in the jar '/tmp/udf-2.2.0-snapshot.jar'. The query fails with a ClassNotFoundException indicating that the class 'com.aginity.amp.hive.udf.UniqueNumberGenerator' cannot be found during the serialization process. This occurs specifically when the query involves a UNION operation and attempts to serialize the UDF for execution in a Tez environment.",
            "StackTrace": [
                "2015-10-16 17:00:55,557 ERROR ql.Driver (SessionState.java:printError(963)) - FAILED: KryoException Unable to find class: com.aginity.amp.hive.udf.UniqueNumberGenerator",
                "Serialization trace:",
                "genericUDF (org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)",
                "colExprMap (org.apache.hadoop.hive.ql.exec.SelectOperator)",
                "parentOperators (org.apache.hadoop.hive.ql.exec.UnionOperator)",
                "childOperators (org.apache.hadoop.hive.ql.exec.SelectOperator)",
                "childOperators (org.apache.hadoop.hive.ql.exec.LimitOperator)",
                "Caused by: java.lang.ClassNotFoundException: com.aginity.amp.hive.udf.UniqueNumberGenerator"
            ],
            "RootCause": "The root cause of the issue is that the class 'com.aginity.amp.hive.udf.UniqueNumberGenerator' is not found in the classpath during the serialization process. This typically indicates that the jar containing the UDF has not been properly added to the Hive session or is not accessible in the execution environment.",
            "StepsToReproduce": [
                "1. Execute the following query without the UDF: 'explain select * from (select key + key from src limit 1) a union all select * from (select key + key from src limit 1) b;'",
                "2. Add the jar containing the UDF using the command: 'add jar /tmp/udf-2.2.0-snapshot.jar;'",
                "3. Create the temporary function with the command: 'create temporary function myudf as 'com.aginity.amp.hive.udf.UniqueNumberGenerator';'",
                "4. Execute the query with the UDF: 'explain select myudf() from (select key from src limit 1) a union all select myudf() from (select key from src limit 1) a;'"
            ],
            "ExpectedBehavior": "The query should execute successfully, utilizing the UDF without any ClassNotFoundException errors.",
            "ObservedBehavior": "The query fails with a ClassNotFoundException indicating that the UDF class cannot be found during the serialization process.",
            "Suggestions": "Ensure that the jar file containing the UDF is correctly added to the Hive session and is accessible in the execution environment. Verify that the class 'com.aginity.amp.hive.udf.UniqueNumberGenerator' is present in the specified jar file.",
            "problem_location": {
                "files": [
                    "SessionState.java",
                    "Utilities.java",
                    "GenTezUtils.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.Driver",
                    "org.apache.hadoop.hive.ql.exec.Utilities",
                    "org.apache.hadoop.hive.ql.parse.GenTezUtils"
                ],
                "methods": [
                    "Driver.runInternal",
                    "Utilities.deserializePlan",
                    "GenTezUtils.removeUnionOperators"
                ]
            },
            "possible_fix": "To resolve the issue, ensure that the jar file '/tmp/udf-2.2.0-snapshot.jar' is correctly added to the Hive session before executing the query. This can be done by verifying the command 'add jar /tmp/udf-2.2.0-snapshot.jar;' is executed successfully and that the jar is accessible in the classpath."
        }
    },
    {
        "filename": "HIVE-10098.json",
        "creation_time": "2015-03-26T17:12:20.000+0000",
        "bug_report": {
            "Title": "HS2 local task for map join fails in KMS encrypted cluster",
            "Description": "The issue arises when executing a Hive query that performs a MapJoin in a KMS encrypted cluster. The problem is triggered by the KMSClientProvider's inability to add delegation tokens due to missing Kerberos credentials, resulting in a java.lang.reflect.UndeclaredThrowableException. This occurs specifically when the KMS was enabled after the cluster was secured with Kerberos, leading to authentication failures.",
            "StackTrace": [
                "2015-03-18 08:49:19,050 ERROR [main]: mr.MapredLocalTask (MapredLocalTask.java:executeFromChildJVM(314)) - Hive Runtime Error: Map local work failed",
                "java.io.IOException: java.io.IOException: java.lang.reflect.UndeclaredThrowableException",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:634)",
                "at org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.startForward(MapredLocalTask.java:363)",
                "at org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.startForward(MapredLocalTask.java:337)",
                "at org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.executeFromChildJVM(MapredLocalTask.java:303)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.main(ExecDriver.java:735)",
                "Caused by: java.lang.reflect.UndeclaredThrowableException",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1655)",
                "at org.apache.hadoop.crypto.key.kms.KMSClientProvider.addDelegationTokens(KMSClientProvider.java:808)",
                "Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)",
                "at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:306)"
            ],
            "RootCause": "The root cause of the issue is the failure to obtain valid Kerberos credentials, which is necessary for the KMSClientProvider to add delegation tokens. This failure is indicated by the AuthenticationException stating that no valid credentials were provided.",
            "StepsToReproduce": [
                "Enable KMS after securing the cluster with Kerberos.",
                "Create two tables in Hive: a small table and a large table.",
                "Load data into both tables.",
                "Execute a Hive query that performs a MapJoin on these tables using beeline."
            ],
            "ExpectedBehavior": "The Hive query should execute successfully, performing the MapJoin without any errors related to Kerberos authentication.",
            "ObservedBehavior": "The Hive query fails with a java.lang.reflect.UndeclaredThrowableException due to missing Kerberos credentials, preventing the addition of delegation tokens.",
            "Suggestions": "Ensure that the Kerberos credentials are available and valid before executing Hive queries that require KMS. This may involve checking the Kerberos ticket granting ticket (TGT) and ensuring that the KMS is properly configured to work with the existing Kerberos setup.",
            "problem_location": {
                "files": [
                    "KMSClientProvider.java",
                    "MapredLocalTask.java",
                    "ExecDriver.java",
                    "FetchOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.crypto.key.kms.KMSClientProvider",
                    "org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask",
                    "org.apache.hadoop.hive.ql.exec.ExecDriver",
                    "org.apache.hadoop.hive.ql.exec.FetchOperator"
                ],
                "methods": [
                    "KMSClientProvider.addDelegationTokens",
                    "MapredLocalTask.executeFromChildJVM",
                    "ExecDriver.main",
                    "FetchOperator.getNextRow"
                ]
            },
            "possible_fix": "To resolve the issue, ensure that the Kerberos authentication is properly configured and that valid credentials are available before executing the Hive query. This may involve running 'kinit' to obtain a valid TGT or checking the KMS configuration to ensure it is compatible with the Kerberos setup."
        }
    },
    {
        "filename": "HIVE-7745.json",
        "creation_time": "2014-08-16T01:20:06.000+0000",
        "bug_report": {
            "Title": "NullPointerException when turn on hive.optimize.union.remove, hive.merge.mapfiles and hive.merge.mapredfiles [Spark Branch]",
            "Description": "A NullPointerException occurs when executing a query that involves union operations while the configuration options hive.optimize.union.remove, hive.merge.mapfiles, and hive.merge.mapredfiles are enabled. The issue arises during the task generation phase, specifically in the createMoveTask method of GenMapRedUtils, where a null reference is encountered when attempting to create a move task for file sinks. This problem does not occur when the aforementioned configurations are disabled.",
            "StackTrace": [
                "2014-08-16 01:32:26,849 ERROR [main]: ql.Driver (SessionState.java:printError(681)) - FAILED: NullPointerException null",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils.createMoveTask(GenMapRedUtils.java:1738)",
                "at org.apache.hadoop.hive.ql.parse.spark.GenSparkUtils.processFileSink(GenSparkUtils.java:281)",
                "at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.generateTaskTree(SparkCompiler.java:187)",
                "at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:199)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:9508)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:208)",
                "at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:74)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:208)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:414)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:310)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1005)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1070)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:942)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:932)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:246)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:198)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:408)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:675)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:197)"
            ],
            "RootCause": "The root cause of the NullPointerException is likely due to the createMoveTask method in GenMapRedUtils attempting to access a property of a null FileSinkOperator or its configuration when merging files, which is triggered by the union operation in the query.",
            "StepsToReproduce": [
                "1. Enable the configurations: hive.optimize.union.remove, hive.merge.mapfiles, and hive.merge.mapredfiles.",
                "2. Create a table inputTbl1 with the specified schema.",
                "3. Load data into inputTbl1 from a local file.",
                "4. Execute the provided insert overwrite query that includes union operations."
            ],
            "ExpectedBehavior": "The query should execute successfully without throwing a NullPointerException, and the output table outputTbl1 should be populated with the expected results.",
            "ObservedBehavior": "A NullPointerException is thrown during the execution of the query, causing the operation to fail.",
            "Suggestions": "Review the createMoveTask method in GenMapRedUtils to ensure that all necessary objects are properly initialized before being accessed. Consider adding null checks or initializing the FileSinkOperator configuration to prevent the NullPointerException.",
            "problem_location": {
                "files": [
                    "GenMapRedUtils.java",
                    "GenSparkUtils.java",
                    "SparkCompiler.java",
                    "TaskCompiler.java",
                    "BaseSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils",
                    "org.apache.hadoop.hive.ql.parse.spark.GenSparkUtils",
                    "org.apache.hadoop.hive.ql.parse.spark.SparkCompiler",
                    "org.apache.hadoop.hive.ql.parse.TaskCompiler",
                    "org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer"
                ],
                "methods": [
                    "GenMapRedUtils.createMoveTask",
                    "GenSparkUtils.processFileSink",
                    "SparkCompiler.generateTaskTree",
                    "TaskCompiler.compile",
                    "BaseSemanticAnalyzer.analyzeInternal"
                ]
            },
            "possible_fix": "In the createMoveTask method, add checks to ensure that the FileSinkOperator and its configuration are not null before attempting to access their properties. For example:\n\nif (fsOp == null || fsOp.getConf() == null) {\n    throw new SemanticException(\"FileSinkOperator or its configuration is null\");\n}\n\nThis will help prevent the NullPointerException from occurring."
        }
    },
    {
        "filename": "HIVE-11762.json",
        "creation_time": "2015-09-08T20:10:54.000+0000",
        "bug_report": {
            "Title": "TestHCatLoaderEncryption failures when using Hadoop 2.7",
            "Description": "The test 'TestHCatLoaderEncryption' fails when executed with Hadoop version 2.7.0 due to a NoSuchMethodError. The method 'setKeyProvider' in the 'DFSClient' class has undergone a change in its parameter type between Hadoop versions 2.6 and 2.7. The test attempts to call the old method signature, which no longer exists in the newer version, leading to the error during the setup phase of the test.",
            "StackTrace": [
                "java.lang.NoSuchMethodError: org.apache.hadoop.hdfs.DFSClient.setKeyProvider(Lorg/apache/hadoop/crypto/key/KeyProviderCryptoExtension;)V",
                "at org.apache.hadoop.hive.shims.Hadoop23Shims.getMiniDfs(Hadoop23Shims.java:534)",
                "at org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.initEncryptionShim(TestHCatLoaderEncryption.java:252)",
                "at org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption.setup(TestHCatLoaderEncryption.java:200)"
            ],
            "RootCause": "The root cause of the issue is the change in the method signature of 'setKeyProvider' in the 'DFSClient' class from 'KeyProviderCryptoExtension' to 'KeyProvider'. The test code is still referencing the old method signature, which results in a NoSuchMethodError.",
            "StepsToReproduce": [
                "Set up a test environment with Hadoop version 2.7.0.",
                "Run the 'TestHCatLoaderEncryption' test suite with the command: -Dhadoop23.version=2.7.0."
            ],
            "ExpectedBehavior": "The test 'TestHCatLoaderEncryption' should pass without any errors when run with Hadoop version 2.7.0.",
            "ObservedBehavior": "The test fails with a NoSuchMethodError indicating that the method 'setKeyProvider' with the old parameter type does not exist.",
            "Suggestions": "Update the test code to use the new method signature for 'setKeyProvider' that accepts 'KeyProvider' instead of 'KeyProviderCryptoExtension'.",
            "problem_location": {
                "files": [
                    "Hadoop23Shims.java",
                    "TestHCatLoaderEncryption.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.shims.Hadoop23Shims",
                    "org.apache.hive.hcatalog.pig.TestHCatLoaderEncryption"
                ],
                "methods": [
                    "Hadoop23Shims.getMiniDfs",
                    "TestHCatLoaderEncryption.initEncryptionShim",
                    "TestHCatLoaderEncryption.setup"
                ]
            },
            "possible_fix": "In the 'TestHCatLoaderEncryption' class, modify the call to 'setKeyProvider' to use the new parameter type. For example:\n\n// Old code\n// dfsClient.setKeyProvider(new KeyProviderCryptoExtension());\n\n// New code\ndfsClient.setKeyProvider(new KeyProvider());"
        }
    },
    {
        "filename": "HIVE-6990.json",
        "creation_time": "2014-04-30T04:24:25.000+0000",
        "bug_report": {
            "Title": "Direct SQL fails when the explicit schema setting is different from the default one",
            "Description": "The application encounters a JDODataStoreException when executing a direct SQL query to retrieve partitions from the Hive metastore. This issue arises specifically when the schema defined in the hive-site.xml is different from the default schema. The error indicates that the SQL query fails, leading to a fallback to ORM, which is not the intended behavior.",
            "StackTrace": [
                "2014-04-23 17:30:23,331 ERROR metastore.ObjectStore (ObjectStore.java:handleDirectSqlError(1756)) - Direct SQL failed, falling back to ORM",
                "javax.jdo.JDODataStoreException: Error executing SQL query \"select PARTITIONS.PART_ID from PARTITIONS inner join TBLS on PARTITIONS.TBL_ID = TBLS.TBL_ID inner join DBS on TBLS.DB_ID = DBS.DB_ID inner join PARTITION_KEY_VALS as FILTER0 on FILTER0.PART_ID = PARTITIONS.PART_ID and FILTER0.INTEGER_IDX = 0 where TBLS.TBL_NAME = ? and DBS.NAME = ? and ((FILTER0.PART_KEY_VAL = ?))\".",
                "at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:451)",
                "at org.datanucleus.api.jdo.JDOQuery.executeWithArray(JDOQuery.java:321)",
                "at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:181)",
                "at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilter(MetaStoreDirectSql.java:98)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByFilterInternal(ObjectStore.java:1833)",
                "at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByFilter(ObjectStore.java:1806)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:94)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)",
                "at java.lang.reflect.Method.invoke(Method.java:619)",
                "at org.apache.hadoop.hive.metastore.RetryingRawStore.invoke(RetryingRawStore.java:124)",
                "at com.sun.proxy.$Proxy11.getPartitionsByFilter(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_partitions_by_filter(HiveMetaStore.java:3310)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:103)",
                "at com.sun.proxy.$Proxy12.get_partitions_by_filter(Unknown Source)"
            ],
            "RootCause": "The root cause of the issue is that the SQL query fails due to the explicit schema setting in hive-site.xml being different from the default schema. This leads to the inability to execute the SQL query correctly, resulting in a JDODataStoreException.",
            "StepsToReproduce": [
                "1. Set the following properties in hive-site.xml:",
                "   <property>",
                "     <name>javax.jdo.mapping.Schema</name>",
                "     <value>HIVE</value>",
                "   </property>",
                "   <property>",
                "     <name>javax.jdo.option.ConnectionUserName</name>",
                "     <value>user1</value>",
                "   </property>",
                "2. Execute the following Hive queries:",
                "   hive> create table mytbl ( key int, value string);",
                "   hive> load data local inpath 'examples/files/kv1.txt' overwrite into table mytbl;",
                "   hive> select * from mytbl;",
                "   hive> create view myview partitioned on (value) as select key, value from mytbl where key=98;",
                "   hive> alter view myview add partition (value='val_98');",
                "   hive> alter view myview drop partition (value='val_xyz');"
            ],
            "ExpectedBehavior": "The expected behavior is that the SQL query executes successfully, retrieving the partitions without falling back to ORM, regardless of the schema settings.",
            "ObservedBehavior": "The observed behavior is that the SQL query fails with a JDODataStoreException, causing the system to fall back to ORM, which is not the intended behavior.",
            "Suggestions": "To resolve this issue, ensure that the schema defined in hive-site.xml matches the default schema expected by the Hive metastore. Additionally, review the SQL query generation logic to handle different schemas appropriately.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.MetaStoreDirectSql",
                    "org.apache.hadoop.hive.metastore.ObjectStore",
                    "org.apache.hadoop.hive.metastore.RetryingHMSHandler"
                ],
                "methods": [
                    "MetaStoreDirectSql.getPartitionsViaSqlFilterInternal",
                    "ObjectStore.getPartitionsByFilterInternal",
                    "RetryingHMSHandler.invoke"
                ]
            },
            "possible_fix": "Ensure that the schema in hive-site.xml is set correctly to match the expected schema. Additionally, consider adding error handling in the SQL query execution to provide more informative error messages when schema mismatches occur."
        }
    },
    {
        "filename": "HIVE-7114.json",
        "creation_time": "2014-05-22T14:58:09.000+0000",
        "bug_report": {
            "Title": "Extra Tez session is started during HiveServer2 startup",
            "Description": "During the startup of HiveServer2, an additional Tez Application Master (AM) is being launched unexpectedly. This occurs due to the configuration settings that trigger the initialization of Tez sessions when HiveServer2 starts. The stack trace indicates that the TezSessionState is being opened, which is not intended in this context.",
            "StackTrace": [
                "2014-05-09 23:11:22,261 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:addAdminUsers(588)) - No user is added in admin role, since config is empty",
                "java.lang.Exception: Opening session",
                "at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:134)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.open(TezSessionState.java:119)",
                "at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:356)",
                "at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:292)",
                "at org.apache.hive.service.cli.session.SessionManager.applyAuthorizationConfigPolicy(SessionManager.java:88)",
                "at org.apache.hive.service.cli.session.SessionManager.init(SessionManager.java:63)",
                "at org.apache.hive.service.CompositeService.init(CompositeService.java:59)",
                "at org.apache.hive.service.cli.CLIService.init(CLIService.java:110)",
                "at org.apache.hive.service.CompositeService.init(CompositeService.java:59)",
                "at org.apache.hive.service.server.HiveServer2.init(HiveServer2.java:68)",
                "at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:100)",
                "at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:149)"
            ],
            "RootCause": "The root cause of the issue is the configuration setting 'HIVE_SERVER2_TEZ_INITIALIZE_DEFAULT_SESSIONS' being set to true, which leads to the automatic creation of a Tez session during the initialization of HiveServer2.",
            "StepsToReproduce": [
                "1. Start HiveServer2 with the configuration 'HIVE_SERVER2_TEZ_INITIALIZE_DEFAULT_SESSIONS' set to true.",
                "2. Observe the logs for the startup process.",
                "3. Note the additional Tez session being created."
            ],
            "ExpectedBehavior": "Only one Tez session should be created when explicitly requested, not during the automatic startup of HiveServer2.",
            "ObservedBehavior": "An extra Tez session is launched during the startup of HiveServer2, leading to unnecessary resource consumption.",
            "Suggestions": "Consider modifying the configuration to prevent automatic Tez session initialization during HiveServer2 startup, or ensure that the session is only created when explicitly required.",
            "problem_location": {
                "files": [
                    "service/src/java/org/apache/hive/service/server/HiveServer2.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java"
                ],
                "classes": [
                    "org.apache.hive.service.server.HiveServer2",
                    "org.apache.hadoop.hive.ql.session.SessionState",
                    "org.apache.hadoop.hive.ql.exec.tez.TezSessionState"
                ],
                "methods": [
                    "HiveServer2.init",
                    "SessionState.start",
                    "TezSessionState.open"
                ]
            },
            "possible_fix": "To resolve this issue, check the configuration for 'HIVE_SERVER2_TEZ_INITIALIZE_DEFAULT_SESSIONS' and set it to false if automatic Tez session initialization is not desired. Additionally, review the logic in 'HiveServer2.startHiveServer2' to ensure that Tez sessions are only created when explicitly required."
        }
    },
    {
        "filename": "HIVE-11991.json",
        "creation_time": "2015-09-29T21:46:06.000+0000",
        "bug_report": {
            "Title": "groupby11.q failing on branch-1.0",
            "Description": "The execution of the query 'groupby11.q' on the branch-1.0 branch results in a ClassCastException. The error indicates that a String type is being incorrectly cast to an org.apache.hadoop.io.Text type, which is not allowed. This issue arises during the fetching of results from the Hive query execution, specifically when processing the output of the query.",
            "StackTrace": [
                "2015-09-29 14:27:51,676 ERROR CliDriver (SessionState.java:printError(833)) - Failed with exception java.io.IOException:org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassCastException: java.lang.String cannot be cast to org.apache.hadoop.io.Text",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:154)",
                "at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1621)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:221)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:153)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:364)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:299)",
                "at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:832)",
                "at org.apache.hadoop.hive.cli.TestCliDriver.runTest(TestCliDriver.java:136)",
                "at org.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby11(TestCliDriver.java:120)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassCastException: java.lang.String cannot be cast to org.apache.hadoop.io.Text",
                "at org.apache.hadoop.hive.ql.exec.ListSinkOperator.processOp(ListSinkOperator.java:90)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)",
                "at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:85)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)",
                "at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:572)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:564)",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:140)"
            ],
            "RootCause": "The root cause of the issue is a ClassCastException occurring when the system attempts to cast a String object to a Text object in the WritableStringObjectInspector.getPrimitiveWritableObject method. This indicates a mismatch in expected data types during serialization or deserialization of query results.",
            "StepsToReproduce": [
                "1. Checkout the branch-1.0.",
                "2. Execute the query 'groupby11.q'.",
                "3. Observe the error in the logs."
            ],
            "ExpectedBehavior": "The query should execute successfully and return the expected results without any exceptions.",
            "ObservedBehavior": "The query execution fails with a ClassCastException indicating that a String cannot be cast to org.apache.hadoop.io.Text.",
            "Suggestions": "Review the data types being used in the query and ensure that they match the expected types in the Hive schema. Additionally, check the serialization logic in the LazySimpleSerDe and WritableStringObjectInspector to ensure proper handling of String types.",
            "problem_location": {
                "files": [
                    "FetchTask.java",
                    "WritableStringObjectInspector.java",
                    "LazySimpleSerDe.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.FetchTask",
                    "org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector",
                    "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"
                ],
                "methods": [
                    "FetchTask.fetch",
                    "WritableStringObjectInspector.getPrimitiveWritableObject",
                    "LazySimpleSerDe.doSerialize"
                ]
            },
            "possible_fix": "In the WritableStringObjectInspector.getPrimitiveWritableObject method, ensure that the object being passed is of the correct type before casting. Additionally, review the serialization logic in LazySimpleSerDe to ensure that it correctly handles String types and converts them to Text objects as needed."
        }
    },
    {
        "filename": "HIVE-17900.json",
        "creation_time": "2017-10-25T17:12:42.000+0000",
        "bug_report": {
            "Title": "Malformed SQL Generation in Compactor for Tables with Multiple Partition Columns",
            "Description": "The issue arises when analyzing statistics on tables with more than one partition column, specifically when the SQL generated by the Compactor is malformed. The error message indicates a parse exception due to a mismatched input near a partition column value, which suggests that the SQL syntax is incorrect when multiple partition columns are involved.",
            "StackTrace": [
                "2017-10-16 09:01:51,255 ERROR [haddl0007.mycenterpointenergy.com-51]: ql.Driver (SessionState.java:printError(993)) - FAILED: ParseException line 1:70 mismatched input 'dates' expecting ) near ''201608'' in analyze statement",
                "org.apache.hadoop.hive.ql.parse.ParseException: line 1:70 mismatched input 'dates' expecting ) near ''201608'' in analyze statement",
                "at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:205)",
                "at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:438)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:321)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1221)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1262)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1158)",
                "at org.apache.hadoop.hive.ql.txn.compactor.Worker$StatsUpdater.gatherStats(Worker.java:294)",
                "at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR.run(CompactorMR.java:265)",
                "at org.apache.hadoop.hive.ql.txn.compactor.Worker.run(Worker.java:168)"
            ],
            "RootCause": "The root cause of the issue is a parse exception triggered by the SQL syntax generated for analyzing statistics on tables with multiple partition columns. The SQL statement fails due to incorrect handling of partition column names and values, particularly when they are included in the generated SQL query.",
            "StepsToReproduce": [
                "Create a Hive table with multiple partition columns.",
                "Insert data into the table.",
                "Run the analyze command on the table to gather statistics."
            ],
            "ExpectedBehavior": "The system should successfully generate and execute a valid SQL statement to analyze the statistics of the table without any parse exceptions.",
            "ObservedBehavior": "The system throws a ParseException indicating a mismatched input error in the generated SQL statement when analyzing the table with multiple partition columns.",
            "Suggestions": "Review the SQL generation logic in the Compactor to ensure that it correctly formats partition column names and values. Implement additional validation to handle cases with multiple partition columns appropriately.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/Driver.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/ParseDriver.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.Driver",
                    "org.apache.hadoop.hive.ql.parse.ParseDriver",
                    "org.apache.hadoop.hive.ql.txn.compactor.Worker",
                    "org.apache.hadoop.hive.ql.txn.compactor.CompactorMR"
                ],
                "methods": [
                    "Driver.compileInternal",
                    "Driver.runInternal",
                    "ParseDriver.parse",
                    "Worker$StatsUpdater.gatherStats",
                    "CompactorMR.run"
                ]
            },
            "possible_fix": "Modify the SQL generation logic in the Compactor to ensure that partition column names are properly escaped and formatted. For example, ensure that partition values are enclosed in quotes and that the SQL syntax adheres to Hive's requirements for multiple partition columns."
        }
    },
    {
        "filename": "HIVE-10816.json",
        "creation_time": "2015-05-25T08:08:37.000+0000",
        "bug_report": {
            "Title": "NPE in ExecDriver::handleSampling when submitted via child JVM",
            "Description": "A NullPointerException (NPE) occurs in the `handleSampling` method of the `ExecDriver` class when the Hive configuration `hive.exec.submitviachild` is set to true. This issue arises during parallel order by operations, causing the system to fall back to single-reducer mode. The NPE is likely due to an uninitialized or null reference in the `mWork` object, particularly when accessing its properties such as `getAliasToWork()` or `getAliases()`.",
            "StackTrace": [
                "2015-05-25 08:41:04,446 ERROR [main]: mr.ExecDriver (ExecDriver.java:execute(386)) - Sampling error",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.handleSampling(ExecDriver.java:513)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:379)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.main(ExecDriver.java:750)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:497)",
                "at org.apache.hadoop.util.RunJar.run(RunJar.java:221)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:136)"
            ],
            "RootCause": "The root cause of the NPE is likely due to the `mWork` object being improperly initialized or not containing the expected data when `handleSampling` is called. Specifically, the method attempts to access the first alias from `mWork.getAliases()`, which may return null if `mWork` is not set up correctly.",
            "StepsToReproduce": [
                "Set the Hive configuration property `hive.exec.submitviachild` to true.",
                "Execute a parallel order by operation that triggers the sampling process.",
                "Observe the logs for the NPE in the `handleSampling` method."
            ],
            "ExpectedBehavior": "The system should handle sampling without throwing a NullPointerException, allowing the parallel order by operation to complete successfully.",
            "ObservedBehavior": "The system throws a NullPointerException in the `handleSampling` method, causing it to fall back to single-reducer mode.",
            "Suggestions": "Ensure that the `mWork` object is properly initialized and contains valid data before calling `handleSampling`. Add null checks for `mWork` and its properties to prevent NPEs.",
            "problem_location": {
                "files": [
                    "ExecDriver.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.ExecDriver"
                ],
                "methods": [
                    "ExecDriver.handleSampling",
                    "ExecDriver.execute"
                ]
            },
            "possible_fix": "Add null checks in the `handleSampling` method to ensure that `mWork` and its properties are not null before accessing them. For example:\n\n```java\nif (mWork == null || mWork.getAliases() == null || mWork.getAliases().isEmpty()) {\n    throw new IllegalStateException(\"MapWork is not properly initialized.\");\n}\n```"
        }
    },
    {
        "filename": "HIVE-13017.json",
        "creation_time": "2016-02-05T23:40:09.000+0000",
        "bug_report": {
            "Title": "Child process of HiveServer2 fails to get delegation token from non-default FileSystem",
            "Description": "When executing a Hive query that involves temporary tables and joins, the child process of HiveServer2 fails to obtain a delegation token from the non-default Azure Filesystem, resulting in an execution error. This issue arises specifically when HDFS is used for intermediate data while Azure Filesystem is set as the default file system. The error manifests as an exit status of 2 from the MapredLocalTask, indicating a failure in processing the query.",
            "StackTrace": [
                "org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:315)",
                "org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:156)",
                "org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:71)",
                "org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:206)",
                "java.security.AccessController.doPrivileged(Native Method)",
                "javax.security.auth.Subject.doAs(Subject.java:415)",
                "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)",
                "org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:218)",
                "java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is that the child process launched by HiveServer2 to handle the MapReduce task is unable to obtain the necessary delegation tokens from the Azure Filesystem, which is set as the default filesystem. This prevents the task from executing successfully, leading to the observed execution error.",
            "StepsToReproduce": [
                "Set Azure Filesystem as the default filesystem.",
                "Create temporary tables using Hive queries.",
                "Execute a query that involves joining these temporary tables with other tables.",
                "Observe the execution failure with exit status 2."
            ],
            "ExpectedBehavior": "The query should execute successfully, with the child process obtaining the necessary delegation tokens from the appropriate filesystem, allowing for the processing of the data as intended.",
            "ObservedBehavior": "The query fails with an execution error, specifically an exit status of 2 from the MapredLocalTask, indicating that the child process could not obtain the required delegation token.",
            "Suggestions": "Review the configuration for delegation token retrieval in the HiveServer2 setup. Ensure that the necessary permissions and configurations are in place for the child process to access both the Azure Filesystem and HDFS. Consider modifying the code in SecureCmdDoAs.java to handle delegation token requests for all filesystem URIs listed under mapreduce.job.hdfs-servers.",
            "problem_location": {
                "files": [
                    "service/src/java/org/apache/hive/service/cli/operation/Operation.java",
                    "service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java"
                ],
                "classes": [
                    "org.apache.hive.service.cli.operation.Operation",
                    "org.apache.hive.service.cli.operation.SQLOperation"
                ],
                "methods": [
                    "Operation.toSQLException",
                    "SQLOperation.runQuery"
                ]
            },
            "possible_fix": "Modify the SecureCmdDoAs.java file to ensure that the child process can obtain delegation tokens from all filesystem URIs specified in the mapreduce.job.hdfs-servers configuration. This may involve adding logic to check for the default filesystem and retrieve tokens accordingly."
        }
    },
    {
        "filename": "HIVE-11303.json",
        "creation_time": "2015-07-18T01:31:02.000+0000",
        "bug_report": {
            "Title": "Getting Tez LimitExceededException after dag execution on large query",
            "Description": "The system encounters a LimitExceededException during the execution of a Tez DAG when processing a large query. The exception indicates that the number of counters exceeded the maximum allowed limit of 1200, resulting in a failure to execute the Tez graph. This issue arises when the query generates more counters than the configured limit, which is not suitable for the scale of the data being processed.",
            "StackTrace": [
                "org.apache.tez.common.counters.LimitExceededException: Too many counters: 1201 max=1200",
                "at org.apache.tez.common.counters.Limits.checkCounters(Limits.java:87)",
                "at org.apache.tez.common.counters.Limits.incrCounters(Limits.java:94)",
                "at org.apache.tez.common.counters.AbstractCounterGroup.addCounter(AbstractCounterGroup.java:76)",
                "at org.apache.tez.common.counters.AbstractCounterGroup.addCounterImpl(AbstractCounterGroup.java:93)",
                "at org.apache.tez.common.counters.AbstractCounterGroup.findCounter(AbstractCounterGroup.java:104)",
                "at org.apache.tez.dag.api.DagTypeConverters.convertTezCountersFromProto(DagTypeConverters.java:567)",
                "at org.apache.tez.dag.api.client.DAGStatus.getDAGCounters(DAGStatus.java:148)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:175)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)"
            ],
            "RootCause": "The root cause of the issue is that the query execution generates more counters than the maximum limit set in the Tez configuration. The current limit is set to 1200, but the execution attempts to increment the counter to 1201, leading to a LimitExceededException.",
            "StepsToReproduce": [
                "1. Execute a large query that generates a significant number of counters.",
                "2. Monitor the execution to observe the counter increments.",
                "3. Observe the LimitExceededException being thrown during the execution."
            ],
            "ExpectedBehavior": "The system should handle the execution of large queries without exceeding the counter limits, either by aggregating counters or by increasing the limit appropriately.",
            "ObservedBehavior": "The system throws a LimitExceededException indicating that the number of counters has exceeded the maximum allowed limit of 1200.",
            "Suggestions": "Consider increasing the maximum counter limit in the Tez configuration to accommodate larger queries. Alternatively, review the query to optimize the number of counters generated.",
            "problem_location": {
                "files": [
                    "Limits.java",
                    "TezTask.java"
                ],
                "classes": [
                    "org.apache.tez.common.counters.Limits",
                    "org.apache.hadoop.hive.ql.exec.tez.TezTask"
                ],
                "methods": [
                    "Limits.checkCounters",
                    "TezTask.execute"
                ]
            },
            "possible_fix": "Increase the maximum counter limit in the Tez configuration by modifying the relevant configuration settings, such as 'tez.counters.max' to a higher value (e.g., 2000) to accommodate larger queries."
        }
    },
    {
        "filename": "HIVE-5899.json",
        "creation_time": "2013-11-27T02:48:39.000+0000",
        "bug_report": {
            "Title": "NPE during explain extended with char/varchar columns",
            "Description": "A NullPointerException (NPE) occurs when executing 'explain extended' on a Hive table that contains char or varchar columns. This happens after running 'analyze table' on the same columns. The NPE is triggered when Hive attempts to annotate the operator tree with statistics, specifically when it tries to access column statistics that are not properly initialized or are missing.",
            "StackTrace": [
                "2013-11-26 01:53:06,682 ERROR ql.Driver (SessionState.java:printError(440)) - FAILED: NullPointerException null",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.metastore.api.ColumnStatisticsData.getFieldDesc(ColumnStatisticsData.java:367)",
                "at org.apache.hadoop.hive.metastore.api.ColumnStatisticsData.getStringStats(ColumnStatisticsData.java:444)",
                "at org.apache.hadoop.hive.ql.stats.StatsUtils.getColStatistics(StatsUtils.java:414)",
                "at org.apache.hadoop.hive.ql.stats.StatsUtils.getTableColumnStatsForColumn(StatsUtils.java:369)",
                "at org.apache.hadoop.hive.ql.stats.StatsUtils.getTableColumnStats(StatsUtils.java:465)",
                "at org.apache.hadoop.hive.ql.stats.StatsUtils.collectStatistics(StatsUtils.java:109)",
                "at org.apache.hadoop.hive.ql.optimizer.stats.annotation.StatsRulesProcFactory$TableScanStatsRule.process(StatsRulesProcFactory.java:102)",
                "at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:94)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:78)",
                "at org.apache.hadoop.hive.ql.lib.PreOrderWalker.walk(PreOrderWalker.java:54)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:109)",
                "at org.apache.hadoop.hive.ql.optimizer.stats.annotation.AnnotateWithStatistics.transform(AnnotateWithStatistics.java:76)",
                "at org.apache.hadoop.hive.ql.optimizer.Optimizer.optimize(Optimizer.java:136)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:8913)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:292)",
                "at org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer.analyzeInternal(ExplainSemanticAnalyzer.java:65)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:292)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:441)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:341)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:994)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:905)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:268)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:220)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:422)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:790)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:684)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:212)"
            ],
            "RootCause": "The root cause of the NullPointerException is that the column statistics for char/varchar columns are not being properly initialized or retrieved, leading to a null reference when the system attempts to access the statistics data.",
            "StepsToReproduce": [
                "1. Run 'analyze table <table_name> for columns with char/varchar columns'.",
                "2. Execute 'explain extended <query>' on the same table."
            ],
            "ExpectedBehavior": "The system should successfully execute 'explain extended' without throwing a NullPointerException, providing the expected output of the query plan.",
            "ObservedBehavior": "A NullPointerException is thrown, causing the explain command to fail.",
            "Suggestions": "Ensure that column statistics for char/varchar columns are correctly initialized and retrieved before they are accessed. This may involve adding null checks or ensuring that the statistics are populated during the analyze phase.",
            "problem_location": {
                "files": [
                    "ColumnStatisticsData.java",
                    "StatsUtils.java",
                    "BaseSemanticAnalyzer.java",
                    "ExplainSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.api.ColumnStatisticsData",
                    "org.apache.hadoop.hive.ql.stats.StatsUtils",
                    "org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer"
                ],
                "methods": [
                    "ColumnStatisticsData.getFieldDesc",
                    "ColumnStatisticsData.getStringStats",
                    "StatsUtils.getColStatistics",
                    "StatsUtils.getTableColumnStatsForColumn",
                    "StatsUtils.getTableColumnStats",
                    "BaseSemanticAnalyzer.analyzeInternal",
                    "ExplainSemanticAnalyzer.analyzeInternal"
                ]
            },
            "possible_fix": "In the method 'getColStatistics' of StatsUtils, add checks to ensure that the 'ColumnStatisticsData' object is not null before accessing its methods. Additionally, ensure that the statistics are properly populated during the analyze phase for char/varchar columns."
        }
    },
    {
        "filename": "HIVE-11102.json",
        "creation_time": "2015-06-24T22:54:55.000+0000",
        "bug_report": {
            "Title": "ReaderImpl: getColumnIndicesFromNames does not work for some cases",
            "Description": "The ORC reader implementation fails to correctly estimate the size of ACID data files due to an IndexOutOfBoundsException. This occurs when the method getColumnIndicesFromNames is called with a list of column names that do not correspond to any existing fields in the ORC file's footer. Specifically, when the footer's types list is empty or when the requested column names do not match any field names, the method attempts to access an index in an empty list, leading to the exception.",
            "StackTrace": [
                "Caused by: java.lang.IndexOutOfBoundsException: Index: 0",
                "at java.util.Collections$EmptyList.get(Collections.java:3212)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcProto$Type.getSubtypes(OrcProto.java:12240)",
                "at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.getColumnIndicesFromNames(ReaderImpl.java:651)",
                "at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.getRawDataSizeOfColumns(ReaderImpl.java:634)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.populateAndCacheStripeDetails(OrcInputFormat.java:938)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:847)",
                "at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:713)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:744)"
            ],
            "RootCause": "The root cause of the issue is that the method getColumnIndicesFromNames attempts to access subtypes of a Type object without checking if the list of types is empty, leading to an IndexOutOfBoundsException when the footer's types list is empty.",
            "StepsToReproduce": [
                "Create an ORC file with no columns or an empty footer.",
                "Attempt to read the column indices using getColumnIndicesFromNames with a list of column names that do not exist in the ORC file."
            ],
            "ExpectedBehavior": "The system should handle cases where the column names do not exist or when the footer's types list is empty gracefully, returning an empty list or throwing a controlled exception.",
            "ObservedBehavior": "The system throws an IndexOutOfBoundsException when trying to access an index in an empty list.",
            "Suggestions": "Implement a check in the getColumnIndicesFromNames method to ensure that the types list is not empty before attempting to access its elements. If it is empty, return an empty list or throw a more informative exception.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/io/orc/ReaderImpl.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.io.orc.ReaderImpl",
                    "org.apache.hadoop.hive.ql.io.orc.OrcProto$Type"
                ],
                "methods": [
                    "ReaderImpl.getColumnIndicesFromNames",
                    "OrcProto$Type.getSubtypes"
                ]
            },
            "possible_fix": "In the method getColumnIndicesFromNames, add a check for the types list before accessing it:\n\nif (footer.getTypesList().isEmpty()) {\n    return Collections.emptyList();\n}\n\nThis will prevent the IndexOutOfBoundsException and allow the method to return an empty list when there are no types available."
        }
    },
    {
        "filename": "HIVE-9195.json",
        "creation_time": "2014-12-23T01:08:45.000+0000",
        "bug_report": {
            "Title": "CBO changes constant to column type",
            "Description": "During the execution of a query involving the percentile_approx function, the Cost-Based Optimizer (CBO) incorrectly transforms a constant expression into a column expression. This issue arises specifically in test mode, leading to an argument type exception when the UDAF evaluator is created, as it expects a constant object inspector for the second argument. The error occurs when the query attempts to evaluate a percentile approximation with a non-constant second argument.",
            "StackTrace": [
                "2014-12-22 17:03:31,433 ERROR parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10102)) - CBO failed, skipping CBO.",
                "org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException: The second argument must be a constant, but double was passed instead.",
                "at org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox.getEvaluator(GenericUDAFPercentileApprox.java:146)",
                "at org.apache.hadoop.hive.ql.exec.FunctionRegistry.getGenericUDAFEvaluator(FunctionRegistry.java:1160)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.getGenericUDAFEvaluator(SemanticAnalyzer.java:3794)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genGroupByPlanMapGroupByOperator(SemanticAnalyzer.java:4467)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:8884)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9745)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10086)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:224)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:419)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1044)"
            ],
            "RootCause": "The root cause of the issue is that the CBO is incorrectly transforming a constant expression into a column expression, which leads to the UDAF evaluator receiving a non-constant argument type. Specifically, the second argument of the percentile_approx function is expected to be a constant, but it is being passed as a double type instead.",
            "StepsToReproduce": [
                "Create a table with a double key and a string value.",
                "Load data into the table from local files.",
                "Execute a query using the percentile_approx function with a case statement that includes a constant expression."
            ],
            "ExpectedBehavior": "The query should execute successfully, returning the expected percentile approximation without any errors related to argument types.",
            "ObservedBehavior": "The query fails with an argument type exception indicating that the second argument must be a constant, but a double was passed instead.",
            "Suggestions": "Review the CBO logic to ensure that constant expressions are not transformed into column expressions. Additionally, validate the argument types before passing them to the UDAF evaluator.",
            "problem_location": {
                "files": [
                    "SemanticAnalyzer.java",
                    "FunctionRegistry.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.SemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.exec.FunctionRegistry"
                ],
                "methods": [
                    "SemanticAnalyzer.analyzeInternal",
                    "FunctionRegistry.getGenericUDAFEvaluator"
                ]
            },
            "possible_fix": "In the SemanticAnalyzer class, modify the logic in the analyzeInternal method to prevent the transformation of constant expressions into column expressions when generating the plan for the percentile_approx function. Ensure that the second argument is validated as a constant before being passed to the UDAF evaluator."
        }
    },
    {
        "filename": "HIVE-11285.json",
        "creation_time": "2015-07-16T20:46:22.000+0000",
        "bug_report": {
            "Title": "ObjectInspector for partition columns in FetchOperator in SMBJoin causes exception",
            "Description": "The issue arises when executing a join operation between two tables, where one table is partitioned. A ClassCastException occurs due to an attempt to cast an IntWritable object to a Java Integer. This happens during the processing of rows in the SMBMapJoinOperator, specifically when fetching and processing rows from the partitioned table. The root of the problem lies in the handling of data types between the ObjectInspector and the expected Java types.",
            "StackTrace": [
                "2015-07-15 13:39:04,333 WARN main org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"key\":1,\"value\":\"One\"}",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:185)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"key\":1,\"value\":\"One\"}",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:503)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:176)",
                "... 8 more",
                "Caused by: java.lang.RuntimeException: Map local work failed",
                "at org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.fetchOneRow(SMBMapJoinOperator.java:569)",
                "at org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.fetchNextGroup(SMBMapJoinOperator.java:429)",
                "at org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.processOp(SMBMapJoinOperator.java:260)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)",
                "at org.apache.hadoop.hive.ql.exec.FilterOperator.processOp(FilterOperator.java:120)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)",
                "at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:157)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:493)",
                "... 9 more",
                "Caused by: java.lang.ClassCastException: org.apache.hadoop.io.IntWritable cannot be cast to java.lang.Integer",
                "at org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaIntObjectInspector.getPrimitiveWritableObject(JavaIntObjectInspector.java:35)",
                "at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.copyToStandardObject(ObjectInspectorUtils.java:305)",
                "at org.apache.hadoop.hive.ql.exec.JoinUtil.computeValues(JoinUtil.java:193)",
                "at org.apache.hadoop.hive.ql.exec.CommonJoinOperator.getFilteredValue(CommonJoinOperator.java:408)",
                "at org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.processOp(SMBMapJoinOperator.java:270)",
                "at org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator.fetchOneRow(SMBMapJoinOperator.java:558)",
                "... 17 more"
            ],
            "RootCause": "A ClassCastException occurs when the system attempts to cast an IntWritable object to a Java Integer, which is not allowed. This happens in the JavaIntObjectInspector when processing rows from the partitioned table.",
            "StepsToReproduce": [
                "Create a data file 'data.out' with the following content: '1|One\n2|Two'",
                "Create a Hive table 'data_table' with the specified schema.",
                "Load data into 'data_table' from 'data.out'.",
                "Create a partitioned table 'smb_table_part' with the specified schema.",
                "Insert data into 'smb_table_part' from 'data_table'.",
                "Set the necessary Hive configurations.",
                "Execute the join query between 'smb_table' and 'smb_table_part'."
            ],
            "ExpectedBehavior": "The join operation should execute successfully and return the expected results without any exceptions.",
            "ObservedBehavior": "A ClassCastException is thrown during the execution of the join operation, causing the process to fail.",
            "Suggestions": "Ensure that the data types being processed are compatible. Modify the ObjectInspector to handle IntWritable correctly or adjust the data types in the Hive schema to avoid casting issues.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaIntObjectInspector.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaIntObjectInspector",
                    "org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator",
                    "org.apache.hadoop.hive.ql.exec.MapOperator"
                ],
                "methods": [
                    "JavaIntObjectInspector.getPrimitiveWritableObject",
                    "SMBMapJoinOperator.fetchOneRow",
                    "MapOperator.process"
                ]
            },
            "possible_fix": "Modify the JavaIntObjectInspector to ensure that it correctly handles IntWritable objects. For example, update the getPrimitiveWritableObject method to check the type before casting, or ensure that the data being processed is converted to the expected type before reaching this point."
        }
    },
    {
        "filename": "HIVE-10288.json",
        "creation_time": "2015-04-09T23:24:16.000+0000",
        "bug_report": {
            "Title": "Cannot call permanent UDFs",
            "Description": "After registering a permanent User Defined Function (UDF) in Hive, subsequent calls to the UDF fail with a NullPointerException if the Hive CLI is exited and reopened. This issue does not occur when the UDF is called immediately after registration, nor does it occur in the Apache Hive 1.0.0 release. The problem seems to stem from the handling of UDF metadata or state persistence across sessions.",
            "StackTrace": [
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc.newInstance(ExprNodeGenericFuncDesc.java:232)",
                "at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.getXpathOrFuncExprNodeDesc(TypeCheckProcFactory.java:1048)",
                "at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor.process(TypeCheckProcFactory.java:1265)",
                "at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:95)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.walk(DefaultGraphWalker.java:133)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:110)",
                "at org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory.genExprNode(TypeCheckProcFactory.java:205)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genExprNodeDesc(SemanticAnalyzer.java:10338)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genSelectPlan(SemanticAnalyzer.java:3815)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genBodyPlan(SemanticAnalyzer.java:8819)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genPlan(SemanticAnalyzer.java:9663)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:424)"
            ],
            "RootCause": "The NullPointerException occurs when the system attempts to create a new instance of ExprNodeGenericFuncDesc for the UDF after the Hive CLI has been restarted. This suggests that the UDF's metadata or state is not being properly retained or reinitialized after the session ends.",
            "StepsToReproduce": [
                "1. Register a permanent UDF in Hive CLI.",
                "2. Exit the Hive CLI.",
                "3. Reopen the Hive CLI.",
                "4. Attempt to call the registered UDF."
            ],
            "ExpectedBehavior": "The UDF should be callable after reopening the Hive CLI without any errors.",
            "ObservedBehavior": "A NullPointerException is thrown when attempting to call the UDF after reopening the Hive CLI.",
            "Suggestions": "Investigate the UDF registration and metadata persistence mechanisms in Hive. Ensure that the UDF's state is correctly restored when the CLI is reopened. Consider adding checks to handle cases where the UDF metadata may not be available.",
            "problem_location": {
                "files": [
                    "ExprNodeGenericFuncDesc.java",
                    "TypeCheckProcFactory.java",
                    "SemanticAnalyzer.java",
                    "Driver.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc",
                    "org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory",
                    "org.apache.hadoop.hive.ql.parse.SemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.Driver"
                ],
                "methods": [
                    "ExprNodeGenericFuncDesc.newInstance",
                    "TypeCheckProcFactory$DefaultExprProcessor.getXpathOrFuncExprNodeDesc",
                    "SemanticAnalyzer.genExprNodeDesc",
                    "Driver.compile"
                ]
            },
            "possible_fix": "Ensure that the UDF's metadata is correctly stored and retrieved across sessions. This may involve modifying the UDF registration process to include session persistence logic or adjusting how the UDF's state is managed in the Hive context."
        }
    },
    {
        "filename": "HIVE-8771.json",
        "creation_time": "2014-11-07T00:30:25.000+0000",
        "bug_report": {
            "Title": "Abstract merge file operator does not move/rename incompatible files correctly",
            "Description": "The AbstractFileMergeOperator is failing to move incompatible files to the final destination due to an IOException caused by the destination path being a file instead of a directory. This issue arises specifically when the merge operation attempts to rename or move files, leading to a failure in the orc_merge_incompat2.q test case under CentOS.",
            "StackTrace": [
                "2014-11-05 02:38:56,588 DEBUG fs.FileSystem (RawLocalFileSystem.java:rename(337)) - Falling through to a copy of file:/home/prasanth/hive/itests/qtest/target/warehouse/orc_merge5a/st=80.0/000000_0 to file:/home/prasanth/hive/itests/qtest/target/tmp/scratchdir/prasanth/0de64e52-6615-4c5a-bdfb-c3b2c28131f6/hive_2014-11-05_02-38-55_511_7578595409877157627-1/_tmp.-ext-10000/000000_0/000000_0",
                "2014-11-05 02:38:56,589 INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(456)) - map task executor complete.",
                "2014-11-05 02:38:56,590 WARN  mapred.LocalJobRunner (LocalJobRunner.java:run(560)) - job_local1144733438_0036",
                "java.lang.Exception: java.io.IOException: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to close AbstractFileMergeOperator",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)",
                "Caused by: java.io.IOException: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to close AbstractFileMergeOperator",
                "at org.apache.hadoop.hive.ql.io.merge.MergeFileMapper.close(MergeFileMapper.java:100)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:166)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:679)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to close AbstractFileMergeOperator",
                "at org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.closeOp(AbstractFileMergeOperator.java:233)",
                "at org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator.closeOp(OrcFileMergeOperator.java:220)",
                "at org.apache.hadoop.hive.ql.io.merge.MergeFileMapper.close(MergeFileMapper.java:98)",
                "... 10 more",
                "Caused by: java.io.FileNotFoundException: Destination exists and is not a directory: /home/prasanth/hive/itests/qtest/target/tmp/scratchdir/prasanth/0de64e52-6615-4c5a-bdfb-c3b2c28131f6/hive_2014-11-05_02-38-55_511_7578595409877157627-1/_tmp.-ext-10000/000000_0",
                "at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:423)",
                "at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:267)",
                "at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:257)",
                "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:887)",
                "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:784)",
                "at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:365)",
                "at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:338)",
                "at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289)",
                "at org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:339)",
                "at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:507)",
                "at org.apache.hadoop.fs.FilterFileSystem.rename(FilterFileSystem.java:214)",
                "at org.apache.hadoop.fs.ProxyFileSystem.rename(FilterFileSystem.java:177)",
                "at org.apache.hadoop.fs.FilterFileSystem.rename(FilterFileSystem.java:214)",
                "at org.apache.hadoop.hive.ql.exec.Utilities.renameOrMoveFiles(Utilities.java:1589)",
                "at org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator.closeOp(AbstractFileMergeOperator.java:218)",
                "... 12 more"
            ],
            "RootCause": "The root cause of the issue is that the destination path for moving incompatible files is a file instead of a directory, which leads to a FileNotFoundException when the system attempts to create a directory at that path.",
            "StepsToReproduce": [
                "Run the orc_merge_incompat2.q test case under CentOS.",
                "Ensure that the destination path for incompatible files is a file.",
                "Observe the IOException thrown during the merge operation."
            ],
            "ExpectedBehavior": "The AbstractFileMergeOperator should successfully move incompatible files to the specified final destination directory without throwing an IOException.",
            "ObservedBehavior": "The system throws an IOException indicating that the destination exists and is not a directory, causing the merge operation to fail.",
            "Suggestions": "Ensure that the destination path for incompatible files is a directory before attempting to move files. Implement checks to verify the path type before executing the move operation.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/AbstractFileMergeOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/merge/MergeFileMapper.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.AbstractFileMergeOperator",
                    "org.apache.hadoop.hive.ql.io.merge.MergeFileMapper"
                ],
                "methods": [
                    "AbstractFileMergeOperator.closeOp",
                    "MergeFileMapper.close"
                ]
            },
            "possible_fix": "In the AbstractFileMergeOperator.closeOp method, add a check to ensure that the destination path is a directory before attempting to move incompatible files. If the destination path is a file, either rename it or delete it before proceeding with the move operation."
        }
    },
    {
        "filename": "HIVE-8008.json",
        "creation_time": "2014-09-05T23:00:11.000+0000",
        "bug_report": {
            "Title": "NPE while reading null decimal value",
            "Description": "The application encounters a NullPointerException (NPE) when attempting to read a decimal value from the `dec_test` table that contains a row with a decimal value of 9999999999.5. This issue arises during the execution of a SELECT query, specifically when the system attempts to serialize the decimal value. The NPE occurs in the `LazyUtils.writePrimitiveUTF8` method, which is called during the serialization process of the decimal type, indicating that the method is not handling null values correctly.",
            "StackTrace": [
                "2014-09-05 14:08:56,023 ERROR [main]: CliDriver (SessionState.java:printError(545)) - Failed with exception java.io.IOException:org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:151)",
                "at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1531)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:285)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:220)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:423)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:792)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:686)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:625)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.ListSinkOperator.processOp(ListSinkOperator.java:90)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796)",
                "at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:87)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:796)",
                "at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:92)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:544)",
                "at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:536)",
                "at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:137)",
                "... 12 more",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.serde2.lazy.LazyUtils.writePrimitiveUTF8(LazyUtils.java:265)",
                "at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serialize(LazySimpleSerDe.java:486)",
                "at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serializeField(LazySimpleSerDe.java:439)",
                "at org.apache.hadoop.hive.serde2.DelimitedJSONSerDe.serializeField(DelimitedJSONSerDe.java:71)",
                "at org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe.serialize(LazySimpleSerDe.java:423)",
                "at org.apache.hadoop.hive.ql.exec.DefaultFetchFormatter.convert(DefaultFetchFormatter.java:70)",
                "at org.apache.hadoop.hive.ql.exec.DefaultFetchFormatter.convert(DefaultFetchFormatter.java:39)",
                "at org.apache.hadoop.hive.ql.exec.ListSinkOperator.processOp(ListSinkOperator.java:87)",
                "... 19 more"
            ],
            "RootCause": "The root cause of the NullPointerException is that the `LazyUtils.writePrimitiveUTF8` method does not handle null values for decimal types correctly, leading to an attempt to dereference a null object.",
            "StepsToReproduce": [
                "Create a table named `dec_test` with a decimal column.",
                "Insert a row with a decimal value of 9999999999.5.",
                "Execute the query: `SELECT * FROM dec_test;`."
            ],
            "ExpectedBehavior": "The system should return the decimal value without errors, even if it is null.",
            "ObservedBehavior": "The system crashes with a NullPointerException when attempting to serialize the decimal value.",
            "Suggestions": "Implement null checks in the `LazyUtils.writePrimitiveUTF8` method to handle null decimal values gracefully. Additionally, ensure that the serialization methods for decimal types are robust against null inputs.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java",
                    "ql/src/java/org/apache/hadoop/hive/serde2/lazy/LazySimpleSerDe.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/ListSinkOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.serde2.lazy.LazyUtils",
                    "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe",
                    "org.apache.hadoop.hive.ql.exec.ListSinkOperator"
                ],
                "methods": [
                    "LazyUtils.writePrimitiveUTF8",
                    "LazySimpleSerDe.serialize",
                    "ListSinkOperator.processOp"
                ]
            },
            "possible_fix": "In the `LazyUtils.writePrimitiveUTF8` method, add a check for null values before attempting to write the decimal value. For example:\n\n```java\nif (o == null) {\n    out.write(nullSequence.getBytes(), 0, nullSequence.getLength());\n    return;\n}\n```"
        }
    },
    {
        "filename": "HIVE-6915.json",
        "creation_time": "2014-04-15T20:20:15.000+0000",
        "bug_report": {
            "Title": "Hive HBase queries fail on secure Tez cluster",
            "Description": "Hive queries that read from and write to HBase are failing in a secure Tez cluster due to SASL authentication issues. The error indicates that the client is unable to provide valid Kerberos credentials, which is necessary for secure communication with HBase. The stack trace shows that the failure occurs during the SASL connection setup, specifically when attempting to obtain a Kerberos ticket-granting ticket (TGT). This issue does not occur when switching the execution engine to MapReduce (MR).",
            "StackTrace": [
                "2014-04-14 13:47:05,644 FATAL [InputInitializer [Map 1] #0] org.apache.hadoop.ipc.RpcClient: SASL authentication failed. The most likely cause is missing or invalid credentials. Consider 'kinit'.",
                "javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]",
                "at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212)",
                "at org.apache.hadoop.hbase.security.HBaseSaslRpcClient.saslConnect(HBaseSaslRpcClient.java:152)",
                "at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupSaslConnection(RpcClient.java:792)",
                "at org.apache.hadoop.hbase.ipc.RpcClient$Connection.access$800(RpcClient.java:349)",
                "at org.apache.hadoop.hbase.ipc.RpcClient$Connection$2.run(RpcClient.java:918)",
                "at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1474)",
                "at org.apache.hadoop.hbase.ipc.RegionCoprocessorRpcChannel.callBlockingMethod(RegionCoprocessorRpcChannel.java:67)",
                "at org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat.getSplits(HiveHBaseTableInputFormat.java:415)"
            ],
            "RootCause": "The root cause of the issue is the failure to obtain valid Kerberos credentials, which is necessary for SASL authentication in a secure Tez cluster. The error message indicates that the client has not successfully acquired a Kerberos ticket-granting ticket (TGT).",
            "StepsToReproduce": [
                "1. Configure a secure Tez cluster with Hive and HBase.",
                "2. Attempt to run Hive queries that read from or write to HBase.",
                "3. Observe the failure in the Tez application logs indicating SASL authentication failure."
            ],
            "ExpectedBehavior": "Hive queries should successfully read from and write to HBase in a secure Tez cluster without authentication errors.",
            "ObservedBehavior": "Hive queries fail with a SASL authentication error due to missing or invalid Kerberos credentials.",
            "Suggestions": "Ensure that the client has valid Kerberos credentials before executing Hive queries. This can be done by running 'kinit' to obtain a TGT. Additionally, verify that the Kerberos configuration is correctly set up in the environment.",
            "problem_location": {
                "files": [
                    "hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat",
                    "org.apache.hadoop.hive.ql.io.HiveInputFormat"
                ],
                "methods": [
                    "HiveHBaseTableInputFormat.getSplits",
                    "HiveInputFormat.getSplits"
                ]
            },
            "possible_fix": "Ensure that the client environment is properly configured for Kerberos authentication. This includes running 'kinit' to obtain a valid TGT before executing Hive queries. Additionally, check the configuration files for any misconfigurations related to Kerberos."
        }
    },
    {
        "filename": "HIVE-12364.json",
        "creation_time": "2015-11-07T02:04:25.000+0000",
        "bug_report": {
            "Title": "Distcp job fails when run under Tez",
            "Description": "The issue arises when executing a Hive query that involves moving data to a specified directory using the DistCp process. The job fails due to an incompatibility between the input format class and the map compatibility mode when the execution engine is set to Tez. This is evident from the stack trace, which indicates that the DistCp process cannot be executed because of this incompatibility.",
            "StackTrace": [
                "org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://hdpsecehdfs/tmp/testindir/.hive-staging_hive_2015-11-05_15-59-44_557_1429894387987411483-1/-ext-10000 to destination /tmp/testindir",
                "at org.apache.hadoop.hive.ql.metadata.Hive.moveFile(Hive.java:2665)",
                "at org.apache.hadoop.hive.ql.exec.MoveTask.moveFile(MoveTask.java:105)",
                "at org.apache.hadoop.hive.ql.exec.MoveTask.execute(MoveTask.java:222)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:89)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1653)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1414)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1195)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)"
            ],
            "RootCause": "The root cause of the issue is that the DistCp process cannot be executed due to an incompatibility between the 'mapreduce.job.inputformat.class' and the map compatibility mode. This is triggered when the source file size exceeds the maximum allowed size set by 'hive.exec.copyfile.maxsize'.",
            "StepsToReproduce": [
                "Set the Hive configuration parameter 'hive.exec.copyfile.maxsize' to a value lower than the size of the source file.",
                "Run a Hive query that involves inserting data into a directory using the 'insert overwrite' command.",
                "Observe the failure of the DistCp job during the move task."
            ],
            "ExpectedBehavior": "The DistCp job should successfully move the data from the temporary staging directory to the specified destination directory without any errors.",
            "ObservedBehavior": "The DistCp job fails with an error indicating that it cannot execute the process due to an incompatibility with the map compatibility mode.",
            "Suggestions": "Consider adjusting the 'hive.exec.copyfile.maxsize' parameter to a value that accommodates the size of the files being moved. Additionally, ensure that the input format class is compatible with the map compatibility mode.",
            "problem_location": {
                "files": [
                    "Driver.java",
                    "FileUtils.java",
                    "Hive.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.Driver",
                    "org.apache.hadoop.hive.common.FileUtils",
                    "org.apache.hadoop.hive.ql.metadata.Hive"
                ],
                "methods": [
                    "Driver.runInternal",
                    "FileUtils.copy",
                    "Hive.moveFile"
                ]
            },
            "possible_fix": "To resolve the issue, ensure that the 'mapreduce.job.inputformat.class' is compatible with the map compatibility mode. This may involve reviewing the configuration settings for the Hive job and adjusting the input format class accordingly. Additionally, consider implementing a check to prevent the DistCp process from being invoked if the file size exceeds the configured maximum size."
        }
    },
    {
        "filename": "HIVE-8766.json",
        "creation_time": "2014-11-06T22:08:43.000+0000",
        "bug_report": {
            "Title": "Hive RetryHMSHandler should be retrying the metastore operation in case of NucleusException",
            "Description": "The current implementation of the Hive metastore does not retry operations when a NucleusException occurs, particularly under conditions where the Metastore Database (SQL Server) is heavily loaded or experiences timeouts. This leads to failures in Hive queries that should otherwise be retried. The stack trace indicates that a connection reset occurs due to the database not returning a ResultSet in a timely manner, which is exacerbated by the lack of a retry mechanism in the HMSHandler. The proposed solution is to implement a retry mechanism for NucleusExceptions to enhance resilience against transient database issues.",
            "StackTrace": [
                "2014-11-04 06:40:03,208 ERROR bonecp.ConnectionHandle (ConnectionHandle.java:markPossiblyBroken(388)) - Database access problem. Killing off this connection and all remaining connections in the connection pool. SQL State = 08S01",
                "2014-11-04 06:40:03,213 ERROR DataNucleus.Transaction (Log4JLogger.java:error(115)) - Operation rollback failed on resource: org.datanucleus.store.rdbms.ConnectionFactoryImpl$EmulatedXAResource@1a35cc16, error code UNKNOWN and transaction: [DataNucleus Transaction, ID=Xid=   \ufffd, enlisted resources=[org.datanucleus.store.rdbms.ConnectionFactoryImpl$EmulatedXAResource@1a35cc16]]",
                "2014-11-04 06:40:03,217 ERROR metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(139)) - MetaException(message:org.datanucleus.exceptions.NucleusDataStoreException: Size request failed : SELECT COUNT(*) FROM SKEWED_VALUES THIS WHERE THIS.SD_ID_OID=? AND THIS.INTEGER_IDX>=0)",
                "Caused by: org.datanucleus.exceptions.NucleusDataStoreException: Size request failed : SELECT COUNT(*) FROM SKEWED_VALUES THIS WHERE THIS.SD_ID_OID=? AND THIS.INTEGER_IDX>=0",
                "Caused by: com.microsoft.sqlserver.jdbc.SQLServerException: SSL peer shut down incorrectly"
            ],
            "RootCause": "The root cause of the issue is the lack of a retry mechanism in the HMSHandler when a NucleusException occurs due to database connection issues, particularly when the SQL Server is overloaded or times out.",
            "StepsToReproduce": [
                "1. Configure SQL Server to have a low timeout setting.",
                "2. Execute a Hive query that requires a metastore operation.",
                "3. Observe the failure due to NucleusException when the database is under load."
            ],
            "ExpectedBehavior": "The Hive metastore should automatically retry the operation when a NucleusException occurs, allowing the query to succeed if the database recovers in time.",
            "ObservedBehavior": "The Hive query fails immediately with a NucleusException without any retries, leading to a poor user experience.",
            "Suggestions": "Implement a retry mechanism in the RetryingHMSHandler to handle NucleusExceptions gracefully. This could involve modifying the invoke method to catch NucleusExceptions and retry the operation a specified number of times before failing.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.RetryingHMSHandler",
                    "org.apache.hadoop.hive.metastore.ObjectStore"
                ],
                "methods": [
                    "RetryingHMSHandler.invoke",
                    "ObjectStore.getTable"
                ]
            },
            "possible_fix": "Modify the invoke method in RetryingHMSHandler to include a retry mechanism for NucleusExceptions. For example:\n\n```java\nint retriesMade = 0;\nwhile (retriesMade < retryLimit) {\n    try {\n        return method.invoke(baseHandler, args);\n    } catch (NucleusException e) {\n        retriesMade++;\n        if (retriesMade >= retryLimit) {\n            throw e;\n        }\n        Thread.sleep(retryDelay);\n    }\n}\n```"
        }
    },
    {
        "filename": "HIVE-5857.json",
        "creation_time": "2013-11-20T01:12:54.000+0000",
        "bug_report": {
            "Title": "Reduce tasks do not work in uber mode in YARN",
            "Description": "A Hive query fails when attempting to execute a reduce task in uber mode on YARN, resulting in a NullPointerException. This occurs in the ExecReducer.configure method due to the absence of the expected plan file (reduce.xml). The Utilities.getBaseWork method fails to return a BaseWork object because it encounters a FileNotFoundException, which is triggered by the LocalContainerLauncher switching the configuration to local mode before the reduce task runs. This configuration change leads to the plan file not being found, causing the subsequent NullPointerException.",
            "StackTrace": [
                "2013-11-20 00:50:56,862 INFO [uber-SubtaskRunner] org.apache.hadoop.hive.ql.exec.Utilities: No plan file found: hdfs://namenode.c.lon.spotify.net:54310/var/tmp/kawaa/hive_2013-11-20_00-50-43_888_3938384086824086680-2/-mr-10003/e3caacf6-15d6-4987-b186-d2906791b5b0/reduce.xml",
                "2013-11-20 00:50:56,862 WARN [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Exception running local (uberized) 'child' : java.lang.RuntimeException: Error in configuring object",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.configure(ExecReducer.java:116)",
                "Caused by: java.lang.reflect.InvocationTargetException",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)"
            ],
            "RootCause": "The root cause of the issue is that the configuration is switched to local mode before the reduce task runs, which prevents the Utilities.getBaseWork method from locating the required plan file (reduce.xml). This results in a NullPointerException when the ExecReducer.configure method attempts to access the BaseWork object.",
            "StepsToReproduce": [
                "1. Submit a Hive query that includes a reduce task.",
                "2. Ensure that the query is set to run in uber mode on YARN.",
                "3. Observe the logs for the NullPointerException and the missing plan file error."
            ],
            "ExpectedBehavior": "The reduce task should execute successfully in uber mode, with the necessary plan file being located and processed correctly.",
            "ObservedBehavior": "The reduce task fails with a NullPointerException due to the plan file not being found, as the configuration is incorrectly set to local mode.",
            "Suggestions": "Implement a check in the LocalContainerLauncher to prevent the configuration from switching to local mode when running reduce tasks in uber mode. Alternatively, modify the Utilities.getBaseWork method to handle the case where the plan file is not found more gracefully.",
            "problem_location": {
                "files": [
                    "org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java",
                    "org/apache/hadoop/mapred/LocalContainerLauncher.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.ExecReducer",
                    "org.apache.hadoop.mapred.LocalContainerLauncher"
                ],
                "methods": [
                    "ExecReducer.configure",
                    "LocalContainerLauncher.runSubtask"
                ]
            },
            "possible_fix": "Add a conditional check in the LocalContainerLauncher.runSubtask method to ensure that the configuration does not switch to local mode when executing a reduce task in uber mode. This could be implemented as follows:\n\nif (!isUberMode) {\n    conf.set(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\n    conf.set(MRConfig.MASTER_ADDRESS, \"local\");\n}\n\nThis will ensure that the configuration remains set to YARN for reduce tasks in uber mode, allowing the plan file to be found."
        }
    },
    {
        "filename": "HIVE-1547.json",
        "creation_time": "2010-08-17T02:09:54.000+0000",
        "bug_report": {
            "Title": "Unarchiving operation throws NPE",
            "Description": "The unarchiving operation for a partition in Hive is throwing a NullPointerException (NPE) when attempting to unarchive a partition. The stack trace indicates that the error occurs in the `unarchive` method of the `DDLTask` class, specifically when trying to access a partition that may not exist or is not properly initialized. This issue appears to be specific to the distributed file system (DFS) and does not occur in local file system tests.",
            "StackTrace": [
                "2010-08-16 12:44:18,801 ERROR exec.DDLTask (SessionState.java:printError(277)) - Failed with exception null",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.unarchive(DDLTask.java:729)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:195)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:108)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:55)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:609)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:478)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:356)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:140)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:199)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:351)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)",
                "at java.lang.reflect.Method.invoke(Method.java:597)",
                "at org.apache.hadoop.util.RunJar.main(RunJar.java:156)"
            ],
            "RootCause": "The root cause of the NullPointerException is likely due to the `getPartition` method returning null when the specified partition does not exist, which is not being handled properly in the `unarchive` method. This can occur if the partition specification provided is incorrect or if the partition has not been created in the Hive metastore.",
            "StepsToReproduce": [
                "1. Attempt to unarchive a partition in Hive using a command that specifies a partition that does not exist.",
                "2. Observe the NullPointerException thrown during the operation."
            ],
            "ExpectedBehavior": "The system should handle the case where the specified partition does not exist gracefully, providing a meaningful error message instead of throwing a NullPointerException.",
            "ObservedBehavior": "The system throws a NullPointerException when attempting to unarchive a partition that does not exist, leading to a failure in the operation.",
            "Suggestions": "Implement null checks for the partition object returned by `getPartition` in the `unarchive` method. Additionally, provide a more informative error message when the specified partition does not exist.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/TaskRunner.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.DDLTask",
                    "org.apache.hadoop.hive.ql.exec.Task",
                    "org.apache.hadoop.hive.ql.exec.TaskRunner"
                ],
                "methods": [
                    "DDLTask.unarchive",
                    "Task.executeTask",
                    "TaskRunner.runSequential"
                ]
            },
            "possible_fix": "In the `unarchive` method of `DDLTask`, add a null check after retrieving the partition:\n\n```java\nPartition p = db.getPartition(tbl, partSpec, false);\nif (p == null) {\n    throw new HiveException(\"Specified partition does not exist\");\n}\n```"
        }
    },
    {
        "filename": "HIVE-6113.json",
        "creation_time": "2013-12-27T07:07:00.000+0000",
        "bug_report": {
            "Title": "Upgrade DataNucleus [was: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient]",
            "Description": "The issue arises when executing the SQL command 'use fdm; desc formatted fdm.tableName;' in Python, which intermittently fails with a HiveException indicating an inability to instantiate the HiveMetaStoreClient. The error is caused by a duplicate entry for the 'default' database in the metastore, leading to a JDODataStoreException during the commit phase of the transaction. This suggests that the database creation logic is not handling existing databases correctly, resulting in a conflict when attempting to create a database that already exists.",
            "StackTrace": [
                "org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient",
                "at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1143)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1128)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.switchDatabase(DDLTask.java:3479)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:237)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1414)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1192)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1020)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)"
            ],
            "RootCause": "The root cause of the issue is a JDODataStoreException due to a duplicate entry for the 'default' database in the metastore, which occurs when the system attempts to create a database that already exists.",
            "StepsToReproduce": [
                "1. Execute the SQL command 'use fdm; desc formatted fdm.tableName;' in Python.",
                "2. Observe the error thrown during the first execution.",
                "3. Execute the command again and note that it succeeds."
            ],
            "ExpectedBehavior": "The command should execute successfully without throwing an error, regardless of whether the database already exists.",
            "ObservedBehavior": "The command fails with a HiveException indicating an inability to instantiate the HiveMetaStoreClient due to a duplicate entry for the 'default' database.",
            "Suggestions": "Implement a check to see if the database already exists before attempting to create it. This can be done by modifying the createDatabase method in the ObjectStore class to handle existing databases gracefully.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.ObjectStore",
                    "org.apache.hadoop.hive.ql.metadata.Hive"
                ],
                "methods": [
                    "ObjectStore.createDatabase",
                    "Hive.getDatabase",
                    "Hive.databaseExists"
                ]
            },
            "possible_fix": "Modify the createDatabase method in ObjectStore to check if the database already exists before attempting to create it. For example:\n\npublic void createDatabase(Database db) throws InvalidObjectException, MetaException {\n    if (databaseExists(db.getName())) {\n        throw new InvalidObjectException(\"Database already exists: \" + db.getName());\n    }\n    // existing logic to create the database\n}"
        }
    },
    {
        "filename": "HIVE-9570.json",
        "creation_time": "2015-02-03T23:30:09.000+0000",
        "bug_report": {
            "Title": "Investigate test failure on union_view.q [Spark Branch]",
            "Description": "The test for union_view.q is failing due to a NullPointerException occurring in the SparkCompiler's setInputFormat method. This exception is triggered when the method attempts to access properties of an operator that is not properly initialized, leading to a failure in the compilation process of the query. The stack trace indicates that the error propagates through several layers of the query processing pipeline, ultimately resulting in a failure to execute the query.",
            "StackTrace": [
                "2015-02-03 15:27:05,723 ERROR [main]: ql.Driver (SessionState.java:printError(861)) - FAILED: NullPointerException null",
                "java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.setInputFormat(SparkCompiler.java:274)",
                "at org.apache.hadoop.hive.ql.parse.spark.SparkCompiler.setInputFormat(SparkCompiler.java:253)",
                "at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:222)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10231)",
                "at org.apache.hadoop.hive.ql.parse.CalcitePlanner.analyzeInternal(CalcitePlanner.java:190)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:224)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:421)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:307)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1112)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1160)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1039)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:207)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:159)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:370)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:305)",
                "at org.apache.hadoop.hive.cli.TestSparkCliDriver.runTest(TestSparkCliDriver.java:136)",
                "at org.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_union_view(TestSparkCliDriver.java:120)"
            ],
            "RootCause": "The root cause of the NullPointerException is likely due to an uninitialized or improperly configured operator being passed to the setInputFormat method in the SparkCompiler class. This can occur if the query being analyzed does not have the necessary context or if the operator tree is not correctly built prior to this method being called.",
            "StepsToReproduce": [
                "Run the union_view.q test case in the Spark branch.",
                "Observe the stack trace for the NullPointerException."
            ],
            "ExpectedBehavior": "The union_view.q test should execute successfully without throwing any exceptions, and the query should return the expected results.",
            "ObservedBehavior": "The test fails with a NullPointerException, indicating that an operator in the query processing pipeline is not properly initialized.",
            "Suggestions": "Investigate the initialization of operators in the query processing pipeline, particularly in the context of the union_view.q query. Ensure that all necessary properties are set before invoking the setInputFormat method. Consider adding null checks or default initializations to prevent this exception from occurring.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkCompiler.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/TaskCompiler.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.spark.SparkCompiler",
                    "org.apache.hadoop.hive.ql.parse.TaskCompiler",
                    "org.apache.hadoop.hive.ql.parse.SemanticAnalyzer"
                ],
                "methods": [
                    "SparkCompiler.setInputFormat",
                    "TaskCompiler.compile",
                    "SemanticAnalyzer.analyzeInternal"
                ]
            },
            "possible_fix": "In the SparkCompiler class, add null checks for the operator before accessing its properties in the setInputFormat method. Additionally, ensure that the operator tree is correctly built and initialized in the TaskCompiler and SemanticAnalyzer classes before invoking the SparkCompiler methods."
        }
    },
    {
        "filename": "HIVE-1678.json",
        "creation_time": "2010-10-01T05:41:21.000+0000",
        "bug_report": {
            "Title": "NPE in MapJoin",
            "Description": "A NullPointerException (NPE) occurs during the execution of a query that involves two map joins followed by a group by operation. The exception is thrown in the MapJoinOperator's processOp method when attempting to compute keys and values from a null row object, which indicates that the input data may not be properly initialized or deserialized.",
            "StackTrace": [
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.exec.MapJoinOperator.processOp(MapJoinOperator.java:177)",
                "at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:457)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:697)",
                "at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84)",
                "at org.apache.hadoop.hive.ql.exec.Operator.process(Operator.java:457)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:697)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:464)"
            ],
            "RootCause": "The root cause of the NPE is likely due to the row object being null when passed to the computeKeys and computeValues methods in the MapJoinOperator's processOp method. This can occur if the input data is not properly deserialized or if there are no valid rows to process.",
            "StepsToReproduce": [
                "1. Create a Hive query that includes two map joins followed by a group by operation.",
                "2. Execute the query with input data that may contain null or improperly formatted rows.",
                "3. Observe the NullPointerException in the logs."
            ],
            "ExpectedBehavior": "The query should execute successfully, processing all rows and returning the expected results without throwing any exceptions.",
            "ObservedBehavior": "The query fails with a NullPointerException, indicating that the processing of rows is interrupted due to a null reference.",
            "Suggestions": "Ensure that the input data is properly formatted and contains valid rows. Additionally, add null checks in the MapJoinOperator's processOp method to handle cases where the row object may be null before attempting to compute keys and values.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/SelectOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.MapJoinOperator",
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.SelectOperator"
                ],
                "methods": [
                    "MapJoinOperator.processOp",
                    "MapOperator.process",
                    "SelectOperator.processOp"
                ]
            },
            "possible_fix": "In the MapJoinOperator's processOp method, add a null check for the row object before proceeding with key and value computation. For example:\n\nif (row == null) {\n    LOG.warn(\"Received null row in MapJoinOperator.processOp\");\n    return;\n}\n\nThis will prevent the NPE and allow for better handling of unexpected null inputs."
        }
    },
    {
        "filename": "HIVE-11820.json",
        "creation_time": "2015-09-14T22:20:28.000+0000",
        "bug_report": {
            "Title": "Export tables with size of >32MB throws 'java.lang.IllegalArgumentException: Skip CRC is valid only with update options'",
            "Description": "When attempting to export tables larger than 32MB, an IllegalArgumentException is thrown due to the improper configuration of the DistCpOptions. The error message indicates that the 'Skip CRC' option can only be used with update options, which is not the case in the current implementation. This issue arises from the order of method calls in the code, specifically the setting of 'setSkipCRC' and 'setSyncFolder'.",
            "StackTrace": [
                "2015-09-14 21:44:16,817 ERROR [main]: exec.Task (SessionState.java:printError(960)) - Failed with exception Skip CRC is valid only with update options",
                "java.lang.IllegalArgumentException: Skip CRC is valid only with update options",
                "at org.apache.hadoop.tools.DistCpOptions.validate(DistCpOptions.java:556)",
                "at org.apache.hadoop.tools.DistCpOptions.setSkipCRC(DistCpOptions.java:311)",
                "at org.apache.hadoop.hive.shims.Hadoop23Shims.runDistCp(Hadoop23Shims.java:1147)",
                "at org.apache.hadoop.hive.common.FileUtils.copy(FileUtils.java:553)",
                "at org.apache.hadoop.hive.ql.exec.CopyTask.execute(CopyTask.java:82)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:89)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1655)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1414)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1195)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:213)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:736)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621)"
            ],
            "RootCause": "The root cause of the issue is the incorrect order of method calls in the code where 'setSkipCRC(true)' is called before 'setSyncFolder(true)'. This leads to the IllegalArgumentException being thrown when the DistCpOptions are validated.",
            "StepsToReproduce": [
                "1. Attempt to export a table larger than 32MB using the export functionality.",
                "2. Observe the exception thrown during the process."
            ],
            "ExpectedBehavior": "The export process should complete successfully without throwing an IllegalArgumentException, regardless of the size of the table.",
            "ObservedBehavior": "An IllegalArgumentException is thrown indicating that 'Skip CRC is valid only with update options' when exporting tables larger than 32MB.",
            "Suggestions": "Reverse the order of the method calls for setting the DistCpOptions in the code. Specifically, call 'options.setSyncFolder(true);' before 'options.setSkipCRC(true);'.",
            "problem_location": {
                "files": [
                    "org/apache/hadoop/hive/shims/Hadoop23Shims.java",
                    "org/apache/hadoop/tools/DistCpOptions.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.shims.Hadoop23Shims",
                    "org.apache.hadoop.tools.DistCpOptions"
                ],
                "methods": [
                    "Hadoop23Shims.runDistCp",
                    "DistCpOptions.setSkipCRC",
                    "DistCpOptions.setSyncFolder"
                ]
            },
            "possible_fix": "In the method 'runDistCp' of the class 'Hadoop23Shims', change the order of the following lines:\n\noptions.setSyncFolder(true);\noptions.setSkipCRC(true);"
        }
    },
    {
        "filename": "HIVE-17274.json",
        "creation_time": "2017-08-08T22:20:33.000+0000",
        "bug_report": {
            "Title": "RowContainer spills for timestamp column throws exception",
            "Description": "The issue arises when the join key is a timestamp column, leading to an exception due to invalid path names that contain a colon (':'). This is a violation of URI syntax rules, as Hadoop's Path class expects valid URIs. The exception is thrown during the creation of a temporary file for the RowContainer, specifically when the key's toString() method includes a timestamp formatted with colons, which are not allowed in file names. The error message indicates a java.net.URISyntaxException caused by a relative path in an absolute URI.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: .RowContainer7551143976922371245.[1792453531, 2016-09-02 01:17:43,%202016-09-02%5D.tmp.crc",
                "at org.apache.hadoop.fs.Path.initialize(Path.java:205)",
                "at org.apache.hadoop.fs.Path.<init>(Path.java:171)",
                "at org.apache.hadoop.fs.Path.<init>(Path.java:93)",
                "at org.apache.hadoop.fs.ChecksumFileSystem.getChecksumFile(ChecksumFileSystem.java:94)",
                "at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:404)",
                "at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:463)",
                "at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:442)",
                "at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:926)",
                "at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1137)",
                "at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:273)",
                "at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:530)",
                "at org.apache.hadoop.hive.ql.exec.Utilities.createSequenceWriter(Utilities.java:1643)",
                "at org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat.getHiveRecordWriter(HiveSequenceFileOutputFormat.java:64)",
                "at org.apache.hadoop.hive.ql.exec.persistence.RowContainer.setupWriter(RowContainer.java:538)",
                "at org.apache.hadoop.hive.ql.exec.persistence.RowContainer.spillBlock(RowContainer.java:299)",
                "at org.apache.hadoop.hive.ql.exec.persistence.RowContainer.copyToDFSDirecory(RowContainer.java:407)",
                "at org.apache.hadoop.hive.ql.exec.SkewJoinHandler.endGroup(SkewJoinHandler.java:185)",
                "at org.apache.hadoop.hive.ql.exec.JoinOperator.endGroup(JoinOperator.java:249)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecReducer.reduce(ExecReducer.java:195)",
                "at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:444)",
                "at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:392)",
                "at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:422)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1724)",
                "at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)"
            ],
            "RootCause": "The root cause of the issue is that the toString() representation of the timestamp column includes colons, which are invalid characters for file names in Hadoop's URI structure. This leads to a java.net.URISyntaxException when attempting to create a Path object.",
            "StepsToReproduce": [
                "Create a Hive table with a timestamp column.",
                "Perform a join operation that uses the timestamp column as a join key.",
                "Trigger the spill operation in the RowContainer."
            ],
            "ExpectedBehavior": "The system should handle timestamp columns correctly without throwing exceptions, allowing for valid file paths to be created.",
            "ObservedBehavior": "An IllegalArgumentException is thrown due to an invalid URI when attempting to create a temporary file for the RowContainer.",
            "Suggestions": "Consider sanitizing the timestamp values used in file names by replacing or removing invalid characters such as colons. Alternatively, use a different format for the timestamp that does not include these characters.",
            "problem_location": {
                "files": [
                    "RowContainer.java",
                    "HiveSequenceFileOutputFormat.java",
                    "Utilities.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.persistence.RowContainer",
                    "org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat",
                    "org.apache.hadoop.hive.ql.exec.Utilities"
                ],
                "methods": [
                    "RowContainer.setupWriter",
                    "RowContainer.spillBlock",
                    "Utilities.createSequenceWriter"
                ]
            },
            "possible_fix": "Modify the setupWriter method in RowContainer to sanitize the keyObject's toString() output by replacing colons with a valid character (e.g., '-') before creating the temporary file name."
        }
    },
    {
        "filename": "HIVE-12522.json",
        "creation_time": "2015-11-25T19:48:44.000+0000",
        "bug_report": {
            "Title": "Wrong FS error during Tez merge files when warehouse and scratchdir are on different FS",
            "Description": "The system throws an IllegalArgumentException indicating a 'Wrong FS' error when attempting to execute a Tez graph with the configuration 'hive.merge.tezfiles=true' while the warehouse directory and scratch directory are located on different filesystems. The error occurs because the expected filesystem (HDFS) does not match the actual filesystem (Azure Blob Storage) of the scratch directory.",
            "StackTrace": [
                "2015-11-13 10:22:10,617 ERROR exec.Task (TezTask.java:execute(184)) - Failed to execute tez graph.",
                "java.lang.IllegalArgumentException: Wrong FS: wasb://chaoyiteztest@chaoyiteztest.blob.core.windows.net/hive/scratch/chaoyitest/c888f405-3c98-46b1-bf39-e57f067dfe4c/hive_2015-11-13_10-16-10_216_8161037519951665173-1/_tmp.-ext-10000, expected: hdfs://headnodehost:9000",
                "at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:1136)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:1132)",
                "at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
                "at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1132)",
                "at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1423)",
                "at org.apache.hadoop.hive.ql.exec.tez.DagUtils.createVertex(DagUtils.java:579)",
                "at org.apache.hadoop.hive.ql.exec.tez.DagUtils.createVertex(DagUtils.java:1083)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezTask.build(TezTask.java:329)",
                "at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:156)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1606)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1367)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1179)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1006)"
            ],
            "RootCause": "The root cause of the issue is that the scratch directory is located on a different filesystem (Azure Blob Storage) than the expected filesystem (HDFS). This discrepancy leads to the IllegalArgumentException when the system attempts to access the scratch directory.",
            "StepsToReproduce": [
                "Set the configuration 'hive.merge.tezfiles=true'.",
                "Configure the warehouse directory to point to an HDFS location.",
                "Configure the scratch directory to point to an Azure Blob Storage location.",
                "Execute a Tez job that requires merging files."
            ],
            "ExpectedBehavior": "The Tez job should execute successfully without any filesystem-related errors, regardless of the locations of the warehouse and scratch directories.",
            "ObservedBehavior": "The Tez job fails with an IllegalArgumentException indicating a 'Wrong FS' error due to the mismatch between the expected and actual filesystems.",
            "Suggestions": "Ensure that both the warehouse and scratch directories are located on the same filesystem. Alternatively, modify the code to handle cases where the scratch directory is on a different filesystem.",
            "problem_location": {
                "files": [
                    "TezTask.java",
                    "Driver.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.tez.TezTask",
                    "org.apache.hadoop.hive.ql.Driver"
                ],
                "methods": [
                    "TezTask.execute",
                    "Driver.runInternal"
                ]
            },
            "possible_fix": "Modify the TezTask and DagUtils classes to check if the scratch directory and warehouse directory are on the same filesystem before proceeding with the execution. If they are not, either throw a more descriptive error or handle the case appropriately."
        }
    },
    {
        "filename": "HIVE-16845.json",
        "creation_time": "2017-06-07T17:07:55.000+0000",
        "bug_report": {
            "Title": "INSERT OVERWRITE a table with dynamic partitions on S3 fails with NPE",
            "Description": "When attempting to perform an INSERT OVERWRITE operation on a partitioned table located on S3, a NullPointerException (NPE) is thrown. This occurs during the execution of the query, specifically when the system tries to resolve dynamic partitions and merge files. The issue arises from the handling of dynamic partition contexts and the associated tasks that are generated for merging files.",
            "StackTrace": [
                "2017-05-08 21:32:50,607 ERROR org.apache.hive.service.cli.operation.Operation: [HiveServer2-Background-Pool: Thread-184028]: Error running hive query: ",
                "org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code -101 from org.apache.hadoop.hive.ql.exec.ConditionalTask. null",
                "at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:400)",
                "at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:239)",
                "at org.apache.hive.service.cli.operation.SQLOperation.access$300(SQLOperation.java:88)",
                "at org.apache.hive.service.cli.operation.SQLOperation$3$1.run(SQLOperation.java:293)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)",
                "at org.apache.hive.service.cli.operation.SQLOperation$3.run(SQLOperation.java:306)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles.generateActualTasks(ConditionalResolverMergeFiles.java:290)",
                "at org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles.getTasks(ConditionalResolverMergeFiles.java:175)",
                "at org.apache.hadoop.hive.ql.exec.ConditionalTask.execute(ConditionalTask.java:81)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:214)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:100)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1977)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1690)",
                "at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:237)"
            ],
            "RootCause": "The root cause of the NullPointerException is due to the dynamic partition context (dpCtx) being null when the method generateActualTasks is called. This can happen if the dynamic partitioning is not properly set up or if the input paths do not contain any valid dynamic partitions.",
            "StepsToReproduce": [
                "Create a partitioned table on S3.",
                "Create a temporary table with sample data.",
                "Set the necessary Hive parameters for dynamic partitioning.",
                "Execute the INSERT OVERWRITE command to insert data from the temporary table into the partitioned table."
            ],
            "ExpectedBehavior": "The INSERT OVERWRITE operation should successfully write the data into the specified partitions of the S3 table without throwing any exceptions.",
            "ObservedBehavior": "The operation fails with a NullPointerException, preventing the data from being written to the S3 table.",
            "Suggestions": "Ensure that the dynamic partition context is properly initialized before calling the generateActualTasks method. Additionally, validate that the input paths contain valid dynamic partitions. Consider adding null checks and handling for the dynamic partition context in the code.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverMergeFiles.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/ConditionalTask.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles",
                    "org.apache.hadoop.hive.ql.exec.ConditionalTask",
                    "org.apache.hadoop.hive.ql.exec.Task"
                ],
                "methods": [
                    "ConditionalResolverMergeFiles.generateActualTasks",
                    "ConditionalResolverMergeFiles.getTasks",
                    "ConditionalTask.execute",
                    "Task.executeTask"
                ]
            },
            "possible_fix": "In the method ConditionalResolverMergeFiles.getTasks, add a check to ensure that dpCtx is not null before proceeding with the logic that relies on it. If dpCtx is null, handle the case appropriately, possibly by skipping the merge tasks or logging an error message."
        }
    },
    {
        "filename": "HIVE-9655.json",
        "creation_time": "2015-02-11T20:58:13.000+0000",
        "bug_report": {
            "Title": "Dynamic partition table insertion error",
            "Description": "The issue arises when attempting to insert data from table t1 into partitioned table t2. The error indicates that the system cannot find the expected field '_col2' in the output of the select statement. This is likely due to the way the select statement is structured, particularly the use of 'select *, c1 as p1' which may not be correctly mapping the fields from t1 to the expected structure in t2.",
            "StackTrace": [
                "2015-02-11 12:50:52,756 ERROR [LocalJobRunner Map Task Executor #0]: mr.ExecMapper (ExecMapper.java:map(178)) - org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row {\"c1\":1,\"c2\":\"one\"}",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:503)",
                "at org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:170)",
                "at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)",
                "at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)",
                "at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)",
                "at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: cannot find field _col2 from [0:_col0, 1:_col1]",
                "at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:397)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)",
                "at org.apache.hadoop.hive.ql.exec.SelectOperator.processOp(SelectOperator.java:84)",
                "at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:815)",
                "at org.apache.hadoop.hive.ql.exec.TableScanOperator.processOp(TableScanOperator.java:95)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx.forward(MapOperator.java:157)",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:493)",
                "... 10 more",
                "Caused by: java.lang.RuntimeException: cannot find field _col2 from [0:_col0, 1:_col1]",
                "at org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.getStandardStructFieldRef(ObjectInspectorUtils.java:410)",
                "at org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector.getStructFieldRef(StandardStructObjectInspector.java:147)",
                "at org.apache.hadoop.hive.ql.exec.ExprNodeColumnEvaluator.initialize(ExprNodeColumnEvaluator.java:55)",
                "at org.apache.hadoop.hive.ql.exec.Operator.initEvaluators(Operator.java:954)",
                "at org.apache.hadoop.hive.ql.exec.ReduceSinkOperator.processOp(ReduceSinkOperator.java:325)",
                "... 16 more"
            ],
            "RootCause": "The root cause of the issue is that the select statement in the insert operation is not correctly mapping the fields from table t1 to the expected structure in table t2. Specifically, the field '_col2' is not present in the output of the select statement, leading to a runtime exception.",
            "StepsToReproduce": [
                "Create table t1 with columns c1 and c2.",
                "Create table t2 with columns c1 and c2, partitioned by p1.",
                "Load data into table t1.",
                "Set hive.exec.dynamic.partition.mode to nonstrict.",
                "Execute the insert statement: insert overwrite table t2 partition(p1) select *, c1 as p1 from t1 distribute by p1."
            ],
            "ExpectedBehavior": "The data from table t1 should be successfully inserted into table t2, with the partitioning done correctly based on the value of c1.",
            "ObservedBehavior": "The insert operation fails with a Hive Runtime Error indicating that the field '_col2' cannot be found.",
            "Suggestions": "Review the select statement in the insert operation to ensure that all required fields are being selected and correctly mapped to the structure of table t2. Consider explicitly specifying the columns instead of using '*'.",
            "problem_location": {
                "files": [
                    "ExecMapper.java",
                    "MapOperator.java",
                    "SelectOperator.java",
                    "ReduceSinkOperator.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.mr.ExecMapper",
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.SelectOperator",
                    "org.apache.hadoop.hive.ql.exec.ReduceSinkOperator"
                ],
                "methods": [
                    "ExecMapper.map",
                    "MapOperator.process",
                    "SelectOperator.processOp",
                    "ReduceSinkOperator.processOp"
                ]
            },
            "possible_fix": "Modify the insert statement to explicitly select the required columns from t1 instead of using '*'. For example: 'insert overwrite table t2 partition(p1) select c1, c2, c1 as p1 from t1 distribute by p1;'."
        }
    },
    {
        "filename": "HIVE-11441.json",
        "creation_time": "2015-08-03T17:42:24.000+0000",
        "bug_report": {
            "Title": "No DDL allowed on table if user accidentally set table location wrong",
            "Description": "When a user attempts to alter the location of a Hive table to an invalid HDFS path, Hive fails to validate the path before executing the command. Instead of providing an immediate error, it allows the command to proceed, resulting in a connection error when the invalid path is accessed. This behavior is particularly problematic when the StorageBasedAuthorizationProvider is enabled, as it leads to a misleading error message about table accessibility rather than a clear indication of the invalid path.",
            "StackTrace": [
                "2015-07-30 12:19:43,573 DEBUG [main]: transport.TSaslTransport (TSaslTransport.java:readFrame(429)) - CLIENT: reading data length: 293",
                "2015-07-30 12:19:43,720 ERROR [main]: ql.Driver (SessionState.java:printError(833)) - FAILED: SemanticException Unable to fetch table testloc. java.net.ConnectException: Call From hdpsecb02.secb.hwxsup.com/172.25.16.178 to hdpsecb02.secb.hwxsup.com:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused",
                "org.apache.hadoop.hive.ql.parse.SemanticException: Unable to fetch table testloc. java.net.ConnectException: Call From hdpsecb02.secb.hwxsup.com/172.25.16.178 to hdpsecb02.secb.hwxsup.com:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTable(BaseSemanticAnalyzer.java:1323)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.getTable(BaseSemanticAnalyzer.java:1309)",
                "at org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.addInputsOutputsAlterTable(DDLSemanticAnalyzer.java:1387)",
                "at org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.analyzeAlterTableLocation(DDLSemanticAnalyzer.java:1452)",
                "at org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer.analyzeInternal(DDLSemanticAnalyzer.java:295)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:221)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:417)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1006)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:247)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:199)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:410)",
                "at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:783)",
                "at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:677)",
                "at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:616)"
            ],
            "RootCause": "The root cause of the issue is that Hive does not validate the HDFS path provided in the 'ALTER TABLE' command before attempting to execute it. This leads to a connection error when the invalid path is accessed, instead of a semantic error indicating the invalid path.",
            "StepsToReproduce": [
                "Create a table with an invalid location: create table testwrongloc(id int);",
                "Attempt to set the location to an invalid HDFS path: alter table testwrongloc set location 'hdfs://a-valid-hostname/tmp/testwrongloc';",
                "Attempt to set the location to a valid HDFS path or drop the table: alter table testwrongloc set location 'hdfs://correct-host:8020/tmp/testwrongloc' or drop table testwrongloc;"
            ],
            "ExpectedBehavior": "Hive should validate the HDFS path provided in the 'ALTER TABLE' command and throw an error if the path is invalid before executing the command.",
            "ObservedBehavior": "Hive allows the command to execute and throws a connection error when attempting to access the invalid HDFS path, leading to confusion about the actual issue.",
            "Suggestions": "Implement validation for the HDFS path in the 'analyzeAlterTableLocation' method to ensure that it conforms to expected formats before proceeding with the alteration.",
            "problem_location": {
                "files": [
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java",
                    "ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer",
                    "org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer"
                ],
                "methods": [
                    "DDLSemanticAnalyzer.analyzeAlterTableLocation",
                    "BaseSemanticAnalyzer.getTable"
                ]
            },
            "possible_fix": "In the 'analyzeAlterTableLocation' method, add a validation step to check if the new location is a valid HDFS path before proceeding with the alteration. This can be done by checking the format of the path and ensuring it matches expected patterns for valid HDFS locations."
        }
    },
    {
        "filename": "HIVE-10801.json",
        "creation_time": "2015-05-22T19:43:23.000+0000",
        "bug_report": {
            "Title": "'drop view' fails throwing java.lang.NullPointerException",
            "Description": "When attempting to drop a view in Hive, a NullPointerException is thrown due to the 'tblPath' variable being null when the method 'isPathEncrypted' is called. This occurs within the 'drop_table_with_environment_context' method of the HiveMetaStore class, which is invoked during the drop operation. The error indicates that the system is trying to check if a path is encrypted without a valid path, leading to the exception.",
            "StackTrace": [
                "2015-05-21 11:53:06,126 ERROR [HiveServer2-Background-Pool: Thread-197]: hdfs.KeyProviderCache (KeyProviderCache.java:createKeyProviderURI(87)) - Could not find uri with key [dfs.encryption.key.provider.uri] to create a keyProvider !!",
                "2015-05-21 11:53:06,134 ERROR [HiveServer2-Background-Pool: Thread-197]: metastore.RetryingHMSHandler (RetryingHMSHandler.java:invoke(155)) - MetaException(message:java.lang.NullPointerException)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:5379)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_with_environment_context(HiveMetaStore.java:1734)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)",
                "at com.sun.proxy.$Proxy7.drop_table_with_environment_context(Unknown Source)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.drop_table_with_environment_context(HiveMetaStoreClient.java:2056)",
                "at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.drop_table_with_environment_context(SessionHiveMetaStoreClient.java:118)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:968)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:904)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:606)",
                "at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)",
                "at com.sun.proxy.$Proxy8.dropTable(Unknown Source)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:1035)",
                "at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:972)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.dropTable(DDLTask.java:3836)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.dropTableOrPartitions(DDLTask.java:3692)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:331)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1650)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1409)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1192)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1054)",
                "at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:154)",
                "at org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:71)",
                "at org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:206)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)",
                "at org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:218)",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.hadoop.hive.shims.Hadoop23Shims$HdfsEncryptionShim.isPathEncrypted(Hadoop23Shims.java:1213)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_core(HiveMetaStore.java:1546)",
                "at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_with_environment_context(HiveMetaStore.java:1723)",
                "... 40 more"
            ],
            "RootCause": "The root cause of the NullPointerException is that the 'tblPath' variable is null when the method 'isPathEncrypted' is called in the 'drop_table_with_environment_context' method. This indicates that the table's path was not properly initialized or retrieved before this check.",
            "StepsToReproduce": [
                "1. Create a view in Hive.",
                "2. Attempt to drop the view using the command: DROP VIEW <view_name>.",
                "3. Observe the error in the logs indicating a NullPointerException."
            ],
            "ExpectedBehavior": "The view should be dropped successfully without any exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown, preventing the view from being dropped.",
            "Suggestions": "Ensure that the 'tblPath' variable is properly initialized before calling 'isPathEncrypted'. This may involve checking the logic that retrieves or sets the table path in the drop operation.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler",
                    "org.apache.hadoop.hive.metastore.HiveMetaStoreClient"
                ],
                "methods": [
                    "HiveMetaStore$HMSHandler.drop_table_with_environment_context",
                    "HiveMetaStoreClient.dropTable"
                ]
            },
            "possible_fix": "In the 'drop_table_with_environment_context' method, add a check to ensure 'tblPath' is not null before calling 'isPathEncrypted'. If it is null, handle the case appropriately, possibly by throwing a more descriptive exception or initializing 'tblPath' correctly."
        }
    },
    {
        "filename": "HIVE-9141.json",
        "creation_time": "2014-12-17T07:23:05.000+0000",
        "bug_report": {
            "Title": "HiveOnTez: mix of union all, distinct, group by generates error",
            "Description": "Executing a complex Hive query involving a mix of UNION ALL, DISTINCT, and GROUP BY operations results in a ClassCastException. The error occurs when the query attempts to process the generated work for the Tez execution engine, specifically when it tries to cast a MapWork object to a ReduceWork object, which is not valid. This indicates a problem in the query's execution plan generation, particularly in how the TezCompiler handles the operator tree.",
            "StackTrace": [
                "2014-12-16 23:19:13,593 ERROR ql.Driver (SessionState.java:printError(834)) - FAILED: ClassCastException org.apache.hadoop.hive.ql.plan.MapWork cannot be cast to org.apache.hadoop.hive.ql.plan.ReduceWork",
                "java.lang.ClassCastException: org.apache.hadoop.hive.ql.plan.MapWork cannot be cast to org.apache.hadoop.hive.ql.plan.ReduceWork",
                "at org.apache.hadoop.hive.ql.parse.GenTezWork.process(GenTezWork.java:361)",
                "at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)",
                "at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:94)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:87)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.walk(GenTezWorkWalker.java:103)",
                "at org.apache.hadoop.hive.ql.parse.GenTezWorkWalker.startWalking(GenTezWorkWalker.java:69)",
                "at org.apache.hadoop.hive.ql.parse.TezCompiler.generateTaskTree(TezCompiler.java:368)",
                "at org.apache.hadoop.hive.ql.parse.TaskCompiler.compile(TaskCompiler.java:202)",
                "at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:10202)",
                "at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:224)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:419)",
                "at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:305)",
                "at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1107)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1155)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1044)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1034)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:206)",
                "at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:158)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:369)",
                "at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:304)",
                "at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:834)",
                "at org.apache.hadoop.hive.cli.TestMiniTezCliDriver.runTest(TestMiniTezCliDriver.java:136)",
                "at org.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_uniontez2(TestMiniTezCliDriver.java:120)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)"
            ],
            "RootCause": "The root cause of the issue is a ClassCastException occurring in the GenTezWork.process method, where a MapWork object is incorrectly being treated as a ReduceWork object. This suggests that the query's execution plan is not being generated correctly, particularly in how the TezCompiler handles the operator tree for the mixed operations.",
            "StepsToReproduce": [
                "Set the Hive execution engine to Tez: set hive.execution.engine=tez;",
                "Execute the provided complex SQL query involving UNION ALL, DISTINCT, and GROUP BY."
            ],
            "ExpectedBehavior": "The query should execute successfully and return the expected results without any ClassCastException.",
            "ObservedBehavior": "The query fails with a ClassCastException indicating that a MapWork object cannot be cast to a ReduceWork object.",
            "Suggestions": "Review the query execution plan generation in the TezCompiler and ensure that the operator types are correctly identified and handled. Consider adding checks to prevent incorrect casting of work types.",
            "problem_location": {
                "files": [
                    "GenTezWork.java",
                    "DefaultRuleDispatcher.java",
                    "GenTezWorkWalker.java",
                    "TezCompiler.java",
                    "TaskCompiler.java",
                    "BaseSemanticAnalyzer.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.parse.GenTezWork",
                    "org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher",
                    "org.apache.hadoop.hive.ql.parse.GenTezWorkWalker",
                    "org.apache.hadoop.hive.ql.parse.TezCompiler",
                    "org.apache.hadoop.hive.ql.parse.TaskCompiler",
                    "org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer"
                ],
                "methods": [
                    "GenTezWork.process",
                    "DefaultRuleDispatcher.dispatch",
                    "GenTezWorkWalker.walk",
                    "TezCompiler.generateTaskTree",
                    "TaskCompiler.compile",
                    "BaseSemanticAnalyzer.analyze"
                ]
            },
            "possible_fix": "In the GenTezWork.process method, add type checks before casting to ensure that the correct type of work is being processed. Additionally, review the logic in the TezCompiler to ensure that the operator tree is being constructed correctly for the mixed operations."
        }
    },
    {
        "filename": "HIVE-10010.json",
        "creation_time": "2015-03-18T17:48:46.000+0000",
        "bug_report": {
            "Title": "Alter table results in NPE [hbase-metastore branch]",
            "Description": "The issue arises when attempting to alter a table, leading to a NullPointerException (NPE) during the initialization of a StorageDescriptor object. This occurs because the method responsible for copying the table does not handle null values appropriately, resulting in an attempt to access a property of a null object.",
            "StackTrace": [
                "2015-03-18 10:45:54,189 ERROR [main]: exec.DDLTask (DDLTask.java:failed(512)) - java.lang.NullPointerException",
                "at org.apache.hadoop.hive.metastore.api.StorageDescriptor.<init>(StorageDescriptor.java:239)",
                "at org.apache.hadoop.hive.metastore.api.Table.<init>(Table.java:270)",
                "at org.apache.hadoop.hive.metastore.api.Table.deepCopy(Table.java:310)",
                "at org.apache.hadoop.hive.ql.metadata.Table.copy(Table.java:856)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.alterTable(DDLTask.java:3329)",
                "at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:3290)",
                "at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160)",
                "at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88)",
                "at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1644)",
                "at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1403)",
                "at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1189)",
                "at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1055)",
                "at org.apache.hadoop.hive.metastore.hbase.TestHBaseMetastoreSql.table(TestHBaseMetastoreSql.java:89)"
            ],
            "RootCause": "The root cause of the NullPointerException is that the method responsible for copying the table does not check for null values in the StorageDescriptor or related objects, leading to an attempt to access properties of a null object.",
            "StepsToReproduce": [
                "1. Attempt to alter a table in the HBase metastore.",
                "2. Observe the NullPointerException in the logs."
            ],
            "ExpectedBehavior": "The alter table operation should complete successfully without throwing any exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown, causing the alter table operation to fail.",
            "Suggestions": "Implement null checks in the methods that handle table copying and initialization of StorageDescriptor objects to prevent NullPointerExceptions.",
            "problem_location": {
                "files": [
                    "StorageDescriptor.java",
                    "Table.java",
                    "DDLTask.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.api.StorageDescriptor",
                    "org.apache.hadoop.hive.metastore.api.Table",
                    "org.apache.hadoop.hive.ql.exec.DDLTask"
                ],
                "methods": [
                    "StorageDescriptor.<init>",
                    "Table.<init>",
                    "Table.deepCopy",
                    "Table.copy",
                    "DDLTask.alterTable"
                ]
            },
            "possible_fix": "In the Table.copy() method, add null checks for the StorageDescriptor and other related objects before attempting to access their properties. For example:\n\nif (this.tTable.getSd() == null) {\n    throw new HiveException(\"StorageDescriptor is null\");\n}\n\nThis will ensure that the method handles null values gracefully."
        }
    },
    {
        "filename": "HIVE-7763.json",
        "creation_time": "2014-08-18T09:35:09.000+0000",
        "bug_report": {
            "Title": "Failed to query TABLESAMPLE on empty bucket table [Spark Branch]",
            "Description": "The system throws a RuntimeException during the execution of a Spark job when attempting to query a TABLESAMPLE on an empty bucket table. The root cause is related to the inconsistency between the configuration and the input path, which leads to a failure in initializing the Map operator. This issue arises specifically when the input path does not match any aliases defined in the configuration, resulting in an error when the system tries to process the input data.",
            "StackTrace": [
                "2014-08-18 16:23:15,213 ERROR [Executor task launch worker-0]: executor.Executor (Logging.scala:logError(96)) - Exception in task 0.0 in stage 1.0 (TID 0)",
                "java.lang.RuntimeException: Map operator initialization failed",
                "at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.init(SparkMapRecordHandler.java:127)",
                "at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.call(HiveMapFunction.java:52)",
                "at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunction.call(HiveMapFunction.java:30)",
                "at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:164)",
                "at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:164)",
                "at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)",
                "at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)",
                "at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)",
                "at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)",
                "at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)",
                "at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)",
                "at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)",
                "at org.apache.spark.scheduler.Task.run(Task.scala:54)",
                "at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:199)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:722)",
                "Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Configuration and input path are inconsistent",
                "at org.apache.hadoop.hive.ql.exec.MapOperator.setChildren(MapOperator.java:404)",
                "at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.init(SparkMapRecordHandler.java:93)"
            ],
            "RootCause": "The root cause of the issue is that the configuration does not have any aliases for the input path being processed, leading to a HiveException indicating that the configuration and input path are inconsistent.",
            "StepsToReproduce": [
                "Create an empty bucket table in Hive.",
                "Attempt to execute a query using TABLESAMPLE on the empty bucket table.",
                "Observe the exception thrown during the execution."
            ],
            "ExpectedBehavior": "The system should handle the case of querying an empty bucket table gracefully, either by returning an empty result set or by providing a meaningful error message without crashing.",
            "ObservedBehavior": "The system throws a RuntimeException indicating that the Map operator initialization failed due to inconsistent configuration and input path.",
            "Suggestions": "Ensure that the configuration includes valid aliases for the input paths being processed. Additionally, implement checks to handle cases where the input table is empty before attempting to execute queries that rely on data.",
            "problem_location": {
                "files": [
                    "MapOperator.java",
                    "SparkMapRecordHandler.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.ql.exec.MapOperator",
                    "org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler"
                ],
                "methods": [
                    "MapOperator.setChildren",
                    "SparkMapRecordHandler.init"
                ]
            },
            "possible_fix": "In the setChildren method of MapOperator, add a check to handle cases where the input path is empty or does not match any aliases. For example, log a warning and return an empty result instead of throwing an exception."
        }
    },
    {
        "filename": "HIVE-12083.json",
        "creation_time": "2015-10-09T22:45:47.000+0000",
        "bug_report": {
            "Title": "HIVE-10965 introduces thrift error if partNames or colNames are empty",
            "Description": "The issue arises from a recent change in the method 'aggrColStatsForPartitions' in the MetaStoreDirectSql class, where an empty AggrStats object is returned if either 'partNames' or 'colNames' is empty. This violates the Thrift protocol requirements for the AggrStats structure, which mandates that 'colStats' must be set. As a result, when the Thrift service attempts to process this invalid AggrStats object, it throws a TProtocolException indicating that the required field 'colStats' is unset.",
            "StackTrace": [
                "2015-10-08 00:00:25,413 ERROR server.TThreadPoolServer (TThreadPoolServer.java:run(213)) - Thrift error occurred during processing of message.",
                "org.apache.thrift.protocol.TProtocolException: Required field 'colStats' is unset! Struct:AggrStats(colStats:null, partsFound:0)",
                "at org.apache.hadoop.hive.metastore.api.AggrStats.validate(AggrStats.java:389)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_aggr_stats_for_result.validate(ThriftHiveMetastore.java)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_aggr_stats_for_result$get_aggr_stats_for_resultStandardScheme.write(ThriftHiveMetastore.java)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_aggr_stats_for_result$get_aggr_stats_for_resultStandardScheme.write(ThriftHiveMetastore.java)",
                "at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_aggr_stats_for_result.write(ThriftHiveMetastore.java)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:53)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)",
                "at java.security.AccessController.doPrivileged(Native Method)",
                "at javax.security.auth.Subject.doAs(Subject.java:415)",
                "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)",
                "at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:536)",
                "at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is the lack of validation for 'partNames' being empty in the 'aggrColStatsForPartitions' method, which leads to the creation of an invalid AggrStats object that does not meet Thrift protocol requirements.",
            "StepsToReproduce": [
                "Call the 'aggrColStatsForPartitions' method with an empty list for 'partNames' or 'colNames'.",
                "Observe the Thrift error when the method attempts to return an AggrStats object."
            ],
            "ExpectedBehavior": "The method should validate the input parameters and return a valid AggrStats object or throw an appropriate exception if the inputs are invalid.",
            "ObservedBehavior": "The method returns an AggrStats object with unset required fields, leading to a Thrift protocol exception when processed.",
            "Suggestions": "Add validation checks for both 'partNames' and 'colNames' in the 'aggrColStatsForPartitions' method to ensure that neither is empty before returning an AggrStats object.",
            "problem_location": {
                "files": [
                    "metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java",
                    "metastore/src/java/org/apache/hadoop/hive/metastore/TUGIBasedProcessor.java"
                ],
                "classes": [
                    "org.apache.hadoop.hive.metastore.MetaStoreDirectSql",
                    "org.apache.hadoop.hive.metastore.TUGIBasedProcessor"
                ],
                "methods": [
                    "MetaStoreDirectSql.aggrColStatsForPartitions",
                    "TUGIBasedProcessor.process"
                ]
            },
            "possible_fix": "In the 'aggrColStatsForPartitions' method, add a check for 'partNames.isEmpty()' and 'colNames.isEmpty()' and throw a MetaException or return a valid AggrStats object with default values instead of an empty one."
        }
    },
    {
        "filename": "HIVE-14784.json",
        "creation_time": "2016-09-17T02:00:28.000+0000",
        "bug_report": {
            "Title": "Operation logs are disabled automatically if the parent directory does not exist.",
            "Description": "The operation logging feature in Hive is designed to create log files for each operation executed within a session. However, if the parent directory for these logs (typically named after the hive session ID) is deleted or does not exist, the logging mechanism fails to create the necessary log files. This results in an IOException when attempting to create a new log file, leading to subsequent errors when trying to fetch operation logs, especially in environments like HUE where sessions may remain open for extended periods.",
            "StackTrace": [
                "2016-09-15 15:09:16,723 WARN org.apache.hive.service.cli.operation.Operation: Unable to create operation log file: /tmp/hive/operation_logs/b8809985-6b38-47ec-a49b-6158a67cd9fc/d35414f7-2418-426c-8489-c6f643ca4599",
                "java.io.IOException: No such file or directory",
                "at java.io.UnixFileSystem.createFileExclusively(Native Method)",
                "at java.io.File.createNewFile(File.java:1012)",
                "at org.apache.hive.service.cli.operation.Operation.createOperationLog(Operation.java:195)",
                "at org.apache.hive.service.cli.operation.Operation.beforeRun(Operation.java:237)",
                "at org.apache.hive.service.cli.operation.Operation.run(Operation.java:255)",
                "at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:398)",
                "at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:385)",
                "at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:271)",
                "at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:490)",
                "at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)",
                "at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:692)",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "RootCause": "The root cause of the issue is that the operation log directory, which is expected to exist for logging operations, is missing. This can occur if the directory is deleted or purged by the operating system, leading to an IOException when the system attempts to create a new log file.",
            "StepsToReproduce": [
                "1. Set the operation log directory to a location that can be purged by the OS (e.g., /tmp).",
                "2. Start a Hive session and execute a query.",
                "3. Delete the operation log directory while the session is still active.",
                "4. Attempt to execute another query from the same session."
            ],
            "ExpectedBehavior": "The system should create operation log files for each executed query without errors, even if the parent directory is purged, by either recreating the directory or handling the absence gracefully.",
            "ObservedBehavior": "When the parent directory does not exist, the system throws an IOException, preventing the creation of operation log files and leading to errors when attempting to fetch results associated with those operations.",
            "Suggestions": "Implement a check to ensure the operation log directory exists before attempting to create log files. If the directory is missing, recreate it or log an appropriate warning without disabling logging entirely.",
            "problem_location": {
                "files": [
                    "service/src/java/org/apache/hive/service/cli/operation/Operation.java",
                    "service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java"
                ],
                "classes": [
                    "org.apache.hive.service.cli.operation.Operation",
                    "org.apache.hive.service.cli.session.HiveSessionImpl"
                ],
                "methods": [
                    "Operation.createOperationLog",
                    "HiveSessionImpl.executeStatementInternal"
                ]
            },
            "possible_fix": "In the createOperationLog method of the Operation class, add a check to verify if the parent directory exists before attempting to create the log file. If it does not exist, create the directory first. Example code:\n\nif (!parentSession.getOperationLogSessionDir().exists()) {\n    parentSession.getOperationLogSessionDir().mkdirs();\n}"
        }
    }
]