[
    {
        "filename": "YARN-5918.json",
        "creation_time": "2016-11-20T14:19:00.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNode(OpportunisticContainerAllocatorAMService.java:420)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNodes(OpportunisticContainerAllocatorAMService.java:412)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.getLeastLoadedNodes(OpportunisticContainerAllocatorAMService.java:402)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.allocate(OpportunisticContainerAllocatorAMService.java:236)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n        at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:467)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:990)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:846)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:789)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1857)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2539)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNode": "  private RemoteNode convertToRemoteNode(NodeId nodeId) {\n    return RemoteNode.newInstance(nodeId,\n        ((AbstractYarnScheduler)rmContext.getScheduler()).getNode(nodeId)\n            .getHttpAddress());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNodes": "  private List<RemoteNode> convertToRemoteNodes(List<NodeId> nodeIds) {\n    ArrayList<RemoteNode> retNodes = new ArrayList<>();\n    for (NodeId nId : nodeIds) {\n      retNodes.add(convertToRemoteNode(nId));\n    }\n    return retNodes;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.getLeastLoadedNodes": "  private synchronized List<RemoteNode> getLeastLoadedNodes() {\n    long currTime = System.currentTimeMillis();\n    if ((currTime - lastCacheUpdateTime > cacheRefreshInterval)\n        || cachedNodes == null) {\n      cachedNodes = convertToRemoteNodes(\n          this.nodeMonitor.selectLeastLoadedNodes(this.k));\n      lastCacheUpdateTime = currTime;\n    }\n    return cachedNodes;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.allocate": "  public AllocateResponse allocate(AllocateRequest request) throws\n      YarnException, IOException {\n\n    // Partition requests to GUARANTEED and OPPORTUNISTIC.\n    OpportunisticContainerAllocator.PartitionedResourceRequests\n        partitionedAsks =\n        oppContainerAllocator.partitionAskList(request.getAskList());\n\n    // Allocate OPPORTUNISTIC containers.\n    request.setAskList(partitionedAsks.getOpportunistic());\n    final ApplicationAttemptId appAttemptId = getAppAttemptId();\n    SchedulerApplicationAttempt appAttempt = ((AbstractYarnScheduler)\n        rmContext.getScheduler()).getApplicationAttempt(appAttemptId);\n\n    OpportunisticContainerContext oppCtx =\n        appAttempt.getOpportunisticContainerContext();\n    oppCtx.updateNodeList(getLeastLoadedNodes());\n\n    List<Container> oppContainers =\n        oppContainerAllocator.allocateContainers(request, appAttemptId, oppCtx,\n        ResourceManager.getClusterTimeStamp(), appAttempt.getUser());\n\n    // Create RMContainers and update the NMTokens.\n    if (!oppContainers.isEmpty()) {\n      handleNewContainers(oppContainers, false);\n      appAttempt.updateNMTokens(oppContainers);\n    }\n\n    // Allocate GUARANTEED containers.\n    request.setAskList(partitionedAsks.getGuaranteed());\n    AllocateResponse allocateResp = super.allocate(request);\n\n    // Add allocated OPPORTUNISTIC containers to the AllocateResponse.\n    if (!oppContainers.isEmpty()) {\n      allocateResp.getAllocatedContainers().addAll(oppContainers);\n    }\n\n    // Update opportunistic container context with the allocated GUARANTEED\n    // containers.\n    oppCtx.updateCompletedContainers(allocateResp);\n\n    // Add all opportunistic containers\n    return allocateResp;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.handleNewContainers": "  private void handleNewContainers(List<Container> allocContainers,\n                                   boolean isRemotelyAllocated) {\n    for (Container container : allocContainers) {\n      // Create RMContainer\n      SchedulerApplicationAttempt appAttempt =\n          ((AbstractYarnScheduler) rmContext.getScheduler())\n              .getCurrentAttemptForContainer(container.getId());\n      RMContainer rmContainer = new RMContainerImpl(container,\n          appAttempt.getApplicationAttemptId(), container.getNodeId(),\n          appAttempt.getUser(), rmContext, isRemotelyAllocated);\n      appAttempt.addRMContainer(container.getId(), rmContainer);\n      ((AbstractYarnScheduler) rmContext.getScheduler()).getNode(\n          container.getNodeId()).allocateContainer(rmContainer);\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(),\n              RMContainerEventType.ACQUIRED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.getAppAttemptId": "  private static ApplicationAttemptId getAppAttemptId() throws YarnException {\n    AMRMTokenIdentifier amrmTokenIdentifier =\n        YarnServerSecurityUtils.authorizeRequest();\n    ApplicationAttemptId applicationAttemptId =\n        amrmTokenIdentifier.getApplicationAttemptId();\n    return applicationAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate": "  public AllocateResponseProto allocate(RpcController arg0,\n      AllocateRequestProto proto) throws ServiceException {\n    AllocateRequestPBImpl request = new AllocateRequestPBImpl(proto);\n    try {\n      AllocateResponse response = real.allocate(request);\n      return ((AllocateResponsePBImpl)response).getProto();\n    } catch (YarnException e) {\n      throw new ServiceException(e);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcProtobufRequest request = (RpcProtobufRequest) writableRequest;\n        RequestHeaderProto rpcRequest = request.getRequestHeader();\n        String methodName = rpcRequest.getMethodName();\n\n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = request.getValue(prototype);\n\n        Message result;\n        long startTime = Time.now();\n        int qTime = (int) (startTime - receiveTime);\n        Exception exception = null;\n        try {\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n        } catch (ServiceException e) {\n          exception = (Exception) e.getCause();\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          exception = e;\n          throw e;\n        } finally {\n          int processingTime = (int) (Time.now() - startTime);\n          if (LOG.isDebugEnabled()) {\n            String msg = \"Served: \" + methodName + \" queueTime= \" + qTime +\n                \" procesingTime= \" + processingTime;\n            if (exception != null) {\n              msg += \" exception= \" + exception.getClass().getSimpleName();\n            }\n            LOG.debug(msg);\n          }\n          String detailedMetricsName = (exception == null) ?\n              methodName :\n              exception.getClass().getSimpleName();\n          server.updateMetrics(detailedMetricsName, qTime, processingTime);\n        }\n        return RpcWritable.wrap(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getProtocolImpl": "      private static ProtoClassProtoImpl getProtocolImpl(RPC.Server server,\n          String protoName, long clientVersion) throws RpcServerException {\n        ProtoNameVer pv = new ProtoNameVer(protoName, clientVersion);\n        ProtoClassProtoImpl impl = \n            server.getProtocolImplMap(RPC.RpcKind.RPC_PROTOCOL_BUFFER).get(pv);\n        if (impl == null) { // no match for Protocol AND Version\n          VerProtocolImpl highest = \n              server.getHighestSupportedProtocol(RPC.RpcKind.RPC_PROTOCOL_BUFFER, \n                  protoName);\n          if (highest == null) {\n            throw new RpcNoSuchProtocolException(\n                \"Unknown protocol: \" + protoName);\n          }\n          // protocol supported but not the version that client wants\n          throw new RPC.VersionMismatch(protoName, clientVersion,\n              highest.version);\n        }\n        return impl;\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getRequestHeader": "    RequestHeaderProto getRequestHeader() throws IOException {\n      if (getByteBuffer() != null && requestHeader == null) {\n        requestHeader = getValue(RequestHeaderProto.getDefaultInstance());\n      }\n      return requestHeader;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RPC.call": "    public Writable call(RPC.RpcKind rpcKind, String protocol,\n        Writable rpcRequest, long receiveTime) throws Exception {\n      return getRpcInvoker(rpcKind).call(this, protocol, rpcRequest,\n          receiveTime);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.run": "        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupResponse": "  private void setupResponse(RpcCall call,\n      RpcResponseHeaderProto header, Writable rv) throws IOException {\n    final byte[] response;\n    if (rv == null || (rv instanceof RpcWritable.ProtobufWrapper)) {\n      response = setupResponseForProtobuf(header, rv);\n    } else {\n      response = setupResponseForWritable(header, rv);\n    }\n    if (response.length > maxRespSize) {\n      LOG.warn(\"Large response size \" + response.length + \" for call \"\n          + call.toString());\n    }\n    call.setResponse(ByteBuffer.wrap(response));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeIdle": "    synchronized void closeIdle(boolean scanAll) {\n      long minLastContact = Time.now() - maxIdleTime;\n      // concurrent iterator might miss new connections added\n      // during the iteration, but that's ok because they won't\n      // be idle yet anyway and will be caught on next scan\n      int closed = 0;\n      for (Connection connection : connections) {\n        // stop if connections dropped below threshold unless scanning all\n        if (!scanAll && size() < idleScanThreshold) {\n          break;\n        }\n        // stop if not scanning all and max connections are closed\n        if (connection.isIdle() &&\n            connection.getLastContact() < minLastContact &&\n            close(connection) &&\n            !scanAll && (++closed == maxIdleToClose)) {\n          break;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.close": "    boolean close(Connection connection) {\n      boolean exists = remove(connection);\n      if (exists) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(Thread.currentThread().getName() +\n              \": disconnecting client \" + connection +\n              \". Number of active connections: \"+ size());\n        }\n        // only close if actually removed to avoid double-closing due\n        // to possible races\n        connection.close();\n        // Remove authorized users only\n        if (connection.user != null && connection.connectionContextRead) {\n          decrUserConnections(connection.user.getShortUserName());\n        }\n      }\n      return exists;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRunLoop": "    private void doRunLoop() {\n      long lastPurgeTime = 0;   // last check for old calls.\n\n      while (running) {\n        try {\n          waitPending();     // If a channel is being registered, wait.\n          writeSelector.select(PURGE_INTERVAL);\n          Iterator<SelectionKey> iter = writeSelector.selectedKeys().iterator();\n          while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            iter.remove();\n            try {\n              if (key.isWritable()) {\n                doAsyncWrite(key);\n              }\n            } catch (CancelledKeyException cke) {\n              // something else closed the connection, ex. reader or the\n              // listener doing an idle scan.  ignore it and let them clean\n              // up\n              RpcCall call = (RpcCall)key.attachment();\n              if (call != null) {\n                LOG.info(Thread.currentThread().getName() +\n                    \": connection aborted from \" + call.connection);\n              }\n            } catch (IOException e) {\n              LOG.info(Thread.currentThread().getName() + \": doAsyncWrite threw exception \" + e);\n            }\n          }\n          long now = Time.now();\n          if (now < lastPurgeTime + PURGE_INTERVAL) {\n            continue;\n          }\n          lastPurgeTime = now;\n          //\n          // If there were some calls that have not been sent out for a\n          // long time, discard them.\n          //\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"Checking for old call responses.\");\n          }\n          ArrayList<RpcCall> calls;\n          \n          // get the list of channels from list of keys.\n          synchronized (writeSelector.keys()) {\n            calls = new ArrayList<RpcCall>(writeSelector.keys().size());\n            iter = writeSelector.keys().iterator();\n            while (iter.hasNext()) {\n              SelectionKey key = iter.next();\n              RpcCall call = (RpcCall)key.attachment();\n              if (call != null && key.channel() == call.connection.channel) { \n                calls.add(call);\n              }\n            }\n          }\n\n          for (RpcCall call : calls) {\n            doPurge(call, now);\n          }\n        } catch (OutOfMemoryError e) {\n          //\n          // we can run out of memory if we have too many threads\n          // log the event and sleep for a minute and give\n          // some thread(s) a chance to finish\n          //\n          LOG.warn(\"Out of Memory in server select\", e);\n          try { Thread.sleep(60000); } catch (Exception ie) {}\n        } catch (Exception e) {\n          LOG.warn(\"Exception in Responder\", e);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.stopIdleScan": "    void stopIdleScan() {\n      idleScanTimer.cancel();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeCurrentConnection": "    private void closeCurrentConnection(SelectionKey key, Throwable e) {\n      if (key != null) {\n        Connection c = (Connection)key.attachment();\n        if (c != null) {\n          closeConnection(c);\n          c = null;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doAccept": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server = (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel = server.accept()) != null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader = getReader();\n        Connection c = connectionManager.register(channel);\n        // If the connectionManager can't take it, close the connection.\n        if (c == null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanup(null, channel);\n          }\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeAll": "    void closeAll() {\n      // use a copy of the connections to be absolutely sure the concurrent\n      // iterator doesn't miss a connection\n      for (Connection connection : toArray()) {\n        close(connection);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.scheduleIdleScanTask": "    private void scheduleIdleScanTask() {\n      if (!running) {\n        return;\n      }\n      TimerTask idleScanTask = new TimerTask(){\n        @Override\n        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }\n      };\n      idleScanTimer.schedule(idleScanTask, idleScanInterval);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getRpcErrorCodeProto": "    public RpcErrorCodeProto getRpcErrorCodeProto() {\n      return errCode;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.call": "  public abstract Writable call(RPC.RpcKind rpcKind, String protocol,\n      Writable param, long receiveTime) throws Exception;\n  \n  /**\n   * Authorize the incoming client connection.\n   * \n   * @param user client user\n   * @param protocolName - the protocol\n   * @param addr InetAddress of incoming connection\n   * @throws AuthorizationException when the client isn't authorized to talk the protocol\n   */\n  private void authorize(UserGroupInformation user, String protocolName,\n      InetAddress addr) throws AuthorizationException {\n    if (authorize) {\n      if (protocolName == null) {\n        throw new AuthorizationException(\"Null protocol not authorized\");\n      }\n      Class<?> protocol = null;\n      try {\n        protocol = getProtocolClass(protocolName, getConf());\n      } catch (ClassNotFoundException cfne) {\n        throw new AuthorizationException(\"Unknown protocol: \" + \n                                         protocolName);\n      }\n      serviceAuthorizationManager.authorize(user, protocol, getConf(), addr);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getSelector": "    synchronized Selector getSelector() { return selector; }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.sendResponse": "    private void sendResponse(RpcCall call) throws IOException {\n      responder.doRespond(call);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getRemoteUser": "    public UserGroupInformation getRemoteUser() {\n      return connection.user;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.startIdleScan": "    void startIdleScan() {\n      scheduleIdleScanTask();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.logException": "  void logException(Log logger, Throwable e, Call call) {\n    if (exceptionsHandler.isSuppressedLog(e.getClass())) {\n      return; // Log nothing.\n    }\n\n    final String logMsg = Thread.currentThread().getName() + \", call \" + call;\n    if (exceptionsHandler.isTerseLog(e.getClass())) {\n      // Don't log the whole stack trace. Way too noisy!\n      logger.info(logMsg + \": \" + e);\n    } else if (e instanceof RuntimeException || e instanceof Error) {\n      // These exception types indicate something is probably wrong\n      // on the server side, as opposed to just a normal exceptional\n      // result.\n      logger.warn(logMsg, e);\n    } else {\n      logger.info(logMsg, e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.remove": "    private boolean remove(Connection connection) {\n      boolean removed = connections.remove(connection);\n      if (removed) {\n        count.getAndDecrement();\n      }\n      return removed;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getScheduler": "  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.getClusterTimeStamp": "  public static long getClusterTimeStamp() {\n    return clusterTimeStamp;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.updateMetrics": "  void updateMetrics(String name, int queueTime, int processingTime) {\n    rpcMetrics.addRpcQueueTime(queueTime);\n    rpcMetrics.addRpcProcessingTime(processingTime);\n    rpcDetailedMetrics.addProcessingTime(name, processingTime);\n    callQueue.addResponseTime(name, getPriorityLevel(), queueTime,\n        processingTime);\n\n    if (isLogSlowRPC()) {\n      logSlowRpcCalls(name, processingTime);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.getPriorityLevel": "    public int getPriorityLevel() {\n      return this.priorityLevel;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.isLogSlowRPC": "  protected boolean isLogSlowRPC() {\n    return logSlowRPC;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.logSlowRpcCalls": "  void logSlowRpcCalls(String methodName, int processingTime) {\n    final int deviation = 3;\n\n    // 1024 for minSampleSize just a guess -- not a number computed based on\n    // sample size analysis. It is chosen with the hope that this\n    // number is high enough to avoid spurious logging, yet useful\n    // in practice.\n    final int minSampleSize = 1024;\n    final double threeSigma = rpcMetrics.getProcessingMean() +\n        (rpcMetrics.getProcessingStdDev() * deviation);\n\n    if ((rpcMetrics.getProcessingSampleCount() > minSampleSize) &&\n        (processingTime > threeSigma)) {\n      if(LOG.isWarnEnabled()) {\n        String client = CurCall.get().toString();\n        LOG.warn(\n            \"Slow RPC : \" + methodName + \" took \" + processingTime +\n                \" milliseconds to process from client \" + client);\n      }\n      rpcMetrics.incrSlowRpc();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcWritable.wrap": "    public static Buffer wrap(ByteBuffer bb) {\n      return new Buffer(bb);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.CallerContext.setCurrent": "  public static void setCurrent(CallerContext callerContext) {\n    CurrentCallerContextHolder.CALLER_CONTEXT.set(callerContext);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcServerException.getRpcStatusProto": "  public RpcStatusProto getRpcStatusProto() {\n    return RpcStatusProto.ERROR;\n  }"
        },
        "bug_report": {
            "Title": "Handle Opportunistic scheduling allocate request failure when NM is lost",
            "Description": "Allocate request failure during Opportunistic container allocation when nodemanager is lost \n\n{noformat}\n2016-11-20 10:38:49,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=root     OPERATION=AM Released Container TARGET=SchedulerApp     RESULT=SUCCESS  APPID=application_1479637990302_0002    CONTAINERID=container_e12_1479637990302_0002_01_000006  RESOURCE=<memory:1024, vCores:1>\n2016-11-20 10:38:49,011 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node docker2:38297 clusterResource: <memory:4096, vCores:8>\n2016-11-20 10:38:49,434 WARN org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8030, call Call#35 Retry#0 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate from 172.17.0.2:51584\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNode(OpportunisticContainerAllocatorAMService.java:420)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNodes(OpportunisticContainerAllocatorAMService.java:412)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.getLeastLoadedNodes(OpportunisticContainerAllocatorAMService.java:402)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.allocate(OpportunisticContainerAllocatorAMService.java:236)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n        at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:467)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:990)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:846)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:789)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1857)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2539)\n2016-11-20 10:38:50,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_e12_1479637990302_0002_01_000002 Container Transitioned from RUNNING to COMPLETED\n\n{noformat}"
        }
    },
    {
        "filename": "YARN-8629.json",
        "creation_time": "2018-08-07T00:14:14.000+0000",
        "stack_trace": "```\njava.io.FileNotFoundException: /sys/fs/cgroup/cpu,cpuacct/hadoop-yarn-tmp-cxx/container_e02_1533336898541_0010_20_000002/tasks (No such file or directory)\n        at java.io.FileInputStream.open0(Native Method)\n        at java.io.FileInputStream.open(FileInputStream.java:195)\n        at java.io.FileInputStream.<init>(FileInputStream.java:138)\n        at java.io.FileInputStream.<init>(FileInputStream.java:93)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.checkAndDeleteCgroup(CGroupsHandlerImpl.java:507)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.deleteCGroup(CGroupsHandlerImpl.java:542)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl.postComplete(CGroupsCpuResourceHandlerImpl.java:238)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.postComplete(ResourceHandlerChain.java:111)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.postComplete(LinuxContainerExecutor.java:964)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.reapContainer(LinuxContainerExecutor.java:787)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer(ContainerLaunch.java:821)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:161)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:57)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\n        at java.lang.Thread.run(Thread.java:748)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.checkAndDeleteCgroup": "  private boolean checkAndDeleteCgroup(File cgf) throws InterruptedException {\n    boolean deleted = false;\n    // FileInputStream in = null;\n    try (FileInputStream in = new FileInputStream(cgf + \"/tasks\")) {\n      if (in.read() == -1) {\n        /*\n         * \"tasks\" file is empty, sleep a bit more and then try to delete the\n         * cgroup. Some versions of linux will occasionally panic due to a race\n         * condition in this area, hence the paranoia.\n         */\n        Thread.sleep(deleteCGroupDelay);\n        deleted = cgf.delete();\n        if (!deleted) {\n          LOG.warn(\"Failed attempt to delete cgroup: \" + cgf);\n        }\n      } else {\n        logLineFromTasksFile(cgf);\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Failed to read cgroup tasks file. \", e);\n    }\n    return deleted;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.logLineFromTasksFile": "  private void logLineFromTasksFile(File cgf) {\n    String str;\n    if (LOG.isDebugEnabled()) {\n      try (BufferedReader inl =\n          new BufferedReader(new InputStreamReader(new FileInputStream(cgf\n              + \"/tasks\"), \"UTF-8\"))) {\n        str = inl.readLine();\n        if (str != null) {\n          LOG.debug(\"First line in cgroup tasks file: \" + cgf + \" \" + str);\n        }\n      } catch (IOException e) {\n        LOG.warn(\"Failed to read cgroup tasks file. \", e);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.deleteCGroup": "  public void deleteCGroup(CGroupController controller, String cGroupId)\n      throws ResourceHandlerException {\n    boolean deleted = false;\n    String cGroupPath = getPathForCGroup(controller, cGroupId);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"deleteCGroup: \" + cGroupPath);\n    }\n\n    long start = clock.getTime();\n\n    do {\n      try {\n        deleted = checkAndDeleteCgroup(new File(cGroupPath));\n        if (!deleted) {\n          Thread.sleep(deleteCGroupDelay);\n        }\n      } catch (InterruptedException ex) {\n        // NOP\n      }\n    } while (!deleted && (clock.getTime() - start) < deleteCGroupTimeout);\n\n    if (!deleted) {\n      LOG.warn(String.format(\"Unable to delete  %s, tried to delete for %d ms\",\n          cGroupPath, deleteCGroupTimeout));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.getPathForCGroup": "  public String getPathForCGroup(CGroupController controller, String cGroupId) {\n    return getControllerPath(controller) + Path.SEPARATOR + cGroupPrefix\n        + Path.SEPARATOR + cGroupId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl.postComplete": "  public List<PrivilegedOperation> postComplete(ContainerId containerId)\n      throws ResourceHandlerException {\n    cGroupsHandler.deleteCGroup(CPU, containerId.toString());\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.postComplete": "  public List<PrivilegedOperation> postComplete(ContainerId containerId)\n      throws ResourceHandlerException {\n    List<PrivilegedOperation> allOperations = new\n        ArrayList<PrivilegedOperation>();\n\n    for (ResourceHandler resourceHandler : resourceHandlers) {\n      List<PrivilegedOperation> handlerOperations =\n          resourceHandler.postComplete(containerId);\n\n      if (handlerOperations != null) {\n        allOperations.addAll(handlerOperations);\n      }\n\n    }\n    return allOperations;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.postComplete": "  void postComplete(final ContainerId containerId) {\n    try {\n      if (resourceHandlerChain != null) {\n        LOG.debug(\"{} post complete\", containerId);\n        resourceHandlerChain.postComplete(containerId);\n      }\n    } catch (ResourceHandlerException e) {\n      LOG.warn(\"ResourceHandlerChain.postComplete failed for \" +\n          \"containerId: {}. Exception: \", containerId, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.reapContainer": "  public boolean reapContainer(ContainerReapContext ctx) throws IOException {\n    Container container = ctx.getContainer();\n    String user = ctx.getUser();\n    String runAsUser = getRunAsUser(user);\n    ContainerRuntimeContext runtimeContext = new ContainerRuntimeContext\n        .Builder(container)\n        .setExecutionAttribute(RUN_AS_USER, runAsUser)\n        .setExecutionAttribute(USER, user)\n        .build();\n    try {\n      linuxContainerRuntime.reapContainer(runtimeContext);\n    } catch (ContainerExecutionException e) {\n      int retCode = e.getExitCode();\n      if (retCode != 0) {\n        return false;\n      }\n      LOG.warn(\"Error in reaping container \"\n          + container.getContainerId().toString() + \" exit = \" + retCode, e);\n      logOutput(e.getOutput());\n      throw new IOException(\"Error in reaping container \"\n          + container.getContainerId().toString() + \" exit = \" + retCode, e);\n    } finally {\n      postComplete(container.getContainerId());\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getRunAsUser": "  String getRunAsUser(String user) {\n    if (UserGroupInformation.isSecurityEnabled() ||\n        !containerLimitUsers) {\n      return user;\n    } else {\n      return nonsecureLocalUser;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getExitCode": "    public int getExitCode() {\n      return code;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.toString": "    public String toString() {\n      return String.valueOf(code);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer": "  public void cleanupContainer() throws IOException {\n    ContainerId containerId = container.getContainerId();\n    String containerIdStr = containerId.toString();\n    LOG.info(\"Cleaning up container \" + containerIdStr);\n\n    try {\n      context.getNMStateStore().storeContainerKilled(containerId);\n    } catch (IOException e) {\n      LOG.error(\"Unable to mark container \" + containerId\n          + \" killed in store\", e);\n    }\n\n    // launch flag will be set to true if process already launched\n    boolean alreadyLaunched =\n        !containerAlreadyLaunched.compareAndSet(false, true);\n    if (!alreadyLaunched) {\n      LOG.info(\"Container \" + containerIdStr + \" not launched.\"\n          + \" No cleanup needed to be done\");\n      return;\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Marking container \" + containerIdStr + \" as inactive\");\n    }\n    // this should ensure that if the container process has not launched \n    // by this time, it will never be launched\n    exec.deactivateContainer(containerId);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Getting pid for container \" + containerIdStr + \" to kill\"\n          + \" from pid file \" \n          + (pidFilePath != null ? pidFilePath.toString() : \"null\"));\n    }\n    \n    // however the container process may have already started\n    try {\n\n      // get process id from pid file if available\n      // else if shell is still active, get it from the shell\n      String processId = null;\n      if (pidFilePath != null) {\n        processId = getContainerPid(pidFilePath);\n      }\n\n      // kill process\n      String user = container.getUser();\n      if (processId != null) {\n        signalProcess(processId, user, containerIdStr);\n      } else {\n        // Normally this means that the process was notified about\n        // deactivateContainer above and did not start.\n        // Since we already set the state to RUNNING or REINITIALIZING\n        // we have to send a killed event to continue.\n        if (!completed.get()) {\n          LOG.warn(\"Container clean up before pid file created \"\n              + containerIdStr);\n          dispatcher.getEventHandler().handle(\n              new ContainerExitEvent(container.getContainerId(),\n                  ContainerEventType.CONTAINER_KILLED_ON_REQUEST,\n                  Shell.WINDOWS ? ExitCode.FORCE_KILLED.getExitCode() :\n                      ExitCode.TERMINATED.getExitCode(),\n                  \"Container terminated before pid file created.\"));\n          // There is a possibility that the launch grabbed the file name before\n          // the deactivateContainer above but it was slow enough to avoid\n          // getContainerPid.\n          // Increasing YarnConfiguration.NM_PROCESS_KILL_WAIT_MS\n          // reduces the likelihood of this race condition and process leak.\n        }\n        // The Docker container may not have fully started, reap the container.\n        if (DockerLinuxContainerRuntime.isDockerContainerRequested(\n            container.getLaunchContext().getEnvironment())) {\n          reapDockerContainerNoPid(user);\n        }\n      }\n    } catch (Exception e) {\n      String message =\n          \"Exception when trying to cleanup container \" + containerIdStr\n              + \": \" + StringUtils.stringifyException(e);\n      LOG.warn(message);\n      dispatcher.getEventHandler().handle(\n        new ContainerDiagnosticsUpdateEvent(containerId, message));\n    } finally {\n      // cleanup pid file if present\n      if (pidFilePath != null) {\n        FileContext lfs = FileContext.getLocalFSFileContext();\n        lfs.delete(pidFilePath, false);\n        lfs.delete(pidFilePath.suffix(EXIT_CODE_FILE_SUFFIX), false);\n      }\n    }\n\n    // Reap the container\n    boolean result = exec.reapContainer(\n        new ContainerReapContext.Builder()\n            .setContainer(container)\n            .setUser(container.getUser())\n            .build());\n    if (!result) {\n      throw new IOException(\"Reap container failed for container \"\n          + containerIdStr);\n    }\n    cleanupContainerFiles(getContainerWorkDir());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.reapDockerContainerNoPid": "  private void reapDockerContainerNoPid(String user) throws IOException {\n    String containerIdStr =\n        container.getContainerTokenIdentifier().getContainerID().toString();\n    LOG.info(\"Unable to obtain pid, but docker container request detected. \"\n            + \"Attempting to reap container \" + containerIdStr);\n    boolean result = exec.reapContainer(\n        new ContainerReapContext.Builder()\n            .setContainer(container)\n            .setUser(container.getUser())\n            .build());\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Sent signal to docker container \" + containerIdStr\n          + \" as user \" + user + \", result=\" + (result ? \"success\" : \"failed\"));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainerFiles": "  protected void cleanupContainerFiles(Path containerWorkDir) {\n    LOG.debug(\"cleanup container {} files\", containerWorkDir);\n    // delete ContainerScriptPath\n    deleteAsUser(new Path(containerWorkDir, CONTAINER_SCRIPT));\n    // delete TokensPath\n    deleteAsUser(new Path(containerWorkDir, FINAL_CONTAINER_TOKENS_FILE));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.signalProcess": "  private void signalProcess(String processId, String user,\n      String containerIdStr) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Sending signal to pid \" + processId + \" as user \" + user\n          + \" for container \" + containerIdStr);\n    }\n    final Signal signal =\n        sleepDelayBeforeSigKill > 0 ? Signal.TERM : Signal.KILL;\n\n    boolean result = sendSignal(user, processId, signal);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Sent signal \" + signal + \" to pid \" + processId + \" as user \"\n          + user + \" for container \" + containerIdStr + \", result=\"\n          + (result ? \"success\" : \"failed\"));\n    }\n    if (sleepDelayBeforeSigKill > 0) {\n      new DelayedProcessKiller(container, user, processId,\n          sleepDelayBeforeSigKill, Signal.KILL, exec).start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerPid": "  private String getContainerPid(Path pidFilePath) throws Exception {\n    String containerIdStr = \n        container.getContainerId().toString();\n    String processId = null;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Accessing pid for container \" + containerIdStr\n          + \" from pid file \" + pidFilePath);\n    }\n    int sleepCounter = 0;\n    final int sleepInterval = 100;\n\n    // loop waiting for pid file to show up \n    // until our timer expires in which case we admit defeat\n    while (true) {\n      processId = ProcessIdFileReader.getProcessId(pidFilePath);\n      if (processId != null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\n              \"Got pid \" + processId + \" for container \" + containerIdStr);\n        }\n        break;\n      }\n      else if ((sleepCounter*sleepInterval) > maxKillWaitTime) {\n        LOG.info(\"Could not get pid for \" + containerIdStr\n        \t\t+ \". Waited for \" + maxKillWaitTime + \" ms.\");\n        break;\n      }\n      else {\n        ++sleepCounter;\n        Thread.sleep(sleepInterval);\n      }\n    }\n    return processId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.toString": "    public String toString() {\n      return sb.toString();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerWorkDir": "  protected Path getContainerWorkDir() throws IOException {\n    String containerWorkDir = container.getWorkDir();\n    if (containerWorkDir == null\n        || !dirsHandler.isGoodLocalDir(containerWorkDir)) {\n      throw new IOException(\n          \"Could not find a good work dir \" + containerWorkDir\n              + \" for container \" + container);\n    }\n\n    return new Path(containerWorkDir);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle": "  public void handle(ContainersLauncherEvent event) {\n    // TODO: ContainersLauncher launches containers one by one!!\n    Container container = event.getContainer();\n    ContainerId containerId = container.getContainerId();\n    switch (event.getType()) {\n      case LAUNCH_CONTAINER:\n        Application app =\n          context.getApplications().get(\n              containerId.getApplicationAttemptId().getApplicationId());\n\n        ContainerLaunch launch =\n            new ContainerLaunch(context, getConfig(), dispatcher, exec, app,\n              event.getContainer(), dirsHandler, containerManager);\n        containerLauncher.submit(launch);\n        running.put(containerId, launch);\n        break;\n      case RELAUNCH_CONTAINER:\n        app = context.getApplications().get(\n                containerId.getApplicationAttemptId().getApplicationId());\n\n        ContainerRelaunch relaunch =\n            new ContainerRelaunch(context, getConfig(), dispatcher, exec, app,\n                event.getContainer(), dirsHandler, containerManager);\n        containerLauncher.submit(relaunch);\n        running.put(containerId, relaunch);\n        break;\n      case RECOVER_CONTAINER:\n        app = context.getApplications().get(\n            containerId.getApplicationAttemptId().getApplicationId());\n        launch = new RecoveredContainerLaunch(context, getConfig(), dispatcher,\n            exec, app, event.getContainer(), dirsHandler, containerManager);\n        containerLauncher.submit(launch);\n        running.put(containerId, launch);\n        break;\n      case RECOVER_PAUSED_CONTAINER:\n        app = context.getApplications().get(\n            containerId.getApplicationAttemptId().getApplicationId());\n        launch = new RecoverPausedContainerLaunch(context, getConfig(),\n            dispatcher, exec, app, event.getContainer(), dirsHandler,\n            containerManager);\n        containerLauncher.submit(launch);\n        break;\n      case CLEANUP_CONTAINER:\n      case CLEANUP_CONTAINER_FOR_REINIT:\n        ContainerLaunch launcher = running.remove(containerId);\n        if (launcher == null) {\n          // Container not launched. So nothing needs to be done.\n          return;\n        }\n\n        // Cleanup a container whether it is running/killed/completed, so that\n        // no sub-processes are alive.\n        try {\n          launcher.cleanupContainer();\n        } catch (IOException e) {\n          LOG.warn(\"Got exception while cleaning container \" + containerId\n              + \". Ignoring.\");\n        }\n        break;\n      case SIGNAL_CONTAINER:\n        SignalContainersLauncherEvent signalEvent =\n            (SignalContainersLauncherEvent) event;\n        ContainerLaunch runningContainer = running.get(containerId);\n        if (runningContainer == null) {\n          // Container not launched. So nothing needs to be done.\n          LOG.info(\"Container \" + containerId + \" not running, nothing to signal.\");\n          return;\n        }\n\n        try {\n          runningContainer.signalContainer(signalEvent.getCommand());\n        } catch (IOException e) {\n          LOG.warn(\"Got exception while signaling container \" + containerId\n              + \" with command \" + signalEvent.getCommand());\n        }\n        break;\n      case PAUSE_CONTAINER:\n        ContainerLaunch launchedContainer = running.get(containerId);\n        if (launchedContainer == null) {\n          // Container not launched. So nothing needs to be done.\n          return;\n        }\n\n        // Pause the container\n        try {\n          launchedContainer.pauseContainer();\n        } catch (Exception e) {\n          LOG.info(\"Got exception while pausing container: \" +\n            StringUtils.stringifyException(e));\n        }\n        break;\n      case RESUME_CONTAINER:\n        ContainerLaunch launchCont = running.get(containerId);\n        if (launchCont == null) {\n          // Container not launched. So nothing needs to be done.\n          return;\n        }\n\n        // Resume the container.\n        try {\n          launchCont.resumeContainer();\n        } catch (Exception e) {\n          LOG.info(\"Got exception while resuming container: \" +\n            StringUtils.stringifyException(e));\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.cGroupsHandler.deleteCGroup": "  void deleteCGroup(CGroupController controller, String cGroupId) throws\n      ResourceHandlerException;\n\n  /**\n   * Gets the absolute path to the specified cgroup controller.\n   * @param controller - controller type for the cgroup\n   * @return the root of the controller.\n   */\n  String getControllerPath(CGroupController controller);\n\n  /**\n   * Gets the relative path for the cgroup, independent of a controller, for a\n   * given cgroup id.\n   * @param cGroupId - id of the cgroup\n   * @return path for the cgroup relative to the root of (any) controller.\n   */\n  String getRelativePathForCGroup(String cGroupId);\n\n  /**\n   * Gets the full path for the cgroup, given a controller and a cgroup id.\n   * @param controller - controller type for the cgroup\n   * @param cGroupId - id of the cgroup\n   * @return full path for the cgroup\n   */\n  String getPathForCGroup(CGroupController controller, String\n      cGroupId);\n\n  /**\n   * Gets the full path for the cgroup's tasks file, given a controller and a\n   * cgroup id.\n   * @param controller - controller type for the cgroup\n   * @param cGroupId - id of the cgroup\n   * @return full path for the cgroup's tasks file\n   */\n  String getPathForCGroupTasks(CGroupController controller, String\n      cGroupId);\n\n  /**\n   * Gets the full path for a cgroup parameter, given a controller,\n   * cgroup id and parameter name.\n   * @param controller - controller type for the cgroup\n   * @param cGroupId - id of the cgroup\n   * @param param - cgroup parameter ( e.g classid )\n   * @return full path for the cgroup parameter\n   */\n  String getPathForCGroupParam(CGroupController controller, String\n      cGroupId, String param);\n\n  /**\n   * updates a cgroup parameter, given a controller, cgroup id, parameter name.\n   * and a parameter value\n   * @param controller - controller type for the cgroup\n   * @param cGroupId - id of the cgroup\n   * @param param - cgroup parameter ( e.g classid )\n   * @param value - value to be written to the parameter file\n   * @throws ResourceHandlerException the operation failed\n   */\n  void updateCGroupParam(CGroupController controller, String cGroupId,\n      String param, String value) throws ResourceHandlerException;\n\n  /**\n   * reads a cgroup parameter value, given a controller, cgroup id, parameter.\n   * name\n   * @param controller - controller type for the cgroup\n   * @param cGroupId - id of the cgroup\n   * @param param - cgroup parameter ( e.g classid )\n   * @return parameter value as read from the parameter file\n   * @throws ResourceHandlerException the operation failed\n   */\n  String getCGroupParam(CGroupController controller, String cGroupId,\n      String param) throws ResourceHandlerException;\n\n  /**\n   * Returns CGroup Mount Path.\n   * @return parameter value as read from the parameter file\n   */\n  String getCGroupMountPath();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.signalContainer": "  public void signalContainer(SignalContainerCommand command)\n      throws IOException {\n    ContainerId containerId =\n        container.getContainerTokenIdentifier().getContainerID();\n    String containerIdStr = containerId.toString();\n    String user = container.getUser();\n    Signal signal = translateCommandToSignal(command);\n    if (signal.equals(Signal.NULL)) {\n      LOG.info(\"ignore signal command \" + command);\n      return;\n    }\n\n    LOG.info(\"Sending signal \" + command + \" to container \" + containerIdStr);\n\n    boolean alreadyLaunched =\n        !containerAlreadyLaunched.compareAndSet(false, true);\n    if (!alreadyLaunched) {\n      LOG.info(\"Container \" + containerIdStr + \" not launched.\"\n          + \" Not sending the signal\");\n      return;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Getting pid for container \" + containerIdStr\n          + \" to send signal to from pid file \"\n          + (pidFilePath != null ? pidFilePath.toString() : \"null\"));\n    }\n\n    try {\n      // get process id from pid file if available\n      // else if shell is still active, get it from the shell\n      String processId = null;\n      if (pidFilePath != null) {\n        processId = getContainerPid(pidFilePath);\n      }\n\n      if (processId != null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Sending signal to pid \" + processId\n              + \" as user \" + user\n              + \" for container \" + containerIdStr);\n        }\n\n        boolean result = exec.signalContainer(\n            new ContainerSignalContext.Builder()\n                .setContainer(container)\n                .setUser(user)\n                .setPid(processId)\n                .setSignal(signal)\n                .build());\n\n        String diagnostics = \"Sent signal \" + command\n            + \" (\" + signal + \") to pid \" + processId\n            + \" as user \" + user\n            + \" for container \" + containerIdStr\n            + \", result=\" + (result ? \"success\" : \"failed\");\n        LOG.info(diagnostics);\n\n        dispatcher.getEventHandler().handle(\n            new ContainerDiagnosticsUpdateEvent(containerId, diagnostics));\n      }\n    } catch (Exception e) {\n      String message =\n          \"Exception when sending signal to container \" + containerIdStr\n              + \": \" + StringUtils.stringifyException(e);\n      LOG.warn(message);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.translateCommandToSignal": "  public static Signal translateCommandToSignal(\n      SignalContainerCommand command) {\n    Signal signal = Signal.NULL;\n    switch (command) {\n      case OUTPUT_THREAD_DUMP:\n        // TODO for windows support.\n        signal = Shell.WINDOWS ? Signal.NULL: Signal.QUIT;\n        break;\n      case GRACEFUL_SHUTDOWN:\n        signal = Signal.TERM;\n        break;\n      case FORCEFUL_SHUTDOWN:\n        signal = Signal.KILL;\n        break;\n    }\n    return signal;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.SignalContainersLauncherEvent.getCommand": "  public SignalContainerCommand getCommand() {\n    return command;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.pauseContainer": "  public void pauseContainer() throws IOException {\n    ContainerId containerId = container.getContainerId();\n    String containerIdStr = containerId.toString();\n    LOG.info(\"Pausing the container \" + containerIdStr);\n\n    // The pause event is only handled if the container is in the running state\n    // (the container state machine), so we don't check for\n    // shouldLaunchContainer over here\n\n    if (!shouldPauseContainer.compareAndSet(false, true)) {\n      LOG.info(\"Container \" + containerId + \" not paused as \"\n          + \"resume already called\");\n      return;\n    }\n\n    try {\n      // Pause the container\n      exec.pauseContainer(container);\n\n      // PauseContainer is a blocking call. We are here almost means the\n      // container is paused, so send out the event.\n      dispatcher.getEventHandler().handle(new ContainerEvent(\n          containerId,\n          ContainerEventType.CONTAINER_PAUSED));\n\n      try {\n        this.context.getNMStateStore().storeContainerPaused(\n            container.getContainerId());\n      } catch (IOException e) {\n        LOG.warn(\"Could not store container [\" + container.getContainerId()\n            + \"] state. The Container has been paused.\", e);\n      }\n    } catch (Exception e) {\n      String message =\n          \"Exception when trying to pause container \" + containerIdStr\n              + \": \" + StringUtils.stringifyException(e);\n      LOG.info(message);\n      container.handle(new ContainerKillEvent(container.getContainerId(),\n          ContainerExitStatus.PREEMPTED, \"Container preempted as there was \"\n          + \" an exception in pausing it.\"));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.resumeContainer": "  public void resumeContainer() throws IOException {\n    ContainerId containerId = container.getContainerId();\n    String containerIdStr = containerId.toString();\n    LOG.info(\"Resuming the container \" + containerIdStr);\n\n    // The resume event is only handled if the container is in a paused state\n    // so we don't check for the launched flag here.\n\n    // paused flag will be set to true if process already paused\n    boolean alreadyPaused = !shouldPauseContainer.compareAndSet(false, true);\n    if (!alreadyPaused) {\n      LOG.info(\"Container \" + containerIdStr + \" not paused.\"\n          + \" No resume necessary\");\n      return;\n    }\n\n    // If the container has already started\n    try {\n      exec.resumeContainer(container);\n      // ResumeContainer is a blocking call. We are here almost means the\n      // container is resumed, so send out the event.\n      dispatcher.getEventHandler().handle(new ContainerEvent(\n          containerId,\n          ContainerEventType.CONTAINER_RESUMED));\n\n      try {\n        this.context.getNMStateStore().removeContainerPaused(\n            container.getContainerId());\n      } catch (IOException e) {\n        LOG.warn(\"Could not store container [\" + container.getContainerId()\n            + \"] state. The Container has been resumed.\", e);\n      }\n    } catch (Exception e) {\n      String message =\n          \"Exception when trying to resume container \" + containerIdStr\n              + \": \" + StringUtils.stringifyException(e);\n      LOG.info(message);\n      container.handle(new ContainerKillEvent(container.getContainerId(),\n          ContainerExitStatus.PREEMPTED, \"Container preempted as there was \"\n          + \" an exception in pausing it.\"));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Container cleanup fails while trying to delete Cgroups",
            "Description": "When an application failed to launch container successfully, the cleanup of container also failed with below message.\r\n{code}\r\n2018-08-06 03:28:20,351 WARN  resources.CGroupsHandlerImpl (CGroupsHandlerImpl.java:checkAndDeleteCgroup(523)) - Failed to read cgroup tasks file.\r\njava.io.FileNotFoundException: /sys/fs/cgroup/cpu,cpuacct/hadoop-yarn-tmp-cxx/container_e02_1533336898541_0010_20_000002/tasks (No such file or directory)\r\n        at java.io.FileInputStream.open0(Native Method)\r\n        at java.io.FileInputStream.open(FileInputStream.java:195)\r\n        at java.io.FileInputStream.<init>(FileInputStream.java:138)\r\n        at java.io.FileInputStream.<init>(FileInputStream.java:93)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.checkAndDeleteCgroup(CGroupsHandlerImpl.java:507)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.deleteCGroup(CGroupsHandlerImpl.java:542)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl.postComplete(CGroupsCpuResourceHandlerImpl.java:238)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.postComplete(ResourceHandlerChain.java:111)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.postComplete(LinuxContainerExecutor.java:964)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.reapContainer(LinuxContainerExecutor.java:787)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer(ContainerLaunch.java:821)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:161)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:57)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n2018-08-06 03:28:20,372 WARN  resources.CGroupsHandlerImpl (CGroupsHandlerImpl.java:checkAndDeleteCgroup(523)) - Failed to read cgroup tasks file.{code}"
        }
    },
    {
        "filename": "YARN-4431.json",
        "creation_time": "2015-12-07T18:31:36.000+0000",
        "stack_trace": "```\njava.net.ConnectException: Call From jduMBP.local/10.200.10.53 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n        at sun.reflect.GeneratedConstructorAccessor30.newInstance(Unknown Source)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:408)\n        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1452)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1385)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n        at com.sun.proxy.$Proxy74.unRegisterNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.unRegisterNodeManager(ResourceTrackerPBClientImpl.java:98)\n        at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:483)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:255)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy75.unRegisterNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.unRegisterNM(NodeStatusUpdaterImpl.java:267)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStop(NodeStatusUpdaterImpl.java:245)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:377)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.wrapWithMessage": "  private static <T extends IOException> T wrapWithMessage(\n      T exception, String msg) {\n    Class<? extends Throwable> clazz = exception.getClass();\n    try {\n      Constructor<? extends Throwable> ctor = clazz.getConstructor(String.class);\n      Throwable t = ctor.newInstance(msg);\n      return (T)(t.initCause(exception));\n    } catch (Throwable e) {\n      LOG.warn(\"Unable to wrap exception of type \" +\n          clazz + \": it has no (String) constructor\", e);\n      return exception;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.wrapException": "  public static IOException wrapException(final String destHost,\n                                          final int destPort,\n                                          final String localHost,\n                                          final int localPort,\n                                          final IOException exception) {\n    if (exception instanceof BindException) {\n      return wrapWithMessage(exception,\n          \"Problem binding to [\"\n              + localHost\n              + \":\"\n              + localPort\n              + \"] \"\n              + exception\n              + \";\"\n              + see(\"BindException\"));\n    } else if (exception instanceof ConnectException) {\n      // connection refused; include the host:port in the error\n      return wrapWithMessage(exception, \n          \"Call From \"\n              + localHost\n              + \" to \"\n              + destHost\n              + \":\"\n              + destPort\n              + \" failed on connection exception: \"\n              + exception\n              + \";\"\n              + see(\"ConnectionRefused\"));\n    } else if (exception instanceof UnknownHostException) {\n      return wrapWithMessage(exception,\n          \"Invalid host name: \"\n              + getHostDetailsAsString(destHost, destPort, localHost)\n              + exception\n              + \";\"\n              + see(\"UnknownHost\"));\n    } else if (exception instanceof SocketTimeoutException) {\n      return wrapWithMessage(exception,\n          \"Call From \"\n              + localHost + \" to \" + destHost + \":\" + destPort\n              + \" failed on socket timeout exception: \" + exception\n              + \";\"\n              + see(\"SocketTimeout\"));\n    } else if (exception instanceof NoRouteToHostException) {\n      return wrapWithMessage(exception,\n          \"No Route to Host from  \"\n              + localHost + \" to \" + destHost + \":\" + destPort\n              + \" failed on socket timeout exception: \" + exception\n              + \";\"\n              + see(\"NoRouteToHost\"));\n    } else if (exception instanceof EOFException) {\n      return wrapWithMessage(exception,\n          \"End of File Exception between \"\n              + getHostDetailsAsString(destHost,  destPort, localHost)\n              + \": \" + exception\n              + \";\"\n              + see(\"EOFException\"));\n    }\n    else {\n      return (IOException) new IOException(\"Failed on local exception: \"\n                                               + exception\n                                               + \"; Host Details : \"\n                                               + getHostDetailsAsString(destHost, destPort, localHost))\n          .initCause(exception);\n\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.see": "  private static String see(final String entry) {\n    return FOR_MORE_DETAILS_SEE + HADOOP_WIKI + entry;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.getHostDetailsAsString": "  private static String getHostDetailsAsString(final String destHost,\n                                               final int destPort,\n                                               final String localHost) {\n    StringBuilder hostDetails = new StringBuilder(27);\n    hostDetails.append(\"local host is: \")\n        .append(quoteHost(localHost))\n        .append(\"; \");\n    hostDetails.append(\"destination host is: \").append(quoteHost(destHost))\n        .append(\":\")\n        .append(destPort).append(\"; \");\n    return hostDetails.toString();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.call": "  public Writable call(RPC.RpcKind rpcKind, Writable rpcRequest,\n      ConnectionId remoteId, int serviceClass,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    final Call call = createCall(rpcKind, rpcRequest);\n    Connection connection = getConnection(remoteId, call, serviceClass,\n      fallbackToSimpleAuth);\n    try {\n      connection.sendRpcRequest(call);                 // send the rpc request\n    } catch (RejectedExecutionException e) {\n      throw new IOException(\"connection has been closed\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      LOG.warn(\"interrupted waiting to send rpc request to server\", e);\n      throw new IOException(e);\n    }\n\n    synchronized (call) {\n      while (!call.done) {\n        try {\n          call.wait();                           // wait for the result\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\"Call interrupted\");\n        }\n      }\n\n      if (call.error != null) {\n        if (call.error instanceof RemoteException) {\n          call.error.fillInStackTrace();\n          throw call.error;\n        } else { // local exception\n          InetSocketAddress address = connection.getRemoteAddress();\n          throw NetUtils.wrapException(address.getHostName(),\n                  address.getPort(),\n                  NetUtils.getHostname(),\n                  0,\n                  call.error);\n        }\n      } else {\n        return call.getRpcResponse();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRpcResponse": "    public synchronized Writable getRpcResponse() {\n      return rpcResponse;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRemoteAddress": "    public InetSocketAddress getRemoteAddress() {\n      return server;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnection": "  private Connection getConnection(ConnectionId remoteId,\n      Call call, int serviceClass, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    while (true) {\n      // These lines below can be shorten with computeIfAbsent in Java8\n      connection = connections.get(remoteId);\n      if (connection == null) {\n        connection = new Connection(remoteId, serviceClass);\n        Connection existing = connections.putIfAbsent(remoteId, connection);\n        if (existing != null) {\n          connection = existing;\n        }\n      }\n\n      if (connection.addCall(call)) {\n        break;\n      } else {\n        // This connection is closed, should be removed. But other thread could\n        // have already known this closedConnection, and replace it with a new\n        // connection. So we should call conditional remove to make sure we only\n        // remove this closedConnection.\n        connections.remove(remoteId, connection);\n      }\n    }\n\n    // If the server happens to be slow, the method below will take longer to\n    // establish a connection.\n    connection.setupIOstreams(fallbackToSimpleAuth);\n    return connection;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnectionId": "    static ConnectionId getConnectionId(InetSocketAddress addr,\n        Class<?> protocol, UserGroupInformation ticket, int rpcTimeout,\n        RetryPolicy connectionRetryPolicy, Configuration conf) throws IOException {\n\n      if (connectionRetryPolicy == null) {\n        final int max = conf.getInt(\n            CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_KEY,\n            CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_DEFAULT);\n        final int retryInterval = conf.getInt(\n            CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_RETRY_INTERVAL_KEY,\n            CommonConfigurationKeysPublic\n                .IPC_CLIENT_CONNECT_RETRY_INTERVAL_DEFAULT);\n\n        connectionRetryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n            max, retryInterval, TimeUnit.MILLISECONDS);\n      }\n\n      return new ConnectionId(addr, protocol, ticket, rpcTimeout,\n          connectionRetryPolicy, conf);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.createCall": "  Call createCall(RPC.RpcKind rpcKind, Writable rpcRequest) {\n    return new Call(rpcKind, rpcRequest);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.sendRpcRequest": "    public void sendRpcRequest(final Call call)\n        throws InterruptedException, IOException {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n\n      // Serialize the call to be sent. This is done from the actual\n      // caller thread, rather than the sendParamsExecutor thread,\n      \n      // so that if the serialization throws an error, it is reported\n      // properly. This also parallelizes the serialization.\n      //\n      // Format of a call on the wire:\n      // 0) Length of rest below (1 + 2)\n      // 1) RpcRequestHeader  - is serialized Delimited hence contains length\n      // 2) RpcRequest\n      //\n      // Items '1' and '2' are prepared here. \n      final DataOutputBuffer d = new DataOutputBuffer();\n      RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader(\n          call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry,\n          clientId);\n      header.writeDelimitedTo(d);\n      call.rpcRequest.write(d);\n\n      synchronized (sendRpcRequestLock) {\n        Future<?> senderFuture = sendParamsExecutor.submit(new Runnable() {\n          @Override\n          public void run() {\n            try {\n              synchronized (Connection.this.out) {\n                if (shouldCloseConnection.get()) {\n                  return;\n                }\n                \n                if (LOG.isDebugEnabled())\n                  LOG.debug(getName() + \" sending #\" + call.id);\n         \n                byte[] data = d.getData();\n                int totalLength = d.getLength();\n                out.writeInt(totalLength); // Total Length\n                out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest\n                out.flush();\n              }\n            } catch (IOException e) {\n              // exception at this point would leave the connection in an\n              // unrecoverable state (eg half a call left on the wire).\n              // So, close the connection, killing any outstanding calls\n              markClosed(e);\n            } finally {\n              //the buffer is just an in-memory buffer, but it is still polite to\n              // close early\n              IOUtils.closeStream(d);\n            }\n          }\n        });\n      \n        try {\n          senderFuture.get();\n        } catch (ExecutionException e) {\n          Throwable cause = e.getCause();\n          \n          // cause should only be a RuntimeException as the Runnable above\n          // catches IOException\n          if (cause instanceof RuntimeException) {\n            throw (RuntimeException) cause;\n          } else {\n            throw new RuntimeException(\"unexpected checked exception\", cause);\n          }\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.invoke": "    public Object invoke(Object proxy, Method method, Object[] args)\n        throws ServiceException {\n      long startTime = 0;\n      if (LOG.isDebugEnabled()) {\n        startTime = Time.now();\n      }\n      \n      if (args.length != 2) { // RpcController + Message\n        throw new ServiceException(\"Too many parameters for request. Method: [\"\n            + method.getName() + \"]\" + \", Expected: 2, Actual: \"\n            + args.length);\n      }\n      if (args[1] == null) {\n        throw new ServiceException(\"null param while calling Method: [\"\n            + method.getName() + \"]\");\n      }\n\n      // if Tracing is on then start a new span for this rpc.\n      // guard it in the if statement to make sure there isn't\n      // any extra string manipulation.\n      Tracer tracer = Tracer.curThreadTracer();\n      TraceScope traceScope = null;\n      if (tracer != null) {\n        traceScope = tracer.newScope(RpcClientUtil.methodToTraceString(method));\n      }\n\n      RequestHeaderProto rpcRequestHeader = constructRpcRequestHeader(method);\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(Thread.currentThread().getId() + \": Call -> \" +\n            remoteId + \": \" + method.getName() +\n            \" {\" + TextFormat.shortDebugString((Message) args[1]) + \"}\");\n      }\n\n\n      Message theRequest = (Message) args[1];\n      final RpcResponseWrapper val;\n      try {\n        val = (RpcResponseWrapper) client.call(RPC.RpcKind.RPC_PROTOCOL_BUFFER,\n            new RpcRequestWrapper(rpcRequestHeader, theRequest), remoteId,\n            fallbackToSimpleAuth);\n\n      } catch (Throwable e) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Exception <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + e + \"}\");\n        }\n        if (traceScope != null) {\n          traceScope.addTimelineAnnotation(\"Call got exception: \" +\n              e.toString());\n        }\n        throw new ServiceException(e);\n      } finally {\n        if (traceScope != null) traceScope.close();\n      }\n\n      if (LOG.isDebugEnabled()) {\n        long callTime = Time.now() - startTime;\n        LOG.debug(\"Call: \" + method.getName() + \" took \" + callTime + \"ms\");\n      }\n      \n      Message prototype = null;\n      try {\n        prototype = getReturnProtoType(method);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      Message returnMessage;\n      try {\n        returnMessage = prototype.newBuilderForType()\n            .mergeFrom(val.theResponseRead).build();\n\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Response <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + TextFormat.shortDebugString(returnMessage) + \"}\");\n        }\n\n      } catch (Throwable e) {\n        throw new ServiceException(e);\n      }\n      return returnMessage;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getReturnProtoType": "    private Message getReturnProtoType(Method method) throws Exception {\n      if (returnTypes.containsKey(method.getName())) {\n        return returnTypes.get(method.getName());\n      }\n      \n      Class<?> returnType = method.getReturnType();\n      Method newInstMethod = returnType.getMethod(\"getDefaultInstance\");\n      newInstMethod.setAccessible(true);\n      Message prototype = (Message) newInstMethod.invoke(null, (Object[]) null);\n      returnTypes.put(method.getName(), prototype);\n      return prototype;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcRequestWrapper request = (RpcRequestWrapper) writableRequest;\n        RequestHeaderProto rpcRequest = request.requestHeader;\n        String methodName = rpcRequest.getMethodName();\n        \n        \n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = prototype.newBuilderForType()\n            .mergeFrom(request.theRequestRead).build();\n        \n        Message result;\n        long startTime = Time.now();\n        int qTime = (int) (startTime - receiveTime);\n        Exception exception = null;\n        try {\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n        } catch (ServiceException e) {\n          exception = (Exception) e.getCause();\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          exception = e;\n          throw e;\n        } finally {\n          int processingTime = (int) (Time.now() - startTime);\n          if (LOG.isDebugEnabled()) {\n            String msg = \"Served: \" + methodName + \" queueTime= \" + qTime +\n                \" procesingTime= \" + processingTime;\n            if (exception != null) {\n              msg += \" exception= \" + exception.getClass().getSimpleName();\n            }\n            LOG.debug(msg);\n          }\n          String detailedMetricsName = (exception == null) ?\n              methodName :\n              exception.getClass().getSimpleName();\n          server.rpcMetrics.addRpcQueueTime(qTime);\n          server.rpcMetrics.addRpcProcessingTime(processingTime);\n          server.rpcDetailedMetrics.addProcessingTime(detailedMetricsName,\n              processingTime);\n          if (server.isLogSlowRPC()) {\n            server.logSlowRpcCalls(methodName, processingTime);\n          }\n        }\n        return new RpcResponseWrapper(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.close": "    public void close() throws IOException {\n      if (!isClosed) {\n        isClosed = true;\n        CLIENTS.stopClient(client);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.toString": "    public String toString() {\n      return requestHeader.getDeclaringClassProtocolName() + \".\" +\n          requestHeader.getMethodName();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.constructRpcRequestHeader": "    private RequestHeaderProto constructRpcRequestHeader(Method method) {\n      RequestHeaderProto.Builder builder = RequestHeaderProto\n          .newBuilder();\n      builder.setMethodName(method.getName());\n     \n\n      // For protobuf, {@code protocol} used when creating client side proxy is\n      // the interface extending BlockingInterface, which has the annotations \n      // such as ProtocolName etc.\n      //\n      // Using Method.getDeclaringClass(), as in WritableEngine to get at\n      // the protocol interface will return BlockingInterface, from where \n      // the annotation ProtocolName and Version cannot be\n      // obtained.\n      //\n      // Hence we simply use the protocol class used to create the proxy.\n      // For PB this may limit the use of mixins on client side.\n      builder.setDeclaringClassProtocolName(protocolName);\n      builder.setClientProtocolVersion(clientProtocolVersion);\n      return builder.build();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.unRegisterNodeManager": "  public UnRegisterNodeManagerResponse unRegisterNodeManager(\n      UnRegisterNodeManagerRequest request) throws YarnException, IOException {\n    UnRegisterNodeManagerRequestProto requestProto =\n        ((UnRegisterNodeManagerRequestPBImpl) request).getProto();\n    try {\n      return new UnRegisterNodeManagerResponsePBImpl(\n          proxy.unRegisterNodeManager(null, requestProto));\n    } catch (ServiceException e) {\n      RPCUtil.unwrapAndThrowException(e);\n      return null;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod": "  protected Object invokeMethod(Method method, Object[] args) throws Throwable {\n    try {\n      if (!method.isAccessible()) {\n        method.setAccessible(true);\n      }\n      return method.invoke(currentProxy.proxy, args);\n    } catch (InvocationTargetException e) {\n      throw e.getCause();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invoke": "  public Object invoke(Object proxy, Method method, Object[] args)\n    throws Throwable {\n    RetryPolicy policy = methodNameToPolicyMap.get(method.getName());\n    if (policy == null) {\n      policy = defaultPolicy;\n    }\n    \n    // The number of times this method invocation has been failed over.\n    int invocationFailoverCount = 0;\n    final boolean isRpc = isRpcInvocation(currentProxy.proxy);\n    final int callId = isRpc? Client.nextCallId(): RpcConstants.INVALID_CALL_ID;\n    int retries = 0;\n    while (true) {\n      // The number of times this invocation handler has ever been failed over,\n      // before this method invocation attempt. Used to prevent concurrent\n      // failed method invocations from triggering multiple failover attempts.\n      long invocationAttemptFailoverCount;\n      synchronized (proxyProvider) {\n        invocationAttemptFailoverCount = proxyProviderFailoverCount;\n      }\n\n      if (isRpc) {\n        Client.setCallIdAndRetryCount(callId, retries);\n      }\n      try {\n        Object ret = invokeMethod(method, args);\n        hasMadeASuccessfulCall = true;\n        return ret;\n      } catch (Exception ex) {\n        if (Thread.currentThread().isInterrupted()) {\n          // If interrupted, do not retry.\n          throw ex;\n        }\n        boolean isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n            .getMethod(method.getName(), method.getParameterTypes())\n            .isAnnotationPresent(Idempotent.class);\n        if (!isIdempotentOrAtMostOnce) {\n          isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n              .getMethod(method.getName(), method.getParameterTypes())\n              .isAnnotationPresent(AtMostOnce.class);\n        }\n        List<RetryAction> actions = extractActions(policy, ex, retries++,\n                invocationFailoverCount, isIdempotentOrAtMostOnce);\n        RetryAction failAction = getFailAction(actions);\n        if (failAction != null) {\n          if (failAction.reason != null) {\n            LOG.warn(\"Exception while invoking \" + currentProxy.proxy.getClass()\n                + \".\" + method.getName() + \" over \" + currentProxy.proxyInfo\n                + \". Not retrying because \" + failAction.reason, ex);\n          }\n          throw ex;\n        } else { // retry or failover\n          // avoid logging the failover if this is the first call on this\n          // proxy object, and we successfully achieve the failover without\n          // any flip-flopping\n          boolean worthLogging = \n            !(invocationFailoverCount == 0 && !hasMadeASuccessfulCall);\n          worthLogging |= LOG.isDebugEnabled();\n          RetryAction failOverAction = getFailOverAction(actions);\n          long delay = getDelayMillis(actions);\n          if (failOverAction != null && worthLogging) {\n            String msg = \"Exception while invoking \" + method.getName()\n                + \" of class \" + currentProxy.proxy.getClass().getSimpleName()\n                + \" over \" + currentProxy.proxyInfo;\n\n            if (invocationFailoverCount > 0) {\n              msg += \" after \" + invocationFailoverCount + \" fail over attempts\"; \n            }\n            msg += \". Trying to fail over \" + formatSleepMessage(delay);\n            LOG.info(msg, ex);\n          } else {\n            if(LOG.isDebugEnabled()) {\n              LOG.debug(\"Exception while invoking \" + method.getName()\n                  + \" of class \" + currentProxy.proxy.getClass().getSimpleName()\n                  + \" over \" + currentProxy.proxyInfo + \". Retrying \"\n                  + formatSleepMessage(delay), ex);\n            }\n          }\n\n          if (delay > 0) {\n            Thread.sleep(delay);\n          }\n          \n          if (failOverAction != null) {\n            // Make sure that concurrent failed method invocations only cause a\n            // single actual fail over.\n            synchronized (proxyProvider) {\n              if (invocationAttemptFailoverCount == proxyProviderFailoverCount) {\n                proxyProvider.performFailover(currentProxy.proxy);\n                proxyProviderFailoverCount++;\n              } else {\n                LOG.warn(\"A failover has occurred since the start of this method\"\n                    + \" invocation attempt.\");\n              }\n              currentProxy = proxyProvider.getProxy();\n            }\n            invocationFailoverCount++;\n          }\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.unRegisterNM": "  private void unRegisterNM() {\n    RecordFactory recordFactory = RecordFactoryPBImpl.get();\n    UnRegisterNodeManagerRequest request = recordFactory\n        .newRecordInstance(UnRegisterNodeManagerRequest.class);\n    request.setNodeId(this.nodeId);\n    try {\n      resourceTracker.unRegisterNodeManager(request);\n      LOG.info(\"Successfully Unregistered the Node \" + this.nodeId\n          + \" with ResourceManager.\");\n    } catch (Exception e) {\n      LOG.warn(\"Unregistration of the Node \" + this.nodeId + \" failed.\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStop": "  protected void serviceStop() throws Exception {\n    // the isStopped check is for avoiding multiple unregistrations.\n    if (this.registeredWithRM && !this.isStopped\n        && !isNMUnderSupervisionWithRecoveryEnabled()\n        && !context.getDecommissioned()) {\n      unRegisterNM();\n    }\n    // Interrupt the updater.\n    this.isStopped = true;\n    stopRMProxy();\n    super.serviceStop();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stopRMProxy": "  protected void stopRMProxy() {\n    if(this.resourceTracker != null) {\n      RPC.stopProxy(this.resourceTracker);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.isNMUnderSupervisionWithRecoveryEnabled": "  private boolean isNMUnderSupervisionWithRecoveryEnabled() {\n    Configuration config = getConfig();\n    return config.getBoolean(YarnConfiguration.NM_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_NM_RECOVERY_ENABLED)\n        && config.getBoolean(YarnConfiguration.NM_RECOVERY_SUPERVISED,\n            YarnConfiguration.DEFAULT_NM_RECOVERY_SUPERVISED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.stop": "  public void stop() {\n    if (isInState(STATE.STOPPED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.STOPPED) != STATE.STOPPED) {\n        try {\n          serviceStop();\n        } catch (Exception e) {\n          //stop-time exceptions are logged if they are the first one,\n          noteFailure(e);\n          throw ServiceStateException.convert(e);\n        } finally {\n          //report that the service has terminated\n          terminationNotification.set(true);\n          synchronized (terminationNotification) {\n            terminationNotification.notifyAll();\n          }\n          //notify anything listening for events\n          notifyListeners();\n        }\n      } else {\n        //already stopped: note it\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring re-entrant call to stop()\");\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStop": "  protected void serviceStop() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.stop": "  private void stop(int numOfServicesStarted, boolean stopOnlyStartedServices) {\n    // stop in reverse order of start\n    Exception firstException = null;\n    List<Service> services = getServices();\n    for (int i = numOfServicesStarted - 1; i >= 0; i--) {\n      Service service = services.get(i);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Stopping service #\" + i + \": \" + service);\n      }\n      STATE state = service.getServiceState();\n      //depending on the stop police\n      if (state == STATE.STARTED \n         || (!stopOnlyStartedServices && state == STATE.INITED)) {\n        Exception ex = ServiceOperations.stopQuietly(LOG, service);\n        if (ex != null && firstException == null) {\n          firstException = ex;\n        }\n      }\n    }\n    //after stopping all services, rethrow the first exception raised\n    if (firstException != null) {\n      throw ServiceStateException.convert(firstException);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceStop": "  protected void serviceStop() throws Exception {\n    //stop all services that were started\n    int numOfServicesToStop = serviceList.size();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": stopping services, size=\" + numOfServicesToStop);\n    }\n    stop(numOfServicesToStop, STOP_ONLY_STARTED_SERVICES);\n    super.serviceStop();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop": "  protected void serviceStop() throws Exception {\n    if (isStopping.getAndSet(true)) {\n      return;\n    }\n    try {\n      super.serviceStop();\n      DefaultMetricsSystem.shutdown();\n    } finally {\n      // YARN-3641: NM's services stop get failed shouldn't block the\n      // release of NMLevelDBStore.\n      stopRecoveryStore();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.stopRecoveryStore": "  private void stopRecoveryStore() throws IOException {\n    if (null != nmStore) {\n      nmStore.stop();\n      if (null != context) {\n        if (context.getDecommissioned() && nmStore.canRecover()) {\n          LOG.info(\"Removing state store due to decommission\");\n          Configuration conf = getConfig();\n          Path recoveryRoot =\n              new Path(conf.get(YarnConfiguration.NM_RECOVERY_DIR));\n          LOG.info(\"Removing state store at \" + recoveryRoot\n              + \" due to decommission\");\n          FileSystem recoveryFs = FileSystem.getLocal(conf);\n          if (!recoveryFs.delete(recoveryRoot, true)) {\n            LOG.warn(\"Unable to delete \" + recoveryRoot);\n          }\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcClientUtil.methodToTraceString": "  public static String methodToTraceString(Method method) {\n    Class<?> clazz = method.getDeclaringClass();\n    while (true) {\n      Class<?> next = clazz.getEnclosingClass();\n      if (next == null || next.getEnclosingClass() == null) break;\n      clazz = next;\n    }\n    return clazz.getSimpleName() + \"#\" + method.getName();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.context.getDecommissioned": "  boolean getDecommissioned();\n\n  void setDecommissioned(boolean isDecommissioned);\n\n  ConcurrentLinkedQueue<LogAggregationReport>\n      getLogAggregationStatusForApps();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.service.getName": "  String getName();\n\n  /**\n   * Get the configuration of this service.\n   * This is normally not a clone and may be manipulated, though there are no\n   * guarantees as to what the consequences of such actions may be\n   * @return the current configuration, unless a specific implentation chooses\n   * otherwise.\n   */\n  Configuration getConfig();\n\n  /**\n   * Get the current service state\n   * @return the state of the service\n   */\n  STATE getServiceState();\n\n  /**\n   * Get the service start time\n   * @return the start time of the service. This will be zero if the service\n   * has not yet been started.\n   */\n  long getStartTime();\n\n  /**\n   * Query to see if the service is in a specific state.\n   * In a multi-threaded system, the state may not hold for very long.\n   * @param state the expected state\n   * @return true if, at the time of invocation, the service was in that state.\n   */\n  boolean isInState(STATE state);\n\n  /**\n   * Get the first exception raised during the service failure. If null,\n   * no exception was logged\n   * @return the failure logged during a transition to the stopped state\n   */\n  Throwable getFailureCause();\n\n  /**\n   * Get the state in which the failure in {@link #getFailureCause()} occurred.",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.getServiceState": "  STATE getServiceState();\n\n  /**\n   * Get the service start time\n   * @return the start time of the service. This will be zero if the service\n   * has not yet been started.\n   */\n  long getStartTime();\n\n  /**\n   * Query to see if the service is in a specific state.\n   * In a multi-threaded system, the state may not hold for very long.\n   * @param state the expected state\n   * @return true if, at the time of invocation, the service was in that state.\n   */\n  boolean isInState(STATE state);\n\n  /**\n   * Get the first exception raised during the service failure. If null,\n   * no exception was logged\n   * @return the failure logged during a transition to the stopped state\n   */\n  Throwable getFailureCause();\n\n  /**\n   * Get the state in which the failure in {@link #getFailureCause()} occurred."
        },
        "bug_report": {
            "Title": "Not necessary to do unRegisterNM() if NM get stop due to failed to connect to RM",
            "Description": "{noformat}\n2015-12-07 12:16:57,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n2015-12-07 12:16:58,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n2015-12-07 12:16:58,876 WARN org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Unregistration of the Node 10.200.10.53:25454 failed.\njava.net.ConnectException: Call From jduMBP.local/10.200.10.53 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n        at sun.reflect.GeneratedConstructorAccessor30.newInstance(Unknown Source)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:408)\n        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1452)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1385)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n        at com.sun.proxy.$Proxy74.unRegisterNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.unRegisterNodeManager(ResourceTrackerPBClientImpl.java:98)\n        at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:483)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:255)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy75.unRegisterNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.unRegisterNM(NodeStatusUpdaterImpl.java:267)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStop(NodeStatusUpdaterImpl.java:245)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:377)\n{noformat}\nIf RM down for some reason, NM's NodeStatusUpdaterImpl will retry the connection with proper retry policy. After retry the maximum times (15 minutes by default), it will send NodeManagerEventType.SHUTDOWN to shutdown NM. But NM shutdown will call NodeStatusUpdaterImpl.serviceStop() which will call unRegisterNM() to unregister NM from RM and get retry again (another 15 minutes). This is completely unnecessary and we should skip unRegisterNM when NM get shutdown because of connection issues."
        }
    },
    {
        "filename": "YARN-2273.json",
        "creation_time": "2014-07-10T18:38:53.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$NodeAvailableResourceComparator.compare(FairScheduler.java:1044)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$NodeAvailableResourceComparator.compare(FairScheduler.java:1040)\n\tat java.util.TimSort.countRunAndMakeAscending(TimSort.java:329)\n\tat java.util.TimSort.sort(TimSort.java:203)\n\tat java.util.TimSort.sort(TimSort.java:173)\n\tat java.util.Arrays.sort(Arrays.java:659)\n\tat java.util.Collections.sort(Collections.java:217)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousScheduling(FairScheduler.java:1012)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.access$600(FairScheduler.java:124)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$2.run(FairScheduler.java:1306)\n\tat java.lang.Thread.run(Thread.java:744)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.compare": "    public int compare(NodeId n1, NodeId n2) {\n      return RESOURCE_CALCULATOR.compare(clusterResource,\n              nodes.get(n2).getAvailableResource(),\n              nodes.get(n1).getAvailableResource());\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousScheduling": "  private void continuousScheduling() {\n    while (true) {\n      List<NodeId> nodeIdList = new ArrayList<NodeId>(nodes.keySet());\n      // Sort the nodes by space available on them, so that we offer\n      // containers on emptier nodes first, facilitating an even spread. This\n      // requires holding the scheduler lock, so that the space available on a\n      // node doesn't change during the sort.\n      synchronized (this) {\n        Collections.sort(nodeIdList, nodeAvailableResourceComparator);\n      }\n\n      // iterate all nodes\n      for (NodeId nodeId : nodeIdList) {\n        if (nodes.containsKey(nodeId)) {\n          FSSchedulerNode node = getFSSchedulerNode(nodeId);\n          try {\n            if (Resources.fitsIn(minimumAllocation,\n                    node.getAvailableResource())) {\n              attemptScheduling(node);\n            }\n          } catch (Throwable ex) {\n            LOG.warn(\"Error while attempting scheduling for node \" + node +\n                    \": \" + ex.toString(), ex);\n          }\n        }\n      }\n      try {\n        Thread.sleep(getContinuousSchedulingSleepMs());\n      } catch (InterruptedException e) {\n        LOG.warn(\"Error while doing sleep in continuous scheduling: \" +\n                e.toString(), e);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getContinuousSchedulingSleepMs": "  public synchronized int getContinuousSchedulingSleepMs() {\n    return continuousSchedulingSleepMs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling": "  private synchronized void attemptScheduling(FSSchedulerNode node) {\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    AppSchedulable reservedAppSchedulable = node.getReservedAppSchedulable();\n    if (reservedAppSchedulable != null) {\n      Priority reservedPriority = node.getReservedContainer().getReservedPriority();\n      if (!reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n        // Don't hold the reservation if app can no longer use it\n        LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n            + \" on node \" + node);\n        reservedAppSchedulable.unreserve(reservedPriority, node);\n        reservedAppSchedulable = null;\n      } else {\n        // Reservation exists; try to fulfill the reservation\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Trying to fulfill reservation for application \"\n              + reservedAppSchedulable.getApp().getApplicationAttemptId()\n              + \" on node: \" + node);\n        }\n        \n        node.getReservedAppSchedulable().assignReservedContainer(node);\n      }\n    }\n    if (reservedAppSchedulable == null) {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers = 0;\n      while (node.getReservedContainer() == null) {\n        boolean assignedContainer = false;\n        if (!queueMgr.getRootQueue().assignContainer(node).equals(\n            Resources.none())) {\n          assignedContainers++;\n          assignedContainer = true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers >= maxAssign) && (maxAssign > 0)) { break; }\n      }\n    }\n    updateRootQueueMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getFSSchedulerNode": "  private FSSchedulerNode getFSSchedulerNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.run": "            public void run() {\n              continuousScheduling();\n            }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update": "  protected synchronized void update() {\n    updatePreemptionVariables(); // Determine if any queues merit preemption\n\n    FSQueue rootQueue = queueMgr.getRootQueue();\n\n    // Recursively update demands for all queues\n    rootQueue.updateDemand();\n\n    rootQueue.setFairShare(clusterResource);\n    // Recursively compute fair shares for all queues\n    // and update metrics\n    rootQueue.recomputeShares();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.preemptTasksIfNecessary": "  protected synchronized void preemptTasksIfNecessary() {\n    if (!shouldAttemptPreemption()) {\n      return;\n    }\n\n    long curTime = clock.getTime();\n    if (curTime - lastPreemptCheckTime < preemptionInterval) {\n      return;\n    }\n    lastPreemptCheckTime = curTime;\n\n    Resource resToPreempt = Resources.clone(Resources.none());\n    for (FSLeafQueue sched : queueMgr.getLeafQueues()) {\n      Resources.addTo(resToPreempt, resToPreempt(sched, curTime));\n    }\n    if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterResource, resToPreempt,\n        Resources.none())) {\n      preemptResources(resToPreempt);\n    }\n  }"
        },
        "bug_report": {
            "Title": "NPE in ContinuousScheduling thread when we lose a node",
            "Description": "One DN experienced memory errors and entered a cycle of rebooting and rejoining the cluster. After the second time the node went away, the RM produced this:\n{code}\n2014-07-09 21:47:36,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Application attempt appattempt_1404858438119_4352_000001 released container container_1404858438119_4352_01_000004 on node: host: node-A16-R09-19.hadoop.dfw.wordpress.com:8041 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: KILL\n2014-07-09 21:47:36,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Removed node node-A16-R09-19.hadoop.dfw.wordpress.com:8041 cluster capacity: <memory:335872, vCores:328>\n2014-07-09 21:47:36,571 ERROR org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[ContinuousScheduling,5,main] threw an Exception.\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$NodeAvailableResourceComparator.compare(FairScheduler.java:1044)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$NodeAvailableResourceComparator.compare(FairScheduler.java:1040)\n\tat java.util.TimSort.countRunAndMakeAscending(TimSort.java:329)\n\tat java.util.TimSort.sort(TimSort.java:203)\n\tat java.util.TimSort.sort(TimSort.java:173)\n\tat java.util.Arrays.sort(Arrays.java:659)\n\tat java.util.Collections.sort(Collections.java:217)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousScheduling(FairScheduler.java:1012)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.access$600(FairScheduler.java:124)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$2.run(FairScheduler.java:1306)\n\tat java.lang.Thread.run(Thread.java:744)\n{code}\n\nA few cycles later YARN was crippled. The RM was running and jobs could be submitted but containers were not assigned and no progress was made. Restarting the RM resolved it."
        }
    },
    {
        "filename": "YARN-2834.json",
        "creation_time": "2014-11-09T06:07:01.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:734)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1089)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:114)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1041)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1005)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:757)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts(RMAppImpl.java:821)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.access$1900(RMAppImpl.java:101)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:843)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:826)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:701)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:312)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:413)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1207)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:590)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1014)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1051)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1047)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1047)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1091)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1226)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    CSQueue queue = (CSQueue) application.getQueue();\n\n    FiCaSchedulerApp attempt =\n        new FiCaSchedulerApp(applicationAttemptId, application.getUser(),\n          queue, queue.getActiveUsersManager(), rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n        .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    queue.submitApplicationAttempt(attempt, application.getUser());\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user \" + application.getUser() + \" in queue \"\n        + queue.getQueueName());\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public synchronized CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return queues.get(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      RMNode node = nodeUpdatedEvent.getRMNode();\n      nodeUpdate(node);\n      if (!scheduleAsynchronously) {\n        allocateContainersToNode(getNode(node.getNodeID()));\n      }\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName,\n            appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent = \n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId), \n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId, \n              SchedulerUtils.EXPIRED_CONTAINER), \n          RMContainerEventType.EXPIRE);\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.transition": "    public void\n        transition(RMAppAttemptImpl appAttempt, RMAppAttemptEvent event) {\n      if (appAttempt.targetedFinalState.equals(RMAppAttemptState.FAILED)\n          || appAttempt.targetedFinalState.equals(RMAppAttemptState.KILLED)) {\n        // ignore Container_Finished Event if we were supposed to reach\n        // FAILED/KILLED state.\n        return;\n      }\n\n      // pass in the earlier AMUnregistered Event also, as this is needed for\n      // AMFinishedAfterFinalSavingTransition later on\n      appAttempt.rememberTargetTransitions(event,\n        new AMFinishedAfterFinalSavingTransition(\n        appAttempt.eventCausingFinalSaving), RMAppAttemptState.FINISHED);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.updateInfoOnAMUnregister": "  private void updateInfoOnAMUnregister(RMAppAttemptEvent event) {\n    progress = 1.0f;\n    RMAppAttemptUnregistrationEvent unregisterEvent =\n        (RMAppAttemptUnregistrationEvent) event;\n    diagnostics.append(unregisterEvent.getDiagnostics());\n    originalTrackingUrl = sanitizeTrackingUrl(unregisterEvent.getFinalTrackingUrl());\n    proxiedTrackingUrl = generateProxyUriWithScheme(originalTrackingUrl);\n    finalStatus = unregisterEvent.getFinalApplicationStatus();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.sanitizeTrackingUrl": "  private static String sanitizeTrackingUrl(String url) {\n    return (url == null || url.trim().isEmpty()) ? \"N/A\" : url;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getSubmissionContext": "  public ApplicationSubmissionContext getSubmissionContext() {\n    return this.submissionContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.launchAttempt": "  private void launchAttempt(){\n    // Send event to launch the AM Container\n    eventHandler.handle(new AMLauncherEvent(AMLauncherEventType.LAUNCH, this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.sendAMContainerToNM": "  private void sendAMContainerToNM(RMAppAttemptImpl appAttempt,\n      RMAppAttemptContainerFinishedEvent containerFinishedEvent) {\n    NodeId nodeId = containerFinishedEvent.getNodeId();\n    finishedContainersSentToAM.putIfAbsent(nodeId,\n      new ArrayList<ContainerStatus>());\n    appAttempt.finishedContainersSentToAM.get(nodeId).add(\n      containerFinishedEvent.getContainerStatus());\n    if (!appAttempt.getSubmissionContext()\n      .getKeepContainersAcrossApplicationAttempts()) {\n      appAttempt.sendFinishedContainersToNM();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.invalidateAMHostAndPort": "  private void invalidateAMHostAndPort() {\n    this.host = \"N/A\";\n    this.rpcPort = -1;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setMasterContainer": "  public void setMasterContainer(Container container) {\n    masterContainer = container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.attemptLaunched": "  private void attemptLaunched() {\n    // Register with AMLivelinessMonitor\n    rmContext.getAMLivelinessMonitor().register(getAppAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getHost": "  public String getHost() {\n    this.readLock.lock();\n\n    try {\n      return this.host;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getProgress": "  public float getProgress() {\n    this.readLock.lock();\n\n    try {\n      return this.progress;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.storeAttempt": "  private void storeAttempt() {\n    // store attempt data in a non-blocking manner to prevent dispatcher\n    // thread starvation and wait for state to be saved\n    LOG.info(\"Storing attempt: AppId: \" + \n              getAppAttemptId().getApplicationId() \n              + \" AttemptId: \" + \n              getAppAttemptId()\n              + \" MasterContainer: \" + masterContainer);\n    rmContext.getStateStore().storeNewApplicationAttempt(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setAMContainerCrashedDiagnosticsAndExitStatus": "  private void setAMContainerCrashedDiagnosticsAndExitStatus(\n      RMAppAttemptContainerFinishedEvent finishEvent) {\n    ContainerStatus status = finishEvent.getContainerStatus();\n    String diagnostics = getAMContainerCrashedDiagnostics(finishEvent);\n    this.diagnostics.append(diagnostics);\n    this.amContainerExitStatus = status.getExitStatus();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setTrackingUrlToRMAppPage": "  private void setTrackingUrlToRMAppPage() {\n    originalTrackingUrl = pjoin(\n        WebAppUtils.getResolvedRMWebAppURLWithScheme(conf),\n        \"cluster\", \"app\", getAppAttemptId().getApplicationId());\n    proxiedTrackingUrl = originalTrackingUrl;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.retryFetchingAMContainer": "  private void retryFetchingAMContainer(final RMAppAttemptImpl appAttempt) {\n    // start a new thread so that we are not blocking main dispatcher thread.\n    new Thread() {\n      @Override\n      public void run() {\n        try {\n          Thread.sleep(500);\n        } catch (InterruptedException e) {\n          LOG.warn(\"Interrupted while waiting to resend the\"\n              + \" ContainerAllocated Event.\");\n        }\n        appAttempt.eventHandler.handle(new RMAppAttemptContainerAllocatedEvent(\n          appAttempt.applicationAttemptId));\n      }\n    }.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAMExpiredDiagnostics": "  private static String getAMExpiredDiagnostics(RMAppAttemptEvent event) {\n    String diag =\n        \"ApplicationMaster for attempt \" + event.getApplicationAttemptId()\n            + \" timed out\";\n    return diag;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.shouldCountTowardsMaxAttemptRetry": "  public boolean shouldCountTowardsMaxAttemptRetry() {\n    try {\n      this.readLock.lock();\n      int exitStatus = getAMContainerExitStatus();\n      return !(exitStatus == ContainerExitStatus.PREEMPTED\n          || exitStatus == ContainerExitStatus.ABORTED\n          || exitStatus == ContainerExitStatus.DISKS_FAILED\n          || exitStatus == ContainerExitStatus.KILLED_BY_RESOURCEMANAGER);\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.addJustFinishedContainer": "  private static void addJustFinishedContainer(RMAppAttemptImpl appAttempt,\n      RMAppAttemptContainerFinishedEvent containerFinishedEvent) {\n    appAttempt.justFinishedContainers.putIfAbsent(containerFinishedEvent\n        .getNodeId(), new ArrayList<ContainerStatus>());\n    appAttempt.justFinishedContainers.get(containerFinishedEvent\n            .getNodeId()).add(containerFinishedEvent.getContainerStatus());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getClientTokenMasterKey": "  public SecretKey getClientTokenMasterKey() {\n    return this.clientTokenMasterKey;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitionsAndStoreState": "  private void rememberTargetTransitionsAndStoreState(RMAppAttemptEvent event,\n      Object transitionToDo, RMAppAttemptState targetFinalState,\n      RMAppAttemptState stateToBeStored) {\n\n    rememberTargetTransitions(event, transitionToDo, targetFinalState);\n    stateBeforeFinalSaving = getState();\n\n    // As of today, finalState, diagnostics, final-tracking-url and\n    // finalAppStatus are the only things that we store into the StateStore\n    // AFTER the initial saving on app-attempt-start\n    // These fields can be visible from outside only after they are saved in\n    // StateStore\n    String diags = null;\n    String finalTrackingUrl = null;\n    FinalApplicationStatus finalStatus = null;\n    int exitStatus = ContainerExitStatus.INVALID;\n    switch (event.getType()) {\n    case LAUNCH_FAILED:\n      RMAppAttemptLaunchFailedEvent launchFaileEvent =\n          (RMAppAttemptLaunchFailedEvent) event;\n      diags = launchFaileEvent.getMessage();\n      break;\n    case REGISTERED:\n      diags = getUnexpectedAMRegisteredDiagnostics();\n      break;\n    case UNREGISTERED:\n      RMAppAttemptUnregistrationEvent unregisterEvent =\n          (RMAppAttemptUnregistrationEvent) event;\n      diags = unregisterEvent.getDiagnostics();\n      finalTrackingUrl = sanitizeTrackingUrl(unregisterEvent.getFinalTrackingUrl());\n      finalStatus = unregisterEvent.getFinalApplicationStatus();\n      break;\n    case CONTAINER_FINISHED:\n      RMAppAttemptContainerFinishedEvent finishEvent =\n          (RMAppAttemptContainerFinishedEvent) event;\n      diags = getAMContainerCrashedDiagnostics(finishEvent);\n      exitStatus = finishEvent.getContainerStatus().getExitStatus();\n      break;\n    case KILL:\n      break;\n    case EXPIRE:\n      diags = getAMExpiredDiagnostics(event);\n      break;\n    default:\n      break;\n    }\n    AggregateAppResourceUsage resUsage =\n        this.attemptMetrics.getAggregateAppResourceUsage();\n    RMStateStore rmStore = rmContext.getStateStore();\n    setFinishTime(System.currentTimeMillis());\n    ApplicationAttemptState attemptState =\n        new ApplicationAttemptState(applicationAttemptId, getMasterContainer(),\n          rmStore.getCredentialsFromAppAttempt(this), startTime,\n          stateToBeStored, finalTrackingUrl, diags, finalStatus, exitStatus,\n          getFinishTime(), resUsage.getMemorySeconds(),\n          resUsage.getVcoreSeconds());\n    LOG.info(\"Updating application attempt \" + applicationAttemptId\n        + \" with final state: \" + targetedFinalState + \", and exit status: \"\n        + exitStatus);\n    rmStore.updateApplicationAttemptState(attemptState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getDiagnostics": "  public String getDiagnostics() {\n    this.readLock.lock();\n\n    try {\n      return this.diagnostics.toString();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.removeCredentials": "  private void removeCredentials(RMAppAttemptImpl appAttempt) {\n    // Unregister from the ClientToAMTokenSecretManager\n    if (UserGroupInformation.isSecurityEnabled()) {\n      appAttempt.rmContext.getClientToAMTokenSecretManager()\n        .unRegisterApplication(appAttempt.getAppAttemptId());\n    }\n\n    // Remove the AppAttempt from the AMRMTokenSecretManager\n    appAttempt.rmContext.getAMRMTokenSecretManager()\n      .applicationMasterFinished(appAttempt.getAppAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.generateProxyUriWithScheme": "  private String generateProxyUriWithScheme(\n      final String trackingUriWithoutScheme) {\n    this.readLock.lock();\n    try {\n      final String scheme = WebAppUtils.getHttpSchemePrefix(conf);\n      URI trackingUri = StringUtils.isEmpty(trackingUriWithoutScheme) ? null :\n        ProxyUriUtils.getUriFromAMUrl(scheme, trackingUriWithoutScheme);\n      String proxy = WebAppUtils.getProxyHostAndPort(conf);\n      URI proxyUri = ProxyUriUtils.getUriFromAMUrl(scheme, proxy);\n      URI result = ProxyUriUtils.getProxyUri(trackingUri, proxyUri,\n          applicationAttemptId.getApplicationId());\n      return result.toASCIIString();\n    } catch (URISyntaxException e) {\n      LOG.warn(\"Could not proxify \"+trackingUriWithoutScheme,e);\n      return trackingUriWithoutScheme;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getMasterContainer": "  public Container getMasterContainer() {\n    this.readLock.lock();\n\n    try {\n      return this.masterContainer;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptId": "  public ApplicationAttemptId getAppAttemptId() {\n    return this.applicationAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitions": "  private void rememberTargetTransitions(RMAppAttemptEvent event,\n      Object transitionToDo, RMAppAttemptState targetFinalState) {\n    transitionTodo = transitionToDo;\n    targetedFinalState = targetFinalState;\n    eventCausingFinalSaving = event;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getUnexpectedAMRegisteredDiagnostics": "  private static String getUnexpectedAMRegisteredDiagnostics() {\n    return \"Unmanaged AM must register after AM attempt reaches LAUNCHED state.\";\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getAppAttemptState()) {\n        LOG.info(appAttemptID + \" State change from \" + oldState + \" to \"\n            + getAppAttemptState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts": "  private void recoverAppAttempts() {\n    for (RMAppAttempt attempt : getAppAttempts().values()) {\n      attempt.handle(new RMAppAttemptEvent(attempt.getAppAttemptId(),\n        RMAppAttemptEventType.RECOVER));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getAppAttempts": "  public Map<ApplicationAttemptId, RMAppAttempt> getAppAttempts() {\n    this.readLock.lock();\n\n    try {\n      return Collections.unmodifiableMap(this.attempts);\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle": "  public void handle(RMAppEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId appID = event.getApplicationId();\n      LOG.debug(\"Processing event for \" + appID + \" of type \"\n          + event.getType());\n      final RMAppState oldState = getState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getState()) {\n        LOG.info(appID + \" State change from \" + oldState + \" to \"\n            + getState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.transition": "    public RMAppState transition(RMAppImpl app, RMAppEvent event) {\n      int numberOfFailure = app.getNumFailedAppAttempts();\n      LOG.info(\"The number of failed attempts\"\n          + (app.attemptFailuresValidityInterval > 0 ? \" in previous \"\n              + app.attemptFailuresValidityInterval + \" milliseconds \" : \" \")\n          + \"is \" + numberOfFailure + \". The max attempts is \"\n          + app.maxAppAttempts);\n      if (!app.submissionContext.getUnmanagedAM()\n          && numberOfFailure < app.maxAppAttempts) {\n        boolean transferStateFromPreviousAttempt;\n        RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n        transferStateFromPreviousAttempt =\n            failedEvent.getTransferStateFromPreviousAttempt();\n\n        RMAppAttempt oldAttempt = app.currentAttempt;\n        app.createAndStartNewAttempt(transferStateFromPreviousAttempt);\n        // Transfer the state from the previous attempt to the current attempt.\n        // Note that the previous failed attempt may still be collecting the\n        // container events from the scheduler and update its data structures\n        // before the new attempt is created. We always transferState for\n        // finished containers so that they can be acked to NM,\n        // but when pulling finished container we will check this flag again.\n        ((RMAppAttemptImpl) app.currentAttempt)\n          .transferStateFromPreviousAttempt(oldAttempt);\n        return initialState;\n      } else {\n        if (numberOfFailure >= app.maxAppAttempts) {\n          app.isNumAttemptsBeyondThreshold = true;\n        }\n        app.rememberTargetTransitionsAndStoreState(event,\n          new AttemptFailedFinalStateSavedTransition(), RMAppState.FAILED,\n          RMAppState.FAILED);\n        return RMAppState.FINAL_SAVING;\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.failToRecoverApp": "    private void failToRecoverApp(RMAppImpl app, RMAppEvent event, String msg,\n        Exception e) {\n      app.diagnostics.append(msg);\n      LOG.error(msg, e);\n      app.rememberTargetTransitionsAndStoreState(event, new FinalTransition(\n        RMAppState.FAILED), RMAppState.FAILED, RMAppState.FAILED);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.processNodeUpdate": "  private void processNodeUpdate(RMAppNodeUpdateType type, RMNode node) {\n    NodeState nodeState = node.getState();\n    updatedNodes.add(node);\n    LOG.debug(\"Received node update event:\" + type + \" for node:\" + node\n        + \" with state:\" + nodeState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.rememberTargetTransitionsAndStoreState": "  private void rememberTargetTransitionsAndStoreState(RMAppEvent event,\n      Object transitionToDo, RMAppState targetFinalState,\n      RMAppState stateToBeStored) {\n    rememberTargetTransitions(event, transitionToDo, targetFinalState);\n    this.stateBeforeFinalSaving = getState();\n    this.storedFinishTime = this.systemClock.getTime();\n\n    LOG.info(\"Updating application \" + this.applicationId\n        + \" with final state: \" + this.targetedFinalState);\n    // we lost attempt_finished diagnostics in app, because attempt_finished\n    // diagnostics is sent after app final state is saved. Later on, we will\n    // create GetApplicationAttemptReport specifically for getting per attempt\n    // info.\n    String diags = null;\n    switch (event.getType()) {\n    case APP_REJECTED:\n      RMAppRejectedEvent rejectedEvent = (RMAppRejectedEvent) event;\n      diags = rejectedEvent.getMessage();\n      break;\n    case ATTEMPT_FINISHED:\n      RMAppFinishedAttemptEvent finishedEvent =\n          (RMAppFinishedAttemptEvent) event;\n      diags = finishedEvent.getDiagnostics();\n      break;\n    case ATTEMPT_FAILED:\n      RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n      diags = getAppAttemptFailedDiagnostics(failedEvent);\n      break;\n    case ATTEMPT_KILLED:\n      diags = getAppKilledDiagnostics();\n      break;\n    default:\n      break;\n    }\n    ApplicationState appState =\n        new ApplicationState(this.submitTime, this.startTime,\n          this.submissionContext, this.user, stateToBeStored, diags,\n          this.storedFinishTime);\n    this.rmContext.getStateStore().updateApplicationState(appState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.isAppInFinalState": "  public static boolean isAppInFinalState(RMApp rmApp) {\n    RMAppState appState = ((RMAppImpl) rmApp).getRecoveredFinalState();\n    if (appState == null) {\n      appState = rmApp.getState();\n    }\n    return appState == RMAppState.FAILED || appState == RMAppState.FINISHED\n        || appState == RMAppState.KILLED;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getState": "  public RMAppState getState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getUser": "  public String getUser() {\n    return this.user;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.parseCredentials": "  protected Credentials parseCredentials() throws IOException {\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = submissionContext.getAMContainerSpec().getTokens();\n    if (tokens != null) {\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n    return credentials;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getAppKilledDiagnostics": "  private static String getAppKilledDiagnostics() {\n    return \"Application killed by user.\";\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.createAndStartNewAttempt": "  private void\n      createAndStartNewAttempt(boolean transferStateFromPreviousAttempt) {\n    createNewAttempt();\n    handler.handle(new RMAppStartAttemptEvent(currentAttempt.getAppAttemptId(),\n      transferStateFromPreviousAttempt));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getRanNodes": "  public Set<NodeId> getRanNodes() {\n    return ranNodes;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.rememberTargetTransitions": "  private void rememberTargetTransitions(RMAppEvent event,\n      Object transitionToDo, RMAppState targetFinalState) {\n    transitionTodo = transitionToDo;\n    targetedFinalState = targetFinalState;\n    eventCausingFinalSaving = event;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recover": "  public void recover(RMState state) throws Exception{\n    ApplicationState appState = state.getApplicationState().get(getApplicationId());\n    this.recoveredFinalState = appState.getState();\n    LOG.info(\"Recovering app: \" + getApplicationId() + \" with \" + \n        + appState.getAttemptCount() + \" attempts and final state = \" + this.recoveredFinalState );\n    this.diagnostics.append(appState.getDiagnostics());\n    this.storedFinishTime = appState.getFinishTime();\n    this.startTime = appState.getStartTime();\n\n    for(int i=0; i<appState.getAttemptCount(); ++i) {\n      // create attempt\n      createNewAttempt();\n      ((RMAppAttemptImpl)this.currentAttempt).recover(state);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getAppAttemptFailedDiagnostics": "  private String getAppAttemptFailedDiagnostics(RMAppEvent event) {\n    String msg = null;\n    RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n    if (this.submissionContext.getUnmanagedAM()) {\n      // RM does not manage the AM. Do not retry\n      msg = \"Unmanaged application \" + this.getApplicationId()\n              + \" failed due to \" + failedEvent.getDiagnostics()\n              + \". Failing the application.\";\n    } else if (this.isNumAttemptsBeyondThreshold) {\n      msg = \"Application \" + this.getApplicationId() + \" failed \"\n              + this.maxAppAttempts + \" times due to \"\n              + failedEvent.getDiagnostics() + \". Failing the application.\";\n    }\n    return msg;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getNumFailedAppAttempts": "  private int getNumFailedAppAttempts() {\n    int completedAttempts = 0;\n    long endTime = this.systemClock.getTime();\n    // Do not count AM preemption, hardware failures or NM resync\n    // as attempt failure.\n    for (RMAppAttempt attempt : attempts.values()) {\n      if (attempt.shouldCountTowardsMaxAttemptRetry()) {\n        if (this.attemptFailuresValidityInterval <= 0\n            || (attempt.getFinishTime() > endTime\n                - this.attemptFailuresValidityInterval)) {\n          completedAttempts++;\n        }\n      }\n    }\n    return completedAttempts;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getDiagnostics": "  public StringBuilder getDiagnostics() {\n    this.readLock.lock();\n\n    try {\n      return this.diagnostics;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication": "  protected void recoverApplication(ApplicationState appState, RMState rmState)\n      throws Exception {\n    ApplicationSubmissionContext appContext =\n        appState.getApplicationSubmissionContext();\n    ApplicationId appId = appState.getAppId();\n\n    // create and recover app.\n    RMAppImpl application =\n        createAndPopulateNewRMApp(appContext, appState.getSubmitTime(),\n          appState.getUser());\n    application.handle(new RMAppRecoverEvent(appId, rmState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp": "  private RMAppImpl createAndPopulateNewRMApp(\n      ApplicationSubmissionContext submissionContext,\n      long submitTime, String user)\n      throws YarnException {\n    ApplicationId applicationId = submissionContext.getApplicationId();\n    ResourceRequest amReq = validateAndCreateResourceRequest(submissionContext);\n    // Create RMApp\n    RMAppImpl application =\n        new RMAppImpl(applicationId, rmContext, this.conf,\n            submissionContext.getApplicationName(), user,\n            submissionContext.getQueue(),\n            submissionContext, this.scheduler, this.masterService,\n            submitTime, submissionContext.getApplicationType(),\n            submissionContext.getApplicationTags(), amReq);\n\n    // Concurrent app submissions with same applicationId will fail here\n    // Concurrent app submissions with different applicationIds will not\n    // influence each other\n    if (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw RPCUtil.getRemoteException(message);\n    }\n    // Inform the ACLs Manager\n    this.applicationACLsManager.addApplication(applicationId,\n        submissionContext.getAMContainerSpec().getApplicationACLs());\n    String appViewACLs = submissionContext.getAMContainerSpec()\n        .getApplicationACLs().get(ApplicationAccessType.VIEW_APP);\n    rmContext.getSystemMetricsPublisher().appACLsUpdated(\n        application, appViewACLs, System.currentTimeMillis());\n    return application;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch(event.getType()) {\n      case APP_COMPLETED: \n      {\n        finishApplication(applicationId);\n        logApplicationSummary(applicationId);\n        checkAppNumCompletedLimit(); \n      } \n      break;\n      default:\n        LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n      }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover": "  public void recover(RMState state) throws Exception {\n    RMStateStore store = rmContext.getStateStore();\n    assert store != null;\n    // recover applications\n    Map<ApplicationId, ApplicationState> appStates = state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationState appState : appStates.values()) {\n      recoverApplication(appState, state);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setSchedulerRecoveryStartAndWaitTime": "  private void setSchedulerRecoveryStartAndWaitTime(RMState state,\n      Configuration conf) {\n    if (!state.getApplicationState().isEmpty()) {\n      long waitTime =\n          conf.getLong(YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS,\n            YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS);\n      rmContext.setSchedulerRecoveryStartAndWaitTime(waitTime);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(true);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n\n    // Use the customized yarn filter instead of the standard kerberos filter to\n    // allow users to authenticate using delegation tokens\n    // 4 conditions need to be satisfied -\n    // 1. security is enabled\n    // 2. http auth type is set to kerberos\n    // 3. \"yarn.resourcemanager.webapp.use-yarn-filter\" override is set to true\n    // 4. hadoop.http.filter.initializers container AuthenticationFilterInitializer\n\n    Configuration conf = getConfig();\n    boolean useYarnAuthenticationFilter =\n        conf.getBoolean(\n          YarnConfiguration.RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER);\n    String authPrefix = \"hadoop.http.authentication.\";\n    String authTypeKey = authPrefix + \"type\";\n    String filterInitializerConfKey = \"hadoop.http.filter.initializers\";\n    String actualInitializers = \"\";\n    Class<?>[] initializersClasses =\n        conf.getClasses(filterInitializerConfKey);\n\n    boolean hasHadoopAuthFilterInitializer = false;\n    boolean hasRMAuthFilterInitializer = false;\n    if (initializersClasses != null) {\n      for (Class<?> initializer : initializersClasses) {\n        if (initializer.getName().equals(\n          AuthenticationFilterInitializer.class.getName())) {\n          hasHadoopAuthFilterInitializer = true;\n        }\n        if (initializer.getName().equals(\n          RMAuthenticationFilterInitializer.class.getName())) {\n          hasRMAuthFilterInitializer = true;\n        }\n      }\n      if (UserGroupInformation.isSecurityEnabled()\n          && useYarnAuthenticationFilter\n          && hasHadoopAuthFilterInitializer\n          && conf.get(authTypeKey, \"\").equals(\n            KerberosAuthenticationHandler.TYPE)) {\n        ArrayList<String> target = new ArrayList<String>();\n        for (Class<?> filterInitializer : initializersClasses) {\n          if (filterInitializer.getName().equals(\n            AuthenticationFilterInitializer.class.getName())) {\n            if (hasRMAuthFilterInitializer == false) {\n              target.add(RMAuthenticationFilterInitializer.class.getName());\n            }\n            continue;\n          }\n          target.add(filterInitializer.getName());\n        }\n        actualInitializers = StringUtils.join(\",\", target);\n\n        LOG.info(\"Using RM authentication filter(kerberos/delegation-token)\"\n            + \" for RM webapp authentication\");\n        RMAuthenticationHandler\n          .setSecretManager(getClientRMService().rmDTSecretManager);\n        RMAuthenticationFilter\n          .setDelegationTokenSecretManager(getClientRMService().rmDTSecretManager);\n        String yarnAuthKey =\n            authPrefix + RMAuthenticationFilter.AUTH_HANDLER_PROPERTY;\n        conf.setStrings(yarnAuthKey, RMAuthenticationHandler.class.getName());\n        conf.set(filterInitializerConfKey, actualInitializers);\n      }\n    }\n\n    // if security is not enabled and the default filter initializer has not \n    // been set, set the initializer to include the\n    // RMAuthenticationFilterInitializer which in turn will set up the simple\n    // auth filter.\n\n    String initializers = conf.get(filterInitializerConfKey);\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      if (initializersClasses == null || initializersClasses.length == 0) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName());\n        conf.set(authTypeKey, \"simple\");\n      } else if (initializers.equals(StaticUserWebFilter.class.getName())) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName() + \",\"\n              + initializers);\n        conf.set(authTypeKey, \"simple\");\n      }\n    }\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .at(webAppAddress);\n    String proxyHostAndPort = WebAppUtils.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n\n    }\n    webApp = builder.start(new RMWebApp(this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          resetDispatcher();\n          createAndInitActiveServices();\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      if (initialize) {\n        resetDispatcher();\n        createAndInitActiveServices();\n      }\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          resetDispatcher();\n          createAndInitActiveServices();\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices": "  protected void createAndInitActiveServices() throws Exception {\n    activeServices = new RMActiveServices(this);\n    activeServices.init(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.resetDispatcher": "  private void resetDispatcher() {\n    Dispatcher dispatcher = setupDispatcher();\n    ((Service)dispatcher).init(this.conf);\n    ((Service)dispatcher).start();\n    removeService((Service)rmDispatcher);\n    // Need to stop previous rmDispatcher before assigning new dispatcher\n    // otherwise causes \"AsyncDispatcher event handler\" thread leak\n    ((Service) rmDispatcher).stop();\n    rmDispatcher = dispatcher;\n    addIfService(rmDispatcher);\n    rmContext.setDispatcher(rmDispatcher);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main": "  public static void main(String argv[]) {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ResourceManager.class, argv, LOG);\n    try {\n      Configuration conf = new YarnConfiguration();\n      // If -format-state-store, then delete RMStateStore; else startup normally\n      if (argv.length == 1 && argv[0].equals(\"-format-state-store\")) {\n        deleteRMStateStore(conf);\n      } else {\n        ResourceManager resourceManager = new ResourceManager();\n        ShutdownHookManager.get().addShutdownHook(\n          new CompositeServiceShutdownHook(resourceManager),\n          SHUTDOWN_HOOK_PRIORITY);\n        resourceManager.init(conf);\n        resourceManager.start();\n      }\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ResourceManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.deleteRMStateStore": "  private static void deleteRMStateStore(Configuration conf) throws Exception {\n    RMStateStore rmStore = RMStateStoreFactory.getStore(conf);\n    rmStore.init(conf);\n    rmStore.start();\n    try {\n      LOG.info(\"Deleting ResourceManager state store...\");\n      rmStore.deleteStore();\n      LOG.info(\"State store deleted\");\n    } finally {\n      rmStore.stop();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n  \n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n  \n  /**\n   * Get actual <em>capacity</em> of the queue, this may be different from\n   * configured capacity when mis-config take place, like add labels to the\n   * cluster\n   * \n   * @return actual queue capacity\n   */\n  public float getAbsActualCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Set used capacity of the queue.\n   * @param usedCapacity\n   *          used capacity of the queue\n   */\n  public void setUsedCapacity(float usedCapacity);\n\n  /**\n   * Set absolute used capacity of the queue.\n   * @param absUsedCapacity\n   *          absolute used capacity of the queue\n   */\n  public void setAbsoluteUsedCapacity(float absUsedCapacity);\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @param needToUnreserve assign container only if it can unreserve one first\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node, boolean needToUnreserve);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   * @param sortQueues indicates whether it should re-sort the queues\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getActiveUsersManager": "  public ActiveUsersManager getActiveUsersManager();\n  \n  /**\n   * Adds all applications in the queue and its subqueues to the given collection.\n   * @param apps the collection to add the applications to\n   */\n  public void collectSchedulerApplications(Collection<ApplicationAttemptId> apps);\n\n  /**\n  * Detach a container from this queue\n  * @param clusterResource the current cluster resource\n  * @param application application to which the container was assigned\n  * @param container the container to detach\n  */\n  public void detachContainer(Resource clusterResource,\n               FiCaSchedulerApp application, RMContainer container);\n\n  /**\n   * Attach a container to this queue\n   * @param clusterResource the current cluster resource\n   * @param application application to which the container was assigned\n   * @param container the container to attach\n   */\n  public void attachContainer(Resource clusterResource,\n               FiCaSchedulerApp application, RMContainer container);\n  \n  /**\n   * Get absolute capacity by label of this queue can use \n   * @param nodeLabel\n   * @return absolute capacity by label of this queue can use\n   */\n  public float getAbsoluteCapacityByNodeLabel(String nodeLabel);\n  \n  /**\n   * Get absolute max capacity by label of this queue can use \n   * @param nodeLabel\n   * @return absolute capacity by label of this queue can use\n   */\n  public float getAbsoluteMaximumCapacityByNodeLabel(String nodeLabel);\n\n  /**\n   * Get capacity by node label\n   * @param nodeLabel\n   * @return capacity by node label\n   */\n  public float getCapacityByNodeLabel(String nodeLabel);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.submitApplicationAttempt": "  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @param needToUnreserve assign container only if it can unreserve one first\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node, boolean needToUnreserve);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   * @param sortQueues indicates whether it should re-sort the queues\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppMoveEvent.getResult": "  public SettableFuture<Object> getResult() {\n    return result;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppNodeUpdateEvent.getNode": "  public RMNode getNode() {\n    return node;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppNodeUpdateEvent.getUpdateType": "  public RMAppNodeUpdateType getUpdateType() {\n    return updateType;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppRunningOnNodeEvent.getNodeId": "  public NodeId getNodeId() {\n    return node;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppRecoverEvent.getRMState": "  public RMState getRMState() {\n    return state;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppFailedAttemptEvent.getTransferStateFromPreviousAttempt": "  public boolean getTransferStateFromPreviousAttempt() {\n    return transferStateFromPreviousAttempt;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppMoveEvent.getTargetQueue": "  public String getTargetQueue() {\n    return targetQueue;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppRejectedEvent.getMessage": "  public String getMessage() {\n    return this.message;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<String, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getAMRMTokenSecretManager": "  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMDelegationTokenSecretManager": "  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "Resource manager crashed with Null Pointer Exception",
            "Description": "Resource manager failed after restart. \n\n{noformat}\n2014-11-09 04:12:53,013 INFO  capacity.CapacityScheduler (CapacityScheduler.java:initializeQueues(467)) - Initialized root queue root: numChildQueue= 2, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\n2014-11-09 04:12:53,013 INFO  capacity.CapacityScheduler (CapacityScheduler.java:initializeQueueMappings(436)) - Initialized queue mappings, override: false\n2014-11-09 04:12:53,013 INFO  capacity.CapacityScheduler (CapacityScheduler.java:initScheduler(305)) - Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:256, vCores:1>>, maximumAllocation=<<memory:2048, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms\n2014-11-09 04:12:53,015 INFO  service.AbstractService (AbstractService.java:noteFailure(272)) - Service ResourceManager failed in state STARTED; cause: java.lang.NullPointerException\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:734)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1089)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:114)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1041)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1005)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:757)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts(RMAppImpl.java:821)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.access$1900(RMAppImpl.java:101)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:843)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:826)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:701)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:312)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:413)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1207)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:590)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1014)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1051)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1047)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1047)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1091)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1226)\n{noformat}"
        }
    },
    {
        "filename": "YARN-370.json",
        "creation_time": "2013-02-01T04:02:58.000+0000",
        "stack_trace": "```\nError launching appattempt_1359688216672_0001_000001. Got exception: RemoteTrace: at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: RemoteTrace: at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unauthorized request to start container. Expected resource <memory:2048, vCores:1> but found <memory:1536, vCores:1> at org.apache.hadoop.yarn.factories.impl.pb.YarnRemoteExceptionFactoryPBImpl.createYarnRemoteException(YarnRemoteExceptionFactoryPBImpl.java:39) at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:47) at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeRequest(ContainerManagerImpl.java:383) at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.startContainer(ContainerManagerImpl.java:400) at org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagerPBServiceImpl.startContainer(ContainerManagerPBServiceImpl.java:68) at org.apache.hadoop.yarn.proto.ContainerManager$ContainerManagerService$2.callBlockingMethod(ContainerManager.java:83) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1014) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1735) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1731) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1441) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1729) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Native Method) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57) at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.unwrapAndThrowException(YarnRemoteExceptionPBImpl.java:123) at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:109) at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:111) at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:255) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722)\n```",
        "source_code": {},
        "bug_report": {
            "Title": "CapacityScheduler app submission fails when min alloc size not multiple of AM size",
            "Description": "I was running 2.0.3-SNAPSHOT with the capacity scheduler configured with minimum allocation size 1G. The AM size was set to 1.5G. I didn't specify resource calculator so it was using DefaultResourceCalculator.  The am launch failed with the error below:\n\nApplication application_1359688216672_0001 failed 1 times due to Error launching appattempt_1359688216672_0001_000001. Got exception: RemoteTrace: at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: RemoteTrace: at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unauthorized request to start container. Expected resource <memory:2048, vCores:1> but found <memory:1536, vCores:1> at org.apache.hadoop.yarn.factories.impl.pb.YarnRemoteExceptionFactoryPBImpl.createYarnRemoteException(YarnRemoteExceptionFactoryPBImpl.java:39) at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:47) at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeRequest(ContainerManagerImpl.java:383) at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.startContainer(ContainerManagerImpl.java:400) at org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagerPBServiceImpl.startContainer(ContainerManagerPBServiceImpl.java:68) at org.apache.hadoop.yarn.proto.ContainerManager$ContainerManagerService$2.callBlockingMethod(ContainerManager.java:83) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1014) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1735) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1731) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1441) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1729) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57) at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.unwrapAndThrowException(YarnRemoteExceptionPBImpl.java:123) at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:109) at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:111) at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:255) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722) . Failing the application. \n\nIt looks like the launchcontext for the app didn't have the resources rounded up."
        }
    },
    {
        "filename": "YARN-3675.json",
        "creation_time": "2015-05-18T22:38:39.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserve(FSAppAttempt.java:469)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer(FairScheduler.java:815)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt(FairScheduler.java:763)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1217)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:111)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserve": "  public void unreserve(Priority priority, FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    unreserveInternal(priority, node);\n    node.unreserveResource(this);\n    getMetrics().unreserveResource(\n        getUser(), rmContainer.getContainer().getResource());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserveInternal": "  private synchronized void unreserveInternal(\n      Priority priority, FSSchedulerNode node) {\n    Map<NodeId, RMContainer> reservedContainers = \n        this.reservedContainers.get(priority);\n    RMContainer reservedContainer = reservedContainers.remove(node.getNodeID());\n    if (reservedContainers.isEmpty()) {\n      this.reservedContainers.remove(priority);\n    }\n    \n    // Reset the re-reservation count\n    resetReReservations(priority);\n\n    Resource resource = reservedContainer.getContainer().getResource();\n    this.attemptResourceUsage.decReserved(resource);\n\n    LOG.info(\"Application \" + getApplicationId() + \" unreserved \" + \" on node \"\n        + node + \", currently has \" + reservedContainers.size()\n        + \" at priority \" + priority + \"; currentReservation \"\n        + this.attemptResourceUsage.getReserved());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getMetrics": "  public QueueMetrics getMetrics() {\n    return queue.getMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer": "  protected synchronized void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n    if (rmContainer == null) {\n      LOG.info(\"Container \" + containerStatus.getContainerId()\n          + \" completed with event \" + event);\n      return;\n    }\n\n    Container container = rmContainer.getContainer();\n\n    // Get the application for the finished container\n    FSAppAttempt application =\n        getCurrentAttemptForContainer(container.getId());\n    ApplicationId appId =\n        container.getId().getApplicationAttemptId().getApplicationId();\n    if (application == null) {\n      LOG.info(\"Container \" + container + \" of\" +\n          \" finished application \" + appId +\n          \" completed with event \" + event);\n      return;\n    }\n\n    // Get the node on which the container was allocated\n    FSSchedulerNode node = getFSSchedulerNode(container.getNodeId());\n\n    if (rmContainer.getState() == RMContainerState.RESERVED) {\n      application.unreserve(rmContainer.getReservedPriority(), node);\n    } else {\n      application.containerCompleted(rmContainer, containerStatus, event);\n      node.releaseContainer(container);\n      updateRootQueueMetrics();\n    }\n\n    LOG.info(\"Application attempt \" + application.getApplicationAttemptId()\n        + \" released container \" + container.getId() + \" on node: \" + node\n        + \" with event: \" + event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateRootQueueMetrics": "  private void updateRootQueueMetrics() {\n    rootMetrics.setAvailableResourcesToQueue(\n        Resources.subtract(\n            clusterResource, rootMetrics.getAllocatedResources()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getFSSchedulerNode": "  private FSSchedulerNode getFSSchedulerNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt": "  private synchronized void removeApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    LOG.info(\"Application \" + applicationAttemptId + \" is done.\" +\n        \" finalState=\" + rmAppAttemptFinalState);\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    FSAppAttempt attempt = getSchedulerApp(applicationAttemptId);\n\n    if (attempt == null || application == null) {\n      LOG.info(\"Unknown application \" + applicationAttemptId + \" has completed!\");\n      return;\n    }\n\n    // Release all the running containers\n    for (RMContainer rmContainer : attempt.getLiveContainers()) {\n      if (keepContainers\n          && rmContainer.getState().equals(RMContainerState.RUNNING)) {\n        // do not kill the running container in the case of work-preserving AM\n        // restart.\n        LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n        continue;\n      }\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              SchedulerUtils.COMPLETED_APPLICATION),\n              RMContainerEventType.KILL);\n    }\n\n    // Release all reserved containers\n    for (RMContainer rmContainer : attempt.getReservedContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              \"Application Complete\"),\n              RMContainerEventType.KILL);\n    }\n    // Clean up pending requests, metrics etc.\n    attempt.stop(rmAppAttemptFinalState);\n\n    // Inform the queue\n    FSLeafQueue queue = queueMgr.getLeafQueue(attempt.getQueue()\n        .getQueueName(), false);\n    boolean wasRunnable = queue.removeApp(attempt);\n\n    if (wasRunnable) {\n      maxRunningEnforcer.untrackRunnableApp(attempt);\n      maxRunningEnforcer.updateRunnabilityOnAppRemoval(attempt,\n          attempt.getQueue());\n    } else {\n      maxRunningEnforcer.untrackNonRunnableApp(attempt);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getSchedulerApp": "  public FSAppAttempt getSchedulerApp(ApplicationAttemptId appAttemptId) {\n    return super.getApplicationAttempt(appAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n          nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName, appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n      break;\n    case NODE_RESOURCE_UPDATE:\n      if (!(event instanceof NodeResourceUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeResource(nodeResourceUpdatedEvent.getRMNode(),\n            nodeResourceUpdatedEvent.getResourceOption());\n      break;\n    case APP_ATTEMPT_ADDED:\n      if (!(event instanceof AppAttemptAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n      break;\n    case APP_ATTEMPT_REMOVED:\n      if (!(event instanceof AppAttemptRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      removeApplicationAttempt(\n          appAttemptRemovedEvent.getApplicationAttemptID(),\n          appAttemptRemovedEvent.getFinalAttemptState(),\n          appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addNode": "  private synchronized void addNode(RMNode node) {\n    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, usePortForNodeName);\n    nodes.put(node.getNodeID(), schedulerNode);\n    Resources.addTo(clusterResource, node.getTotalCapability());\n    updateRootQueueMetrics();\n    updateMaximumAllocation(schedulerNode, true);\n\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n    LOG.info(\"Added node \" + node.getNodeAddress() +\n        \" cluster capacity: \" + clusterResource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected synchronized void addApplication(ApplicationId applicationId,\n      String queueName, String user, boolean isAppRecovering) {\n    if (queueName == null || queueName.isEmpty()) {\n      String message = \"Reject application \" + applicationId +\n              \" submitted by user \" + user + \" with an empty queue name.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n\n    if (queueName.startsWith(\".\") || queueName.endsWith(\".\")) {\n      String message = \"Reject application \" + applicationId\n          + \" submitted by user \" + user + \" with an illegal queue name \"\n          + queueName + \". \"\n          + \"The queue name cannot start/end with period.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n\n    RMApp rmApp = rmContext.getRMApps().get(applicationId);\n    FSLeafQueue queue = assignToQueue(rmApp, queueName, user);\n    if (queue == null) {\n      return;\n    }\n\n    // Enforce ACLs\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n\n    if (!queue.hasAccess(QueueACL.SUBMIT_APPLICATIONS, userUgi)\n        && !queue.hasAccess(QueueACL.ADMINISTER_QUEUE, userUgi)) {\n      String msg = \"User \" + userUgi.getUserName() +\n              \" cannot submit applications to queue \" + queue.getName();\n      LOG.info(msg);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, msg));\n      return;\n    }\n  \n    SchedulerApplication<FSAppAttempt> application =\n        new SchedulerApplication<FSAppAttempt>(queue, user);\n    applications.put(applicationId, application);\n    queue.getMetrics().submitApp(user);\n\n    LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n        + \", in queue: \" + queueName + \", currently num of applications: \"\n        + applications.size());\n    if (isAppRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler()\n        .handle(new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start = getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node = getFSSchedulerNode(nm.getNodeID());\n    \n    List<UpdatedContainerInfo> containerInfoList = nm.pullContainerUpdates();\n    List<ContainerStatus> newlyLaunchedContainers = new ArrayList<ContainerStatus>();\n    List<ContainerStatus> completedContainers = new ArrayList<ContainerStatus>();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    long duration = getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication": "  private synchronized void removeApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationId);\n    if (application == null){\n      LOG.warn(\"Couldn't find application \" + applicationId);\n      return;\n    }\n    application.stop(finalState);\n    applications.remove(applicationId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.resolveReservationQueueName": "  private synchronized String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID) {\n    FSQueue queue = queueMgr.getQueue(queueName);\n    if ((queue == null) || !allocConf.isReservable(queue.getQueueName())) {\n      return queueName;\n    }\n    // Use fully specified name from now on (including root. prefix)\n    queueName = queue.getQueueName();\n    if (reservationID != null) {\n      String resQName = queueName + \".\" + reservationID.toString();\n      queue = queueMgr.getQueue(resQName);\n      if (queue == null) {\n        String message =\n            \"Application \"\n                + applicationId\n                + \" submitted to a reservation which is not yet currently active: \"\n                + resQName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, message));\n        return null;\n      }\n      if (!queue.getParent().getQueueName().equals(queueName)) {\n        String message =\n            \"Application: \" + applicationId + \" submitted to a reservation \"\n                + resQName + \" which does not belong to the specified queue: \"\n                + queueName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, message));\n        return null;\n      }\n      // use the reservation queue to run the app\n      queueName = resQName;\n    } else {\n      // use the default child queue of the plan for unreserved apps\n      queueName = getDefaultQueueForPlanQueue(queueName);\n    }\n    return queueName;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateNodeResource": "  public synchronized void updateNodeResource(RMNode nm, \n      ResourceOption resourceOption) {\n    super.updateNodeResource(nm, resourceOption);\n    updateRootQueueMetrics();\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplicationAttempt": "  protected synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    String user = application.getUser();\n    FSLeafQueue queue = (FSLeafQueue) application.getQueue();\n\n    FSAppAttempt attempt =\n        new FSAppAttempt(this, applicationAttemptId, user,\n            queue, new ActiveUsersManager(getRootQueueMetrics()),\n            rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n          .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    boolean runnable = maxRunningEnforcer.canAppBeRunnable(queue, user);\n    queue.addApp(attempt, runnable);\n    if (runnable) {\n      maxRunningEnforcer.trackRunnableApp(attempt);\n    } else {\n      maxRunningEnforcer.trackNonRunnableApp(attempt);\n    }\n    \n    queue.getMetrics().submitAppAttempt(user);\n\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user: \" + user);\n\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeNode": "  private synchronized void removeNode(RMNode rmNode) {\n    FSSchedulerNode node = getFSSchedulerNode(rmNode.getNodeID());\n    // This can occur when an UNHEALTHY node reconnects\n    if (node == null) {\n      return;\n    }\n    Resources.subtractFrom(clusterResource, rmNode.getTotalCapability());\n    updateRootQueueMetrics();\n\n    // Remove running containers\n    List<RMContainer> runningContainers = node.getRunningContainers();\n    for (RMContainer container : runningContainers) {\n      completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    // Remove reservations, if any\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      completedContainer(reservedContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              reservedContainer.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    nodes.remove(rmNode.getNodeID());\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n    updateMaximumAllocation(node, false);\n    LOG.info(\"Removed node \" + rmNode.getNodeAddress() +\n        \" cluster capacity: \" + clusterResource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) throws Exception {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.removeApp": "  public boolean removeApp(FSAppAttempt app) {\n    boolean runnable = false;\n\n    // Remove app from runnable/nonRunnable list while holding the write lock\n    writeLock.lock();\n    try {\n      runnable = runnableApps.remove(app);\n      if (!runnable) {\n        // removeNonRunnableApp acquires the write lock again, which is fine\n        if (!removeNonRunnableApp(app)) {\n          throw new IllegalStateException(\"Given app to remove \" + app +\n              \" does not exist in queue \" + this);\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n\n    // Update AM resource usage if needed. If isAMRunning is true, we're not\n    // running an unmanaged AM.\n    if (runnable && app.isAmRunning()) {\n      Resources.subtractFrom(amResourceUsage, app.getAMResource());\n    }\n\n    return runnable;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.removeNonRunnableApp": "  public boolean removeNonRunnableApp(FSAppAttempt app) {\n    writeLock.lock();\n    try {\n      return nonRunnableApps.remove(app);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getQueue": "  public FSLeafQueue getQueue() {\n    return (FSLeafQueue)super.getQueue();\n  }"
        },
        "bug_report": {
            "Title": "FairScheduler: RM quits when node removal races with continousscheduling on the same node",
            "Description": "With continuous scheduling, scheduling can be done on a node thats just removed causing errors like below.\n\n{noformat}\n12:28:53.782 AM FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager\n\nError in handling event type APP_ATTEMPT_REMOVED to the scheduler\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserve(FSAppAttempt.java:469)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer(FairScheduler.java:815)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt(FairScheduler.java:763)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1217)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:111)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n\tat java.lang.Thread.run(Thread.java:745)\n12:28:53.783 AM\t INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager Exiting, bbye..\n{noformat}"
        }
    },
    {
        "filename": "YARN-4763.json",
        "creation_time": "2016-03-04T10:03:56.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppsBlock.renderData(RMAppsBlock.java:100)\n        at org.apache.hadoop.yarn.server.webapp.AppsBlock.render(AppsBlock.java:140)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n        at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock$Block.subView(HtmlBlock.java:43)\n        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet._(Hamlet.java:30354)\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsBlockWithMetrics.render(AppsBlockWithMetrics.java:30)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n        at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n        at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n        at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)\n        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:848)\n        at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)\n        at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n        at org.apache.hadoop.yarn.webapp.Dispatcher.render(Dispatcher.java:197)\n        at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:156)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppsBlock.renderData": "  protected void renderData(Block html) {\n    TBODY<TABLE<Hamlet>> tbody =\n        html.table(\"#apps\").thead().tr().th(\".id\", \"ID\").th(\".user\", \"User\")\n          .th(\".name\", \"Name\").th(\".type\", \"Application Type\")\n          .th(\".queue\", \"Queue\").th(\".priority\", \"Application Priority\")\n          .th(\".starttime\", \"StartTime\")\n          .th(\".finishtime\", \"FinishTime\").th(\".state\", \"State\")\n          .th(\".finalstatus\", \"FinalStatus\")\n          .th(\".runningcontainer\", \"Running Containers\")\n          .th(\".allocatedCpu\", \"Allocated CPU VCores\")\n          .th(\".allocatedMemory\", \"Allocated Memory MB\")\n          .th(\".queuePercentage\", \"% of Queue\")\n          .th(\".clusterPercentage\", \"% of Cluster\")\n          .th(\".progress\", \"Progress\")\n          .th(\".ui\", \"Tracking UI\")\n          .th(\".blacklisted\", \"Blacklisted Nodes\")._()\n          ._().tbody();\n\n    StringBuilder appsTableData = new StringBuilder(\"[\\n\");\n    for (ApplicationReport appReport : appReports) {\n      // TODO: remove the following condition. It is still here because\n      // the history side implementation of ApplicationBaseProtocol\n      // hasn't filtering capability (YARN-1819).\n      if (!reqAppStates.isEmpty()\n          && !reqAppStates.contains(appReport.getYarnApplicationState())) {\n        continue;\n      }\n\n      AppInfo app = new AppInfo(appReport);\n      ApplicationAttemptId appAttemptId =\n          ConverterUtils.toApplicationAttemptId(app.getCurrentAppAttemptId());\n      String queuePercent = \"N/A\";\n      String clusterPercent = \"N/A\";\n      if(appReport.getApplicationResourceUsageReport() != null) {\n        queuePercent = String.format(\"%.1f\",\n            appReport.getApplicationResourceUsageReport()\n                .getQueueUsagePercentage());\n        clusterPercent = String.format(\"%.1f\",\n            appReport.getApplicationResourceUsageReport().getClusterUsagePercentage());\n      }\n\n      String blacklistedNodesCount = \"N/A\";\n      Set<String> nodes = rm.getRMContext().getRMApps()\n          .get(appAttemptId.getApplicationId()).getAppAttempts()\n          .get(appAttemptId).getBlacklistedNodes();\n      if (nodes != null) {\n        blacklistedNodesCount = String.valueOf(nodes.size());\n      }\n      String percent = StringUtils.format(\"%.1f\", app.getProgress());\n      appsTableData\n        .append(\"[\\\"<a href='\")\n        .append(url(\"app\", app.getAppId()))\n        .append(\"'>\")\n        .append(app.getAppId())\n        .append(\"</a>\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(\n              StringEscapeUtils.escapeHtml(app.getUser())))\n        .append(\"\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(\n              StringEscapeUtils.escapeHtml(app.getName())))\n        .append(\"\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(app\n            .getType())))\n        .append(\"\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(app\n             .getQueue()))).append(\"\\\",\\\"\").append(String\n             .valueOf(app.getPriority()))\n        .append(\"\\\",\\\"\").append(app.getStartedTime())\n        .append(\"\\\",\\\"\").append(app.getFinishedTime())\n        .append(\"\\\",\\\"\")\n        .append(app.getAppState() == null ? UNAVAILABLE : app.getAppState())\n        .append(\"\\\",\\\"\")\n        .append(app.getFinalAppStatus())\n        .append(\"\\\",\\\"\")\n        .append(app.getRunningContainers() == -1 ? \"N/A\" : String\n            .valueOf(app.getRunningContainers()))\n        .append(\"\\\",\\\"\")\n        .append(app.getAllocatedCpuVcores() == -1 ? \"N/A\" : String\n            .valueOf(app.getAllocatedCpuVcores()))\n        .append(\"\\\",\\\"\")\n        .append(app.getAllocatedMemoryMB() == -1 ? \"N/A\" :\n            String.valueOf(app.getAllocatedMemoryMB()))\n        .append(\"\\\",\\\"\")\n        .append(queuePercent)\n        .append(\"\\\",\\\"\")\n        .append(clusterPercent)\n        .append(\"\\\",\\\"\")\n        // Progress bar\n          .append(\"<br title='\").append(percent).append(\"'> <div class='\")\n        .append(C_PROGRESSBAR).append(\"' title='\").append(join(percent, '%'))\n        .append(\"'> \").append(\"<div class='\").append(C_PROGRESSBAR_VALUE)\n        .append(\"' style='\").append(join(\"width:\", percent, '%'))\n        .append(\"'> </div> </div>\").append(\"\\\",\\\"<a \");\n\n      String trackingURL =\n          app.getTrackingUrl() == null\n              || app.getTrackingUrl().equals(UNAVAILABLE)\n              || app.getAppState() == YarnApplicationState.NEW ? null : app\n              .getTrackingUrl();\n\n      String trackingUI =\n          app.getTrackingUrl() == null\n              || app.getTrackingUrl().equals(UNAVAILABLE)\n              || app.getAppState() == YarnApplicationState.NEW ? \"Unassigned\"\n              : app.getAppState() == YarnApplicationState.FINISHED\n              || app.getAppState() == YarnApplicationState.FAILED\n              || app.getAppState() == YarnApplicationState.KILLED ? \"History\"\n              : \"ApplicationMaster\";\n      appsTableData.append(trackingURL == null ? \"#\" : \"href='\" + trackingURL)\n        .append(\"'>\").append(trackingUI).append(\"</a>\\\",\").append(\"\\\"\")\n        .append(blacklistedNodesCount).append(\"\\\"],\\n\");\n\n    }\n    if (appsTableData.charAt(appsTableData.length() - 2) == ',') {\n      appsTableData.delete(appsTableData.length() - 2,\n        appsTableData.length() - 1);\n    }\n    appsTableData.append(\"]\");\n    html.script().$type(\"text/javascript\")\n      ._(\"var appsTableData=\" + appsTableData)._();\n\n    tbody._()._();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppsBlock.render": "  public void render(Block html) {\n    setTitle(\"Applications\");\n\n    try {\n      fetchData();\n    }\n    catch( Exception e) {\n      String message = \"Failed to read the applications.\";\n      LOG.error(message, e);\n      html.p()._(message)._();\n      return;\n    }\n    renderData(html);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppsBlock.renderData": "  protected void renderData(Block html) {\n    TBODY<TABLE<Hamlet>> tbody =\n        html.table(\"#apps\").thead().tr().th(\".id\", \"ID\").th(\".user\", \"User\")\n          .th(\".name\", \"Name\").th(\".type\", \"Application Type\")\n          .th(\".queue\", \"Queue\").th(\".priority\", \"Application Priority\")\n          .th(\".starttime\", \"StartTime\").th(\".finishtime\", \"FinishTime\")\n          .th(\".state\", \"State\").th(\".finalstatus\", \"FinalStatus\")\n          .th(\".progress\", \"Progress\").th(\".ui\", \"Tracking UI\")._()._().tbody();\n\n    StringBuilder appsTableData = new StringBuilder(\"[\\n\");\n    for (ApplicationReport appReport : appReports) {\n      // TODO: remove the following condition. It is still here because\n      // the history side implementation of ApplicationBaseProtocol\n      // hasn't filtering capability (YARN-1819).\n      if (!reqAppStates.isEmpty()\n          && !reqAppStates.contains(appReport.getYarnApplicationState())) {\n        continue;\n      }\n      AppInfo app = new AppInfo(appReport);\n      String percent = StringUtils.format(\"%.1f\", app.getProgress());\n      appsTableData\n        .append(\"[\\\"<a href='\")\n        .append(url(\"app\", app.getAppId()))\n        .append(\"'>\")\n        .append(app.getAppId())\n        .append(\"</a>\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(app\n              .getUser())))\n        .append(\"\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(app\n            .getName())))\n        .append(\"\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(app\n            .getType())))\n        .append(\"\\\",\\\"\")\n        .append(\n          StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(app\n            .getQueue()))).append(\"\\\",\\\"\").append(String\n                .valueOf(app.getPriority()))\n        .append(\"\\\",\\\"\").append(app.getStartedTime())\n        .append(\"\\\",\\\"\").append(app.getFinishedTime())\n        .append(\"\\\",\\\"\")\n        .append(app.getAppState() == null ? UNAVAILABLE : app.getAppState())\n        .append(\"\\\",\\\"\")\n        .append(app.getFinalAppStatus())\n        .append(\"\\\",\\\"\")\n        // Progress bar\n        .append(\"<br title='\").append(percent).append(\"'> <div class='\")\n        .append(C_PROGRESSBAR).append(\"' title='\").append(join(percent, '%'))\n        .append(\"'> \").append(\"<div class='\").append(C_PROGRESSBAR_VALUE)\n        .append(\"' style='\").append(join(\"width:\", percent, '%'))\n        .append(\"'> </div> </div>\").append(\"\\\",\\\"<a \");\n\n      String trackingURL =\n          app.getTrackingUrl() == null\n              || app.getTrackingUrl().equals(UNAVAILABLE) ? null : app\n            .getTrackingUrl();\n\n      String trackingUI =\n          app.getTrackingUrl() == null || app.getTrackingUrl().equals(UNAVAILABLE)\n              ? \"Unassigned\"\n              : app.getAppState() == YarnApplicationState.FINISHED\n                  || app.getAppState() == YarnApplicationState.FAILED\n                  || app.getAppState() == YarnApplicationState.KILLED\n                  ? \"History\" : \"ApplicationMaster\";\n      appsTableData.append(trackingURL == null ? \"#\" : \"href='\" + trackingURL)\n        .append(\"'>\").append(trackingUI).append(\"</a>\\\"],\\n\");\n\n    }\n    if (appsTableData.charAt(appsTableData.length() - 2) == ',') {\n      appsTableData.delete(appsTableData.length() - 2,\n        appsTableData.length() - 1);\n    }\n    appsTableData.append(\"]\");\n    html.script().$type(\"text/javascript\")\n      ._(\"var appsTableData=\" + appsTableData)._();\n\n    tbody._()._();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppsBlock.fetchData": "  protected void fetchData() throws YarnException, IOException,\n      InterruptedException {\n    reqAppStates = EnumSet.noneOf(YarnApplicationState.class);\n    String reqStateString = $(APP_STATE);\n    if (reqStateString != null && !reqStateString.isEmpty()) {\n      String[] appStateStrings = reqStateString.split(\",\");\n      for (String stateString : appStateStrings) {\n        reqAppStates.add(YarnApplicationState.valueOf(stateString.trim()));\n      }\n    }\n    callerUGI = getCallerUGI();\n    final GetApplicationsRequest request =\n        GetApplicationsRequest.newInstance(reqAppStates);\n    String appsNumStr = $(APPS_NUM);\n    if (appsNumStr != null && !appsNumStr.isEmpty()) {\n      long appsNum = Long.parseLong(appsNumStr);\n      request.setLimit(appsNum);\n    }\n\n    String appStartedTimeBegainStr = $(APP_START_TIME_BEGIN);\n    long appStartedTimeBegain = 0;\n    if (appStartedTimeBegainStr != null && !appStartedTimeBegainStr.isEmpty()) {\n      appStartedTimeBegain = Long.parseLong(appStartedTimeBegainStr);\n      if (appStartedTimeBegain < 0) {\n        throw new BadRequestException(\n          \"app.started-time.begin must be greater than 0\");\n      }\n    }\n    String appStartedTimeEndStr = $(APP_START_TIME_END);\n    long appStartedTimeEnd = Long.MAX_VALUE;\n    if (appStartedTimeEndStr != null && !appStartedTimeEndStr.isEmpty()) {\n      appStartedTimeEnd = Long.parseLong(appStartedTimeEndStr);\n      if (appStartedTimeEnd < 0) {\n        throw new BadRequestException(\n          \"app.started-time.end must be greater than 0\");\n      }\n    }\n    if (appStartedTimeBegain > appStartedTimeEnd) {\n      throw new BadRequestException(\n        \"app.started-time.end must be greater than app.started-time.begin\");\n    }\n    request.setStartRange(\n        new LongRange(appStartedTimeBegain, appStartedTimeEnd));\n\n    if (callerUGI == null) {\n      appReports = appBaseProt.getApplications(request).getApplicationList();\n    } else {\n      appReports =\n          callerUGI\n            .doAs(new PrivilegedExceptionAction<Collection<ApplicationReport>>() {\n              @Override\n              public Collection<ApplicationReport> run() throws Exception {\n                return appBaseProt.getApplications(request)\n                  .getApplicationList();\n              }\n            });\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.render": "  protected abstract void render(Block html);\n\n  protected UserGroupInformation getCallerUGI() {\n    // Check for the authorization.\n    String remoteUser = request().getRemoteUser();\n    UserGroupInformation callerUGI = null;\n    if (remoteUser != null) {\n      callerUGI = UserGroupInformation.createRemoteUser(remoteUser);\n    }\n    return callerUGI;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.block": "  private Block block() {\n    if (block == null) {\n      block = new Block(writer(), context().nestLevel(), context().wasInline());\n    }\n    return block;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial": "  public void renderPartial() {\n    render();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.render": "  public void render(Class<? extends SubView> cls) {\n    int saved = context().nestLevel;\n    getInstance(cls).renderPartial();\n    if (context().nestLevel != saved) {\n      throw new WebAppException(\"View \"+ cls.getSimpleName() +\" not complete\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.context": "  public ViewContext context() {\n    if (vc == null) {\n      if (injector == null) {\n        // One downside of making the injection in subclasses optional\n        throw new WebAppException(join(\"Error accessing ViewContext from a\\n\",\n            \"child constructor, either move the usage of the View methods\\n\",\n            \"out of the constructor or inject the ViewContext into the\\n\",\n            \"constructor\"));\n      }\n      vc = injector.getInstance(ViewContext.class);\n    }\n    return vc;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.getInstance": "  public <T> T getInstance(Class<T> cls) {\n    return injector().getInstance(cls);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.subView": "    protected void subView(Class<? extends SubView> cls) {\n      context().set(nestLevel(), wasInline());\n      render(cls);\n      setWasInline(context().wasInline());\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.Hamlet._": "  public Hamlet _(Class<? extends SubView> cls) {\n    subView(cls);\n    return this;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsBlockWithMetrics.render": "  @Override public void render(Block html) {\n    html._(MetricsOverviewTable.class);\n    html._(RMAppsBlock.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlPage.subView": "    protected void subView(Class<? extends SubView> cls) {\n      context().set(nestLevel(), wasInline());\n      render(cls);\n      setWasInline(context().wasInline());\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlPage.render": "  protected abstract void render(Page.HTML<_> html);\n}\n",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.HamletImpl._v": "    protected void _v(Class<? extends SubView> cls) {\n      closeAttrs();\n      subView(cls);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.HamletImpl.subView": "  protected void subView(Class<? extends SubView> cls) {\n    indent(of(ENDTAG)); // not an inline view\n    sb.setLength(0);\n    out.print(sb.append('[').append(cls.getName()).append(']').toString());\n    out.println();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.HamletImpl.closeAttrs": "    protected void closeAttrs() {\n      if (!attrsClosed) {\n        startIfNeeded();\n        ++nestLevel;\n        out.print('>');\n        if (!opts.contains(INLINE) && !opts.contains(PRE)) {\n          out.println();\n        }\n        attrsClosed = true;\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render": "  @Override protected void render(Page.HTML<_> html) {\n    preHead(html);\n    html.\n      title($(TITLE)).\n      link(root_url(\"static\",\"yarn.css\")).\n      style(\"#layout { height: 100%; }\",\n            \"#layout thead td { height: 3em; }\",\n            \"#layout #navcell { width: 11em; padding: 0 1em; }\",\n            \"#layout td.content { padding-top: 0 }\",\n            \"#layout tbody { vertical-align: top; }\",\n            \"#layout tfoot td { height: 4em; }\").\n      _(JQueryUI.class);\n    postHead(html);\n    JQueryUI.jsnotice(html);\n    html.\n      table(\"#layout.ui-widget-content\").\n        thead().\n          tr().\n            td().$colspan(2).\n              _(header())._()._()._().\n        tfoot().\n          tr().\n            td().$colspan(2).\n              _(footer())._()._()._().\n        tbody().\n          tr().\n            td().$id(\"navcell\").\n              _(nav())._().\n            td().$class(\"content\").\n              _(content())._()._()._()._()._();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.content": "  protected Class<? extends SubView> content() {\n    return LipsumBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.postHead": "  protected void postHead(Page.HTML<_> html) {\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.nav": "  protected Class<? extends SubView> nav() {\n    return NavBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.header": "  protected Class<? extends SubView> header() {\n    return HeaderBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.preHead": "  protected void preHead(Page.HTML<_> html) {\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.footer": "  protected Class<? extends SubView> footer() {\n    return FooterBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.render": "  private void render(Class<? extends View> cls) {\n    injector.getInstance(cls).render();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.service": "  public void service(HttpServletRequest req, HttpServletResponse res)\n      throws ServletException, IOException {\n    res.setCharacterEncoding(\"UTF-8\");\n    String uri = HtmlQuoting.quoteHtmlChars(req.getRequestURI());\n\n    if (uri == null) {\n      uri = \"/\";\n    }\n    if (devMode && uri.equals(\"/__stop\")) {\n      // quick hack to restart servers in dev mode without OS commands\n      res.setStatus(res.SC_NO_CONTENT);\n      LOG.info(\"dev mode restart requested\");\n      prepareToExit();\n      return;\n    }\n    // if they provide a redirectPath go there instead of going to\n    // \"/\" so that filters can differentiate the webapps.\n    if (uri.equals(\"/\")) {\n      String redirectPath = webApp.getRedirectPath();\n      if (redirectPath != null && !redirectPath.isEmpty()) {\n        res.sendRedirect(redirectPath);\n        return;\n      }\n    }\n    String method = req.getMethod();\n    if (method.equals(\"OPTIONS\")) {\n      doOptions(req, res);\n      return;\n    }\n    if (method.equals(\"TRACE\")) {\n      doTrace(req, res);\n      return;\n    }\n    if (method.equals(\"HEAD\")) {\n      doGet(req, res); // default to bad request\n      return;\n    }\n    String pathInfo = req.getPathInfo();\n    if (pathInfo == null) {\n      pathInfo = \"/\";\n    }\n    Controller.RequestContext rc =\n        injector.getInstance(Controller.RequestContext.class);\n    if (setCookieParams(rc, req) > 0) {\n      Cookie ec = rc.cookies().get(ERROR_COOKIE);\n      if (ec != null) {\n        rc.setStatus(Integer.parseInt(rc.cookies().\n            get(STATUS_COOKIE).getValue()));\n        removeErrorCookies(res, uri);\n        rc.set(Params.ERROR_DETAILS, ec.getValue());\n        render(ErrorPage.class);\n        return;\n      }\n    }\n    rc.prefix = webApp.name();\n    Router.Dest dest = null;\n    try {\n      dest = router.resolve(method, pathInfo);\n    } catch (WebAppException e) {\n      rc.error = e;\n      if (!e.getMessage().contains(\"not found\")) {\n        rc.setStatus(res.SC_INTERNAL_SERVER_ERROR);\n        render(ErrorPage.class);\n        return;\n      }\n    }\n    if (dest == null) {\n      rc.setStatus(res.SC_NOT_FOUND);\n      render(ErrorPage.class);\n      return;\n    }\n    rc.devMode = devMode;\n    setMoreParams(rc, pathInfo, dest);\n    Controller controller = injector.getInstance(dest.controllerClass);\n    try {\n      // TODO: support args converted from /path/:arg1/...\n      dest.action.invoke(controller, (Object[]) null);\n      if (!rc.rendered) {\n        if (dest.defaultViewClass != null) {\n          render(dest.defaultViewClass);\n        } else if (rc.status == 200) {\n          throw new IllegalStateException(\"No view rendered for 200\");\n        }\n      }\n    } catch (Exception e) {\n      LOG.error(\"error handling URI: \"+ uri, e);\n      // Page could be half rendered (but still not flushed). So redirect.\n      redirectToErrorPage(res, e, uri, devMode);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.setMoreParams": "  private void setMoreParams(RequestContext rc, String pathInfo, Dest dest) {\n    checkState(pathInfo.startsWith(dest.prefix), \"prefix should match\");\n    if (dest.pathParams.size() == 0 ||\n        dest.prefix.length() == pathInfo.length()) {\n      return;\n    }\n    String[] parts = Iterables.toArray(WebApp.pathSplitter.split(\n        pathInfo.substring(dest.prefix.length())), String.class);\n    LOG.debug(\"parts={}, params={}\", parts, dest.pathParams);\n    for (int i = 0; i < dest.pathParams.size() && i < parts.length; ++i) {\n      String key = dest.pathParams.get(i);\n      if (key.charAt(0) == ':') {\n        rc.moreParams().put(key.substring(1), parts[i]);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.doOptions": "  public void doOptions(HttpServletRequest req, HttpServletResponse res) {\n    // for simplicity\n    res.setHeader(\"Allow\", \"GET, POST\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.removeErrorCookies": "  public static void removeErrorCookies(HttpServletResponse res, String path) {\n    removeCookie(res, ERROR_COOKIE, path);\n    removeCookie(res, STATUS_COOKIE, path);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.prepareToExit": "  private void prepareToExit() {\n    checkState(devMode, \"only in dev mode\");\n    new Timer(\"webapp exit\", true).schedule(new TimerTask() {\n      @Override public void run() {\n        LOG.info(\"WebAppp /{} exiting...\", webApp.name());\n        webApp.stop();\n        System.exit(0); // FINDBUG: this is intended in dev mode\n      }\n    }, 18); // enough time for the last local request to complete\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.setCookieParams": "  private int setCookieParams(RequestContext rc, HttpServletRequest req) {\n    Cookie[] cookies = req.getCookies();\n    if (cookies != null) {\n      for (Cookie cookie : cookies) {\n        rc.cookies().put(cookie.getName(), cookie);\n      }\n      return cookies.length;\n    }\n    return 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.redirectToErrorPage": "  public static void redirectToErrorPage(HttpServletResponse res, Throwable e,\n                                         String path, boolean devMode) {\n    String st = devMode ? ErrorPage.toStackTrace(e, 1024 * 3) // spec: min 4KB\n                        : \"See logs for stack trace\";\n    res.setStatus(res.SC_FOUND);\n    Cookie cookie = new Cookie(STATUS_COOKIE, String.valueOf(500));\n    cookie.setPath(path);\n    res.addCookie(cookie);\n    cookie = new Cookie(ERROR_COOKIE, st);\n    cookie.setPath(path);\n    res.addCookie(cookie);\n    res.setHeader(\"Location\", path);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.JQueryUI.jsnotice": "  public static void jsnotice(HTML html) {\n    html.\n      div(\"#jsnotice.ui-state-error\").\n          _(\"This page will not function without javascript enabled.\"\n            + \" Please enable javascript on your browser.\")._();\n    html.\n      script().$type(\"text/javascript\").\n        _(\"$('#jsnotice').hide();\")._();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.setStatus": "  public void setStatus(int status) {\n    context().setStatus(status);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.context": "  public RequestContext context() {\n    if (context == null) {\n      if (injector == null) {\n        // One of the downsides of making injection in subclasses optional.\n        throw new WebAppException(join(\"Error accessing RequestContext from\\n\",\n            \"a child constructor, either move the usage of the Controller\\n\",\n            \"methods out of the constructor or inject the RequestContext\\n\",\n            \"into the constructor\"));\n      }\n      context = injector.getInstance(RequestContext.class);\n    }\n    return context;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.cookies": "  public Map<String, Cookie> cookies() {\n    return context().cookies();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.set": "  public void set(String key, String value) {\n    context().set(key, value);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.moreParams": "    public Map<String, String> moreParams() {\n      if (moreParams == null) {\n        moreParams = Maps.newHashMap();\n      }\n      return moreParams; // OK\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.webApp.getRedirectPath": "  public String getRedirectPath() { return this.redirectPath; }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.webApp.name": "  public String name() { return this.name; }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.router.resolve": "  synchronized Dest resolve(String httpMethod, String path) {\n    WebApp.HTTP method = WebApp.HTTP.valueOf(httpMethod); // can throw\n    Dest dest = lookupRoute(method, path);\n    if (dest == null) {\n      return resolveDefault(method, path);\n    }\n    return dest;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.router.lookupRoute": "  private Dest lookupRoute(WebApp.HTTP method, String path) {\n    String key = path;\n    do {\n      Dest dest = routes.get(key);\n      if (dest != null && methodAllowed(method, dest)) {\n        if ((Object)key == path) { // shut up warnings\n          LOG.debug(\"exact match for {}: {}\", key, dest.action);\n          return dest;\n        } else if (isGoodMatch(dest, path)) {\n          LOG.debug(\"prefix match2 for {}: {}\", key, dest.action);\n          return dest;\n        }\n        return resolveAction(method, dest, path);\n      }\n      Map.Entry<String, Dest> lower = routes.lowerEntry(key);\n      if (lower == null) {\n        return null;\n      }\n      dest = lower.getValue();\n      if (prefixMatches(dest, path)) {\n        if (methodAllowed(method, dest)) {\n          if (isGoodMatch(dest, path)) {\n            LOG.debug(\"prefix match for {}: {}\", lower.getKey(), dest.action);\n            return dest;\n          }\n          return resolveAction(method, dest, path);\n        }\n        // check other candidates\n        int slashPos = key.lastIndexOf('/');\n        key = slashPos > 0 ? path.substring(0, slashPos) : \"/\";\n      } else {\n        key = \"/\";\n      }\n    } while (true);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.router.resolveDefault": "  private Dest resolveDefault(WebApp.HTTP method, String path) {\n    List<String> parts = WebApp.parseRoute(path);\n    String controller = parts.get(WebApp.R_CONTROLLER);\n    String action = parts.get(WebApp.R_ACTION);\n    // NameController is encouraged default\n    Class<? extends Controller> cls = find(Controller.class,\n                                           join(controller, \"Controller\"));\n    if (cls == null) {\n      cls = find(Controller.class, controller);\n    }\n    if (cls == null) {\n      throw new WebAppException(join(path, \": controller for \", controller,\n                                \" not found\"));\n    }\n    return add(method, defaultPrefix(controller, action), cls, action, null);\n  }"
        },
        "bug_report": {
            "Title": "RMApps Page crashes with NPE",
            "Description": "{noformat}\n=application_1457010932347_0121\n2016-03-04 10:16:27,016 INFO org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer: application_1457010932347_0121 found existing hdfs token Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:hacluster, Ident: (HDFS_DELEGATION_TOKEN token 128 for yarn with renewer yarn)\n2016-03-04 10:16:27,029 ERROR org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /cluster/apps\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppsBlock.renderData(RMAppsBlock.java:100)\n        at org.apache.hadoop.yarn.server.webapp.AppsBlock.render(AppsBlock.java:140)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n        at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock$Block.subView(HtmlBlock.java:43)\n        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet._(Hamlet.java:30354)\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsBlockWithMetrics.render(AppsBlockWithMetrics.java:30)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n        at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n        at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n        at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)\n        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:848)\n        at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)\n        at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n        at org.apache.hadoop.yarn.webapp.Dispatcher.render(Dispatcher.java:197)\n        at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:156)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)\n\n{noformat}\nApplication state is NEW the apptempts can be empty as per inital analysis\n{noformat}\nrm.getRMContext().getRMApps()\n          .get(appAttemptId.getApplicationId()).getAppAttempts()\n          .get(appAttemptId)\n{noformat}\n"
        }
    },
    {
        "filename": "YARN-8202.json",
        "creation_time": "2018-04-24T15:52:00.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[resource1] < 0 or greater than maximum allowed allocation. Requested resource=<memory:200, vCores:1, resource1: 500M>, maximum allowed allocation=<memory:6144, vCores:8, resource1: 5G>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:8192, resource1: 9223372036854775807G>\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:286)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:242)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndvalidateRequest(SchedulerUtils.java:258)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.normalizeAndValidateRequests(RMServerUtils.java:249)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.allocate(DefaultAMSProcessor.java:230)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor.allocate(DisabledPlacementProcessor.java:75)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain.allocate(AMSProcessingChain.java:92)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:433)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)\n\u00a0 \u00a0 \u00a0 \u00a0 at java.security.AccessController.doPrivileged(Native Method)\n\u00a0 \u00a0 \u00a0 \u00a0 at javax.security.auth.Subject.doAs(Subject.java:422)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest": "  private static void validateResourceRequest(ResourceRequest resReq,\n      Resource maximumResource, QueueInfo queueInfo, RMContext rmContext)\n      throws InvalidResourceRequestException {\n    Resource requestedResource = resReq.getCapability();\n    for (int i = 0; i < ResourceUtils.getNumberOfKnownResourceTypes(); i++) {\n      ResourceInformation reqRI = requestedResource.getResourceInformation(i);\n      ResourceInformation maxRI = maximumResource.getResourceInformation(i);\n      if (reqRI.getValue() < 0 || reqRI.getValue() > maxRI.getValue()) {\n        throw new InvalidResourceRequestException(\n            \"Invalid resource request, requested resource type=[\" + reqRI\n                .getName()\n                + \"] < 0 or greater than maximum allowed allocation. Requested \"\n                + \"resource=\" + requestedResource\n                + \", maximum allowed allocation=\" + maximumResource\n                + \", please note that maximum allowed allocation is calculated \"\n                + \"by scheduler based on maximum resource of registered \"\n                + \"NodeManagers, which might be less than configured \"\n                + \"maximum allocation=\" + ResourceUtils\n                .getResourceTypesMaximumAllocation());\n      }\n    }\n    String labelExp = resReq.getNodeLabelExpression();\n    // we don't allow specify label expression other than resourceName=ANY now\n    if (!ResourceRequest.ANY.equals(resReq.getResourceName())\n        && labelExp != null && !labelExp.trim().isEmpty()) {\n      throw new InvalidLabelResourceRequestException(\n          \"Invalid resource request, queue=\" + queueInfo.getQueueName()\n              + \" specified node label expression in a \"\n              + \"resource request has resource name = \"\n              + resReq.getResourceName());\n    }\n\n    // we don't allow specify label expression with more than one node labels now\n    if (labelExp != null && labelExp.contains(\"&&\")) {\n      throw new InvalidLabelResourceRequestException(\n          \"Invalid resource request, queue=\" + queueInfo.getQueueName()\n              + \" specified more than one node label \"\n              + \"in a node label expression, node label expression = \"\n              + labelExp);\n    }\n\n    if (labelExp != null && !labelExp.trim().isEmpty() && queueInfo != null) {\n      if (!checkQueueLabelExpression(queueInfo.getAccessibleNodeLabels(),\n          labelExp, rmContext)) {\n        throw new InvalidLabelResourceRequestException(\n            \"Invalid resource request\" + \", queue=\" + queueInfo.getQueueName()\n                + \" doesn't have permission to access all labels \"\n                + \"in resource request. labelExpression of resource request=\"\n                + labelExp + \". Queue labels=\"\n                + (queueInfo.getAccessibleNodeLabels() == null ? \"\"\n                    : StringUtils.join(\n                        queueInfo.getAccessibleNodeLabels().iterator(), ',')));\n      } else {\n        checkQueueLabelInLabelManager(labelExp, rmContext);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkQueueLabelInLabelManager": "  private static void checkQueueLabelInLabelManager(String labelExpression,\n      RMContext rmContext) throws InvalidLabelResourceRequestException {\n    // check node label manager contains this label\n    if (null != rmContext) {\n      RMNodeLabelsManager nlm = rmContext.getNodeLabelManager();\n      if (nlm != null && !nlm.containsNodeLabel(labelExpression)) {\n        throw new InvalidLabelResourceRequestException(\n            \"Invalid label resource request, cluster do not contain \"\n                + \", label= \" + labelExpression);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkQueueLabelExpression": "  public static boolean checkQueueLabelExpression(Set<String> queueLabels,\n      String labelExpression, RMContext rmContext) {\n    // if label expression is empty, we can allocate container on any node\n    if (labelExpression == null) {\n      return true;\n    }\n    for (String str : labelExpression.split(\"&&\")) {\n      str = str.trim();\n      if (!str.trim().isEmpty()) {\n        // check queue label\n        if (queueLabels == null) {\n          return false; \n        } else {\n          if (!queueLabels.contains(str)\n              && !queueLabels.contains(RMNodeLabelsManager.ANY)) {\n            return false;\n          }\n        }\n      }\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest": "  public static void normalizeAndValidateRequest(ResourceRequest resReq,\n      Resource maximumResource, String queueName, YarnScheduler scheduler,\n      boolean isRecovery, RMContext rmContext, QueueInfo queueInfo)\n      throws InvalidResourceRequestException {\n    Configuration conf = rmContext.getYarnConfiguration();\n    // If Node label is not enabled throw exception\n    if (null != conf && !YarnConfiguration.areNodeLabelsEnabled(conf)) {\n      String labelExp = resReq.getNodeLabelExpression();\n      if (!(RMNodeLabelsManager.NO_LABEL.equals(labelExp)\n          || null == labelExp)) {\n        String message = \"NodeLabel is not enabled in cluster, but resource\"\n            + \" request contains a label expression.\";\n        LOG.warn(message);\n        if (!isRecovery) {\n          throw new InvalidLabelResourceRequestException(\n              \"Invalid resource request, node label not enabled \"\n                  + \"but request contains label expression\");\n        }\n      }\n    }\n    if (null == queueInfo) {\n      try {\n        queueInfo = scheduler.getQueueInfo(queueName, false, false);\n      } catch (IOException e) {\n        //Queue may not exist since it could be auto-created in case of\n        // dynamic queues\n      }\n    }\n    SchedulerUtils.normalizeNodeLabelExpressionInRequest(resReq, queueInfo);\n\n    if (!isRecovery) {\n      validateResourceRequest(resReq, maximumResource, queueInfo, rmContext);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeNodeLabelExpressionInRequest": "  private static void normalizeNodeLabelExpressionInRequest(\n      ResourceRequest resReq, QueueInfo queueInfo) {\n\n    String labelExp = resReq.getNodeLabelExpression();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Requested Node Label Expression : \" + labelExp);\n      LOG.debug(\"Queue Info : \" + queueInfo);\n    }\n\n    // if queue has default label expression, and RR doesn't have, use the\n    // default label expression of queue\n    if (labelExp == null && queueInfo != null && ResourceRequest.ANY\n        .equals(resReq.getResourceName())) {\n      if ( LOG.isDebugEnabled()) {\n        LOG.debug(\"Setting default node label expression : \" + queueInfo\n            .getDefaultNodeLabelExpression());\n      }\n      labelExp = queueInfo.getDefaultNodeLabelExpression();\n    }\n\n    // If labelExp still equals to null, it could either be a dynamic queue\n    // or the label is not configured\n    // set it to be NO_LABEL in case of a pre-configured queue. Dynamic\n    // queues are handled in RMAppAttemptImp.ScheduledTransition\n    if (labelExp == null && queueInfo != null) {\n      labelExp = RMNodeLabelsManager.NO_LABEL;\n    }\n\n    if ( labelExp != null) {\n      resReq.setNodeLabelExpression(labelExp);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndvalidateRequest": "  public static void normalizeAndvalidateRequest(ResourceRequest resReq,\n      Resource maximumResource, String queueName, YarnScheduler scheduler,\n      RMContext rmContext, QueueInfo queueInfo)\n      throws InvalidResourceRequestException {\n    normalizeAndValidateRequest(resReq, maximumResource, queueName, scheduler,\n        false, rmContext, queueInfo);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.normalizeAndValidateRequests": "  public static void normalizeAndValidateRequests(List<ResourceRequest> ask,\n      Resource maximumResource, String queueName, YarnScheduler scheduler,\n      RMContext rmContext) throws InvalidResourceRequestException {\n    // Get queue from scheduler\n    QueueInfo queueInfo = null;\n    try {\n      queueInfo = scheduler.getQueueInfo(queueName, false, false);\n    } catch (IOException e) {\n      //Queue may not exist since it could be auto-created in case of\n      // dynamic queues\n    }\n\n    for (ResourceRequest resReq : ask) {\n      SchedulerUtils.normalizeAndvalidateRequest(resReq, maximumResource,\n          queueName, scheduler, rmContext, queueInfo);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.allocate": "  public void allocate(ApplicationAttemptId appAttemptId,\n      AllocateRequest request, AllocateResponse response) throws YarnException {\n\n    handleProgress(appAttemptId, request);\n\n    List<ResourceRequest> ask = request.getAskList();\n    List<ContainerId> release = request.getReleaseList();\n\n    ResourceBlacklistRequest blacklistRequest =\n        request.getResourceBlacklistRequest();\n    List<String> blacklistAdditions =\n        (blacklistRequest != null) ?\n            blacklistRequest.getBlacklistAdditions() : Collections.emptyList();\n    List<String> blacklistRemovals =\n        (blacklistRequest != null) ?\n            blacklistRequest.getBlacklistRemovals() : Collections.emptyList();\n    RMApp app =\n        getRmContext().getRMApps().get(appAttemptId.getApplicationId());\n\n    // set label expression for Resource Requests if resourceName=ANY\n    ApplicationSubmissionContext asc = app.getApplicationSubmissionContext();\n    for (ResourceRequest req : ask) {\n      if (null == req.getNodeLabelExpression()\n          && ResourceRequest.ANY.equals(req.getResourceName())) {\n        req.setNodeLabelExpression(asc.getNodeLabelExpression());\n      }\n    }\n\n    Resource maximumCapacity = getScheduler().getMaximumResourceCapability();\n\n    // sanity check\n    try {\n      RMServerUtils.normalizeAndValidateRequests(ask,\n          maximumCapacity, app.getQueue(),\n          getScheduler(), getRmContext());\n    } catch (InvalidResourceRequestException e) {\n      LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n      throw e;\n    }\n\n    try {\n      RMServerUtils.validateBlacklistRequest(blacklistRequest);\n    }  catch (InvalidResourceBlacklistRequestException e) {\n      LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n      throw e;\n    }\n\n    // In the case of work-preserving AM restart, it's possible for the\n    // AM to release containers from the earlier attempt.\n    if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n      try {\n        RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n      } catch (InvalidContainerReleaseException e) {\n        LOG.warn(\"Invalid container release by application \" + appAttemptId,\n            e);\n        throw e;\n      }\n    }\n\n    // Split Update Resource Requests into increase and decrease.\n    // No Exceptions are thrown here. All update errors are aggregated\n    // and returned to the AM.\n    List<UpdateContainerError> updateErrors = new ArrayList<>();\n    ContainerUpdates containerUpdateRequests =\n        RMServerUtils.validateAndSplitUpdateResourceRequests(\n            getRmContext(), request, maximumCapacity, updateErrors);\n\n    // Send new requests to appAttempt.\n    Allocation allocation;\n    RMAppAttemptState state =\n        app.getRMAppAttempt(appAttemptId).getAppAttemptState();\n    if (state.equals(RMAppAttemptState.FINAL_SAVING) ||\n        state.equals(RMAppAttemptState.FINISHING) ||\n        app.isAppFinalStateStored()) {\n      LOG.warn(appAttemptId + \" is in \" + state +\n          \" state, ignore container allocate request.\");\n      allocation = EMPTY_ALLOCATION;\n    } else {\n      try {\n        allocation = getScheduler().allocate(appAttemptId, ask,\n            request.getSchedulingRequests(), release,\n            blacklistAdditions, blacklistRemovals, containerUpdateRequests);\n      } catch (SchedulerInvalidResoureRequestException e) {\n        LOG.warn(\"Exceptions caught when scheduler handling requests\");\n        throw new YarnException(e);\n      }\n    }\n\n    if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n      LOG.info(\"blacklist are updated in Scheduler.\" +\n          \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n          \"blacklistRemovals: \" + blacklistRemovals);\n    }\n    RMAppAttempt appAttempt = app.getRMAppAttempt(appAttemptId);\n\n    if (allocation.getNMTokens() != null &&\n        !allocation.getNMTokens().isEmpty()) {\n      response.setNMTokens(allocation.getNMTokens());\n    }\n\n    // Notify the AM of container update errors\n    ApplicationMasterServiceUtils.addToUpdateContainerErrors(\n        response, updateErrors);\n\n    // update the response with the deltas of node status changes\n    handleNodeUpdates(app, response);\n\n    ApplicationMasterServiceUtils.addToAllocatedContainers(\n        response, allocation.getContainers());\n\n    response.setCompletedContainersStatuses(appAttempt\n        .pullJustFinishedContainers());\n    response.setAvailableResources(allocation.getResourceLimit());\n\n    addToContainerUpdates(response, allocation,\n        ((AbstractYarnScheduler)getScheduler())\n            .getApplicationAttempt(appAttemptId).pullUpdateContainerErrors());\n\n    response.setNumClusterNodes(getScheduler().getNumClusterNodes());\n\n    // add collector address for this application\n    if (YarnConfiguration.timelineServiceV2Enabled(\n        getRmContext().getYarnConfiguration())) {\n      CollectorInfo collectorInfo = app.getCollectorInfo();\n      if (collectorInfo != null) {\n        response.setCollectorInfo(collectorInfo);\n      }\n    }\n\n    // add preemption to the allocateResponse message (if any)\n    response.setPreemptionMessage(generatePreemptionMessage(allocation));\n\n    // Set application priority\n    response.setApplicationPriority(app\n        .getApplicationPriority());\n\n    response.setContainersFromPreviousAttempts(\n        allocation.getPreviousAttemptContainers());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.handleProgress": "  private void handleProgress(ApplicationAttemptId appAttemptId,\n      AllocateRequest request) {\n    //filter illegal progress values\n    float filteredProgress = request.getProgress();\n    if (Float.isNaN(filteredProgress) ||\n        filteredProgress == Float.NEGATIVE_INFINITY ||\n        filteredProgress < 0) {\n      request.setProgress(0);\n    } else if (filteredProgress > 1 ||\n        filteredProgress == Float.POSITIVE_INFINITY) {\n      request.setProgress(1);\n    }\n\n    // Send the status update to the appAttempt.\n    getRmContext().getDispatcher().getEventHandler().handle(\n        new RMAppAttemptStatusupdateEvent(appAttemptId, request\n            .getProgress()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.handleNodeUpdates": "  private void handleNodeUpdates(RMApp app, AllocateResponse allocateResponse) {\n    Map<RMNode, NodeUpdateType> updatedNodes = new HashMap<>();\n    if(app.pullRMNodeUpdates(updatedNodes) > 0) {\n      List<NodeReport> updatedNodeReports = new ArrayList<>();\n      for(Map.Entry<RMNode, NodeUpdateType> rmNodeEntry :\n          updatedNodes.entrySet()) {\n        RMNode rmNode = rmNodeEntry.getKey();\n        SchedulerNodeReport schedulerNodeReport =\n            getScheduler().getNodeReport(rmNode.getNodeID());\n        Resource used = BuilderUtils.newResource(0, 0);\n        int numContainers = 0;\n        if (schedulerNodeReport != null) {\n          used = schedulerNodeReport.getUsedResource();\n          numContainers = schedulerNodeReport.getNumContainers();\n        }\n        NodeId nodeId = rmNode.getNodeID();\n        NodeReport report =\n            BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                rmNode.getTotalCapability(), numContainers,\n                rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                rmNode.getNodeLabels(), rmNode.getDecommissioningTimeout(),\n                rmNodeEntry.getValue());\n\n        updatedNodeReports.add(report);\n      }\n      allocateResponse.setUpdatedNodes(updatedNodeReports);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.generatePreemptionMessage": "  private PreemptionMessage generatePreemptionMessage(Allocation allocation){\n    PreemptionMessage pMsg = null;\n    // assemble strict preemption request\n    if (allocation.getStrictContainerPreemptions() != null) {\n      pMsg =\n          recordFactory.newRecordInstance(PreemptionMessage.class);\n      StrictPreemptionContract pStrict =\n          recordFactory.newRecordInstance(StrictPreemptionContract.class);\n      Set<PreemptionContainer> pCont = new HashSet<>();\n      for (ContainerId cId : allocation.getStrictContainerPreemptions()) {\n        PreemptionContainer pc =\n            recordFactory.newRecordInstance(PreemptionContainer.class);\n        pc.setId(cId);\n        pCont.add(pc);\n      }\n      pStrict.setContainers(pCont);\n      pMsg.setStrictContract(pStrict);\n    }\n\n    // assemble negotiable preemption request\n    if (allocation.getResourcePreemptions() != null &&\n        allocation.getResourcePreemptions().size() > 0 &&\n        allocation.getContainerPreemptions() != null &&\n        allocation.getContainerPreemptions().size() > 0) {\n      if (pMsg == null) {\n        pMsg =\n            recordFactory.newRecordInstance(PreemptionMessage.class);\n      }\n      PreemptionContract contract =\n          recordFactory.newRecordInstance(PreemptionContract.class);\n      Set<PreemptionContainer> pCont = new HashSet<>();\n      for (ContainerId cId : allocation.getContainerPreemptions()) {\n        PreemptionContainer pc =\n            recordFactory.newRecordInstance(PreemptionContainer.class);\n        pc.setId(cId);\n        pCont.add(pc);\n      }\n      List<PreemptionResourceRequest> pRes = new ArrayList<>();\n      for (ResourceRequest crr : allocation.getResourcePreemptions()) {\n        PreemptionResourceRequest prr =\n            recordFactory.newRecordInstance(PreemptionResourceRequest.class);\n        prr.setResourceRequest(crr);\n        pRes.add(prr);\n      }\n      contract.setContainers(pCont);\n      contract.setResourceRequest(pRes);\n      pMsg.setContract(contract);\n    }\n\n    return pMsg;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.getRmContext": "  protected RMContext getRmContext() {\n    return rmContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.getScheduler": "  protected YarnScheduler getScheduler() {\n    return rmContext.getScheduler();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.addToContainerUpdates": "  private static void addToContainerUpdates(AllocateResponse allocateResponse,\n      Allocation allocation, List<UpdateContainerError> updateContainerErrors) {\n    // Handling increased containers\n    ApplicationMasterServiceUtils.addToUpdatedContainers(\n        allocateResponse, ContainerUpdateType.INCREASE_RESOURCE,\n        allocation.getIncreasedContainers());\n\n    // Handling decreased containers\n    ApplicationMasterServiceUtils.addToUpdatedContainers(\n        allocateResponse, ContainerUpdateType.DECREASE_RESOURCE,\n        allocation.getDecreasedContainers());\n\n    // Handling promoted containers\n    ApplicationMasterServiceUtils.addToUpdatedContainers(\n        allocateResponse, ContainerUpdateType.PROMOTE_EXECUTION_TYPE,\n        allocation.getPromotedContainers());\n\n    // Handling demoted containers\n    ApplicationMasterServiceUtils.addToUpdatedContainers(\n        allocateResponse, ContainerUpdateType.DEMOTE_EXECUTION_TYPE,\n        allocation.getDemotedContainers());\n\n    ApplicationMasterServiceUtils.addToUpdateContainerErrors(\n        allocateResponse, updateContainerErrors);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor.allocate": "  public void allocate(ApplicationAttemptId appAttemptId,\n      AllocateRequest request, AllocateResponse response) throws YarnException {\n    if (request.getSchedulingRequests() != null && !request\n        .getSchedulingRequests().isEmpty()) {\n      String message = \"Found non empty SchedulingRequest in \"\n          + \"AllocateRequest for application=\"\n          + appAttemptId.toString() + \", but the configured \"\n          + YarnConfiguration.RM_PLACEMENT_CONSTRAINTS_HANDLER\n          + \" cannot handle placement constraints. Rejecting this \"\n          + \"allocate operation\";\n      LOG.warn(message);\n      throw new YarnException(message);\n    }\n    nextAMSProcessor.allocate(appAttemptId, request, response);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain.allocate": "  public void allocate(ApplicationAttemptId appAttemptId,\n      AllocateRequest request, AllocateResponse response) throws YarnException {\n    this.head.allocate(appAttemptId, request, response);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier =\n        YarnServerSecurityUtils.authorizeRequest();\n\n    ApplicationAttemptId appAttemptId =\n        amrmTokenIdentifier.getApplicationAttemptId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock = responseMap.get(appAttemptId);\n    if (lock == null) {\n      String message =\n          \"Application attempt \" + appAttemptId\n              + \" doesn't exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse = lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message =\n            \"AM is not registered for known application attempt: \"\n                + appAttemptId\n                + \" or RM had restarted after AM registered. \"\n                + \" AM should re-register.\";\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      // Normally request.getResponseId() == lastResponse.getResponseId()\n      if (getNextResponseId(request.getResponseId()) == lastResponse\n          .getResponseId()) {\n        // heartbeat one step old, simply return lastReponse\n        return lastResponse;\n      } else if (request.getResponseId() != lastResponse.getResponseId()) {\n        String message =\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + lastResponse.getResponseId() + \", but get \"\n                + request.getResponseId();\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      AllocateResponse response =\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      this.amsProcessingChain.allocate(\n          amrmTokenIdentifier.getApplicationAttemptId(), request, response);\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey =\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey != null\n          && nextMasterKey.getMasterKey().getKeyId() != amrmTokenIdentifier\n          .getKeyId()) {\n        RMApp app =\n            this.rmContext.getRMApps().get(appAttemptId.getApplicationId());\n        RMAppAttempt appAttempt = app.getRMAppAttempt(appAttemptId);\n        RMAppAttemptImpl appAttemptImpl = (RMAppAttemptImpl)appAttempt;\n        Token<AMRMTokenIdentifier> amrmToken = appAttempt.getAMRMToken();\n        if (nextMasterKey.getMasterKey().getKeyId() !=\n            appAttemptImpl.getAMRMTokenKeyId()) {\n          LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n              + \" to application: \" + appAttemptId.getApplicationId());\n          amrmToken = rmContext.getAMRMTokenSecretManager()\n              .createAndGetAMRMToken(appAttemptId);\n          appAttemptImpl.setAMRMToken(amrmToken);\n        }\n        response.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n            .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n                .toString(), amrmToken.getPassword(), amrmToken.getService()\n                .toString()));\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don't\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      response.setResponseId(getNextResponseId(lastResponse.getResponseId()));\n      lock.setAllocateResponse(response);\n      return response;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.getAllocateResponse": "    public synchronized AllocateResponse getAllocateResponse() {\n      return response;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.getNextResponseId": "  private int getNextResponseId(int responseId) {\n    // Loop between 0 to Integer.MAX_VALUE\n    return (responseId + 1) & Integer.MAX_VALUE;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.hasApplicationMasterRegistered": "  public boolean hasApplicationMasterRegistered(\n      ApplicationAttemptId appAttemptId) {\n    boolean hasApplicationMasterRegistered = false;\n    AllocateResponseLock lastResponse = responseMap.get(appAttemptId);\n    if (lastResponse != null) {\n      synchronized (lastResponse) {\n        if (lastResponse.getAllocateResponse() != null\n            && lastResponse.getAllocateResponse().getResponseId() >= 0) {\n          hasApplicationMasterRegistered = true;\n        }\n      }\n    }\n    return hasApplicationMasterRegistered;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.setAllocateResponse": "    public synchronized void setAllocateResponse(AllocateResponse response) {\n      this.response = response;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate": "  public AllocateResponseProto allocate(RpcController arg0,\n      AllocateRequestProto proto) throws ServiceException {\n    AllocateRequestPBImpl request = new AllocateRequestPBImpl(proto);\n    try {\n      AllocateResponse response = real.allocate(request);\n      return ((AllocateResponsePBImpl)response).getProto();\n    } catch (YarnException e) {\n      throw new ServiceException(e);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcProtobufRequest request = (RpcProtobufRequest) writableRequest;\n        RequestHeaderProto rpcRequest = request.getRequestHeader();\n        String methodName = rpcRequest.getMethodName();\n\n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = request.getValue(prototype);\n\n        Message result;\n        long startTime = Time.now();\n        int qTime = (int) (startTime - receiveTime);\n        Exception exception = null;\n        boolean isDeferred = false;\n        try {\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          currentCallInfo.set(new CallInfo(server, methodName));\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n          // Check if this needs to be a deferred response,\n          // by checking the ThreadLocal callback being set\n          if (currentCallback.get() != null) {\n            Server.getCurCall().get().deferResponse();\n            isDeferred = true;\n            currentCallback.set(null);\n            return null;\n          }\n        } catch (ServiceException e) {\n          exception = (Exception) e.getCause();\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          exception = e;\n          throw e;\n        } finally {\n          currentCallInfo.set(null);\n          int processingTime = (int) (Time.now() - startTime);\n          if (LOG.isDebugEnabled()) {\n            String msg =\n                \"Served: \" + methodName + (isDeferred ? \", deferred\" : \"\") +\n                    \", queueTime= \" + qTime +\n                    \" procesingTime= \" + processingTime;\n            if (exception != null) {\n              msg += \" exception= \" + exception.getClass().getSimpleName();\n            }\n            LOG.debug(msg);\n          }\n          String detailedMetricsName = (exception == null) ?\n              methodName :\n              exception.getClass().getSimpleName();\n          server.updateMetrics(detailedMetricsName, qTime, processingTime,\n              isDeferred);\n        }\n        return RpcWritable.wrap(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.get": "          public Message get(long timeout, TimeUnit unit) throws Exception {\n            return getReturnMessage(method, arr.get(timeout, unit));\n          }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getProtocolImpl": "      private static ProtoClassProtoImpl getProtocolImpl(RPC.Server server,\n          String protoName, long clientVersion) throws RpcServerException {\n        ProtoNameVer pv = new ProtoNameVer(protoName, clientVersion);\n        ProtoClassProtoImpl impl = \n            server.getProtocolImplMap(RPC.RpcKind.RPC_PROTOCOL_BUFFER).get(pv);\n        if (impl == null) { // no match for Protocol AND Version\n          VerProtocolImpl highest = \n              server.getHighestSupportedProtocol(RPC.RpcKind.RPC_PROTOCOL_BUFFER, \n                  protoName);\n          if (highest == null) {\n            throw new RpcNoSuchProtocolException(\n                \"Unknown protocol: \" + protoName);\n          }\n          // protocol supported but not the version that client wants\n          throw new RPC.VersionMismatch(protoName, clientVersion,\n              highest.version);\n        }\n        return impl;\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getRequestHeader": "    RequestHeaderProto getRequestHeader() throws IOException {\n      if (getByteBuffer() != null && requestHeader == null) {\n        requestHeader = getValue(RequestHeaderProto.getDefaultInstance());\n      }\n      return requestHeader;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RPC.call": "    public Writable call(RPC.RpcKind rpcKind, String protocol,\n        Writable rpcRequest, long receiveTime) throws Exception {\n      return getRpcInvoker(rpcKind).call(this, protocol, rpcRequest,\n          receiveTime);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.run": "        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupResponse": "  private void setupResponse(RpcCall call,\n      RpcResponseHeaderProto header, Writable rv) throws IOException {\n    final byte[] response;\n    if (rv == null || (rv instanceof RpcWritable.ProtobufWrapper)) {\n      response = setupResponseForProtobuf(header, rv);\n    } else {\n      response = setupResponseForWritable(header, rv);\n    }\n    if (response.length > maxRespSize) {\n      LOG.warn(\"Large response size \" + response.length + \" for call \"\n          + call.toString());\n    }\n    call.setResponse(ByteBuffer.wrap(response));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeIdle": "    synchronized void closeIdle(boolean scanAll) {\n      long minLastContact = Time.now() - maxIdleTime;\n      // concurrent iterator might miss new connections added\n      // during the iteration, but that's ok because they won't\n      // be idle yet anyway and will be caught on next scan\n      int closed = 0;\n      for (Connection connection : connections) {\n        // stop if connections dropped below threshold unless scanning all\n        if (!scanAll && size() < idleScanThreshold) {\n          break;\n        }\n        // stop if not scanning all and max connections are closed\n        if (connection.isIdle() &&\n            connection.getLastContact() < minLastContact &&\n            close(connection) &&\n            !scanAll && (++closed == maxIdleToClose)) {\n          break;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.close": "    boolean close(Connection connection) {\n      boolean exists = remove(connection);\n      if (exists) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(Thread.currentThread().getName() +\n              \": disconnecting client \" + connection +\n              \". Number of active connections: \"+ size());\n        }\n        // only close if actually removed to avoid double-closing due\n        // to possible races\n        connection.close();\n        // Remove authorized users only\n        if (connection.user != null && connection.connectionContextRead) {\n          decrUserConnections(connection.user.getShortUserName());\n        }\n      }\n      return exists;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRunLoop": "    private void doRunLoop() {\n      long lastPurgeTime = 0;   // last check for old calls.\n\n      while (running) {\n        try {\n          waitPending();     // If a channel is being registered, wait.\n          writeSelector.select(PURGE_INTERVAL);\n          Iterator<SelectionKey> iter = writeSelector.selectedKeys().iterator();\n          while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            iter.remove();\n            try {\n              if (key.isWritable()) {\n                doAsyncWrite(key);\n              }\n            } catch (CancelledKeyException cke) {\n              // something else closed the connection, ex. reader or the\n              // listener doing an idle scan.  ignore it and let them clean\n              // up\n              RpcCall call = (RpcCall)key.attachment();\n              if (call != null) {\n                LOG.info(Thread.currentThread().getName() +\n                    \": connection aborted from \" + call.connection);\n              }\n            } catch (IOException e) {\n              LOG.info(Thread.currentThread().getName() + \": doAsyncWrite threw exception \" + e);\n            }\n          }\n          long now = Time.now();\n          if (now < lastPurgeTime + PURGE_INTERVAL) {\n            continue;\n          }\n          lastPurgeTime = now;\n          //\n          // If there were some calls that have not been sent out for a\n          // long time, discard them.\n          //\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"Checking for old call responses.\");\n          }\n          ArrayList<RpcCall> calls;\n          \n          // get the list of channels from list of keys.\n          synchronized (writeSelector.keys()) {\n            calls = new ArrayList<RpcCall>(writeSelector.keys().size());\n            iter = writeSelector.keys().iterator();\n            while (iter.hasNext()) {\n              SelectionKey key = iter.next();\n              RpcCall call = (RpcCall)key.attachment();\n              if (call != null && key.channel() == call.connection.channel) { \n                calls.add(call);\n              }\n            }\n          }\n\n          for (RpcCall call : calls) {\n            doPurge(call, now);\n          }\n        } catch (OutOfMemoryError e) {\n          //\n          // we can run out of memory if we have too many threads\n          // log the event and sleep for a minute and give\n          // some thread(s) a chance to finish\n          //\n          LOG.warn(\"Out of Memory in server select\", e);\n          try { Thread.sleep(60000); } catch (Exception ie) {}\n        } catch (Exception e) {\n          LOG.warn(\"Exception in Responder\", e);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.populateResponseParamsOnError": "    private void populateResponseParamsOnError(Throwable t,\n                                               ResponseParams responseParams) {\n      if (t instanceof UndeclaredThrowableException) {\n        t = t.getCause();\n      }\n      logException(Server.LOG, t, this);\n      if (t instanceof RpcServerException) {\n        RpcServerException rse = ((RpcServerException) t);\n        responseParams.returnStatus = rse.getRpcStatusProto();\n        responseParams.detailedErr = rse.getRpcErrorCodeProto();\n      } else {\n        responseParams.returnStatus = RpcStatusProto.ERROR;\n        responseParams.detailedErr = RpcErrorCodeProto.ERROR_APPLICATION;\n      }\n      responseParams.errorClass = t.getClass().getName();\n      responseParams.error = StringUtils.stringifyException(t);\n      // Remove redundant error class name from the beginning of the\n      // stack trace\n      String exceptionHdr = responseParams.errorClass + \": \";\n      if (responseParams.error.startsWith(exceptionHdr)) {\n        responseParams.error =\n            responseParams.error.substring(exceptionHdr.length());\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.stopIdleScan": "    void stopIdleScan() {\n      idleScanTimer.cancel();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeCurrentConnection": "    private void closeCurrentConnection(SelectionKey key, Throwable e) {\n      if (key != null) {\n        Connection c = (Connection)key.attachment();\n        if (c != null) {\n          closeConnection(c);\n          c = null;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doAccept": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server = (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel = server.accept()) != null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader = getReader();\n        Connection c = connectionManager.register(channel);\n        // If the connectionManager can't take it, close the connection.\n        if (c == null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanup(null, channel);\n          }\n          connectionManager.droppedConnections.getAndIncrement();\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeAll": "    void closeAll() {\n      // use a copy of the connections to be absolutely sure the concurrent\n      // iterator doesn't miss a connection\n      for (Connection connection : toArray()) {\n        close(connection);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.scheduleIdleScanTask": "    private void scheduleIdleScanTask() {\n      if (!running) {\n        return;\n      }\n      TimerTask idleScanTask = new TimerTask(){\n        @Override\n        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }\n      };\n      idleScanTimer.schedule(idleScanTask, idleScanInterval);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.call": "  public abstract Writable call(RPC.RpcKind rpcKind, String protocol,\n      Writable param, long receiveTime) throws Exception;\n  \n  /**\n   * Authorize the incoming client connection.\n   * \n   * @param user client user\n   * @param protocolName - the protocol\n   * @param addr InetAddress of incoming connection\n   * @throws AuthorizationException when the client isn't authorized to talk the protocol\n   */\n  private void authorize(UserGroupInformation user, String protocolName,\n      InetAddress addr) throws AuthorizationException {\n    if (authorize) {\n      if (protocolName == null) {\n        throw new AuthorizationException(\"Null protocol not authorized\");\n      }\n      Class<?> protocol = null;\n      try {\n        protocol = getProtocolClass(protocolName, getConf());\n      } catch (ClassNotFoundException cfne) {\n        throw new AuthorizationException(\"Unknown protocol: \" + \n                                         protocolName);\n      }\n      serviceAuthorizationManager.authorize(user, protocol, getConf(), addr);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getSelector": "    synchronized Selector getSelector() { return selector; }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.sendResponse": "    private void sendResponse(RpcCall call) throws IOException {\n      responder.doRespond(call);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getRemoteUser": "    public UserGroupInformation getRemoteUser() {\n      return connection.user;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.startIdleScan": "    void startIdleScan() {\n      scheduleIdleScanTask();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.isResponseDeferred": "    public boolean isResponseDeferred() {\n      return this.deferredResponse;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.remove": "    private boolean remove(Connection connection) {\n      boolean removed = connections.remove(connection);\n      if (removed) {\n        count.getAndDecrement();\n      }\n      return removed;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateAndSplitUpdateResourceRequests": "  public static ContainerUpdates\n      validateAndSplitUpdateResourceRequests(RMContext rmContext,\n      AllocateRequest request, Resource maximumAllocation,\n      List<UpdateContainerError> updateErrors) {\n    ContainerUpdates updateRequests =\n        new ContainerUpdates();\n    Set<ContainerId> outstandingUpdate = new HashSet<>();\n    for (UpdateContainerRequest updateReq : request.getUpdateRequests()) {\n      RMContainer rmContainer = rmContext.getScheduler().getRMContainer(\n          updateReq.getContainerId());\n      String msg = validateContainerIdAndVersion(outstandingUpdate,\n          updateReq, rmContainer);\n      ContainerUpdateType updateType = updateReq.getContainerUpdateType();\n      if (msg == null) {\n        if ((updateType != ContainerUpdateType.PROMOTE_EXECUTION_TYPE) &&\n            (updateType !=ContainerUpdateType.DEMOTE_EXECUTION_TYPE)) {\n          if (validateIncreaseDecreaseRequest(\n              rmContext, updateReq, maximumAllocation)) {\n            if (ContainerUpdateType.INCREASE_RESOURCE == updateType) {\n              updateRequests.getIncreaseRequests().add(updateReq);\n            } else {\n              updateRequests.getDecreaseRequests().add(updateReq);\n            }\n            outstandingUpdate.add(updateReq.getContainerId());\n          } else {\n            msg = RESOURCE_OUTSIDE_ALLOWED_RANGE;\n          }\n        } else {\n          ExecutionType original = rmContainer.getExecutionType();\n          ExecutionType target = updateReq.getExecutionType();\n          if (target != original) {\n            if (target == ExecutionType.GUARANTEED &&\n                original == ExecutionType.OPPORTUNISTIC) {\n              updateRequests.getPromotionRequests().add(updateReq);\n              outstandingUpdate.add(updateReq.getContainerId());\n            } else if (target == ExecutionType.OPPORTUNISTIC &&\n                original == ExecutionType.GUARANTEED) {\n              updateRequests.getDemotionRequests().add(updateReq);\n              outstandingUpdate.add(updateReq.getContainerId());\n            }\n          }\n        }\n      }\n      checkAndcreateUpdateError(updateErrors, updateReq, rmContainer, msg);\n    }\n    return updateRequests;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateIncreaseDecreaseRequest": "  private static boolean validateIncreaseDecreaseRequest(RMContext rmContext,\n      UpdateContainerRequest request, Resource maximumAllocation) {\n    if (request.getCapability().getMemorySize() < 0\n        || request.getCapability().getMemorySize() > maximumAllocation\n        .getMemorySize()) {\n      return false;\n    }\n    if (request.getCapability().getVirtualCores() < 0\n        || request.getCapability().getVirtualCores() > maximumAllocation\n        .getVirtualCores()) {\n      return false;\n    }\n    ResourceScheduler scheduler = rmContext.getScheduler();\n    request.setCapability(scheduler.getNormalizedResource(request.getCapability()));\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.checkAndcreateUpdateError": "  private static void checkAndcreateUpdateError(\n      List<UpdateContainerError> errors, UpdateContainerRequest updateReq,\n      RMContainer rmContainer, String msg) {\n    if (msg != null) {\n      UpdateContainerError updateError = RECORD_FACTORY\n          .newRecordInstance(UpdateContainerError.class);\n      updateError.setReason(msg);\n      updateError.setUpdateContainerRequest(updateReq);\n      if (rmContainer != null) {\n        updateError.setCurrentContainerVersion(\n            rmContainer.getContainer().getVersion());\n      } else {\n        updateError.setCurrentContainerVersion(-1);\n      }\n      errors.add(updateError);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateContainerIdAndVersion": "  private static String validateContainerIdAndVersion(\n      Set<ContainerId> outstandingUpdate, UpdateContainerRequest updateReq,\n      RMContainer rmContainer) {\n    String msg = null;\n    if (rmContainer == null) {\n      msg = INVALID_CONTAINER_ID;\n    }\n    // Only allow updates if the requested version matches the current\n    // version\n    if (msg == null && updateReq.getContainerVersion() !=\n        rmContainer.getContainer().getVersion()) {\n      msg = INCORRECT_CONTAINER_VERSION_ERROR;\n    }\n    // No more than 1 container update per request.\n    if (msg == null &&\n        outstandingUpdate.contains(updateReq.getContainerId())) {\n      msg = UPDATE_OUTSTANDING_ERROR;\n    }\n    return msg;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateContainerReleaseRequest": "  public static void\n      validateContainerReleaseRequest(List<ContainerId> containerReleaseList,\n      ApplicationAttemptId appAttemptId)\n      throws InvalidContainerReleaseException {\n    for (ContainerId cId : containerReleaseList) {\n      if (!appAttemptId.equals(cId.getApplicationAttemptId())) {\n        throw new InvalidContainerReleaseException(\n            \"Cannot release container : \"\n                + cId.toString()\n                + \" not belonging to this application attempt : \"\n                + appAttemptId);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateBlacklistRequest": "  public static void validateBlacklistRequest(\n      ResourceBlacklistRequest blacklistRequest)\n      throws InvalidResourceBlacklistRequestException {\n    if (blacklistRequest != null) {\n      List<String> plus = blacklistRequest.getBlacklistAdditions();\n      if (plus != null && plus.contains(ResourceRequest.ANY)) {\n        throw new InvalidResourceBlacklistRequestException(\n            \"Cannot add \" + ResourceRequest.ANY + \" to the blacklist!\");\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getAMRMTokenSecretManager": "  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getCurCall": "  public static ThreadLocal<Call> getCurCall() {\n    return CurCall;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.updateMetrics": "  void updateMetrics(String name, int queueTime, int processingTime,\n                     boolean deferredCall) {\n    rpcMetrics.addRpcQueueTime(queueTime);\n    if (!deferredCall) {\n      rpcMetrics.addRpcProcessingTime(processingTime);\n      rpcDetailedMetrics.addProcessingTime(name, processingTime);\n      callQueue.addResponseTime(name, getPriorityLevel(), queueTime,\n          processingTime);\n      if (isLogSlowRPC()) {\n        logSlowRpcCalls(name, processingTime);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.getPriorityLevel": "    public int getPriorityLevel() {\n      return this.priorityLevel;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.isLogSlowRPC": "  protected boolean isLogSlowRPC() {\n    return logSlowRPC;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.logSlowRpcCalls": "  void logSlowRpcCalls(String methodName, int processingTime) {\n    final int deviation = 3;\n\n    // 1024 for minSampleSize just a guess -- not a number computed based on\n    // sample size analysis. It is chosen with the hope that this\n    // number is high enough to avoid spurious logging, yet useful\n    // in practice.\n    final int minSampleSize = 1024;\n    final double threeSigma = rpcMetrics.getProcessingMean() +\n        (rpcMetrics.getProcessingStdDev() * deviation);\n\n    if ((rpcMetrics.getProcessingSampleCount() > minSampleSize) &&\n        (processingTime > threeSigma)) {\n      if(LOG.isWarnEnabled()) {\n        String client = CurCall.get().toString();\n        LOG.warn(\n            \"Slow RPC : \" + methodName + \" took \" + processingTime +\n                \" milliseconds to process from client \" + client);\n      }\n      rpcMetrics.incrSlowRpc();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcWritable.wrap": "    public static Buffer wrap(ByteBuffer bb) {\n      return new Buffer(bb);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.CallerContext.setCurrent": "  public static void setCurrent(CallerContext callerContext) {\n    CurrentCallerContextHolder.CALLER_CONTEXT.set(callerContext);\n  }"
        },
        "bug_report": {
            "Title": "DefaultAMSProcessor should properly check units of requested custom resource types against minimum/maximum allocation",
            "Description": "\u00a0\r\n\r\nWhen I execute a pi job with arguments:\u00a0\r\n{code:java}\r\n-Dmapreduce.map.resource.memory-mb=200 -Dmapreduce.map.resource.resource1=500M 1 1000{code}\r\nand I have one node with 5GB of resource1, I get the following exception on every second and the job hangs:\r\n{code:java}\r\n2018-04-24 08:42:03,694 INFO org.apache.hadoop.ipc.Server: IPC Server handler 20 on 8030, call Call#386 Retry#0 org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.allocate from 172.31.119.172:58138\r\n\r\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[resource1] < 0 or greater than maximum allowed allocation. Requested resource=<memory:200, vCores:1, resource1: 500M>, maximum allowed allocation=<memory:6144, vCores:8, resource1: 5G>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:8192, resource1: 9223372036854775807G>\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:286)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:242)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndvalidateRequest(SchedulerUtils.java:258)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.normalizeAndValidateRequests(RMServerUtils.java:249)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.allocate(DefaultAMSProcessor.java:230)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor.allocate(DisabledPlacementProcessor.java:75)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain.allocate(AMSProcessingChain.java:92)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:433)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.security.AccessController.doPrivileged(Native Method)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at javax.security.auth.Subject.doAs(Subject.java:422)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)\r\n{code}\r\n*This is because\u00a0org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils#validateResourceRequest does not take resource units into account.*\r\n\r\n\u00a0\r\n\r\nHowever, if I start a job with arguments:\u00a0\r\n{code:java}\r\n-Dmapreduce.map.resource.memory-mb=200 -Dmapreduce.map.resource.resource1=1G 1 1000{code}\r\nand I still have 5GB of resource1 on one node then the job runs successfully.\r\n\r\n\u00a0\r\n\r\nI also tried a third\u00a0job run, when I request 1GB of resource1 and I have no nodes with any amount of resource1, then I restart the node with 5GBs of resource1, the job ultimately completes, but just after the node with enough resources registered in RM, which is the desired behaviour.\r\n\r\n\u00a0"
        }
    },
    {
        "filename": "YARN-7118.json",
        "creation_time": "2017-08-29T12:04:01.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.webapp.WebServices.getApps(WebServices.java:191)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices.getApps(AHSWebServices.java:96)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.WebServices.getApps": "  public AppsInfo getApps(HttpServletRequest req, HttpServletResponse res,\n      String stateQuery, Set<String> statesQuery, String finalStatusQuery,\n      String userQuery, String queueQuery, String count, String startedBegin,\n      String startedEnd, String finishBegin, String finishEnd,\n      Set<String> applicationTypes) {\n    UserGroupInformation callerUGI = getUser(req);\n    boolean checkEnd = false;\n    boolean checkAppTypes = false;\n    boolean checkAppStates = false;\n    long countNum = Long.MAX_VALUE;\n\n    // set values suitable in case both of begin/end not specified\n    long sBegin = 0;\n    long sEnd = Long.MAX_VALUE;\n    long fBegin = 0;\n    long fEnd = Long.MAX_VALUE;\n\n    if (count != null && !count.isEmpty()) {\n      countNum = Long.parseLong(count);\n      if (countNum <= 0) {\n        throw new BadRequestException(\"limit value must be greater then 0\");\n      }\n    }\n\n    if (startedBegin != null && !startedBegin.isEmpty()) {\n      sBegin = Long.parseLong(startedBegin);\n      if (sBegin < 0) {\n        throw new BadRequestException(\"startedTimeBegin must be greater than 0\");\n      }\n    }\n    if (startedEnd != null && !startedEnd.isEmpty()) {\n      sEnd = Long.parseLong(startedEnd);\n      if (sEnd < 0) {\n        throw new BadRequestException(\"startedTimeEnd must be greater than 0\");\n      }\n    }\n    if (sBegin > sEnd) {\n      throw new BadRequestException(\n        \"startedTimeEnd must be greater than startTimeBegin\");\n    }\n\n    if (finishBegin != null && !finishBegin.isEmpty()) {\n      checkEnd = true;\n      fBegin = Long.parseLong(finishBegin);\n      if (fBegin < 0) {\n        throw new BadRequestException(\"finishTimeBegin must be greater than 0\");\n      }\n    }\n    if (finishEnd != null && !finishEnd.isEmpty()) {\n      checkEnd = true;\n      fEnd = Long.parseLong(finishEnd);\n      if (fEnd < 0) {\n        throw new BadRequestException(\"finishTimeEnd must be greater than 0\");\n      }\n    }\n    if (fBegin > fEnd) {\n      throw new BadRequestException(\n        \"finishTimeEnd must be greater than finishTimeBegin\");\n    }\n\n    Set<String> appTypes = parseQueries(applicationTypes, false);\n    if (!appTypes.isEmpty()) {\n      checkAppTypes = true;\n    }\n\n    // stateQuery is deprecated.\n    if (stateQuery != null && !stateQuery.isEmpty()) {\n      statesQuery.add(stateQuery);\n    }\n    Set<String> appStates = parseQueries(statesQuery, true);\n    if (!appStates.isEmpty()) {\n      checkAppStates = true;\n    }\n\n    AppsInfo allApps = new AppsInfo();\n    Collection<ApplicationReport> appReports = null;\n    final GetApplicationsRequest request =\n        GetApplicationsRequest.newInstance();\n    request.setLimit(countNum);\n    request.setStartRange(new LongRange(sBegin, sEnd));\n    try {\n      if (callerUGI == null) {\n        // TODO: the request should take the params like what RMWebServices does\n        // in YARN-1819.\n        appReports = appBaseProt.getApplications(request).getApplicationList();\n      } else {\n        appReports = callerUGI.doAs(\n            new PrivilegedExceptionAction<Collection<ApplicationReport>> () {\n          @Override\n          public Collection<ApplicationReport> run() throws Exception {\n            return appBaseProt.getApplications(request).getApplicationList();\n          }\n        });\n      }\n    } catch (Exception e) {\n      rewrapAndThrowException(e);\n    }\n    if (appReports == null) {\n      return allApps;\n    }\n    for (ApplicationReport appReport : appReports) {\n\n      if (checkAppStates &&\n          !appStates.contains(StringUtils.toLowerCase(\n              appReport.getYarnApplicationState().toString()))) {\n        continue;\n      }\n      if (finalStatusQuery != null && !finalStatusQuery.isEmpty()) {\n        FinalApplicationStatus.valueOf(finalStatusQuery);\n        if (!appReport.getFinalApplicationStatus().toString()\n          .equalsIgnoreCase(finalStatusQuery)) {\n          continue;\n        }\n      }\n      if (userQuery != null && !userQuery.isEmpty()) {\n        if (!appReport.getUser().equals(userQuery)) {\n          continue;\n        }\n      }\n      if (queueQuery != null && !queueQuery.isEmpty()) {\n        if (!appReport.getQueue().equals(queueQuery)) {\n          continue;\n        }\n      }\n      if (checkAppTypes &&\n          !appTypes.contains(\n              StringUtils.toLowerCase(appReport.getApplicationType().trim()))) {\n        continue;\n      }\n\n      if (checkEnd\n          && (appReport.getFinishTime() < fBegin || appReport.getFinishTime() > fEnd)) {\n        continue;\n      }\n      AppInfo app = new AppInfo(appReport);\n\n      allApps.add(app);\n    }\n    return allApps;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.WebServices.getUser": "  protected static UserGroupInformation getUser(HttpServletRequest req) {\n    String remoteUser = req.getRemoteUser();\n    UserGroupInformation callerUGI = null;\n    if (remoteUser != null) {\n      callerUGI = UserGroupInformation.createRemoteUser(remoteUser);\n    }\n    return callerUGI;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.WebServices.rewrapAndThrowException": "  private static void rewrapAndThrowException(Exception e) {\n    if (e instanceof UndeclaredThrowableException) {\n      rewrapAndThrowThrowable(e.getCause());\n    } else {\n      rewrapAndThrowThrowable(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.WebServices.parseQueries": "  protected static Set<String>\n      parseQueries(Set<String> queries, boolean isState) {\n    Set<String> params = new HashSet<String>();\n    if (!queries.isEmpty()) {\n      for (String query : queries) {\n        if (query != null && !query.trim().isEmpty()) {\n          String[] paramStrs = query.split(\",\");\n          for (String paramStr : paramStrs) {\n            if (paramStr != null && !paramStr.trim().isEmpty()) {\n              if (isState) {\n                try {\n                  // enum string is in the uppercase\n                  YarnApplicationState.valueOf(\n                      StringUtils.toUpperCase(paramStr.trim()));\n                } catch (RuntimeException e) {\n                  YarnApplicationState[] stateArray =\n                      YarnApplicationState.values();\n                  String allAppStates = Arrays.toString(stateArray);\n                  throw new BadRequestException(\"Invalid application-state \"\n                      + paramStr.trim() + \" specified. It should be one of \"\n                      + allAppStates);\n                }\n              }\n              params.add(StringUtils.toLowerCase(paramStr.trim()));\n            }\n          }\n        }\n      }\n    }\n    return params;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices.getApps": "  public AppsInfo getApps(@Context HttpServletRequest req,\n      @Context HttpServletResponse res, @QueryParam(\"state\") String stateQuery,\n      @QueryParam(\"states\") Set<String> statesQuery,\n      @QueryParam(\"finalStatus\") String finalStatusQuery,\n      @QueryParam(\"user\") String userQuery,\n      @QueryParam(\"queue\") String queueQuery,\n      @QueryParam(\"limit\") String count,\n      @QueryParam(\"startedTimeBegin\") String startedBegin,\n      @QueryParam(\"startedTimeEnd\") String startedEnd,\n      @QueryParam(\"finishedTimeBegin\") String finishBegin,\n      @QueryParam(\"finishedTimeEnd\") String finishEnd,\n      @QueryParam(\"applicationTypes\") Set<String> applicationTypes) {\n    init(res);\n    validateStates(stateQuery, statesQuery);\n    return super.getApps(req, res, stateQuery, statesQuery, finalStatusQuery,\n      userQuery, queueQuery, count, startedBegin, startedEnd, finishBegin,\n      finishEnd, applicationTypes);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices.validateStates": "  private static void\n      validateStates(String stateQuery, Set<String> statesQuery) {\n    // stateQuery is deprecated.\n    if (stateQuery != null && !stateQuery.isEmpty()) {\n      statesQuery.add(stateQuery);\n    }\n    Set<String> appStates = parseQueries(statesQuery, true);\n    for (String appState : appStates) {\n      switch (YarnApplicationState.valueOf(\n          StringUtils.toUpperCase(appState))) {\n        case FINISHED:\n        case FAILED:\n        case KILLED:\n          continue;\n        default:\n          throw new BadRequestException(\"Invalid application-state \" + appState\n              + \" specified. It should be a final state\");\n      }\n    }\n  }"
        },
        "bug_report": {
            "Title": "AHS REST API can return NullPointerException",
            "Description": "ApplicationHistoryService REST Api returns NullPointerException\n{code}\n[prabhu@prabhu2 root]$ curl --negotiate -u: 'http://<ATS IP>:8188/ws/v1/applicationhistory/apps?queue=test'\n{\"exception\":\"NullPointerException\",\"javaClassName\":\"java.lang.NullPointerException\"}\n{code}\n\nTimelineServer logs shows below.\n\n{code}\n2017-08-17 17:54:54,128 WARN  webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.webapp.WebServices.getApps(WebServices.java:191)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices.getApps(AHSWebServices.java:96)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n{code}\n\n\n"
        }
    },
    {
        "filename": "YARN-4743.json",
        "creation_time": "2016-02-27T09:12:28.000+0000",
        "stack_trace": "```\njava.lang.IllegalArgumentException: Comparison method violates its general contract!\n         at java.util.TimSort.mergeHi(TimSort.java:868)\n         at java.util.TimSort.mergeAt(TimSort.java:485)\n         at java.util.TimSort.mergeCollapse(TimSort.java:410)\n         at java.util.TimSort.sort(TimSort.java:214)\n         at java.util.TimSort.sort(TimSort.java:173)\n         at java.util.Arrays.sort(Arrays.java:659)\n         at java.util.Collections.sort(Collections.java:217)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:316)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:240)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1091)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:989)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1185)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:112)\n         at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n         at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    Resource assigned = Resources.none();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Node \" + node.getNodeName() + \" offered to queue: \" +\n          getName() + \" fairShare: \" + getFairShare());\n    }\n\n    if (!assignContainerPreCheck(node)) {\n      return assigned;\n    }\n\n    // Apps that have resource demands.\n    TreeSet<FSAppAttempt> pendingForResourceApps =\n        new TreeSet<FSAppAttempt>(policy.getComparator());\n    readLock.lock();\n    try {\n      for (FSAppAttempt app : runnableApps) {\n        Resource pending = app.getAppAttemptResourceUsage().getPending();\n        if (!pending.equals(Resources.none())) {\n          pendingForResourceApps.add(app);\n        }\n      }\n    } finally {\n      readLock.unlock();\n    }\n    for (FSAppAttempt sched : pendingForResourceApps) {\n      if (SchedulerAppUtils.isBlacklisted(sched, node, LOG)) {\n        continue;\n      }\n      assigned = sched.assignContainer(node);\n      if (!assigned.equals(Resources.none())) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Assigned container in queue:\" + getName() + \" \" +\n              \"container:\" + assigned);\n        }\n        break;\n      }\n    }\n    return assigned;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    Resource assigned = Resources.none();\n\n    // If this queue is over its limit, reject\n    if (!assignContainerPreCheck(node)) {\n      return assigned;\n    }\n\n    // Hold the write lock when sorting childQueues\n    writeLock.lock();\n    try {\n      Collections.sort(childQueues, policy.getComparator());\n    } finally {\n      writeLock.unlock();\n    }\n\n    /*\n     * We are releasing the lock between the sort and iteration of the\n     * \"sorted\" list. There could be changes to the list here:\n     * 1. Add a child queue to the end of the list, this doesn't affect\n     * container assignment.\n     * 2. Remove a child queue, this is probably good to take care of so we\n     * don't assign to a queue that is going to be removed shortly.\n     */\n    readLock.lock();\n    try {\n      for (FSQueue child : childQueues) {\n        assigned = child.assignContainer(node);\n        if (!Resources.equals(assigned, Resources.none())) {\n          break;\n        }\n      }\n    } finally {\n      readLock.unlock();\n    }\n    return assigned;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling": "  synchronized void attemptScheduling(FSSchedulerNode node) {\n    if (rmContext.isWorkPreservingRecoveryEnabled()\n        && !rmContext.isSchedulerReadyForAllocatingContainers()) {\n      return;\n    }\n\n    final NodeId nodeID = node.getNodeID();\n    if (!nodes.containsKey(nodeID)) {\n      // The node might have just been removed while this thread was waiting\n      // on the synchronized lock before it entered this synchronized method\n      LOG.info(\"Skipping scheduling as the node \" + nodeID +\n          \" has been removed\");\n      return;\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    boolean validReservation = false;\n    FSAppAttempt reservedAppSchedulable = node.getReservedAppSchedulable();\n    if (reservedAppSchedulable != null) {\n      validReservation = reservedAppSchedulable.assignReservedContainer(node);\n    }\n    if (!validReservation) {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers = 0;\n      while (node.getReservedContainer() == null) {\n        boolean assignedContainer = false;\n        if (!queueMgr.getRootQueue().assignContainer(node).equals(\n            Resources.none())) {\n          assignedContainers++;\n          assignedContainer = true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers >= maxAssign) && (maxAssign > 0)) { break; }\n      }\n    }\n    updateRootQueueMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateRootQueueMetrics": "  private void updateRootQueueMetrics() {\n    rootMetrics.setAvailableResourcesToQueue(\n        Resources.subtract(\n            clusterResource, rootMetrics.getAllocatedResources()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start = getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node = getFSSchedulerNode(nm.getNodeID());\n    \n    List<UpdatedContainerInfo> containerInfoList = nm.pullContainerUpdates();\n    List<ContainerStatus> newlyLaunchedContainers = new ArrayList<ContainerStatus>();\n    List<ContainerStatus> completedContainers = new ArrayList<ContainerStatus>();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() == NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getUsedResource(), 0)));\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration = getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getClock": "  public Clock getClock() {\n    return clock;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getFSSchedulerNode": "  private FSSchedulerNode getFSSchedulerNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getContainerReports(),\n          nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID(),\n              appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName, appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n      break;\n    case NODE_RESOURCE_UPDATE:\n      if (!(event instanceof NodeResourceUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeResource(nodeResourceUpdatedEvent.getRMNode(),\n            nodeResourceUpdatedEvent.getResourceOption());\n      break;\n    case APP_ATTEMPT_ADDED:\n      if (!(event instanceof AppAttemptAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n      break;\n    case APP_ATTEMPT_REMOVED:\n      if (!(event instanceof AppAttemptRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      removeApplicationAttempt(\n          appAttemptRemovedEvent.getApplicationAttemptID(),\n          appAttemptRemovedEvent.getFinalAttemptState(),\n          appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      super.completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignReservedContainer": "  public boolean assignReservedContainer(FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    Priority reservedPriority = rmContainer.getReservedPriority();\n\n    if (!isValidReservation(node)) {\n      // Don't hold the reservation if app can no longer use it\n      LOG.info(\"Releasing reservation that cannot be satisfied for \" +\n          \"application \" + getApplicationAttemptId() + \" on node \" + node);\n      unreserve(reservedPriority, node);\n      return false;\n    }\n\n    // Reservation valid; try to fulfill the reservation\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Trying to fulfill reservation for application \"\n          + getApplicationAttemptId() + \" on node: \" + node);\n    }\n\n    // Fail early if the reserved container won't fit.\n    // Note that we have an assumption here that\n    // there's only one container size per priority.\n    if (Resources.fitsIn(node.getReservedContainer().getReservedResource(),\n        node.getAvailableResource())) {\n      assignContainer(node, true);\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    if (isOverAMShareLimit()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Skipping allocation because maxAMShare limit would \" +\n            \"be exceeded\");\n      }\n      return Resources.none();\n    }\n    return assignContainer(node, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.isValidReservation": "  private boolean isValidReservation(FSSchedulerNode node) {\n    Priority reservedPriority = node.getReservedContainer().\n        getReservedPriority();\n    return hasContainerForNode(reservedPriority, node) &&\n        !isOverAMShareLimit();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserve": "  public void unreserve(Priority priority, FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    unreserveInternal(priority, node);\n    node.unreserveResource(this);\n    clearReservation(node);\n    getMetrics().unreserveResource(\n        getUser(), rmContainer.getContainer().getResource());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.getReservedAppSchedulable": "  public synchronized FSAppAttempt getReservedAppSchedulable() {\n    return reservedAppSchedulable;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.fsOpDurations.addNodeUpdateDuration": "  public void addNodeUpdateDuration(long value) {\n    nodeUpdateCall.add(value);\n  }"
        },
        "bug_report": {
            "Title": "FairSharePolicy breaks TimSort assumption",
            "Description": "{code}\n2016-02-26 14:08:50,821 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler\njava.lang.IllegalArgumentException: Comparison method violates its general contract!\n         at java.util.TimSort.mergeHi(TimSort.java:868)\n         at java.util.TimSort.mergeAt(TimSort.java:485)\n         at java.util.TimSort.mergeCollapse(TimSort.java:410)\n         at java.util.TimSort.sort(TimSort.java:214)\n         at java.util.TimSort.sort(TimSort.java:173)\n         at java.util.Arrays.sort(Arrays.java:659)\n         at java.util.Collections.sort(Collections.java:217)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:316)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:240)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1091)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:989)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1185)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:112)\n         at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n         at java.lang.Thread.run(Thread.java:745)\n2016-02-26 14:08:50,822 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Exiting, bbye..\n{code}\n\nActually, this bug found in 2.6.0-cdh5.4.7. {{FairShareComparator}} is not transitive.\n\nWe get NaN when memorySize=0 and weight=0.\n{code:title=FairSharePolicy.java}\nuseToWeightRatio1 = s1.getResourceUsage().getMemorySize() /\n  s1.getWeights().getWeight(ResourceType.MEMORY)\n{code}\n"
        }
    },
    {
        "filename": "YARN-2414.json",
        "creation_time": "2014-08-12T23:48:48.000+0000",
        "stack_trace": "```\njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:153)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)\n\tat com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)\n\tat com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter(RMWebAppFilter.java:84)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:460)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1191)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.AppBlock.render(AppBlock.java:116)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:67)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:77)\n\tat org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n\tat org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)\n\tat org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:845)\n\tat org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:56)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n\tat org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:212)\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app(RmController.java:55)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.service": "  public void service(HttpServletRequest req, HttpServletResponse res)\n      throws ServletException, IOException {\n    res.setCharacterEncoding(\"UTF-8\");\n    String uri = HtmlQuoting.quoteHtmlChars(req.getRequestURI());\n\n    if (uri == null) {\n      uri = \"/\";\n    }\n    if (devMode && uri.equals(\"/__stop\")) {\n      // quick hack to restart servers in dev mode without OS commands\n      res.setStatus(res.SC_NO_CONTENT);\n      LOG.info(\"dev mode restart requested\");\n      prepareToExit();\n      return;\n    }\n    // if they provide a redirectPath go there instead of going to\n    // \"/\" so that filters can differentiate the webapps.\n    if (uri.equals(\"/\")) {\n      String redirectPath = webApp.getRedirectPath();\n      if (redirectPath != null && !redirectPath.isEmpty()) {\n        res.sendRedirect(redirectPath);\n        return;\n      }\n    }\n    String method = req.getMethod();\n    if (method.equals(\"OPTIONS\")) {\n      doOptions(req, res);\n      return;\n    }\n    if (method.equals(\"TRACE\")) {\n      doTrace(req, res);\n      return;\n    }\n    if (method.equals(\"HEAD\")) {\n      doGet(req, res); // default to bad request\n      return;\n    }\n    String pathInfo = req.getPathInfo();\n    if (pathInfo == null) {\n      pathInfo = \"/\";\n    }\n    Controller.RequestContext rc =\n        injector.getInstance(Controller.RequestContext.class);\n    if (setCookieParams(rc, req) > 0) {\n      Cookie ec = rc.cookies().get(ERROR_COOKIE);\n      if (ec != null) {\n        rc.setStatus(Integer.parseInt(rc.cookies().\n            get(STATUS_COOKIE).getValue()));\n        removeErrorCookies(res, uri);\n        rc.set(Params.ERROR_DETAILS, ec.getValue());\n        render(ErrorPage.class);\n        return;\n      }\n    }\n    rc.prefix = webApp.name();\n    Router.Dest dest = null;\n    try {\n      dest = router.resolve(method, pathInfo);\n    } catch (WebAppException e) {\n      rc.error = e;\n      if (!e.getMessage().contains(\"not found\")) {\n        rc.setStatus(res.SC_INTERNAL_SERVER_ERROR);\n        render(ErrorPage.class);\n        return;\n      }\n    }\n    if (dest == null) {\n      rc.setStatus(res.SC_NOT_FOUND);\n      render(ErrorPage.class);\n      return;\n    }\n    rc.devMode = devMode;\n    setMoreParams(rc, pathInfo, dest);\n    Controller controller = injector.getInstance(dest.controllerClass);\n    try {\n      // TODO: support args converted from /path/:arg1/...\n      dest.action.invoke(controller, (Object[]) null);\n      if (!rc.rendered) {\n        if (dest.defaultViewClass != null) {\n          render(dest.defaultViewClass);\n        } else if (rc.status == 200) {\n          throw new IllegalStateException(\"No view rendered for 200\");\n        }\n      }\n    } catch (Exception e) {\n      LOG.error(\"error handling URI: \"+ uri, e);\n      // Page could be half rendered (but still not flushed). So redirect.\n      redirectToErrorPage(res, e, uri, devMode);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.setMoreParams": "  private void setMoreParams(RequestContext rc, String pathInfo, Dest dest) {\n    checkState(pathInfo.startsWith(dest.prefix), \"prefix should match\");\n    if (dest.pathParams.size() == 0 ||\n        dest.prefix.length() == pathInfo.length()) {\n      return;\n    }\n    String[] parts = Iterables.toArray(WebApp.pathSplitter.split(\n        pathInfo.substring(dest.prefix.length())), String.class);\n    LOG.debug(\"parts={}, params={}\", parts, dest.pathParams);\n    for (int i = 0; i < dest.pathParams.size() && i < parts.length; ++i) {\n      String key = dest.pathParams.get(i);\n      if (key.charAt(0) == ':') {\n        rc.moreParams().put(key.substring(1), parts[i]);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.doOptions": "  public void doOptions(HttpServletRequest req, HttpServletResponse res) {\n    // for simplicity\n    res.setHeader(\"Allow\", \"GET, POST\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.removeErrorCookies": "  public static void removeErrorCookies(HttpServletResponse res, String path) {\n    removeCookie(res, ERROR_COOKIE, path);\n    removeCookie(res, STATUS_COOKIE, path);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.prepareToExit": "  private void prepareToExit() {\n    checkState(devMode, \"only in dev mode\");\n    new Timer(\"webapp exit\", true).schedule(new TimerTask() {\n      @Override public void run() {\n        LOG.info(\"WebAppp /{} exiting...\", webApp.name());\n        webApp.stop();\n        System.exit(0); // FINDBUG: this is intended in dev mode\n      }\n    }, 18); // enough time for the last local request to complete\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.setCookieParams": "  private int setCookieParams(RequestContext rc, HttpServletRequest req) {\n    Cookie[] cookies = req.getCookies();\n    if (cookies != null) {\n      for (Cookie cookie : cookies) {\n        rc.cookies().put(cookie.getName(), cookie);\n      }\n      return cookies.length;\n    }\n    return 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.render": "  private void render(Class<? extends View> cls) {\n    injector.getInstance(cls).render();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Dispatcher.redirectToErrorPage": "  public static void redirectToErrorPage(HttpServletResponse res, Throwable e,\n                                         String path, boolean devMode) {\n    String st = devMode ? ErrorPage.toStackTrace(e, 1024 * 3) // spec: min 4KB\n                        : \"See logs for stack trace\";\n    res.setStatus(res.SC_FOUND);\n    Cookie cookie = new Cookie(STATUS_COOKIE, String.valueOf(500));\n    cookie.setPath(path);\n    res.addCookie(cookie);\n    cookie = new Cookie(ERROR_COOKIE, st);\n    cookie.setPath(path);\n    res.addCookie(cookie);\n    res.setHeader(\"Location\", path);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter": "  public void doFilter(HttpServletRequest request,\n      HttpServletResponse response, FilterChain chain) throws IOException,\n      ServletException {\n    response.setCharacterEncoding(\"UTF-8\");\n    String uri = HtmlQuoting.quoteHtmlChars(request.getRequestURI());\n\n    if (uri == null) {\n      uri = \"/\";\n    }\n    RMWebApp rmWebApp = injector.getInstance(RMWebApp.class);\n    rmWebApp.checkIfStandbyRM();\n    if (rmWebApp.isStandby()\n        && shouldRedirect(rmWebApp, uri)) {\n      String redirectPath = rmWebApp.getRedirectPath() + uri;\n\n      if (redirectPath != null && !redirectPath.isEmpty()) {\n        String redirectMsg =\n            \"This is standby RM. Redirecting to the current active RM: \"\n                + redirectPath;\n        response.addHeader(\"Refresh\", \"3; url=\" + redirectPath);\n        PrintWriter out = response.getWriter();\n        out.println(redirectMsg);\n        return;\n      }\n    }\n\n    super.doFilter(request, response, chain);\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.shouldRedirect": "  private boolean shouldRedirect(RMWebApp rmWebApp, String uri) {\n    return !uri.equals(\"/\" + rmWebApp.wsName() + \"/v1/cluster/info\")\n        && !uri.equals(\"/\" + rmWebApp.name() + \"/cluster\")\n        && !NON_REDIRECTED_URIS.contains(uri);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.lib.StaticUserWebFilter.doFilter": "    public void doFilter(ServletRequest request, ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequest httpRequest = (HttpServletRequest) request;\n      // if the user is already authenticated, don't override it\n      if (httpRequest.getRemoteUser() != null) {\n        chain.doFilter(request, response);\n      } else {\n        HttpServletRequestWrapper wrapper = \n            new HttpServletRequestWrapper(httpRequest) {\n          @Override\n          public Principal getUserPrincipal() {\n            return user;\n          }\n          @Override\n          public String getRemoteUser() {\n            return username;\n          }\n        };\n        chain.doFilter(wrapper, response);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.lib.StaticUserWebFilter.getRemoteUser": "          public String getRemoteUser() {\n            return username;\n          }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.doFilter": "    public void doFilter(ServletRequest request,\n                         ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequestWrapper quoted =\n        new RequestQuoter((HttpServletRequest) request);\n      HttpServletResponse httpResponse = (HttpServletResponse) response;\n\n      String mime = inferMimeType(request);\n      if (mime == null) {\n        httpResponse.setContentType(\"text/plain; charset=utf-8\");\n      } else if (mime.startsWith(\"text/html\")) {\n        // HTML with unspecified encoding, we want to\n        // force HTML with utf-8 encoding\n        // This is to avoid the following security issue:\n        // http://openmya.hacker.jp/hasegawa/security/utf7cs.html\n        httpResponse.setContentType(\"text/html; charset=utf-8\");\n      } else if (mime.startsWith(\"application/xml\")) {\n        httpResponse.setContentType(\"text/xml; charset=utf-8\");\n      }\n      chain.doFilter(quoted, httpResponse);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.inferMimeType": "    private String inferMimeType(ServletRequest request) {\n      String path = ((HttpServletRequest)request).getRequestURI();\n      ContextHandler.SContext sContext = (ContextHandler.SContext)config.getServletContext();\n      MimeTypes mimes = sContext.getContextHandler().getMimeTypes();\n      Buffer mimeBuffer = mimes.getMimeByExtension(path);\n      return (mimeBuffer == null) ? null : mimeBuffer.toString();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.NoCacheFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n                       FilterChain chain)\n    throws IOException, ServletException {\n    HttpServletResponse httpRes = (HttpServletResponse) res;\n    httpRes.setHeader(\"Cache-Control\", \"no-cache\");\n    long now = System.currentTimeMillis();\n    httpRes.addDateHeader(\"Expires\", now);\n    httpRes.addDateHeader(\"Date\", now);\n    httpRes.addHeader(\"Pragma\", \"no-cache\");\n    chain.doFilter(req, res);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.render": "  protected void render(Block html) {\n    String aid = $(APPLICATION_ID);\n    if (aid.isEmpty()) {\n      puts(\"Bad request: requires Application ID\");\n      return;\n    }\n\n    ApplicationId appID = null;\n    try {\n      appID = Apps.toAppID(aid);\n    } catch (Exception e) {\n      puts(\"Invalid Application ID: \" + aid);\n      return;\n    }\n\n    ApplicationReport appReport;\n    try {\n      appReport = appContext.getApplication(appID);\n    } catch (IOException e) {\n      String message = \"Failed to read the application \" + appID + \".\";\n      LOG.error(message, e);\n      html.p()._(message)._();\n      return;\n    }\n    if (appReport == null) {\n      puts(\"Application not found: \" + aid);\n      return;\n    }\n    AppInfo app = new AppInfo(appReport);\n\n    setTitle(join(\"Application \", aid));\n\n    info(\"Application Overview\")\n      ._(\"User:\", app.getUser())\n      ._(\"Name:\", app.getName())\n      ._(\"Application Type:\", app.getType())\n      ._(\"State:\", app.getAppState())\n      ._(\"FinalStatus:\", app.getFinalAppStatus())\n      ._(\"Started:\", Times.format(app.getStartedTime()))\n      ._(\n        \"Elapsed:\",\n        StringUtils.formatTime(Times.elapsed(app.getStartedTime(),\n          app.getFinishedTime())))\n      ._(\"Tracking URL:\",\n        app.getTrackingUrl() == null ? \"#\" : root_url(app.getTrackingUrl()),\n        \"History\")._(\"Diagnostics:\", app.getDiagnosticsInfo());\n\n    html._(InfoBlock.class);\n\n    Collection<ApplicationAttemptReport> attempts;\n    try {\n      attempts = appContext.getApplicationAttempts(appID).values();\n    } catch (IOException e) {\n      String message =\n          \"Failed to read the attempts of the application \" + appID + \".\";\n      LOG.error(message, e);\n      html.p()._(message)._();\n      return;\n    }\n\n    // Application Attempt Table\n    TBODY<TABLE<Hamlet>> tbody =\n        html.table(\"#attempts\").thead().tr().th(\".id\", \"Attempt ID\")\n          .th(\".started\", \"Started\").th(\".node\", \"Node\").th(\".logs\", \"Logs\")\n          ._()._().tbody();\n\n    StringBuilder attemptsTableData = new StringBuilder(\"[\\n\");\n    for (ApplicationAttemptReport appAttemptReport : attempts) {\n      AppAttemptInfo appAttempt = new AppAttemptInfo(appAttemptReport);\n      ContainerReport containerReport;\n      try {\n        containerReport =\n            appContext.getAMContainer(appAttemptReport\n              .getApplicationAttemptId());\n      } catch (IOException e) {\n        String message =\n            \"Failed to read the AM container of the application attempt \"\n                + appAttemptReport.getApplicationAttemptId() + \".\";\n        LOG.error(message, e);\n        html.p()._(message)._();\n        return;\n      }\n      long startTime = Long.MAX_VALUE;\n      String logsLink = null;\n      if (containerReport != null) {\n        ContainerInfo container = new ContainerInfo(containerReport);\n        startTime = container.getStartedTime();\n        logsLink = containerReport.getLogUrl();\n      }\n      String nodeLink = null;\n      if (appAttempt.getHost() != null && appAttempt.getRpcPort() >= 0\n          && appAttempt.getRpcPort() < 65536) {\n        nodeLink = appAttempt.getHost() + \":\" + appAttempt.getRpcPort();\n      }\n      // AppAttemptID numerical value parsed by parseHadoopID in\n      // yarn.dt.plugins.js\n      attemptsTableData\n        .append(\"[\\\"<a href='\")\n        .append(url(\"appattempt\", appAttempt.getAppAttemptId()))\n        .append(\"'>\")\n        .append(appAttempt.getAppAttemptId())\n        .append(\"</a>\\\",\\\"\")\n        .append(startTime)\n        .append(\"\\\",\\\"<a href='\")\n        .append(\n          nodeLink == null ? \"#\" : url(\"//\", nodeLink))\n        .append(\"'>\")\n        .append(\n          nodeLink == null ? \"N/A\" : StringEscapeUtils\n            .escapeJavaScript(StringEscapeUtils.escapeHtml(nodeLink)))\n        .append(\"</a>\\\",\\\"<a href='\")\n        .append(logsLink == null ? \"#\" : logsLink).append(\"'>\")\n        .append(logsLink == null ? \"N/A\" : \"Logs\").append(\"</a>\\\"],\\n\");\n    }\n    if (attemptsTableData.charAt(attemptsTableData.length() - 2) == ',') {\n      attemptsTableData.delete(attemptsTableData.length() - 2,\n        attemptsTableData.length() - 1);\n    }\n    attemptsTableData.append(\"]\");\n    html.script().$type(\"text/javascript\")\n      ._(\"var attemptsTableData=\" + attemptsTableData)._();\n\n    tbody._()._();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.render": "  protected abstract void render(Block html);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.block": "  private Block block() {\n    if (block == null) {\n      block = new Block(writer(), context().nestLevel(), context().wasInline());\n    }\n    return block;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial": "  public void renderPartial() {\n    render();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.render": "  public void render(Class<? extends SubView> cls) {\n    int saved = context().nestLevel;\n    getInstance(cls).renderPartial();\n    if (context().nestLevel != saved) {\n      throw new WebAppException(\"View \"+ cls.getSimpleName() +\" not complete\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.context": "  public ViewContext context() {\n    if (vc == null) {\n      if (injector == null) {\n        // One downside of making the injection in subclasses optional\n        throw new WebAppException(join(\"Error accessing ViewContext from a\\n\",\n            \"child constructor, either move the usage of the View methods\\n\",\n            \"out of the constructor or inject the ViewContext into the\\n\",\n            \"constructor\"));\n      }\n      vc = injector.getInstance(ViewContext.class);\n    }\n    return vc;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.getInstance": "  public <T> T getInstance(Class<T> cls) {\n    return injector().getInstance(cls);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlPage.subView": "    protected void subView(Class<? extends SubView> cls) {\n      context().set(nestLevel(), wasInline());\n      render(cls);\n      setWasInline(context().wasInline());\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlPage.render": "  protected abstract void render(Page.HTML<_> html);\n}\n",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.HamletImpl._v": "    protected void _v(Class<? extends SubView> cls) {\n      closeAttrs();\n      subView(cls);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.HamletImpl.subView": "  protected void subView(Class<? extends SubView> cls) {\n    indent(of(ENDTAG)); // not an inline view\n    sb.setLength(0);\n    out.print(sb.append('[').append(cls.getName()).append(']').toString());\n    out.println();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.HamletImpl.closeAttrs": "    protected void closeAttrs() {\n      if (!attrsClosed) {\n        startIfNeeded();\n        ++nestLevel;\n        out.print('>');\n        if (!opts.contains(INLINE) && !opts.contains(PRE)) {\n          out.println();\n        }\n        attrsClosed = true;\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet.Hamlet._": "  public Hamlet _(Class<? extends SubView> cls) {\n    subView(cls);\n    return this;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render": "  @Override protected void render(Page.HTML<_> html) {\n    preHead(html);\n    html.\n      title($(TITLE)).\n      link(root_url(\"static\",\"yarn.css\")).\n      style(\"#layout { height: 100%; }\",\n            \"#layout thead td { height: 3em; }\",\n            \"#layout #navcell { width: 11em; padding: 0 1em; }\",\n            \"#layout td.content { padding-top: 0 }\",\n            \"#layout tbody { vertical-align: top; }\",\n            \"#layout tfoot td { height: 4em; }\").\n      _(JQueryUI.class);\n    postHead(html);\n    JQueryUI.jsnotice(html);\n    html.\n      table(\"#layout.ui-widget-content\").\n        thead().\n          tr().\n            td().$colspan(2).\n              _(header())._()._()._().\n        tfoot().\n          tr().\n            td().$colspan(2).\n              _(footer())._()._()._().\n        tbody().\n          tr().\n            td().$id(\"navcell\").\n              _(nav())._().\n            td().$class(\"content\").\n              _(content())._()._()._()._()._();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.content": "  protected Class<? extends SubView> content() {\n    return LipsumBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.postHead": "  protected void postHead(Page.HTML<_> html) {\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.nav": "  protected Class<? extends SubView> nav() {\n    return NavBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.header": "  protected Class<? extends SubView> header() {\n    return HeaderBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.preHead": "  protected void preHead(Page.HTML<_> html) {\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.footer": "  protected Class<? extends SubView> footer() {\n    return FooterBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.render": "  protected void render(Class<? extends View> cls) {\n    context().rendered = true;\n    getInstance(cls).render();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.context": "  public RequestContext context() {\n    if (context == null) {\n      if (injector == null) {\n        // One of the downsides of making injection in subclasses optional.\n        throw new WebAppException(join(\"Error accessing RequestContext from\\n\",\n            \"a child constructor, either move the usage of the Controller\\n\",\n            \"methods out of the constructor or inject the RequestContext\\n\",\n            \"into the constructor\"));\n      }\n      context = injector.getInstance(RequestContext.class);\n    }\n    return context;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.getInstance": "  public <T> T getInstance(Class<T> cls) {\n    return injector.getInstance(cls);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app": "  public void app() {\n    render(AppPage.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.setStatus": "  public void setStatus(int status) {\n    context().setStatus(status);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.cookies": "  public Map<String, Cookie> cookies() {\n    return context().cookies();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.set": "  public void set(String key, String value) {\n    context().set(key, value);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.moreParams": "    public Map<String, String> moreParams() {\n      if (moreParams == null) {\n        moreParams = Maps.newHashMap();\n      }\n      return moreParams; // OK\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.webApp.getRedirectPath": "  public String getRedirectPath() { return this.redirectPath; }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.webApp.name": "  public String name() { return this.name; }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.router.resolve": "  synchronized Dest resolve(String httpMethod, String path) {\n    WebApp.HTTP method = WebApp.HTTP.valueOf(httpMethod); // can throw\n    Dest dest = lookupRoute(method, path);\n    if (dest == null) {\n      return resolveDefault(method, path);\n    }\n    return dest;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.router.lookupRoute": "  private Dest lookupRoute(WebApp.HTTP method, String path) {\n    String key = path;\n    do {\n      Dest dest = routes.get(key);\n      if (dest != null && methodAllowed(method, dest)) {\n        if ((Object)key == path) { // shut up warnings\n          LOG.debug(\"exact match for {}: {}\", key, dest.action);\n          return dest;\n        } else if (isGoodMatch(dest, path)) {\n          LOG.debug(\"prefix match2 for {}: {}\", key, dest.action);\n          return dest;\n        }\n        return resolveAction(method, dest, path);\n      }\n      Map.Entry<String, Dest> lower = routes.lowerEntry(key);\n      if (lower == null) {\n        return null;\n      }\n      dest = lower.getValue();\n      if (prefixMatches(dest, path)) {\n        if (methodAllowed(method, dest)) {\n          if (isGoodMatch(dest, path)) {\n            LOG.debug(\"prefix match for {}: {}\", lower.getKey(), dest.action);\n            return dest;\n          }\n          return resolveAction(method, dest, path);\n        }\n        // check other candidates\n        int slashPos = key.lastIndexOf('/');\n        key = slashPos > 0 ? path.substring(0, slashPos) : \"/\";\n      } else {\n        key = \"/\";\n      }\n    } while (true);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.router.resolveDefault": "  private Dest resolveDefault(WebApp.HTTP method, String path) {\n    List<String> parts = WebApp.parseRoute(path);\n    String controller = parts.get(WebApp.R_CONTROLLER);\n    String action = parts.get(WebApp.R_ACTION);\n    // NameController is encouraged default\n    Class<? extends Controller> cls = find(Controller.class,\n                                           join(controller, \"Controller\"));\n    if (cls == null) {\n      cls = find(Controller.class, controller);\n    }\n    if (cls == null) {\n      throw new WebAppException(join(path, \": controller for \", controller,\n                                \" not found\"));\n    }\n    return add(method, defaultPrefix(controller, action), cls, action, null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.checkIfStandbyRM": "  public void checkIfStandbyRM() {\n    standby = (rm.getRMContext().getHAServiceState() == HAServiceState.STANDBY);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.getRedirectPath": "  public String getRedirectPath() {\n    if (standby) {\n      return buildRedirectPath();\n    } else\n      return super.getRedirectPath();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.buildRedirectPath": "  private String buildRedirectPath() {\n    // make a copy of the original configuration so not to mutate it. Also use\n    // an YarnConfiguration to force loading of yarn-site.xml.\n    YarnConfiguration yarnConf = new YarnConfiguration(rm.getConfig());\n    String activeRMHAId = RMHAUtils.findActiveRMHAId(yarnConf);\n    String path = \"\";\n    if (activeRMHAId != null) {\n      yarnConf.set(YarnConfiguration.RM_HA_ID, activeRMHAId);\n\n      InetSocketAddress sock = YarnConfiguration.useHttps(yarnConf)\n          ? yarnConf.getSocketAddr(YarnConfiguration.RM_WEBAPP_HTTPS_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_HTTPS_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_HTTPS_PORT)\n          : yarnConf.getSocketAddr(YarnConfiguration.RM_WEBAPP_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_PORT);\n\n      path = sock.getHostName() + \":\" + Integer.toString(sock.getPort());\n      path = YarnConfiguration.useHttps(yarnConf)\n          ? \"https://\" + path\n          : \"http://\" + path;\n    }\n    return path;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.isStandby": "  public boolean isStandby() {\n    return standby;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.JQueryUI.jsnotice": "  public static void jsnotice(HTML html) {\n    html.\n      div(\"#jsnotice.ui-state-error\").\n          _(\"This page works best with javascript enabled.\")._();\n    html.\n      script().$type(\"text/javascript\").\n        _(\"$('#jsnotice').hide();\")._();\n  }"
        },
        "bug_report": {
            "Title": "RM web UI: app page will crash if app is failed before any attempt has been created",
            "Description": "{code}\n2014-08-12 16:45:13,573 ERROR org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /cluster/app/application_1407887030038_0001\njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:153)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)\n\tat com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)\n\tat com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter(RMWebAppFilter.java:84)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:460)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1191)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.AppBlock.render(AppBlock.java:116)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:67)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:77)\n\tat org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n\tat org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)\n\tat org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:845)\n\tat org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:56)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n\tat org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:212)\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app(RmController.java:55)\n\t... 44 more\n{code}"
        }
    },
    {
        "filename": "YARN-3878.json",
        "creation_time": "2015-07-02T00:20:59.000+0000",
        "stack_trace": "```\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationAttemptState(RMStateStore.java:652)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitionsAndStoreState(RMAppAttemptImpl.java:1173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.access$3300(RMAppAttemptImpl.java:109)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$ContainerFinishedTransition.transition(RMAppAttemptImpl.java:1650)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$ContainerFinishedTransition.transition(RMAppAttemptImpl.java:1619)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:786)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:108)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:838)\n\n\"AsyncDispatcher event handler\" prio=10 tid=0x00007fb980222800 nid=0x4b1e waiting on condition [0x00007fb9654e9000]\n   java.lang.Thread.State: WAITING (parking)\n        at sun.misc.Unsafe.park(Native Method)\n        - parking to wait for  <0x0000000700b79250> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:113)\n        at java.lang.Thread.run(Thread.java:744)\n\n\"main\" prio=10 tid=0x00007fb98000a800 nid=0x49c3 in Object.wait() [0x00007fb989851000]\n   java.lang.Thread.State: TIMED_WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\t- waiting on <0x0000000700b79430> (a java.lang.Object)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop(AsyncDispatcher.java:156)\n\t- locked <0x0000000700b79430> (a java.lang.Object)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\t- locked <0x0000000700b79420> (a java.lang.Object)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.serviceStop(RMStateStore.java:515)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\t- locked <0x0000000700b79630> (a java.lang.Object)\n\tat org.apache.hadoop.service.AbstractService.close(AbstractService.java:250)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStop(ResourceManager.java:599)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationAttemptState": "  public synchronized void updateApplicationAttemptState(\n      ApplicationAttemptStateData attemptState) {\n    dispatcher.getEventHandler().handle(\n      new RMStateUpdateAppAttemptEvent(attemptState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handle": "    public void handle(RMStateStoreEvent event) {\n      handleStoreEvent(event);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitionsAndStoreState": "  private void rememberTargetTransitionsAndStoreState(RMAppAttemptEvent event,\n      Object transitionToDo, RMAppAttemptState targetFinalState,\n      RMAppAttemptState stateToBeStored) {\n\n    rememberTargetTransitions(event, transitionToDo, targetFinalState);\n    stateBeforeFinalSaving = getState();\n\n    // As of today, finalState, diagnostics, final-tracking-url and\n    // finalAppStatus are the only things that we store into the StateStore\n    // AFTER the initial saving on app-attempt-start\n    // These fields can be visible from outside only after they are saved in\n    // StateStore\n    String diags = null;\n\n    // don't leave the tracking URL pointing to a non-existent AM\n    setTrackingUrlToRMAppPage(stateToBeStored);\n    String finalTrackingUrl = getOriginalTrackingUrl();\n    FinalApplicationStatus finalStatus = null;\n    int exitStatus = ContainerExitStatus.INVALID;\n    switch (event.getType()) {\n    case LAUNCH_FAILED:\n      RMAppAttemptLaunchFailedEvent launchFaileEvent =\n          (RMAppAttemptLaunchFailedEvent) event;\n      diags = launchFaileEvent.getMessage();\n      break;\n    case REGISTERED:\n      diags = getUnexpectedAMRegisteredDiagnostics();\n      break;\n    case UNREGISTERED:\n      RMAppAttemptUnregistrationEvent unregisterEvent =\n          (RMAppAttemptUnregistrationEvent) event;\n      diags = unregisterEvent.getDiagnostics();\n      // reset finalTrackingUrl to url sent by am\n      finalTrackingUrl = sanitizeTrackingUrl(unregisterEvent.getFinalTrackingUrl());\n      finalStatus = unregisterEvent.getFinalApplicationStatus();\n      break;\n    case CONTAINER_FINISHED:\n      RMAppAttemptContainerFinishedEvent finishEvent =\n          (RMAppAttemptContainerFinishedEvent) event;\n      diags = getAMContainerCrashedDiagnostics(finishEvent);\n      exitStatus = finishEvent.getContainerStatus().getExitStatus();\n      break;\n    case KILL:\n      break;\n    case EXPIRE:\n      diags = getAMExpiredDiagnostics(event);\n      break;\n    default:\n      break;\n    }\n    AggregateAppResourceUsage resUsage =\n        this.attemptMetrics.getAggregateAppResourceUsage();\n    RMStateStore rmStore = rmContext.getStateStore();\n    setFinishTime(System.currentTimeMillis());\n\n    ApplicationAttemptStateData attemptState =\n        ApplicationAttemptStateData.newInstance(\n            applicationAttemptId,  getMasterContainer(),\n            rmStore.getCredentialsFromAppAttempt(this),\n            startTime, stateToBeStored, finalTrackingUrl, diags,\n            finalStatus, exitStatus,\n          getFinishTime(), resUsage.getMemorySeconds(),\n          resUsage.getVcoreSeconds());\n    LOG.info(\"Updating application attempt \" + applicationAttemptId\n        + \" with final state: \" + targetedFinalState + \", and exit status: \"\n        + exitStatus);\n    rmStore.updateApplicationAttemptState(attemptState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getFinalApplicationStatus": "  public FinalApplicationStatus getFinalApplicationStatus() {\n    this.readLock.lock();\n    try {\n      return this.finalStatus;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAMExpiredDiagnostics": "  private static String getAMExpiredDiagnostics(RMAppAttemptEvent event) {\n    String diag =\n        \"ApplicationMaster for attempt \" + event.getApplicationAttemptId()\n            + \" timed out\";\n    return diag;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getOriginalTrackingUrl": "  public String getOriginalTrackingUrl() {\n    this.readLock.lock();\n    try {\n      return this.originalTrackingUrl;\n    } finally {\n      this.readLock.unlock();\n    }    \n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.sanitizeTrackingUrl": "  private static String sanitizeTrackingUrl(String url) {\n    return (url == null || url.trim().isEmpty()) ? \"N/A\" : url;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getState": "  public RMAppAttemptState getState() {\n    this.readLock.lock();\n\n    try {\n      return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setFinishTime": "  private void setFinishTime(long finishTime) {\n    try {\n      this.writeLock.lock();\n      this.finishTime = finishTime;\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setTrackingUrlToRMAppPage": "  private void setTrackingUrlToRMAppPage(RMAppAttemptState stateToBeStored) {\n    originalTrackingUrl = pjoin(\n        WebAppUtils.getResolvedRMWebAppURLWithScheme(conf),\n        \"cluster\", \"app\", getAppAttemptId().getApplicationId());\n    switch (stateToBeStored) {\n    case KILLED:\n    case FAILED:\n      proxiedTrackingUrl = originalTrackingUrl;\n      break;\n    default:\n      break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getMasterContainer": "  public Container getMasterContainer() {\n    return this.masterContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitions": "  private void rememberTargetTransitions(RMAppAttemptEvent event,\n      Object transitionToDo, RMAppAttemptState targetFinalState) {\n    transitionTodo = transitionToDo;\n    targetedFinalState = targetFinalState;\n    eventCausingFinalSaving = event;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getFinishTime": "  public long getFinishTime() {\n    try {\n      this.readLock.lock();\n      return this.finishTime;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAMContainerCrashedDiagnostics": "  private String getAMContainerCrashedDiagnostics(\n      RMAppAttemptContainerFinishedEvent finishEvent) {\n    ContainerStatus status = finishEvent.getContainerStatus();\n    StringBuilder diagnosticsBuilder = new StringBuilder();\n    diagnosticsBuilder.append(\"AM Container for \").append(\n      finishEvent.getApplicationAttemptId()).append(\n      \" exited with \").append(\" exitCode: \").append(status.getExitStatus()).\n      append(\"\\n\");\n    diagnosticsBuilder.append(\"Failing this attempt.\").append(\"Diagnostics: \")\n        .append(status.getDiagnostics());\n    if (this.getTrackingUrl() != null) {\n      diagnosticsBuilder.append(\"For more detailed output,\").append(\n        \" check the application tracking page: \").append(\n        this.getTrackingUrl()).append(\n        \" Then click on links to logs of each attempt.\\n\");\n    }\n    return diagnosticsBuilder.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getDiagnostics": "  public String getDiagnostics() {\n    this.readLock.lock();\n\n    try {\n      return this.diagnostics.toString();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getUnexpectedAMRegisteredDiagnostics": "  private static String getUnexpectedAMRegisteredDiagnostics() {\n    return \"Unmanaged AM must register after AM attempt reaches LAUNCHED state.\";\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.transition": "    public void\n        transition(RMAppAttemptImpl appAttempt, RMAppAttemptEvent event) {\n      if (appAttempt.targetedFinalState.equals(RMAppAttemptState.FAILED)\n          || appAttempt.targetedFinalState.equals(RMAppAttemptState.KILLED)) {\n        // ignore Container_Finished Event if we were supposed to reach\n        // FAILED/KILLED state.\n        return;\n      }\n\n      // pass in the earlier AMUnregistered Event also, as this is needed for\n      // AMFinishedAfterFinalSavingTransition later on\n      appAttempt.rememberTargetTransitions(event,\n        new AMFinishedAfterFinalSavingTransition(\n        appAttempt.eventCausingFinalSaving), RMAppAttemptState.FINISHED);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.updateInfoOnAMUnregister": "  private void updateInfoOnAMUnregister(RMAppAttemptEvent event) {\n    progress = 1.0f;\n    RMAppAttemptUnregistrationEvent unregisterEvent =\n        (RMAppAttemptUnregistrationEvent) event;\n    diagnostics.append(unregisterEvent.getDiagnostics());\n    originalTrackingUrl = sanitizeTrackingUrl(unregisterEvent.getFinalTrackingUrl());\n    finalStatus = unregisterEvent.getFinalApplicationStatus();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getSubmissionContext": "  public ApplicationSubmissionContext getSubmissionContext() {\n    return this.submissionContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.launchAttempt": "  private void launchAttempt(){\n    launchAMStartTime = System.currentTimeMillis();\n    // Send event to launch the AM Container\n    eventHandler.handle(new AMLauncherEvent(AMLauncherEventType.LAUNCH, this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.sendAMContainerToNM": "  private void sendAMContainerToNM(RMAppAttemptImpl appAttempt,\n      RMAppAttemptContainerFinishedEvent containerFinishedEvent) {\n    NodeId nodeId = containerFinishedEvent.getNodeId();\n    finishedContainersSentToAM.putIfAbsent(nodeId,\n      new ArrayList<ContainerStatus>());\n    appAttempt.finishedContainersSentToAM.get(nodeId).add(\n      containerFinishedEvent.getContainerStatus());\n    if (!appAttempt.getSubmissionContext()\n      .getKeepContainersAcrossApplicationAttempts()) {\n      appAttempt.sendFinishedContainersToNM();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.invalidateAMHostAndPort": "  private void invalidateAMHostAndPort() {\n    this.host = \"N/A\";\n    this.rpcPort = -1;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setMasterContainer": "  public void setMasterContainer(Container container) {\n    masterContainer = container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.attemptLaunched": "  private void attemptLaunched() {\n    // Register with AMLivelinessMonitor\n    rmContext.getAMLivelinessMonitor().register(getAppAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getHost": "  public String getHost() {\n    this.readLock.lock();\n\n    try {\n      return this.host;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getProgress": "  public float getProgress() {\n    this.readLock.lock();\n\n    try {\n      return this.progress;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.storeAttempt": "  private void storeAttempt() {\n    // store attempt data in a non-blocking manner to prevent dispatcher\n    // thread starvation and wait for state to be saved\n    LOG.info(\"Storing attempt: AppId: \" + \n              getAppAttemptId().getApplicationId() \n              + \" AttemptId: \" + \n              getAppAttemptId()\n              + \" MasterContainer: \" + masterContainer);\n    rmContext.getStateStore().storeNewApplicationAttempt(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setAMContainerCrashedDiagnosticsAndExitStatus": "  private void setAMContainerCrashedDiagnosticsAndExitStatus(\n      RMAppAttemptContainerFinishedEvent finishEvent) {\n    ContainerStatus status = finishEvent.getContainerStatus();\n    String diagnostics = getAMContainerCrashedDiagnostics(finishEvent);\n    this.diagnostics.append(diagnostics);\n    this.amContainerExitStatus = status.getExitStatus();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.retryFetchingAMContainer": "  private void retryFetchingAMContainer(final RMAppAttemptImpl appAttempt) {\n    // start a new thread so that we are not blocking main dispatcher thread.\n    new Thread() {\n      @Override\n      public void run() {\n        try {\n          Thread.sleep(500);\n        } catch (InterruptedException e) {\n          LOG.warn(\"Interrupted while waiting to resend the\"\n              + \" ContainerAllocated Event.\");\n        }\n        appAttempt.eventHandler.handle(new RMAppAttemptContainerAllocatedEvent(\n          appAttempt.applicationAttemptId));\n      }\n    }.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.shouldCountTowardsMaxAttemptRetry": "  public boolean shouldCountTowardsMaxAttemptRetry() {\n    try {\n      this.readLock.lock();\n      int exitStatus = getAMContainerExitStatus();\n      return !(exitStatus == ContainerExitStatus.PREEMPTED\n          || exitStatus == ContainerExitStatus.ABORTED\n          || exitStatus == ContainerExitStatus.DISKS_FAILED\n          || exitStatus == ContainerExitStatus.KILLED_BY_RESOURCEMANAGER);\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.addJustFinishedContainer": "  private static void addJustFinishedContainer(RMAppAttemptImpl appAttempt,\n      RMAppAttemptContainerFinishedEvent containerFinishedEvent) {\n    appAttempt.justFinishedContainers.putIfAbsent(containerFinishedEvent\n        .getNodeId(), new ArrayList<ContainerStatus>());\n    appAttempt.justFinishedContainers.get(containerFinishedEvent\n            .getNodeId()).add(containerFinishedEvent.getContainerStatus());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getClientTokenMasterKey": "  public SecretKey getClientTokenMasterKey() {\n    return this.clientTokenMasterKey;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.transferStateFromAttempt": "  public void transferStateFromAttempt(RMAppAttempt attempt) {\n    this.justFinishedContainers = attempt.getJustFinishedContainersReference();\n    this.finishedContainersSentToAM =\n        attempt.getFinishedContainersSentToAMReference();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.removeCredentials": "  private void removeCredentials(RMAppAttemptImpl appAttempt) {\n    // Unregister from the ClientToAMTokenSecretManager\n    if (UserGroupInformation.isSecurityEnabled()) {\n      appAttempt.rmContext.getClientToAMTokenSecretManager()\n        .unRegisterApplication(appAttempt.getAppAttemptId());\n    }\n\n    // Remove the AppAttempt from the AMRMTokenSecretManager\n    appAttempt.rmContext.getAMRMTokenSecretManager()\n      .applicationMasterFinished(appAttempt.getAppAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptId": "  public ApplicationAttemptId getAppAttemptId() {\n    return this.applicationAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getAppAttemptState()) {\n        LOG.info(appAttemptID + \" State change from \" + oldState + \" to \"\n            + getAppAttemptState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop": "  protected void serviceStop() throws Exception {\n    if (drainEventsOnStop) {\n      blockNewEvents = true;\n      LOG.info(\"AsyncDispatcher is draining to stop, igonring any new events.\");\n      synchronized (waitForDrained) {\n        while (!drained && eventHandlingThread.isAlive()) {\n          waitForDrained.wait(1000);\n          LOG.info(\"Waiting for AsyncDispatcher to drain. Thread state is :\" +\n              eventHandlingThread.getState());\n        }\n      }\n    }\n    stopped = true;\n    if (eventHandlingThread != null) {\n      eventHandlingThread.interrupt();\n      try {\n        eventHandlingThread.join();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted Exception while stopping\", ie);\n      }\n    }\n\n    // stop all the components\n    super.serviceStop();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.stop": "  public void stop() {\n    if (isInState(STATE.STOPPED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.STOPPED) != STATE.STOPPED) {\n        try {\n          serviceStop();\n        } catch (Exception e) {\n          //stop-time exceptions are logged if they are the first one,\n          noteFailure(e);\n          throw ServiceStateException.convert(e);\n        } finally {\n          //report that the service has terminated\n          terminationNotification.set(true);\n          synchronized (terminationNotification) {\n            terminationNotification.notifyAll();\n          }\n          //notify anything listening for events\n          notifyListeners();\n        }\n      } else {\n        //already stopped: note it\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring re-entrant call to stop()\");\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStop": "  protected void serviceStop() throws Exception {\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.serviceStop": "  protected void serviceStop() throws Exception {\n    dispatcher.stop();\n    closeInternal();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.closeInternal": "  protected abstract void closeInternal() throws Exception;\n\n  /**\n   * 1) Versioning scheme: major.minor. For e.g. 1.0, 1.1, 1.2...1.25, 2.0 etc.\n   * 2) Any incompatible change of state-store is a major upgrade, and any\n   *    compatible change of state-store is a minor upgrade.\n   * 3) If theres's no version, treat it as CURRENT_VERSION_INFO.\n   * 4) Within a minor upgrade, say 1.1 to 1.2:\n   *    overwrite the version info and proceed as normal.\n   * 5) Within a major upgrade, say 1.2 to 2.0:\n   *    throw exception and indicate user to use a separate upgrade tool to\n   *    upgrade RM state.\n   */\n  public void checkVersion() throws Exception {\n    Version loadedVersion = loadVersion();\n    LOG.info(\"Loaded RM state version info \" + loadedVersion);\n    if (loadedVersion != null && loadedVersion.equals(getCurrentVersion())) {\n      return;\n    }\n    // if there is no version info, treat it as CURRENT_VERSION_INFO;\n    if (loadedVersion == null) {\n      loadedVersion = getCurrentVersion();\n    }\n    if (loadedVersion.isCompatibleTo(getCurrentVersion())) {\n      LOG.info(\"Storing RM state version info \" + getCurrentVersion());\n      storeVersion();\n    } else {\n      throw new RMStateVersionIncompatibleException(\n        \"Expecting RM state version \" + getCurrentVersion()\n            + \", but loading version \" + loadedVersion);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.close": "  public final void close() throws IOException {\n    stop();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStop": "  protected void serviceStop() throws Exception {\n    if (webApp != null) {\n      webApp.stop();\n    }\n    if (fetcher != null) {\n      fetcher.stop();\n    }\n    if (configurationProvider != null) {\n      configurationProvider.close();\n    }\n    super.serviceStop();\n    transitionToStandby(false);\n    rmContext.setHAServiceState(HAServiceState.STOPPING);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AggregateAppResourceUsage.getMemorySeconds": "  public long getMemorySeconds() {\n    return memorySeconds;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.AggregateAppResourceUsage.getVcoreSeconds": "  public long getVcoreSeconds() {\n    return vcoreSeconds;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}"
        },
        "bug_report": {
            "Title": "AsyncDispatcher can hang while stopping if it is configured for draining events on stop",
            "Description": "The sequence of events is as under :\n# RM is stopped while putting a RMStateStore Event to RMStateStore's AsyncDispatcher. This leads to an Interrupted Exception being thrown.\n# As RM is being stopped, RMStateStore's AsyncDispatcher is also stopped. On {{serviceStop}}, we will check if all events have been drained and wait for event queue to drain(as RM State Store dispatcher is configured for queue to drain on stop). \n# This condition never becomes true and AsyncDispatcher keeps on waiting incessantly for dispatcher event queue to drain till JVM exits.\n\n*Initial exception while posting RM State store event to queue*\n{noformat}\n2015-06-27 20:08:35,922 DEBUG [main] service.AbstractService (AbstractService.java:enterState(452)) - Service: Dispatcher entered state STOPPED\n2015-06-27 20:08:35,923 WARN  [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:handle(247)) - AsyncDispatcher thread interrupted\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationAttemptState(RMStateStore.java:652)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitionsAndStoreState(RMAppAttemptImpl.java:1173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.access$3300(RMAppAttemptImpl.java:109)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$ContainerFinishedTransition.transition(RMAppAttemptImpl.java:1650)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$ContainerFinishedTransition.transition(RMAppAttemptImpl.java:1619)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:786)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:108)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:838)\n{noformat}\n\n*JStack of AsyncDispatcher hanging on stop*\n{noformat}\n\"AsyncDispatcher event handler\" prio=10 tid=0x00007fb980222800 nid=0x4b1e waiting on condition [0x00007fb9654e9000]\n   java.lang.Thread.State: WAITING (parking)\n        at sun.misc.Unsafe.park(Native Method)\n        - parking to wait for  <0x0000000700b79250> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:113)\n        at java.lang.Thread.run(Thread.java:744)\n\n\"main\" prio=10 tid=0x00007fb98000a800 nid=0x49c3 in Object.wait() [0x00007fb989851000]\n   java.lang.Thread.State: TIMED_WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\t- waiting on <0x0000000700b79430> (a java.lang.Object)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop(AsyncDispatcher.java:156)\n\t- locked <0x0000000700b79430> (a java.lang.Object)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\t- locked <0x0000000700b79420> (a java.lang.Object)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.serviceStop(RMStateStore.java:515)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\t- locked <0x0000000700b79630> (a java.lang.Object)\n\tat org.apache.hadoop.service.AbstractService.close(AbstractService.java:250)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStop(ResourceManager.java:599)\n{noformat}\n\nWe keep on getting below logs\n{noformat}\n2015-06-27 20:08:35,926 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(140)) - AsyncDispatcher is draining to stop, igonring any new events.\n2015-06-27 20:08:36,926 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:37,927 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:38,927 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:39,928 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:40,929 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:41,929 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:42,930 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:43,930 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:44,931 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:45,931 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n2015-06-27 20:08:46,932 INFO  [main] event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(144)) - Waiting for AsyncDispatcher to drain. Thread state is :WAITING\n{noformat}"
        }
    },
    {
        "filename": "YARN-6683.json",
        "creation_time": "2017-06-02T00:29:13.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: COLLECTOR_UPDATE at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:903)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:118)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:904)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:888)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:201)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:127)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle": "  public void handle(RMAppEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId appID = event.getApplicationId();\n      LOG.debug(\"Processing event for \" + appID + \" of type \"\n          + event.getType());\n      final RMAppState oldState = getState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      // Log at INFO if we're not recovering or not in a terminal state.\n      // Log at DEBUG otherwise.\n      if ((oldState != getState()) &&\n          (((recoveredFinalState == null)) ||\n            (event.getType() != RMAppEventType.RECOVER))) {\n        LOG.info(String.format(STATE_CHANGE_MESSAGE, appID, oldState,\n            getState(), event.getType()));\n      } else if ((oldState != getState()) && LOG.isDebugEnabled()) {\n        LOG.debug(String.format(STATE_CHANGE_MESSAGE, appID, oldState,\n            getState(), event.getType()));\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getState": "  public RMAppState getState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handleTransitionToStandByInNewThread": "  private void handleTransitionToStandByInNewThread() {\n    Thread standByTransitionThread =\n        new Thread(activeServices.standByTransitionRunnable);\n    standByTransitionThread.setName(\"StandByTransitionThread\");\n    standByTransitionThread.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Invalid event: COLLECTOR_UPDATE at KILLED",
            "Description": "{code}\n2017-06-01 20:01:22,686 ERROR rmapp.RMAppImpl (RMAppImpl.java:handle(905)) - Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: COLLECTOR_UPDATE at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:903)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:118)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:904)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:888)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:201)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:127)\n{code}\n\nBelow code already gets the RMApp instance and then send an event to RMApp to update the collector address. Instead of updating via event, it could just update via a method of RMApp. This also avoids state-machine changes.\nAlso, is there any implications that COLLECTOR_UPDATE happened at KILLED state ?\n\n{code}\n          } else {\n            String previousCollectorAddr = rmApp.getCollectorAddr();\n            if (previousCollectorAddr == null\n                || !previousCollectorAddr.equals(collectorAddr)) {\n              // sending collector update event.\n              RMAppCollectorUpdateEvent event =\n                  new RMAppCollectorUpdateEvent(appId, collectorAddr);\n              rmContext.getDispatcher().getEventHandler().handle(event);\n            }\n          }\n{code}"
        }
    },
    {
        "filename": "YARN-2910.json",
        "creation_time": "2014-11-27T06:19:00.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException: java.util.ConcurrentModificationException\nat java.util.ArrayList$Itr.checkForComodification(ArrayList.java:859)\nat java.util.ArrayList$Itr.next(ArrayList.java:831)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.getResourceUsage(FSLeafQueue.java:147)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getHeadroom(FSAppAttempt.java:180)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.allocate(FairScheduler.java:923)\nat org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:516)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.getResourceUsage": "  public Resource getResourceUsage() {\n    Resource usage = Resources.createResource(0);\n    for (FSAppAttempt app : runnableApps) {\n      Resources.addTo(usage, app.getResourceUsage());\n    }\n    for (FSAppAttempt app : nonRunnableApps) {\n      Resources.addTo(usage, app.getResourceUsage());\n    }\n    return usage;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getHeadroom": "  public synchronized Resource getHeadroom() {\n    final FSQueue queue = (FSQueue) this.queue;\n    SchedulingPolicy policy = queue.getPolicy();\n\n    Resource queueFairShare = queue.getFairShare();\n    Resource queueUsage = queue.getResourceUsage();\n    Resource clusterResource = this.scheduler.getClusterResource();\n    Resource clusterUsage = this.scheduler.getRootQueueMetrics()\n        .getAllocatedResources();\n    Resource clusterAvailableResource = Resources.subtract(clusterResource,\n        clusterUsage);\n    Resource headroom = policy.getHeadroom(queueFairShare,\n        queueUsage, clusterAvailableResource);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Headroom calculation for \" + this.getName() + \":\" +\n          \"Min(\" +\n          \"(queueFairShare=\" + queueFairShare +\n          \" - queueUsage=\" + queueUsage + \"),\" +\n          \" clusterAvailableResource=\" + clusterAvailableResource +\n          \"(clusterResource=\" + clusterResource +\n          \" - clusterUsage=\" + clusterUsage + \")\" +\n          \"Headroom=\" + headroom);\n    }\n    return headroom;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getFairShare": "  public Resource getFairShare() {\n    return this.fairShare;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getResourceUsage": "  public Resource getResourceUsage() {\n    // Here the getPreemptedResources() always return zero, except in\n    // a preemption round\n    return Resources.subtract(getCurrentConsumption(), getPreemptedResources());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getName": "  public String getName() {\n    return getApplicationId().toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.allocate": "  public Allocation allocate(ApplicationAttemptId appAttemptId,\n      List<ResourceRequest> ask, List<ContainerId> release, List<String> blacklistAdditions, List<String> blacklistRemovals) {\n\n    // Make sure this application exists\n    FSAppAttempt application = getSchedulerApp(appAttemptId);\n    if (application == null) {\n      LOG.info(\"Calling allocate on removed \" +\n          \"or non existant application \" + appAttemptId);\n      return EMPTY_ALLOCATION;\n    }\n\n    // Sanity check\n    SchedulerUtils.normalizeRequests(ask, new DominantResourceCalculator(),\n        clusterResource, minimumAllocation, getMaximumResourceCapability(),\n        incrAllocation);\n\n    // Set amResource for this app\n    if (!application.getUnmanagedAM() && ask.size() == 1\n        && application.getLiveContainers().isEmpty()) {\n      application.setAMResource(ask.get(0).getCapability());\n    }\n\n    // Release containers\n    releaseContainers(release, application);\n\n    synchronized (application) {\n      if (!ask.isEmpty()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"allocate: pre-update\" +\n              \" applicationAttemptId=\" + appAttemptId +\n              \" application=\" + application.getApplicationId());\n        }\n        application.showRequests();\n\n        // Update application requests\n        application.updateResourceRequests(ask);\n\n        application.showRequests();\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: post-update\" +\n            \" applicationAttemptId=\" + appAttemptId +\n            \" #ask=\" + ask.size() +\n            \" reservation= \" + application.getCurrentReservation());\n\n        LOG.debug(\"Preempting \" + application.getPreemptionContainers().size()\n            + \" container(s)\");\n      }\n      \n      Set<ContainerId> preemptionContainerIds = new HashSet<ContainerId>();\n      for (RMContainer container : application.getPreemptionContainers()) {\n        preemptionContainerIds.add(container.getContainerId());\n      }\n\n      application.updateBlacklist(blacklistAdditions, blacklistRemovals);\n      ContainersAndNMTokensAllocation allocation =\n          application.pullNewlyAllocatedContainersAndNMTokens();\n      return new Allocation(allocation.getContainerList(),\n        application.getHeadroom(), preemptionContainerIds, null, null,\n        allocation.getNMTokenList());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getSchedulerApp": "  public FSAppAttempt getSchedulerApp(ApplicationAttemptId appAttemptId) {\n    return super.getApplicationAttempt(appAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate": "  public AllocateResponse allocate(AllocateRequest request)\n      throws YarnException, IOException {\n\n    AMRMTokenIdentifier amrmTokenIdentifier = authorizeRequest();\n\n    ApplicationAttemptId appAttemptId =\n        amrmTokenIdentifier.getApplicationAttemptId();\n    ApplicationId applicationId = appAttemptId.getApplicationId();\n\n    this.amLivelinessMonitor.receivedPing(appAttemptId);\n\n    /* check if its in cache */\n    AllocateResponseLock lock = responseMap.get(appAttemptId);\n    if (lock == null) {\n      String message =\n          \"Application attempt \" + appAttemptId\n              + \" doesn't exist in ApplicationMasterService cache.\";\n      LOG.error(message);\n      throw new ApplicationAttemptNotFoundException(message);\n    }\n    synchronized (lock) {\n      AllocateResponse lastResponse = lock.getAllocateResponse();\n      if (!hasApplicationMasterRegistered(appAttemptId)) {\n        String message =\n            \"AM is not registered for known application attempt: \" + appAttemptId\n                + \" or RM had restarted after AM registered . AM should re-register.\";\n        LOG.info(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps().get(appAttemptId.getApplicationId())\n            .getUser(), AuditConstants.AM_ALLOCATE, \"\",\n          \"ApplicationMasterService\", message, applicationId, appAttemptId);\n        throw new ApplicationMasterNotRegisteredException(message);\n      }\n\n      if ((request.getResponseId() + 1) == lastResponse.getResponseId()) {\n        /* old heartbeat */\n        return lastResponse;\n      } else if (request.getResponseId() + 1 < lastResponse.getResponseId()) {\n        String message =\n            \"Invalid responseId in AllocateRequest from application attempt: \"\n                + appAttemptId + \", expect responseId to be \"\n                + (lastResponse.getResponseId() + 1);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n\n      //filter illegal progress values\n      float filteredProgress = request.getProgress();\n      if (Float.isNaN(filteredProgress) || filteredProgress == Float.NEGATIVE_INFINITY\n        || filteredProgress < 0) {\n         request.setProgress(0);\n      } else if (filteredProgress > 1 || filteredProgress == Float.POSITIVE_INFINITY) {\n        request.setProgress(1);\n      }\n\n      // Send the status update to the appAttempt.\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptStatusupdateEvent(appAttemptId, request\n              .getProgress()));\n\n      List<ResourceRequest> ask = request.getAskList();\n      List<ContainerId> release = request.getReleaseList();\n\n      ResourceBlacklistRequest blacklistRequest =\n          request.getResourceBlacklistRequest();\n      List<String> blacklistAdditions =\n          (blacklistRequest != null) ?\n              blacklistRequest.getBlacklistAdditions() : Collections.EMPTY_LIST;\n      List<String> blacklistRemovals =\n          (blacklistRequest != null) ?\n              blacklistRequest.getBlacklistRemovals() : Collections.EMPTY_LIST;\n      RMApp app =\n          this.rmContext.getRMApps().get(applicationId);\n      \n      // set label expression for Resource Requests\n      ApplicationSubmissionContext asc = app.getApplicationSubmissionContext();\n      for (ResourceRequest req : ask) {\n        if (null == req.getNodeLabelExpression()) {\n          req.setNodeLabelExpression(asc.getNodeLabelExpression());\n        }\n      }\n              \n      // sanity check\n      try {\n        RMServerUtils.validateResourceRequests(ask,\n            rScheduler.getMaximumResourceCapability(), app.getQueue(),\n            rScheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"Invalid resource ask by application \" + appAttemptId, e);\n        throw e;\n      }\n      \n      try {\n        RMServerUtils.validateBlacklistRequest(blacklistRequest);\n      }  catch (InvalidResourceBlacklistRequestException e) {\n        LOG.warn(\"Invalid blacklist request by application \" + appAttemptId, e);\n        throw e;\n      }\n\n      // In the case of work-preserving AM restart, it's possible for the\n      // AM to release containers from the earlier attempt.\n      if (!app.getApplicationSubmissionContext()\n        .getKeepContainersAcrossApplicationAttempts()) {\n        try {\n          RMServerUtils.validateContainerReleaseRequest(release, appAttemptId);\n        } catch (InvalidContainerReleaseException e) {\n          LOG.warn(\"Invalid container release by application \" + appAttemptId, e);\n          throw e;\n        }\n      }\n\n      // Send new requests to appAttempt.\n      Allocation allocation =\n          this.rScheduler.allocate(appAttemptId, ask, release, \n              blacklistAdditions, blacklistRemovals);\n\n      if (!blacklistAdditions.isEmpty() || !blacklistRemovals.isEmpty()) {\n        LOG.info(\"blacklist are updated in Scheduler.\" +\n            \"blacklistAdditions: \" + blacklistAdditions + \", \" +\n            \"blacklistRemovals: \" + blacklistRemovals);\n      }\n      RMAppAttempt appAttempt = app.getRMAppAttempt(appAttemptId);\n      AllocateResponse allocateResponse =\n          recordFactory.newRecordInstance(AllocateResponse.class);\n      if (!allocation.getContainers().isEmpty()) {\n        allocateResponse.setNMTokens(allocation.getNMTokens());\n      }\n\n      // update the response with the deltas of node status changes\n      List<RMNode> updatedNodes = new ArrayList<RMNode>();\n      if(app.pullRMNodeUpdates(updatedNodes) > 0) {\n        List<NodeReport> updatedNodeReports = new ArrayList<NodeReport>();\n        for(RMNode rmNode: updatedNodes) {\n          SchedulerNodeReport schedulerNodeReport =  \n              rScheduler.getNodeReport(rmNode.getNodeID());\n          Resource used = BuilderUtils.newResource(0, 0);\n          int numContainers = 0;\n          if (schedulerNodeReport != null) {\n            used = schedulerNodeReport.getUsedResource();\n            numContainers = schedulerNodeReport.getNumContainers();\n          }\n          NodeId nodeId = rmNode.getNodeID();\n          NodeReport report =\n              BuilderUtils.newNodeReport(nodeId, rmNode.getState(),\n                  rmNode.getHttpAddress(), rmNode.getRackName(), used,\n                  rmNode.getTotalCapability(), numContainers,\n                  rmNode.getHealthReport(), rmNode.getLastHealthReportTime(),\n                  rmNode.getNodeLabels());\n\n          updatedNodeReports.add(report);\n        }\n        allocateResponse.setUpdatedNodes(updatedNodeReports);\n      }\n\n      allocateResponse.setAllocatedContainers(allocation.getContainers());\n      allocateResponse.setCompletedContainersStatuses(appAttempt\n          .pullJustFinishedContainers());\n      allocateResponse.setResponseId(lastResponse.getResponseId() + 1);\n      allocateResponse.setAvailableResources(allocation.getResourceLimit());\n\n      allocateResponse.setNumClusterNodes(this.rScheduler.getNumClusterNodes());\n\n      // add preemption to the allocateResponse message (if any)\n      allocateResponse\n          .setPreemptionMessage(generatePreemptionMessage(allocation));\n\n      // update AMRMToken if the token is rolled-up\n      MasterKeyData nextMasterKey =\n          this.rmContext.getAMRMTokenSecretManager().getNextMasterKeyData();\n\n      if (nextMasterKey != null\n          && nextMasterKey.getMasterKey().getKeyId() != amrmTokenIdentifier\n            .getKeyId()) {\n        Token<AMRMTokenIdentifier> amrmToken =\n            rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n              appAttemptId);\n        ((RMAppAttemptImpl)appAttempt).setAMRMToken(amrmToken);\n        allocateResponse.setAMRMToken(org.apache.hadoop.yarn.api.records.Token\n          .newInstance(amrmToken.getIdentifier(), amrmToken.getKind()\n            .toString(), amrmToken.getPassword(), amrmToken.getService()\n            .toString()));\n        LOG.info(\"The AMRMToken has been rolled-over. Send new AMRMToken back\"\n            + \" to application: \" + applicationId);\n      }\n\n      /*\n       * As we are updating the response inside the lock object so we don't\n       * need to worry about unregister call occurring in between (which\n       * removes the lock object).\n       */\n      lock.setAllocateResponse(allocateResponse);\n      return allocateResponse;\n    }    \n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.hasApplicationMasterRegistered": "  public boolean hasApplicationMasterRegistered(\n      ApplicationAttemptId appAttemptId) {\n    boolean hasApplicationMasterRegistered = false;\n    AllocateResponseLock lastResponse = responseMap.get(appAttemptId);\n    if (lastResponse != null) {\n      synchronized (lastResponse) {\n        if (lastResponse.getAllocateResponse() != null\n            && lastResponse.getAllocateResponse().getResponseId() >= 0) {\n          hasApplicationMasterRegistered = true;\n        }\n      }\n    }\n    return hasApplicationMasterRegistered;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.generatePreemptionMessage": "  private PreemptionMessage generatePreemptionMessage(Allocation allocation){\n    PreemptionMessage pMsg = null;\n    // assemble strict preemption request\n    if (allocation.getStrictContainerPreemptions() != null) {\n       pMsg =\n        recordFactory.newRecordInstance(PreemptionMessage.class);\n      StrictPreemptionContract pStrict =\n          recordFactory.newRecordInstance(StrictPreemptionContract.class);\n      Set<PreemptionContainer> pCont = new HashSet<PreemptionContainer>();\n      for (ContainerId cId : allocation.getStrictContainerPreemptions()) {\n        PreemptionContainer pc =\n            recordFactory.newRecordInstance(PreemptionContainer.class);\n        pc.setId(cId);\n        pCont.add(pc);\n      }\n      pStrict.setContainers(pCont);\n      pMsg.setStrictContract(pStrict);\n    }\n\n    // assemble negotiable preemption request\n    if (allocation.getResourcePreemptions() != null &&\n        allocation.getResourcePreemptions().size() > 0 &&\n        allocation.getContainerPreemptions() != null &&\n        allocation.getContainerPreemptions().size() > 0) {\n      if (pMsg == null) {\n        pMsg =\n            recordFactory.newRecordInstance(PreemptionMessage.class);\n      }\n      PreemptionContract contract =\n          recordFactory.newRecordInstance(PreemptionContract.class);\n      Set<PreemptionContainer> pCont = new HashSet<PreemptionContainer>();\n      for (ContainerId cId : allocation.getContainerPreemptions()) {\n        PreemptionContainer pc =\n            recordFactory.newRecordInstance(PreemptionContainer.class);\n        pc.setId(cId);\n        pCont.add(pc);\n      }\n      List<PreemptionResourceRequest> pRes = new ArrayList<PreemptionResourceRequest>();\n      for (ResourceRequest crr : allocation.getResourcePreemptions()) {\n        PreemptionResourceRequest prr =\n            recordFactory.newRecordInstance(PreemptionResourceRequest.class);\n        prr.setResourceRequest(crr);\n        pRes.add(prr);\n      }\n      contract.setContainers(pCont);\n      contract.setResourceRequest(pRes);\n      pMsg.setContract(contract);\n    }\n    \n    return pMsg;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.setAllocateResponse": "    public synchronized void setAllocateResponse(AllocateResponse response) {\n      this.response = response;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.getAllocateResponse": "    public synchronized AllocateResponse getAllocateResponse() {\n      return response;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.authorizeRequest": "  private AMRMTokenIdentifier authorizeRequest()\n      throws YarnException {\n\n    UserGroupInformation remoteUgi;\n    try {\n      remoteUgi = UserGroupInformation.getCurrentUser();\n    } catch (IOException e) {\n      String msg =\n          \"Cannot obtain the user-name for authorizing ApplicationMaster. \"\n              + \"Got exception: \" + StringUtils.stringifyException(e);\n      LOG.warn(msg);\n      throw RPCUtil.getRemoteException(msg);\n    }\n\n    boolean tokenFound = false;\n    String message = \"\";\n    AMRMTokenIdentifier appTokenIdentifier = null;\n    try {\n      appTokenIdentifier = selectAMRMTokenIdentifier(remoteUgi);\n      if (appTokenIdentifier == null) {\n        tokenFound = false;\n        message = \"No AMRMToken found for user \" + remoteUgi.getUserName();\n      } else {\n        tokenFound = true;\n      }\n    } catch (IOException e) {\n      tokenFound = false;\n      message =\n          \"Got exception while looking for AMRMToken for user \"\n              + remoteUgi.getUserName();\n    }\n\n    if (!tokenFound) {\n      LOG.warn(message);\n      throw RPCUtil.getRemoteException(message);\n    }\n\n    return appTokenIdentifier;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue.getPolicy": "  public SchedulingPolicy getPolicy() {\n    return policy;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateResourceRequests": "  public static void validateResourceRequests(List<ResourceRequest> ask,\n      Resource maximumResource, String queueName, YarnScheduler scheduler)\n      throws InvalidResourceRequestException {\n    for (ResourceRequest resReq : ask) {\n      SchedulerUtils.validateResourceRequest(resReq, maximumResource,\n          queueName, scheduler);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateContainerReleaseRequest": "  public static void\n      validateContainerReleaseRequest(List<ContainerId> containerReleaseList,\n          ApplicationAttemptId appAttemptId)\n          throws InvalidContainerReleaseException {\n    for (ContainerId cId : containerReleaseList) {\n      if (!appAttemptId.equals(cId.getApplicationAttemptId())) {\n        throw new InvalidContainerReleaseException(\n            \"Cannot release container : \"\n                + cId.toString()\n                + \" not belonging to this application attempt : \"\n                + appAttemptId);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ApplicationId appId,\n      ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.FAILURE, b);\n    add(Keys.DESCRIPTION, description, b);\n    add(Keys.PERMISSIONS, perm, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getAMRMTokenSecretManager": "  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateBlacklistRequest": "  public static void validateBlacklistRequest(\n      ResourceBlacklistRequest blacklistRequest)\n      throws InvalidResourceBlacklistRequestException {\n    if (blacklistRequest != null) {\n      List<String> plus = blacklistRequest.getBlacklistAdditions();\n      if (plus != null && plus.contains(ResourceRequest.ANY)) {\n        throw new InvalidResourceBlacklistRequestException(\n            \"Cannot add \" + ResourceRequest.ANY + \" to the blacklist!\");\n      }\n    }\n  }"
        },
        "bug_report": {
            "Title": "FSLeafQueue can throw ConcurrentModificationException",
            "Description": "The list that maintains the runnable and the non runnable apps are a standard ArrayList but there is no guarantee that it will only be manipulated by one thread in the system. This can lead to the following exception:\n{noformat}\n2014-11-12 02:29:01,169 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM.\njava.util.ConcurrentModificationException: java.util.ConcurrentModificationException\nat java.util.ArrayList$Itr.checkForComodification(ArrayList.java:859)\nat java.util.ArrayList$Itr.next(ArrayList.java:831)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.getResourceUsage(FSLeafQueue.java:147)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getHeadroom(FSAppAttempt.java:180)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.allocate(FairScheduler.java:923)\nat org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:516)\n{noformat}\n\nFull stack trace in the attached file.\n\nWe should guard against that by using a thread safe version from java.util.concurrent.CopyOnWriteArrayList\n"
        }
    },
    {
        "filename": "YARN-192.json",
        "creation_time": "2012-11-01T05:00:41.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.unreserve(FSSchedulerApp.java:356)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.unreserve(AppSchedulable.java:214)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:266)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:330)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueSchedulable.assignContainer(FSQueueSchedulable.java:161)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:759)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:836)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:329)\n        at java.lang.Thread.run(Thread.java:662)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.unreserve": "  public synchronized void unreserve(FSSchedulerNode node, Priority priority) {\n    Map<NodeId, RMContainer> reservedContainers = \n        this.reservedContainers.get(priority);\n    RMContainer reservedContainer = reservedContainers.remove(node.getNodeID());\n    if (reservedContainers.isEmpty()) {\n      this.reservedContainers.remove(priority);\n    }\n    \n    // Reset the re-reservation count\n    resetReReservations(priority);\n\n    Resource resource = reservedContainer.getContainer().getResource();\n    Resources.subtractFrom(currentReservation, resource);\n\n    LOG.info(\"Application \" + getApplicationId() + \" unreserved \" + \" on node \"\n        + node + \", currently has \" + reservedContainers.size() + \" at priority \"\n        + priority + \"; currentReservation \" + currentReservation);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.resetReReservations": "  synchronized void resetReReservations(Priority priority) {\n    this.reReservations.setCount(priority, 0);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.appSchedulingInfo.getApplicationId();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.getResource": "  public Resource getResource(Priority priority) {\n    return this.appSchedulingInfo.getResource(priority);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.unreserve": "  private void unreserve(FSSchedulerApp application, Priority priority,\n      FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    application.unreserve(node, priority);\n    node.unreserveResource(application);\n    getMetrics().unreserveResource(\n        application.getUser(), rmContainer.getContainer().getResource());\n    scheduler.getRootQueueMetrics().unreserveResource(\n        application.getUser(), rmContainer.getContainer().getResource());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getMetrics": "  public QueueMetrics getMetrics() {\n    return this.queue.getQueueSchedulable().getMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer": "  public Resource assignContainer(FSSchedulerNode node, boolean reserved) {\n    LOG.info(\"Node offered to app: \" + getName() + \" reserved: \" + reserved);\n\n    if (reserved) {\n      RMContainer rmContainer = node.getReservedContainer();\n      Priority priority = rmContainer.getReservedPriority();\n\n      // Make sure the application still needs requests at this priority\n      if (app.getTotalRequiredResources(priority) == 0) {\n        this.unreserve(app, priority, node);\n        return Resources.none();\n      }\n    } else {\n      // If this app is over quota, don't schedule anything\n      if (!(getRunnable())) { return Resources.none(); }\n\n    }\n    // For each priority, see if we can schedule a node local, rack local\n    // or off-switch request. Rack of off-switch requests may be delayed\n    // (not scheduled) in order to promote better locality.\n    for (Priority priority : app.getPriorities()) {\n      app.addSchedulingOpportunity(priority);\n      NodeType allowedLocality = app.getAllowedLocalityLevel(priority,\n          scheduler.getNumClusterNodes(), scheduler.getNodeLocalityThreshold(),\n          scheduler.getRackLocalityThreshold());\n\n      ResourceRequest localRequest = app.getResourceRequest(priority,\n          node.getHostName());\n      if (localRequest != null && localRequest.getNumContainers() != 0) {\n        return assignContainer(node, app, priority,\n            localRequest, NodeType.NODE_LOCAL, reserved);\n      }\n\n      ResourceRequest rackLocalRequest = app.getResourceRequest(priority,\n          node.getRackName());\n      if (rackLocalRequest != null && rackLocalRequest.getNumContainers() != 0\n          && (allowedLocality.equals(NodeType.RACK_LOCAL) ||\n              allowedLocality.equals(NodeType.OFF_SWITCH))) {\n        return assignContainer(node, app, priority, rackLocalRequest,\n            NodeType.RACK_LOCAL, reserved);\n      }\n\n      ResourceRequest offSwitchRequest = app.getResourceRequest(priority,\n          RMNode.ANY);\n      if (offSwitchRequest != null && offSwitchRequest.getNumContainers() != 0\n          && allowedLocality.equals(NodeType.OFF_SWITCH)) {\n        return assignContainer(node, app, priority, offSwitchRequest,\n            NodeType.OFF_SWITCH, reserved);\n      }\n    }\n    return Resources.none();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.createContainer": "  public Container createContainer(\n      FSSchedulerApp application, FSSchedulerNode node,\n      Resource capability, Priority priority) {\n\n    NodeId nodeId = node.getRMNode().getNodeID();\n    ContainerId containerId = BuilderUtils.newContainerId(application\n        .getApplicationAttemptId(), application.getNewContainerId());\n    ContainerToken containerToken = null;\n\n    // If security is enabled, send the container-tokens too.\n    if (UserGroupInformation.isSecurityEnabled()) {\n      containerToken =\n          containerTokenSecretManager.createContainerToken(containerId, nodeId,\n            application.getUser(), capability);\n      if (containerToken == null) {\n        return null; // Try again later.\n      }\n    }\n\n    // Create the container\n    Container container = BuilderUtils.newContainer(containerId, nodeId,\n        node.getRMNode().getHttpAddress(), capability, priority,\n        containerToken);\n\n    return container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.reserve": "  private void reserve(FSSchedulerApp application, Priority priority,\n      FSSchedulerNode node, Container container, boolean alreadyReserved) {\n    LOG.info(\"Making reservation: node=\" + node.getHostName() +\n                                 \" app_id=\" + app.getApplicationId());\n    if (!alreadyReserved) {\n      getMetrics().reserveResource(application.getUser(), container.getResource());\n      RMContainer rmContainer = application.reserve(node, priority, null,\n          container);\n      node.reserveResource(application, priority, rmContainer);\n      getMetrics().reserveResource(this.app.getUser(),\n          container.getResource());\n      scheduler.getRootQueueMetrics().reserveResource(this.app.getUser(),\n          container.getResource());\n    }\n\n    else {\n      RMContainer rmContainer = node.getReservedContainer();\n      application.reserve(node, priority, rmContainer, container);\n      node.reserveResource(application, priority, rmContainer);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getName": "  public String getName() {\n    return app.getApplicationId().toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getRunnable": "  public boolean getRunnable() {\n    return runnable;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueSchedulable.assignContainer": "  public Resource assignContainer(FSSchedulerNode node, boolean reserved) {\n    LOG.debug(\"Node offered to queue: \" + this.getName() + \" reserved: \" + reserved);\n    // If this queue is over its limit, reject\n    if (Resources.greaterThan(this.getResourceUsage(),\n        queueMgr.getMaxResources(queue.getName()))) {\n      return Resources.none();\n    }\n\n    // If this node already has reserved resources for an app, first try to\n    // finish allocating resources for that app.\n    if (reserved) {\n      for (AppSchedulable sched : appScheds) {\n        if (sched.getApp().getApplicationAttemptId() ==\n            node.getReservedContainer().getApplicationAttemptId()) {\n          return sched.assignContainer(node, reserved);\n        }\n      }\n      return Resources.none(); // We should never get here\n    }\n\n    // Otherwise, chose app to schedule based on given policy (fair vs fifo).\n    else {\n      SchedulingMode mode = queue.getSchedulingMode();\n\n      Comparator<Schedulable> comparator;\n      if (mode == SchedulingMode.FIFO) {\n        comparator = new SchedulingAlgorithms.FifoComparator();\n      } else if (mode == SchedulingMode.FAIR) {\n        comparator = new SchedulingAlgorithms.FairShareComparator();\n      } else {\n        throw new RuntimeException(\"Unsupported queue scheduling mode \" + mode);\n      }\n\n      Collections.sort(appScheds, comparator);\n      for (AppSchedulable sched: appScheds) {\n        return sched.assignContainer(node, reserved);\n      }\n\n      return Resources.none();\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueSchedulable.getResourceUsage": "  public Resource getResourceUsage() {\n    Resource usage = Resources.createResource(0);\n    for (AppSchedulable app : appScheds) {\n      Resources.addTo(usage, app.getResourceUsage());\n    }\n    return usage;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueSchedulable.getName": "  public String getName() {\n    return queue.getName();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm,\n      List<ContainerStatus> newlyLaunchedContainers,\n      List<ContainerStatus> completedContainers) {\n    LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node = nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      FSSchedulerApp reservedApplication =\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSQueue queue = queueMgr.getQueue(reservedApplication.getQueueName());\n      queue.getQueueSchedulable().assignContainer(node, true);\n    }\n\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers = 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List<FSQueueSchedulable> scheds = this.getQueueSchedulables();\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer = false;\n        for (FSQueueSchedulable sched : scheds) {\n          Resource assigned = sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none())) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer = true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers >= maxAssign) && (maxAssign > 0)) { break; }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getRMContainer": "  private RMContainer getRMContainer(ContainerId containerId) {\n    FSSchedulerApp application =\n        applications.get(containerId.getApplicationAttemptId());\n    return (application == null) ? null : application.getRMContainer(containerId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getQueueSchedulables": "  public List<FSQueueSchedulable> getQueueSchedulables() {\n    List<FSQueueSchedulable> scheds = new ArrayList<FSQueueSchedulable>();\n    for (FSQueue queue: queueMgr.getQueues()) {\n      scheds.add(queue.getQueueSchedulable());\n    }\n    return scheds;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.containerLaunchedOnNode": "  private void containerLaunchedOnNode(ContainerId containerId, FSSchedulerNode node) {\n    // Get the application for the finished container\n    ApplicationAttemptId applicationAttemptId = containerId.getApplicationAttemptId();\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n    if (application == null) {\n      LOG.info(\"Unknown application: \" + applicationAttemptId +\n          \" launched container \" + containerId +\n          \" on node: \" + node);\n      return;\n    }\n\n    application.containerLaunchedOnNode(containerId, node.getNodeID());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer": "  private synchronized void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n    if (rmContainer == null) {\n      LOG.info(\"Null container completed...\");\n      return;\n    }\n\n    Container container = rmContainer.getContainer();\n\n    // Get the application for the finished container\n    ApplicationAttemptId applicationAttemptId = container.getId().getApplicationAttemptId();\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n    if (application == null) {\n      LOG.info(\"Container \" + container + \" of\" +\n          \" unknown application \" + applicationAttemptId +\n          \" completed with event \" + event);\n      return;\n    }\n\n    // Get the node on which the container was allocated\n    FSSchedulerNode node = nodes.get(container.getNodeId());\n\n    if (rmContainer.getState() == RMContainerState.RESERVED) {\n      application.unreserve(node, rmContainer.getReservedPriority());\n      node.unreserveResource(application);\n    } else {\n      application.containerCompleted(rmContainer, containerStatus, event);\n      node.releaseContainer(container);\n    }\n\n    LOG.info(\"Application \" + applicationAttemptId +\n        \" released container \" + container.getId() +\n        \" on node: \" + node +\n        \" with event: \" + event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent =\n      (NodeUpdateSchedulerEvent)event;\n      this.nodeUpdate(nodeUpdatedEvent.getRMNode(),\n          nodeUpdatedEvent.getNewlyLaunchedContainers(),\n          nodeUpdatedEvent.getCompletedContainers());\n    }\n    break;\n    case APP_ADDED:\n    {\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queue = appAddedEvent.getQueue();\n\n      // Potentially set queue to username if configured to do so\n      String def = YarnConfiguration.DEFAULT_QUEUE_NAME;\n      if (queue.equals(def) && userAsDefaultQueue) {\n        queue = appAddedEvent.getUser();\n      }\n\n      addApplication(appAddedEvent.getApplicationAttemptId(), queue,\n          appAddedEvent.getUser());\n    }\n    break;\n    case APP_REMOVED:\n    {\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      this.removeApplication(appRemovedEvent.getApplicationAttemptID(),\n          appRemovedEvent.getFinalAttemptState());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n    }\n    break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addNode": "  private synchronized void addNode(RMNode node) {\n    this.nodes.put(node.getNodeID(), new FSSchedulerNode(node));\n    Resources.addTo(clusterCapacity, node.getTotalCapability());\n\n    LOG.info(\"Added node \" + node.getNodeAddress() +\n        \" cluster capacity: \" + clusterCapacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected synchronized void\n  addApplication(ApplicationAttemptId applicationAttemptId,\n      String queueName, String user) {\n\n    FSQueue queue = this.queueMgr.getQueue(queueName);\n\n    FSSchedulerApp schedulerApp =\n        new FSSchedulerApp(applicationAttemptId, user,\n            queue.getQueueSchedulable(), new ActiveUsersManager(this.getRootQueueMetrics()),\n            rmContext, null);\n\n    // Inforce ACLs\n    UserGroupInformation userUgi;\n    try {\n      userUgi = UserGroupInformation.getCurrentUser();\n    } catch (IOException ioe) {\n      LOG.info(\"Failed to get current user information\");\n      return;\n    }\n\n    List<QueueUserACLInfo> info = queue.getQueueSchedulable().getQueueUserAclInfo(\n        userUgi); // Always a signleton list\n    if (!info.get(0).getUserAcls().contains(QueueACL.SUBMIT_APPLICATIONS)) {\n      LOG.info(\"User \" + userUgi.getUserName() +\n          \" cannot submit\" + \" applications to queue \" + queue.getName());\n      return;\n    }\n\n    queue.addApp(schedulerApp);\n    queue.getQueueSchedulable().getMetrics().submitApp(user,\n    \t\tapplicationAttemptId.getAttemptId());\n    rootMetrics.submitApp(user, applicationAttemptId.getAttemptId());\n\n    applications.put(applicationAttemptId, schedulerApp);\n\n    LOG.info(\"Application Submission: \" + applicationAttemptId +\n        \", user: \" + user +\n        \", currently active: \" + applications.size());\n\n    rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.APP_ACCEPTED));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication": "  private synchronized void removeApplication(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState) {\n    LOG.info(\"Application \" + applicationAttemptId + \" is done.\" +\n        \" finalState=\" + rmAppAttemptFinalState);\n\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n\n    if (application == null) {\n      LOG.info(\"Unknown application \" + applicationAttemptId + \" has completed!\");\n      return;\n    }\n\n    // Release all the running containers\n    for (RMContainer rmContainer : application.getLiveContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              SchedulerUtils.COMPLETED_APPLICATION),\n          RMContainerEventType.KILL);\n    }\n\n     // Release all reserved containers\n    for (RMContainer rmContainer : application.getReservedContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              \"Application Complete\"),\n          RMContainerEventType.KILL);\n    }\n\n    // Clean up pending requests, metrics etc.\n    application.stop(rmAppAttemptFinalState);\n\n    // Inform the queue\n    FSQueue queue = this.queueMgr.getQueue(application.getQueue().getQueueName());\n    queue.removeJob(application);\n\n    // Remove from our data-structure\n    applications.remove(applicationAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeNode": "  private synchronized void removeNode(RMNode rmNode) {\n    FSSchedulerNode node = this.nodes.get(rmNode.getNodeID());\n    Resources.subtractFrom(clusterCapacity, rmNode.getTotalCapability());\n\n    // Remove running containers\n    List<RMContainer> runningContainers = node.getRunningContainers();\n    for (RMContainer container : runningContainers) {\n      completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    // Remove reservations, if any\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      completedContainer(reservedContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              reservedContainer.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    this.nodes.remove(rmNode.getNodeID());\n    LOG.info(\"Removed node \" + rmNode.getNodeAddress() +\n        \" cluster capacity: \" + clusterCapacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public void run() {\n\n        SchedulerEvent event;\n\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          try {\n            event = eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return; // TODO: Kill RM.\n          }\n\n          try {\n            scheduler.handle(event);\n          } catch (Throwable t) {\n            // An error occurred, but we are shutting down anyway.\n            // If it was an InterruptedException, the very act of \n            // shutdown could have caused it and is probably harmless.\n            if (stopped) {\n              LOG.warn(\"Exception during shutdown: \", t);\n              break;\n            }\n            LOG.fatal(\"Error in handling event type \" + event.getType()\n                + \" to the scheduler\", t);\n            if (shouldExitOnError\n                && !ShutdownHookManager.get().isShutdownInProgress()) {\n              LOG.info(\"Exiting, bbye..\");\n              System.exit(-1);\n            }\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.getReservedContainer": "  public synchronized RMContainer getReservedContainer() {\n    return reservedContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.getQueueName": "  public String getQueueName() {\n    return this.appSchedulingInfo.getQueueName();\n  }"
        },
        "bug_report": {
            "Title": "Node update causes NPE in the fair scheduler",
            "Description": "The exception occurs when unreserve is called on an FSSchedulerApp with a NodeId that it does not know about.  The RM seems to have a different idea about what apps are reserved for which node than the scheduler.\n\n2012-10-29 22:30:52,901 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.unreserve(FSSchedulerApp.java:356)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.unreserve(AppSchedulable.java:214)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:266)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:330)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueSchedulable.assignContainer(FSQueueSchedulable.java:161)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:759)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:836)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:329)\n        at java.lang.Thread.run(Thread.java:662)\n2012-10-29 22:30:52,903 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Exiting, bbye.."
        }
    },
    {
        "filename": "YARN-4581.json",
        "creation_time": "2016-01-12T03:37:40.000+0000",
        "stack_trace": "```\njava.io.IOException: Output file not at zero offset.\n        at org.apache.hadoop.io.file.tfile.BCFile$Writer.<init>(BCFile.java:288)\n        at org.apache.hadoop.io.file.tfile.TFile$Writer.<init>(TFile.java:288)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore$HistoryFileWriter.<init>(FileSystemApplicationHistoryStore.java:728)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.applicationStarted(FileSystemApplicationHistoryStore.java:418)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent(RMApplicationHistoryWriter.java:140)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:292)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:191)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:124)\n        at java.lang.Thread.run(Thread.java:745)\n\njava.lang.OutOfMemoryError: unable to create new native thread\n        at java.lang.Thread.start0(Native Method)\n        at java.lang.Thread.start(Thread.java:714)\n        at org.apache.hadoop.hdfs.DFSOutputStream.start(DFSOutputStream.java:2033)\n        at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForAppend(DFSOutputStream.java:1652)\n        at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1573)\n        at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1603)\n        at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1591)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:324)\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:324)\n        at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1161)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore$HistoryFileWriter.<init>(FileSystemApplicationHistoryStore.java:723)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.applicationStarted(FileSystemApplicationHistoryStore.java:418)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent(RMApplicationHistoryWriter.java:140)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:292)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:191)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:124)\n        at java.lang.Thread.run(Thread.java:745)\n\njava.lang.Thread.State: TIMED_WAITING (on object monitor)\n        at java.lang.Object.wait(Native Method)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:502)\n        - locked <0x0000000745f88b98> (a java.util.LinkedList)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.applicationStarted": "  public void applicationStarted(ApplicationStartData appStart)\n      throws IOException {\n    HistoryFileWriter hfWriter =\n        outstandingWriters.get(appStart.getApplicationId());\n    if (hfWriter == null) {\n      Path applicationHistoryFile =\n          new Path(rootDirPath, appStart.getApplicationId().toString());\n      try {\n        hfWriter = new HistoryFileWriter(applicationHistoryFile);\n        LOG.info(\"Opened history file of application \"\n            + appStart.getApplicationId());\n      } catch (IOException e) {\n        LOG.error(\"Error when openning history file of application \"\n            + appStart.getApplicationId(), e);\n        throw e;\n      }\n      outstandingWriters.put(appStart.getApplicationId(), hfWriter);\n    } else {\n      throw new IOException(\"History file of application \"\n          + appStart.getApplicationId() + \" is already opened\");\n    }\n    assert appStart instanceof ApplicationStartDataPBImpl;\n    try {\n      hfWriter.writeHistoryData(new HistoryDataKey(appStart.getApplicationId()\n        .toString(), START_DATA_SUFFIX),\n        ((ApplicationStartDataPBImpl) appStart).getProto().toByteArray());\n      LOG.info(\"Start information of application \"\n          + appStart.getApplicationId() + \" is written\");\n    } catch (IOException e) {\n      LOG.error(\"Error when writing start information of application \"\n          + appStart.getApplicationId(), e);\n      throw e;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.writeHistoryData": "    public synchronized void writeHistoryData(HistoryDataKey key, byte[] value)\n        throws IOException {\n      DataOutputStream dos = null;\n      try {\n        dos = writer.prepareAppendKey(-1);\n        key.write(dos);\n      } finally {\n        IOUtils.cleanup(LOG, dos);\n      }\n      try {\n        dos = writer.prepareAppendValue(value.length);\n        dos.write(value);\n      } finally {\n        IOUtils.cleanup(LOG, dos);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent": "  protected void handleWritingApplicationHistoryEvent(\n      WritingApplicationHistoryEvent event) {\n    switch (event.getType()) {\n      case APP_START:\n        WritingApplicationStartEvent wasEvent =\n            (WritingApplicationStartEvent) event;\n        try {\n          writer.applicationStarted(wasEvent.getApplicationStartData());\n          LOG.info(\"Stored the start data of application \"\n              + wasEvent.getApplicationId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the start data of application \"\n              + wasEvent.getApplicationId());\n        }\n        break;\n      case APP_FINISH:\n        WritingApplicationFinishEvent wafEvent =\n            (WritingApplicationFinishEvent) event;\n        try {\n          writer.applicationFinished(wafEvent.getApplicationFinishData());\n          LOG.info(\"Stored the finish data of application \"\n              + wafEvent.getApplicationId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the finish data of application \"\n              + wafEvent.getApplicationId());\n        }\n        break;\n      case APP_ATTEMPT_START:\n        WritingApplicationAttemptStartEvent waasEvent =\n            (WritingApplicationAttemptStartEvent) event;\n        try {\n          writer.applicationAttemptStarted(waasEvent\n            .getApplicationAttemptStartData());\n          LOG.info(\"Stored the start data of application attempt \"\n              + waasEvent.getApplicationAttemptId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the start data of application attempt \"\n              + waasEvent.getApplicationAttemptId());\n        }\n        break;\n      case APP_ATTEMPT_FINISH:\n        WritingApplicationAttemptFinishEvent waafEvent =\n            (WritingApplicationAttemptFinishEvent) event;\n        try {\n          writer.applicationAttemptFinished(waafEvent\n            .getApplicationAttemptFinishData());\n          LOG.info(\"Stored the finish data of application attempt \"\n              + waafEvent.getApplicationAttemptId());\n        } catch (IOException e) {\n          LOG\n            .error(\"Error when storing the finish data of application attempt \"\n                + waafEvent.getApplicationAttemptId());\n        }\n        break;\n      case CONTAINER_START:\n        WritingContainerStartEvent wcsEvent =\n            (WritingContainerStartEvent) event;\n        try {\n          writer.containerStarted(wcsEvent.getContainerStartData());\n          LOG.info(\"Stored the start data of container \"\n              + wcsEvent.getContainerId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the start data of container \"\n              + wcsEvent.getContainerId());\n        }\n        break;\n      case CONTAINER_FINISH:\n        WritingContainerFinishEvent wcfEvent =\n            (WritingContainerFinishEvent) event;\n        try {\n          writer.containerFinished(wcfEvent.getContainerFinishData());\n          LOG.info(\"Stored the finish data of container \"\n              + wcfEvent.getContainerId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the finish data of container \"\n              + wcfEvent.getContainerId());\n        }\n        break;\n      default:\n        LOG.error(\"Unknown WritingApplicationHistoryEvent type: \"\n            + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.containerFinished": "  public void containerFinished(RMContainer container) {\n    if (historyServiceEnabled) {\n      dispatcher.getEventHandler().handle(\n        new WritingContainerFinishEvent(container.getContainerId(),\n          ContainerFinishData.newInstance(container.getContainerId(),\n            container.getFinishTime(), container.getDiagnosticsInfo(),\n            container.getContainerExitStatus(),\n            container.getContainerState())));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.applicationStarted": "  public void applicationStarted(RMApp app) {\n    if (historyServiceEnabled) {\n      dispatcher.getEventHandler().handle(\n        new WritingApplicationStartEvent(app.getApplicationId(),\n          ApplicationStartData.newInstance(app.getApplicationId(), app.getName(),\n            app.getApplicationType(), app.getQueue(), app.getUser(),\n            app.getSubmitTime(), app.getStartTime())));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.containerStarted": "  public void containerStarted(RMContainer container) {\n    if (historyServiceEnabled) {\n      dispatcher.getEventHandler().handle(\n        new WritingContainerStartEvent(container.getContainerId(),\n          ContainerStartData.newInstance(container.getContainerId(),\n            container.getAllocatedResource(), container.getAllocatedNode(),\n            container.getAllocatedPriority(), container.getCreationTime())));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.applicationFinished": "  public void applicationFinished(RMApp app, RMAppState finalState) {\n    if (historyServiceEnabled) {\n      dispatcher.getEventHandler().handle(\n        new WritingApplicationFinishEvent(app.getApplicationId(),\n          ApplicationFinishData.newInstance(app.getApplicationId(),\n            app.getFinishTime(), app.getDiagnostics().toString(),\n            app.getFinalApplicationStatus(),\n            RMServerUtils.createApplicationState(finalState))));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.applicationAttemptFinished": "  public void applicationAttemptFinished(RMAppAttempt appAttempt,\n      RMAppAttemptState finalState) {\n    if (historyServiceEnabled) {\n      dispatcher.getEventHandler().handle(\n        new WritingApplicationAttemptFinishEvent(appAttempt.getAppAttemptId(),\n          ApplicationAttemptFinishData.newInstance(\n            appAttempt.getAppAttemptId(), appAttempt.getDiagnostics()\n              .toString(), appAttempt.getTrackingUrl(), appAttempt\n              .getFinalApplicationStatus(),\n              RMServerUtils.createApplicationAttemptState(finalState))));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.applicationAttemptStarted": "  public void applicationAttemptStarted(RMAppAttempt appAttempt) {\n    if (historyServiceEnabled) {\n      dispatcher.getEventHandler().handle(\n        new WritingApplicationAttemptStartEvent(appAttempt.getAppAttemptId(),\n          ApplicationAttemptStartData.newInstance(appAttempt.getAppAttemptId(),\n            appAttempt.getHost(), appAttempt.getRpcPort(), appAttempt\n              .getMasterContainer().getId())));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handle": "      public void handle(Event event) {\n        // Use hashCode (of ApplicationId) to dispatch the event to the child\n        // dispatcher, such that all the writing events of one application will\n        // be handled by one thread, the scheduled order of the these events\n        // will be preserved\n        int index = (event.hashCode() & Integer.MAX_VALUE) % dispatchers.size();\n        dispatchers.get(index).getEventHandler().handle(event);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.getEventHandler": "    public EventHandler getEventHandler() {\n      return new CompositEventHandler();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystemLinkResolver.resolve": "  public T resolve(final FileSystem filesys, final Path path)\n      throws IOException {\n    int count = 0;\n    T in = null;\n    Path p = path;\n    // Assumes path belongs to this FileSystem.\n    // Callers validate this by passing paths through FileSystem#checkPath\n    FileSystem fs = filesys;\n    for (boolean isLink = true; isLink;) {\n      try {\n        in = doCall(p);\n        isLink = false;\n      } catch (UnresolvedLinkException e) {\n        if (!filesys.resolveSymlinks) {\n          throw new IOException(\"Path \" + path + \" contains a symlink\"\n              + \" and symlink resolution is disabled (\"\n              + CommonConfigurationKeys.FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY\n              + \").\", e);\n        }\n        if (!FileSystem.areSymlinksEnabled()) {\n          throw new IOException(\"Symlink resolution is disabled in\" +\n              \" this version of Hadoop.\");\n        }\n        if (count++ > FsConstants.MAX_PATH_LINKS) {\n          throw new IOException(\"Possible cyclic loop while \" +\n                                \"following symbolic link \" + path);\n        }\n        // Resolve the first unresolved path component\n        p = FSLinkResolver.qualifySymlinkTarget(fs.getUri(), p,\n            filesys.resolveLink(p));\n        fs = FileSystem.getFSofPath(p, filesys.getConf());\n        // Have to call next if it's a new FS\n        if (!fs.equals(filesys)) {\n          return next(fs, p);\n        }\n        // Else, we keep resolving with this filesystem\n      }\n    }\n    // Successful call, path was fully resolved\n    return in;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystemLinkResolver.doCall": "  abstract public T doCall(final Path p) throws IOException,\n      UnresolvedLinkException;\n\n  /**\n   * Calls the abstract FileSystem call equivalent to the specialized subclass\n   * implementation in {@link #doCall(Path)}. This is used when retrying the",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystemLinkResolver.next": "  abstract public T next(final FileSystem fs, final Path p) throws IOException;\n\n  /**\n   * Attempt calling overridden {@link #doCall(Path)} method with",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.append": "  public abstract FSDataOutputStream append(Path f, int bufferSize,\n      Progressable progress) throws IOException;\n\n  /**\n   * Concat existing files together.\n   * @param trg the path to the target destination.\n   * @param psrcs the paths to the sources to use for the concatenation.\n   * @throws IOException\n   */\n  public void concat(final Path trg, final Path [] psrcs) throws IOException {\n    throw new UnsupportedOperationException(\"Not implemented by the \" + \n        getClass().getSimpleName() + \" FileSystem implementation\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationAttemptStartEvent.getApplicationAttemptStartData": "  public ApplicationAttemptStartData getApplicationAttemptStartData() {\n    return appAttemptStart;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerFinishEvent.getContainerId": "  public ContainerId getContainerId() {\n    return containerId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationAttemptFinishEvent.getApplicationAttemptId": "  public ApplicationAttemptId getApplicationAttemptId() {\n    return appAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationAttemptFinishEvent.getApplicationAttemptFinishData": "  public ApplicationAttemptFinishData getApplicationAttemptFinishData() {\n    return appAttemptFinish;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationFinishEvent.getApplicationId": "  public ApplicationId getApplicationId() {\n    return appId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationFinishEvent.getApplicationFinishData": "  public ApplicationFinishData getApplicationFinishData() {\n    return appFinish;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerFinishEvent.getContainerFinishData": "  public ContainerFinishData getContainerFinishData() {\n    return containerFinish;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationStartEvent.getApplicationId": "  public ApplicationId getApplicationId() {\n    return appId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationAttemptStartEvent.getApplicationAttemptId": "  public ApplicationAttemptId getApplicationAttemptId() {\n    return appAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingApplicationStartEvent.getApplicationStartData": "  public ApplicationStartData getApplicationStartData() {\n    return appStart;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerStartEvent.getContainerStartData": "  public ContainerStartData getContainerStartData() {\n    return containerStart;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerStartEvent.getContainerId": "  public ContainerId getContainerId() {\n    return containerId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FSLinkResolver.qualifySymlinkTarget": "  public static Path qualifySymlinkTarget(final URI pathURI,\n      Path pathWithLink, Path target) {\n    // NB: makeQualified uses the target's scheme and authority, if\n    // specified, and the scheme and authority of pathURI, if not.\n    final URI targetUri = target.toUri();\n    final String scheme = targetUri.getScheme();\n    final String auth = targetUri.getAuthority();\n    return (scheme == null && auth == null) ? target.makeQualified(pathURI,\n        pathWithLink.getParent()) : target;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.areSymlinksEnabled": "  public static boolean areSymlinksEnabled() {\n    return symlinksEnabled;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getUri": "  public abstract URI getUri();\n  \n  /**\n   * Return a canonicalized form of this FileSystem's URI.\n   * \n   * The default implementation simply calls {@link #canonicalizeUri(URI)}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.equals": "      public boolean equals(Object obj) {\n        if (obj == this) {\n          return true;\n        }\n        if (obj != null && obj instanceof Key) {\n          Key that = (Key)obj;\n          return isEqual(this.scheme, that.scheme)\n                 && isEqual(this.authority, that.authority)\n                 && isEqual(this.ugi, that.ugi)\n                 && (this.unique == that.unique);\n        }\n        return false;        \n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.isEqual": "      static boolean isEqual(Object a, Object b) {\n        return a == b || (a != null && a.equals(b));        \n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getFSofPath": "  protected static FileSystem getFSofPath(final Path absOrFqPath,\n      final Configuration conf)\n      throws UnsupportedFileSystemException, IOException {\n    absOrFqPath.checkNotSchemeWithRelative();\n    absOrFqPath.checkNotRelative();\n\n    // Uses the default file system if not fully qualified\n    return get(absOrFqPath.toUri(), conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.get": "    FileSystem get(URI uri, Configuration conf) throws IOException{\n      Key key = new Key(uri, conf);\n      return getInternal(uri, conf, key);\n    }"
        },
        "bug_report": {
            "Title": "AHS writer thread leak makes RM crash while RM is recovering",
            "Description": "we enable ApplicationHistoryWriter, and find thousands of  Errors:\n\n{quote}\n2016-01-08 03:13:03,441 ERROR org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore: Error when openning history file of application application_1451878591907_0197\njava.io.IOException: Output file not at zero offset.\n        at org.apache.hadoop.io.file.tfile.BCFile$Writer.<init>(BCFile.java:288)\n        at org.apache.hadoop.io.file.tfile.TFile$Writer.<init>(TFile.java:288)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore$HistoryFileWriter.<init>(FileSystemApplicationHistoryStore.java:728)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.applicationStarted(FileSystemApplicationHistoryStore.java:418)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent(RMApplicationHistoryWriter.java:140)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:292)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:191)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:124)\n        at java.lang.Thread.run(Thread.java:745)\n{quote}\n\nand this leads rm crashed:\n\n{quote}\n2016-01-08 03:13:08,335 FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\njava.lang.OutOfMemoryError: unable to create new native thread\n        at java.lang.Thread.start0(Native Method)\n        at java.lang.Thread.start(Thread.java:714)\n        at org.apache.hadoop.hdfs.DFSOutputStream.start(DFSOutputStream.java:2033)\n        at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForAppend(DFSOutputStream.java:1652)\n        at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1573)\n        at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1603)\n        at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1591)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:324)\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:324)\n        at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1161)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore$HistoryFileWriter.<init>(FileSystemApplicationHistoryStore.java:723)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.applicationStarted(FileSystemApplicationHistoryStore.java:418)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent(RMApplicationHistoryWriter.java:140)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:292)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:191)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:124)\n        at java.lang.Thread.run(Thread.java:745)\n{quote}\n\nafter serveval failover, rm finish recovering, thousands of hdfs client thread are leaked in rm.\n{quote}\n\"Thread-22723\" #22893 daemon prio=5 os_prio=0 tid=0x00007f75f0346000 nid=0x132e in Object.wait() [0x00007f74ea7ca000]\n   java.lang.Thread.State: TIMED_WAITING (on object monitor)\n        at java.lang.Object.wait(Native Method)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:502)\n        - locked <0x0000000745f88b98> (a java.util.LinkedList)\n{quote}"
        }
    },
    {
        "filename": "YARN-7786.json",
        "creation_time": "2018-01-22T14:29:46.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.setupTokens(AMLauncher.java:205)\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.createAMContainerLaunchContext(AMLauncher.java:193)\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:112)\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:304)\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.setupTokens": "  protected void setupTokens(\n      ContainerLaunchContext container, ContainerId containerID)\n      throws IOException {\n    Map<String, String> environment = container.getEnvironment();\n    environment.put(ApplicationConstants.APPLICATION_WEB_PROXY_BASE_ENV,\n        application.getWebProxyBase());\n    // Set AppSubmitTime to be consumable by the AM.\n    ApplicationId applicationId =\n        application.getAppAttemptId().getApplicationId();\n    environment.put(\n        ApplicationConstants.APP_SUBMIT_TIME_ENV,\n        String.valueOf(rmContext.getRMApps()\n            .get(applicationId)\n            .getSubmitTime()));\n\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = container.getTokens();\n    if (tokens != null) {\n      // TODO: Don't do this kind of checks everywhere.\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n\n    // Add AMRMToken\n    Token<AMRMTokenIdentifier> amrmToken = createAndSetAMRMToken();\n    if (amrmToken != null) {\n      credentials.addToken(amrmToken.getService(), amrmToken);\n    }\n    DataOutputBuffer dob = new DataOutputBuffer();\n    credentials.writeTokenStorageToStream(dob);\n    container.setTokens(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.createAndSetAMRMToken": "  protected Token<AMRMTokenIdentifier> createAndSetAMRMToken() {\n    Token<AMRMTokenIdentifier> amrmToken =\n        this.rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n          application.getAppAttemptId());\n    ((RMAppAttemptImpl)application).setAMRMToken(amrmToken);\n    return amrmToken;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.createAMContainerLaunchContext": "  private ContainerLaunchContext createAMContainerLaunchContext(\n      ApplicationSubmissionContext applicationMasterContext,\n      ContainerId containerID) throws IOException {\n\n    // Construct the actual Container\n    ContainerLaunchContext container =\n        applicationMasterContext.getAMContainerSpec();\n\n    // Finalize the container\n    setupTokens(container, containerID);\n    // set the flow context optionally for timeline service v.2\n    setFlowContext(container);\n\n    return container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.setFlowContext": "  private void setFlowContext(ContainerLaunchContext container) {\n    if (YarnConfiguration.timelineServiceV2Enabled(conf)) {\n      Map<String, String> environment = container.getEnvironment();\n      ApplicationId applicationId =\n          application.getAppAttemptId().getApplicationId();\n      RMApp app = rmContext.getRMApps().get(applicationId);\n\n      // initialize the flow in the environment with default values for those\n      // that do not specify the flow tags\n      // flow name: app name (or app id if app name is missing),\n      // flow version: \"1\", flow run id: start time\n      setFlowTags(environment, TimelineUtils.FLOW_NAME_TAG_PREFIX,\n          TimelineUtils.generateDefaultFlowName(app.getName(), applicationId));\n      setFlowTags(environment, TimelineUtils.FLOW_VERSION_TAG_PREFIX,\n          TimelineUtils.DEFAULT_FLOW_VERSION);\n      setFlowTags(environment, TimelineUtils.FLOW_RUN_ID_TAG_PREFIX,\n          String.valueOf(app.getStartTime()));\n\n      // Set flow context info: the flow context is received via the application\n      // tags\n      for (String tag : app.getApplicationTags()) {\n        String[] parts = tag.split(\":\", 2);\n        if (parts.length != 2 || parts[1].isEmpty()) {\n          continue;\n        }\n        switch (parts[0].toUpperCase()) {\n        case TimelineUtils.FLOW_NAME_TAG_PREFIX:\n          setFlowTags(environment, TimelineUtils.FLOW_NAME_TAG_PREFIX,\n              parts[1]);\n          break;\n        case TimelineUtils.FLOW_VERSION_TAG_PREFIX:\n          setFlowTags(environment, TimelineUtils.FLOW_VERSION_TAG_PREFIX,\n              parts[1]);\n          break;\n        case TimelineUtils.FLOW_RUN_ID_TAG_PREFIX:\n          setFlowTags(environment, TimelineUtils.FLOW_RUN_ID_TAG_PREFIX,\n              parts[1]);\n          break;\n        default:\n          break;\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch": "  private void launch() throws IOException, YarnException {\n    connect();\n    ContainerId masterContainerID = masterContainer.getId();\n    ApplicationSubmissionContext applicationContext =\n      application.getSubmissionContext();\n    LOG.info(\"Setting up container \" + masterContainer\n        + \" for AM \" + application.getAppAttemptId());\n    ContainerLaunchContext launchContext =\n        createAMContainerLaunchContext(applicationContext, masterContainerID);\n\n    StartContainerRequest scRequest =\n        StartContainerRequest.newInstance(launchContext,\n          masterContainer.getContainerToken());\n    List<StartContainerRequest> list = new ArrayList<StartContainerRequest>();\n    list.add(scRequest);\n    StartContainersRequest allRequests =\n        StartContainersRequest.newInstance(list);\n\n    StartContainersResponse response =\n        containerMgrProxy.startContainers(allRequests);\n    if (response.getFailedRequests() != null\n        && response.getFailedRequests().containsKey(masterContainerID)) {\n      Throwable t =\n          response.getFailedRequests().get(masterContainerID).deSerialize();\n      parseAndThrowException(t);\n    } else {\n      LOG.info(\"Done launching container \" + masterContainer + \" for AM \"\n          + application.getAppAttemptId());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.connect": "  private void connect() throws IOException {\n    ContainerId masterContainerID = masterContainer.getId();\n\n    containerMgrProxy = getContainerMgrProxy(masterContainerID);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.parseAndThrowException": "  private void parseAndThrowException(Throwable t) throws YarnException,\n      IOException {\n    if (t instanceof YarnException) {\n      throw (YarnException) t;\n    } else if (t instanceof InvalidToken) {\n      throw (InvalidToken) t;\n    } else {\n      throw (IOException) t;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run": "  public void run() {\n    switch (eventType) {\n    case LAUNCH:\n      try {\n        LOG.info(\"Launching master\" + application.getAppAttemptId());\n        launch();\n        handler.handle(new RMAppAttemptEvent(application.getAppAttemptId(),\n            RMAppAttemptEventType.LAUNCHED));\n      } catch(Exception ie) {\n        String message = \"Error launching \" + application.getAppAttemptId()\n            + \". Got exception: \" + StringUtils.stringifyException(ie);\n        LOG.info(message);\n        handler.handle(new RMAppAttemptEvent(application\n            .getAppAttemptId(), RMAppAttemptEventType.LAUNCH_FAILED, message));\n      }\n      break;\n    case CLEANUP:\n      try {\n        LOG.info(\"Cleaning master \" + application.getAppAttemptId());\n        cleanup();\n      } catch(IOException ie) {\n        LOG.info(\"Error cleaning master \", ie);\n      } catch (YarnException e) {\n        StringBuilder sb = new StringBuilder(\"Container \");\n        sb.append(masterContainer.getId().toString());\n        sb.append(\" is not handled by this NodeManager\");\n        if (!e.getMessage().contains(sb.toString())) {\n          // Ignoring if container is already killed by Node Manager.\n          LOG.info(\"Error cleaning master \", e);\n        }\n      }\n      break;\n    default:\n      LOG.warn(\"Received unknown event-type \" + eventType + \". Ignoring.\");\n      break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup": "  private void cleanup() throws IOException, YarnException {\n    connect();\n    ContainerId containerId = masterContainer.getId();\n    List<ContainerId> containerIds = new ArrayList<ContainerId>();\n    containerIds.add(containerId);\n    StopContainersRequest stopRequest =\n        StopContainersRequest.newInstance(containerIds);\n    StopContainersResponse response =\n        containerMgrProxy.stopContainers(stopRequest);\n    if (response.getFailedRequests() != null\n        && response.getFailedRequests().containsKey(containerId)) {\n      Throwable t = response.getFailedRequests().get(containerId).deSerialize();\n      parseAndThrowException(t);\n    }\n  }"
        },
        "bug_report": {
            "Title": "NullPointerException while launching ApplicationMaster",
            "Description": "Before launching the ApplicationMaster, send kill command to the job, then some Null pointer appears:\r\n\r\n{code}\r\n\r\n2017-11-25 21:27:25,333 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1511616410268_0001_000001. Got exception: java.lang.NullPointerException\r\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.setupTokens(AMLauncher.java:205)\r\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.createAMContainerLaunchContext(AMLauncher.java:193)\r\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:112)\r\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:304)\r\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n at java.lang.Thread.run(Thread.java:745)\r\n\r\n{code}"
        }
    },
    {
        "filename": "YARN-8035.json",
        "creation_time": "2018-03-16T12:02:04.000+0000",
        "stack_trace": "```\norg.apache.hadoop.metrics2.MetricsException: Tag ContainerPid already exists!\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.checkTagName(MetricsRegistry.java:433)\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.tag(MetricsRegistry.java:394)\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.tag(MetricsRegistry.java:400)\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerMetrics.recordProcessId(ContainerMetrics.java:277)\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.initializeProcessTrees(ContainersMonitorImpl.java:559)\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.run(ContainersMonitorImpl.java:448)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.metrics2.lib.MetricsRegistry.checkTagName": "  private void checkTagName(String name) {\n    if (tagsMap.containsKey(name)) {\n      throw new MetricsException(\"Tag \"+ name +\" already exists!\");\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.metrics2.lib.MetricsRegistry.tag": "  public MetricsRegistry tag(MetricsInfo info, String value) {\n    return tag(info, value, false);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.metrics2.lib.MetricsRegistry.info": "  public MetricsInfo info() {\n    return metricsInfo;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerMetrics.recordProcessId": "  public void recordProcessId(String processId) {\n    registry.tag(PROCESSID_INFO, processId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerMetrics.tag": "  ContainerMetrics tag(MetricsInfo info, ContainerId containerId) {\n    registry.tag(info, containerId.toString());\n    return this;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.initializeProcessTrees": "    private void initializeProcessTrees(\n            Entry<ContainerId, ProcessTreeInfo> entry)\n        throws ContainerExecutionException {\n      ContainerId containerId = entry.getKey();\n      ProcessTreeInfo ptInfo = entry.getValue();\n      String pId = ptInfo.getPID();\n\n      // Initialize any uninitialized processTrees\n      if (pId == null) {\n        // get pid from ContainerId\n        pId = containerExecutor.getProcessId(ptInfo.getContainerId());\n        if (pId != null) {\n          // pId will be null, either if the container is not spawned yet\n          // or if the container's pid is removed from ContainerExecutor\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Tracking ProcessTree \" + pId + \" for the first time\");\n          }\n          ResourceCalculatorProcessTree pt =\n              getResourceCalculatorProcessTree(pId);\n          ptInfo.setPid(pId);\n          ptInfo.setProcessTree(pt);\n\n          if (containerMetricsEnabled) {\n            ContainerMetrics usageMetrics = ContainerMetrics\n                    .forContainer(containerId, containerMetricsPeriodMs,\n                      containerMetricsUnregisterDelayMs);\n            usageMetrics.recordProcessId(pId);\n          }\n\n          Container container = context.getContainers().get(containerId);\n\n          if (container != null) {\n            String[] ipAndHost = containerExecutor.getIpAndHost(container);\n\n            if ((ipAndHost != null) && (ipAndHost[0] != null) &&\n                (ipAndHost[1] != null)) {\n              container.setIpAndHost(ipAndHost);\n              LOG.info(containerId + \"'s ip = \" + ipAndHost[0]\n                  + \", and hostname = \" + ipAndHost[1]);\n            } else {\n              LOG.info(\"Can not get both ip and hostname: \"\n                  + Arrays.toString(ipAndHost));\n            }\n          } else {\n            LOG.info(containerId + \" is missing. Not setting ip and hostname\");\n          }\n        }\n      }\n      // End of initializing any uninitialized processTrees\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.getResourceCalculatorProcessTree": "  private ResourceCalculatorProcessTree\n      getResourceCalculatorProcessTree(String pId) {\n    return ResourceCalculatorProcessTree.\n        getResourceCalculatorProcessTree(\n            pId, processTreeClass, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.getContainerId": "    public ContainerId getContainerId() {\n      return this.containerId;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.setPid": "    public void setPid(String pid) {\n      this.pid = pid;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.setProcessTree": "    void setProcessTree(ResourceCalculatorProcessTree mypTree) {\n      this.pTree = mypTree;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.getPID": "    public String getPID() {\n      return this.pid;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.run": "    public void run() {\n\n      while (!stopped && !Thread.currentThread().isInterrupted()) {\n        // Print the processTrees for debugging.\n        if (LOG.isDebugEnabled()) {\n          StringBuilder tmp = new StringBuilder(\"[ \");\n          for (ProcessTreeInfo p : trackingContainers.values()) {\n            tmp.append(p.getPID());\n            tmp.append(\" \");\n          }\n          LOG.debug(\"Current ProcessTree list : \"\n              + tmp.substring(0, tmp.length()) + \"]\");\n        }\n\n        // Temporary structure to calculate the total resource utilization of\n        // the containers\n        ResourceUtilization trackedContainersUtilization  =\n            ResourceUtilization.newInstance(0, 0, 0.0f);\n\n        // Now do the monitoring for the trackingContainers\n        // Check memory usage and kill any overflowing containers\n        long vmemUsageByAllContainers = 0;\n        long pmemByAllContainers = 0;\n        long cpuUsagePercentPerCoreByAllContainers = 0;\n        for (Entry<ContainerId, ProcessTreeInfo> entry : trackingContainers\n            .entrySet()) {\n          ContainerId containerId = entry.getKey();\n          ProcessTreeInfo ptInfo = entry.getValue();\n          try {\n            String pId = ptInfo.getPID();\n\n            // Initialize uninitialized process trees\n            initializeProcessTrees(entry);\n\n            if (pId == null || !isResourceCalculatorAvailable()) {\n              continue; // processTree cannot be tracked\n            }\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Constructing ProcessTree for : PID = \" + pId\n                  + \" ContainerId = \" + containerId);\n            }\n            ResourceCalculatorProcessTree pTree = ptInfo.getProcessTree();\n            pTree.updateProcessTree();    // update process-tree\n            long currentVmemUsage = pTree.getVirtualMemorySize();\n            long currentPmemUsage = pTree.getRssMemorySize();\n\n            // if machine has 6 cores and 3 are used,\n            // cpuUsagePercentPerCore should be 300%\n            float cpuUsagePercentPerCore = pTree.getCpuUsagePercent();\n            if (cpuUsagePercentPerCore < 0) {\n              // CPU usage is not available likely because the container just\n              // started. Let us skip this turn and consider this container\n              // in the next iteration.\n              LOG.info(\"Skipping monitoring container \" + containerId\n                  + \" since CPU usage is not yet available.\");\n              continue;\n            }\n\n            recordUsage(containerId, pId, pTree, ptInfo, currentVmemUsage,\n                    currentPmemUsage, trackedContainersUtilization);\n\n            checkLimit(containerId, pId, pTree, ptInfo,\n                    currentVmemUsage, currentPmemUsage);\n\n            // Accounting the total memory in usage for all containers\n            vmemUsageByAllContainers += currentVmemUsage;\n            pmemByAllContainers += currentPmemUsage;\n            // Accounting the total cpu usage for all containers\n            cpuUsagePercentPerCoreByAllContainers += cpuUsagePercentPerCore;\n\n            reportResourceUsage(containerId, currentPmemUsage,\n                    cpuUsagePercentPerCore);\n          } catch (Exception e) {\n            // Log the exception and proceed to the next container.\n            LOG.warn(\"Uncaught exception in ContainersMonitorImpl \"\n                + \"while monitoring resource of \" + containerId, e);\n          }\n        }\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Total Resource Usage stats in NM by all containers : \"\n              + \"Virtual Memory= \" + vmemUsageByAllContainers\n              + \", Physical Memory= \" + pmemByAllContainers\n              + \", Total CPU usage(% per core)= \"\n              + cpuUsagePercentPerCoreByAllContainers);\n        }\n\n        // Save the aggregated utilization of the containers\n        setContainersUtilization(trackedContainersUtilization);\n\n        // Publish the container utilization metrics to node manager\n        // metrics system.\n        NodeManagerMetrics nmMetrics = context.getNodeManagerMetrics();\n        if (nmMetrics != null) {\n          nmMetrics.setContainerUsedMemGB(\n              trackedContainersUtilization.getPhysicalMemory());\n          nmMetrics.setContainerUsedVMemGB(\n              trackedContainersUtilization.getVirtualMemory());\n          nmMetrics.setContainerCpuUtilization(\n              trackedContainersUtilization.getCPU());\n        }\n\n        try {\n          Thread.sleep(monitoringInterval);\n        } catch (InterruptedException e) {\n          LOG.warn(ContainersMonitorImpl.class.getName()\n              + \" is interrupted. Exiting.\");\n          break;\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.checkLimit": "    private void checkLimit(ContainerId containerId, String pId,\n                            ResourceCalculatorProcessTree pTree,\n                            ProcessTreeInfo ptInfo,\n                            long currentVmemUsage,\n                            long currentPmemUsage) {\n      boolean isMemoryOverLimit = false;\n      long vmemLimit = ptInfo.getVmemLimit();\n      long pmemLimit = ptInfo.getPmemLimit();\n      // as processes begin with an age 1, we want to see if there\n      // are processes more than 1 iteration old.\n      long curMemUsageOfAgedProcesses = pTree.getVirtualMemorySize(1);\n      long curRssMemUsageOfAgedProcesses = pTree.getRssMemorySize(1);\n      String msg = \"\";\n      int containerExitStatus = ContainerExitStatus.INVALID;\n      if (isVmemCheckEnabled()\n              && isProcessTreeOverLimit(containerId.toString(),\n              currentVmemUsage, curMemUsageOfAgedProcesses, vmemLimit)) {\n        // The current usage (age=0) is always higher than the aged usage. We\n        // do not show the aged size in the message, base the delta on the\n        // current usage\n        long delta = currentVmemUsage - vmemLimit;\n        // Container (the root process) is still alive and overflowing\n        // memory.\n        // Dump the process-tree and then clean it up.\n        msg = formatErrorMessage(\"virtual\",\n                formatUsageString(currentVmemUsage, vmemLimit,\n                  currentPmemUsage, pmemLimit),\n                pId, containerId, pTree, delta);\n        isMemoryOverLimit = true;\n        containerExitStatus = ContainerExitStatus.KILLED_EXCEEDED_VMEM;\n      } else if (isPmemCheckEnabled()\n              && isProcessTreeOverLimit(containerId.toString(),\n              currentPmemUsage, curRssMemUsageOfAgedProcesses,\n              pmemLimit)) {\n        // The current usage (age=0) is always higher than the aged usage. We\n        // do not show the aged size in the message, base the delta on the\n        // current usage\n        long delta = currentPmemUsage - pmemLimit;\n        // Container (the root process) is still alive and overflowing\n        // memory.\n        // Dump the process-tree and then clean it up.\n        msg = formatErrorMessage(\"physical\",\n                formatUsageString(currentVmemUsage, vmemLimit,\n                  currentPmemUsage, pmemLimit),\n                pId, containerId, pTree, delta);\n        isMemoryOverLimit = true;\n        containerExitStatus = ContainerExitStatus.KILLED_EXCEEDED_PMEM;\n      }\n\n      if (isMemoryOverLimit) {\n        // Virtual or physical memory over limit. Fail the container and\n        // remove\n        // the corresponding process tree\n        LOG.warn(msg);\n        // warn if not a leader\n        if (!pTree.checkPidPgrpidForMatch()) {\n          LOG.error(\"Killed container process with PID \" + pId\n                  + \" but it is not a process group leader.\");\n        }\n        // kill the container\n        eventDispatcher.getEventHandler().handle(\n                new ContainerKillEvent(containerId,\n                      containerExitStatus, msg));\n        trackingContainers.remove(containerId);\n        LOG.info(\"Removed ProcessTree with root \" + pId);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.getProcessTree": "    ResourceCalculatorProcessTree getProcessTree() {\n      return this.pTree;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.isResourceCalculatorAvailable": "  private boolean isResourceCalculatorAvailable() {\n    if (resourceCalculatorPlugin == null) {\n      LOG.info(\"ResourceCalculatorPlugin is unavailable on this system. \" + this\n          .getClass().getName() + \" is disabled.\");\n      return false;\n    }\n    if (getResourceCalculatorProcessTree(\"0\") == null) {\n      LOG.info(\"ResourceCalculatorProcessTree is unavailable on this system. \"\n          + this.getClass().getName() + \" is disabled.\");\n      return false;\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.reportResourceUsage": "    private void reportResourceUsage(ContainerId containerId,\n        long currentPmemUsage, float cpuUsagePercentPerCore) {\n      ContainerImpl container =\n              (ContainerImpl) context.getContainers().get(containerId);\n      if (container != null) {\n        NMTimelinePublisher nmMetricsPublisher =\n                container.getNMTimelinePublisher();\n        if (nmMetricsPublisher != null) {\n          nmMetricsPublisher.reportContainerResourceUsage(container,\n                  currentPmemUsage, cpuUsagePercentPerCore);\n        }\n      } else {\n        LOG.info(containerId + \" does not exist to report\");\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.setContainersUtilization": "  private void setContainersUtilization(ResourceUtilization utilization) {\n    this.containersUtilization = utilization;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.recordUsage": "    private void recordUsage(ContainerId containerId, String pId,\n                             ResourceCalculatorProcessTree pTree,\n                             ProcessTreeInfo ptInfo,\n                             long currentVmemUsage, long currentPmemUsage,\n                             ResourceUtilization trackedContainersUtilization) {\n      // if machine has 6 cores and 3 are used,\n      // cpuUsagePercentPerCore should be 300% and\n      // cpuUsageTotalCoresPercentage should be 50%\n      float cpuUsagePercentPerCore = pTree.getCpuUsagePercent();\n      float cpuUsageTotalCoresPercentage = cpuUsagePercentPerCore /\n              resourceCalculatorPlugin.getNumProcessors();\n\n      // Multiply by 1000 to avoid losing data when converting to int\n      int milliVcoresUsed = (int) (cpuUsageTotalCoresPercentage * 1000\n              * maxVCoresAllottedForContainers /nodeCpuPercentageForYARN);\n      long vmemLimit = ptInfo.getVmemLimit();\n      long pmemLimit = ptInfo.getPmemLimit();\n      if (AUDITLOG.isDebugEnabled()) {\n        AUDITLOG.debug(String.format(\n            \"Resource usage of ProcessTree %s for container-id %s:\" +\n                \" %s CPU:%f CPU/core:%f\",\n            pId, containerId.toString(),\n            formatUsageString(\n                currentVmemUsage, vmemLimit,\n                currentPmemUsage, pmemLimit),\n            cpuUsagePercentPerCore,\n            cpuUsageTotalCoresPercentage));\n      }\n\n      // Add resource utilization for this container\n      trackedContainersUtilization.addTo(\n              (int) (currentPmemUsage >> 20),\n              (int) (currentVmemUsage >> 20),\n              milliVcoresUsed / 1000.0f);\n\n      // Add usage to container metrics\n      if (containerMetricsEnabled) {\n        ContainerMetrics.forContainer(\n                containerId, containerMetricsPeriodMs,\n                containerMetricsUnregisterDelayMs).recordMemoryUsage(\n                (int) (currentPmemUsage >> 20));\n        ContainerMetrics.forContainer(\n                containerId, containerMetricsPeriodMs,\n                containerMetricsUnregisterDelayMs).recordCpuUsage((int)\n                cpuUsagePercentPerCore, milliVcoresUsed);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerMetrics.forContainer": "  synchronized static ContainerMetrics forContainer(\n      MetricsSystem ms, ContainerId containerId, long flushPeriodMs,\n      long delayMs) {\n    ContainerMetrics metrics = usageMetrics.get(containerId);\n    if (metrics == null) {\n      metrics = new ContainerMetrics(ms, containerId, flushPeriodMs,\n          delayMs).tag(RECORD_INFO, containerId);\n\n      // Register with the MetricsSystems\n      if (ms != null) {\n        metrics =\n            ms.register(sourceName(containerId),\n                \"Metrics for container: \" + containerId, metrics);\n      }\n      usageMetrics.put(containerId, metrics);\n    }\n\n    return metrics;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerMetrics.sourceName": "  static String sourceName(ContainerId containerId) {\n    return RECORD_INFO.name() + \"_\" + containerId.toString();\n  }"
        },
        "bug_report": {
            "Title": "Uncaught exception in ContainersMonitorImpl during relaunch due to the process ID changing",
            "Description": "In the case of a container relaunch event, the container ID is reused but a new process is spawned.\u00a0For resource monitoring, {{ContainersMonitorImpl}} will obtain the new PID post relaunch and initialize the process tree monitoring. As part of this initialization, a tag called {{ContainerPid}}, whose value is the\u00a0PID for the container, is\u00a0populated for\u00a0the metrics associated with the container. If the prior container failed after its process started, the original PID will already be populated for the container, resulting in the {{MetricsException}} below.\r\n{code:java}\r\n2018-03-16 11:59:02,563 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Uncaught exception in ContainersMonitorImpl while monitoring resource of container_1521201379995_0001_01_000002\r\norg.apache.hadoop.metrics2.MetricsException: Tag ContainerPid already exists!\r\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.checkTagName(MetricsRegistry.java:433)\r\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.tag(MetricsRegistry.java:394)\r\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.tag(MetricsRegistry.java:400)\r\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerMetrics.recordProcessId(ContainerMetrics.java:277)\r\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.initializeProcessTrees(ContainersMonitorImpl.java:559)\r\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.run(ContainersMonitorImpl.java:448){code}\r\n{{MetricsRegistry}} provides a {{tag}} method that allows for updating the value of an existing tag. Updating the value ensures that the PID associated with container is the currently running process, which appears to be an appropriate fix. However, it's unclear how this tag might be being used by other systems. I'm not finding any usage in Hadoop itself."
        }
    },
    {
        "filename": "YARN-4152.json",
        "creation_time": "2015-09-12T15:02:22.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.stopContainer(LogAggregationService.java:422)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:456)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:68)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.stopContainer": "  private void stopContainer(ContainerId containerId, int exitCode) {\n\n    // A container is complete. Put this containers' logs up for aggregation if\n    // this containers' logs are needed.\n\n    AppLogAggregator aggregator = this.appLogAggregators.get(\n        containerId.getApplicationAttemptId().getApplicationId());\n    if (aggregator == null) {\n      LOG.warn(\"Log aggregation is not initialized for \" + containerId\n          + \", did it fail to start?\");\n      return;\n    }\n    ContainerType containerType = context.getContainers().get(\n        containerId).getContainerTokenIdentifier().getContainerType();\n    aggregator.startContainerLogAggregation(\n        new ContainerLogContext(containerId, containerType, exitCode));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle": "  public void handle(LogHandlerEvent event) {\n    switch (event.getType()) {\n      case APPLICATION_STARTED:\n        LogHandlerAppStartedEvent appStartEvent =\n            (LogHandlerAppStartedEvent) event;\n        initApp(appStartEvent.getApplicationId(), appStartEvent.getUser(),\n            appStartEvent.getCredentials(),\n            appStartEvent.getApplicationAcls(),\n            appStartEvent.getLogAggregationContext());\n        break;\n      case CONTAINER_FINISHED:\n        LogHandlerContainerFinishedEvent containerFinishEvent =\n            (LogHandlerContainerFinishedEvent) event;\n        stopContainer(containerFinishEvent.getContainerId(),\n            containerFinishEvent.getExitCode());\n        break;\n      case APPLICATION_FINISHED:\n        LogHandlerAppFinishedEvent appFinishedEvent =\n            (LogHandlerAppFinishedEvent) event;\n        stopApp(appFinishedEvent.getApplicationId());\n        break;\n      default:\n        ; // Ignore\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.stopApp": "  private void stopApp(ApplicationId appId) {\n\n    // App is complete. Finish up any containers' pending log aggregation and\n    // close the application specific logFile.\n\n    AppLogAggregator aggregator = this.appLogAggregators.get(appId);\n    if (aggregator == null) {\n      LOG.warn(\"Log aggregation is not initialized for \" + appId\n          + \", did it fail to start?\");\n      return;\n    }\n    aggregator.finishLogAggregation();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initApp": "  private void initApp(final ApplicationId appId, String user,\n      Credentials credentials, Map<ApplicationAccessType, String> appAcls,\n      LogAggregationContext logAggregationContext) {\n    ApplicationEvent eventResponse;\n    try {\n      verifyAndCreateRemoteLogDir(getConfig());\n      initAppAggregator(appId, user, credentials, appAcls,\n          logAggregationContext);\n      eventResponse = new ApplicationEvent(appId,\n          ApplicationEventType.APPLICATION_LOG_HANDLING_INITED);\n    } catch (YarnRuntimeException e) {\n      LOG.warn(\"Application failed to init aggregation\", e);\n      eventResponse = new ApplicationEvent(appId,\n          ApplicationEventType.APPLICATION_LOG_HANDLING_FAILED);\n    }\n    this.dispatcher.getEventHandler().handle(eventResponse);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregator.startContainerLogAggregation": "  void startContainerLogAggregation(ContainerLogContext logContext);\n\n  void abortLogAggregation();\n\n  void finishLogAggregation();\n\n  void disableLogAggregation();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "NM crash with NPE when LogAggregationService#stopContainer called for absent container",
            "Description": "NM crash during of log aggregation.\nRan Pi job with 500 container and killed application in between\n\n*Logs*\n{code}\n2015-09-12 18:44:25,597 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_e51_1442063466801_0001_01_000099 is : 143\n2015-09-12 18:44:25,670 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: KILL_CONTAINER sent to absent container container_e51_1442063466801_0001_01_000101\n2015-09-12 18:44:25,670 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_e51_1442063466801_0001_01_000101 from application application_1442063466801_0001\n2015-09-12 18:44:25,670 FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.stopContainer(LogAggregationService.java:422)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:456)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:68)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)\n        at java.lang.Thread.run(Thread.java:745)\n2015-09-12 18:44:25,692 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1442063466801_0001\n2015-09-12 18:44:25,692 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..\n2015-09-12 18:44:25,692 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=dsperf       OPERATION=Container Finished - Succeeded        TARGET=ContainerImpl    RESULT=SUCCESS  APPID=application_1442063466801_0001    CONTAINERID=container_e51_1442063466801_0001_01_000100\n\n{code}\n\n*Analysis*\n\nLooks like for absent container also {{stopContainer}} is called \n{code}\n      case CONTAINER_FINISHED:\n        LogHandlerContainerFinishedEvent containerFinishEvent =\n            (LogHandlerContainerFinishedEvent) event;\n        stopContainer(containerFinishEvent.getContainerId(),\n            containerFinishEvent.getExitCode());\n        break;\n{code}\n\n*Event EventType: KILL_CONTAINER sent to absent container container_e51_1442063466801_0001_01_000101*\n\nShould skip when {{null==context.getContainers().get(containerId)}} "
        }
    },
    {
        "filename": "YARN-3697.json",
        "creation_time": "2015-05-21T18:05:38.000+0000",
        "stack_trace": "```\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:467)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:462)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:387)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:58)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate(FSAppAttempt.java:357)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:516)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:649)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:803)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:334)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1082)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:1014)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:285)\n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.InterruptedException\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:249)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:467)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:462)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:387)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:58)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate(FSAppAttempt.java:357)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:516)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:649)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:803)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:334)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1082)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:1014)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:285)\n\nCaused by: java.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.transition": "    public void transition(RMContainerImpl container, RMContainerEvent event) {\n\n      // Unregister from containerAllocationExpirer.\n      container.containerAllocationExpirer.unregister(container\n          .getContainerId());\n\n      // Inform node\n      container.eventHandler.handle(new RMNodeCleanContainerEvent(\n          container.nodeId, container.containerId));\n\n      // Inform appAttempt\n      super.transition(container, event);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getContainerId": "  public ContainerId getContainerId() {\n    return this.containerId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.updateAttemptMetrics": "    private static void updateAttemptMetrics(RMContainerImpl container) {\n      // If this is a preempted container, update preemption metrics\n      Resource resource = container.getContainer().getResource();\n      RMAppAttempt rmAttempt = container.rmContext.getRMApps()\n          .get(container.getApplicationAttemptId().getApplicationId())\n          .getCurrentAppAttempt();\n      if (ContainerExitStatus.PREEMPTED == container.finishedStatus\n        .getExitStatus()) {\n        rmAttempt.getRMAppAttemptMetrics().updatePreemptionInfo(resource,\n          container);\n      }\n\n      if (rmAttempt != null) {\n        long usedMillis = container.finishTime - container.creationTime;\n        long memorySeconds = resource.getMemory()\n                              * usedMillis / DateUtils.MILLIS_PER_SECOND;\n        long vcoreSeconds = resource.getVirtualCores()\n                             * usedMillis / DateUtils.MILLIS_PER_SECOND;\n        rmAttempt.getRMAppAttemptMetrics()\n                  .updateAggregateAppResourceUsage(memorySeconds,vcoreSeconds);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getReservedNode": "  public NodeId getReservedNode() {\n    return reservedNode;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.setResourceRequests": "  public void setResourceRequests(List<ResourceRequest> requests) {\n    try {\n      writeLock.lock();\n      this.resourceRequests = requests;\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getReservedPriority": "  public Priority getReservedPriority() {\n    return reservedPriority;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getContainerState": "  public ContainerState getContainerState() {\n    try {\n      readLock.lock();\n      if (getFinishedStatus() != null) {\n        return getFinishedStatus().getState();\n      } else {\n        return ContainerState.RUNNING;\n      }\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getApplicationAttemptId": "  public ApplicationAttemptId getApplicationAttemptId() {\n    return this.appAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getContainerExitStatus": "  public int getContainerExitStatus() {\n    try {\n      readLock.lock();\n      if (getFinishedStatus() != null) {\n        return getFinishedStatus().getExitStatus();\n      } else {\n        return 0;\n      }\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getAllocatedNode": "  public NodeId getAllocatedNode() {\n    return container.getNodeId();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getReservedResource": "  public Resource getReservedResource() {\n    return reservedResource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.equals": "  public boolean equals(Object obj) {\n    if (obj instanceof RMContainer) {\n      if (null != getContainerId()) {\n        return getContainerId().equals(((RMContainer) obj).getContainerId());\n      }\n    }\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle": "  public void handle(RMContainerEvent event) {\n    LOG.debug(\"Processing \" + event.getContainerId() + \" of type \" + event.getType());\n    try {\n      writeLock.lock();\n      RMContainerState oldState = getState();\n      try {\n         stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        LOG.error(\"Invalid event \" + event.getType() + \n            \" on container \" + this.containerId);\n      }\n      if (oldState != getState()) {\n        LOG.info(event.getContainerId() + \" Container Transitioned from \"\n            + oldState + \" to \" + getState());\n      }\n    }\n    \n    finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.getState": "  public RMContainerState getState() {\n    this.readLock.lock();\n\n    try {\n      return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate": "  synchronized public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      Priority priority, ResourceRequest request,\n      Container container) {\n    // Update allowed locality level\n    NodeType allowed = allowedLocalityLevel.get(priority);\n    if (allowed != null) {\n      if (allowed.equals(NodeType.OFF_SWITCH) &&\n          (type.equals(NodeType.NODE_LOCAL) ||\n              type.equals(NodeType.RACK_LOCAL))) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL) &&\n          type.equals(NodeType.NODE_LOCAL)) {\n        this.resetAllowedLocalityLevel(priority, type);\n      }\n    }\n\n    // Required sanity check - AM can call 'allocate' to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) <= 0) {\n      return null;\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer = new RMContainerImpl(container, \n        getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), rmContext);\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List<ResourceRequest> resourceRequestList = appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    this.attemptResourceUsage.incUsed(container.getResource());\n\n    // Update resource requests related to \"request\" and store in RMContainer\n    ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId=\" \n          + container.getId().getApplicationAttemptId() \n          + \" container=\" + container.getId() + \" host=\"\n          + container.getNodeId().getHost() + \" type=\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId());\n    \n    return rmContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.resetAllowedLocalityLevel": "  public synchronized void resetAllowedLocalityLevel(Priority priority,\n      NodeType level) {\n    NodeType old = allowedLocalityLevel.get(priority);\n    LOG.info(\"Raising locality level from \" + old + \" to \" + level + \" at \" +\n        \" priority \" + priority);\n    allowedLocalityLevel.put(priority, level);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    return assignContainer(node, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getAllowedLocalityLevelByTime": "  public synchronized NodeType getAllowedLocalityLevelByTime(Priority priority,\n          long nodeLocalityDelayMs, long rackLocalityDelayMs,\n          long currentTimeMs) {\n\n    // if not being used, can schedule anywhere\n    if (nodeLocalityDelayMs < 0 || rackLocalityDelayMs < 0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    // default level is NODE_LOCAL\n    if (! allowedLocalityLevel.containsKey(priority)) {\n      allowedLocalityLevel.put(priority, NodeType.NODE_LOCAL);\n      return NodeType.NODE_LOCAL;\n    }\n\n    NodeType allowed = allowedLocalityLevel.get(priority);\n\n    // if level is already most liberal, we're done\n    if (allowed.equals(NodeType.OFF_SWITCH)) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    // check waiting time\n    long waitTime = currentTimeMs;\n    if (lastScheduledContainer.containsKey(priority)) {\n      waitTime -= lastScheduledContainer.get(priority);\n    } else {\n      waitTime -= getStartTime();\n    }\n\n    long thresholdTime = allowed.equals(NodeType.NODE_LOCAL) ?\n            nodeLocalityDelayMs : rackLocalityDelayMs;\n\n    if (waitTime > thresholdTime) {\n      if (allowed.equals(NodeType.NODE_LOCAL)) {\n        allowedLocalityLevel.put(priority, NodeType.RACK_LOCAL);\n        resetSchedulingOpportunities(priority, currentTimeMs);\n      } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n        allowedLocalityLevel.put(priority, NodeType.OFF_SWITCH);\n        resetSchedulingOpportunities(priority, currentTimeMs);\n      }\n    }\n    return allowedLocalityLevel.get(priority);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getPriority": "  public Priority getPriority() {\n    // Right now per-app priorities are not passed to scheduler,\n    // so everyone has the same priority.\n    return priority;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.createContainer": "  public Container createContainer(\n      FSSchedulerNode node, Resource capability, Priority priority) {\n\n    NodeId nodeId = node.getRMNode().getNodeID();\n    ContainerId containerId = BuilderUtils.newContainerId(\n        getApplicationAttemptId(), getNewContainerId());\n\n    // Create the container\n    Container container =\n        BuilderUtils.newContainer(containerId, nodeId, node.getRMNode()\n            .getHttpAddress(), capability, priority, null);\n\n    return container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.hasContainerForNode": "  public boolean hasContainerForNode(Priority prio, FSSchedulerNode node) {\n    ResourceRequest anyRequest = getResourceRequest(prio, ResourceRequest.ANY);\n    ResourceRequest rackRequest = getResourceRequest(prio, node.getRackName());\n    ResourceRequest nodeRequest = getResourceRequest(prio, node.getNodeName());\n\n    return\n        // There must be outstanding requests at the given priority:\n        anyRequest != null && anyRequest.getNumContainers() > 0 &&\n            // If locality relaxation is turned off at *-level, there must be a\n            // non-zero request for the node's rack:\n            (anyRequest.getRelaxLocality() ||\n                (rackRequest != null && rackRequest.getNumContainers() > 0)) &&\n            // If locality relaxation is turned off at rack-level, there must be a\n            // non-zero request at the node:\n            (rackRequest == null || rackRequest.getRelaxLocality() ||\n                (nodeRequest != null && nodeRequest.getNumContainers() > 0)) &&\n            // The requested container must be able to fit on the node:\n            Resources.lessThanOrEqual(RESOURCE_CALCULATOR, null,\n                anyRequest.getCapability(), node.getRMNode().getTotalCapability());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.reserve": "  private void reserve(Priority priority, FSSchedulerNode node,\n      Container container, boolean alreadyReserved) {\n    LOG.info(\"Making reservation: node=\" + node.getNodeName() +\n        \" app_id=\" + getApplicationId());\n\n    if (!alreadyReserved) {\n      getMetrics().reserveResource(getUser(), container.getResource());\n      RMContainer rmContainer =\n          super.reserve(node, priority, null, container);\n      node.reserveResource(this, priority, rmContainer);\n    } else {\n      RMContainer rmContainer = node.getReservedContainer();\n      super.reserve(node, priority, rmContainer, container);\n      node.reserveResource(this, priority, rmContainer);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getName": "  public String getName() {\n    return getApplicationId().toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserve": "  public void unreserve(Priority priority, FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    unreserveInternal(priority, node);\n    node.unreserveResource(this);\n    getMetrics().unreserveResource(\n        getUser(), rmContainer.getContainer().getResource());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getAllowedLocalityLevel": "  public synchronized NodeType getAllowedLocalityLevel(Priority priority,\n      int numNodes, double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold > 1.0) { nodeLocalityThreshold = 1.0; }\n    if (rackLocalityThreshold > 1.0) { rackLocalityThreshold = 1.0; }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold < 0.0 || rackLocalityThreshold < 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    // Default level is NODE_LOCAL\n    if (!allowedLocalityLevel.containsKey(priority)) {\n      allowedLocalityLevel.put(priority, NodeType.NODE_LOCAL);\n      return NodeType.NODE_LOCAL;\n    }\n\n    NodeType allowed = allowedLocalityLevel.get(priority);\n\n    // If level is already most liberal, we're done\n    if (allowed.equals(NodeType.OFF_SWITCH)) return NodeType.OFF_SWITCH;\n\n    double threshold = allowed.equals(NodeType.NODE_LOCAL) ? nodeLocalityThreshold :\n      rackLocalityThreshold;\n\n    // Relax locality constraints once we've surpassed threshold.\n    if (getSchedulingOpportunities(priority) > (numNodes * threshold)) {\n      if (allowed.equals(NodeType.NODE_LOCAL)) {\n        allowedLocalityLevel.put(priority, NodeType.RACK_LOCAL);\n        resetSchedulingOpportunities(priority);\n      }\n      else if (allowed.equals(NodeType.RACK_LOCAL)) {\n        allowedLocalityLevel.put(priority, NodeType.OFF_SWITCH);\n        resetSchedulingOpportunities(priority);\n      }\n    }\n    return allowedLocalityLevel.get(priority);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.hasNodeOrRackLocalRequests": "  private boolean hasNodeOrRackLocalRequests(Priority priority) {\n    return getResourceRequests(priority).size() > 1;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getQueue": "  public FSLeafQueue getQueue() {\n    return (FSLeafQueue)super.getQueue();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    Resource assigned = Resources.none();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Node \" + node.getNodeName() + \" offered to queue: \" +\n          getName() + \" fairShare: \" + getFairShare());\n    }\n\n    if (!assignContainerPreCheck(node)) {\n      return assigned;\n    }\n\n    Comparator<Schedulable> comparator = policy.getComparator();\n    writeLock.lock();\n    try {\n      Collections.sort(runnableApps, comparator);\n    } finally {\n      writeLock.unlock();\n    }\n    // Release write lock here for better performance and avoiding deadlocks.\n    // runnableApps can be in unsorted state because of this section,\n    // but we can accept it in practice since the probability is low.\n    readLock.lock();\n    try {\n      for (FSAppAttempt sched : runnableApps) {\n        if (SchedulerAppUtils.isBlacklisted(sched, node, LOG)) {\n          continue;\n        }\n\n        assigned = sched.assignContainer(node);\n        if (!assigned.equals(Resources.none())) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Assigned container in queue:\" + getName() + \" \" +\n                \"container:\" + assigned);\n          }\n          break;\n        }\n      }\n    } finally {\n      readLock.unlock();\n    }\n    return assigned;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    Resource assigned = Resources.none();\n\n    // If this queue is over its limit, reject\n    if (!assignContainerPreCheck(node)) {\n      return assigned;\n    }\n\n    Collections.sort(childQueues, policy.getComparator());\n    for (FSQueue child : childQueues) {\n      assigned = child.assignContainer(node);\n      if (!Resources.equals(assigned, Resources.none())) {\n        break;\n      }\n    }\n    return assigned;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling": "  private synchronized void attemptScheduling(FSSchedulerNode node) {\n    if (rmContext.isWorkPreservingRecoveryEnabled()\n        && !rmContext.isSchedulerReadyForAllocatingContainers()) {\n      return;\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    FSAppAttempt reservedAppSchedulable = node.getReservedAppSchedulable();\n    if (reservedAppSchedulable != null) {\n      Priority reservedPriority = node.getReservedContainer().getReservedPriority();\n      FSQueue queue = reservedAppSchedulable.getQueue();\n\n      if (!reservedAppSchedulable.hasContainerForNode(reservedPriority, node)\n          || !fitsInMaxShare(queue,\n          node.getReservedContainer().getReservedResource())) {\n        // Don't hold the reservation if app can no longer use it\n        LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n            + reservedAppSchedulable.getApplicationAttemptId()\n            + \" on node \" + node);\n        reservedAppSchedulable.unreserve(reservedPriority, node);\n        reservedAppSchedulable = null;\n      } else {\n        // Reservation exists; try to fulfill the reservation\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Trying to fulfill reservation for application \"\n              + reservedAppSchedulable.getApplicationAttemptId()\n              + \" on node: \" + node);\n        }\n        node.getReservedAppSchedulable().assignReservedContainer(node);\n      }\n    }\n    if (reservedAppSchedulable == null) {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers = 0;\n      while (node.getReservedContainer() == null) {\n        boolean assignedContainer = false;\n        if (!queueMgr.getRootQueue().assignContainer(node).equals(\n            Resources.none())) {\n          assignedContainers++;\n          assignedContainer = true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers >= maxAssign) && (maxAssign > 0)) { break; }\n      }\n    }\n    updateRootQueueMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateRootQueueMetrics": "  private void updateRootQueueMetrics() {\n    rootMetrics.setAvailableResourcesToQueue(\n        Resources.subtract(\n            clusterResource, rootMetrics.getAllocatedResources()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.fitsInMaxShare": "  static boolean fitsInMaxShare(FSQueue queue, Resource\n      additionalResource) {\n    Resource usagePlusAddition =\n        Resources.add(queue.getResourceUsage(), additionalResource);\n\n    if (!Resources.fitsIn(usagePlusAddition, queue.getMaxShare())) {\n      return false;\n    }\n    \n    FSQueue parentQueue = queue.getParent();\n    if (parentQueue != null) {\n      return fitsInMaxShare(parentQueue, additionalResource);\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt": "  void continuousSchedulingAttempt() throws InterruptedException {\n    long start = getClock().getTime();\n    List<NodeId> nodeIdList = new ArrayList<NodeId>(nodes.keySet());\n    // Sort the nodes by space available on them, so that we offer\n    // containers on emptier nodes first, facilitating an even spread. This\n    // requires holding the scheduler lock, so that the space available on a\n    // node doesn't change during the sort.\n    synchronized (this) {\n      Collections.sort(nodeIdList, nodeAvailableResourceComparator);\n    }\n\n    // iterate all nodes\n    for (NodeId nodeId : nodeIdList) {\n      FSSchedulerNode node = getFSSchedulerNode(nodeId);\n      try {\n        if (node != null && Resources.fitsIn(minimumAllocation,\n            node.getAvailableResource())) {\n          attemptScheduling(node);\n        }\n      } catch (Throwable ex) {\n        LOG.error(\"Error while attempting scheduling for node \" + node +\n            \": \" + ex.toString(), ex);\n      }\n    }\n\n    long duration = getClock().getTime() - start;\n    fsOpDurations.addContinuousSchedulingRunDuration(duration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getClock": "  public Clock getClock() {\n    return clock;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getFSSchedulerNode": "  private FSSchedulerNode getFSSchedulerNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.run": "    public void run() {\n      while (!Thread.currentThread().isInterrupted()) {\n        try {\n          continuousSchedulingAttempt();\n          Thread.sleep(getContinuousSchedulingSleepMs());\n        } catch (InterruptedException e) {\n          LOG.warn(\"Continuous scheduling thread interrupted. Exiting.\", e);\n          return;\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getContinuousSchedulingSleepMs": "  public synchronized int getContinuousSchedulingSleepMs() {\n    return continuousSchedulingSleepMs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update": "  protected synchronized void update() {\n    long start = getClock().getTime();\n    updateStarvationStats(); // Determine if any queues merit preemption\n\n    FSQueue rootQueue = queueMgr.getRootQueue();\n\n    // Recursively update demands for all queues\n    rootQueue.updateDemand();\n\n    rootQueue.setFairShare(clusterResource);\n    // Recursively compute fair shares for all queues\n    // and update metrics\n    rootQueue.recomputeShares();\n    updateRootQueueMetrics();\n\n    if (LOG.isDebugEnabled()) {\n      if (--updatesToSkipForDebug < 0) {\n        updatesToSkipForDebug = UPDATE_DEBUG_FREQUENCY;\n        LOG.debug(\"Cluster Capacity: \" + clusterResource +\n            \"  Allocations: \" + rootMetrics.getAllocatedResources() +\n            \"  Availability: \" + Resource.newInstance(\n            rootMetrics.getAvailableMB(),\n            rootMetrics.getAvailableVirtualCores()) +\n            \"  Demand: \" + rootQueue.getDemand());\n      }\n    }\n\n    long duration = getClock().getTime() - start;\n    fsOpDurations.addUpdateCallDuration(duration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.preemptTasksIfNecessary": "  protected synchronized void preemptTasksIfNecessary() {\n    if (!shouldAttemptPreemption()) {\n      return;\n    }\n\n    long curTime = getClock().getTime();\n    if (curTime - lastPreemptCheckTime < preemptionInterval) {\n      return;\n    }\n    lastPreemptCheckTime = curTime;\n\n    Resource resToPreempt = Resources.clone(Resources.none());\n    for (FSLeafQueue sched : queueMgr.getLeafQueues()) {\n      Resources.addTo(resToPreempt, resToPreempt(sched, curTime));\n    }\n    if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterResource, resToPreempt,\n        Resources.none())) {\n      preemptResources(resToPreempt);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerFinishedEvent.getRemoteContainerStatus": "  public ContainerStatus getRemoteContainerStatus() {\n    return this.remoteContainerStatus;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.getReservedAppSchedulable": "  public synchronized FSAppAttempt getReservedAppSchedulable() {\n    return reservedAppSchedulable;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.fsOpDurations.addContinuousSchedulingRunDuration": "  public void addContinuousSchedulingRunDuration(long value) {\n    continuousSchedulingRun.add(value);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.fsOpDurations.addUpdateThreadRunDuration": "  public void addUpdateThreadRunDuration(long value) {\n    updateThreadRun.add(value);\n  }"
        },
        "bug_report": {
            "Title": "FairScheduler: ContinuousSchedulingThread can fail to shutdown",
            "Description": "FairScheduler: ContinuousSchedulingThread can't be shutdown after stop sometimes. \nThe reason is because the InterruptedException is blocked in continuousSchedulingAttempt\n{code}\n      try {\n        if (node != null && Resources.fitsIn(minimumAllocation,\n            node.getAvailableResource())) {\n          attemptScheduling(node);\n        }\n      } catch (Throwable ex) {\n        LOG.error(\"Error while attempting scheduling for node \" + node +\n            \": \" + ex.toString(), ex);\n      }\n{code}\n\nI saw the following exception after stop:\n{code}\n2015-05-17 23:30:43,065 WARN  [FairSchedulerContinuousScheduling] event.AsyncDispatcher (AsyncDispatcher.java:handle(247)) - AsyncDispatcher thread interrupted\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:467)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:462)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:387)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:58)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate(FSAppAttempt.java:357)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:516)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:649)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:803)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:334)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1082)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:1014)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:285)\n2015-05-17 23:30:43,066 ERROR [FairSchedulerContinuousScheduling] fair.FairScheduler (FairScheduler.java:continuousSchedulingAttempt(1017)) - Error while attempting scheduling for node host: 127.0.0.2:2 #containers=1 available=<memory:7168, vCores:7> used=<memory:1024, vCores:1>: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.InterruptedException\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.InterruptedException\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:249)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:467)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:462)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:387)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:58)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate(FSAppAttempt.java:357)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:516)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:649)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:803)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:334)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1082)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:1014)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:285)\nCaused by: java.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\t... 17 more\n{code}\n"
        }
    },
    {
        "filename": "YARN-2340.json",
        "creation_time": "2014-07-23T15:18:38.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:568)\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:916)\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:101)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:602)\n at java.lang.Thread.run(Thread.java:662)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    CSQueue queue = (CSQueue) application.getQueue();\n\n    FiCaSchedulerApp attempt =\n        new FiCaSchedulerApp(applicationAttemptId, application.getUser(),\n          queue, queue.getActiveUsersManager(), rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n        .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    queue.submitApplicationAttempt(attempt, application.getUser());\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user \" + application.getUser() + \" in queue \"\n        + queue.getQueueName());\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  synchronized CSQueue getQueue(String queueName) {\n    return queues.get(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      RMNode node = nodeUpdatedEvent.getRMNode();\n      nodeUpdate(node);\n      if (!scheduleAsynchronously) {\n        allocateContainersToNode(getNode(node.getNodeID()));\n      }\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      addApplication(appAddedEvent.getApplicationId(),\n        appAddedEvent.getQueue(), appAddedEvent.getUser(),\n        appAddedEvent.getIsAppRecovering());\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent = \n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId), \n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId, \n              SchedulerUtils.EXPIRED_CONTAINER), \n          RMContainerEventType.EXPIRE);\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        startActiveServices();\n        return null;\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n  \n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Get the current used capacity of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n  \n  /**\n   * Set used capacity of the queue.\n   * @param usedCapacity used capacity of the queue\n   */\n  public void setUsedCapacity(float usedCapacity);\n  \n  /**\n   * Set absolute used capacity of the queue.\n   * @param absUsedCapacity absolute used capacity of the queue\n   */\n  public void setAbsoluteUsedCapacity(float absUsedCapacity);\n\n  /**\n   * Get the currently utilized resources in the cluster \n   * by the queue and children (if any).\n   * @return used resources by the queue and it's children \n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getActiveUsersManager": "  public ActiveUsersManager getActiveUsersManager();\n  \n  /**\n   * Adds all applications in the queue and its subqueues to the given collection.\n   * @param apps the collection to add the applications to\n   */\n  public void collectSchedulerApplications(Collection<ApplicationAttemptId> apps);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.submitApplicationAttempt": "  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue."
        },
        "bug_report": {
            "Title": "NPE thrown when RM restart after queue is STOPPED. There after RM can not recovery application's and remain in standby",
            "Description": "While job is in progress make Queue  state as STOPPED and then restart RM \n\nObserve that standby RM fails to come up as acive throwing below NPE\n\n2014-07-23 18:43:24,432 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1406116264351_0014_000002 State change from NEW to SUBMITTED\n2014-07-23 18:43:24,433 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type APP_ATTEMPT_ADDED to the scheduler\njava.lang.NullPointerException\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:568)\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:916)\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:101)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:602)\n at java.lang.Thread.run(Thread.java:662)\n2014-07-23 18:43:24,434 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Exiting, bbye..\n\n"
        }
    },
    {
        "filename": "YARN-8022.json",
        "creation_time": "2018-03-10T19:29:27.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n at org.apache.hadoop.yarn.server.webapp.AppBlock$3.run(AppBlock.java:283)\n at org.apache.hadoop.yarn.server.webapp.AppBlock$3.run(AppBlock.java:280)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)\n at org.apache.hadoop.yarn.server.webapp.AppBlock.render(AppBlock.java:279)\n at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppBlock.render(RMAppBlock.java:71)\n at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n at org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl$EImp._v(HamletImpl.java:117)\n at org.apache.hadoop.yarn.webapp.hamlet2.Hamlet$TD.__(Hamlet.java:848)\n at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)\n at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:212)\n at org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app(RmController.java:54)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.run": "            public ContainerReport run() throws Exception {\n              ContainerReport report = null;\n              if (request.getContainerId() != null) {\n                  try {\n                    report = getContainerReport(request);\n                  } catch (ContainerNotFoundException ex) {\n                    LOG.warn(ex.getMessage());\n                  }\n              }\n              return report;\n            }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.getApplicationAttemptsReport": "  protected List<ApplicationAttemptReport> getApplicationAttemptsReport(\n      final GetApplicationAttemptsRequest request)\n      throws YarnException, IOException {\n    return appBaseProt.getApplicationAttempts(request)\n        .getApplicationAttemptList();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.getApplicationReport": "  protected ApplicationReport getApplicationReport(\n      final GetApplicationReportRequest request)\n      throws YarnException, IOException {\n    return appBaseProt.getApplicationReport(request).getApplicationReport();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.getContainerReport": "  protected ContainerReport getContainerReport(\n      final GetContainerReportRequest request)\n      throws YarnException, IOException {\n    return appBaseProt.getContainerReport(request).getContainerReport();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.render": "  protected void render(Block html) {\n    String webUiType = $(WEB_UI_TYPE);\n    String aid = $(APPLICATION_ID);\n    if (aid.isEmpty()) {\n      puts(\"Bad request: requires Application ID\");\n      return;\n    }\n\n    try {\n      appID = Apps.toAppID(aid);\n    } catch (Exception e) {\n      puts(\"Invalid Application ID: \" + aid);\n      return;\n    }\n\n    UserGroupInformation callerUGI = getCallerUGI();\n    ApplicationReport appReport;\n    try {\n      final GetApplicationReportRequest request =\n          GetApplicationReportRequest.newInstance(appID);\n      if (callerUGI == null) {\n        appReport =\n            appBaseProt.getApplicationReport(request).getApplicationReport();\n      } else {\n        appReport = callerUGI.doAs(\n            new PrivilegedExceptionAction<ApplicationReport> () {\n          @Override\n          public ApplicationReport run() throws Exception {\n            return getApplicationReport(request);\n          }\n        });\n      }\n    } catch (Exception e) {\n      String message = \"Failed to read the application \" + appID + \".\";\n      LOG.error(message, e);\n      html.p().__(message).__();\n      return;\n    }\n\n    if (appReport == null) {\n      puts(\"Application not found: \" + aid);\n      return;\n    }\n\n    AppInfo app = new AppInfo(appReport);\n\n    setTitle(join(\"Application \", aid));\n\n    //Validate if able to read application attempts\n    // which should also validate if kill is allowed for the user based on ACLs\n\n    Collection<ApplicationAttemptReport> attempts;\n    try {\n      final GetApplicationAttemptsRequest request =\n          GetApplicationAttemptsRequest.newInstance(appID);\n      attempts = callerUGI.doAs(\n          new PrivilegedExceptionAction<Collection<\n              ApplicationAttemptReport>>() {\n            @Override\n            public Collection<ApplicationAttemptReport> run() throws Exception {\n              return getApplicationAttemptsReport(request);\n            }\n          });\n    } catch (Exception e) {\n      String message =\n          \"Failed to read the attempts of the application \" + appID + \".\";\n      LOG.error(message, e);\n      html.p().__(message).__();\n      return;\n    }\n\n\n    // YARN-6890. for secured cluster allow anonymous UI access, application kill\n    // shouldn't be there.\n    boolean unsecuredUIForSecuredCluster = UserGroupInformation.isSecurityEnabled()\n        && this.unsecuredUI;\n\n    if (webUiType != null\n        && webUiType.equals(YarnWebParams.RM_WEB_UI)\n        && conf.getBoolean(YarnConfiguration.RM_WEBAPP_UI_ACTIONS_ENABLED,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_UI_ACTIONS_ENABLED)\n            && !unsecuredUIForSecuredCluster\n            && !isAppInFinalState(app)) {\n      // Application Kill\n      html.div()\n        .button()\n          .$onclick(\"confirmAction()\").b(\"Kill Application\").__()\n          .__();\n\n      StringBuilder script = new StringBuilder();\n      script.append(\"function confirmAction() {\")\n          .append(\" b = confirm(\\\"Are you sure?\\\");\")\n          .append(\" if (b == true) {\")\n          .append(\" $.ajax({\")\n          .append(\" type: 'PUT',\")\n          .append(\" url: '/ws/v1/cluster/apps/\").append(aid).append(\"/state',\")\n          .append(\" contentType: 'application/json',\")\n          .append(getCSRFHeaderString(conf))\n          .append(\" data: '{\\\"state\\\":\\\"KILLED\\\"}',\")\n          .append(\" dataType: 'json'\")\n          .append(\" }).done(function(data){\")\n          .append(\" setTimeout(function(){\")\n          .append(\" location.href = '/cluster/app/\").append(aid).append(\"';\")\n          .append(\" }, 1000);\")\n          .append(\" }).fail(function(data){\")\n          .append(\" console.log(data);\")\n          .append(\" });\")\n          .append(\" }\")\n          .append(\"}\");\n\n      html.script().$type(\"text/javascript\").__(script.toString()).__();\n    }\n\n    String schedulerPath = WebAppUtils.getResolvedRMWebAppURLWithScheme(conf) +\n        \"/cluster/scheduler?openQueues=\" + app.getQueue();\n\n    ResponseInfo overviewTable = info(\"Application Overview\")\n      .__(\"User:\", schedulerPath, app.getUser())\n      .__(\"Name:\", app.getName())\n      .__(\"Application Type:\", app.getType())\n      .__(\"Application Tags:\",\n        app.getApplicationTags() == null ? \"\" : app.getApplicationTags())\n      .__(\"Application Priority:\", clarifyAppPriority(app.getPriority()))\n      .__(\n        \"YarnApplicationState:\",\n        app.getAppState() == null ? UNAVAILABLE : clarifyAppState(app\n          .getAppState()))\n      .__(\"Queue:\", schedulerPath, app.getQueue())\n      .__(\"FinalStatus Reported by AM:\",\n        clairfyAppFinalStatus(app.getFinalAppStatus()))\n      .__(\"Started:\", Times.format(app.getStartedTime()))\n      .__(\n        \"Elapsed:\",\n        StringUtils.formatTime(Times.elapsed(app.getStartedTime(),\n          app.getFinishedTime())))\n      .__(\n        \"Tracking URL:\",\n        app.getTrackingUrl() == null\n            || app.getTrackingUrl().equals(UNAVAILABLE) ? null : root_url(app\n          .getTrackingUrl()),\n        app.getTrackingUrl() == null\n            || app.getTrackingUrl().equals(UNAVAILABLE) ? \"Unassigned\" : app\n          .getAppState() == YarnApplicationState.FINISHED\n            || app.getAppState() == YarnApplicationState.FAILED\n            || app.getAppState() == YarnApplicationState.KILLED ? \"History\"\n            : \"ApplicationMaster\");\n    if (webUiType != null\n        && webUiType.equals(YarnWebParams.RM_WEB_UI)) {\n      LogAggregationStatus status = getLogAggregationStatus();\n      if (status == null) {\n        overviewTable.__(\"Log Aggregation Status:\", \"N/A\");\n      } else if (status == LogAggregationStatus.DISABLED\n          || status == LogAggregationStatus.NOT_START\n          || status == LogAggregationStatus.SUCCEEDED) {\n        overviewTable.__(\"Log Aggregation Status:\", status.name());\n      } else {\n        overviewTable.__(\"Log Aggregation Status:\",\n            root_url(\"logaggregationstatus\", app.getAppId()), status.name());\n      }\n      long timeout = appReport.getApplicationTimeouts()\n          .get(ApplicationTimeoutType.LIFETIME).getRemainingTime();\n      if (timeout < 0) {\n        overviewTable.__(\"Application Timeout (Remaining Time):\", \"Unlimited\");\n      } else {\n        overviewTable.__(\"Application Timeout (Remaining Time):\",\n            String.format(\"%d seconds\", timeout));\n      }\n    }\n    overviewTable.__(\"Diagnostics:\",\n        app.getDiagnosticsInfo() == null ? \"\" : app.getDiagnosticsInfo());\n    overviewTable.__(\"Unmanaged Application:\", app.isUnmanagedApp());\n    overviewTable.__(\"Application Node Label expression:\",\n        app.getAppNodeLabelExpression() == null ? \"<Not set>\"\n            : app.getAppNodeLabelExpression());\n    overviewTable.__(\"AM container Node Label expression:\",\n        app.getAmNodeLabelExpression() == null ? \"<Not set>\"\n            : app.getAmNodeLabelExpression());\n\n    try {\n      final GetApplicationAttemptsRequest request =\n          GetApplicationAttemptsRequest.newInstance(appID);\n      if (callerUGI == null) {\n        attempts = appBaseProt.getApplicationAttempts(request)\n            .getApplicationAttemptList();\n      } else {\n        attempts = callerUGI.doAs(\n            new PrivilegedExceptionAction<Collection<ApplicationAttemptReport>> () {\n          @Override\n          public Collection<ApplicationAttemptReport> run() throws Exception {\n            return appBaseProt.getApplicationAttempts(request)\n                .getApplicationAttemptList();\n          }\n        });\n      }\n    } catch (Exception e) {\n      String message =\n          \"Failed to read the attempts of the application \" + appID + \".\";\n      LOG.error(message, e);\n      html.p().__(message).__();\n      return;\n    }\n\n    createApplicationMetricsTable(html);\n\n    html.__(InfoBlock.class);\n\n    generateApplicationTable(html, callerUGI, attempts);\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.isAppInFinalState": "  private boolean isAppInFinalState(AppInfo app) {\n    return app.getAppState() == YarnApplicationState.FINISHED\n        || app.getAppState() == YarnApplicationState.FAILED\n        || app.getAppState() == YarnApplicationState.KILLED;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.clarifyAppPriority": "  private String clarifyAppPriority(int priority) {\n    return priority + \" (Higher Integer value indicates higher priority)\";\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.createApplicationMetricsTable": "  protected void createApplicationMetricsTable(Block html) {\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.generateApplicationTable": "  protected void generateApplicationTable(Block html,\n      UserGroupInformation callerUGI,\n      Collection<ApplicationAttemptReport> attempts) {\n    // Application Attempt Table\n    TBODY<TABLE<Hamlet>> tbody =\n        html.table(\"#attempts\").thead().tr().th(\".id\", \"Attempt ID\")\n          .th(\".started\", \"Started\").th(\".node\", \"Node\").th(\".logs\", \"Logs\")\n          .__().__().tbody();\n\n    StringBuilder attemptsTableData = new StringBuilder(\"[\\n\");\n    for (final ApplicationAttemptReport appAttemptReport : attempts) {\n      AppAttemptInfo appAttempt = new AppAttemptInfo(appAttemptReport);\n      ContainerReport containerReport;\n      try {\n        final GetContainerReportRequest request =\n                GetContainerReportRequest.newInstance(\n                      appAttemptReport.getAMContainerId());\n        if (callerUGI == null) {\n          containerReport =\n              getContainerReport(request);\n        } else {\n          containerReport = callerUGI.doAs(\n              new PrivilegedExceptionAction<ContainerReport>() {\n            @Override\n            public ContainerReport run() throws Exception {\n              ContainerReport report = null;\n              if (request.getContainerId() != null) {\n                  try {\n                    report = getContainerReport(request);\n                  } catch (ContainerNotFoundException ex) {\n                    LOG.warn(ex.getMessage());\n                  }\n              }\n              return report;\n            }\n          });\n        }\n      } catch (Exception e) {\n        String message =\n            \"Failed to read the AM container of the application attempt \"\n                + appAttemptReport.getApplicationAttemptId() + \".\";\n        LOG.error(message, e);\n        html.p().__(message).__();\n        return;\n      }\n      long startTime = 0L;\n      String logsLink = null;\n      String nodeLink = null;\n      if (containerReport != null) {\n        ContainerInfo container = new ContainerInfo(containerReport);\n        startTime = container.getStartedTime();\n        logsLink = containerReport.getLogUrl();\n        nodeLink = containerReport.getNodeHttpAddress();\n      }\n      attemptsTableData\n        .append(\"[\\\"<a href='\")\n        .append(url(\"appattempt\", appAttempt.getAppAttemptId()))\n        .append(\"'>\")\n        .append(appAttempt.getAppAttemptId())\n        .append(\"</a>\\\",\\\"\")\n        .append(startTime)\n        .append(\"\\\",\\\"<a \")\n        .append(nodeLink == null ? \"#\" : \"href='\" + nodeLink)\n        .append(\"'>\")\n        .append(nodeLink == null ? \"N/A\" : StringEscapeUtils\n            .escapeJavaScript(StringEscapeUtils.escapeHtml(nodeLink)))\n        .append(\"</a>\\\",\\\"<a \")\n        .append(logsLink == null ? \"#\" : \"href='\" + logsLink).append(\"'>\")\n        .append(logsLink == null ? \"N/A\" : \"Logs\").append(\"</a>\\\"],\\n\");\n    }\n    if (attemptsTableData.charAt(attemptsTableData.length() - 2) == ',') {\n      attemptsTableData.delete(attemptsTableData.length() - 2,\n        attemptsTableData.length() - 1);\n    }\n    attemptsTableData.append(\"]\");\n    html.script().$type(\"text/javascript\")\n      .__(\"var attemptsTableData=\" + attemptsTableData).__();\n\n    tbody.__().__();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.getCSRFHeaderString": "  public static String getCSRFHeaderString(Configuration conf) {\n    String ret = \"\";\n    if (conf.getBoolean(YarnConfiguration.RM_CSRF_ENABLED, false)) {\n      ret = \" headers : { '\";\n      Map<String, String> filterParams = RestCsrfPreventionFilter\n          .getFilterParams(conf, YarnConfiguration.RM_CSRF_PREFIX);\n      if (filterParams\n          .containsKey(RestCsrfPreventionFilter.CUSTOM_HEADER_PARAM)) {\n        ret += filterParams.get(RestCsrfPreventionFilter.CUSTOM_HEADER_PARAM);\n      } else {\n        ret += RestCsrfPreventionFilter.HEADER_DEFAULT;\n      }\n      ret += \"' : 'null' },\";\n    }\n    return ret;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.clairfyAppFinalStatus": "  private String clairfyAppFinalStatus(FinalApplicationStatus status) {\n    if (status == FinalApplicationStatus.UNDEFINED) {\n      return \"Application has not completed yet.\";\n    }\n    return status.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.getLogAggregationStatus": "  protected LogAggregationStatus getLogAggregationStatus() {\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.webapp.AppBlock.clarifyAppState": "  private String clarifyAppState(YarnApplicationState state) {\n    String ret = state.toString();\n    switch (state) {\n    case NEW:\n      return ret + \": waiting for application to be initialized\";\n    case NEW_SAVING:\n      return ret + \": waiting for application to be persisted in state-store.\";\n    case SUBMITTED:\n      return ret + \": waiting for application to be accepted by scheduler.\";\n    case ACCEPTED:\n      return ret + \": waiting for AM container to be allocated, launched and\"\n          + \" register with RM.\";\n    case RUNNING:\n      return ret + \": AM has registered with RM and started running.\";\n    default:\n      return ret;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppBlock.render": "  protected void render(Block html) {\n    super.render(html);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.render": "  protected abstract void render(Block html);\n\n  protected UserGroupInformation getCallerUGI() {\n    // Check for the authorization.\n    String remoteUser = request().getRemoteUser();\n    UserGroupInformation callerUGI = null;\n    if (remoteUser != null) {\n      callerUGI = UserGroupInformation.createRemoteUser(remoteUser);\n    }\n    return callerUGI;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.block": "  private Block block() {\n    if (block == null) {\n      block = new Block(writer(), context().nestLevel(), context().wasInline());\n    }\n    return block;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial": "  public void renderPartial() {\n    render();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.render": "  public void render(Class<? extends SubView> cls) {\n    int saved = context().nestLevel;\n    getInstance(cls).renderPartial();\n    if (context().nestLevel != saved) {\n      throw new WebAppException(\"View \"+ cls.getSimpleName() +\" not complete\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.context": "  public ViewContext context() {\n    if (vc == null) {\n      if (injector == null) {\n        // One downside of making the injection in subclasses optional\n        throw new WebAppException(join(\"Error accessing ViewContext from a\\n\",\n            \"child constructor, either move the usage of the View methods\\n\",\n            \"out of the constructor or inject the ViewContext into the\\n\",\n            \"constructor\"));\n      }\n      vc = injector.getInstance(ViewContext.class);\n    }\n    return vc;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.View.getInstance": "  public <T> T getInstance(Class<T> cls) {\n    return injector().getInstance(cls);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlPage.subView": "    protected void subView(Class<? extends SubView> cls) {\n      context().set(nestLevel(), wasInline());\n      render(cls);\n      setWasInline(context().wasInline());\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlPage.render": "  protected abstract void render(Page.HTML<__> html);\n}\n",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl._v": "    protected void _v(Class<? extends SubView> cls) {\n      closeAttrs();\n      subView(cls);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl.subView": "  protected void subView(Class<? extends SubView> cls) {\n    indent(of(ENDTAG)); // not an inline view\n    sb.setLength(0);\n    out.print(sb.append('[').append(cls.getName()).append(']').toString());\n    out.println();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl.closeAttrs": "    protected void closeAttrs() {\n      if (!attrsClosed) {\n        startIfNeeded();\n        ++nestLevel;\n        out.print('>');\n        if (!opts.contains(INLINE) && !opts.contains(PRE)) {\n          out.println();\n        }\n        attrsClosed = true;\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.__": "  public Hamlet __(Class<? extends SubView> cls) {\n    subView(cls);\n    return this;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render": "  @Override protected void render(Page.HTML<__> html) {\n    preHead(html);\n    html.\n      title($(TITLE)).\n      link(root_url(\"static\", \"yarn.css\")).\n      style(\"#layout { height: 100%; }\",\n            \"#layout thead td { height: 3em; }\",\n            \"#layout #navcell { width: 11em; padding: 0 1em; }\",\n            \"#layout td.content { padding-top: 0 }\",\n            \"#layout tbody { vertical-align: top; }\",\n            \"#layout tfoot td { height: 4em; }\").\n        __(JQueryUI.class);\n    postHead(html);\n    JQueryUI.jsnotice(html);\n    html.\n      table(\"#layout.ui-widget-content\").\n        thead().\n          tr().\n            td().$colspan(2).\n        __(header()).__().__().__().\n        tfoot().\n          tr().\n            td().$colspan(2).\n        __(footer()).__().__().__().\n        tbody().\n          tr().\n            td().$id(\"navcell\").\n        __(nav()).__().\n            td().$class(\"content\").\n        __(content()).__().__().__().__().__();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.content": "  protected Class<? extends SubView> content() {\n    return LipsumBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.postHead": "  protected void postHead(Page.HTML<__> html) {\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.nav": "  protected Class<? extends SubView> nav() {\n    return NavBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.header": "  protected Class<? extends SubView> header() {\n    return HeaderBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.preHead": "  protected void preHead(Page.HTML<__> html) {\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.footer": "  protected Class<? extends SubView> footer() {\n    return FooterBlock.class;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.render": "  protected void render(Class<? extends View> cls) {\n    context().rendered = true;\n    getInstance(cls).render();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.context": "  public RequestContext context() {\n    if (context == null) {\n      if (injector == null) {\n        // One of the downsides of making injection in subclasses optional.\n        throw new WebAppException(join(\"Error accessing RequestContext from\\n\",\n            \"a child constructor, either move the usage of the Controller\\n\",\n            \"methods out of the constructor or inject the RequestContext\\n\",\n            \"into the constructor\"));\n      }\n      context = injector.getInstance(RequestContext.class);\n    }\n    return context;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.Controller.getInstance": "  public <T> T getInstance(Class<T> cls) {\n    return injector.getInstance(cls);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app": "  public void app() {\n    render(AppPage.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.JQueryUI.jsnotice": "  public static void jsnotice(HTML html) {\n    html.\n      div(\"#jsnotice.ui-state-error\").\n        __(\"This page will not function without javascript enabled.\"\n            + \" Please enable javascript on your browser.\").__();\n    html.\n      script().$type(\"text/javascript\").\n        __(\"$('#jsnotice').hide();\").__();\n  }"
        },
        "bug_report": {
            "Title": "ResourceManager UI cluster/app/<app-id> page fails to render",
            "Description": "The page displays the message \"Failed to read the attempts of the application\"\r\n\r\n\u00a0\r\n\r\nThe following stack trace is observed in RM log.\r\n\r\norg.apache.hadoop.yarn.server.webapp.AppBlock: Failed to read the attempts of the application application_1520597233415_0002.\r\njava.lang.NullPointerException\r\n at org.apache.hadoop.yarn.server.webapp.AppBlock$3.run(AppBlock.java:283)\r\n at org.apache.hadoop.yarn.server.webapp.AppBlock$3.run(AppBlock.java:280)\r\n at java.security.AccessController.doPrivileged(Native Method)\r\n at javax.security.auth.Subject.doAs(Subject.java:422)\r\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)\r\n at org.apache.hadoop.yarn.server.webapp.AppBlock.render(AppBlock.java:279)\r\n at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppBlock.render(RMAppBlock.java:71)\r\n at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\r\n at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\r\n at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\r\n at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\r\n at org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl$EImp._v(HamletImpl.java:117)\r\n at org.apache.hadoop.yarn.webapp.hamlet2.Hamlet$TD.__(Hamlet.java:848)\r\n at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)\r\n at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\r\n at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:212)\r\n at org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app(RmController.java:54)"
        }
    },
    {
        "filename": "YARN-3793.json",
        "creation_time": "2015-06-10T20:52:38.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.fs.FileContext.fixRelativePart(FileContext.java:274)\n        at org.apache.hadoop.fs.FileContext.delete(FileContext.java:755)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.deleteAsUser(DefaultContainerExecutor.java:458)\n        at org.apache.hadoop.yarn.server.nodemanager.DeletionService$FileDeletionTask.run(DeletionService.java:293)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.fixRelativePart": "  Path fixRelativePart(Path p) {\n    if (p.isUriPathAbsolute()) {\n      return p;\n    } else {\n      return new Path(workingDir, p);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.delete": "  public boolean delete(final Path f, final boolean recursive)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    Path absF = fixRelativePart(f);\n    return new FSLinkResolver<Boolean>() {\n      @Override\n      public Boolean next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return Boolean.valueOf(fs.delete(p, recursive));\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.resolve": "  protected Path resolve(final Path f) throws FileNotFoundException,\n      UnresolvedLinkException, AccessControlException, IOException {\n    return new FSLinkResolver<Path>() {\n      @Override\n      public Path next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.resolvePath(p);\n      }\n    }.resolve(this, f);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.deleteAsUser": "  public void deleteAsUser(DeletionAsUserContext ctx)\n      throws IOException, InterruptedException {\n    Path subDir = ctx.getSubDir();\n    List<Path> baseDirs = ctx.getBasedirs();\n\n    if (baseDirs == null || baseDirs.size() == 0) {\n      LOG.info(\"Deleting absolute path : \" + subDir);\n      if (!lfs.delete(subDir, true)) {\n        //Maybe retry\n        LOG.warn(\"delete returned false for path: [\" + subDir + \"]\");\n      }\n      return;\n    }\n    for (Path baseDir : baseDirs) {\n      Path del = subDir == null ? baseDir : new Path(baseDir, subDir);\n      LOG.info(\"Deleting path : \" + del);\n      if (!lfs.delete(del, true)) {\n        LOG.warn(\"delete returned false for path: [\" + del + \"]\");\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.DeletionService.run": "    public void run() {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(this);\n      }\n      boolean error = false;\n      if (null == user) {\n        if (baseDirs == null || baseDirs.size() == 0) {\n          LOG.debug(\"NM deleting absolute path : \" + subDir);\n          try {\n            lfs.delete(subDir, true);\n          } catch (IOException e) {\n            error = true;\n            LOG.warn(\"Failed to delete \" + subDir);\n          }\n        } else {\n          for (Path baseDir : baseDirs) {\n            Path del = subDir == null? baseDir : new Path(baseDir, subDir);\n            LOG.debug(\"NM deleting path : \" + del);\n            try {\n              lfs.delete(del, true);\n            } catch (IOException e) {\n              error = true;\n              LOG.warn(\"Failed to delete \" + subDir);\n            }\n          }\n        }\n      } else {\n        try {\n          LOG.debug(\"Deleting path: [\" + subDir + \"] as user: [\" + user + \"]\");\n          if (baseDirs == null || baseDirs.size() == 0) {\n            delService.exec.deleteAsUser(new DeletionAsUserContext.Builder()\n                .setUser(user)\n                .setSubDir(subDir)\n                .build());\n          } else {\n            delService.exec.deleteAsUser(new DeletionAsUserContext.Builder()\n                .setUser(user)\n                .setSubDir(subDir)\n                .setBasedirs(baseDirs.toArray(new Path[0]))\n                .build());\n          }\n        } catch (IOException e) {\n          error = true;\n          LOG.warn(\"Failed to delete as user \" + user, e);\n        } catch (InterruptedException e) {\n          error = true;\n          LOG.warn(\"Failed to delete as user \" + user, e);\n        }\n      }\n      if (error) {\n        setSuccess(!error);        \n      }\n      fileDeletionTaskFinished();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.DeletionService.delete": "  public void delete(String user, Path subDir, Path... baseDirs) {\n    // TODO if parent owned by NM, rename within parent inline\n    if (debugDelay != -1) {\n      List<Path> baseDirList = null;\n      if (baseDirs != null && baseDirs.length != 0) {\n        baseDirList = Arrays.asList(baseDirs);\n      }\n      FileDeletionTask task =\n          new FileDeletionTask(this, user, subDir, baseDirList);\n      recordDeletionTaskInStateStore(task);\n      sched.schedule(task, debugDelay, TimeUnit.SECONDS);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.DeletionService.setSuccess": "    public synchronized void setSuccess(boolean success) {\n      this.success = success;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.DeletionService.fileDeletionTaskFinished": "    private synchronized void fileDeletionTaskFinished() {\n      try {\n        delService.stateStore.removeDeletionTask(taskId);\n      } catch (IOException e) {\n        LOG.error(\"Unable to remove deletion task \" + taskId\n            + \" from state store\", e);\n      }\n      Iterator<FileDeletionTask> successorTaskI =\n          this.successorTaskSet.iterator();\n      while (successorTaskI.hasNext()) {\n        FileDeletionTask successorTask = successorTaskI.next();\n        if (!success) {\n          successorTask.setSuccess(success);\n        }\n        int count = successorTask.decrementAndGetPendingPredecessorTasks();\n        if (count == 0) {\n          if (successorTask.getSucess()) {\n            successorTask.delService.scheduleFileDeletionTask(successorTask);\n          } else {\n            successorTask.fileDeletionTaskFinished();\n          }\n        }\n      }\n    }"
        },
        "bug_report": {
            "Title": "Several NPEs when deleting local files on NM recovery",
            "Description": "When NM work-preserving restart is enabled, we see several NPEs on recovery. These seem to correspond to sub-directories that need to be deleted. I wonder if null pointers here mean incorrect tracking of these resources and a potential leak. This JIRA is to investigate and fix anything required.\n\nLogs show:\n{noformat}\n2015-05-18 07:06:10,225 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : null\n2015-05-18 07:06:10,224 ERROR org.apache.hadoop.yarn.server.nodemanager.DeletionService: Exception during execution of task in DeletionService\njava.lang.NullPointerException\n        at org.apache.hadoop.fs.FileContext.fixRelativePart(FileContext.java:274)\n        at org.apache.hadoop.fs.FileContext.delete(FileContext.java:755)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.deleteAsUser(DefaultContainerExecutor.java:458)\n        at org.apache.hadoop.yarn.server.nodemanager.DeletionService$FileDeletionTask.run(DeletionService.java:293)\n{noformat}"
        }
    },
    {
        "filename": "YARN-6102.json",
        "creation_time": "2017-01-17T09:36:29.000+0000",
        "stack_trace": "```\njava.lang.Exception: No handler for registered for class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:196)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:120)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "RMActiveService context to be updated with new RMContext on failover",
            "Description": "{code}2017-01-17 16:42:17,911 FATAL [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(200)) - Error in dispatcher thread\njava.lang.Exception: No handler for registered for class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:196)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:120)\n        at java.lang.Thread.run(Thread.java:745)\n2017-01-17 16:42:17,914 INFO  [AsyncDispatcher ShutDown handler] event.AsyncDispatcher (AsyncDispatcher.java:run(303)) - Exiting, bbye..{code}\n\nThe same stack i was also noticed in {{TestResourceTrackerOnHA}} exits abnormally, after some analysis, i was able to reproduce.\n\nOnce the nodeHeartBeat is sent to RM, inside {{org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService.nodeHeartbeat(NodeHeartbeatRequest)}}, before sending it to dispatcher through\n{{this.rmContext.getDispatcher().getEventHandler().handle(nodeStatusEvent);}} if RM failover is called, the dispatcher is reset\nThe new dispatcher is however first started and then the events are registered at {{org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize(boolean)}}\n\nSo event order will look like\n1. Send Node heartbeat to {{ResourceTrackerService}}\n2. In {{ResourceTrackerService.nodeHeartbeat}}, before passing to dispatcher call RM failover\n3. In RM Failover, current active will reset dispatcher @reinitialize i.e ( {{resetDispatcher();}} + {{createAndInitActiveServices();}} )\n\nNow between {{resetDispatcher();}} and {{createAndInitActiveServices();}} , the {{ResourceTrackerService.nodeHeartbeat}} invokes dipatcher\n\nThis will cause the above error as at point of time when {{STATUS_UPDATE}} event is given to dispatcher in {{ResourceTrackerService}} , the new dispatcher(from the failover) may be started but not yet registered for events\nUsing same steps(with pausing JVM at debug), i was able to reproduce this in production cluster also. for {{STATUS_UPDATE}} active service event, when the service is yet to forward the event to RM dispatcher but a failover is called and dispatcher reset is between {{resetDispatcher();}} & {{createAndInitActiveServices();}}"
        }
    },
    {
        "filename": "YARN-8409.json",
        "creation_time": "2018-06-08T20:36:32.000+0000",
        "stack_trace": "```\njava.net.ConnectException: Connection refused\n\nat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\nat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\nat org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)\n\nat org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1125)\n\njava.lang.NullPointerException\n\nat org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1033)\n\nat org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1030)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1087)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1030)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:347)\n\nat org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.serviceInit(ActiveStandbyElectorBasedElectorService.java:110)\n\nat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\nat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:336)\n\nat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1479)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.run": "    T run() throws KeeperException, InterruptedException; \n  }\n  \n  /**\n   * The callbacks and watchers pass a reference to the ZK client\n   * which made the original call. We don't want to take action\n   * based on any callbacks from prior clients after we quit\n   * the election.\n   * @param ctx the ZK client passed into the watcher\n   * @return true if it matches the current client\n   */\n  private synchronized boolean isStaleClient(Object ctx) {",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries": "  private <T> T zkDoWithRetries(ZKAction<T> action, Code retryCode)\n      throws KeeperException, InterruptedException {\n    int retry = 0;\n    while (true) {\n      try {\n        return action.run();\n      } catch (KeeperException ke) {\n        if ((shouldRetry(ke.code()) || shouldRetry(ke.code(), retryCode))\n            && ++retry < maxRetryNum) {\n          continue;\n        }\n        throw ke;\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code, Code retryIfCode) {\n    return (retryIfCode == null ? false : retryIfCode == code);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries": "  private String createWithRetries(final String path, final byte[] data,\n      final List<ACL> acl, final CreateMode mode)\n      throws InterruptedException, KeeperException {\n    return zkDoWithRetries(new ZKAction<String>() {\n      @Override\n      public String run() throws KeeperException, InterruptedException {\n        return zkClient.create(path, data, acl, mode);\n      }\n    });\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode": "  public synchronized void ensureParentZNode()\n      throws IOException, InterruptedException {\n    Preconditions.checkState(!wantToBeInElection,\n        \"ensureParentZNode() may not be called while in the election\");\n\n    String pathParts[] = znodeWorkingDir.split(\"/\");\n    Preconditions.checkArgument(pathParts.length >= 1 &&\n        pathParts[0].isEmpty(),\n        \"Invalid path: %s\", znodeWorkingDir);\n    \n    StringBuilder sb = new StringBuilder();\n    for (int i = 1; i < pathParts.length; i++) {\n      sb.append(\"/\").append(pathParts[i]);\n      String prefixPath = sb.toString();\n      LOG.debug(\"Ensuring existence of \" + prefixPath);\n      try {\n        createWithRetries(prefixPath, new byte[]{}, zkAcl, CreateMode.PERSISTENT);\n      } catch (KeeperException e) {\n        if (isNodeExists(e.code())) {\n          // Set ACLs for parent node, if they do not exist or are different\n          try {\n            setAclsWithRetries(prefixPath);\n          } catch (KeeperException e1) {\n            throw new IOException(\"Couldn't set ACLs on parent ZNode: \" +\n                prefixPath, e1);\n          }\n        } else {\n          throw new IOException(\"Couldn't create \" + prefixPath, e);\n        }\n      }\n    }\n    \n    LOG.info(\"Successfully created \" + znodeWorkingDir + \" in ZK.\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.setAclsWithRetries": "  private void setAclsWithRetries(final String path)\n      throws KeeperException, InterruptedException {\n    Stat stat = new Stat();\n    zkDoWithRetries(new ZKAction<Void>() {\n      @Override\n      public Void run() throws KeeperException, InterruptedException {\n        List<ACL> acl = zkClient.getACL(path, stat);\n        if (acl == null || !acl.containsAll(zkAcl) ||\n            !zkAcl.containsAll(acl)) {\n          zkClient.setACL(path, zkAcl, stat.getAversion());\n        }\n        return null;\n      }\n    }, Code.BADVERSION);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.serviceInit": "  protected void serviceInit(Configuration conf)\n      throws Exception {\n    conf = conf instanceof YarnConfiguration\n        ? conf\n        : new YarnConfiguration(conf);\n\n    String zkQuorum = conf.get(YarnConfiguration.RM_ZK_ADDRESS);\n    if (zkQuorum == null) {\n      throw new YarnRuntimeException(\"Embedded automatic failover \" +\n          \"is enabled, but \" + YarnConfiguration.RM_ZK_ADDRESS +\n          \" is not set\");\n    }\n\n    String rmId = HAUtil.getRMHAId(conf);\n    String clusterId = YarnConfiguration.getClusterId(conf);\n    localActiveNodeInfo = createActiveNodeInfo(clusterId, rmId);\n\n    String zkBasePath = conf.get(YarnConfiguration.AUTO_FAILOVER_ZK_BASE_PATH,\n        YarnConfiguration.DEFAULT_AUTO_FAILOVER_ZK_BASE_PATH);\n    String electionZNode = zkBasePath + \"/\" + clusterId;\n\n    zkSessionTimeout = conf.getLong(YarnConfiguration.RM_ZK_TIMEOUT_MS,\n        YarnConfiguration.DEFAULT_RM_ZK_TIMEOUT_MS);\n\n    List<ACL> zkAcls = ZKCuratorManager.getZKAcls(conf);\n    List<ZKUtil.ZKAuthInfo> zkAuths = ZKCuratorManager.getZKAuths(conf);\n\n    int maxRetryNum =\n        conf.getInt(YarnConfiguration.RM_HA_FC_ELECTOR_ZK_RETRIES_KEY, conf\n          .getInt(CommonConfigurationKeys.HA_FC_ELECTOR_ZK_OP_RETRIES_KEY,\n            CommonConfigurationKeys.HA_FC_ELECTOR_ZK_OP_RETRIES_DEFAULT));\n    elector = new ActiveStandbyElector(zkQuorum, (int) zkSessionTimeout,\n        electionZNode, zkAcls, zkAuths, this, maxRetryNum, false);\n\n    elector.ensureParentZNode();\n    if (!isParentZnodeSafe(clusterId)) {\n      notifyFatalError(String.format(\"invalid data in znode, %s, \" +\n          \"which may require the state store to be reformatted\",\n          electionZNode));\n    }\n\n    super.serviceInit(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.notifyFatalError": "  public void notifyFatalError(String errorMessage) {\n    rm.getRMContext().getDispatcher().getEventHandler().handle(\n        new RMFatalEvent(RMFatalEventType.EMBEDDED_ELECTOR_FAILED,\n            errorMessage));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.isParentZnodeSafe": "  private boolean isParentZnodeSafe(String clusterId)\n      throws InterruptedException, IOException, KeeperException {\n    byte[] data;\n    try {\n      data = elector.getActiveData();\n    } catch (ActiveStandbyElector.ActiveNotFoundException e) {\n      // no active found, parent znode is safe\n      return true;\n    }\n\n    YarnServerResourceManagerServiceProtos.ActiveRMInfoProto proto;\n    try {\n      proto = YarnServerResourceManagerServiceProtos.ActiveRMInfoProto\n          .parseFrom(data);\n    } catch (InvalidProtocolBufferException e) {\n      LOG.error(\"Invalid data in ZK: \" + StringUtils.byteToHexString(data));\n      return false;\n    }\n\n    // Check if the passed proto corresponds to an RM in the same cluster\n    if (!proto.getClusterId().equals(clusterId)) {\n      LOG.error(\"Mismatched cluster! The other RM seems \" +\n          \"to be from a different cluster. Current cluster = \" + clusterId +\n          \"Other RM's cluster = \" + proto.getClusterId());\n      return false;\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.createActiveNodeInfo": "  private static byte[] createActiveNodeInfo(String clusterId, String rmId)\n      throws IOException {\n    return YarnServerResourceManagerServiceProtos.ActiveRMInfoProto\n        .newBuilder()\n        .setClusterId(clusterId)\n        .setRmId(rmId)\n        .build()\n        .toByteArray();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of {}\", this, e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      LOG.debug(\"Service: {} entered state {}\", getName(), getServiceState());\n\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    LOG.debug(\"noteFailure {}\" + exception);\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service {} failed in state {}\",\n            getName(), failureState, exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": initing services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      service.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit": "    protected void serviceInit(Configuration configuration) throws Exception {\n      standByTransitionRunnable = new StandByTransitionRunnable();\n\n      rmSecretManagerService = createRMSecretManagerService();\n      addService(rmSecretManagerService);\n\n      containerAllocationExpirer = new ContainerAllocationExpirer(rmDispatcher);\n      addService(containerAllocationExpirer);\n      rmContext.setContainerAllocationExpirer(containerAllocationExpirer);\n\n      AMLivelinessMonitor amLivelinessMonitor = createAMLivelinessMonitor();\n      addService(amLivelinessMonitor);\n      rmContext.setAMLivelinessMonitor(amLivelinessMonitor);\n\n      AMLivelinessMonitor amFinishingMonitor = createAMLivelinessMonitor();\n      addService(amFinishingMonitor);\n      rmContext.setAMFinishingMonitor(amFinishingMonitor);\n      \n      RMAppLifetimeMonitor rmAppLifetimeMonitor = createRMAppLifetimeMonitor();\n      addService(rmAppLifetimeMonitor);\n      rmContext.setRMAppLifetimeMonitor(rmAppLifetimeMonitor);\n\n      RMNodeLabelsManager nlm = createNodeLabelManager();\n      nlm.setRMContext(rmContext);\n      addService(nlm);\n      rmContext.setNodeLabelManager(nlm);\n\n      AllocationTagsManager allocationTagsManager =\n          createAllocationTagsManager();\n      rmContext.setAllocationTagsManager(allocationTagsManager);\n\n      PlacementConstraintManagerService placementConstraintManager =\n          createPlacementConstraintManager();\n      addService(placementConstraintManager);\n      rmContext.setPlacementConstraintManager(placementConstraintManager);\n\n      // add resource profiles here because it's used by AbstractYarnScheduler\n      ResourceProfilesManager resourceProfilesManager =\n          createResourceProfileManager();\n      resourceProfilesManager.init(conf);\n      rmContext.setResourceProfilesManager(resourceProfilesManager);\n\n      RMDelegatedNodeLabelsUpdater delegatedNodeLabelsUpdater =\n          createRMDelegatedNodeLabelsUpdater();\n      if (delegatedNodeLabelsUpdater != null) {\n        addService(delegatedNodeLabelsUpdater);\n        rmContext.setRMDelegatedNodeLabelsUpdater(delegatedNodeLabelsUpdater);\n      }\n\n      recoveryEnabled = conf.getBoolean(YarnConfiguration.RECOVERY_ENABLED,\n          YarnConfiguration.DEFAULT_RM_RECOVERY_ENABLED);\n\n      RMStateStore rmStore = null;\n      if (recoveryEnabled) {\n        rmStore = RMStateStoreFactory.getStore(conf);\n        boolean isWorkPreservingRecoveryEnabled =\n            conf.getBoolean(\n              YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_ENABLED,\n              YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_ENABLED);\n        rmContext\n            .setWorkPreservingRecoveryEnabled(isWorkPreservingRecoveryEnabled);\n      } else {\n        rmStore = new NullRMStateStore();\n      }\n\n      try {\n        rmStore.setResourceManager(rm);\n        rmStore.init(conf);\n        rmStore.setRMDispatcher(rmDispatcher);\n      } catch (Exception e) {\n        // the Exception from stateStore.init() needs to be handled for\n        // HA and we need to give up master status if we got fenced\n        LOG.error(\"Failed to init state store\", e);\n        throw e;\n      }\n      rmContext.setStateStore(rmStore);\n\n      if (UserGroupInformation.isSecurityEnabled()) {\n        delegationTokenRenewer = createDelegationTokenRenewer();\n        rmContext.setDelegationTokenRenewer(delegationTokenRenewer);\n      }\n\n      // Register event handler for NodesListManager\n      nodesListManager = new NodesListManager(rmContext);\n      rmDispatcher.register(NodesListManagerEventType.class, nodesListManager);\n      addService(nodesListManager);\n      rmContext.setNodesListManager(nodesListManager);\n\n      // Initialize the scheduler\n      scheduler = createScheduler();\n      scheduler.setRMContext(rmContext);\n      addIfService(scheduler);\n      rmContext.setScheduler(scheduler);\n\n      schedulerDispatcher = createSchedulerEventDispatcher();\n      addIfService(schedulerDispatcher);\n      rmDispatcher.register(SchedulerEventType.class, schedulerDispatcher);\n\n      // Register event handler for RmAppEvents\n      rmDispatcher.register(RMAppEventType.class,\n          new ApplicationEventDispatcher(rmContext));\n\n      // Register event handler for RmAppAttemptEvents\n      rmDispatcher.register(RMAppAttemptEventType.class,\n          new ApplicationAttemptEventDispatcher(rmContext));\n\n      // Register event handler for RmNodes\n      rmDispatcher.register(\n          RMNodeEventType.class, new NodeEventDispatcher(rmContext));\n\n      nmLivelinessMonitor = createNMLivelinessMonitor();\n      addService(nmLivelinessMonitor);\n\n      resourceTracker = createResourceTrackerService();\n      addService(resourceTracker);\n      rmContext.setResourceTrackerService(resourceTracker);\n\n      MetricsSystem ms = DefaultMetricsSystem.initialize(\"ResourceManager\");\n      if (fromActive) {\n        JvmMetrics.reattach(ms, jvmMetrics);\n        UserGroupInformation.reattachMetrics();\n      } else {\n        jvmMetrics = JvmMetrics.initSingleton(\"ResourceManager\", null);\n      }\n\n      JvmPauseMonitor pauseMonitor = new JvmPauseMonitor();\n      addService(pauseMonitor);\n      jvmMetrics.setPauseMonitor(pauseMonitor);\n\n      // Initialize the Reservation system\n      if (conf.getBoolean(YarnConfiguration.RM_RESERVATION_SYSTEM_ENABLE,\n          YarnConfiguration.DEFAULT_RM_RESERVATION_SYSTEM_ENABLE)) {\n        reservationSystem = createReservationSystem();\n        if (reservationSystem != null) {\n          reservationSystem.setRMContext(rmContext);\n          addIfService(reservationSystem);\n          rmContext.setReservationSystem(reservationSystem);\n          LOG.info(\"Initialized Reservation system\");\n        }\n      }\n\n      masterService = createApplicationMasterService();\n      addService(masterService) ;\n      rmContext.setApplicationMasterService(masterService);\n\n      applicationACLsManager = new ApplicationACLsManager(conf);\n\n      queueACLsManager = createQueueACLsManager(scheduler, conf);\n\n      rmAppManager = createRMAppManager();\n      // Register event handler for RMAppManagerEvents\n      rmDispatcher.register(RMAppManagerEventType.class, rmAppManager);\n\n      clientRM = createClientRMService();\n      addService(clientRM);\n      rmContext.setClientRMService(clientRM);\n\n      applicationMasterLauncher = createAMLauncher();\n      rmDispatcher.register(AMLauncherEventType.class,\n          applicationMasterLauncher);\n\n      addService(applicationMasterLauncher);\n      if (UserGroupInformation.isSecurityEnabled()) {\n        addService(delegationTokenRenewer);\n        delegationTokenRenewer.setRMContext(rmContext);\n      }\n\n      if(HAUtil.isFederationEnabled(conf)) {\n        String cId = YarnConfiguration.getClusterId(conf);\n        if (cId.isEmpty()) {\n          String errMsg =\n              \"Cannot initialize RM as Federation is enabled\"\n                  + \" but cluster id is not configured.\";\n          LOG.error(errMsg);\n          throw new YarnRuntimeException(errMsg);\n        }\n        federationStateStoreService = createFederationStateStoreService();\n        addIfService(federationStateStoreService);\n        LOG.info(\"Initialized Federation membership.\");\n      }\n\n      new RMNMInfo(rmContext, scheduler);\n\n      if (conf.getBoolean(YarnConfiguration.YARN_API_SERVICES_ENABLE,\n          false)) {\n        SystemServiceManager systemServiceManager = createServiceManager();\n        addIfService(systemServiceManager);\n      }\n\n      super.serviceInit(conf);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMApplicationHistoryWriter": "  protected RMApplicationHistoryWriter createRMApplicationHistoryWriter() {\n    return new RMApplicationHistoryWriter();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLivelinessMonitor": "  protected AMLivelinessMonitor createAMLivelinessMonitor() {\n    return new AMLivelinessMonitor(this.rmDispatcher);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices": "  protected void createAndInitActiveServices(boolean fromActive) {\n    activeServices = new RMActiveServices(this);\n    activeServices.fromActive = fromActive;\n    activeServices.init(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createFederationStateStoreService": "  private FederationStateStoreService createFederationStateStoreService() {\n    return new FederationStateStoreService(rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMAppManager": "  protected RMAppManager createRMAppManager() {\n    return new RMAppManager(this.rmContext, this.scheduler, this.masterService,\n      this.applicationACLsManager, this.conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createDelegationTokenRenewer": "  protected DelegationTokenRenewer createDelegationTokenRenewer() {\n    return new DelegationTokenRenewer();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createPlacementConstraintManager": "  protected PlacementConstraintManagerService\n      createPlacementConstraintManager() {\n    // Use the in memory Placement Constraint Manager.\n    return new MemoryPlacementConstraintManager();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMSecretManagerService": "  protected RMSecretManagerService createRMSecretManagerService() {\n    return new RMSecretManagerService(conf, rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNodeLabelManager": "  protected RMNodeLabelsManager createNodeLabelManager()\n      throws InstantiationException, IllegalAccessException {\n    return new RMNodeLabelsManager();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createScheduler": "  protected ResourceScheduler createScheduler() {\n    String schedulerClassName = conf.get(YarnConfiguration.RM_SCHEDULER,\n        YarnConfiguration.DEFAULT_RM_SCHEDULER);\n    LOG.info(\"Using Scheduler: \" + schedulerClassName);\n    try {\n      Class<?> schedulerClazz = Class.forName(schedulerClassName);\n      if (ResourceScheduler.class.isAssignableFrom(schedulerClazz)) {\n        return (ResourceScheduler) ReflectionUtils.newInstance(schedulerClazz,\n            this.conf);\n      } else {\n        throw new YarnRuntimeException(\"Class: \" + schedulerClassName\n            + \" not instance of \" + ResourceScheduler.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\"Could not instantiate Scheduler: \"\n          + schedulerClassName, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createEmbeddedElector": "  protected EmbeddedElector createEmbeddedElector() throws IOException {\n    EmbeddedElector elector;\n    curatorEnabled =\n        conf.getBoolean(YarnConfiguration.CURATOR_LEADER_ELECTOR,\n            YarnConfiguration.DEFAULT_CURATOR_LEADER_ELECTOR_ENABLED);\n    if (curatorEnabled) {\n      this.zkManager = createAndStartZKManager(conf);\n      elector = new CuratorBasedElectorService(this);\n    } else {\n      elector = new ActiveStandbyElectorBasedElectorService(this);\n    }\n    return elector;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMDelegatedNodeLabelsUpdater": "  protected RMDelegatedNodeLabelsUpdater createRMDelegatedNodeLabelsUpdater() {\n    if (conf.getBoolean(YarnConfiguration.NODE_LABELS_ENABLED,\n            YarnConfiguration.DEFAULT_NODE_LABELS_ENABLED)\n        && YarnConfiguration.isDelegatedCentralizedNodeLabelConfiguration(\n            conf)) {\n      return new RMDelegatedNodeLabelsUpdater(rmContext);\n    } else {\n      return null;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createApplicationMasterService": "  protected ApplicationMasterService createApplicationMasterService() {\n    Configuration config = this.rmContext.getYarnConfiguration();\n    if (YarnConfiguration.isOpportunisticContainerAllocationEnabled(config)\n        || YarnConfiguration.isDistSchedulingEnabled(config)) {\n      if (YarnConfiguration.isDistSchedulingEnabled(config) &&\n          !YarnConfiguration\n              .isOpportunisticContainerAllocationEnabled(config)) {\n        throw new YarnRuntimeException(\n            \"Invalid parameters: opportunistic container allocation has to \" +\n                \"be enabled when distributed scheduling is enabled.\");\n      }\n      OpportunisticContainerAllocatorAMService\n          oppContainerAllocatingAMService =\n          new OpportunisticContainerAllocatorAMService(this.rmContext,\n              scheduler);\n      EventDispatcher oppContainerAllocEventDispatcher =\n          new EventDispatcher(oppContainerAllocatingAMService,\n              OpportunisticContainerAllocatorAMService.class.getName());\n      // Add an event dispatcher for the\n      // OpportunisticContainerAllocatorAMService to handle node\n      // additions, updates and removals. Since the SchedulerEvent is currently\n      // a super set of theses, we register interest for it.\n      addService(oppContainerAllocEventDispatcher);\n      rmDispatcher.register(SchedulerEventType.class,\n          oppContainerAllocEventDispatcher);\n      this.rmContext.setContainerQueueLimitCalculator(\n          oppContainerAllocatingAMService.getNodeManagerQueueLimitCalculator());\n      return oppContainerAllocatingAMService;\n    }\n    return new ApplicationMasterService(this.rmContext, scheduler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLauncher": "  protected ApplicationMasterLauncher createAMLauncher() {\n    return new ApplicationMasterLauncher(this.rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createServiceManager": "  protected SystemServiceManager createServiceManager() {\n    String schedulerClassName =\n        YarnConfiguration.DEFAULT_YARN_API_SYSTEM_SERVICES_CLASS;\n    LOG.info(\"Using SystemServiceManager: \" + schedulerClassName);\n    try {\n      Class<?> schedulerClazz = Class.forName(schedulerClassName);\n      if (SystemServiceManager.class.isAssignableFrom(schedulerClazz)) {\n        return (SystemServiceManager) ReflectionUtils\n            .newInstance(schedulerClazz, this.conf);\n      } else {\n        throw new YarnRuntimeException(\n            \"Class: \" + schedulerClassName + \" not instance of \"\n                + SystemServiceManager.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\n          \"Could not instantiate SystemServiceManager: \" + schedulerClassName,\n          e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.loadConfigurationXml": "  private void loadConfigurationXml(String configurationFile)\n      throws YarnException, IOException {\n    InputStream configurationInputStream =\n        this.configurationProvider.getConfigurationInputStream(this.conf,\n            configurationFile);\n    if (configurationInputStream != null) {\n      this.conf.addResource(configurationInputStream, configurationFile);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createReservationSystem": "  protected ReservationSystem createReservationSystem() {\n    String reservationClassName =\n        conf.get(YarnConfiguration.RM_RESERVATION_SYSTEM_CLASS,\n            AbstractReservationSystem.getDefaultReservationSystem(scheduler));\n    if (reservationClassName == null) {\n      return null;\n    }\n    LOG.info(\"Using ReservationSystem: \" + reservationClassName);\n    try {\n      Class<?> reservationClazz = Class.forName(reservationClassName);\n      if (ReservationSystem.class.isAssignableFrom(reservationClazz)) {\n        return (ReservationSystem) ReflectionUtils.newInstance(\n            reservationClazz, this.conf);\n      } else {\n        throw new YarnRuntimeException(\"Class: \" + reservationClassName\n            + \" not instance of \" + ReservationSystem.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\n          \"Could not instantiate ReservationSystem: \" + reservationClassName, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMTimelineCollectorManager": "  private RMTimelineCollectorManager createRMTimelineCollectorManager() {\n    return new RMTimelineCollectorManager(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAdminService": "  protected AdminService createAdminService() {\n    return new AdminService(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createClientRMService": "  protected ClientRMService createClientRMService() {\n    return new ClientRMService(this.rmContext, scheduler, this.rmAppManager,\n        this.applicationACLsManager, this.queueACLsManager,\n        this.rmContext.getRMDelegationTokenSecretManager());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setupDispatcher": "  private Dispatcher setupDispatcher() {\n    Dispatcher dispatcher = createDispatcher();\n    dispatcher.register(RMFatalEventType.class,\n        new ResourceManager.RMFatalEventDispatcher());\n    return dispatcher;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNMLivelinessMonitor": "  private NMLivelinessMonitor createNMLivelinessMonitor() {\n    return new NMLivelinessMonitor(this.rmContext\n        .getDispatcher());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createResourceProfileManager": "  protected ResourceProfilesManager createResourceProfileManager() {\n    ResourceProfilesManager resourceProfilesManager =\n        new ResourceProfilesManagerImpl();\n    return resourceProfilesManager;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAllocationTagsManager": "  protected AllocationTagsManager createAllocationTagsManager() {\n    return new AllocationTagsManager(this.rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createSystemMetricsPublisher": "  protected SystemMetricsPublisher createSystemMetricsPublisher() {\n    List<SystemMetricsPublisher> publishers =\n        new ArrayList<SystemMetricsPublisher>();\n    if (YarnConfiguration.timelineServiceV1Enabled(conf)) {\n      SystemMetricsPublisher publisherV1 = new TimelineServiceV1Publisher();\n      publishers.add(publisherV1);\n    }\n    if (YarnConfiguration.timelineServiceV2Enabled(conf)) {\n      // we're dealing with the v.2.x publisher\n      LOG.info(\"system metrics publisher with the timeline service V2 is \"\n          + \"configured\");\n      SystemMetricsPublisher publisherV2 = new TimelineServiceV2Publisher(\n          rmContext.getRMTimelineCollectorManager());\n      publishers.add(publisherV2);\n    }\n    if (publishers.isEmpty()) {\n      LOG.info(\"TimelineServicePublisher is not configured\");\n      SystemMetricsPublisher noopPublisher = new NoOpSystemMetricPublisher();\n      publishers.add(noopPublisher);\n    }\n\n    for (SystemMetricsPublisher publisher : publishers) {\n      addIfService(publisher);\n    }\n\n    SystemMetricsPublisher combinedPublisher =\n        new CombinedSystemMetricsPublisher(publishers);\n    return combinedPublisher;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createSchedulerEventDispatcher": "  protected EventHandler<SchedulerEvent> createSchedulerEventDispatcher() {\n    return new EventDispatcher(this.scheduler, \"SchedulerEventDispatcher\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.doSecureLogin": "  protected void doSecureLogin() throws IOException {\n\tInetSocketAddress socAddr = getBindAddress(conf);\n    SecurityUtil.login(this.conf, YarnConfiguration.RM_KEYTAB,\n        YarnConfiguration.RM_PRINCIPAL, socAddr.getHostName());\n\n    // if security is enable, set rmLoginUGI as UGI of loginUser\n    if (UserGroupInformation.isSecurityEnabled()) {\n      this.rmLoginUGI = UserGroupInformation.getLoginUser();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMAppLifetimeMonitor": "  protected RMAppLifetimeMonitor createRMAppLifetimeMonitor() {\n    return new RMAppLifetimeMonitor(this.rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createQueueACLsManager": "  protected QueueACLsManager createQueueACLsManager(ResourceScheduler scheduler,\n      Configuration conf) {\n    return new QueueACLsManager(scheduler, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createResourceTrackerService": "  protected ResourceTrackerService createResourceTrackerService() {\n    return new ResourceTrackerService(this.rmContext, this.nodesListManager,\n        this.nmLivelinessMonitor,\n        this.rmContext.getContainerTokenSecretManager(),\n        this.rmContext.getNMTokenSecretManager());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.validateConfigs": "  protected static void validateConfigs(Configuration conf) {\n    // validate max-attempts\n    int globalMaxAppAttempts =\n        conf.getInt(YarnConfiguration.RM_AM_MAX_ATTEMPTS,\n        YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS);\n    if (globalMaxAppAttempts <= 0) {\n      throw new YarnRuntimeException(\"Invalid global max attempts configuration\"\n          + \", \" + YarnConfiguration.RM_AM_MAX_ATTEMPTS\n          + \"=\" + globalMaxAppAttempts + \", it should be a positive integer.\");\n    }\n\n    // validate expireIntvl >= heartbeatIntvl\n    long expireIntvl = conf.getLong(YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_RM_NM_EXPIRY_INTERVAL_MS);\n    long heartbeatIntvl =\n        conf.getLong(YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS,\n            YarnConfiguration.DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS);\n    if (expireIntvl < heartbeatIntvl) {\n      throw new YarnRuntimeException(\"Nodemanager expiry interval should be no\"\n          + \" less than heartbeat interval, \"\n          + YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS + \"=\" + expireIntvl\n          + \", \" + YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS + \"=\"\n          + heartbeatIntvl);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main": "  public static void main(String argv[]) {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ResourceManager.class, argv, LOG);\n    try {\n      Configuration conf = new YarnConfiguration();\n      GenericOptionsParser hParser = new GenericOptionsParser(conf, argv);\n      argv = hParser.getRemainingArgs();\n      // If -format-state-store, then delete RMStateStore; else startup normally\n      if (argv.length >= 1) {\n        if (argv[0].equals(\"-format-state-store\")) {\n          deleteRMStateStore(conf);\n        } else if (argv[0].equals(\"-remove-application-from-state-store\")\n            && argv.length == 2) {\n          removeApplication(conf, argv[1]);\n        } else {\n          printUsage(System.err);\n        }\n      } else {\n        ResourceManager resourceManager = new ResourceManager();\n        ShutdownHookManager.get().addShutdownHook(\n          new CompositeServiceShutdownHook(resourceManager),\n          SHUTDOWN_HOOK_PRIORITY);\n        resourceManager.init(conf);\n        resourceManager.start();\n      }\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ResourceManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.removeApplication": "  static void removeApplication(Configuration conf, String applicationId)\n      throws Exception {\n    RMStateStore rmStore = RMStateStoreFactory.getStore(conf);\n    rmStore.setResourceManager(new ResourceManager());\n    rmStore.init(conf);\n    rmStore.start();\n    try {\n      ApplicationId removeAppId = ApplicationId.fromString(applicationId);\n      LOG.info(\"Deleting application \" + removeAppId + \" from state store\");\n      rmStore.removeApplication(removeAppId);\n      LOG.info(\"Application is deleted from state store\");\n    } finally {\n      rmStore.stop();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.printUsage": "  private static void printUsage(PrintStream out) {\n    out.println(\"Usage: yarn resourcemanager [-format-state-store]\");\n    out.println(\"                            \"\n        + \"[-remove-application-from-state-store <appId>]\" + \"\\n\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.deleteRMStateStore": "  static void deleteRMStateStore(Configuration conf) throws Exception {\n    RMStateStore rmStore = RMStateStoreFactory.getStore(conf);\n    rmStore.setResourceManager(new ResourceManager());\n    rmStore.init(conf);\n    rmStore.start();\n    try {\n      LOG.info(\"Deleting ResourceManager state store...\");\n      rmStore.deleteStore();\n      LOG.info(\"State store deleted\");\n    } finally {\n      rmStore.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Logger log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service {}\", service.getName(), e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.init": "  void init(Configuration config);\n\n\n  /**\n   * Start the service.\n   *\n   * The transition MUST be from {@link STATE#INITED} to {@link STATE#STARTED}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setNodeLabelManager": "  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setAllocationTagsManager": "  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setSystemMetricsPublisher": "  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setLeaderElectorService": "  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMTimelineCollectorManager": "  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMAppLifetimeMonitor": "  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.processRMProxyUsersConf": "  public static void processRMProxyUsersConf(Configuration conf) {\n    Map<String, String> rmProxyUsers = new HashMap<String, String>();\n    for (Map.Entry<String, String> entry : conf) {\n      String propName = entry.getKey();\n      if (propName.startsWith(YarnConfiguration.RM_PROXY_USER_PREFIX)) {\n        rmProxyUsers.put(ProxyUsers.CONF_HADOOP_PROXYUSER + \".\" +\n                propName.substring(YarnConfiguration.RM_PROXY_USER_PREFIX\n                    .length()),\n            entry.getValue());\n      }\n    }\n    for (Map.Entry<String, String> entry : rmProxyUsers.entrySet()) {\n      conf.set(entry.getKey(), entry.getValue());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setResourceProfilesManager": "  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setPlacementConstraintManager": "  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setClientRMService": "  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMDelegatedNodeLabelsUpdater": "  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMApplicationHistoryWriter": "  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}"
        },
        "bug_report": {
            "Title": "ActiveStandbyElectorBasedElectorService is failing with NPE",
            "Description": "In RM-HA env, kill ZK leader and then perform RM failover.\u00a0\r\n\r\nSometimes, active RM gets NPE and fail to come up successfully\r\n{code:java}\r\n\r\n2018-06-08 10:31:03,007 INFO\u00a0 client.ZooKeeperSaslClient (ZooKeeperSaslClient.java:run(289)) - Client will use GSSAPI as SASL mechanism.\r\n\r\n2018-06-08 10:31:03,008 INFO\u00a0 zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(1019)) - Opening socket connection to server xxx/xxx:2181. Will attempt to SASL-authenticate using Login Context section 'Client'\r\n\r\n2018-06-08 10:31:03,009 WARN\u00a0 zookeeper.ClientCnxn (ClientCnxn.java:run(1146)) - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect\r\n\r\njava.net.ConnectException: Connection refused\r\n\r\nat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\r\n\r\nat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\r\n\r\nat org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)\r\n\r\nat org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1125)\r\n\r\n2018-06-08 10:31:03,344 INFO\u00a0 service.AbstractService (AbstractService.java:noteFailure(267)) - Service org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService failed in state INITED\r\n\r\njava.lang.NullPointerException\r\n\r\nat org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1033)\r\n\r\nat org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1030)\r\n\r\nat org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095)\r\n\r\nat org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1087)\r\n\r\nat org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1030)\r\n\r\nat org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:347)\r\n\r\nat org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.serviceInit(ActiveStandbyElectorBasedElectorService.java:110)\r\n\r\nat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\r\nat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\r\n\r\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:336)\r\n\r\nat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\r\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1479)\r\n\r\n2018-06-08 10:31:03,345 INFO\u00a0 ha.ActiveStandbyElector (ActiveStandbyElector.java:quitElection(409)) - Yielding from election{code}"
        }
    },
    {
        "filename": "YARN-8223.json",
        "creation_time": "2018-04-27T11:49:02.000+0000",
        "stack_trace": "```\njava.lang.ClassNotFoundException: org.apache.auxtest.AuxServiceFromLocal\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat org.apache.hadoop.util.ApplicationClassLoader.loadClass(ApplicationClassLoader.java:189)\n\tat org.apache.hadoop.util.ApplicationClassLoader.loadClass(ApplicationClassLoader.java:157)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:348)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxiliaryServiceWithCustomClassLoader.getInstance(AuxiliaryServiceWithCustomClassLoader.java:169)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:249)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:472)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:918)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:979)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ApplicationClassLoader.loadClass": "  protected synchronized Class<?> loadClass(String name, boolean resolve)\n      throws ClassNotFoundException {\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Loading class: \" + name);\n    }\n\n    Class<?> c = findLoadedClass(name);\n    ClassNotFoundException ex = null;\n\n    if (c == null && !isSystemClass(name, systemClasses)) {\n      // Try to load class from this classloader's URLs. Note that this is like\n      // the servlet spec, not the usual Java 2 behaviour where we ask the\n      // parent to attempt to load first.\n      try {\n        c = findClass(name);\n        if (LOG.isDebugEnabled() && c != null) {\n          LOG.debug(\"Loaded class: \" + name + \" \");\n        }\n      } catch (ClassNotFoundException e) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(e.toString());\n        }\n        ex = e;\n      }\n    }\n\n    if (c == null) { // try parent\n      c = parent.loadClass(name);\n      if (LOG.isDebugEnabled() && c != null) {\n        LOG.debug(\"Loaded class from parent: \" + name + \" \");\n      }\n    }\n\n    if (c == null) {\n      throw ex != null ? ex : new ClassNotFoundException(name);\n    }\n\n    if (resolve) {\n      resolveClass(c);\n    }\n\n    return c;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ApplicationClassLoader.isSystemClass": "  public static boolean isSystemClass(String name, List<String> systemClasses) {\n    boolean result = false;\n    if (systemClasses != null) {\n      String canonicalName = name.replace('/', '.');\n      while (canonicalName.startsWith(\".\")) {\n        canonicalName=canonicalName.substring(1);\n      }\n      for (String c : systemClasses) {\n        boolean shouldInclude = true;\n        if (c.startsWith(\"-\")) {\n          c = c.substring(1);\n          shouldInclude = false;\n        }\n        if (canonicalName.startsWith(c)) {\n          if (   c.endsWith(\".\")                                   // package\n              || canonicalName.length() == c.length()              // class\n              ||    canonicalName.length() > c.length()            // nested\n                 && canonicalName.charAt(c.length()) == '$' ) {\n            if (shouldInclude) {\n              result = true;\n            } else {\n              return false;\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxiliaryServiceWithCustomClassLoader.getInstance": "  public static AuxiliaryServiceWithCustomClassLoader getInstance(\n      Configuration conf, String className, String appClassPath)\n      throws IOException, ClassNotFoundException {\n    String[] systemClasses = conf.getTrimmedStrings(String.format(\n        YarnConfiguration.NM_AUX_SERVICES_SYSTEM_CLASSES,\n        className));\n    ClassLoader customClassLoader = createAuxServiceClassLoader(\n        appClassPath, systemClasses);\n    Class<?> clazz = Class.forName(className, true,\n        customClassLoader);\n    Class<? extends AuxiliaryService> sClass = clazz.asSubclass(\n        AuxiliaryService.class);\n    AuxiliaryService wrapped = ReflectionUtils.newInstance(sClass, conf);\n    return new AuxiliaryServiceWithCustomClassLoader(\n        className + \" with custom class loader\", wrapped,\n        customClassLoader);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxiliaryServiceWithCustomClassLoader.createAuxServiceClassLoader": "  private static ClassLoader createAuxServiceClassLoader(\n      final String appClasspath, final String[] systemClasses)\n      throws IOException {\n    try {\n      return AccessController.doPrivileged(\n        new PrivilegedExceptionAction<ClassLoader>() {\n          @Override\n          public ClassLoader run() throws MalformedURLException {\n            return new ApplicationClassLoader(appClasspath,\n                AuxServices.class.getClassLoader(),\n                Arrays.asList(systemClasses));\n          }\n        }\n      );\n    } catch (PrivilegedActionException e) {\n      Throwable t = e.getCause();\n      if (t instanceof MalformedURLException) {\n        throw (MalformedURLException) t;\n      }\n      throw new IOException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit": "  public void serviceInit(Configuration conf) throws Exception {\n    final FsPermission storeDirPerms = new FsPermission((short)0700);\n    Path stateStoreRoot = null;\n    FileSystem stateStoreFs = null;\n    boolean recoveryEnabled = conf.getBoolean(\n        YarnConfiguration.NM_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_NM_RECOVERY_ENABLED);\n    if (recoveryEnabled) {\n      stateStoreRoot = new Path(conf.get(YarnConfiguration.NM_RECOVERY_DIR),\n          STATE_STORE_ROOT_NAME);\n      stateStoreFs = FileSystem.getLocal(conf);\n    }\n    Collection<String> auxNames = conf.getStringCollection(\n        YarnConfiguration.NM_AUX_SERVICES);\n    for (final String sName : auxNames) {\n      try {\n        Preconditions\n            .checkArgument(\n                validateAuxServiceName(sName),\n                \"The ServiceName: \" + sName + \" set in \" +\n                YarnConfiguration.NM_AUX_SERVICES +\" is invalid.\" +\n                \"The valid service name should only contain a-zA-Z0-9_ \" +\n                \"and can not start with numbers\");\n        String classKey = String.format(\n            YarnConfiguration.NM_AUX_SERVICE_FMT, sName);\n        String className = conf.get(classKey);\n        final String appLocalClassPath = conf.get(String.format(\n            YarnConfiguration.NM_AUX_SERVICES_CLASSPATH, sName));\n        final String appRemoteClassPath = conf.get(String.format(\n            YarnConfiguration.NM_AUX_SERVICE_REMOTE_CLASSPATH, sName));\n        AuxiliaryService s = null;\n        boolean useCustomerClassLoader = ((appLocalClassPath != null\n            && !appLocalClassPath.isEmpty()) ||\n            (appRemoteClassPath != null && !appRemoteClassPath.isEmpty()))\n            && className != null && !className.isEmpty();\n        if (useCustomerClassLoader) {\n          // load AuxiliaryService from local class path\n          if (appRemoteClassPath == null || appRemoteClassPath.isEmpty()) {\n            s = AuxiliaryServiceWithCustomClassLoader.getInstance(\n                conf, className, appLocalClassPath);\n          } else {\n            // load AuxiliaryService from remote class path\n            if (appLocalClassPath != null && !appLocalClassPath.isEmpty()) {\n              throw new YarnRuntimeException(\"The aux serivce:\" + sName\n                  + \" has configured local classpath:\" + appLocalClassPath\n                  + \" and remote classpath:\" + appRemoteClassPath\n                  + \". Only one of them should be configured.\");\n            }\n            FileContext localLFS = getLocalFileContext(conf);\n            // create NM aux-service dir in NM localdir if it does not exist.\n            Path nmAuxDir = dirsHandler.getLocalPathForWrite(\".\"\n                + Path.SEPARATOR + NM_AUX_SERVICE_DIR);\n            if (!localLFS.util().exists(nmAuxDir)) {\n              try {\n                localLFS.mkdir(nmAuxDir, NM_AUX_SERVICE_DIR_PERM, true);\n              } catch (IOException ex) {\n                throw new YarnRuntimeException(\"Fail to create dir:\"\n                    + nmAuxDir.toString(), ex);\n              }\n            }\n            Path src = new Path(appRemoteClassPath);\n            FileContext remoteLFS = getRemoteFileContext(src.toUri(), conf);\n            FileStatus scFileStatus = remoteLFS.getFileStatus(src);\n            if (!scFileStatus.getOwner().equals(\n                this.userUGI.getShortUserName())) {\n              throw new YarnRuntimeException(\"The remote jarfile owner:\"\n                  + scFileStatus.getOwner() + \" is not the same as the NM user:\"\n                  + this.userUGI.getShortUserName() + \".\");\n            }\n            if ((scFileStatus.getPermission().toShort() & 0022) != 0) {\n              throw new YarnRuntimeException(\"The remote jarfile should not \"\n                  + \"be writable by group or others. \"\n                  + \"The current Permission is \"\n                  + scFileStatus.getPermission().toShort());\n            }\n            Path dest = null;\n            Path downloadDest = new Path(nmAuxDir,\n                className + \"_\" + scFileStatus.getModificationTime());\n            // check whether we need to re-download the jar\n            // from remote directory\n            Path targetDirPath = new Path(downloadDest,\n                scFileStatus.getPath().getName());\n            FileStatus[] allSubDirs = localLFS.util().listStatus(nmAuxDir);\n            boolean reDownload = true;\n            for (FileStatus sub : allSubDirs) {\n              if (sub.getPath().getName().equals(downloadDest.getName())) {\n                reDownload = false;\n                dest = new Path(targetDirPath + Path.SEPARATOR + \"*\");\n                break;\n              } else {\n                if (sub.getPath().getName().contains(className) &&\n                    !sub.getPath().getName().endsWith(DEL_SUFFIX)) {\n                  Path delPath = new Path(sub.getPath().getParent(),\n                      sub.getPath().getName() + DEL_SUFFIX);\n                  localLFS.rename(sub.getPath(), delPath);\n                  LOG.info(\"delete old aux service jar dir:\"\n                      + delPath.toString());\n                  FileDeletionTask deletionTask = new FileDeletionTask(\n                      this.delService, null, delPath, null);\n                  this.delService.delete(deletionTask);\n                }\n              }\n            }\n            if (reDownload) {\n              LocalResource scRsrc = LocalResource.newInstance(\n                  URL.fromURI(src.toUri()),\n                  LocalResourceType.ARCHIVE, LocalResourceVisibility.PRIVATE,\n                  scFileStatus.getLen(), scFileStatus.getModificationTime());\n              FSDownload download = new FSDownload(localLFS, null, conf,\n                  downloadDest, scRsrc, null);\n              try {\n                Path downloaded = download.call();\n                dest = new Path(downloaded + Path.SEPARATOR + \"*\");\n              } catch (Exception ex) {\n                throw new YarnRuntimeException(\n                    \"Exception happend while downloading files \"\n                    + \"for aux-service:\" + sName + \" and remote-file-path:\"\n                    + src + \".\\n\" + ex.getMessage());\n              }\n            }\n            s = AuxiliaryServiceWithCustomClassLoader.getInstance(\n                conf, className, dest.toString());\n          }\n          LOG.info(\"The aux service:\" + sName\n              + \" are using the custom classloader\");\n        } else {\n          Class<? extends AuxiliaryService> sClass = conf.getClass(\n              classKey, null, AuxiliaryService.class);\n\n          if (sClass == null) {\n            throw new RuntimeException(\"No class defined for \" + sName);\n          }\n          s = ReflectionUtils.newInstance(sClass, conf);\n        }\n        if (s == null) {\n          throw new RuntimeException(\"No object created for \" + sName);\n        }\n        // TODO better use s.getName()?\n        if(!sName.equals(s.getName())) {\n          LOG.warn(\"The Auxiliary Service named '\"+sName+\"' in the \"\n              +\"configuration is for \"+s.getClass()+\" which has \"\n              +\"a name of '\"+s.getName()+\"'. Because these are \"\n              +\"not the same tools trying to send ServiceData and read \"\n              +\"Service Meta Data may have issues unless the refer to \"\n              +\"the name in the config.\");\n        }\n        s.setAuxiliaryLocalPathHandler(auxiliaryLocalPathHandler);\n        addService(sName, s);\n        if (recoveryEnabled) {\n          Path storePath = new Path(stateStoreRoot, sName);\n          stateStoreFs.mkdirs(storePath, storeDirPerms);\n          s.setRecoveryPath(storePath);\n        }\n        s.init(conf);\n      } catch (RuntimeException e) {\n        LOG.error(\"Failed to initialize \" + sName, e);\n        throw e;\n      }\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.getRemoteFileContext": "  FileContext getRemoteFileContext(final URI path, Configuration conf) {\n    try {\n      return FileContext.getFileContext(path, conf);\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to access remote fs\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.validateAuxServiceName": "  private boolean validateAuxServiceName(String name) {\n    if (name == null || name.trim().isEmpty()) {\n      return false;\n    }\n    return p.matcher(name).matches();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.getLocalFileContext": "  FileContext getLocalFileContext(Configuration conf) {\n    try {\n      return FileContext.getLocalFSFileContext(conf);\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to access local fs\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.addService": "  protected final synchronized void addService(String name,\n      AuxiliaryService service) {\n    LOG.info(\"Adding auxiliary service \" +\n        service.getName() + \", \\\"\" + name + \"\\\"\");\n    serviceMap.put(name, service);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of {}\", this, e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      LOG.debug(\"Service: {} entered state {}\", getName(), getServiceState());\n\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    LOG.debug(\"noteFailure {}\" + exception);\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service {} failed in state {}\",\n            getName(), failureState, exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": initing services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      service.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit": "  public void serviceInit(Configuration conf) throws Exception {\n\n    LogHandler logHandler =\n      createLogHandler(conf, this.context, this.deletionService);\n    addIfService(logHandler);\n    dispatcher.register(LogHandlerEventType.class, logHandler);\n    \n    // add the shared cache upload service (it will do nothing if the shared\n    // cache is disabled)\n    SharedCacheUploadService sharedCacheUploader =\n        createSharedCacheUploaderService();\n    addService(sharedCacheUploader);\n    dispatcher.register(SharedCacheUploadEventType.class, sharedCacheUploader);\n\n    createAMRMProxyService(conf);\n\n    waitForContainersOnShutdownMillis =\n        conf.getLong(YarnConfiguration.NM_SLEEP_DELAY_BEFORE_SIGKILL_MS,\n            YarnConfiguration.DEFAULT_NM_SLEEP_DELAY_BEFORE_SIGKILL_MS) +\n        conf.getLong(YarnConfiguration.NM_PROCESS_KILL_WAIT_MS,\n            YarnConfiguration.DEFAULT_NM_PROCESS_KILL_WAIT_MS) +\n        SHUTDOWN_CLEANUP_SLOP_MS;\n\n    super.serviceInit(conf);\n    recover();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover": "  private void recover() throws IOException, URISyntaxException {\n    NMStateStoreService stateStore = context.getNMStateStore();\n    if (stateStore.canRecover()) {\n      rsrcLocalizationSrvc.recoverLocalizedResources(\n          stateStore.loadLocalizationState());\n\n      RecoveredApplicationsState appsState = stateStore.loadApplicationsState();\n      for (ContainerManagerApplicationProto proto :\n           appsState.getApplications()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Recovering application with state: \" + proto.toString());\n        }\n        recoverApplication(proto);\n      }\n\n      for (RecoveredContainerState rcs : stateStore.loadContainersState()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Recovering container with state: \" + rcs);\n        }\n        recoverContainer(rcs);\n      }\n\n      // Recovery AMRMProxy state after apps and containers are recovered\n      if (this.amrmProxyEnabled) {\n        this.getAMRMProxyService().recover();\n      }\n\n      //Dispatching the RECOVERY_COMPLETED event through the dispatcher\n      //so that all the paused, scheduled and queued containers will\n      //be scheduled for execution on availability of resources.\n      dispatcher.getEventHandler().handle(\n          new ContainerSchedulerEvent(null,\n              ContainerSchedulerEventType.RECOVERY_COMPLETED));\n    } else {\n      LOG.info(\"Not a recoverable state store. Nothing to recover.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createAMRMProxyService": "  protected void createAMRMProxyService(Configuration conf) {\n    this.amrmProxyEnabled =\n        conf.getBoolean(YarnConfiguration.AMRM_PROXY_ENABLED,\n            YarnConfiguration.DEFAULT_AMRM_PROXY_ENABLED) ||\n            conf.getBoolean(YarnConfiguration.DIST_SCHEDULING_ENABLED,\n                YarnConfiguration.DEFAULT_DIST_SCHEDULING_ENABLED);\n\n    if (amrmProxyEnabled) {\n      LOG.info(\"AMRMProxyService is enabled. \"\n          + \"All the AM->RM requests will be intercepted by the proxy\");\n      this.setAMRMProxyService(\n          new AMRMProxyService(this.context, this.dispatcher));\n      addService(this.getAMRMProxyService());\n    } else {\n      LOG.info(\"AMRMProxyService is disabled\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createLogHandler": "  protected LogHandler createLogHandler(Configuration conf, Context context,\n      DeletionService deletionService) {\n    if (conf.getBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED,\n        YarnConfiguration.DEFAULT_LOG_AGGREGATION_ENABLED)) {\n      return new LogAggregationService(this.dispatcher, context,\n          deletionService, dirsHandler);\n    } else {\n      return new NonAggregatingLogHandler(this.dispatcher, deletionService,\n                                          dirsHandler,\n                                          context.getNMStateStore());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createSharedCacheUploaderService": "  protected SharedCacheUploadService createSharedCacheUploaderService() {\n    return new SharedCacheUploadService();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    rmWorkPreservingRestartEnabled = conf.getBoolean(YarnConfiguration\n            .RM_WORK_PRESERVING_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_ENABLED);\n\n    try {\n      initAndStartRecoveryStore(conf);\n    } catch (IOException e) {\n      String recoveryDirName = conf.get(YarnConfiguration.NM_RECOVERY_DIR);\n      throw new\n          YarnRuntimeException(\"Unable to initialize recovery directory at \"\n              + recoveryDirName, e);\n    }\n\n    NMContainerTokenSecretManager containerTokenSecretManager =\n        new NMContainerTokenSecretManager(conf, nmStore);\n\n    NMTokenSecretManagerInNM nmTokenSecretManager =\n        new NMTokenSecretManagerInNM(nmStore);\n\n    recoverTokens(nmTokenSecretManager, containerTokenSecretManager);\n    \n    this.aclsManager = new ApplicationACLsManager(conf);\n\n    this.dirsHandler = new LocalDirsHandlerService(metrics);\n\n    boolean isDistSchedulingEnabled =\n        conf.getBoolean(YarnConfiguration.DIST_SCHEDULING_ENABLED,\n            YarnConfiguration.DEFAULT_DIST_SCHEDULING_ENABLED);\n\n    this.context = createNMContext(containerTokenSecretManager,\n        nmTokenSecretManager, nmStore, isDistSchedulingEnabled, conf);\n\n    ResourcePluginManager pluginManager = createResourcePluginManager();\n    pluginManager.initialize(context);\n    ((NMContext)context).setResourcePluginManager(pluginManager);\n\n    ContainerExecutor exec = createContainerExecutor(conf);\n    try {\n      exec.init(context);\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to initialize container executor\", e);\n    }    \n    DeletionService del = createDeletionService(exec);\n    addService(del);\n\n    // NodeManager level dispatcher\n    this.dispatcher = new AsyncDispatcher(\"NM Event dispatcher\");\n\n    nodeHealthChecker =\n        new NodeHealthCheckerService(\n            getNodeHealthScriptRunner(conf), dirsHandler);\n    addService(nodeHealthChecker);\n\n\n    ((NMContext)context).setContainerExecutor(exec);\n    ((NMContext)context).setDeletionService(del);\n\n    nodeLabelsProvider = createNodeLabelsProvider(conf);\n\n    if (null == nodeLabelsProvider) {\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker);\n    } else {\n      addIfService(nodeLabelsProvider);\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker,\n              nodeLabelsProvider);\n    }\n\n    nodeResourceMonitor = createNodeResourceMonitor();\n    addService(nodeResourceMonitor);\n    ((NMContext) context).setNodeResourceMonitor(nodeResourceMonitor);\n\n    containerManager =\n        createContainerManager(context, exec, del, nodeStatusUpdater,\n        this.aclsManager, dirsHandler);\n    addService(containerManager);\n    ((NMContext) context).setContainerManager(containerManager);\n\n    this.nmLogAggregationStatusTracker = createNMLogAggregationStatusTracker(\n        context);\n    addService(nmLogAggregationStatusTracker);\n    ((NMContext)context).setNMLogAggregationStatusTracker(\n        this.nmLogAggregationStatusTracker);\n\n    WebServer webServer = createWebServer(context, containerManager\n        .getContainersMonitor(), this.aclsManager, dirsHandler);\n    addService(webServer);\n    ((NMContext) context).setWebServer(webServer);\n\n    ((NMContext) context).setQueueableContainerAllocator(\n        new OpportunisticContainerAllocator(\n            context.getContainerTokenSecretManager()));\n\n    dispatcher.register(ContainerManagerEventType.class, containerManager);\n    dispatcher.register(NodeManagerEventType.class, this);\n    addService(dispatcher);\n\n    pauseMonitor = new JvmPauseMonitor();\n    addService(pauseMonitor);\n    metrics.getJvmMetrics().setPauseMonitor(pauseMonitor);\n\n    DefaultMetricsSystem.initialize(\"NodeManager\");\n\n    if (YarnConfiguration.timelineServiceV2Enabled(conf)) {\n      this.nmCollectorService = createNMCollectorService(context);\n      addService(nmCollectorService);\n    }\n\n    // StatusUpdater should be added last so that it get started last \n    // so that we make sure everything is up before registering with RM. \n    addService(nodeStatusUpdater);\n    ((NMContext) context).setNodeStatusUpdater(nodeStatusUpdater);\n    nmStore.setNodeStatusUpdater(nodeStatusUpdater);\n\n    // Do secure login before calling init for added services.\n    try {\n      doSecureLogin();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed NodeManager login\", e);\n    }\n\n    super.serviceInit(conf);\n    // TODO add local dirs to del\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createContainerExecutor": "  protected ContainerExecutor createContainerExecutor(Configuration conf) {\n    return ReflectionUtils.newInstance(\n        conf.getClass(YarnConfiguration.NM_CONTAINER_EXECUTOR,\n            DefaultContainerExecutor.class, ContainerExecutor.class), conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMCollectorService": "  protected NMCollectorService createNMCollectorService(Context ctxt) {\n    return new NMCollectorService(ctxt);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMContext": "  protected NMContext createNMContext(\n      NMContainerTokenSecretManager containerTokenSecretManager,\n      NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMStateStoreService stateStore, boolean isDistSchedulerEnabled,\n      Configuration conf) {\n    List<ContainerStateTransitionListener> listeners =\n        conf.getInstances(\n            YarnConfiguration.NM_CONTAINER_STATE_TRANSITION_LISTENERS,\n        ContainerStateTransitionListener.class);\n    NMContext nmContext = new NMContext(containerTokenSecretManager,\n        nmTokenSecretManager, dirsHandler, aclsManager, stateStore,\n        isDistSchedulerEnabled, conf);\n    nmContext.setNodeManagerMetrics(metrics);\n    DefaultContainerStateListener defaultListener =\n        new DefaultContainerStateListener();\n    nmContext.setContainerStateTransitionListener(defaultListener);\n    defaultListener.init(nmContext);\n    for (ContainerStateTransitionListener listener : listeners) {\n      listener.init(nmContext);\n      defaultListener.addListener(listener);\n    }\n    return nmContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.recoverTokens": "  private void recoverTokens(NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMContainerTokenSecretManager containerTokenSecretManager)\n          throws IOException {\n    if (nmStore.canRecover()) {\n      nmTokenSecretManager.recover();\n      containerTokenSecretManager.recover();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartRecoveryStore": "  private void initAndStartRecoveryStore(Configuration conf)\n      throws IOException {\n    boolean recoveryEnabled = conf.getBoolean(\n        YarnConfiguration.NM_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_NM_RECOVERY_ENABLED);\n    if (recoveryEnabled) {\n      FileSystem recoveryFs = FileSystem.getLocal(conf);\n      String recoveryDirName = conf.get(YarnConfiguration.NM_RECOVERY_DIR);\n      if (recoveryDirName == null) {\n        throw new IllegalArgumentException(\"Recovery is enabled but \" +\n            YarnConfiguration.NM_RECOVERY_DIR + \" is not set.\");\n      }\n      Path recoveryRoot = new Path(recoveryDirName);\n      recoveryFs.mkdirs(recoveryRoot, new FsPermission((short)0700));\n      nmStore = new NMLeveldbStateStoreService();\n    } else {\n      nmStore = new NMNullStateStoreService();\n    }\n    nmStore.init(conf);\n    nmStore.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeStatusUpdater": "  protected NodeStatusUpdater createNodeStatusUpdater(Context context,\n      Dispatcher dispatcher, NodeHealthCheckerService healthChecker,\n      NodeLabelsProvider nodeLabelsProvider) {\n    return new NodeStatusUpdaterImpl(context, dispatcher, healthChecker,\n        metrics, nodeLabelsProvider);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.init": "    public void init(Context context) {}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createWebServer": "  protected WebServer createWebServer(Context nmContext,\n      ResourceView resourceView, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new WebServer(nmContext, resourceView, aclsManager, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.setNodeStatusUpdater": "    public void setNodeStatusUpdater(NodeStatusUpdater nodeStatusUpdater) {\n      this.nodeStatusUpdater = nodeStatusUpdater;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.doSecureLogin": "  protected void doSecureLogin() throws IOException {\n    SecurityUtil.login(getConfig(), YarnConfiguration.NM_KEYTAB,\n        YarnConfiguration.NM_PRINCIPAL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createContainerManager": "  protected ContainerManagerImpl createContainerManager(Context context,\n      ContainerExecutor exec, DeletionService del,\n      NodeStatusUpdater nodeStatusUpdater, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new ContainerManagerImpl(context, exec, del, nodeStatusUpdater,\n        metrics, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createDeletionService": "  protected DeletionService createDeletionService(ContainerExecutor exec) {\n    return new DeletionService(exec, nmStore);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createResourcePluginManager": "  protected ResourcePluginManager createResourcePluginManager() {\n    return new ResourcePluginManager();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeResourceMonitor": "  protected NodeResourceMonitor createNodeResourceMonitor() {\n    return new NodeResourceMonitorImpl(context);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeLabelsProvider": "  protected NodeLabelsProvider createNodeLabelsProvider(Configuration conf)\n      throws IOException {\n    NodeLabelsProvider provider = null;\n    String providerString =\n        conf.get(YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG, null);\n    if (providerString == null || providerString.trim().length() == 0) {\n      // Seems like Distributed Node Labels configuration is not enabled\n      return provider;\n    }\n    switch (providerString.trim().toLowerCase()) {\n    case YarnConfiguration.CONFIG_NODE_LABELS_PROVIDER:\n      provider = new ConfigurationNodeLabelsProvider();\n      break;\n    case YarnConfiguration.SCRIPT_NODE_LABELS_PROVIDER:\n      provider = new ScriptBasedNodeLabelsProvider();\n      break;\n    default:\n      try {\n        Class<? extends NodeLabelsProvider> labelsProviderClass =\n            conf.getClass(YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG,\n                null, NodeLabelsProvider.class);\n        provider = labelsProviderClass.newInstance();\n      } catch (InstantiationException | IllegalAccessException\n          | RuntimeException e) {\n        LOG.error(\"Failed to create NodeLabelsProvider based on Configuration\",\n            e);\n        throw new IOException(\n            \"Failed to create NodeLabelsProvider : \" + e.getMessage(), e);\n      }\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Distributed Node Labels is enabled\"\n          + \" with provider class as : \" + provider.getClass().toString());\n    }\n    return provider;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.getNodeHealthScriptRunner": "  public static NodeHealthScriptRunner getNodeHealthScriptRunner(Configuration conf) {\n    String nodeHealthScript = \n        conf.get(YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_PATH);\n    if(!NodeHealthScriptRunner.shouldRun(nodeHealthScript)) {\n      LOG.info(\"Node Manager health check script is not available \"\n          + \"or doesn't have execute permission, so not \"\n          + \"starting the node health script runner.\");\n      return null;\n    }\n    long nmCheckintervalTime = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS);\n    long scriptTimeout = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS);\n    String[] scriptArgs = conf.getStrings(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_OPTS, new String[] {});\n    return new NodeHealthScriptRunner(nodeHealthScript,\n        nmCheckintervalTime, scriptTimeout, scriptArgs);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMLogAggregationStatusTracker": "  private NMLogAggregationStatusTracker createNMLogAggregationStatusTracker(\n      Context ctxt) {\n    return new NMLogAggregationStatusTracker(ctxt);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager": "  private void initAndStartNodeManager(Configuration conf, boolean hasToReboot) {\n    try {\n      // Failed to start if we're a Unix based system but we don't have bash.\n      // Bash is necessary to launch containers under Unix-based systems.\n      if (!Shell.WINDOWS) {\n        if (!Shell.checkIsBashSupported()) {\n          String message =\n              \"Failing NodeManager start since we're on a \"\n                  + \"Unix-based system but bash doesn't seem to be available.\";\n          LOG.error(message);\n          throw new YarnRuntimeException(message);\n        }\n      }\n\n      // Remove the old hook if we are rebooting.\n      if (hasToReboot && null != nodeManagerShutdownHook) {\n        ShutdownHookManager.get().removeShutdownHook(nodeManagerShutdownHook);\n      }\n\n      nodeManagerShutdownHook = new CompositeServiceShutdownHook(this);\n      ShutdownHookManager.get().addShutdownHook(nodeManagerShutdownHook,\n                                                SHUTDOWN_HOOK_PRIORITY);\n      // System exit should be called only when NodeManager is instantiated from\n      // main() funtion\n      this.shouldExitOnShutdownEvent = true;\n      this.init(conf);\n      this.start();\n    } catch (Throwable t) {\n      LOG.error(\"Error starting NodeManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.main": "  public static void main(String[] args) throws IOException {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(NodeManager.class, args, LOG);\n    @SuppressWarnings(\"resource\")\n    NodeManager nodeManager = new NodeManager();\n    Configuration conf = new YarnConfiguration();\n    new GenericOptionsParser(conf, args);\n    nodeManager.initAndStartNodeManager(conf, false);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Logger log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service {}\", service.getName(), e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.init": "  void init(Configuration config);\n\n\n  /**\n   * Start the service.\n   *\n   * The transition MUST be from {@link STATE#INITED} to {@link STATE#STARTED}"
        },
        "bug_report": {
            "Title": "ClassNotFoundException when auxiliary service is loaded from HDFS",
            "Description": "Loading an auxiliary jar from a local location on a node manager works as expected,\r\n{noformat}\r\n2018-04-26 15:09:26,179 INFO  util.ApplicationClassLoader (ApplicationClassLoader.java:<init>(98)) - classpath: [file:/grid/0/hadoop/yarn/local/aux-service-local.jar]\r\n2018-04-26 15:09:26,179 INFO  util.ApplicationClassLoader (ApplicationClassLoader.java:<init>(99)) - system classes: [java., javax.accessibility., javax.activation., javax.activity., javax.annotation., javax.annotation.processing., javax.crypto., javax.imageio., javax.jws., javax.lang.model., -javax.management.j2ee., javax.management., javax.naming., javax.net., javax.print., javax.rmi., javax.script., -javax.security.auth.message., javax.security.auth., javax.security.cert., javax.security.sasl., javax.sound., javax.sql., javax.swing., javax.tools., javax.transaction., -javax.xml.registry., -javax.xml.rpc., javax.xml., org.w3c.dom., org.xml.sax., org.apache.commons.logging., org.apache.log4j., -org.apache.hadoop.hbase., org.apache.hadoop., core-default.xml, hdfs-default.xml, mapred-default.xml, yarn-default.xml]\r\n2018-04-26 15:09:26,181 INFO  containermanager.AuxServices (AuxServices.java:serviceInit(252)) - The aux service:test_aux_local are using the custom classloader\r\n2018-04-26 15:09:26,182 WARN  containermanager.AuxServices (AuxServices.java:serviceInit(268)) - The Auxiliary Service named 'test_aux_local' in the configuration is for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxiliaryServiceWithCustomClassLoader which has a name of 'org.apache.auxtest.AuxServiceFromLocal with custom class loader'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.\r\n2018-04-26 15:09:26,182 INFO  containermanager.AuxServices (AuxServices.java:addService(103)) - Adding auxiliary service org.apache.auxtest.AuxServiceFromLocal with custom class loader, \"test_aux_local\"{noformat}\r\nBut loading the same jar from a location on HDFS fails with a ClassNotFoundException.\r\n{noformat}\r\n018-04-26 15:14:39,683 INFO  util.ApplicationClassLoader (ApplicationClassLoader.java:<init>(98)) - classpath: []\r\n2018-04-26 15:14:39,683 INFO  util.ApplicationClassLoader (ApplicationClassLoader.java:<init>(99)) - system classes: [java., javax.accessibility., javax.activation., javax.activity., javax.annotation., javax.annotation.processing., javax.crypto., javax.imageio., javax.jws., javax.lang.model., -javax.management.j2ee., javax.management., javax.naming., javax.net., javax.print., javax.rmi., javax.script., -javax.security.auth.message., javax.security.auth., javax.security.cert., javax.security.sasl., javax.sound., javax.sql., javax.swing., javax.tools., javax.transaction., -javax.xml.registry., -javax.xml.rpc., javax.xml., org.w3c.dom., org.xml.sax., org.apache.commons.logging., org.apache.log4j., -org.apache.hadoop.hbase., org.apache.hadoop., core-default.xml, hdfs-default.xml, mapred-default.xml, yarn-default.xml]\r\n2018-04-26 15:14:39,687 INFO  service.AbstractService (AbstractService.java:noteFailure(267)) - Service org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices failed in state INITED\r\njava.lang.ClassNotFoundException: org.apache.auxtest.AuxServiceFromLocal\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat org.apache.hadoop.util.ApplicationClassLoader.loadClass(ApplicationClassLoader.java:189)\r\n\tat org.apache.hadoop.util.ApplicationClassLoader.loadClass(ApplicationClassLoader.java:157)\r\n\tat java.lang.Class.forName0(Native Method)\r\n\tat java.lang.Class.forName(Class.java:348)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxiliaryServiceWithCustomClassLoader.getInstance(AuxiliaryServiceWithCustomClassLoader.java:169)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:249)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:472)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:918)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:979)\r\n{noformat}\r\nThe difference between the 2 logs is the classpath variable in the 1st line of the log is empty in the HDFS case. It doesn't have the URL/filename of the jar file specified in the config.\u00a0"
        }
    },
    {
        "filename": "YARN-8331.json",
        "creation_time": "2018-05-21T05:19:35.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: CONTAINER_LAUNCHED at DONE\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$500(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:487)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:2104)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:104)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1525)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1518)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\n\tat java.lang.Thread.run(Thread.java:748)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      listener.preTransition(operand, currentState, event);\n      STATE oldState = currentState;\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      listener.postTransition(operand, oldState, currentState, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.postTransition": "    public void postTransition(Object op, Enum beforeState, Enum afterState,\n        Object processedEvent) { }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.preTransition": "    public void preTransition(Object op, Enum beforeState,\n        Object eventToBeProcessed) { }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle": "  public void handle(ContainerEvent event) {\n    try {\n      this.writeLock.lock();\n\n      ContainerId containerID = event.getContainerID();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing \" + containerID + \" of type \" + event.getType());\n      }\n      ContainerState oldState = stateMachine.getCurrentState();\n      ContainerState newState = null;\n      try {\n        newState =\n            stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.warn(\"Can't handle this event at current state: Current: [\"\n            + oldState + \"], eventType: [\" + event.getType() + \"],\" +\n            \" container: [\" + containerID + \"]\", e);\n      }\n      if (newState != null && oldState != newState) {\n        LOG.info(\"Container \" + containerID + \" transitioned from \"\n            + oldState\n            + \" to \" + newState);\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getCurrentState": "  public org.apache.hadoop.yarn.api.records.ContainerState getCurrentState() {\n    switch (stateMachine.getCurrentState()) {\n    case NEW:\n    case LOCALIZING:\n    case LOCALIZATION_FAILED:\n    case SCHEDULED:\n    case PAUSED:\n    case RESUMING:\n    case RUNNING:\n    case RELAUNCHING:\n    case REINITIALIZING:\n    case REINITIALIZING_AWAITING_KILL:\n    case EXITED_WITH_SUCCESS:\n    case EXITED_WITH_FAILURE:\n    case KILLING:\n    case CONTAINER_CLEANEDUP_AFTER_KILL:\n    case CONTAINER_RESOURCES_CLEANINGUP:\n    case PAUSING:\n      return org.apache.hadoop.yarn.api.records.ContainerState.RUNNING;\n    case DONE:\n    default:\n      return org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        Application app = this.context.getApplications().get(appID);\n        if (app == null) {\n          LOG.info(\"couldn't find application \" + appID + \" while processing\"\n              + \" FINISH_APPS event. The ResourceManager allocated resources\"\n              + \" for this application to the NodeManager but no active\"\n              + \" containers were found to process.\");\n          continue;\n        }\n\n        boolean shouldDropEvent = false;\n        for (Container container : app.getContainers().values()) {\n          if (container.isRecovering()) {\n            LOG.info(\"drop FINISH_APPS event to \" + appID + \" because \"\n                + \"container \" + container.getContainerId()\n                + \" is recovering\");\n            shouldDropEvent = true;\n            break;\n          }\n        }\n        if (shouldDropEvent) {\n          continue;\n        }\n\n        String diagnostic = \"\";\n        if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Application killed on shutdown\";\n        } else if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Application killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                diagnostic));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId containerId : containersFinishedEvent\n          .getContainersToCleanup()) {\n        ApplicationId appId =\n            containerId.getApplicationAttemptId().getApplicationId();\n        Application app = this.context.getApplications().get(appId);\n        if (app == null) {\n          LOG.warn(\"couldn't find app \" + appId + \" while processing\"\n              + \" FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        Container container = app.getContainers().get(containerId);\n        if (container == null) {\n          LOG.warn(\"couldn't find container \" + containerId\n              + \" while processing FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        if (container.isRecovering()) {\n          LOG.info(\"drop FINISH_CONTAINERS event to \" + containerId\n              + \" because container is recovering\");\n          continue;\n        }\n\n        this.dispatcher.getEventHandler().handle(\n              new ContainerKillEvent(containerId,\n                  ContainerExitStatus.KILLED_BY_RESOURCEMANAGER,\n                  \"Container Killed by ResourceManager\"));\n      }\n      break;\n    case UPDATE_CONTAINERS:\n      CMgrUpdateContainersEvent containersDecreasedEvent =\n          (CMgrUpdateContainersEvent) event;\n      for (org.apache.hadoop.yarn.api.records.Container container\n          : containersDecreasedEvent.getContainersToUpdate()) {\n        try {\n          ContainerTokenIdentifier containerTokenIdentifier =\n              BuilderUtils.newContainerTokenIdentifier(\n                  container.getContainerToken());\n          updateContainerInternal(container.getId(),\n              containerTokenIdentifier);\n        } catch (YarnException e) {\n          LOG.error(\"Unable to decrease container resource\", e);\n        } catch (IOException e) {\n          LOG.error(\"Unable to update container resource in store\", e);\n        }\n      }\n      break;\n    case SIGNAL_CONTAINERS:\n      CMgrSignalContainersEvent containersSignalEvent =\n          (CMgrSignalContainersEvent) event;\n      for (SignalContainerRequest request : containersSignalEvent\n          .getContainersToSignal()) {\n        internalSignalToContainer(request, \"ResourceManager\");\n      }\n      break;\n    default:\n        throw new YarnRuntimeException(\n            \"Got an unknown ContainerManagerEvent type: \" + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.updateContainerInternal": "  private void updateContainerInternal(ContainerId containerId,\n      ContainerTokenIdentifier containerTokenIdentifier)\n      throws YarnException, IOException {\n    Container container = context.getContainers().get(containerId);\n    // Check container existence\n    if (container == null) {\n      if (nodeStatusUpdater.isContainerRecentlyStopped(containerId)) {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" was recently stopped on node manager.\");\n      } else {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" is not handled by this NodeManager\");\n      }\n    }\n    // Check container version.\n    int currentVersion = container.getContainerTokenIdentifier().getVersion();\n    if (containerTokenIdentifier.getVersion() <= currentVersion) {\n      throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n          + \" has update version [\" + currentVersion + \"] >= requested version\"\n          + \" [\" + containerTokenIdentifier.getVersion() + \"]\");\n    }\n\n    // Check validity of the target resource.\n    Resource currentResource = container.getResource();\n    ExecutionType currentExecType =\n        container.getContainerTokenIdentifier().getExecutionType();\n    boolean isResourceChange = false;\n    boolean isExecTypeUpdate = false;\n    Resource targetResource = containerTokenIdentifier.getResource();\n    ExecutionType targetExecType = containerTokenIdentifier.getExecutionType();\n\n    // Is true if either the resources has increased or execution type\n    // updated from opportunistic to guaranteed\n    boolean isIncrease = false;\n    if (!currentResource.equals(targetResource)) {\n      isResourceChange = true;\n      isIncrease = Resources.fitsIn(currentResource, targetResource)\n          && !Resources.fitsIn(targetResource, currentResource);\n    } else if (!currentExecType.equals(targetExecType)) {\n      isExecTypeUpdate = true;\n      isIncrease = currentExecType == ExecutionType.OPPORTUNISTIC &&\n          targetExecType == ExecutionType.GUARANTEED;\n    }\n    if (isIncrease) {\n      org.apache.hadoop.yarn.api.records.Container increasedContainer = null;\n      if (isResourceChange) {\n        increasedContainer =\n            org.apache.hadoop.yarn.api.records.Container.newInstance(\n                containerId, null, null, targetResource, null, null,\n                currentExecType);\n        if (context.getIncreasedContainers().putIfAbsent(containerId,\n            increasedContainer) != null){\n          throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n              + \" resource is being increased -or- \" +\n              \"is undergoing ExecutionType promoted.\");\n        }\n      }\n    }\n    this.readLock.lock();\n    try {\n      if (!serviceStopped) {\n        // Dispatch message to Container to actually\n        // make the change.\n        dispatcher.getEventHandler().handle(new UpdateContainerTokenEvent(\n            container.getContainerId(), containerTokenIdentifier,\n            isResourceChange, isExecTypeUpdate, isIncrease));\n      } else {\n        throw new YarnException(\n            \"Unable to change container resource as the NodeManager is \"\n                + \"in the process of shutting down\");\n      }\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.internalSignalToContainer": "  private void internalSignalToContainer(SignalContainerRequest request,\n      String sentBy) {\n    ContainerId containerId = request.getContainerId();\n    Container container = this.context.getContainers().get(containerId);\n    if (container != null) {\n      LOG.info(containerId + \" signal request \" + request.getCommand()\n            + \" by \" + sentBy);\n      this.dispatcher.getEventHandler().handle(\n          new SignalContainersLauncherEvent(container,\n              request.getCommand()));\n    } else {\n      LOG.info(\"Container \" + containerId + \" no longer exists\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Race condition in NM container launched after done",
            "Description": "When a container is launching, in ContainerLaunch#launchContainer, state is SCHEDULED,\r\nkill event was sent to this container, state : SCHEDULED->KILLING->DONE\r\n Then ContainerLaunch send CONTAINER_LAUNCHED event and start the container processes. These absent container processes will not be cleaned up anymore.\r\n\r\n\u00a0\r\n{code:java}\r\n2018-05-21 13:11:56,114 INFO  [Thread-11] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=nobody\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_0_0000\tCONTAINERID=container_0_0000_01_000000\r\n2018-05-21 13:11:56,114 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(632)) - Application application_0_0000 transitioned from NEW to INITING\r\n2018-05-21 13:11:56,114 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(446)) - Adding container_0_0000_01_000000 to application application_0_0000\r\n2018-05-21 13:11:56,118 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:handle(632)) - Application application_0_0000 transitioned from INITING to RUNNING\r\n2018-05-21 13:11:56,119 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2111)) - Container container_0_0000_01_000000 transitioned from NEW to SCHEDULED\r\n2018-05-21 13:11:56,119 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(220)) - Got event CONTAINER_INIT for appId application_0_0000\r\n2018-05-21 13:11:56,119 INFO  [NM ContainerManager dispatcher] scheduler.ContainerScheduler (ContainerScheduler.java:startContainer(504)) - Starting container [container_0_0000_01_000000]\r\n2018-05-21 13:11:56,226 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2111)) - Container container_0_0000_01_000000 transitioned from SCHEDULED to KILLING\r\n2018-05-21 13:11:56,227 INFO  [NM ContainerManager dispatcher] containermanager.TestContainerManager (BaseContainerManagerTest.java:delete(287)) - Psuedo delete: user - nobody, type - FILE\r\n2018-05-21 13:11:56,227 INFO  [NM ContainerManager dispatcher] nodemanager.NMAuditLogger (NMAuditLogger.java:logSuccess(94)) - USER=nobody\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_0_0000\tCONTAINERID=container_0_0000_01_000000\r\n2018-05-21 13:11:56,238 INFO  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2111)) - Container container_0_0000_01_000000 transitioned from KILLING to DONE\r\n2018-05-21 13:11:56,238 INFO  [NM ContainerManager dispatcher] application.ApplicationImpl (ApplicationImpl.java:transition(489)) - Removing container_0_0000_01_000000 from application application_0_0000\r\n2018-05-21 13:11:56,239 INFO  [NM ContainerManager dispatcher] monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:onStopMonitoringContainer(932)) - Stopping resource-monitoring for container_0_0000_01_000000\r\n2018-05-21 13:11:56,239 INFO  [NM ContainerManager dispatcher] containermanager.AuxServices (AuxServices.java:handle(220)) - Got event CONTAINER_STOP for appId application_0_0000\r\n2018-05-21 13:11:56,274 WARN  [NM ContainerManager dispatcher] container.ContainerImpl (ContainerImpl.java:handle(2106)) - Can't handle this event at current state: Current: [DONE], eventType: [CONTAINER_LAUNCHED], container: [container_0_0000_01_000000]\r\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: CONTAINER_LAUNCHED at DONE\r\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\r\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$500(StateMachineFactory.java:46)\r\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:487)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:2104)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:104)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1525)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1518)\r\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\r\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n{code}"
        }
    },
    {
        "filename": "YARN-2931.json",
        "creation_time": "2014-12-08T21:09:13.000+0000",
        "stack_trace": "```\njava.io.FileNotFoundException: File /data/yarn/nm/filecache does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:524)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:737)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:514)\n\tat org.apache.hadoop.fs.FileSystem.primitiveMkdir(FileSystem.java:1051)\n\tat org.apache.hadoop.fs.DelegateToFileSystem.mkdir(DelegateToFileSystem.java:162)\n\tat org.apache.hadoop.fs.FilterFs.mkdir(FilterFs.java:197)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:724)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:720)\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:720)\n\tat org.apache.hadoop.yarn.util.FSDownload.createDir(FSDownload.java:104)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:351)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:60)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus": "  private FileStatus deprecatedGetFileStatus(Path f) throws IOException {\n    File path = pathToFile(f);\n    if (path.exists()) {\n      return new DeprecatedRawLocalFileStatus(pathToFile(f),\n          getDefaultBlockSize(f), this);\n    } else {\n      throw new FileNotFoundException(\"File \" + f + \" does not exist\");\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.pathToFile": "  public File pathToFile(Path path) {\n    checkPath(path);\n    if (!path.isAbsolute()) {\n      path = new Path(getWorkingDirectory(), path);\n    }\n    return new File(path.toUri().getPath());\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal": "  private FileStatus getFileLinkStatusInternal(final Path f,\n      boolean dereference) throws IOException {\n    if (!useDeprecatedFileStatus) {\n      return getNativeFileLinkStatus(f, dereference);\n    } else if (dereference) {\n      return deprecatedGetFileStatus(f);\n    } else {\n      return deprecatedGetFileLinkStatusInternal(f);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal": "  private FileStatus deprecatedGetFileLinkStatusInternal(final Path f)\n      throws IOException {\n    String target = FileUtil.readLink(new File(f.toString()));\n\n    try {\n      FileStatus fs = getFileStatus(f);\n      // If f refers to a regular file or directory\n      if (target.isEmpty()) {\n        return fs;\n      }\n      // Otherwise f refers to a symlink\n      return new FileStatus(fs.getLen(),\n          false,\n          fs.getReplication(),\n          fs.getBlockSize(),\n          fs.getModificationTime(),\n          fs.getAccessTime(),\n          fs.getPermission(),\n          fs.getOwner(),\n          fs.getGroup(),\n          new Path(target),\n          f);\n    } catch (FileNotFoundException e) {\n      /* The exists method in the File class returns false for dangling\n       * links so we can get a FileNotFoundException for links that exist.\n       * It's also possible that we raced with a delete of the link. Use\n       * the readBasicFileAttributes method in java.nio.file.attributes\n       * when available.\n       */\n      if (!target.isEmpty()) {\n        return new FileStatus(0, false, 0, 0, 0, 0, FsPermission.getDefault(),\n            \"\", \"\", new Path(target), f);\n      }\n      // f refers to a file or directory that does not exist\n      throw e;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.getNativeFileLinkStatus": "  private FileStatus getNativeFileLinkStatus(final Path f,\n      boolean dereference) throws IOException {\n    checkPath(f);\n    Stat stat = new Stat(f, getDefaultBlockSize(f), dereference, this);\n    FileStatus status = stat.getFileStatus();\n    return status;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus": "  public FileStatus getFileStatus(Path f) throws IOException {\n    return getFileLinkStatusInternal(f, true);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.primitiveMkdir": "  protected void primitiveMkdir(Path f, FsPermission absolutePermission, \n                    boolean createParent)\n    throws IOException {\n    \n    if (!createParent) { // parent must exist.\n      // since the this.mkdirs makes parent dirs automatically\n      // we must throw exception if parent does not exist.\n      final FileStatus stat = getFileStatus(f.getParent());\n      if (stat == null) {\n        throw new FileNotFoundException(\"Missing parent:\" + f);\n      }\n      if (!stat.isDirectory()) {\n        throw new ParentNotDirectoryException(\"parent is not a dir\");\n      }\n      // parent does exist - go ahead with mkdir of leaf\n    }\n    // Default impl is to assume that permissions do not matter and hence\n    // calling the regular mkdirs is good enough.\n    // FSs that implement permissions should override this.\n    if (!this.mkdirs(f, absolutePermission)) {\n      throw new IOException(\"mkdir of \"+ f + \" failed\");\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.mkdirs": "  public abstract boolean mkdirs(Path f, FsPermission permission\n      ) throws IOException;\n\n  /**\n   * The src file is on the local disk.  Add it to FS at\n   * the given dst name and the source is kept intact afterwards\n   * @param src path\n   * @param dst path\n   */\n  public void copyFromLocalFile(Path src, Path dst)\n    throws IOException {\n    copyFromLocalFile(false, src, dst);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getFileStatus": "  public abstract FileStatus getFileStatus(Path f) throws IOException;\n\n  /**\n   * Checks if the user can access a path.  The mode specifies which access\n   * checks to perform.  If the requested permissions are granted, then the\n   * method returns normally.  If access is denied, then the method throws an\n   * {@link AccessControlException}.",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.isDirectory": "  public boolean isDirectory(Path f) throws IOException {\n    try {\n      return getFileStatus(f).isDirectory();\n    } catch (FileNotFoundException e) {\n      return false;               // f does not exist\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.DelegateToFileSystem.mkdir": "  public void mkdir(Path dir, FsPermission permission, boolean createParent)\n      throws IOException {\n    checkPath(dir);\n    fsImpl.primitiveMkdir(dir, permission, createParent);\n    \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FilterFs.mkdir": "  public void mkdir(Path dir, FsPermission permission, boolean createParent)\n    throws IOException, UnresolvedLinkException {\n    checkPath(dir);\n    myFs.mkdir(dir, permission, createParent);\n    \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FilterFs.checkPath": "  public void checkPath(Path path) {\n    myFs.checkPath(path);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FSLinkResolver.resolve": "  public T resolve(final FileContext fc, final Path path) throws IOException {\n    int count = 0;\n    T in = null;\n    Path p = path;\n    // NB: More than one AbstractFileSystem can match a scheme, eg \n    // \"file\" resolves to LocalFs but could have come by RawLocalFs.\n    AbstractFileSystem fs = fc.getFSofPath(p);\n\n    // Loop until all symlinks are resolved or the limit is reached\n    for (boolean isLink = true; isLink;) {\n      try {\n        in = next(fs, p);\n        isLink = false;\n      } catch (UnresolvedLinkException e) {\n        if (!fc.resolveSymlinks) {\n          throw new IOException(\"Path \" + path + \" contains a symlink\"\n              + \" and symlink resolution is disabled (\"\n              + CommonConfigurationKeys.FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY + \").\", e);\n        }\n        if (count++ > FsConstants.MAX_PATH_LINKS) {\n          throw new IOException(\"Possible cyclic loop while \" +\n                                \"following symbolic link \" + path);\n        }\n        // Resolve the first unresolved path component\n        p = qualifySymlinkTarget(fs.getUri(), p, fs.getLinkTarget(p));\n        fs = fc.getFSofPath(p);\n      }\n    }\n    return in;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FSLinkResolver.qualifySymlinkTarget": "  public static Path qualifySymlinkTarget(final URI pathURI,\n      Path pathWithLink, Path target) {\n    // NB: makeQualified uses the target's scheme and authority, if\n    // specified, and the scheme and authority of pathURI, if not.\n    final URI targetUri = target.toUri();\n    final String scheme = targetUri.getScheme();\n    final String auth = targetUri.getAuthority();\n    return (scheme == null && auth == null) ? target.makeQualified(pathURI,\n        pathWithLink.getParent()) : target;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FSLinkResolver.next": "  abstract public T next(final AbstractFileSystem fs, final Path p)\n      throws IOException, UnresolvedLinkException;\n\n  /**\n   * Performs the operation specified by the next function, calling it\n   * repeatedly until all symlinks in the given path are resolved.\n   * @param fc FileContext used to access file systems.\n   * @param path The path to resolve symlinks on.\n   * @return Generic type determined by the implementation of next.\n   * @throws IOException\n   */\n  public T resolve(final FileContext fc, final Path path) throws IOException {\n    int count = 0;\n    T in = null;\n    Path p = path;\n    // NB: More than one AbstractFileSystem can match a scheme, eg \n    // \"file\" resolves to LocalFs but could have come by RawLocalFs.\n    AbstractFileSystem fs = fc.getFSofPath(p);\n\n    // Loop until all symlinks are resolved or the limit is reached\n    for (boolean isLink = true; isLink;) {\n      try {\n        in = next(fs, p);\n        isLink = false;\n      } catch (UnresolvedLinkException e) {\n        if (!fc.resolveSymlinks) {\n          throw new IOException(\"Path \" + path + \" contains a symlink\"\n              + \" and symlink resolution is disabled (\"\n              + CommonConfigurationKeys.FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY + \").\", e);\n        }\n        if (count++ > FsConstants.MAX_PATH_LINKS) {\n          throw new IOException(\"Possible cyclic loop while \" +\n                                \"following symbolic link \" + path);\n        }\n        // Resolve the first unresolved path component\n        p = qualifySymlinkTarget(fs.getUri(), p, fs.getLinkTarget(p));\n        fs = fc.getFSofPath(p);\n      }\n    }\n    return in;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.createDir": "  private void createDir(Path path, FsPermission perm) throws IOException {\n    files.mkdir(path, perm, false);\n    if (!perm.equals(files.getUMask().applyUMask(perm))) {\n      files.setPermission(path, perm);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.call": "  public Path call() throws Exception {\n    final Path sCopy;\n    try {\n      sCopy = ConverterUtils.getPathFromYarnURL(resource.getResource());\n    } catch (URISyntaxException e) {\n      throw new IOException(\"Invalid resource\", e);\n    }\n    createDir(destDirPath, cachePerms);\n    final Path dst_work = new Path(destDirPath + \"_tmp\");\n    createDir(dst_work, cachePerms);\n    Path dFinal = files.makeQualified(new Path(dst_work, sCopy.getName()));\n    try {\n      Path dTmp = null == userUgi ? files.makeQualified(copy(sCopy, dst_work))\n          : userUgi.doAs(new PrivilegedExceptionAction<Path>() {\n            public Path run() throws Exception {\n              return files.makeQualified(copy(sCopy, dst_work));\n            };\n          });\n      unpack(new File(dTmp.toUri()), new File(dFinal.toUri()));\n      changePermissions(dFinal.getFileSystem(conf), dFinal);\n      files.rename(dst_work, destDirPath, Rename.OVERWRITE);\n    } catch (Exception e) {\n      try {\n        files.delete(destDirPath, true);\n      } catch (IOException ignore) {\n      }\n      throw e;\n    } finally {\n      try {\n        files.delete(dst_work, true);\n      } catch (FileNotFoundException ignore) {\n      }\n      conf = null;\n      resource = null;\n    }\n    return files.makeQualified(new Path(destDirPath, sCopy.getName()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.unpack": "  private long unpack(File localrsrc, File dst) throws IOException {\n    switch (resource.getType()) {\n    case ARCHIVE: {\n      String lowerDst = dst.getName().toLowerCase();\n      if (lowerDst.endsWith(\".jar\")) {\n        RunJar.unJar(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".zip\")) {\n        FileUtil.unZip(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".tar.gz\") ||\n                 lowerDst.endsWith(\".tgz\") ||\n                 lowerDst.endsWith(\".tar\")) {\n        FileUtil.unTar(localrsrc, dst);\n      } else {\n        LOG.warn(\"Cannot unpack \" + localrsrc);\n        if (!localrsrc.renameTo(dst)) {\n            throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + dst + \"]\");\n        }\n      }\n    }\n    break;\n    case PATTERN: {\n      String lowerDst = dst.getName().toLowerCase();\n      if (lowerDst.endsWith(\".jar\")) {\n        String p = resource.getPattern();\n        RunJar.unJar(localrsrc, dst,\n            p == null ? RunJar.MATCH_ANY : Pattern.compile(p));\n        File newDst = new File(dst, dst.getName());\n        if (!dst.exists() && !dst.mkdir()) {\n          throw new IOException(\"Unable to create directory: [\" + dst + \"]\");\n        }\n        if (!localrsrc.renameTo(newDst)) {\n          throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + newDst + \"]\");\n        }\n      } else if (lowerDst.endsWith(\".zip\")) {\n        LOG.warn(\"Treating [\" + localrsrc + \"] as an archive even though it \" +\n        \t\t\"was specified as PATTERN\");\n        FileUtil.unZip(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".tar.gz\") ||\n                 lowerDst.endsWith(\".tgz\") ||\n                 lowerDst.endsWith(\".tar\")) {\n        LOG.warn(\"Treating [\" + localrsrc + \"] as an archive even though it \" +\n        \"was specified as PATTERN\");\n        FileUtil.unTar(localrsrc, dst);\n      } else {\n        LOG.warn(\"Cannot unpack \" + localrsrc);\n        if (!localrsrc.renameTo(dst)) {\n          throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + dst + \"]\");\n        }\n      }\n    }\n    break;\n    case FILE:\n    default:\n      if (!localrsrc.renameTo(dst)) {\n        throw new IOException(\"Unable to rename file: [\" + localrsrc\n          + \"] to [\" + dst + \"]\");\n      }\n      break;\n    }\n    if(localrsrc.isFile()){\n      try {\n        files.delete(new Path(localrsrc.toString()), false);\n      } catch (IOException ignore) {\n      }\n    }\n    return 0;\n    // TODO Should calculate here before returning\n    //return FileUtil.getDU(destDir);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.changePermissions": "  private void changePermissions(FileSystem fs, final Path path)\n      throws IOException, InterruptedException {\n    File f = new File(path.toUri());\n    if (FileUtils.isSymlink(f)) {\n      // avoid following symlinks when changing permissions\n      return;\n    }\n    boolean isDir = f.isDirectory();\n    FsPermission perm = cachePerms;\n    // set public perms as 755 or 555 based on dir or file\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      perm = isDir ? PUBLIC_DIR_PERMS : PUBLIC_FILE_PERMS;\n    }\n    // set private perms as 700 or 500\n    else {\n      // PRIVATE:\n      // APPLICATION:\n      perm = isDir ? PRIVATE_DIR_PERMS : PRIVATE_FILE_PERMS;\n    }\n    LOG.debug(\"Changing permissions for path \" + path\n        + \" to perm \" + perm);\n    final FsPermission fPerm = perm;\n    if (null == userUgi) {\n      files.setPermission(path, perm);\n    }\n    else {\n      userUgi.doAs(new PrivilegedExceptionAction<Void>() {\n        public Void run() throws Exception {\n          files.setPermission(path, fPerm);\n          return null;\n        }\n      });\n    }\n    if (isDir) {\n      FileStatus[] statuses = fs.listStatus(path);\n      for (FileStatus status : statuses) {\n        changePermissions(fs, status.getPath());\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.getResource": "  LocalResource getResource() {\n    return resource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.copy": "  private Path copy(Path sCopy, Path dstdir) throws IOException {\n    FileSystem sourceFs = sCopy.getFileSystem(conf);\n    Path dCopy = new Path(dstdir, \"tmp_\"+sCopy.getName());\n    FileStatus sStat = sourceFs.getFileStatus(sCopy);\n    if (sStat.getModificationTime() != resource.getTimestamp()) {\n      throw new IOException(\"Resource \" + sCopy +\n          \" changed on src filesystem (expected \" + resource.getTimestamp() +\n          \", was \" + sStat.getModificationTime());\n    }\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      if (!isPublic(sourceFs, sCopy, sStat, statCache)) {\n        throw new IOException(\"Resource \" + sCopy +\n            \" is not publicly accessable and as such cannot be part of the\" +\n            \" public cache.\");\n      }\n    }\n\n    FileUtil.copy(sourceFs, sStat, FileSystem.getLocal(conf), dCopy, false,\n        true, conf);\n    return dCopy;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.getLinkTarget": "  public Path getLinkTarget(final Path f) throws IOException {\n    throw new AssertionError(\"Implementation Error: \" + getClass()\n        + \" that threw an UnresolvedLinkException, causing this method to be\"\n        + \" called, needs to override this method.\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.getUri": "  public URI getUri() {\n    return myUri;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.checkScheme": "  public void checkScheme(URI uri, String supportedScheme) {\n    String scheme = uri.getScheme();\n    if (scheme == null) {\n      throw new HadoopIllegalArgumentException(\"Uri without scheme: \" + uri);\n    }\n    if (!scheme.equals(supportedScheme)) {\n      throw new HadoopIllegalArgumentException(\"Uri scheme \" + uri\n          + \" does not match the scheme \" + supportedScheme);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.ConverterUtils.getPathFromYarnURL": "  public static Path getPathFromYarnURL(URL url) throws URISyntaxException {\n    String scheme = url.getScheme() == null ? \"\" : url.getScheme();\n    \n    String authority = \"\";\n    if (url.getHost() != null) {\n      authority = url.getHost();\n      if (url.getUserInfo() != null) {\n        authority = url.getUserInfo() + \"@\" + authority;\n      }\n      if (url.getPort() > 0) {\n        authority += \":\" + url.getPort();\n      }\n    }\n    \n    return new Path(\n        (new URI(scheme, authority, url.getFile(), null, null)).normalize());\n  }"
        },
        "bug_report": {
            "Title": "PublicLocalizer may fail until directory is initialized by LocalizeRunner",
            "Description": "When the data directory is cleaned up and NM is started with existing recovery state, because of YARN-90, it will not recreate the local dirs.\nThis causes a PublicLocalizer to fail until getInitializedLocalDirs is called due to some LocalizeRunner for private localization.\n\nExample error \n\n{noformat}\n2014-12-02 22:57:32,629 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Failed to download rsrc { { hdfs:/<blah machine>:8020/tmp/hive-hive/hive_2014-12-02_22-56-58_741_2045919883676051996-3/-mr-10004/8060c9dd-54b6-42fc-9d77-34b655fa5e82/reduce.xml, 1417589819618, FILE, null },pending,[(container_1417589109512_0001_02_000003)],119413444132127,DOWNLOADING}\njava.io.FileNotFoundException: File /data/yarn/nm/filecache does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:524)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:737)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:514)\n\tat org.apache.hadoop.fs.FileSystem.primitiveMkdir(FileSystem.java:1051)\n\tat org.apache.hadoop.fs.DelegateToFileSystem.mkdir(DelegateToFileSystem.java:162)\n\tat org.apache.hadoop.fs.FilterFs.mkdir(FilterFs.java:197)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:724)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:720)\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:720)\n\tat org.apache.hadoop.yarn.util.FSDownload.createDir(FSDownload.java:104)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:351)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:60)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n2014-12-02 22:57:32,629 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1417589109512_0001_02_000003 transitioned from LOCALIZING to LOCALIZATION_FAILED\n{noformat}"
        }
    },
    {
        "filename": "YARN-6837.json",
        "creation_time": "2017-07-18T11:17:55.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.addResources(ResourceSet.java:84)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$RequestResourcesTransition.transition(ContainerImpl.java:868)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$RequestResourcesTransition.transition(ContainerImpl.java:819)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1684)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:96)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1418)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1411)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.addResources": "  public Map<LocalResourceVisibility, Collection<LocalResourceRequest>>\n      addResources(Map<String, LocalResource> localResourceMap)\n      throws URISyntaxException {\n    if (localResourceMap == null || localResourceMap.isEmpty()) {\n      return null;\n    }\n    Map<LocalResourceRequest, Set<String>> allResources = new HashMap<>();\n    List<LocalResourceRequest> publicList = new ArrayList<>();\n    List<LocalResourceRequest> privateList = new ArrayList<>();\n    List<LocalResourceRequest> appList = new ArrayList<>();\n\n    for (Map.Entry<String, LocalResource> rsrc : localResourceMap.entrySet()) {\n      LocalResource resource = rsrc.getValue();\n      LocalResourceRequest req = new LocalResourceRequest(rsrc.getValue());\n      allResources.putIfAbsent(req, new HashSet<>());\n      allResources.get(req).add(rsrc.getKey());\n      storeSharedCacheUploadPolicy(req,\n          resource.getShouldBeUploadedToSharedCache());\n      switch (resource.getVisibility()) {\n      case PUBLIC:\n        publicList.add(req);\n        break;\n      case PRIVATE:\n        privateList.add(req);\n        break;\n      case APPLICATION:\n        appList.add(req);\n        break;\n      default:\n        break;\n      }\n    }\n    Map<LocalResourceVisibility, Collection<LocalResourceRequest>> req =\n        new LinkedHashMap<>();\n    if (!publicList.isEmpty()) {\n      publicRsrcs.addAll(publicList);\n      req.put(LocalResourceVisibility.PUBLIC, publicList);\n    }\n    if (!privateList.isEmpty()) {\n      privateRsrcs.addAll(privateList);\n      req.put(LocalResourceVisibility.PRIVATE, privateList);\n    }\n    if (!appList.isEmpty()) {\n      appRsrcs.addAll(appList);\n      req.put(LocalResourceVisibility.APPLICATION, appList);\n    }\n    if (!allResources.isEmpty()) {\n      this.pendingResources.putAll(allResources);\n    }\n    return req;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.storeSharedCacheUploadPolicy": "  private void storeSharedCacheUploadPolicy(\n      LocalResourceRequest resourceRequest, Boolean uploadPolicy) {\n    Boolean storedUploadPolicy = resourcesUploadPolicies.get(resourceRequest);\n    if (storedUploadPolicy == null || (!storedUploadPolicy && uploadPolicy)) {\n      resourcesUploadPolicies.put(resourceRequest, uploadPolicy);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.transition": "    public void transition(ContainerImpl container, ContainerEvent event) {\n      ContainerDiagnosticsUpdateEvent updateEvent =\n          (ContainerDiagnosticsUpdateEvent) event;\n      container.addDiagnostics(updateEvent.getDiagnosticsUpdate(), \"\\n\");\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.doRelaunch": "    private void doRelaunch(final ContainerImpl container,\n        int remainingRetryAttempts, final int retryInterval) {\n      LOG.info(\"Relaunching Container \" + container.getContainerId()\n          + \". Remaining retry attempts(after relaunch) : \"\n          + remainingRetryAttempts + \". Interval between retries is \"\n          + retryInterval + \"ms\");\n      container.wasLaunched  = false;\n      container.metrics.endRunningContainer();\n      if (retryInterval == 0) {\n        container.sendRelaunchEvent();\n      } else {\n        // wait for some time, then send launch event\n        new Thread() {\n          @Override\n          public void run() {\n            try {\n              Thread.sleep(retryInterval);\n              container.sendRelaunchEvent();\n            } catch (InterruptedException e) {\n              return;\n            }\n          }\n        }.start();\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.configureRetryContext": "  private static ContainerRetryContext configureRetryContext(\n      Configuration conf, ContainerLaunchContext launchContext,\n      ContainerId containerId) {\n    ContainerRetryContext context;\n    if (launchContext != null\n        && launchContext.getContainerRetryContext() != null) {\n      context = launchContext.getContainerRetryContext();\n    } else {\n      context = ContainerRetryContext.NEVER_RETRY_CONTEXT;\n    }\n    int minimumRestartInterval = conf.getInt(\n        YarnConfiguration.NM_CONTAINER_RETRY_MINIMUM_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_NM_CONTAINER_RETRY_MINIMUM_INTERVAL_MS);\n    if (context.getRetryPolicy() != ContainerRetryPolicy.NEVER_RETRY\n        && context.getRetryInterval() < minimumRestartInterval) {\n      LOG.info(\"Set restart interval to minimum value \" + minimumRestartInterval\n          + \"ms for container \" + containerId);\n      context.setRetryInterval(minimumRestartInterval);\n    }\n    return context;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.createReInitContext": "    protected ReInitializationContext createReInitContext(ContainerImpl\n        container, ContainerEvent event) {\n      container.addDiagnostics(\"Container upgrade will be Rolled-back.\\n\");\n      LOG.warn(\"Container [\" + container.getContainerId() + \"]\" +\n          \" about to be explicitly Rolledback !!\");\n      return container.reInitContext.createContextForRollback();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.canRollback": "  public boolean canRollback() {\n    return (this.reInitContext != null)\n        && (this.reInitContext.canRollback());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.sendScheduleEvent": "  private void sendScheduleEvent() {\n    dispatcher.getEventHandler().handle(\n        new ContainerSchedulerEvent(this,\n            ContainerSchedulerEventType.SCHEDULE_CONTAINER)\n    );\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getResource": "  public Resource getResource() {\n    return Resources.clone(this.resource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.shouldBeUploadedToSharedCache": "  private static boolean shouldBeUploadedToSharedCache(ContainerImpl container,\n      LocalResourceRequest resource) {\n    return container.resourceSet.getResourcesUploadPolicies().get(resource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.toString": "  public String toString() {\n    this.readLock.lock();\n    try {\n      return this.containerId.toString();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.addDiagnostics": "  private void addDiagnostics(String... diags) {\n    for (String s : diags) {\n      this.diagnostics.append(\"[\" + dateFormat.format(new Date()) + \"]\" + s);\n    }\n    if (diagnostics.length() > diagnosticsMaxSize) {\n      diagnostics.delete(0, diagnostics.length() - diagnosticsMaxSize);\n    }\n    try {\n      stateStore.storeContainerDiagnostics(containerId, diagnostics);\n    } catch (IOException e) {\n      LOG.warn(\"Unable to update diagnostics in state store for \"\n          + containerId, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.sendContainerMonitorStartEvent": "  private void sendContainerMonitorStartEvent() {\n    long launchDuration = clock.getTime() - containerLaunchStartTime;\n    metrics.addContainerLaunchDuration(launchDuration);\n\n    long pmemBytes = getResource().getMemorySize() * 1024 * 1024L;\n    float pmemRatio = daemonConf.getFloat(\n        YarnConfiguration.NM_VMEM_PMEM_RATIO,\n        YarnConfiguration.DEFAULT_NM_VMEM_PMEM_RATIO);\n    long vmemBytes = (long) (pmemRatio * pmemBytes);\n    int cpuVcores = getResource().getVirtualCores();\n    long localizationDuration = containerLaunchStartTime -\n        containerLocalizationStartTime;\n    dispatcher.getEventHandler().handle(\n        new ContainerStartMonitoringEvent(containerId,\n        vmemBytes, pmemBytes, cpuVcores, launchDuration,\n        localizationDuration));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.isReInitializing": "  public boolean isReInitializing() {\n    return this.isReInitializing;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getLaunchContext": "  public ContainerLaunchContext getLaunchContext() {\n    this.readLock.lock();\n    try {\n      return launchContext;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getContainerId": "  public ContainerId getContainerId() {\n    return this.containerId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.hasDefaultExitCode": "  private boolean hasDefaultExitCode() {\n    return (this.exitCode == ContainerExitStatus.INVALID);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle": "  public void handle(ContainerEvent event) {\n    try {\n      this.writeLock.lock();\n\n      ContainerId containerID = event.getContainerID();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing \" + containerID + \" of type \" + event.getType());\n      }\n      ContainerState oldState = stateMachine.getCurrentState();\n      ContainerState newState = null;\n      try {\n        newState =\n            stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.warn(\"Can't handle this event at current state: Current: [\"\n            + oldState + \"], eventType: [\" + event.getType() + \"],\" +\n            \" container: [\" + containerID + \"]\", e);\n      }\n      if (newState != null && oldState != newState) {\n        LOG.info(\"Container \" + containerID + \" transitioned from \"\n            + oldState\n            + \" to \" + newState);\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getContainerState": "  public ContainerState getContainerState() {\n    this.readLock.lock();\n    try {\n      return stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.setIsReInitializing": "  public void setIsReInitializing(boolean isReInitializing) {\n    if (this.isReInitializing && !isReInitializing) {\n      metrics.endReInitingContainer();\n    }\n    this.isReInitializing = isReInitializing;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.cleanup": "  public void cleanup() {\n    Map<LocalResourceVisibility, Collection<LocalResourceRequest>> rsrc =\n        resourceSet.getAllResourcesByVisibility();\n    dispatcher.getEventHandler().handle(\n        new ContainerLocalizationCleanupEvent(this, rsrc));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.sendFinishedEvents": "  private void sendFinishedEvents() {\n    // Inform the application\n    @SuppressWarnings(\"rawtypes\")\n    EventHandler eventHandler = dispatcher.getEventHandler();\n\n    ContainerStatus containerStatus = cloneAndGetContainerStatus();\n    eventHandler.handle(new ApplicationContainerFinishedEvent(containerStatus));\n\n    // Tell the scheduler the container is Done\n    eventHandler.handle(new ContainerSchedulerEvent(this,\n        ContainerSchedulerEventType.CONTAINER_COMPLETED));\n    // Remove the container from the resource-monitor\n    eventHandler.handle(new ContainerStopMonitoringEvent(containerId));\n    // Tell the logService too\n    eventHandler.handle(new LogHandlerContainerFinishedEvent(\n      containerId, exitCode));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getUser": "  public String getUser() {\n    this.readLock.lock();\n    try {\n      return this.user;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.shouldRetry": "  public static boolean shouldRetry(int errorCode,\n      ContainerRetryContext retryContext, int remainingRetryAttempts) {\n    if (errorCode == ExitCode.SUCCESS.getExitCode()\n        || errorCode == ExitCode.FORCE_KILLED.getExitCode()\n        || errorCode == ExitCode.TERMINATED.getExitCode()) {\n      return false;\n    }\n\n    ContainerRetryPolicy retryPolicy = retryContext.getRetryPolicy();\n    if (retryPolicy == ContainerRetryPolicy.RETRY_ON_ALL_ERRORS\n        || (retryPolicy == ContainerRetryPolicy.RETRY_ON_SPECIFIC_ERROR_CODES\n        && retryContext.getErrorCodes() != null\n        && retryContext.getErrorCodes().contains(errorCode))) {\n      return remainingRetryAttempts > 0\n          || remainingRetryAttempts == ContainerRetryContext.RETRY_FOREVER;\n    }\n\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getCurrentState": "  public org.apache.hadoop.yarn.api.records.ContainerState getCurrentState() {\n    switch (stateMachine.getCurrentState()) {\n    case NEW:\n    case LOCALIZING:\n    case LOCALIZATION_FAILED:\n    case SCHEDULED:\n      return org.apache.hadoop.yarn.api.records.ContainerState.SCHEDULED;\n    case RUNNING:\n    case RELAUNCHING:\n    case REINITIALIZING:\n    case EXITED_WITH_SUCCESS:\n    case EXITED_WITH_FAILURE:\n    case KILLING:\n    case CONTAINER_CLEANEDUP_AFTER_KILL:\n    case CONTAINER_RESOURCES_CLEANINGUP:\n      return org.apache.hadoop.yarn.api.records.ContainerState.RUNNING;\n    case DONE:\n    default:\n      return org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        Application app = this.context.getApplications().get(appID);\n        if (app == null) {\n          LOG.info(\"couldn't find application \" + appID + \" while processing\"\n              + \" FINISH_APPS event. The ResourceManager allocated resources\"\n              + \" for this application to the NodeManager but no active\"\n              + \" containers were found to process.\");\n          continue;\n        }\n\n        boolean shouldDropEvent = false;\n        for (Container container : app.getContainers().values()) {\n          if (container.isRecovering()) {\n            LOG.info(\"drop FINISH_APPS event to \" + appID + \" because \"\n                + \"container \" + container.getContainerId()\n                + \" is recovering\");\n            shouldDropEvent = true;\n            break;\n          }\n        }\n        if (shouldDropEvent) {\n          continue;\n        }\n\n        String diagnostic = \"\";\n        if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Application killed on shutdown\";\n        } else if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Application killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                diagnostic));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId containerId : containersFinishedEvent\n          .getContainersToCleanup()) {\n        ApplicationId appId =\n            containerId.getApplicationAttemptId().getApplicationId();\n        Application app = this.context.getApplications().get(appId);\n        if (app == null) {\n          LOG.warn(\"couldn't find app \" + appId + \" while processing\"\n              + \" FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        Container container = app.getContainers().get(containerId);\n        if (container == null) {\n          LOG.warn(\"couldn't find container \" + containerId\n              + \" while processing FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        if (container.isRecovering()) {\n          LOG.info(\"drop FINISH_CONTAINERS event to \" + containerId\n              + \" because container is recovering\");\n          continue;\n        }\n\n        this.dispatcher.getEventHandler().handle(\n              new ContainerKillEvent(containerId,\n                  ContainerExitStatus.KILLED_BY_RESOURCEMANAGER,\n                  \"Container Killed by ResourceManager\"));\n      }\n      break;\n    case DECREASE_CONTAINERS_RESOURCE:\n      CMgrDecreaseContainersResourceEvent containersDecreasedEvent =\n          (CMgrDecreaseContainersResourceEvent) event;\n      for (org.apache.hadoop.yarn.api.records.Container container\n          : containersDecreasedEvent.getContainersToDecrease()) {\n        try {\n          changeContainerResourceInternal(container.getId(),\n              container.getVersion(), container.getResource(), false);\n        } catch (YarnException e) {\n          LOG.error(\"Unable to decrease container resource\", e);\n        } catch (IOException e) {\n          LOG.error(\"Unable to update container resource in store\", e);\n        }\n      }\n      break;\n    case SIGNAL_CONTAINERS:\n      CMgrSignalContainersEvent containersSignalEvent =\n          (CMgrSignalContainersEvent) event;\n      for (SignalContainerRequest request : containersSignalEvent\n          .getContainersToSignal()) {\n        internalSignalToContainer(request, \"ResourceManager\");\n      }\n      break;\n    default:\n        throw new YarnRuntimeException(\n            \"Got an unknown ContainerManagerEvent type: \" + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.changeContainerResourceInternal": "  private void changeContainerResourceInternal(ContainerId containerId,\n      int containerVersion, Resource targetResource, boolean increase)\n          throws YarnException, IOException {\n    Container container = context.getContainers().get(containerId);\n    // Check container existence\n    if (container == null) {\n      if (nodeStatusUpdater.isContainerRecentlyStopped(containerId)) {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" was recently stopped on node manager.\");\n      } else {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" is not handled by this NodeManager\");\n      }\n    }\n    // Check container state\n    org.apache.hadoop.yarn.server.nodemanager.\n        containermanager.container.ContainerState currentState =\n        container.getContainerState();\n    if (currentState != org.apache.hadoop.yarn.server.\n        nodemanager.containermanager.container.ContainerState.RUNNING) {\n      throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n          + \" is in \" + currentState.name() + \" state.\"\n          + \" Resource can only be changed when a container is in\"\n          + \" RUNNING state\");\n    }\n    // Check validity of the target resource.\n    Resource currentResource = container.getResource();\n    if (currentResource.equals(targetResource)) {\n      LOG.warn(\"Unable to change resource for container \"\n          + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is the same as the current resource\");\n      return;\n    }\n    if (increase && !Resources.fitsIn(currentResource, targetResource)) {\n      throw RPCUtil.getRemoteException(\"Unable to increase resource for \"\n          + \"container \" + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is smaller than the current resource \"\n          + currentResource.toString());\n    }\n    if (!increase &&\n        (!Resources.fitsIn(Resources.none(), targetResource)\n            || !Resources.fitsIn(targetResource, currentResource))) {\n      throw RPCUtil.getRemoteException(\"Unable to decrease resource for \"\n          + \"container \" + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is not smaller than the current resource \"\n          + currentResource.toString());\n    }\n    if (increase) {\n      org.apache.hadoop.yarn.api.records.Container increasedContainer =\n          org.apache.hadoop.yarn.api.records.Container.newInstance(\n              containerId, null, null, targetResource, null, null);\n      if (context.getIncreasedContainers().putIfAbsent(containerId,\n          increasedContainer) != null){\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" resource is being increased.\");\n      }\n    }\n    this.readLock.lock();\n    try {\n      if (!serviceStopped) {\n        // Persist container resource change for recovery\n        this.context.getNMStateStore().storeContainerResourceChanged(\n            containerId, containerVersion, targetResource);\n        getContainersMonitor().handle(\n            new ChangeMonitoringContainerResourceEvent(\n                containerId, targetResource));\n      } else {\n        throw new YarnException(\n            \"Unable to change container resource as the NodeManager is \"\n                + \"in the process of shutting down\");\n      }\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.internalSignalToContainer": "  private void internalSignalToContainer(SignalContainerRequest request,\n      String sentBy) {\n    ContainerId containerId = request.getContainerId();\n    Container container = this.context.getContainers().get(containerId);\n    if (container != null) {\n      LOG.info(containerId + \" signal request \" + request.getCommand()\n            + \" by \" + sentBy);\n      this.dispatcher.getEventHandler().handle(\n          new SignalContainersLauncherEvent(container,\n              request.getCommand()));\n    } else {\n      LOG.info(\"Container \" + containerId + \" no longer exists\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerResourceFailedEvent.getDiagnosticMessage": "  public String getDiagnosticMessage() {\n    return diagnosticMesage;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerKillEvent.getDiagnostic": "  public String getDiagnostic() {\n    return this.diagnostic;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerExitEvent.getExitCode": "  public int getExitCode() {\n    return this.exitCode;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerExitEvent.getDiagnosticInfo": "  public String getDiagnosticInfo() {\n    return diagnosticInfo;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerResourceLocalizedEvent.getLocation": "  public Path getLocation() {\n    return loc;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerDiagnosticsUpdateEvent.getDiagnosticsUpdate": "  public String getDiagnosticsUpdate() {\n    return this.diagnosticsUpdate;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerKillEvent.getContainerExitStatus": "  public int getContainerExitStatus() {\n    return this.exitStatus;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Null LocalResource visibility or resource type can crash the nodemanager",
            "Description": "When I write an yarn application, I create a LocalResource like this\n{quote}\nLocalResource resource = Records.newRecord(LocalResource.class);\n{quote}\nBecause I forget to set the visibilty of it, so the job is failed when I submit it.\nBut NodeManager shutdown one by one at the same time, and there is NullPointerExceptionin NodeManager's log:\n{quote}\n2017-07-18 17:54:09,289 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=hadoop       IP=10.43.156.177        OPERATION=Start Container Request       TARGET=ContainerManageImpl      RESULT=SUCCESS  APPID=application_1499221670783_0067    CONTAINERID=container_1499221670783_0067_02_000003\n2017-07-18 17:54:09,292 FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.addResources(ResourceSet.java:84)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$RequestResourcesTransition.transition(ContainerImpl.java:868)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$RequestResourcesTransition.transition(ContainerImpl.java:819)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1684)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:96)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1418)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1411)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\n        at java.lang.Thread.run(Thread.java:745)\n2017-07-18 17:54:09,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1499221670783_0067_02_000002 by user hadoop\n{quote}\n\nThen I change my code and still set the visibility to null\n{quote}\nLocalResource resource = LocalResource.newInstance(\n                                URL.fromURI(dst.toUri()),\n                                LocalResourceType.FILE, {color:red}null{color},\n                                fileStatus.getLen(), fileStatus.getModificationTime());\n{quote}\nThis error still happen.\n\nAt last I set the visibility to correct value, the error do not happen again.\nSo I think the visibility of LocalResource is null will cause NodeManager shutdown."
        }
    },
    {
        "filename": "YARN-4762.json",
        "creation_time": "2016-03-04T02:24:47.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:240)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:539)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:587)\nCaused by: java.io.IOException: Failed to initialize linux container runtime(s)!\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:207)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:238)\n        ... 3 more\n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:240)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:539)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:587)\nCaused by: java.io.IOException: Failed to initialize linux container runtime(s)!\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:207)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:238)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n\n    conf.setBoolean(Dispatcher.DISPATCHER_EXIT_ON_ERROR_KEY, true);\n\n    rmWorkPreservingRestartEnabled = conf.getBoolean(YarnConfiguration\n            .RM_WORK_PRESERVING_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_ENABLED);\n\n    initAndStartRecoveryStore(conf);\n\n    NMContainerTokenSecretManager containerTokenSecretManager =\n        new NMContainerTokenSecretManager(conf, nmStore);\n\n    NMTokenSecretManagerInNM nmTokenSecretManager =\n        new NMTokenSecretManagerInNM(nmStore);\n\n    recoverTokens(nmTokenSecretManager, containerTokenSecretManager);\n    \n    this.aclsManager = new ApplicationACLsManager(conf);\n\n    ContainerExecutor exec = ReflectionUtils.newInstance(\n        conf.getClass(YarnConfiguration.NM_CONTAINER_EXECUTOR,\n          DefaultContainerExecutor.class, ContainerExecutor.class), conf);\n    try {\n      exec.init();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to initialize container executor\", e);\n    }    \n    DeletionService del = createDeletionService(exec);\n    addService(del);\n\n    // NodeManager level dispatcher\n    this.dispatcher = new AsyncDispatcher();\n\n    dirsHandler = new LocalDirsHandlerService(metrics);\n    nodeHealthChecker =\n        new NodeHealthCheckerService(\n            getNodeHealthScriptRunner(conf), dirsHandler);\n    addService(nodeHealthChecker);\n\n    this.context = createNMContext(containerTokenSecretManager,\n        nmTokenSecretManager, nmStore);\n\n    nodeLabelsProvider = createNodeLabelsProvider(conf);\n\n    if (null == nodeLabelsProvider) {\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker);\n    } else {\n      addIfService(nodeLabelsProvider);\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker,\n              nodeLabelsProvider);\n    }\n\n    nodeResourceMonitor = createNodeResourceMonitor();\n    addService(nodeResourceMonitor);\n    ((NMContext) context).setNodeResourceMonitor(nodeResourceMonitor);\n\n    containerManager =\n        createContainerManager(context, exec, del, nodeStatusUpdater,\n        this.aclsManager, dirsHandler);\n    addService(containerManager);\n    ((NMContext) context).setContainerManager(containerManager);\n\n    WebServer webServer = createWebServer(context, containerManager\n        .getContainersMonitor(), this.aclsManager, dirsHandler);\n    addService(webServer);\n    ((NMContext) context).setWebServer(webServer);\n\n    dispatcher.register(ContainerManagerEventType.class, containerManager);\n    dispatcher.register(NodeManagerEventType.class, this);\n    addService(dispatcher);\n\n    pauseMonitor = new JvmPauseMonitor();\n    addService(pauseMonitor);\n    metrics.getJvmMetrics().setPauseMonitor(pauseMonitor);\n\n    DefaultMetricsSystem.initialize(\"NodeManager\");\n\n    // StatusUpdater should be added last so that it get started last \n    // so that we make sure everything is up before registering with RM. \n    addService(nodeStatusUpdater);\n    ((NMContext) context).setNodeStatusUpdater(nodeStatusUpdater);\n\n    super.serviceInit(conf);\n    // TODO add local dirs to del\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMContext": "  protected NMContext createNMContext(\n      NMContainerTokenSecretManager containerTokenSecretManager,\n      NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMStateStoreService stateStore) {\n    return new NMContext(containerTokenSecretManager, nmTokenSecretManager,\n        dirsHandler, aclsManager, stateStore);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.recoverTokens": "  private void recoverTokens(NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMContainerTokenSecretManager containerTokenSecretManager)\n          throws IOException {\n    if (nmStore.canRecover()) {\n      nmTokenSecretManager.recover();\n      containerTokenSecretManager.recover();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartRecoveryStore": "  private void initAndStartRecoveryStore(Configuration conf)\n      throws IOException {\n    boolean recoveryEnabled = conf.getBoolean(\n        YarnConfiguration.NM_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_NM_RECOVERY_ENABLED);\n    if (recoveryEnabled) {\n      FileSystem recoveryFs = FileSystem.getLocal(conf);\n      String recoveryDirName = conf.get(YarnConfiguration.NM_RECOVERY_DIR);\n      if (recoveryDirName == null) {\n        throw new IllegalArgumentException(\"Recovery is enabled but \" +\n            YarnConfiguration.NM_RECOVERY_DIR + \" is not set.\");\n      }\n      Path recoveryRoot = new Path(recoveryDirName);\n      recoveryFs.mkdirs(recoveryRoot, new FsPermission((short)0700));\n      nmStore = new NMLeveldbStateStoreService();\n    } else {\n      nmStore = new NMNullStateStoreService();\n    }\n    nmStore.init(conf);\n    nmStore.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeStatusUpdater": "  protected NodeStatusUpdater createNodeStatusUpdater(Context context,\n      Dispatcher dispatcher, NodeHealthCheckerService healthChecker,\n      NodeLabelsProvider nodeLabelsProvider) {\n    return new NodeStatusUpdaterImpl(context, dispatcher, healthChecker,\n        metrics, nodeLabelsProvider);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createWebServer": "  protected WebServer createWebServer(Context nmContext,\n      ResourceView resourceView, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new WebServer(nmContext, resourceView, aclsManager, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createContainerManager": "  protected ContainerManagerImpl createContainerManager(Context context,\n      ContainerExecutor exec, DeletionService del,\n      NodeStatusUpdater nodeStatusUpdater, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new ContainerManagerImpl(context, exec, del, nodeStatusUpdater,\n      metrics, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createDeletionService": "  protected DeletionService createDeletionService(ContainerExecutor exec) {\n    return new DeletionService(exec, nmStore);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeResourceMonitor": "  protected NodeResourceMonitor createNodeResourceMonitor() {\n    return new NodeResourceMonitorImpl();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeLabelsProvider": "  protected NodeLabelsProvider createNodeLabelsProvider(Configuration conf)\n      throws IOException {\n    NodeLabelsProvider provider = null;\n    String providerString =\n        conf.get(YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG, null);\n    if (providerString == null || providerString.trim().length() == 0) {\n      // Seems like Distributed Node Labels configuration is not enabled\n      return provider;\n    }\n    switch (providerString.trim().toLowerCase()) {\n    case YarnConfiguration.CONFIG_NODE_LABELS_PROVIDER:\n      provider = new ConfigurationNodeLabelsProvider();\n      break;\n    case YarnConfiguration.SCRIPT_NODE_LABELS_PROVIDER:\n      provider = new ScriptBasedNodeLabelsProvider();\n      break;\n    default:\n      try {\n        Class<? extends NodeLabelsProvider> labelsProviderClass =\n            conf.getClass(YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG,\n                null, NodeLabelsProvider.class);\n        provider = labelsProviderClass.newInstance();\n      } catch (InstantiationException | IllegalAccessException\n          | RuntimeException e) {\n        LOG.error(\"Failed to create NodeLabelsProvider based on Configuration\",\n            e);\n        throw new IOException(\n            \"Failed to create NodeLabelsProvider : \" + e.getMessage(), e);\n      }\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Distributed Node Labels is enabled\"\n          + \" with provider class as : \" + provider.getClass().toString());\n    }\n    return provider;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.getNodeHealthScriptRunner": "  public static NodeHealthScriptRunner getNodeHealthScriptRunner(Configuration conf) {\n    String nodeHealthScript = \n        conf.get(YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_PATH);\n    if(!NodeHealthScriptRunner.shouldRun(nodeHealthScript)) {\n      LOG.info(\"Node Manager health check script is not available \"\n          + \"or doesn't have execute permission, so not \"\n          + \"starting the node health script runner.\");\n      return null;\n    }\n    long nmCheckintervalTime = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS);\n    long scriptTimeout = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS);\n    String[] scriptArgs = conf.getStrings(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_OPTS, new String[] {});\n    return new NodeHealthScriptRunner(nodeHealthScript,\n        nmCheckintervalTime, scriptTimeout, scriptArgs);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager": "  private void initAndStartNodeManager(Configuration conf, boolean hasToReboot) {\n    try {\n      // Failed to start if we're a Unix based system but we don't have bash.\n      // Bash is necessary to launch containers under Unix-based systems.\n      if (!Shell.WINDOWS) {\n        if (!Shell.isBashSupported) {\n          String message =\n              \"Failing NodeManager start since we're on a \"\n                  + \"Unix-based system but bash doesn't seem to be available.\";\n          LOG.fatal(message);\n          throw new YarnRuntimeException(message);\n        }\n      }\n\n      // Remove the old hook if we are rebooting.\n      if (hasToReboot && null != nodeManagerShutdownHook) {\n        ShutdownHookManager.get().removeShutdownHook(nodeManagerShutdownHook);\n      }\n\n      nodeManagerShutdownHook = new CompositeServiceShutdownHook(this);\n      ShutdownHookManager.get().addShutdownHook(nodeManagerShutdownHook,\n                                                SHUTDOWN_HOOK_PRIORITY);\n      // System exit should be called only when NodeManager is instantiated from\n      // main() funtion\n      this.shouldExitOnShutdownEvent = true;\n      this.init(conf);\n      this.start();\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting NodeManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.main": "  public static void main(String[] args) throws IOException {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(NodeManager.class, args, LOG);\n    NodeManager nodeManager = new NodeManager();\n    Configuration conf = new YarnConfiguration();\n    new GenericOptionsParser(conf, args);\n    nodeManager.initAndStartNodeManager(conf, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init": "  public void init() throws IOException {\n    Configuration conf = super.getConf();\n\n    // Send command to executor which will just start up,\n    // verify configuration/permissions and exit\n    try {\n      PrivilegedOperation checkSetupOp = new PrivilegedOperation(\n          PrivilegedOperation.OperationType.CHECK_SETUP, (String) null);\n      PrivilegedOperationExecutor privilegedOperationExecutor =\n          PrivilegedOperationExecutor.getInstance(conf);\n\n      privilegedOperationExecutor.executePrivilegedOperation(checkSetupOp,\n          false);\n    } catch (PrivilegedOperationException e) {\n      int exitCode = e.getExitCode();\n      LOG.warn(\"Exit code from container executor initialization is : \"\n          + exitCode, e);\n\n      throw new IOException(\"Linux container executor not configured properly\"\n          + \" (error=\" + exitCode + \")\", e);\n    }\n\n    try {\n      resourceHandlerChain = ResourceHandlerModule\n          .getConfiguredResourceHandlerChain(conf);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Resource handler chain enabled = \" + (resourceHandlerChain\n            == null));\n      }\n      if (resourceHandlerChain != null) {\n        LOG.debug(\"Bootstrapping resource handler chain\");\n        resourceHandlerChain.bootstrap(conf);\n      }\n    } catch (ResourceHandlerException e) {\n      LOG.error(\"Failed to bootstrap configured resource subsystems! \", e);\n      throw new IOException(\n          \"Failed to bootstrap configured resource subsystems!\");\n    }\n\n    try {\n      if (linuxContainerRuntime == null) {\n        LinuxContainerRuntime runtime = new DelegatingLinuxContainerRuntime();\n\n        runtime.initialize(conf);\n        this.linuxContainerRuntime = runtime;\n      }\n    } catch (ContainerExecutionException e) {\n      throw new IOException(\"Failed to initialize linux container runtime(s)!\");\n    }\n\n    resourcesHandler.init(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.init": "  public abstract void init() throws IOException;\n\n  /**\n   * On Windows the ContainerLaunch creates a temporary special jar manifest of \n   * other jars to workaround the CLASSPATH length. In a  secure cluster this \n   * jar must be localized so that the container has access to it. \n   * This function localizes on-demand the jar.\n   * \n   * @param classPathJar\n   * @param owner\n   * @throws IOException\n   */\n  public Path localizeClasspathJar(Path classPathJar, Path pwd, String owner) \n      throws IOException {\n    // Non-secure executor simply use the classpath created \n    // in the NM fprivate folder\n    return classPathJar;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "NMs failing on DelegatingLinuxContainerRuntime init with LCE on",
            "Description": "Seeing this exception and the NMs crash.\n{code}\n2016-03-03 16:47:57,807 DEBUG org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService is started\n2016-03-03 16:47:58,027 DEBUG org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: checkLinuxExecutorSetup: [/hadoop/hadoop-yarn-nodemanager/bin/container-executor, --checksetup]\n2016-03-03 16:47:58,043 ERROR org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl: Mount point Based on mtab file: /proc/mounts. Controller mount point not writable for: cpu\n2016-03-03 16:47:58,043 ERROR org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime: Unable to get cgroups handle.\n2016-03-03 16:47:58,044 DEBUG org.apache.hadoop.service.AbstractService: noteFailure org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\n2016-03-03 16:47:58,044 INFO org.apache.hadoop.service.AbstractService: Service NodeManager failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:240)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:539)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:587)\nCaused by: java.io.IOException: Failed to initialize linux container runtime(s)!\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:207)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:238)\n        ... 3 more\n2016-03-03 16:47:58,047 DEBUG org.apache.hadoop.service.AbstractService: Service: NodeManager entered state STOPPED\n2016-03-03 16:47:58,047 DEBUG org.apache.hadoop.service.CompositeService: NodeManager: stopping services, size=0\n2016-03-03 16:47:58,047 DEBUG org.apache.hadoop.service.AbstractService: Service: org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService entered state STOPPED\n2016-03-03 16:47:58,047 FATAL org.apache.hadoop.yarn.server.nodemanager.NodeManager: Error starting NodeManager\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:240)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:539)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:587)\nCaused by: java.io.IOException: Failed to initialize linux container runtime(s)!\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:207)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:238)\n        ... 3 more\n{code}"
        }
    },
    {
        "filename": "YARN-2823.json",
        "creation_time": "2014-11-06T21:38:47.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.transferStateFromPreviousAttempt(SchedulerApplicationAttempt.java:530)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:678)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1015)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:603)\n        at java.lang.Thread.run(Thread.java:744)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.transferStateFromPreviousAttempt": "  public synchronized void transferStateFromPreviousAttempt(\n      SchedulerApplicationAttempt appAttempt) {\n    this.liveContainers = appAttempt.getLiveContainersMap();\n    // this.reReservations = appAttempt.reReservations;\n    this.currentConsumption = appAttempt.getCurrentConsumption();\n    this.resourceLimit = appAttempt.getResourceLimit();\n    // this.currentReservation = appAttempt.currentReservation;\n    // this.newlyAllocatedContainers = appAttempt.newlyAllocatedContainers;\n    // this.schedulingOpportunities = appAttempt.schedulingOpportunities;\n    this.lastScheduledContainer = appAttempt.getLastScheduledContainer();\n    this.appSchedulingInfo\n      .transferStateFromPreviousAppSchedulingInfo(appAttempt.appSchedulingInfo);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getCurrentConsumption": "  public Resource getCurrentConsumption() {\n    return currentConsumption;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getResourceLimit": "  public synchronized Resource getResourceLimit() {\n    return this.resourceLimit;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getLastScheduledContainer": "  public synchronized Map<Priority, Long> getLastScheduledContainer() {\n    return this.lastScheduledContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getLiveContainersMap": "  public synchronized Map<ContainerId, RMContainer> getLiveContainersMap() {\n    return this.liveContainers;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    CSQueue queue = (CSQueue) application.getQueue();\n\n    FiCaSchedulerApp attempt =\n        new FiCaSchedulerApp(applicationAttemptId, application.getUser(),\n          queue, queue.getActiveUsersManager(), rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n        .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    queue.submitApplicationAttempt(attempt, application.getUser());\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user \" + application.getUser() + \" in queue \"\n        + queue.getQueueName());\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public synchronized CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return queues.get(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      RMNode node = nodeUpdatedEvent.getRMNode();\n      nodeUpdate(node);\n      if (!scheduleAsynchronously) {\n        allocateContainersToNode(getNode(node.getNodeID()));\n      }\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName,\n            appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent = \n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId), \n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId, \n              SchedulerUtils.EXPIRED_CONTAINER), \n          RMContainerEventType.EXPIRE);\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          resetDispatcher();\n          createAndInitActiveServices();\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices": "  protected void createAndInitActiveServices() throws Exception {\n    activeServices = new RMActiveServices(this);\n    activeServices.init(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.resetDispatcher": "  private void resetDispatcher() {\n    Dispatcher dispatcher = setupDispatcher();\n    ((Service)dispatcher).init(this.conf);\n    ((Service)dispatcher).start();\n    removeService((Service)rmDispatcher);\n    // Need to stop previous rmDispatcher before assigning new dispatcher\n    // otherwise causes \"AsyncDispatcher event handler\" thread leak\n    ((Service) rmDispatcher).stop();\n    rmDispatcher = dispatcher;\n    addIfService(rmDispatcher);\n    rmContext.setDispatcher(rmDispatcher);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n  \n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n  \n  /**\n   * Get actual <em>capacity</em> of the queue, this may be different from\n   * configured capacity when mis-config take place, like add labels to the\n   * cluster\n   * \n   * @return actual queue capacity\n   */\n  public float getAbsActualCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Set used capacity of the queue.\n   * @param usedCapacity\n   *          used capacity of the queue\n   */\n  public void setUsedCapacity(float usedCapacity);\n\n  /**\n   * Set absolute used capacity of the queue.\n   * @param absUsedCapacity\n   *          absolute used capacity of the queue\n   */\n  public void setAbsoluteUsedCapacity(float absUsedCapacity);\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @param needToUnreserve assign container only if it can unreserve one first\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node, boolean needToUnreserve);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   * @param sortQueues indicates whether it should re-sort the queues\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getActiveUsersManager": "  public ActiveUsersManager getActiveUsersManager();\n  \n  /**\n   * Adds all applications in the queue and its subqueues to the given collection.\n   * @param apps the collection to add the applications to\n   */\n  public void collectSchedulerApplications(Collection<ApplicationAttemptId> apps);\n\n  /**\n  * Detach a container from this queue\n  * @param clusterResource the current cluster resource\n  * @param application application to which the container was assigned\n  * @param container the container to detach\n  */\n  public void detachContainer(Resource clusterResource,\n               FiCaSchedulerApp application, RMContainer container);\n\n  /**\n   * Attach a container to this queue\n   * @param clusterResource the current cluster resource\n   * @param application application to which the container was assigned\n   * @param container the container to attach\n   */\n  public void attachContainer(Resource clusterResource,\n               FiCaSchedulerApp application, RMContainer container);\n  \n  /**\n   * Get absolute capacity by label of this queue can use \n   * @param nodeLabel\n   * @return absolute capacity by label of this queue can use\n   */\n  public float getAbsoluteCapacityByNodeLabel(String nodeLabel);\n  \n  /**\n   * Get absolute max capacity by label of this queue can use \n   * @param nodeLabel\n   * @return absolute capacity by label of this queue can use\n   */\n  public float getAbsoluteMaximumCapacityByNodeLabel(String nodeLabel);\n\n  /**\n   * Get capacity by node label\n   * @param nodeLabel\n   * @return capacity by node label\n   */\n  public float getCapacityByNodeLabel(String nodeLabel);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.submitApplicationAttempt": "  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @param needToUnreserve assign container only if it can unreserve one first\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node, boolean needToUnreserve);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   * @param sortQueues indicates whether it should re-sort the queues\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue."
        },
        "bug_report": {
            "Title": "NullPointerException in RM HA enabled 3-node cluster",
            "Description": "Branch:\n2.6.0\n\nEnvironment: \nA 3-node cluster with RM HA enabled. The HA setup went pretty smooth (used Ambari) and then installed HBase using Slider. After some time the RMs went down and would not come back up anymore. Following is the NPE we see in both the RM logs.\n\n{noformat}\n2014-09-16 01:36:28,037 FATAL resourcemanager.ResourceManager (ResourceManager.java:run(612)) - Error in handling event type APP_ATTEMPT_ADDED to the scheduler\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.transferStateFromPreviousAttempt(SchedulerApplicationAttempt.java:530)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:678)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1015)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:603)\n        at java.lang.Thread.run(Thread.java:744)\n2014-09-16 01:36:28,042 INFO  resourcemanager.ResourceManager (ResourceManager.java:run(616)) - Exiting, bbye..\n{noformat}\n\nAll the logs for this 3-node cluster has been uploaded."
        }
    },
    {
        "filename": "YARN-5098.json",
        "creation_time": "2016-05-17T00:43:08.000+0000",
        "stack_trace": "```\norg.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 171 for hrt_qa) can't be found in cache\n        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:375)\n        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:583)\n        at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:398)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:752)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:748)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1719)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:747)\n        at org.apache.hadoop.ipc.Client$Connection.access$3100(Client.java:398)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1597)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1439)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:240)\n        at com.sun.proxy.$Proxy83.getServerDefaults(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getServerDefaults(ClientNamenodeProtocolTranslatorPB.java:282)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)\n        at com.sun.proxy.$Proxy84.getServerDefaults(Unknown Source)\n        at org.apache.hadoop.hdfs.DFSClient.getServerDefaults(DFSClient.java:1018)\n        at org.apache.hadoop.fs.Hdfs.getServerDefaults(Hdfs.java:156)\n        at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:550)\n        at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:687)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.SaslRpcClient.saslConnect": "  public AuthMethod saslConnect(InputStream inS, OutputStream outS)\n      throws IOException {\n    DataInputStream inStream = new DataInputStream(new BufferedInputStream(inS));\n    DataOutputStream outStream = new DataOutputStream(new BufferedOutputStream(\n        outS));\n    \n    // redefined if/when a SASL negotiation starts, can be queried if the\n    // negotiation fails\n    authMethod = AuthMethod.SIMPLE;\n\n    sendSaslMessage(outStream, negotiateRequest);\n\n    // loop until sasl is complete or a rpc error occurs\n    boolean done = false;\n    do {\n      int totalLen = inStream.readInt();\n      RpcResponseMessageWrapper responseWrapper =\n          new RpcResponseMessageWrapper();\n      responseWrapper.readFields(inStream);\n      RpcResponseHeaderProto header = responseWrapper.getMessageHeader();\n      switch (header.getStatus()) {\n        case ERROR: // might get a RPC error during \n        case FATAL:\n          throw new RemoteException(header.getExceptionClassName(),\n                                    header.getErrorMsg());\n        default: break;\n      }\n      if (totalLen != responseWrapper.getLength()) {\n        throw new SaslException(\"Received malformed response length\");\n      }\n      \n      if (header.getCallId() != AuthProtocol.SASL.callId) {\n        throw new SaslException(\"Non-SASL response during negotiation\");\n      }\n      RpcSaslProto saslMessage =\n          RpcSaslProto.parseFrom(responseWrapper.getMessageBytes());\n      // handle sasl negotiation process\n      RpcSaslProto.Builder response = null;\n      switch (saslMessage.getState()) {\n        case NEGOTIATE: {\n          // create a compatible SASL client, throws if no supported auths\n          SaslAuth saslAuthType = selectSaslClient(saslMessage.getAuthsList());\n          // define auth being attempted, caller can query if connect fails\n          authMethod = AuthMethod.valueOf(saslAuthType.getMethod());\n          \n          byte[] responseToken = null;\n          if (authMethod == AuthMethod.SIMPLE) { // switching to SIMPLE\n            done = true; // not going to wait for success ack\n          } else {\n            byte[] challengeToken = null;\n            if (saslAuthType.hasChallenge()) {\n              // server provided the first challenge\n              challengeToken = saslAuthType.getChallenge().toByteArray();\n              saslAuthType =\n                  SaslAuth.newBuilder(saslAuthType).clearChallenge().build();\n            } else if (saslClient.hasInitialResponse()) {\n              challengeToken = new byte[0];\n            }\n            responseToken = (challengeToken != null)\n                ? saslClient.evaluateChallenge(challengeToken)\n                    : new byte[0];\n          }\n          response = createSaslReply(SaslState.INITIATE, responseToken);\n          response.addAuths(saslAuthType);\n          break;\n        }\n        case CHALLENGE: {\n          if (saslClient == null) {\n            // should probably instantiate a client to allow a server to\n            // demand a specific negotiation\n            throw new SaslException(\"Server sent unsolicited challenge\");\n          }\n          byte[] responseToken = saslEvaluateToken(saslMessage, false);\n          response = createSaslReply(SaslState.RESPONSE, responseToken);\n          break;\n        }\n        case SUCCESS: {\n          // simple server sends immediate success to a SASL client for\n          // switch to simple\n          if (saslClient == null) {\n            authMethod = AuthMethod.SIMPLE;\n          } else {\n            saslEvaluateToken(saslMessage, true);\n          }\n          done = true;\n          break;\n        }\n        default: {\n          throw new SaslException(\n              \"RPC client doesn't support SASL \" + saslMessage.getState());\n        }\n      }\n      if (response != null) {\n        sendSaslMessage(outStream, response.build());\n      }\n    } while (!done);\n    return authMethod;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.SaslRpcClient.createSaslReply": "  private RpcSaslProto.Builder createSaslReply(SaslState state,\n                                               byte[] responseToken) {\n    RpcSaslProto.Builder response = RpcSaslProto.newBuilder();\n    response.setState(state);\n    if (responseToken != null) {\n      response.setToken(ByteString.copyFrom(responseToken));\n    }\n    return response;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.SaslRpcClient.sendSaslMessage": "  private void sendSaslMessage(DataOutputStream out, RpcSaslProto message)\n      throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Sending sasl message \"+message);\n    }\n    RpcRequestMessageWrapper request =\n        new RpcRequestMessageWrapper(saslHeader, message);\n    out.writeInt(request.getLength());\n    request.write(out);\n    out.flush();    \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.SaslRpcClient.selectSaslClient": "  private SaslAuth selectSaslClient(List<SaslAuth> authTypes)\n      throws SaslException, AccessControlException, IOException {\n    SaslAuth selectedAuthType = null;\n    boolean switchToSimple = false;\n    for (SaslAuth authType : authTypes) {\n      if (!isValidAuthType(authType)) {\n        continue; // don't know what it is, try next\n      }\n      AuthMethod authMethod = AuthMethod.valueOf(authType.getMethod());\n      if (authMethod == AuthMethod.SIMPLE) {\n        switchToSimple = true;\n      } else {\n        saslClient = createSaslClient(authType);\n        if (saslClient == null) { // client lacks credentials, try next\n          continue;\n        }\n      }\n      selectedAuthType = authType;\n      break;\n    }\n    if (saslClient == null && !switchToSimple) {\n      List<String> serverAuthMethods = new ArrayList<String>();\n      for (SaslAuth authType : authTypes) {\n        serverAuthMethods.add(authType.getMethod());\n      }\n      throw new AccessControlException(\n          \"Client cannot authenticate via:\" + serverAuthMethods);\n    }\n    if (LOG.isDebugEnabled() && selectedAuthType != null) {\n      LOG.debug(\"Use \" + selectedAuthType.getMethod() +\n          \" authentication for protocol \" + protocol.getSimpleName());\n    }\n    return selectedAuthType;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.SaslRpcClient.saslEvaluateToken": "  private byte[] saslEvaluateToken(RpcSaslProto saslResponse,\n      boolean serverIsDone) throws SaslException {\n    byte[] saslToken = null;\n    if (saslResponse.hasToken()) {\n      saslToken = saslResponse.getToken().toByteArray();\n      saslToken = saslClient.evaluateChallenge(saslToken);\n    } else if (!serverIsDone) {\n      // the server may only omit a token when it's done\n      throw new SaslException(\"Server challenge contains no token\");\n    }\n    if (serverIsDone) {\n      // server tried to report success before our client completed\n      if (!saslClient.isComplete()) {\n        throw new SaslException(\"Client is out of sync with server\");\n      }\n      // a client cannot generate a response to a success message\n      if (saslToken != null) {\n        throw new SaslException(\"Client generated spurious response\");        \n      }\n    }\n    return saslToken;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupSaslConnection": "    private synchronized AuthMethod setupSaslConnection(final InputStream in2, \n        final OutputStream out2) throws IOException {\n      // Do not use Client.conf here! We must use ConnectionId.conf, since the\n      // Client object is cached and shared between all RPC clients, even those\n      // for separate services.\n      saslRpcClient = new SaslRpcClient(remoteId.getTicket(),\n          remoteId.getProtocol(), remoteId.getAddress(), remoteId.conf);\n      return saslRpcClient.saslConnect(in2, out2);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getTicket": "    UserGroupInformation getTicket() {\n      return ticket;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getAddress": "    InetSocketAddress getAddress() {\n      return address;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getProtocol": "    Class<?> getProtocol() {\n      return protocol;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.run": "          public void run() {\n            try {\n              synchronized (Connection.this.out) {\n                if (shouldCloseConnection.get()) {\n                  return;\n                }\n                \n                if (LOG.isDebugEnabled())\n                  LOG.debug(getName() + \" sending #\" + call.id);\n         \n                byte[] data = d.getData();\n                int totalLength = d.getLength();\n                out.writeInt(totalLength); // Total Length\n                out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest\n                out.flush();\n              }\n            } catch (IOException e) {\n              // exception at this point would leave the connection in an\n              // unrecoverable state (eg half a call left on the wire).\n              // So, close the connection, killing any outstanding calls\n              markClosed(e);\n            } finally {\n              //the buffer is just an in-memory buffer, but it is still polite to\n              // close early\n              IOUtils.closeStream(d);\n            }\n          }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.get": "        public Writable get() throws InterruptedException, ExecutionException {\n          if (callled.compareAndSet(false, true)) {\n            try {\n              set(getRpcResponse(call, connection));\n            } catch (IOException ie) {\n              setException(ie);\n            } finally {\n              releaseAsyncCall();\n            }\n          }\n          return super.get();\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.shouldAuthenticateOverKrb": "    private synchronized boolean shouldAuthenticateOverKrb() throws IOException {\n      UserGroupInformation loginUser = UserGroupInformation.getLoginUser();\n      UserGroupInformation currentUser = UserGroupInformation.getCurrentUser();\n      UserGroupInformation realUser = currentUser.getRealUser();\n      if (authMethod == AuthMethod.KERBEROS && loginUser != null &&\n      // Make sure user logged in using Kerberos either keytab or TGT\n          loginUser.hasKerberosCredentials() &&\n          // relogin only in case it is the login user (e.g. JT)\n          // or superuser (like oozie).\n          (loginUser.equals(currentUser) || loginUser.equals(realUser))) {\n        return true;\n      }\n      return false;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.close": "  public void close() throws Exception {\n    stop();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.disposeSasl": "    private synchronized void disposeSasl() {\n      if (saslRpcClient != null) {\n        try {\n          saslRpcClient.dispose();\n          saslRpcClient = null;\n        } catch (IOException ignored) {\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.closeConnection": "    private void closeConnection() {\n      if (socket == null) {\n        return;\n      }\n      // close the current connection\n      try {\n        socket.close();\n      } catch (IOException e) {\n        LOG.warn(\"Not able to close a socket\", e);\n      }\n      // set socket to null so that the next call to setupIOstreams\n      // can start the process of connect all over again.\n      socket = null;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.markClosed": "    private synchronized void markClosed(IOException e) {\n      if (shouldCloseConnection.compareAndSet(false, true)) {\n        closeException = e;\n        notifyAll();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.waitForWork": "    private synchronized boolean waitForWork() {\n      if (calls.isEmpty() && !shouldCloseConnection.get()  && running.get())  {\n        long timeout = maxIdleTime-\n              (Time.now()-lastActivity.get());\n        if (timeout>0) {\n          try {\n            wait(timeout);\n          } catch (InterruptedException e) {}\n        }\n      }\n      \n      if (!calls.isEmpty() && !shouldCloseConnection.get() && running.get()) {\n        return true;\n      } else if (shouldCloseConnection.get()) {\n        return false;\n      } else if (calls.isEmpty()) { // idle connection closed or stopped\n        markClosed(null);\n        return false;\n      } else { // get stopped but there are still pending requests \n        markClosed((IOException)new IOException().initCause(\n            new InterruptedException()));\n        return false;\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.receiveRpcResponse": "    private void receiveRpcResponse() {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n      touch();\n      \n      try {\n        int totalLen = in.readInt();\n        RpcResponseHeaderProto header = \n            RpcResponseHeaderProto.parseDelimitedFrom(in);\n        checkResponse(header);\n\n        int headerLen = header.getSerializedSize();\n        headerLen += CodedOutputStream.computeRawVarint32Size(headerLen);\n\n        int callId = header.getCallId();\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \" got value #\" + callId);\n\n        RpcStatusProto status = header.getStatus();\n        if (status == RpcStatusProto.SUCCESS) {\n          Writable value = ReflectionUtils.newInstance(valueClass, conf);\n          value.readFields(in);                 // read value\n          final Call call = calls.remove(callId);\n          call.setRpcResponse(value);\n          \n          // verify that length was correct\n          // only for ProtobufEngine where len can be verified easily\n          if (call.getRpcResponse() instanceof ProtobufRpcEngine.RpcWrapper) {\n            ProtobufRpcEngine.RpcWrapper resWrapper = \n                (ProtobufRpcEngine.RpcWrapper) call.getRpcResponse();\n            if (totalLen != headerLen + resWrapper.getLength()) { \n              throw new RpcClientException(\n                  \"RPC response length mismatch on rpc success\");\n            }\n          }\n        } else { // Rpc Request failed\n          // Verify that length was correct\n          if (totalLen != headerLen) {\n            throw new RpcClientException(\n                \"RPC response length mismatch on rpc error\");\n          }\n          \n          final String exceptionClassName = header.hasExceptionClassName() ?\n                header.getExceptionClassName() : \n                  \"ServerDidNotSetExceptionClassName\";\n          final String errorMsg = header.hasErrorMsg() ? \n                header.getErrorMsg() : \"ServerDidNotSetErrorMsg\" ;\n          final RpcErrorCodeProto erCode = \n                    (header.hasErrorDetail() ? header.getErrorDetail() : null);\n          if (erCode == null) {\n             LOG.warn(\"Detailed error code not set by server on rpc error\");\n          }\n          RemoteException re = new RemoteException(exceptionClassName, errorMsg, erCode);\n          if (status == RpcStatusProto.ERROR) {\n            final Call call = calls.remove(callId);\n            call.setException(re);\n          } else if (status == RpcStatusProto.FATAL) {\n            // Close the connection\n            markClosed(re);\n          }\n        }\n      } catch (IOException e) {\n        markClosed(e);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupIOstreams": "    private synchronized void setupIOstreams(\n        AtomicBoolean fallbackToSimpleAuth) {\n      if (socket != null || shouldCloseConnection.get()) {\n        return;\n      } \n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to \"+server);\n        }\n        Span span = Tracer.getCurrentSpan();\n        if (span != null) {\n          span.addTimelineAnnotation(\"IPC client connecting to \" + server);\n        }\n        short numRetries = 0;\n        Random rand = null;\n        while (true) {\n          setupConnection();\n          InputStream inStream = NetUtils.getInputStream(socket);\n          OutputStream outStream = NetUtils.getOutputStream(socket);\n          writeConnectionHeader(outStream);\n          if (authProtocol == AuthProtocol.SASL) {\n            final InputStream in2 = inStream;\n            final OutputStream out2 = outStream;\n            UserGroupInformation ticket = remoteId.getTicket();\n            if (ticket.getRealUser() != null) {\n              ticket = ticket.getRealUser();\n            }\n            try {\n              authMethod = ticket\n                  .doAs(new PrivilegedExceptionAction<AuthMethod>() {\n                    @Override\n                    public AuthMethod run()\n                        throws IOException, InterruptedException {\n                      return setupSaslConnection(in2, out2);\n                    }\n                  });\n            } catch (IOException ex) {\n              if (saslRpcClient == null) {\n                // whatever happened -it can't be handled, so rethrow\n                throw ex;\n              }\n              // otherwise, assume a connection problem\n              authMethod = saslRpcClient.getAuthMethod();\n              if (rand == null) {\n                rand = new Random();\n              }\n              handleSaslConnectionFailure(numRetries++, maxRetriesOnSasl, ex,\n                  rand, ticket);\n              continue;\n            }\n            if (authMethod != AuthMethod.SIMPLE) {\n              // Sasl connect is successful. Let's set up Sasl i/o streams.\n              inStream = saslRpcClient.getInputStream(inStream);\n              outStream = saslRpcClient.getOutputStream(outStream);\n              // for testing\n              remoteId.saslQop =\n                  (String)saslRpcClient.getNegotiatedProperty(Sasl.QOP);\n              LOG.debug(\"Negotiated QOP is :\" + remoteId.saslQop);\n              if (fallbackToSimpleAuth != null) {\n                fallbackToSimpleAuth.set(false);\n              }\n            } else if (UserGroupInformation.isSecurityEnabled()) {\n              if (!fallbackAllowed) {\n                throw new IOException(\"Server asks us to fall back to SIMPLE \" +\n                    \"auth, but this client is configured to only allow secure \" +\n                    \"connections.\");\n              }\n              if (fallbackToSimpleAuth != null) {\n                fallbackToSimpleAuth.set(true);\n              }\n            }\n          }\n        \n          if (doPing) {\n            inStream = new PingInputStream(inStream);\n          }\n          this.in = new DataInputStream(new BufferedInputStream(inStream));\n\n          // SASL may have already buffered the stream\n          if (!(outStream instanceof BufferedOutputStream)) {\n            outStream = new BufferedOutputStream(outStream);\n          }\n          this.out = new DataOutputStream(outStream);\n          \n          writeConnectionContext(remoteId, authMethod);\n\n          // update last activity time\n          touch();\n\n          span = Tracer.getCurrentSpan();\n          if (span != null) {\n            span.addTimelineAnnotation(\"IPC client connected to \" + server);\n          }\n\n          // start the receiver thread after the socket connection has been set\n          // up\n          start();\n          return;\n        }\n      } catch (Throwable t) {\n        if (t instanceof IOException) {\n          markClosed((IOException)t);\n        } else {\n          markClosed(new IOException(\"Couldn't set up IO streams: \" + t, t));\n        }\n        close();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.handleSaslConnectionFailure": "    private synchronized void handleSaslConnectionFailure(\n        final int currRetries, final int maxRetries, final Exception ex,\n        final Random rand, final UserGroupInformation ugi) throws IOException,\n        InterruptedException {\n      ugi.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws IOException, InterruptedException {\n          final short MAX_BACKOFF = 5000;\n          closeConnection();\n          disposeSasl();\n          if (shouldAuthenticateOverKrb()) {\n            if (currRetries < maxRetries) {\n              if(LOG.isDebugEnabled()) {\n                LOG.debug(\"Exception encountered while connecting to \"\n                    + \"the server : \" + ex);\n              }\n              // try re-login\n              if (UserGroupInformation.isLoginKeytabBased()) {\n                UserGroupInformation.getLoginUser().reloginFromKeytab();\n              } else if (UserGroupInformation.isLoginTicketBased()) {\n                UserGroupInformation.getLoginUser().reloginFromTicketCache();\n              }\n              // have granularity of milliseconds\n              //we are sleeping with the Connection lock held but since this\n              //connection instance is being used for connecting to the server\n              //in question, it is okay\n              Thread.sleep((rand.nextInt(MAX_BACKOFF) + 1));\n              return null;\n            } else {\n              String msg = \"Couldn't setup connection for \"\n                  + UserGroupInformation.getLoginUser().getUserName() + \" to \"\n                  + remoteId;\n              LOG.warn(msg, ex);\n              throw (IOException) new IOException(msg).initCause(ex);\n            }\n          } else {\n            LOG.warn(\"Exception encountered while connecting to \"\n                + \"the server : \" + ex);\n          }\n          if (ex instanceof RemoteException)\n            throw (RemoteException) ex;\n          throw new IOException(ex);\n        }\n      });\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.writeConnectionContext": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      IpcConnectionContextProto message = ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod);\n      RpcRequestHeaderProto connectionContextHeader = ProtoUtil\n          .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n              OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n              RpcConstants.INVALID_RETRY_COUNT, clientId);\n      RpcRequestMessageWrapper request =\n          new RpcRequestMessageWrapper(connectionContextHeader, message);\n      \n      // Write out the packet length\n      out.writeInt(request.getLength());\n      request.write(out);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupConnection": "    private synchronized void setupConnection() throws IOException {\n      short ioFailures = 0;\n      short timeoutFailures = 0;\n      while (true) {\n        try {\n          this.socket = socketFactory.createSocket();\n          this.socket.setTcpNoDelay(tcpNoDelay);\n          this.socket.setKeepAlive(true);\n          \n          if (tcpLowLatency) {\n            /*\n             * This allows intermediate switches to shape IPC traffic\n             * differently from Shuffle/HDFS DataStreamer traffic.\n             *\n             * IPTOS_RELIABILITY (0x04) | IPTOS_LOWDELAY (0x10)\n             *\n             * Prefer to optimize connect() speed & response latency over net\n             * throughput.\n             */\n            this.socket.setTrafficClass(0x04 | 0x10);\n            this.socket.setPerformancePreferences(1, 2, 0);\n          }\n\n          /*\n           * Bind the socket to the host specified in the principal name of the\n           * client, to ensure Server matching address of the client connection\n           * to host name in principal passed.\n           */\n          UserGroupInformation ticket = remoteId.getTicket();\n          if (ticket != null && ticket.hasKerberosCredentials()) {\n            KerberosInfo krbInfo = \n              remoteId.getProtocol().getAnnotation(KerberosInfo.class);\n            if (krbInfo != null && krbInfo.clientPrincipal() != null) {\n              String host = \n                SecurityUtil.getHostFromPrincipal(remoteId.getTicket().getUserName());\n              \n              // If host name is a valid local address then bind socket to it\n              InetAddress localAddr = NetUtils.getLocalInetAddress(host);\n              if (localAddr != null) {\n                this.socket.setReuseAddress(true);\n                this.socket.bind(new InetSocketAddress(localAddr, 0));\n              }\n            }\n          }\n          \n          NetUtils.connect(this.socket, server, connectionTimeout);\n          this.socket.setSoTimeout(soTimeout);\n          return;\n        } catch (ConnectTimeoutException toe) {\n          /* Check for an address change and update the local reference.\n           * Reset the failure counter if the address was changed\n           */\n          if (updateAddress()) {\n            timeoutFailures = ioFailures = 0;\n          }\n          handleConnectionTimeout(timeoutFailures++,\n              maxRetriesOnSocketTimeouts, toe);\n        } catch (IOException ie) {\n          if (updateAddress()) {\n            timeoutFailures = ioFailures = 0;\n          }\n          handleConnectionFailure(ioFailures++, ie);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.touch": "    private void touch() {\n      lastActivity.set(Time.now());\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.writeConnectionHeader": "    private void writeConnectionHeader(OutputStream outStream)\n        throws IOException {\n      DataOutputStream out = new DataOutputStream(new BufferedOutputStream(outStream));\n      // Write out the header, version and authentication method\n      out.write(RpcConstants.HEADER.array());\n      out.write(RpcConstants.CURRENT_VERSION);\n      out.write(serviceClass);\n      out.write(authProtocol.callId);\n      out.flush();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnection": "  private Connection getConnection(ConnectionId remoteId,\n      Call call, int serviceClass, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    while (true) {\n      // These lines below can be shorten with computeIfAbsent in Java8\n      connection = connections.get(remoteId);\n      if (connection == null) {\n        connection = new Connection(remoteId, serviceClass);\n        Connection existing = connections.putIfAbsent(remoteId, connection);\n        if (existing != null) {\n          connection = existing;\n        }\n      }\n\n      if (connection.addCall(call)) {\n        break;\n      } else {\n        // This connection is closed, should be removed. But other thread could\n        // have already known this closedConnection, and replace it with a new\n        // connection. So we should call conditional remove to make sure we only\n        // remove this closedConnection.\n        connections.remove(remoteId, connection);\n      }\n    }\n\n    // If the server happens to be slow, the method below will take longer to\n    // establish a connection.\n    connection.setupIOstreams(fallbackToSimpleAuth);\n    return connection;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.addCall": "    private synchronized boolean addCall(Call call) {\n      if (shouldCloseConnection.get())\n        return false;\n      calls.put(call.id, call);\n      notify();\n      return true;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.call": "  Writable call(RPC.RpcKind rpcKind, Writable rpcRequest,\n      ConnectionId remoteId, int serviceClass,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    final Call call = createCall(rpcKind, rpcRequest);\n    final Connection connection = getConnection(remoteId, call, serviceClass,\n        fallbackToSimpleAuth);\n\n    try {\n      checkAsyncCall();\n      try {\n        connection.sendRpcRequest(call);                 // send the rpc request\n      } catch (RejectedExecutionException e) {\n        throw new IOException(\"connection has been closed\", e);\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        LOG.warn(\"interrupted waiting to send rpc request to server\", e);\n        throw new IOException(e);\n      }\n    } catch(Exception e) {\n      if (isAsynchronousMode()) {\n        releaseAsyncCall();\n      }\n      throw e;\n    }\n\n    if (isAsynchronousMode()) {\n      Future<Writable> returnFuture = new AbstractFuture<Writable>() {\n        private final AtomicBoolean callled = new AtomicBoolean(false);\n        @Override\n        public Writable get() throws InterruptedException, ExecutionException {\n          if (callled.compareAndSet(false, true)) {\n            try {\n              set(getRpcResponse(call, connection));\n            } catch (IOException ie) {\n              setException(ie);\n            } finally {\n              releaseAsyncCall();\n            }\n          }\n          return super.get();\n        }\n      };\n\n      RETURN_RPC_RESPONSE.set(returnFuture);\n      return null;\n    } else {\n      return getRpcResponse(call, connection);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.isAsynchronousMode": "  public static boolean isAsynchronousMode() {\n    return asynchronousMode.get();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.createCall": "  Call createCall(RPC.RpcKind rpcKind, Writable rpcRequest) {\n    return new Call(rpcKind, rpcRequest);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.releaseAsyncCall": "  private void releaseAsyncCall() {\n    asyncCallCounter.decrementAndGet();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.checkAsyncCall": "  private void checkAsyncCall() throws IOException {\n    if (isAsynchronousMode()) {\n      if (asyncCallCounter.incrementAndGet() > maxAsyncCalls) {\n        asyncCallCounter.decrementAndGet();\n        String errMsg = String.format(\n            \"Exceeded limit of max asynchronous calls: %d, \" +\n            \"please configure %s to adjust it.\",\n            maxAsyncCalls,\n            CommonConfigurationKeys.IPC_CLIENT_ASYNC_CALLS_MAX_KEY);\n        throw new AsyncCallLimitExceededException(errMsg);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.sendRpcRequest": "    public void sendRpcRequest(final Call call)\n        throws InterruptedException, IOException {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n\n      // Serialize the call to be sent. This is done from the actual\n      // caller thread, rather than the sendParamsExecutor thread,\n      \n      // so that if the serialization throws an error, it is reported\n      // properly. This also parallelizes the serialization.\n      //\n      // Format of a call on the wire:\n      // 0) Length of rest below (1 + 2)\n      // 1) RpcRequestHeader  - is serialized Delimited hence contains length\n      // 2) RpcRequest\n      //\n      // Items '1' and '2' are prepared here. \n      final DataOutputBuffer d = new DataOutputBuffer();\n      RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader(\n          call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry,\n          clientId);\n      header.writeDelimitedTo(d);\n      call.rpcRequest.write(d);\n\n      synchronized (sendRpcRequestLock) {\n        Future<?> senderFuture = sendParamsExecutor.submit(new Runnable() {\n          @Override\n          public void run() {\n            try {\n              synchronized (Connection.this.out) {\n                if (shouldCloseConnection.get()) {\n                  return;\n                }\n                \n                if (LOG.isDebugEnabled())\n                  LOG.debug(getName() + \" sending #\" + call.id);\n         \n                byte[] data = d.getData();\n                int totalLength = d.getLength();\n                out.writeInt(totalLength); // Total Length\n                out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest\n                out.flush();\n              }\n            } catch (IOException e) {\n              // exception at this point would leave the connection in an\n              // unrecoverable state (eg half a call left on the wire).\n              // So, close the connection, killing any outstanding calls\n              markClosed(e);\n            } finally {\n              //the buffer is just an in-memory buffer, but it is still polite to\n              // close early\n              IOUtils.closeStream(d);\n            }\n          }\n        });\n      \n        try {\n          senderFuture.get();\n        } catch (ExecutionException e) {\n          Throwable cause = e.getCause();\n          \n          // cause should only be a RuntimeException as the Runnable above\n          // catches IOException\n          if (cause instanceof RuntimeException) {\n            throw (RuntimeException) cause;\n          } else {\n            throw new RuntimeException(\"unexpected checked exception\", cause);\n          }\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRpcResponse": "  private Writable getRpcResponse(final Call call, final Connection connection)\n      throws IOException {\n    synchronized (call) {\n      while (!call.done) {\n        try {\n          call.wait();                           // wait for the result\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\"Call interrupted\");\n        }\n      }\n\n      if (call.error != null) {\n        if (call.error instanceof RemoteException) {\n          call.error.fillInStackTrace();\n          throw call.error;\n        } else { // local exception\n          InetSocketAddress address = connection.getRemoteAddress();\n          throw NetUtils.wrapException(address.getHostName(),\n                  address.getPort(),\n                  NetUtils.getHostname(),\n                  0,\n                  call.error);\n        }\n      } else {\n        return call.getRpcResponse();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setException": "    public synchronized void setException(IOException error) {\n      this.error = error;\n      callComplete();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.invoke": "    public Object invoke(Object proxy, final Method method, Object[] args)\n        throws ServiceException {\n      long startTime = 0;\n      if (LOG.isDebugEnabled()) {\n        startTime = Time.now();\n      }\n      \n      if (args.length != 2) { // RpcController + Message\n        throw new ServiceException(\"Too many parameters for request. Method: [\"\n            + method.getName() + \"]\" + \", Expected: 2, Actual: \"\n            + args.length);\n      }\n      if (args[1] == null) {\n        throw new ServiceException(\"null param while calling Method: [\"\n            + method.getName() + \"]\");\n      }\n\n      // if Tracing is on then start a new span for this rpc.\n      // guard it in the if statement to make sure there isn't\n      // any extra string manipulation.\n      Tracer tracer = Tracer.curThreadTracer();\n      TraceScope traceScope = null;\n      if (tracer != null) {\n        traceScope = tracer.newScope(RpcClientUtil.methodToTraceString(method));\n      }\n\n      RequestHeaderProto rpcRequestHeader = constructRpcRequestHeader(method);\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(Thread.currentThread().getId() + \": Call -> \" +\n            remoteId + \": \" + method.getName() +\n            \" {\" + TextFormat.shortDebugString((Message) args[1]) + \"}\");\n      }\n\n\n      Message theRequest = (Message) args[1];\n      final RpcResponseWrapper val;\n      try {\n        val = (RpcResponseWrapper) client.call(RPC.RpcKind.RPC_PROTOCOL_BUFFER,\n            new RpcRequestWrapper(rpcRequestHeader, theRequest), remoteId,\n            fallbackToSimpleAuth);\n\n      } catch (Throwable e) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Exception <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + e + \"}\");\n        }\n        if (traceScope != null) {\n          traceScope.addTimelineAnnotation(\"Call got exception: \" +\n              e.toString());\n        }\n        throw new ServiceException(e);\n      } finally {\n        if (traceScope != null) traceScope.close();\n      }\n\n      if (LOG.isDebugEnabled()) {\n        long callTime = Time.now() - startTime;\n        LOG.debug(\"Call: \" + method.getName() + \" took \" + callTime + \"ms\");\n      }\n      \n      if (Client.isAsynchronousMode()) {\n        final Future<RpcResponseWrapper> frrw = Client.getReturnRpcResponse();\n        Callable<Message> callback = new Callable<Message>() {\n          @Override\n          public Message call() throws Exception {\n            return getReturnMessage(method, frrw.get());\n          }\n        };\n        RETURN_MESSAGE_CALLBACK.set(callback);\n        return null;\n      } else {\n        return getReturnMessage(method, val);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcRequestWrapper request = (RpcRequestWrapper) writableRequest;\n        RequestHeaderProto rpcRequest = request.requestHeader;\n        String methodName = rpcRequest.getMethodName();\n        \n        \n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = prototype.newBuilderForType()\n            .mergeFrom(request.theRequestRead).build();\n        \n        Message result;\n        long startTime = Time.now();\n        int qTime = (int) (startTime - receiveTime);\n        Exception exception = null;\n        try {\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n        } catch (ServiceException e) {\n          exception = (Exception) e.getCause();\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          exception = e;\n          throw e;\n        } finally {\n          int processingTime = (int) (Time.now() - startTime);\n          if (LOG.isDebugEnabled()) {\n            String msg = \"Served: \" + methodName + \" queueTime= \" + qTime +\n                \" procesingTime= \" + processingTime;\n            if (exception != null) {\n              msg += \" exception= \" + exception.getClass().getSimpleName();\n            }\n            LOG.debug(msg);\n          }\n          String detailedMetricsName = (exception == null) ?\n              methodName :\n              exception.getClass().getSimpleName();\n          server.updateMetrics(detailedMetricsName, qTime, processingTime);\n        }\n        return new RpcResponseWrapper(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.close": "    public void close() throws IOException {\n      if (!isClosed) {\n        isClosed = true;\n        CLIENTS.stopClient(client);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.toString": "    public String toString() {\n      return requestHeader.getDeclaringClassProtocolName() + \".\" +\n          requestHeader.getMethodName();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getReturnMessage": "    private Message getReturnMessage(final Method method,\n        final RpcResponseWrapper rrw) throws ServiceException {\n      Message prototype = null;\n      try {\n        prototype = getReturnProtoType(method);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      Message returnMessage;\n      try {\n        returnMessage = prototype.newBuilderForType()\n            .mergeFrom(rrw.theResponseRead).build();\n\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Response <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + TextFormat.shortDebugString(returnMessage) + \"}\");\n        }\n\n      } catch (Throwable e) {\n        throw new ServiceException(e);\n      }\n      return returnMessage;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.constructRpcRequestHeader": "    private RequestHeaderProto constructRpcRequestHeader(Method method) {\n      RequestHeaderProto.Builder builder = RequestHeaderProto\n          .newBuilder();\n      builder.setMethodName(method.getName());\n     \n\n      // For protobuf, {@code protocol} used when creating client side proxy is\n      // the interface extending BlockingInterface, which has the annotations \n      // such as ProtocolName etc.\n      //\n      // Using Method.getDeclaringClass(), as in WritableEngine to get at\n      // the protocol interface will return BlockingInterface, from where \n      // the annotation ProtocolName and Version cannot be\n      // obtained.\n      //\n      // Hence we simply use the protocol class used to create the proxy.\n      // For PB this may limit the use of mixins on client side.\n      builder.setDeclaringClassProtocolName(protocolName);\n      builder.setClientProtocolVersion(clientProtocolVersion);\n      return builder.build();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod": "  protected Object invokeMethod(Method method, Object[] args) throws Throwable {\n    try {\n      if (!method.isAccessible()) {\n        method.setAccessible(true);\n      }\n      return method.invoke(proxyDescriptor.getProxy(), args);\n    } catch (InvocationTargetException e) {\n      throw e.getCause();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invoke": "  private Object invoke(final Method method, final Object[] args,\n      final boolean isRpc, final int callId, final Counters counters)\n      throws Throwable {\n    final RetryPolicy policy = getRetryPolicy(method);\n\n    while (true) {\n      // The number of times this invocation handler has ever been failed over,\n      // before this method invocation attempt. Used to prevent concurrent\n      // failed method invocations from triggering multiple failover attempts.\n      final long failoverCount = proxyDescriptor.getFailoverCount();\n\n      if (isRpc) {\n        Client.setCallIdAndRetryCount(callId, counters.retries);\n      }\n      try {\n        final Object ret = invokeMethod(method, args);\n        hasMadeASuccessfulCall = true;\n        return ret;\n      } catch (Exception ex) {\n        if (Thread.currentThread().isInterrupted()) {\n          // If interrupted, do not retry.\n          throw ex;\n        }\n        handleException(method, policy, failoverCount, counters, ex);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.getProxy": "    synchronized T getProxy() {\n      return proxyInfo.proxy;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.create": "  public final FSDataOutputStream create(final Path f,\n      final EnumSet<CreateFlag> createFlag, Options.CreateOpts... opts)\n      throws AccessControlException, FileAlreadyExistsException,\n      FileNotFoundException, ParentNotDirectoryException,\n      UnsupportedFileSystemException, UnresolvedLinkException, IOException {\n    checkPath(f);\n    int bufferSize = -1;\n    short replication = -1;\n    long blockSize = -1;\n    int bytesPerChecksum = -1;\n    ChecksumOpt checksumOpt = null;\n    FsPermission permission = null;\n    Progressable progress = null;\n    Boolean createParent = null;\n \n    for (CreateOpts iOpt : opts) {\n      if (CreateOpts.BlockSize.class.isInstance(iOpt)) {\n        if (blockSize != -1) {\n          throw new HadoopIllegalArgumentException(\n              \"BlockSize option is set multiple times\");\n        }\n        blockSize = ((CreateOpts.BlockSize) iOpt).getValue();\n      } else if (CreateOpts.BufferSize.class.isInstance(iOpt)) {\n        if (bufferSize != -1) {\n          throw new HadoopIllegalArgumentException(\n              \"BufferSize option is set multiple times\");\n        }\n        bufferSize = ((CreateOpts.BufferSize) iOpt).getValue();\n      } else if (CreateOpts.ReplicationFactor.class.isInstance(iOpt)) {\n        if (replication != -1) {\n          throw new HadoopIllegalArgumentException(\n              \"ReplicationFactor option is set multiple times\");\n        }\n        replication = ((CreateOpts.ReplicationFactor) iOpt).getValue();\n      } else if (CreateOpts.BytesPerChecksum.class.isInstance(iOpt)) {\n        if (bytesPerChecksum != -1) {\n          throw new HadoopIllegalArgumentException(\n              \"BytesPerChecksum option is set multiple times\");\n        }\n        bytesPerChecksum = ((CreateOpts.BytesPerChecksum) iOpt).getValue();\n      } else if (CreateOpts.ChecksumParam.class.isInstance(iOpt)) {\n        if (checksumOpt != null) {\n          throw new  HadoopIllegalArgumentException(\n              \"CreateChecksumType option is set multiple times\");\n        }\n        checksumOpt = ((CreateOpts.ChecksumParam) iOpt).getValue();\n      } else if (CreateOpts.Perms.class.isInstance(iOpt)) {\n        if (permission != null) {\n          throw new HadoopIllegalArgumentException(\n              \"Perms option is set multiple times\");\n        }\n        permission = ((CreateOpts.Perms) iOpt).getValue();\n      } else if (CreateOpts.Progress.class.isInstance(iOpt)) {\n        if (progress != null) {\n          throw new HadoopIllegalArgumentException(\n              \"Progress option is set multiple times\");\n        }\n        progress = ((CreateOpts.Progress) iOpt).getValue();\n      } else if (CreateOpts.CreateParent.class.isInstance(iOpt)) {\n        if (createParent != null) {\n          throw new HadoopIllegalArgumentException(\n              \"CreateParent option is set multiple times\");\n        }\n        createParent = ((CreateOpts.CreateParent) iOpt).getValue();\n      } else {\n        throw new HadoopIllegalArgumentException(\"Unkown CreateOpts of type \" +\n            iOpt.getClass().getName());\n      }\n    }\n    if (permission == null) {\n      throw new HadoopIllegalArgumentException(\"no permission supplied\");\n    }\n\n\n    FsServerDefaults ssDef = getServerDefaults();\n    if (ssDef.getBlockSize() % ssDef.getBytesPerChecksum() != 0) {\n      throw new IOException(\"Internal error: default blockSize is\" + \n          \" not a multiple of default bytesPerChecksum \");\n    }\n    \n    if (blockSize == -1) {\n      blockSize = ssDef.getBlockSize();\n    }\n\n    // Create a checksum option honoring user input as much as possible.\n    // If bytesPerChecksum is specified, it will override the one set in\n    // checksumOpt. Any missing value will be filled in using the default.\n    ChecksumOpt defaultOpt = new ChecksumOpt(\n        ssDef.getChecksumType(),\n        ssDef.getBytesPerChecksum());\n    checksumOpt = ChecksumOpt.processChecksumOpt(defaultOpt,\n        checksumOpt, bytesPerChecksum);\n\n    if (bufferSize == -1) {\n      bufferSize = ssDef.getFileBufferSize();\n    }\n    if (replication == -1) {\n      replication = ssDef.getReplication();\n    }\n    if (createParent == null) {\n      createParent = false;\n    }\n\n    if (blockSize % bytesPerChecksum != 0) {\n      throw new HadoopIllegalArgumentException(\n             \"blockSize should be a multiple of checksumsize\");\n    }\n\n    return this.createInternal(f, createFlag, permission, bufferSize,\n      replication, blockSize, progress, checksumOpt, createParent);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.getServerDefaults": "  public abstract FsServerDefaults getServerDefaults() throws IOException; \n\n  /**\n   * Return the fully-qualified path of path f resolving the path\n   * through any internal symlinks or mount point\n   * @param p path to be resolved\n   * @return fully qualified path \n   * @throws FileNotFoundException, AccessControlException, IOException\n   *         UnresolvedLinkException if symbolic link on path cannot be resolved\n   *          internally\n   */\n   public Path resolvePath(final Path p) throws FileNotFoundException,\n           UnresolvedLinkException, AccessControlException, IOException {\n     checkPath(p);\n     return getFileStatus(p).getPath(); // default impl is to return the path\n   }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.createInternal": "  public abstract FSDataOutputStream createInternal(Path f,\n      EnumSet<CreateFlag> flag, FsPermission absolutePermission,\n      int bufferSize, short replication, long blockSize, Progressable progress,\n      ChecksumOpt checksumOpt, boolean createParent)\n      throws AccessControlException, FileAlreadyExistsException,\n      FileNotFoundException, ParentNotDirectoryException,\n      UnsupportedFileSystemException, UnresolvedLinkException, IOException;\n\n  /**\n   * The specification of this method matches that of\n   * {@link FileContext#mkdir(Path, FsPermission, boolean)} except that the Path",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.checkPath": "  public void checkPath(Path path) {\n    URI uri = path.toUri();\n    String thatScheme = uri.getScheme();\n    String thatAuthority = uri.getAuthority();\n    if (thatScheme == null) {\n      if (thatAuthority == null) {\n        if (path.isUriPathAbsolute()) {\n          return;\n        }\n        throw new InvalidPathException(\"relative paths not allowed:\" + \n            path);\n      } else {\n        throw new InvalidPathException(\n            \"Path without scheme with non-null authority:\" + path);\n      }\n    }\n    String thisScheme = this.getUri().getScheme();\n    String thisHost = this.getUri().getHost();\n    String thatHost = uri.getHost();\n    \n    // Schemes and hosts must match.\n    // Allow for null Authority for file:///\n    if (!thisScheme.equalsIgnoreCase(thatScheme) ||\n       (thisHost != null && \n            !thisHost.equalsIgnoreCase(thatHost)) ||\n       (thisHost == null && thatHost != null)) {\n      throw new InvalidPathException(\"Wrong FS: \" + path + \", expected: \"\n          + this.getUri());\n    }\n    \n    // Ports must match, unless this FS instance is using the default port, in\n    // which case the port may be omitted from the given URI\n    int thisPort = this.getUri().getPort();\n    int thatPort = uri.getPort();\n    if (thatPort == -1) { // -1 => defaultPort of Uri scheme\n      thatPort = this.getUriDefaultPort();\n    }\n    if (thisPort != thatPort) {\n      throw new InvalidPathException(\"Wrong FS: \" + path + \", expected: \"\n          + this.getUri());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.next": "      public BlockStoragePolicySpi next(final AbstractFileSystem fs,\n          final Path p)\n          throws IOException {\n        return fs.getStoragePolicy(p);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.modifyAclEntries": "  public void modifyAclEntries(final Path path, final List<AclEntry> aclSpec)\n      throws IOException {\n    Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.modifyAclEntries(p, aclSpec);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.removeAclEntries": "  public void removeAclEntries(final Path path, final List<AclEntry> aclSpec)\n      throws IOException {\n    Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.removeAclEntries(p, aclSpec);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.open": "  public FSDataInputStream open(final Path f, final int bufferSize)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<FSDataInputStream>() {\n      @Override\n      public FSDataInputStream next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.open(p, bufferSize);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.listCorruptFileBlocks": "  public RemoteIterator<Path> listCorruptFileBlocks(Path path)\n    throws IOException {\n    final Path absF = fixRelativePart(path);\n    return new FSLinkResolver<RemoteIterator<Path>>() {\n      @Override\n      public RemoteIterator<Path> next(final AbstractFileSystem fs,\n                                       final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.listCorruptFileBlocks(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.setXAttr": "  public void setXAttr(Path path, final String name, final byte[] value,\n      final EnumSet<XAttrSetFlag> flag) throws IOException {\n    final Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.setXAttr(p, name, value, flag);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.removeDefaultAcl": "  public void removeDefaultAcl(Path path)\n      throws IOException {\n    Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.removeDefaultAcl(p);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.setAcl": "  public void setAcl(Path path, final List<AclEntry> aclSpec)\n      throws IOException {\n    Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.setAcl(p, aclSpec);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.renameSnapshot": "  public void renameSnapshot(final Path path, final String snapshotOldName,\n      final String snapshotNewName) throws IOException {\n    final Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.renameSnapshot(p, snapshotOldName, snapshotNewName);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.rename": "  public void rename(final Path src, final Path dst,\n      final Options.Rename... options) throws AccessControlException,\n      FileAlreadyExistsException, FileNotFoundException,\n      ParentNotDirectoryException, UnsupportedFileSystemException,\n      IOException {\n    final Path absSrc = fixRelativePart(src);\n    final Path absDst = fixRelativePart(dst);\n    AbstractFileSystem srcFS = getFSofPath(absSrc);\n    AbstractFileSystem dstFS = getFSofPath(absDst);\n    if(!srcFS.getUri().equals(dstFS.getUri())) {\n      throw new IOException(\"Renames across AbstractFileSystems not supported\");\n    }\n    try {\n      srcFS.rename(absSrc, absDst, options);\n    } catch (UnresolvedLinkException e) {\n      /* We do not know whether the source or the destination path\n       * was unresolved. Resolve the source path up until the final\n       * path component, then fully resolve the destination. \n       */\n      final Path source = resolveIntermediate(absSrc);    \n      new FSLinkResolver<Void>() {\n        @Override\n        public Void next(final AbstractFileSystem fs, final Path p) \n          throws IOException, UnresolvedLinkException {\n          fs.rename(source, p, options);\n          return null;\n        }\n      }.resolve(this, absDst);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.access": "  public void access(final Path path, final FsAction mode)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absPath = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(AbstractFileSystem fs, Path p) throws IOException,\n          UnresolvedLinkException {\n        fs.access(p, mode);\n        return null;\n      }\n    }.resolve(this, absPath);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getFileLinkStatus": "  public FileStatus getFileLinkStatus(final Path f)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<FileStatus>() {\n      @Override\n      public FileStatus next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        FileStatus fi = fs.getFileLinkStatus(p);\n        if (fi.isSymlink()) {\n          fi.setSymlink(FSLinkResolver.qualifySymlinkTarget(fs.getUri(), p,\n              fi.getSymlink()));\n        }\n        return fi;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.createSnapshot": "  public Path createSnapshot(final Path path, final String snapshotName)\n      throws IOException {\n    final Path absF = fixRelativePart(path);\n    return new FSLinkResolver<Path>() {\n\n      @Override\n      public Path next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        return fs.createSnapshot(p, snapshotName);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.create": "  public FSDataOutputStream create(final Path f,\n      final EnumSet<CreateFlag> createFlag, Options.CreateOpts... opts)\n      throws AccessControlException, FileAlreadyExistsException,\n      FileNotFoundException, ParentNotDirectoryException,\n      UnsupportedFileSystemException, IOException {\n    Path absF = fixRelativePart(f);\n\n    // If one of the options is a permission, extract it & apply umask\n    // If not, add a default Perms and apply umask;\n    // AbstractFileSystem#create\n\n    CreateOpts.Perms permOpt = CreateOpts.getOpt(CreateOpts.Perms.class, opts);\n    FsPermission permission = (permOpt != null) ? permOpt.getValue() :\n                                      FILE_DEFAULT_PERM;\n    permission = permission.applyUMask(umask);\n\n    final CreateOpts[] updatedOpts = \n                      CreateOpts.setOpt(CreateOpts.perms(permission), opts);\n    return new FSLinkResolver<FSDataOutputStream>() {\n      @Override\n      public FSDataOutputStream next(final AbstractFileSystem fs, final Path p) \n        throws IOException {\n        return fs.create(p, createFlag, updatedOpts);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.removeXAttr": "  public void removeXAttr(Path path, final String name) throws IOException {\n    final Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.removeXAttr(p, name);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.resolvePath": "  public Path resolvePath(final Path f) throws FileNotFoundException,\n      UnresolvedLinkException, AccessControlException, IOException {\n    return resolve(f);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.setPermission": "  public void setPermission(final Path f, final FsPermission permission)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        fs.setPermission(p, permission);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.listLocatedStatus": "  public RemoteIterator<LocatedFileStatus> listLocatedStatus(\n      final Path f) throws\n      AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<RemoteIterator<LocatedFileStatus>>() {\n      @Override\n      public RemoteIterator<LocatedFileStatus> next(\n          final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.listLocatedStatus(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getXAttrs": "  public Map<String, byte[]> getXAttrs(Path path, final List<String> names)\n      throws IOException {\n    final Path absF = fixRelativePart(path);\n    return new FSLinkResolver<Map<String, byte[]>>() {\n      @Override\n      public Map<String, byte[]> next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        return fs.getXAttrs(p, names);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.removeAcl": "  public void removeAcl(Path path) throws IOException {\n    Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.removeAcl(p);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getAclStatus": "  public AclStatus getAclStatus(Path path) throws IOException {\n    Path absF = fixRelativePart(path);\n    return new FSLinkResolver<AclStatus>() {\n      @Override\n      public AclStatus next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        return fs.getAclStatus(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.truncate": "  public boolean truncate(final Path f, final long newLength)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<Boolean>() {\n      @Override\n      public Boolean next(final AbstractFileSystem fs, final Path p)\n          throws IOException, UnresolvedLinkException {\n        return fs.truncate(p, newLength);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getFileChecksum": "  public FileChecksum getFileChecksum(final Path f)\n      throws AccessControlException, FileNotFoundException,\n      IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<FileChecksum>() {\n      @Override\n      public FileChecksum next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.getFileChecksum(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.hasNext": "        public boolean hasNext() throws IOException {\n          while (curFile == null) {\n            if (curItor.hasNext()) {\n              handleFileStat(curItor.next());\n            } else if (!itors.empty()) {\n              curItor = itors.pop();\n            } else {\n              return false;\n            }\n          }\n          return true;\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getXAttr": "  public byte[] getXAttr(Path path, final String name) throws IOException {\n    final Path absF = fixRelativePart(path);\n    return new FSLinkResolver<byte[]>() {\n      @Override\n      public byte[] next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        return fs.getXAttr(p, name);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.delete": "  public boolean delete(final Path f, final boolean recursive)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    Path absF = fixRelativePart(f);\n    return new FSLinkResolver<Boolean>() {\n      @Override\n      public Boolean next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.delete(p, recursive);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.deleteSnapshot": "  public void deleteSnapshot(final Path path, final String snapshotName)\n      throws IOException {\n    final Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.deleteSnapshot(p, snapshotName);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getStoragePolicy": "  public BlockStoragePolicySpi getStoragePolicy(Path path) throws IOException {\n    final Path absF = fixRelativePart(path);\n    return new FSLinkResolver<BlockStoragePolicySpi>() {\n      @Override\n      public BlockStoragePolicySpi next(final AbstractFileSystem fs,\n          final Path p)\n          throws IOException {\n        return fs.getStoragePolicy(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.mkdir": "  public void mkdir(final Path dir, final FsPermission permission,\n      final boolean createParent) throws AccessControlException,\n      FileAlreadyExistsException, FileNotFoundException,\n      ParentNotDirectoryException, UnsupportedFileSystemException, \n      IOException {\n    final Path absDir = fixRelativePart(dir);\n    final FsPermission absFerms = (permission == null ? \n          FsPermission.getDirDefault() : permission).applyUMask(umask);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        fs.mkdir(p, absFerms, createParent);\n        return null;\n      }\n    }.resolve(this, absDir);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getFileBlockLocations": "  public BlockLocation[] getFileBlockLocations(final Path f, final long start,\n      final long len) throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<BlockLocation[]>() {\n      @Override\n      public BlockLocation[] next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.getFileBlockLocations(p, start, len);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.setOwner": "  public void setOwner(final Path f, final String username,\n      final String groupname) throws AccessControlException,\n      UnsupportedFileSystemException, FileNotFoundException,\n      IOException {\n    if ((username == null) && (groupname == null)) {\n      throw new HadoopIllegalArgumentException(\n          \"username and groupname cannot both be null\");\n    }\n    final Path absF = fixRelativePart(f);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        fs.setOwner(p, username, groupname);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.setTimes": "  public void setTimes(final Path f, final long mtime, final long atime)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        fs.setTimes(p, mtime, atime);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.listXAttrs": "  public List<String> listXAttrs(Path path) throws IOException {\n    final Path absF = fixRelativePart(path);\n    return new FSLinkResolver<List<String>>() {\n      @Override\n      public List<String> next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        return fs.listXAttrs(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.unsetStoragePolicy": "  public void unsetStoragePolicy(final Path src) throws IOException {\n    final Path absF = fixRelativePart(src);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.unsetStoragePolicy(src);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.setReplication": "  public boolean setReplication(final Path f, final short replication)\n      throws AccessControlException, FileNotFoundException,\n      IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<Boolean>() {\n      @Override\n      public Boolean next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.setReplication(p, replication);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.createSymlink": "  public void createSymlink(final Path target, final Path link,\n      final boolean createParent) throws AccessControlException,\n      FileAlreadyExistsException, FileNotFoundException,\n      ParentNotDirectoryException, UnsupportedFileSystemException, \n      IOException { \n    if (!FileSystem.areSymlinksEnabled()) {\n      throw new UnsupportedOperationException(\"Symlinks not supported\");\n    }\n    final Path nonRelLink = fixRelativePart(link);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        fs.createSymlink(target, p, createParent);\n        return null;\n      }\n    }.resolve(this, nonRelLink);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.setStoragePolicy": "  public void setStoragePolicy(final Path path, final String policyName)\n      throws IOException {\n    final Path absF = fixRelativePart(path);\n    new FSLinkResolver<Void>() {\n      @Override\n      public Void next(final AbstractFileSystem fs, final Path p)\n          throws IOException {\n        fs.setStoragePolicy(path, policyName);\n        return null;\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getFileStatus": "  public FileStatus getFileStatus(final Path f) throws AccessControlException,\n      FileNotFoundException, UnsupportedFileSystemException, IOException {\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<FileStatus>() {\n      @Override\n      public FileStatus next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.getFileStatus(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getFsStatus": "  public FsStatus getFsStatus(final Path f) throws AccessControlException,\n      FileNotFoundException, UnsupportedFileSystemException, IOException {\n    if (f == null) {\n      return defaultFS.getFsStatus();\n    }\n    final Path absF = fixRelativePart(f);\n    return new FSLinkResolver<FsStatus>() {\n      @Override\n      public FsStatus next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.getFsStatus(p);\n      }\n    }.resolve(this, absF);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.listStatus": "    public FileStatus[] listStatus(final Path f) throws AccessControlException,\n        FileNotFoundException, UnsupportedFileSystemException,\n        IOException {\n      final Path absF = fixRelativePart(f);\n      return new FSLinkResolver<FileStatus[]>() {\n        @Override\n        public FileStatus[] next(final AbstractFileSystem fs, final Path p) \n          throws IOException, UnresolvedLinkException {\n          return fs.listStatus(p);\n        }\n      }.resolve(FileContext.this, absF);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcClientUtil.methodToTraceString": "  public static String methodToTraceString(Method method) {\n    Class<?> clazz = method.getDeclaringClass();\n    while (true) {\n      Class<?> next = clazz.getEnclosingClass();\n      if (next == null || next.getEnclosingClass() == null) break;\n      clazz = next;\n    }\n    return clazz.getSimpleName() + \"#\" + method.getName();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getReturnRpcResponse": "  public static <T> Future<T> getReturnRpcResponse() {\n    return (Future<T>) RETURN_RPC_RESPONSE.get();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FsServerDefaults.getChecksumType": "  public DataChecksum.Type getChecksumType() {\n    return checksumType;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FsServerDefaults.getFileBufferSize": "  public int getFileBufferSize() {\n    return fileBufferSize;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FsServerDefaults.getReplication": "  public short getReplication() {\n    return replication;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FsServerDefaults.getBlockSize": "  public long getBlockSize() {\n    return blockSize;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FsServerDefaults.getBytesPerChecksum": "  public int getBytesPerChecksum() {\n    return bytesPerChecksum;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.isSymlink": "  public boolean isSymlink() {\n    return symlink != null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FSLinkResolver.qualifySymlinkTarget": "  public static Path qualifySymlinkTarget(final URI pathURI,\n      Path pathWithLink, Path target) {\n    // NB: makeQualified uses the target's scheme and authority, if\n    // specified, and the scheme and authority of pathURI, if not.\n    final URI targetUri = target.toUri();\n    final String scheme = targetUri.getScheme();\n    final String auth = targetUri.getAuthority();\n    return (scheme == null && auth == null) ? target.makeQualified(pathURI,\n        pathWithLink.getParent()) : target;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.setSymlink": "  public void setSymlink(final Path p) {\n    symlink = p;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.getSymlink": "  public Path getSymlink() throws IOException {\n    if (!isSymlink()) {\n      throw new IOException(\"Path \" + path + \" is not a symbolic link\");\n    }\n    return symlink;\n  }"
        },
        "bug_report": {
            "Title": "Yarn Application log Aggreagation fails due to NM can not get correct HDFS delegation token",
            "Description": "Environment : HA cluster\n\nYarn application logs for long running application could not be gathered because Nodemanager failed to talk to HDFS with below error.\n{code}\n2016-05-16 18:18:28,533 INFO  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:finishLogAggregation(555)) - Application just finished : application_1463170334122_0002\n2016-05-16 18:18:28,545 WARN  ipc.Client (Client.java:run(705)) - Exception encountered while connecting to the server :\norg.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 171 for hrt_qa) can't be found in cache\n        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:375)\n        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:583)\n        at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:398)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:752)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:748)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1719)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:747)\n        at org.apache.hadoop.ipc.Client$Connection.access$3100(Client.java:398)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1597)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1439)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:240)\n        at com.sun.proxy.$Proxy83.getServerDefaults(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getServerDefaults(ClientNamenodeProtocolTranslatorPB.java:282)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)\n        at com.sun.proxy.$Proxy84.getServerDefaults(Unknown Source)\n        at org.apache.hadoop.hdfs.DFSClient.getServerDefaults(DFSClient.java:1018)\n        at org.apache.hadoop.fs.Hdfs.getServerDefaults(Hdfs.java:156)\n        at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:550)\n        at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:687)\n{code}"
        }
    },
    {
        "filename": "YARN-3971.json",
        "creation_time": "2015-07-24T10:17:05.000+0000",
        "stack_trace": "```\njava.io.IOException: Cannot remove label=x, because queue=a1 is using this label. Please remove label on queue before remove the label\n        at org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.checkRemoveFromClusterNodeLabelsOfQueue(RMNodeLabelsManager.java:104)\n        at org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.removeFromClusterNodeLabels(RMNodeLabelsManager.java:118)\n        at org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore.recover(FileSystemNodeLabelsStore.java:221)\n        at org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.initNodeLabelStore(CommonNodeLabelsManager.java:232)\n        at org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.serviceStart(CommonNodeLabelsManager.java:245)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:587)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:964)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1005)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1001)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1666)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1001)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:312)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:832)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:422)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.checkRemoveFromClusterNodeLabelsOfQueue": "  protected void checkRemoveFromClusterNodeLabelsOfQueue(\n      Collection<String> labelsToRemove) throws IOException {\n    // Check if label to remove doesn't existed or null/empty, will throw\n    // exception if any of labels to remove doesn't meet requirement\n    for (String label : labelsToRemove) {\n      label = normalizeLabel(label);\n\n      // check if any queue contains this label\n      for (Entry<String, Queue> entry : queueCollections.entrySet()) {\n        String queueName = entry.getKey();\n        Set<String> queueLabels = entry.getValue().accessibleNodeLabels;\n        if (queueLabels.contains(label)) {\n          throw new IOException(\"Cannot remove label=\" + label\n              + \", because queue=\" + queueName + \" is using this label. \"\n              + \"Please remove label on queue before remove the label\");\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.removeFromClusterNodeLabels": "  public void removeFromClusterNodeLabels(Collection<String> labelsToRemove)\n      throws IOException {\n    try {\n      writeLock.lock();\n\n      checkRemoveFromClusterNodeLabelsOfQueue(labelsToRemove);\n\n      // copy before NMs\n      Map<String, Host> before = cloneNodeMap();\n\n      super.removeFromClusterNodeLabels(labelsToRemove);\n\n      updateResourceMappings(before, nodeCollections);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.cloneNodeMap": "  private Map<String, Host> cloneNodeMap() {\n    Set<NodeId> nodesToCopy = new HashSet<NodeId>();\n    for (String nodeName : nodeCollections.keySet()) {\n      nodesToCopy.add(NodeId.newInstance(nodeName, WILDCARD_PORT));\n    }\n    return cloneNodeMap(nodesToCopy);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.updateResourceMappings": "  private void updateResourceMappings(Map<String, Host> before,\n      Map<String, Host> after) {\n    // Get NMs in before only\n    Set<NodeId> allNMs = new HashSet<NodeId>();\n    for (Entry<String, Host> entry : before.entrySet()) {\n      allNMs.addAll(entry.getValue().nms.keySet());\n    }\n    for (Entry<String, Host> entry : after.entrySet()) {\n      allNMs.addAll(entry.getValue().nms.keySet());\n    }\n    \n    // Map used to notify RM\n    Map<NodeId, Set<String>> newNodeToLabelsMap =\n        new HashMap<NodeId, Set<String>>();\n\n    // traverse all nms\n    for (NodeId nodeId : allNMs) {\n      Node oldNM;\n      if ((oldNM = getNMInNodeSet(nodeId, before, true)) != null) {\n        Set<String> oldLabels = getLabelsByNode(nodeId, before);\n        // no label in the past\n        if (oldLabels.isEmpty()) {\n          // update labels\n          RMNodeLabel label = labelCollections.get(NO_LABEL);\n          label.removeNode(oldNM.resource);\n\n          // update queues, all queue can access this node\n          for (Queue q : queueCollections.values()) {\n            Resources.subtractFrom(q.resource, oldNM.resource);\n          }\n        } else {\n          // update labels\n          for (String labelName : oldLabels) {\n            RMNodeLabel label = labelCollections.get(labelName);\n            if (null == label) {\n              continue;\n            }\n            label.removeNode(oldNM.resource);\n          }\n\n          // update queues, only queue can access this node will be subtract\n          for (Queue q : queueCollections.values()) {\n            if (isNodeUsableByQueue(oldLabels, q)) {\n              Resources.subtractFrom(q.resource, oldNM.resource);\n            }\n          }\n        }\n      }\n\n      Node newNM;\n      if ((newNM = getNMInNodeSet(nodeId, after, true)) != null) {\n        Set<String> newLabels = getLabelsByNode(nodeId, after);\n        \n        newNodeToLabelsMap.put(nodeId, ImmutableSet.copyOf(newLabels));\n        \n        // no label in the past\n        if (newLabels.isEmpty()) {\n          // update labels\n          RMNodeLabel label = labelCollections.get(NO_LABEL);\n          label.addNode(newNM.resource);\n\n          // update queues, all queue can access this node\n          for (Queue q : queueCollections.values()) {\n            Resources.addTo(q.resource, newNM.resource);\n          }\n        } else {\n          // update labels\n          for (String labelName : newLabels) {\n            RMNodeLabel label = labelCollections.get(labelName);\n            label.addNode(newNM.resource);\n          }\n\n          // update queues, only queue can access this node will be subtract\n          for (Queue q : queueCollections.values()) {\n            if (isNodeUsableByQueue(newLabels, q)) {\n              Resources.addTo(q.resource, newNM.resource);\n            }\n          }\n        }\n      }\n    }\n    \n    // Notify RM\n    if (rmContext != null && rmContext.getDispatcher() != null) {\n      rmContext.getDispatcher().getEventHandler().handle(\n          new NodeLabelsUpdateSchedulerEvent(newNodeToLabelsMap));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore.recover": "  public void recover(boolean ignoreNodeToLabelsMappings) throws YarnException,\n      IOException {\n    /*\n     * Steps of recover\n     * 1) Read from last mirror (from mirror or mirror.old)\n     * 2) Read from last edit log, and apply such edit log\n     * 3) Write new mirror to mirror.writing\n     * 4) Rename mirror to mirror.old\n     * 5) Move mirror.writing to mirror\n     * 6) Remove mirror.old\n     * 7) Remove edit log and create a new empty edit log \n     */\n    \n    // Open mirror from serialized file\n    Path mirrorPath = new Path(fsWorkingPath, MIRROR_FILENAME);\n    Path oldMirrorPath = new Path(fsWorkingPath, MIRROR_FILENAME + \".old\");\n\n    FSDataInputStream is = null;\n    if (fs.exists(mirrorPath)) {\n      is = fs.open(mirrorPath);\n    } else if (fs.exists(oldMirrorPath)) {\n      is = fs.open(oldMirrorPath);\n    }\n\n    if (null != is) {\n      List<NodeLabel> labels =\n          new AddToClusterNodeLabelsRequestPBImpl(\n              AddToClusterNodeLabelsRequestProto.parseDelimitedFrom(is)).getNodeLabels();\n      Map<NodeId, Set<String>> nodeToLabels =\n          new ReplaceLabelsOnNodeRequestPBImpl(\n              ReplaceLabelsOnNodeRequestProto.parseDelimitedFrom(is))\n              .getNodeToLabels();\n      mgr.addToCluserNodeLabels(labels);\n      mgr.replaceLabelsOnNode(nodeToLabels);\n      is.close();\n    }\n\n    // Open and process editlog\n    editLogPath = new Path(fsWorkingPath, EDITLOG_FILENAME);\n    if (fs.exists(editLogPath)) {\n      is = fs.open(editLogPath);\n\n      while (true) {\n        try {\n          // read edit log one by one\n          SerializedLogType type = SerializedLogType.values()[is.readInt()];\n          \n          switch (type) {\n          case ADD_LABELS: {\n            List<NodeLabel> labels =\n                new AddToClusterNodeLabelsRequestPBImpl(\n                    AddToClusterNodeLabelsRequestProto.parseDelimitedFrom(is))\n                    .getNodeLabels();\n            mgr.addToCluserNodeLabels(labels);\n            break;\n          }\n          case REMOVE_LABELS: {\n            Collection<String> labels =\n                RemoveFromClusterNodeLabelsRequestProto.parseDelimitedFrom(is)\n                    .getNodeLabelsList();\n            mgr.removeFromClusterNodeLabels(labels);\n            break;\n          }\n          case NODE_TO_LABELS: {\n            Map<NodeId, Set<String>> map =\n                new ReplaceLabelsOnNodeRequestPBImpl(\n                    ReplaceLabelsOnNodeRequestProto.parseDelimitedFrom(is))\n                    .getNodeToLabels();\n            if (!ignoreNodeToLabelsMappings) {\n              /*\n               * In case of Distributed NodeLabels setup,\n               * ignoreNodeToLabelsMappings will be set to true and recover will\n               * be invoked. As RM will collect the node labels from NM through\n               * registration/HB\n               */\n              mgr.replaceLabelsOnNode(map);\n            }\n            break;\n          }\n          }\n        } catch (EOFException e) {\n          // EOF hit, break\n          break;\n        }\n      }\n    }\n\n    // Serialize current mirror to mirror.writing\n    Path writingMirrorPath = new Path(fsWorkingPath, MIRROR_FILENAME + \".writing\");\n    FSDataOutputStream os = fs.create(writingMirrorPath, true);\n    ((AddToClusterNodeLabelsRequestPBImpl) AddToClusterNodeLabelsRequestPBImpl\n        .newInstance(mgr.getClusterNodeLabels())).getProto().writeDelimitedTo(os);\n    ((ReplaceLabelsOnNodeRequestPBImpl) ReplaceLabelsOnNodeRequest\n        .newInstance(mgr.getNodeLabels())).getProto().writeDelimitedTo(os);\n    os.close();\n    \n    // Move mirror to mirror.old\n    if (fs.exists(mirrorPath)) {\n      fs.delete(oldMirrorPath, false);\n      fs.rename(mirrorPath, oldMirrorPath);\n    }\n    \n    // move mirror.writing to mirror\n    fs.rename(writingMirrorPath, mirrorPath);\n    fs.delete(writingMirrorPath, false);\n    \n    // remove mirror.old\n    fs.delete(oldMirrorPath, false);\n    \n    // create a new editlog file\n    editlogOs = fs.create(editLogPath, true);\n    editlogOs.close();\n    \n    LOG.info(\"Finished write mirror at:\" + mirrorPath.toString());\n    LOG.info(\"Finished create editlog file at:\" + editLogPath.toString());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore.close": "  public void close() throws IOException {\n    try {\n      fs.close();\n      editlogOs.close();\n    } catch (IOException e) {\n      LOG.warn(\"Exception happened whiling shutting down,\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.initNodeLabelStore": "  protected void initNodeLabelStore(Configuration conf) throws Exception {\n    this.store = new FileSystemNodeLabelsStore(this);\n    this.store.init(conf);\n    this.store.recover(isDistributedNodeLabelConfiguration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (nodeLabelsEnabled) {\n      initNodeLabelStore(getConfig());\n    }\n    \n    // init dispatcher only when service start, because recover will happen in\n    // service init, we don't want to trigger any event handling at that time.\n    initDispatcher(getConfig());\n\n    if (null != dispatcher) {\n      dispatcher.register(NodeLabelsStoreEventType.class,\n          new ForwardingEventHandler());\n    }\n    \n    startDispatcher();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.startDispatcher": "  protected void startDispatcher() {\n    // start dispatcher\n    AsyncDispatcher asyncDispatcher = (AsyncDispatcher) dispatcher;\n    asyncDispatcher.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.initDispatcher": "  protected void initDispatcher(Configuration conf) {\n    // create async handler\n    dispatcher = new AsyncDispatcher();\n    AsyncDispatcher asyncDispatcher = (AsyncDispatcher) dispatcher;\n    asyncDispatcher.init(conf);\n    asyncDispatcher.setDrainEventsOnStop();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceStart": "  protected void serviceStart() throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": starting services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      // start the service. If this fails that service\n      // will be stopped and an exception raised\n      service.start();\n    }\n    super.serviceStart();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(true);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n\n    // Use the customized yarn filter instead of the standard kerberos filter to\n    // allow users to authenticate using delegation tokens\n    // 4 conditions need to be satisfied -\n    // 1. security is enabled\n    // 2. http auth type is set to kerberos\n    // 3. \"yarn.resourcemanager.webapp.use-yarn-filter\" override is set to true\n    // 4. hadoop.http.filter.initializers container AuthenticationFilterInitializer\n\n    Configuration conf = getConfig();\n    boolean useYarnAuthenticationFilter =\n        conf.getBoolean(\n          YarnConfiguration.RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER);\n    String authPrefix = \"hadoop.http.authentication.\";\n    String authTypeKey = authPrefix + \"type\";\n    String filterInitializerConfKey = \"hadoop.http.filter.initializers\";\n    String actualInitializers = \"\";\n    Class<?>[] initializersClasses =\n        conf.getClasses(filterInitializerConfKey);\n\n    boolean hasHadoopAuthFilterInitializer = false;\n    boolean hasRMAuthFilterInitializer = false;\n    if (initializersClasses != null) {\n      for (Class<?> initializer : initializersClasses) {\n        if (initializer.getName().equals(\n          AuthenticationFilterInitializer.class.getName())) {\n          hasHadoopAuthFilterInitializer = true;\n        }\n        if (initializer.getName().equals(\n          RMAuthenticationFilterInitializer.class.getName())) {\n          hasRMAuthFilterInitializer = true;\n        }\n      }\n      if (UserGroupInformation.isSecurityEnabled()\n          && useYarnAuthenticationFilter\n          && hasHadoopAuthFilterInitializer\n          && conf.get(authTypeKey, \"\").equals(\n            KerberosAuthenticationHandler.TYPE)) {\n        ArrayList<String> target = new ArrayList<String>();\n        for (Class<?> filterInitializer : initializersClasses) {\n          if (filterInitializer.getName().equals(\n            AuthenticationFilterInitializer.class.getName())) {\n            if (hasRMAuthFilterInitializer == false) {\n              target.add(RMAuthenticationFilterInitializer.class.getName());\n            }\n            continue;\n          }\n          target.add(filterInitializer.getName());\n        }\n        actualInitializers = StringUtils.join(\",\", target);\n\n        LOG.info(\"Using RM authentication filter(kerberos/delegation-token)\"\n            + \" for RM webapp authentication\");\n        RMAuthenticationFilter\n          .setDelegationTokenSecretManager(getClientRMService().rmDTSecretManager);\n        conf.set(filterInitializerConfKey, actualInitializers);\n      }\n    }\n\n    // if security is not enabled and the default filter initializer has not \n    // been set, set the initializer to include the\n    // RMAuthenticationFilterInitializer which in turn will set up the simple\n    // auth filter.\n\n    String initializers = conf.get(filterInitializerConfKey);\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      if (initializersClasses == null || initializersClasses.length == 0) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName());\n        conf.set(authTypeKey, \"simple\");\n      } else if (initializers.equals(StaticUserWebFilter.class.getName())) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName() + \",\"\n              + initializers);\n        conf.set(authTypeKey, \"simple\");\n      }\n    }\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .at(webAppAddress);\n    String proxyHostAndPort = WebAppUtils.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n\n    }\n    webApp = builder.start(new RMWebApp(this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) throws Exception {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive": "  public synchronized void transitionToActive(\n      HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {\n    // call refreshAdminAcls before HA state transition\n    // for the case that adminAcls have been updated in previous active RM\n    try {\n      refreshAdminAcls(false);\n    } catch (YarnException ex) {\n      throw new ServiceFailedException(\"Can not execute refreshAdminAcls\", ex);\n    }\n\n    UserGroupInformation user = checkAccess(\"transitionToActive\");\n    checkHaStateChange(reqInfo);\n    try {\n      rm.transitionToActive();\n      // call all refresh*s for active RM to get the updated configurations.\n      refreshAll();\n      RMAuditLogger.logSuccess(user.getShortUserName(),\n          \"transitionToActive\", \"RMHAProtocolService\");\n    } catch (Exception e) {\n      RMAuditLogger.logFailure(user.getShortUserName(), \"transitionToActive\",\n          \"\", \"RMHAProtocolService\",\n          \"Exception transitioning to active\");\n      throw new ServiceFailedException(\n          \"Error when transitioning to Active mode\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkHaStateChange": "  private void checkHaStateChange(StateChangeRequestInfo req)\n      throws AccessControlException {\n    switch (req.getSource()) {\n      case REQUEST_BY_USER:\n        if (autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Manual failover for this ResourceManager is disallowed, \" +\n                  \"because automatic failover is enabled.\");\n        }\n        break;\n      case REQUEST_BY_USER_FORCED:\n        if (autoFailoverEnabled) {\n          LOG.warn(\"Allowing manual failover from \" +\n              org.apache.hadoop.ipc.Server.getRemoteAddress() +\n              \" even though automatic failover is enabled, because the user \" +\n              \"specified the force flag\");\n        }\n        break;\n      case REQUEST_BY_ZKFC:\n        if (!autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Request from ZK failover controller at \" +\n                  org.apache.hadoop.ipc.Server.getRemoteAddress() + \" denied \" +\n                  \"since automatic failover is not enabled\");\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess": "  private UserGroupInformation checkAccess(String method) throws IOException {\n    return RMServerUtils.verifyAdminAccess(authorizer, method, LOG);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll": "  private void refreshAll() throws ServiceFailedException {\n    try {\n      refreshQueues(RefreshQueuesRequest.newInstance());\n      refreshNodes(RefreshNodesRequest.newInstance(DecommissionType.NORMAL));\n      refreshSuperUserGroupsConfiguration(\n          RefreshSuperUserGroupsConfigurationRequest.newInstance());\n      refreshUserToGroupsMappings(\n          RefreshUserToGroupsMappingsRequest.newInstance());\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls(RefreshServiceAclsRequest.newInstance());\n      }\n    } catch (Exception ex) {\n      throw new ServiceFailedException(ex.getMessage());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls": "  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    String argName = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), argName, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    authorizer.setAdmins(getAdminAclList(conf), UserGroupInformation\n        .getCurrentUser());\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive": "  public void becomeActive() throws ServiceFailedException {\n    try {\n      rmContext.getRMAdminService().transitionToActive(req);\n    } catch (Exception e) {\n      throw new ServiceFailedException(\"RM could not transition to Active\", e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeActive": "  private boolean becomeActive() {\n    assert wantToBeInElection;\n    if (state == State.ACTIVE) {\n      // already active\n      return true;\n    }\n    try {\n      Stat oldBreadcrumbStat = fenceOldActive();\n      writeBreadCrumbNode(oldBreadcrumbStat);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming active for \" + this);\n      }\n      appClient.becomeActive();\n      state = State.ACTIVE;\n      return true;\n    } catch (Exception e) {\n      LOG.warn(\"Exception handling the winning of election\", e);\n      // Caller will handle quitting and rejoining the election.\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.writeBreadCrumbNode": "  private void writeBreadCrumbNode(Stat oldBreadcrumbStat)\n      throws KeeperException, InterruptedException {\n    Preconditions.checkState(appData != null, \"no appdata\");\n    \n    LOG.info(\"Writing znode \" + zkBreadCrumbPath +\n        \" to indicate that the local node is the most recent active...\");\n    if (oldBreadcrumbStat == null) {\n      // No previous active, just create the node\n      createWithRetries(zkBreadCrumbPath, appData, zkAcl,\n        CreateMode.PERSISTENT);\n    } else {\n      // There was a previous active, update the node\n      setDataWithRetries(zkBreadCrumbPath, appData, oldBreadcrumbStat.getVersion());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fenceOldActive": "  private Stat fenceOldActive() throws InterruptedException, KeeperException {\n    final Stat stat = new Stat();\n    byte[] data;\n    LOG.info(\"Checking for any old active which needs to be fenced...\");\n    try {\n      data = zkDoWithRetries(new ZKAction<byte[]>() {\n        @Override\n        public byte[] run() throws KeeperException, InterruptedException {\n          return zkClient.getData(zkBreadCrumbPath, false, stat);\n        }\n      });\n    } catch (KeeperException ke) {\n      if (isNodeDoesNotExist(ke.code())) {\n        LOG.info(\"No old node to fence\");\n        return null;\n      }\n      \n      // If we failed to read for any other reason, then likely we lost\n      // our session, or we don't have permissions, etc. In any case,\n      // we probably shouldn't become active, and failing the whole\n      // thing is the best bet.\n      throw ke;\n    }\n\n    LOG.info(\"Old node exists: \" + StringUtils.byteToHexString(data));\n    if (Arrays.equals(data, appData)) {\n      LOG.info(\"But old node has our own data, so don't need to fence it.\");\n    } else {\n      appClient.fenceOldActive(data);\n    }\n    return stat;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.processResult": "  public synchronized void processResult(int rc, String path, Object ctx,\n      Stat stat) {\n    if (isStaleClient(ctx)) return;\n    monitorLockNodePending = false;\n\n    assert wantToBeInElection :\n        \"Got a StatNode result after quitting election\";\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"StatNode result: \" + rc + \" for path: \" + path\n          + \" connectionState: \" + zkConnectionState + \" for \" + this);\n    }\n\n    Code code = Code.get(rc);\n    if (isSuccess(code)) {\n      // the following owner check completes verification in case the lock znode\n      // creation was retried\n      if (stat.getEphemeralOwner() == zkClient.getSessionId()) {\n        // we own the lock znode. so we are the leader\n        if (!becomeActive()) {\n          reJoinElectionAfterFailureToBecomeActive();\n        }\n      } else {\n        // we dont own the lock znode. so we are a standby.\n        becomeStandby();\n      }\n      // the watch set by us will notify about changes\n      return;\n    }\n\n    if (isNodeDoesNotExist(code)) {\n      // the lock znode disappeared before we started monitoring it\n      enterNeutralMode();\n      joinElectionInternal();\n      return;\n    }\n\n    String errorMessage = \"Received stat error from Zookeeper. code:\"\n        + code.toString();\n    LOG.debug(errorMessage);\n\n    if (shouldRetry(code)) {\n      if (statRetryCount < maxRetryNum) {\n        ++statRetryCount;\n        monitorLockNodeAsync();\n        return;\n      }\n      errorMessage = errorMessage\n          + \". Not retrying further znode monitoring connection errors.\";\n    } else if (isSessionExpired(code)) {\n      // This isn't fatal - the client Watcher will re-join the election\n      LOG.warn(\"Lock monitoring failed because session was lost\");\n      return;\n    }\n\n    fatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code) {\n    return code == Code.CONNECTIONLOSS || code == Code.OPERATIONTIMEOUT;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.joinElectionInternal": "  private void joinElectionInternal() {\n    Preconditions.checkState(appData != null,\n        \"trying to join election without any app data\");\n    if (zkClient == null) {\n      if (!reEstablishSession()) {\n        fatalError(\"Failed to reEstablish connection with ZooKeeper\");\n        return;\n      }\n    }\n\n    createRetryCount = 0;\n    wantToBeInElection = true;\n    createLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createLockNodeAsync": "  private void createLockNodeAsync() {\n    zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,\n        this, zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSuccess": "  private static boolean isSuccess(Code code) {\n    return (code == Code.OK);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorActiveStatus": "  private void monitorActiveStatus() {\n    assert wantToBeInElection;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Monitoring active leader for \" + this);\n    }\n    statRetryCount = 0;\n    monitorLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeDoesNotExist": "  private static boolean isNodeDoesNotExist(Code code) {\n    return (code == Code.NONODE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.reJoinElectionAfterFailureToBecomeActive": "  private void reJoinElectionAfterFailureToBecomeActive() {\n    reJoinElection(SLEEP_AFTER_FAILURE_TO_BECOME_ACTIVE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.enterNeutralMode": "  private void enterNeutralMode() {\n    if (state != State.NEUTRAL) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Entering neutral mode for \" + this);\n      }\n      state = State.NEUTRAL;\n      appClient.enterNeutralMode();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorLockNodeAsync": "  private void monitorLockNodeAsync() {\n    if (monitorLockNodePending && monitorLockNodeClient == zkClient) {\n      LOG.info(\"Ignore duplicate monitor lock-node request.\");\n      return;\n    }\n    monitorLockNodePending = true;\n    monitorLockNodeClient = zkClient;\n    zkClient.exists(zkLockFilePath,\n        watcher, this,\n        zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSessionExpired": "  private static boolean isSessionExpired(Code code) {\n    return (code == Code.SESSIONEXPIRED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeStandby": "  private void becomeStandby() {\n    if (state != State.STANDBY) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming standby for \" + this);\n      }\n      state = State.STANDBY;\n      appClient.becomeStandby();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fatalError": "  private void fatalError(String errorMessage) {\n    LOG.fatal(errorMessage);\n    reset();\n    appClient.notifyFatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isStaleClient": "  private synchronized boolean isStaleClient(Object ctx) {\n    Preconditions.checkNotNull(ctx);\n    if (zkClient != (ZooKeeper)ctx) {\n      LOG.warn(\"Ignoring stale result from old client with sessionId \" +\n          String.format(\"0x%08x\", ((ZooKeeper)ctx).getSessionId()));\n      return true;\n    }\n    return false;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.start": "  void start();\n\n  /**\n   * Stop the service. This MUST be a no-op if the service is already\n   * in the {@link STATE#STOPPED} state. It SHOULD be a best-effort attempt",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ApplicationId appId,\n      ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.FAILURE, b);\n    add(Keys.DESCRIPTION, description, b);\n    add(Keys.PERMISSIONS, perm, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      ApplicationId appId, ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.SUCCESS, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMAdminService": "  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}"
        },
        "bug_report": {
            "Title": "Skip RMNodeLabelsManager#checkRemoveFromClusterNodeLabelsOfQueue on nodelabel recovery",
            "Description": "Steps to reproduce \n# Create label x,y\n# Delete label x,y\n# Create label x,y add capacity scheduler xml for labels x and y too\n# Restart RM \n \nBoth RM will become Standby.\n\nSince below exception is thrown on {{FileSystemNodeLabelsStore#recover}}\n{code}\n2015-07-23 14:03:33,627 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager failed in state STARTED; cause: java.io.IOException: Cannot remove label=x, because queue=a1 is using this label. Please remove label on queue before remove the label\njava.io.IOException: Cannot remove label=x, because queue=a1 is using this label. Please remove label on queue before remove the label\n        at org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.checkRemoveFromClusterNodeLabelsOfQueue(RMNodeLabelsManager.java:104)\n        at org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.removeFromClusterNodeLabels(RMNodeLabelsManager.java:118)\n        at org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore.recover(FileSystemNodeLabelsStore.java:221)\n        at org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.initNodeLabelStore(CommonNodeLabelsManager.java:232)\n        at org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.serviceStart(CommonNodeLabelsManager.java:245)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:587)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:964)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1005)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1001)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1666)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1001)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:312)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:832)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:422)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n\n{code}"
        }
    },
    {
        "filename": "YARN-6948.json",
        "creation_time": "2017-08-04T08:23:46.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: ATTEMPT_ADDED at FINAL_SAVING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:757)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:834)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:815)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      // Log at INFO if we're not recovering or not in a terminal state.\n      // Log at DEBUG otherwise.\n      if ((oldState != getAppAttemptState()) &&\n          ((recoveredFinalState == null) ||\n            (event.getType() != RMAppAttemptEventType.RECOVER))) {\n        LOG.info(String.format(STATE_CHANGE_MESSAGE, appAttemptID, oldState,\n            getAppAttemptState(), event.getType()));\n      } else if ((oldState != getAppAttemptState()) && LOG.isDebugEnabled()) {\n        LOG.debug(String.format(STATE_CHANGE_MESSAGE, appAttemptID, oldState,\n            getAppAttemptState(), event.getType()));\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handleTransitionToStandByInNewThread": "  private void handleTransitionToStandByInNewThread() {\n    Thread standByTransitionThread =\n        new Thread(activeServices.standByTransitionRunnable);\n    standByTransitionThread.setName(\"StandByTransitionThread\");\n    standByTransitionThread.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Invalid event: ATTEMPT_ADDED at FINAL_SAVING",
            "Description": "When I send kill command to a running job, I check the logs and find the Exception:\n\n{code:java}\n2017-08-03 01:35:20,485 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: ATTEMPT_ADDED at FINAL_SAVING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:757)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:834)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:815)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:745)\n{code}\n"
        }
    },
    {
        "filename": "YARN-1409.json",
        "creation_time": "2013-11-13T11:25:56.000+0000",
        "stack_trace": "```\njava.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@d51df63 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7a20e369[Shutting down, pool size = 4, active threads = 0, queued tasks = 7, completed tasks = 0]\n        at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)\n        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)\n        at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:325)\n        at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:530)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(NonAggregatingLogHandler.java:121)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(NonAggregatingLogHandler.java:49)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:159)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:95)\n        at java.lang.Thread.run(Thread.java:724)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle": "  public void handle(LogHandlerEvent event) {\n    switch (event.getType()) {\n      case APPLICATION_STARTED:\n        LogHandlerAppStartedEvent appStartedEvent =\n            (LogHandlerAppStartedEvent) event;\n        this.appOwners.put(appStartedEvent.getApplicationId(),\n            appStartedEvent.getUser());\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationEvent(appStartedEvent.getApplicationId(),\n                ApplicationEventType.APPLICATION_LOG_HANDLING_INITED));\n        break;\n      case CONTAINER_FINISHED:\n        // Ignore\n        break;\n      case APPLICATION_FINISHED:\n        LogHandlerAppFinishedEvent appFinishedEvent =\n            (LogHandlerAppFinishedEvent) event;\n        // Schedule - so that logs are available on the UI till they're deleted.\n        LOG.info(\"Scheduling Log Deletion for application: \"\n            + appFinishedEvent.getApplicationId() + \", with delay of \"\n            + this.deleteDelaySeconds + \" seconds\");\n        sched.schedule(\n            new LogDeleterRunnable(appOwners.remove(appFinishedEvent\n                .getApplicationId()), appFinishedEvent.getApplicationId()),\n            this.deleteDelaySeconds, TimeUnit.SECONDS);\n        break;\n      default:\n        ; // Ignore\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          drained = eventQueue.isEmpty();\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "NonAggregatingLogHandler can throw RejectedExecutionException",
            "Description": "This problem is caused by handling APPLICATION_FINISHED events after calling sched.shotdown() in NonAggregatingLongHandler#serviceStop(). org.apache.hadoop.mapred.TestJobCleanup can fail because of RejectedExecutionException by NonAggregatingLogHandler.\n\n{code}\n2013-11-13 10:53:06,970 FATAL [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(166)) - Error in dispatcher thread\njava.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@d51df63 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7a20e369[Shutting down, pool size = 4, active threads = 0, queued tasks = 7, completed tasks = 0]\n        at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)\n        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)\n        at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:325)\n        at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:530)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(NonAggregatingLogHandler.java:121)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(NonAggregatingLogHandler.java:49)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:159)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:95)\n        at java.lang.Thread.run(Thread.java:724)\n{code}"
        }
    },
    {
        "filename": "YARN-5545.json",
        "creation_time": "2016-08-21T12:57:35.000+0000",
        "stack_trace": "```\njava.io.IOException: org.apache.hadoop.yarn.exceptions.YarnException: Failed to submit application_1471670113386_0001 to YARN : org.apache.hadoop.security.AccessControlException: Queue root.default already has 0 applications, cannot accept submission of application: application_1471670113386_0001\n\tat org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:316)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:255)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1344)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n...\nCaused by: org.apache.hadoop.yarn.exceptions.YarnException: Failed to submit application_1471670113386_0001 to YARN : org.apache.hadoop.security.AccessControlException: Queue root.default already has 0 applications, cannot accept submission of application: application_1471670113386_0001\n\tat org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:286)\n\tat org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:296)\n\tat org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication": "  public ApplicationId\n      submitApplication(ApplicationSubmissionContext appContext)\n          throws YarnException, IOException {\n    ApplicationId applicationId = appContext.getApplicationId();\n    if (applicationId == null) {\n      throw new ApplicationIdNotProvidedException(\n          \"ApplicationId is not provided in ApplicationSubmissionContext\");\n    }\n    SubmitApplicationRequest request =\n        Records.newRecord(SubmitApplicationRequest.class);\n    request.setApplicationSubmissionContext(appContext);\n\n    // Automatically add the timeline DT into the CLC\n    // Only when the security and the timeline service are both enabled\n    if (isSecurityEnabled() && timelineServiceEnabled) {\n      addTimelineDelegationToken(appContext.getAMContainerSpec());\n    }\n\n    //TODO: YARN-1763:Handle RM failovers during the submitApplication call.\n    rmClient.submitApplication(request);\n\n    int pollCount = 0;\n    long startTime = System.currentTimeMillis();\n    EnumSet<YarnApplicationState> waitingStates = \n                                 EnumSet.of(YarnApplicationState.NEW,\n                                 YarnApplicationState.NEW_SAVING,\n                                 YarnApplicationState.SUBMITTED);\n    EnumSet<YarnApplicationState> failToSubmitStates = \n                                  EnumSet.of(YarnApplicationState.FAILED,\n                                  YarnApplicationState.KILLED);\t\t\n    while (true) {\n      try {\n        ApplicationReport appReport = getApplicationReport(applicationId);\n        YarnApplicationState state = appReport.getYarnApplicationState();\n        if (!waitingStates.contains(state)) {\n          if(failToSubmitStates.contains(state)) {\n            throw new YarnException(\"Failed to submit \" + applicationId + \n                \" to YARN : \" + appReport.getDiagnostics());\n          }\n          LOG.info(\"Submitted application \" + applicationId);\n          break;\n        }\n\n        long elapsedMillis = System.currentTimeMillis() - startTime;\n        if (enforceAsyncAPITimeout() &&\n            elapsedMillis >= asyncApiPollTimeoutMillis) {\n          throw new YarnException(\"Timed out while waiting for application \" +\n              applicationId + \" to be submitted successfully\");\n        }\n\n        // Notify the client through the log every 10 poll, in case the client\n        // is blocked here too long.\n        if (++pollCount % 10 == 0) {\n          LOG.info(\"Application submission is not finished, \" +\n              \"submitted application \" + applicationId +\n              \" is still in \" + state);\n        }\n        try {\n          Thread.sleep(submitPollIntervalMillis);\n        } catch (InterruptedException ie) {\n          LOG.error(\"Interrupted while waiting for application \"\n              + applicationId\n              + \" to be successfully submitted.\");\n        }\n      } catch (ApplicationNotFoundException ex) {\n        // FailOver or RM restart happens before RMStateStore saves\n        // ApplicationState\n        LOG.info(\"Re-submit application \" + applicationId + \"with the \" +\n            \"same ApplicationSubmissionContext\");\n        rmClient.submitApplication(request);\n      }\n    }\n\n    return applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.isSecurityEnabled": "  protected boolean isSecurityEnabled() {\n    return UserGroupInformation.isSecurityEnabled();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.addTimelineDelegationToken": "  private void addTimelineDelegationToken(\n      ContainerLaunchContext clc) throws YarnException, IOException {\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = clc.getTokens();\n    if (tokens != null) {\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n    // If the timeline delegation token is already in the CLC, no need to add\n    // one more\n    for (org.apache.hadoop.security.token.Token<? extends TokenIdentifier> token : credentials\n        .getAllTokens()) {\n      if (token.getKind().equals(TimelineDelegationTokenIdentifier.KIND_NAME)) {\n        return;\n      }\n    }\n    org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier>\n        timelineDelegationToken = getTimelineDelegationToken();\n    if (timelineDelegationToken == null) {\n      return;\n    }\n    credentials.addToken(timelineService, timelineDelegationToken);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Add timline delegation token into credentials: \"\n          + timelineDelegationToken);\n    }\n    DataOutputBuffer dob = new DataOutputBuffer();\n    credentials.writeTokenStorageToStream(dob);\n    tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    clc.setTokens(tokens);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.enforceAsyncAPITimeout": "  boolean enforceAsyncAPITimeout() {\n    return asyncApiPollTimeoutMillis >= 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplicationReport": "  public ApplicationReport getApplicationReport(ApplicationId appId)\n      throws YarnException, IOException {\n    GetApplicationReportResponse response = null;\n    try {\n      GetApplicationReportRequest request = Records\n          .newRecord(GetApplicationReportRequest.class);\n      request.setApplicationId(appId);\n      response = rmClient.getApplicationReport(request);\n    } catch (ApplicationNotFoundException e) {\n      if (!historyServiceEnabled) {\n        // Just throw it as usual if historyService is not enabled.\n        throw e;\n      }\n      return historyClient.getApplicationReport(appId);\n    }\n    return response.getApplicationReport();\n  }"
        },
        "bug_report": {
            "Title": "Fix issues related to Max App in capacity scheduler",
            "Description": "Issues as part of Max apps in Capacity scheduler:\n1. Cap total applications across the queue hierarchy based on existing max app calculation\n2. Introduce a new configuration to take default max apps per queue irrespective of the queue capacity configuration\n3. When the capacity configuration of the default partition is ZERO but queue has capacity for other partition then app is not getting submitted, though app is submitted in other partition\n\nSteps to reproduce Issue 3 : \n\nConfigure capacity scheduler \nyarn.scheduler.capacity.root.default.capacity=0\nyarn.scheduler.capacity.root.queue1.accessible-node-labels.labelx.capacity=50\nyarn.scheduler.capacity.root.default.accessible-node-labels.labelx.capacity=50\n\n\nSubmit application as below\n\n./yarn jar ../share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha2-SNAPSHOT-tests.jar sleep -Dmapreduce.job.node-label-expression=labelx -Dmapreduce.job.queuename=default -m 1 -r 1 -mt 10000000 -rt 1\n\n{noformat}\n2016-08-21 18:21:31,375 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1471670113386_0001\njava.io.IOException: org.apache.hadoop.yarn.exceptions.YarnException: Failed to submit application_1471670113386_0001 to YARN : org.apache.hadoop.security.AccessControlException: Queue root.default already has 0 applications, cannot accept submission of application: application_1471670113386_0001\n\tat org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:316)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:255)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1344)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n...\nCaused by: org.apache.hadoop.yarn.exceptions.YarnException: Failed to submit application_1471670113386_0001 to YARN : org.apache.hadoop.security.AccessControlException: Queue root.default already has 0 applications, cannot accept submission of application: application_1471670113386_0001\n\tat org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:286)\n\tat org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:296)\n\tat org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)\n\t... 25 more\n{noformat}\n"
        }
    },
    {
        "filename": "YARN-301.json",
        "creation_time": "2013-01-01T05:40:18.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)\n        at java.util.TreeMap$KeyIterator.next(TreeMap.java:1154)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:181)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:780)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:842)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:340)\n        at java.lang.Thread.run(Thread.java:662)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer": "  public Resource assignContainer(FSSchedulerNode node, boolean reserved) {\n    LOG.info(\"Node offered to app: \" + getName() + \" reserved: \" + reserved);\n\n    if (reserved) {\n      RMContainer rmContainer = node.getReservedContainer();\n      Priority priority = rmContainer.getReservedPriority();\n\n      // Make sure the application still needs requests at this priority\n      if (app.getTotalRequiredResources(priority) == 0) {\n        unreserve(app, priority, node);\n        return Resources.none();\n      }\n    } else {\n      // If this app is over quota, don't schedule anything\n      if (!(getRunnable())) { return Resources.none(); }\n\n    }\n    // For each priority, see if we can schedule a node local, rack local\n    // or off-switch request. Rack of off-switch requests may be delayed\n    // (not scheduled) in order to promote better locality.\n    for (Priority priority : app.getPriorities()) {\n      app.addSchedulingOpportunity(priority);\n      NodeType allowedLocality = app.getAllowedLocalityLevel(priority,\n          scheduler.getNumClusterNodes(), scheduler.getNodeLocalityThreshold(),\n          scheduler.getRackLocalityThreshold());\n\n      ResourceRequest localRequest = app.getResourceRequest(priority,\n          node.getHostName());\n      if (localRequest != null && localRequest.getNumContainers() != 0) {\n        return assignContainer(node, app, priority,\n            localRequest, NodeType.NODE_LOCAL, reserved);\n      }\n\n      ResourceRequest rackLocalRequest = app.getResourceRequest(priority,\n          node.getRackName());\n      if (rackLocalRequest != null && rackLocalRequest.getNumContainers() != 0\n          && (allowedLocality.equals(NodeType.RACK_LOCAL) ||\n              allowedLocality.equals(NodeType.OFF_SWITCH))) {\n        return assignContainer(node, app, priority, rackLocalRequest,\n            NodeType.RACK_LOCAL, reserved);\n      }\n\n      ResourceRequest offSwitchRequest = app.getResourceRequest(priority,\n          RMNode.ANY);\n      if (offSwitchRequest != null && offSwitchRequest.getNumContainers() != 0\n          && allowedLocality.equals(NodeType.OFF_SWITCH)) {\n        return assignContainer(node, app, priority, offSwitchRequest,\n            NodeType.OFF_SWITCH, reserved);\n      }\n    }\n    return Resources.none();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.createContainer": "  public Container createContainer(\n      FSSchedulerApp application, FSSchedulerNode node,\n      Resource capability, Priority priority) {\n\n    NodeId nodeId = node.getRMNode().getNodeID();\n    ContainerId containerId = BuilderUtils.newContainerId(application\n        .getApplicationAttemptId(), application.getNewContainerId());\n    ContainerToken containerToken = null;\n\n    // If security is enabled, send the container-tokens too.\n    if (UserGroupInformation.isSecurityEnabled()) {\n      containerToken =\n          containerTokenSecretManager.createContainerToken(containerId, nodeId,\n            application.getUser(), capability);\n      if (containerToken == null) {\n        return null; // Try again later.\n      }\n    }\n\n    // Create the container\n    Container container = BuilderUtils.newContainer(containerId, nodeId,\n        node.getRMNode().getHttpAddress(), capability, priority,\n        containerToken);\n\n    return container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.reserve": "  private void reserve(FSSchedulerApp application, Priority priority,\n      FSSchedulerNode node, Container container, boolean alreadyReserved) {\n    LOG.info(\"Making reservation: node=\" + node.getHostName() +\n                                 \" app_id=\" + app.getApplicationId());\n    if (!alreadyReserved) {\n      getMetrics().reserveResource(application.getUser(), container.getResource());\n      RMContainer rmContainer = application.reserve(node, priority, null,\n          container);\n      node.reserveResource(application, priority, rmContainer);\n      getMetrics().reserveResource(app.getUser(),\n          container.getResource());\n      scheduler.getRootQueueMetrics().reserveResource(app.getUser(),\n          container.getResource());\n    }\n\n    else {\n      RMContainer rmContainer = node.getReservedContainer();\n      application.reserve(node, priority, rmContainer, container);\n      node.reserveResource(application, priority, rmContainer);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getName": "  public String getName() {\n    return app.getApplicationId().toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getMetrics": "  public QueueMetrics getMetrics() {\n    return queue.getMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.unreserve": "  private void unreserve(FSSchedulerApp application, Priority priority,\n      FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    application.unreserve(node, priority);\n    node.unreserveResource(application);\n    getMetrics().unreserveResource(\n        application.getUser(), rmContainer.getContainer().getResource());\n    scheduler.getRootQueueMetrics().unreserveResource(\n        application.getUser(), rmContainer.getContainer().getResource());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getRunnable": "  public boolean getRunnable() {\n    return runnable;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer": "  public Resource assignContainer(FSSchedulerNode node, boolean reserved) {\n    LOG.debug(\"Node offered to queue: \" + getName() + \" reserved: \" + reserved);\n    // If this queue is over its limit, reject\n    if (Resources.greaterThan(getResourceUsage(),\n        queueMgr.getMaxResources(getName()))) {\n      return Resources.none();\n    }\n\n    // If this node already has reserved resources for an app, first try to\n    // finish allocating resources for that app.\n    if (reserved) {\n      for (AppSchedulable sched : appScheds) {\n        if (sched.getApp().getApplicationAttemptId() ==\n            node.getReservedContainer().getApplicationAttemptId()) {\n          return sched.assignContainer(node, reserved);\n        }\n      }\n      return Resources.none(); // We should never get here\n    }\n\n    // Otherwise, chose app to schedule based on given policy (fair vs fifo).\n    else {\n      Comparator<Schedulable> comparator;\n      if (schedulingMode == SchedulingMode.FIFO) {\n        comparator = new SchedulingAlgorithms.FifoComparator();\n      } else if (schedulingMode == SchedulingMode.FAIR) {\n        comparator = new SchedulingAlgorithms.FairShareComparator();\n      } else {\n        throw new RuntimeException(\"Unsupported queue scheduling mode \" + \n            schedulingMode);\n      }\n\n      Collections.sort(appScheds, comparator);\n      for (AppSchedulable sched: appScheds) {\n        if (sched.getRunnable()) {\n          return sched.assignContainer(node, reserved);\n        }\n      }\n\n      return Resources.none();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.getResourceUsage": "  public Resource getResourceUsage() {\n    Resource usage = Resources.createResource(0);\n    for (AppSchedulable app : appScheds) {\n      Resources.addTo(usage, app.getResourceUsage());\n    }\n    return usage;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm,\n      List<ContainerStatus> newlyLaunchedContainers,\n      List<ContainerStatus> completedContainers) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node = nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      FSSchedulerApp reservedApplication =\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSLeafQueue queue = queueMgr.getLeafQueue(reservedApplication.getQueueName());\n      queue.assignContainer(node, true);\n    }\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers = 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List<FSLeafQueue> scheds = new ArrayList<FSLeafQueue>(\n            queueMgr.getLeafQueues());\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer = false;\n        for (FSLeafQueue sched : scheds) {\n          Resource assigned = sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none()) ||\n              node.getReservedContainer() != null) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer = true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers >= maxAssign) && (maxAssign > 0)) { break; }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getRMContainer": "  private RMContainer getRMContainer(ContainerId containerId) {\n    FSSchedulerApp application = \n        applications.get(containerId.getApplicationAttemptId());\n    return (application == null) ? null : application.getRMContainer(containerId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.containerLaunchedOnNode": "  private void containerLaunchedOnNode(ContainerId containerId, FSSchedulerNode node) {\n    // Get the application for the finished container\n    ApplicationAttemptId applicationAttemptId = containerId.getApplicationAttemptId();\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n    if (application == null) {\n      LOG.info(\"Unknown application: \" + applicationAttemptId +\n          \" launched container \" + containerId +\n          \" on node: \" + node);\n      return;\n    }\n\n    application.containerLaunchedOnNode(containerId, node.getNodeID());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer": "  private synchronized void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n    if (rmContainer == null) {\n      LOG.info(\"Null container completed...\");\n      return;\n    }\n\n    Container container = rmContainer.getContainer();\n\n    // Get the application for the finished container\n    ApplicationAttemptId applicationAttemptId = container.getId().getApplicationAttemptId();\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n    if (application == null) {\n      LOG.info(\"Container \" + container + \" of\" +\n          \" unknown application \" + applicationAttemptId +\n          \" completed with event \" + event);\n      return;\n    }\n\n    // Get the node on which the container was allocated\n    FSSchedulerNode node = nodes.get(container.getNodeId());\n\n    if (rmContainer.getState() == RMContainerState.RESERVED) {\n      application.unreserve(node, rmContainer.getReservedPriority());\n      node.unreserveResource(application);\n    } else {\n      application.containerCompleted(rmContainer, containerStatus, event);\n      node.releaseContainer(container);\n    }\n\n    LOG.info(\"Application \" + applicationAttemptId +\n        \" released container \" + container.getId() +\n        \" on node: \" + node +\n        \" with event: \" + event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode(),\n          nodeUpdatedEvent.getNewlyLaunchedContainers(),\n          nodeUpdatedEvent.getCompletedContainers());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent)event;\n      String queue = appAddedEvent.getQueue();\n\n      // Potentially set queue to username if configured to do so\n      String def = YarnConfiguration.DEFAULT_QUEUE_NAME;\n      if (queue.equals(def) && userAsDefaultQueue) {\n        queue = appAddedEvent.getUser();\n      }\n\n      addApplication(appAddedEvent.getApplicationAttemptId(), queue,\n          appAddedEvent.getUser());\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationAttemptID(),\n          appRemovedEvent.getFinalAttemptState());\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addNode": "  private synchronized void addNode(RMNode node) {\n    nodes.put(node.getNodeID(), new FSSchedulerNode(node));\n    Resources.addTo(clusterCapacity, node.getTotalCapability());\n\n    LOG.info(\"Added node \" + node.getNodeAddress() +\n        \" cluster capacity: \" + clusterCapacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected synchronized void addApplication(\n      ApplicationAttemptId applicationAttemptId, String queueName, String user) {\n\n    FSLeafQueue queue = queueMgr.getLeafQueue(queueName);\n    if (queue == null) {\n      // queue is not an existing or createable leaf queue\n      queue = queueMgr.getLeafQueue(YarnConfiguration.DEFAULT_QUEUE_NAME);\n    }\n\n    FSSchedulerApp schedulerApp =\n        new FSSchedulerApp(applicationAttemptId, user,\n            queue, new ActiveUsersManager(getRootQueueMetrics()),\n            rmContext);\n    \n    // Enforce ACLs\n    UserGroupInformation userUgi;\n    try {\n      userUgi = UserGroupInformation.getCurrentUser();\n    } catch (IOException ioe) {\n      LOG.info(\"Failed to get current user information\");\n      return;\n    }\n\n    // Always a singleton list\n    List<QueueUserACLInfo> info = queue.getQueueUserAclInfo(userUgi);\n    if (!info.get(0).getUserAcls().contains(QueueACL.SUBMIT_APPLICATIONS)) {\n      LOG.info(\"User \" + userUgi.getUserName() +\n          \" cannot submit\" + \" applications to queue \" + queue.getName());\n      return;\n    }\n\n    queue.addApp(schedulerApp);\n    queue.getMetrics().submitApp(user, applicationAttemptId.getAttemptId());\n\n    applications.put(applicationAttemptId, schedulerApp);\n\n    LOG.info(\"Application Submission: \" + applicationAttemptId +\n        \", user: \"+ user +\n        \", currently active: \" + applications.size());\n\n    rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.APP_ACCEPTED));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication": "  private synchronized void removeApplication(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState) {\n    LOG.info(\"Application \" + applicationAttemptId + \" is done.\" +\n        \" finalState=\" + rmAppAttemptFinalState);\n\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n\n    if (application == null) {\n      LOG.info(\"Unknown application \" + applicationAttemptId + \" has completed!\");\n      return;\n    }\n\n    // Release all the running containers\n    for (RMContainer rmContainer : application.getLiveContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              SchedulerUtils.COMPLETED_APPLICATION),\n              RMContainerEventType.KILL);\n    }\n\n    // Release all reserved containers\n    for (RMContainer rmContainer : application.getReservedContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              \"Application Complete\"),\n          RMContainerEventType.KILL);\n    }\n\n    // Clean up pending requests, metrics etc.\n    application.stop(rmAppAttemptFinalState);\n\n    // Inform the queue\n    FSLeafQueue queue = queueMgr.getLeafQueue(application.getQueue()\n        .getQueueName());\n    queue.removeApp(application);\n\n    // Remove from our data-structure\n    applications.remove(applicationAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeNode": "  private synchronized void removeNode(RMNode rmNode) {\n    FSSchedulerNode node = nodes.get(rmNode.getNodeID());\n    Resources.subtractFrom(clusterCapacity, rmNode.getTotalCapability());\n\n    // Remove running containers\n    List<RMContainer> runningContainers = node.getRunningContainers();\n    for (RMContainer container : runningContainers) {\n      completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    // Remove reservations, if any\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      completedContainer(reservedContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              reservedContainer.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    nodes.remove(rmNode.getNodeID());\n    LOG.info(\"Removed node \" + rmNode.getNodeAddress() +\n        \" cluster capacity: \" + clusterCapacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public void run() {\n\n        SchedulerEvent event;\n\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          try {\n            event = eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return; // TODO: Kill RM.\n          }\n\n          try {\n            scheduler.handle(event);\n          } catch (Throwable t) {\n            // An error occurred, but we are shutting down anyway.\n            // If it was an InterruptedException, the very act of \n            // shutdown could have caused it and is probably harmless.\n            if (stopped) {\n              LOG.warn(\"Exception during shutdown: \", t);\n              break;\n            }\n            LOG.fatal(\"Error in handling event type \" + event.getType()\n                + \" to the scheduler\", t);\n            if (shouldExitOnError\n                && !ShutdownHookManager.get().isShutdownInProgress()) {\n              LOG.info(\"Exiting, bbye..\");\n              System.exit(-1);\n            }\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.getReservedContainer": "  public synchronized RMContainer getReservedContainer() {\n    return reservedContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.getQueueName": "  public String getQueueName() {\n    return appSchedulingInfo.getQueueName();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.getApplicationId": "  public ApplicationId getApplicationId() {\n    return appSchedulingInfo.getApplicationId();\n  }"
        },
        "bug_report": {
            "Title": "Fair scheduler throws ConcurrentModificationException when iterating over app's priorities",
            "Description": "In my test cluster, fairscheduler appear to concurrentModificationException and RM crash,  here is the message:\n\n2012-12-30 17:14:17,171 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler\njava.util.ConcurrentModificationException\n        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)\n        at java.util.TreeMap$KeyIterator.next(TreeMap.java:1154)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:181)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:780)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:842)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:340)\n        at java.lang.Thread.run(Thread.java:662)\n\n"
        }
    },
    {
        "filename": "YARN-7942.json",
        "creation_time": "2018-02-16T19:09:39.000+0000",
        "stack_trace": "```\norg.apache.hadoop.registry.client.exceptions.NoPathPermissionsException: `/registry/users/hbase/services/yarn-service/hbase-app-test': Not authorized to access path; ACLs: [null ACL]: KeeperErrorCode = NoAuth for /registry/users/hbase/services/yarn-service/hbase-app-test\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.operationFailure(CuratorService.java:412)\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.operationFailure(CuratorService.java:390)\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.zkDelete(CuratorService.java:722)\n        at org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService.delete(RegistryOperationsService.java:162)\n        at org.apache.hadoop.yarn.service.client.ServiceClient.actionDestroy(ServiceClient.java:462)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$4.run(ApiServer.java:253)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$4.run(ApiServer.java:243)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.stopService(ApiServer.java:243)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.deleteService(ApiServer.java:223)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:941)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter(RMWebAppFilter.java:178)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:119)\n        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133)\n        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130)\n        at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter$Context.java:203)\n        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.http.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:57)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.AuthenticationWithProxyUserFilter.doFilter(AuthenticationWithProxyUserFilter.java:101)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1617)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n        at org.eclipse.jetty.server.Server.handle(Server.java:534)\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n        at java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /registry/users/hbase/services/yarn-service/hbase-app-test\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:113)\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n        at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:250)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:244)\n        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:109)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:241)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:225)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:35)\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.zkDelete(CuratorService.java:718)\n        ... 75 more\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.CuratorService.operationFailure": "  protected IOException operationFailure(String path,\n      String operation,\n      Exception exception,\n      List<ACL> acls) {\n    IOException ioe;\n    String aclList = \"[\" + RegistrySecurity.aclsToString(acls) + \"]\";\n    if (exception instanceof KeeperException.NoNodeException) {\n      ioe = new PathNotFoundException(path);\n    } else if (exception instanceof KeeperException.NodeExistsException) {\n      ioe = new FileAlreadyExistsException(path);\n    } else if (exception instanceof KeeperException.NoAuthException) {\n      ioe = new NoPathPermissionsException(path,\n          \"Not authorized to access path; ACLs: \" + aclList);\n    } else if (exception instanceof KeeperException.NotEmptyException) {\n      ioe = new PathIsNotEmptyDirectoryException(path);\n    } else if (exception instanceof KeeperException.AuthFailedException) {\n      ioe = new AuthenticationFailedException(path,\n          \"Authentication Failed: \" + exception\n              + \"; \" + securityConnectionDiagnostics,\n          exception);\n    } else if (exception instanceof\n        KeeperException.NoChildrenForEphemeralsException) {\n      ioe = new NoChildrenForEphemeralsException(path,\n          \"Cannot create a path under an ephemeral node: \" + exception,\n          exception);\n    } else if (exception instanceof KeeperException.InvalidACLException) {\n      // this is a security exception of a kind\n      // include the ACLs to help the diagnostics\n      StringBuilder builder = new StringBuilder();\n      builder.append(\"Path access failure \").append(aclList);\n      builder.append(\" \");\n      builder.append(securityConnectionDiagnostics);\n      ioe = new NoPathPermissionsException(path, builder.toString());\n    } else {\n      ioe = new RegistryIOException(path,\n          \"Failure of \" + operation + \" on \" + path + \": \" +\n              exception.toString(),\n          exception);\n    }\n    if (ioe.getCause() == null) {\n      ioe.initCause(exception);\n    }\n    return ioe;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.CuratorService.toString": "  public String toString() {\n    return super.toString()\n        + \" \" + bindingDiagnosticDetails();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.CuratorService.zkDelete": "  public void zkDelete(String path,\n      boolean recursive,\n      BackgroundCallback backgroundCallback) throws IOException {\n    checkServiceLive();\n    String fullpath = createFullPath(path);\n    try {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Deleting {}\", fullpath);\n      }\n      DeleteBuilder delete = curator.delete();\n      if (recursive) {\n        delete.deletingChildrenIfNeeded();\n      }\n      if (backgroundCallback != null) {\n        delete.inBackground(backgroundCallback);\n      }\n      delete.forPath(fullpath);\n    } catch (KeeperException.NoNodeException e) {\n      // not an error\n    } catch (Exception e) {\n      throw operationFailure(fullpath, \"delete()\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.CuratorService.checkServiceLive": "  private void checkServiceLive() throws ServiceStateException {\n    if (!isInState(STATE.STARTED)) {\n      throw new ServiceStateException(\n          \"Service \" + getName() + \" is in wrong state: \"\n              + getServiceState());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.CuratorService.createFullPath": "  protected String createFullPath(String path) throws IOException {\n    return RegistryPathUtils.createFullPath(registryRoot, path);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService.delete": "  public void delete(String path, boolean recursive) throws IOException {\n    validatePath(path);\n    zkDelete(path, recursive, null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService.validatePath": "  protected void validatePath(String path) throws InvalidPathnameException {\n    // currently no checks are performed\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.actionDestroy": "  public int actionDestroy(String serviceName) throws YarnException,\n      IOException {\n    ServiceApiUtil.validateNameFormat(serviceName, getConfig());\n    verifyNoLiveAppInRM(serviceName, \"destroy\");\n\n    Path appDir = fs.buildClusterDirPath(serviceName);\n    FileSystem fileSystem = fs.getFileSystem();\n    // remove from the appId cache\n    cachedAppInfo.remove(serviceName);\n    boolean destroySucceed = true;\n    if (fileSystem.exists(appDir)) {\n      if (fileSystem.delete(appDir, true)) {\n        LOG.info(\"Successfully deleted service dir for \" + serviceName + \": \"\n            + appDir);\n      } else {\n        String message =\n            \"Failed to delete service + \" + serviceName + \" at:  \" + appDir;\n        LOG.info(message);\n        throw new YarnException(message);\n      }\n    } else {\n      LOG.info(\"Service '\" + serviceName + \"' doesn't exist at hdfs path: \"\n          + appDir);\n      destroySucceed = false;\n    }\n    try {\n      deleteZKNode(serviceName);\n    } catch (Exception e) {\n      throw new IOException(\"Could not delete zk node for \" + serviceName, e);\n    }\n    String registryPath =\n        ServiceRegistryUtils.registryPathForInstance(serviceName);\n    try {\n      if (getRegistryClient().exists(registryPath)) {\n        getRegistryClient().delete(registryPath, true);\n      } else {\n        LOG.info(\n            \"Service '\" + serviceName + \"' doesn't exist at ZK registry path: \"\n                + registryPath);\n        destroySucceed = false;\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Error deleting registry entry {}\", registryPath, e);\n    }\n    if (destroySucceed) {\n      LOG.info(\"Successfully destroyed service {}\", serviceName);\n      return EXIT_SUCCESS;\n    } else {\n      LOG.error(\"Error on destroy '\" + serviceName + \"': not found.\");\n      return -1;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.deleteZKNode": "  private boolean deleteZKNode(String clusterName) throws Exception {\n    CuratorFramework curatorFramework = getCuratorClient();\n    String user = RegistryUtils.currentUser();\n    String zkPath = ServiceRegistryUtils.mkServiceHomePath(user, clusterName);\n    if (curatorFramework.checkExists().forPath(zkPath) != null) {\n      curatorFramework.delete().deletingChildrenIfNeeded().forPath(zkPath);\n      LOG.info(\"Deleted zookeeper path: \" + zkPath);\n      return true;\n    } else {\n      LOG.info(\n          \"Service '\" + clusterName + \"' doesn't exist at ZK path: \" + zkPath);\n      return false;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.verifyNoLiveAppInRM": "  private void verifyNoLiveAppInRM(String serviceName, String action)\n      throws IOException, YarnException {\n    Set<String> types = new HashSet<>(1);\n    types.add(YarnServiceConstants.APP_TYPE);\n    Set<String> tags = null;\n    if (serviceName != null) {\n      tags = Collections.singleton(ServiceUtils.createNameTag(serviceName));\n    }\n    GetApplicationsRequest request = GetApplicationsRequest.newInstance();\n    request.setApplicationTypes(types);\n    request.setApplicationTags(tags);\n    request.setApplicationStates(liveStates);\n    String user = UserGroupInformation.getCurrentUser().getUserName();\n    if (user != null) {\n      request.setUsers(Collections.singleton(user));\n    }\n    List<ApplicationReport> reports = yarnClient.getApplications(request);\n    if (!reports.isEmpty()) {\n      String message = \"\";\n      if (action.equals(\"destroy\")) {\n        message = \"Failed to destroy service \" + serviceName\n            + \", because it is still running.\";\n      } else {\n        message = \"Failed to \" + action + \" service \" + serviceName\n            + \", because it already exists.\";\n      }\n      throw new YarnException(message);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.getRegistryClient": "  private synchronized RegistryOperations getRegistryClient()\n      throws SliderException, IOException {\n\n    if (registryClient == null) {\n      registryClient =\n          RegistryOperationsFactory.createInstance(\"ServiceClient\", getConfig());\n      registryClient.init(getConfig());\n      registryClient.start();\n    }\n    return registryClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter": "  public void doFilter(HttpServletRequest request,\n      HttpServletResponse response, FilterChain chain) throws IOException,\n      ServletException {\n    response.setCharacterEncoding(\"UTF-8\");\n    String htmlEscapedUri = HtmlQuoting.quoteHtmlChars(request.getRequestURI());\n\n    if (htmlEscapedUri == null) {\n      htmlEscapedUri = \"/\";\n    }\n\n    String uriWithQueryString =\n        WebAppUtils.appendQueryParams(request, htmlEscapedUri);\n    String htmlEscapedUriWithQueryString =\n        WebAppUtils.getHtmlEscapedURIWithQueryString(request);\n\n    RMWebApp rmWebApp = injector.getInstance(RMWebApp.class);\n    rmWebApp.checkIfStandbyRM();\n    if (rmWebApp.isStandby()\n        && shouldRedirect(rmWebApp, htmlEscapedUri)) {\n\n      String redirectPath = rmWebApp.getRedirectPath();\n\n      if (redirectPath != null && !redirectPath.isEmpty()) {\n        redirectPath += uriWithQueryString;\n        String redirectMsg = \"This is standby RM. The redirect url is: \"\n            + htmlEscapedUriWithQueryString;\n        PrintWriter out = response.getWriter();\n        out.println(redirectMsg);\n        response.setHeader(\"Location\", redirectPath);\n        response.setStatus(HttpServletResponse.SC_TEMPORARY_REDIRECT);\n        return;\n      } else {\n        boolean doRetry = true;\n        String retryIntervalStr =\n            request.getParameter(YarnWebParams.NEXT_REFRESH_INTERVAL);\n        int retryInterval = 0;\n        if (retryIntervalStr != null) {\n          try {\n            retryInterval = Integer.parseInt(retryIntervalStr.trim());\n          } catch (NumberFormatException ex) {\n            doRetry = false;\n          }\n        }\n        int next = calculateExponentialTime(retryInterval);\n\n        String redirectUrl =\n            appendOrReplaceParamter(path + uriWithQueryString,\n              YarnWebParams.NEXT_REFRESH_INTERVAL + \"=\" + (retryInterval + 1));\n        if (redirectUrl == null || next > MAX_SLEEP_TIME) {\n          doRetry = false;\n        }\n        String redirectMsg =\n            doRetry ? \"Can not find any active RM. Will retry in next \" + next\n                + \" seconds.\" : \"There is no active RM right now.\";\n        redirectMsg += \"\\nHA Zookeeper Connection State: \"\n            + rmWebApp.getHAZookeeperConnectionState();\n        PrintWriter out = response.getWriter();\n        out.println(redirectMsg);\n        if (doRetry) {\n          response.setHeader(\"Refresh\", next + \";url=\" + redirectUrl);\n          response.setStatus(HttpServletResponse.SC_TEMPORARY_REDIRECT);\n        }\n      }\n      return;\n    } else if (ahsEnabled) {\n      String ahsRedirectUrl = ahsRedirectPath(uriWithQueryString, rmWebApp);\n      if(ahsRedirectUrl != null) {\n        response.setHeader(\"Location\", ahsRedirectUrl);\n        response.setStatus(HttpServletResponse.SC_TEMPORARY_REDIRECT);\n        return;\n      }\n    }\n\n    super.doFilter(request, response, chain);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.appendOrReplaceParamter": "  private String appendOrReplaceParamter(String uri, String newQuery) {\n    if (uri.contains(YarnWebParams.NEXT_REFRESH_INTERVAL + \"=\")) {\n      return uri.replaceAll(YarnWebParams.NEXT_REFRESH_INTERVAL + \"=[^&]+\",\n        newQuery);\n    }\n    try {\n      URI oldUri = new URI(uri);\n      String appendQuery = oldUri.getQuery();\n      if (appendQuery == null) {\n        appendQuery = newQuery;\n      } else {\n        appendQuery += \"&\" + newQuery;\n      }\n\n      URI newUri =\n          new URI(oldUri.getScheme(), oldUri.getAuthority(), oldUri.getPath(),\n            appendQuery, oldUri.getFragment());\n\n      return newUri.toString();\n    } catch (URISyntaxException e) {\n      return null;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.calculateExponentialTime": "  private static int calculateExponentialTime(int retries) {\n    long baseTime = BASIC_SLEEP_TIME * (1L << retries);\n    return (int) (baseTime * (randnum.nextDouble() + 0.5));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.shouldRedirect": "  private boolean shouldRedirect(RMWebApp rmWebApp, String uri) {\n    return !uri.equals(\"/\" + rmWebApp.wsName() + \"/v1/cluster/info\")\n        && !uri.equals(\"/\" + rmWebApp.name() + \"/cluster\")\n        && !uri.startsWith(ProxyUriUtils.PROXY_BASE)\n        && !NON_REDIRECTED_URIS.contains(uri);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.ahsRedirectPath": "  private String ahsRedirectPath(String uri, RMWebApp rmWebApp) {\n    // TODO: Commonize URL parsing code. Will be done in YARN-4642.\n    String redirectPath = null;\n    if(uri.contains(\"/cluster/\")) {\n      String[] parts = uri.split(\"/\");\n      if(parts.length > 3) {\n        RMContext context = rmWebApp.getRMContext();\n        String type = parts[2];\n        ApplicationId appId = null;\n        ApplicationAttemptId appAttemptId = null;\n        ContainerId containerId = null;\n        switch(type){\n        case \"app\":\n          try {\n            appId = Apps.toAppID(parts[3]);\n          } catch (YarnRuntimeException | NumberFormatException e) {\n            LOG.debug(\"Error parsing {} as an ApplicationId\",\n                parts[3], e);\n            return redirectPath;\n          }\n          if(!context.getRMApps().containsKey(appId)) {\n            redirectPath = pjoin(ahsPageURLPrefix, \"app\", appId);\n          }\n          break;\n        case \"appattempt\":\n          try{\n            appAttemptId = ApplicationAttemptId.fromString(parts[3]);\n          } catch (IllegalArgumentException e) {\n            LOG.debug(\"Error parsing {} as an ApplicationAttemptId\",\n                parts[3], e);\n            return redirectPath;\n          }\n          if(!context.getRMApps().containsKey(\n              appAttemptId.getApplicationId())) {\n            redirectPath = pjoin(ahsPageURLPrefix,\n                \"appattempt\", appAttemptId);\n          }\n          break;\n        case \"container\":\n          try {\n            containerId = ContainerId.fromString(parts[3]);\n          } catch (IllegalArgumentException e) {\n            LOG.debug(\"Error parsing {} as an ContainerId\",\n                parts[3], e);\n            return redirectPath;\n          }\n          if(!context.getRMApps().containsKey(\n              containerId.getApplicationAttemptId().getApplicationId())) {\n            redirectPath = pjoin(ahsPageURLPrefix,\n                \"container\", containerId);\n          }\n          break;\n        default:\n          break;\n        }\n      }\n    }\n    return redirectPath;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.http.XFrameOptionsFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n      FilterChain chain) throws IOException, ServletException {\n    ((HttpServletResponse) res).setHeader(X_FRAME_OPTIONS, option);\n    chain.doFilter(req,\n        new XFrameOptionsResponseWrapper((HttpServletResponse) res));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.AuthenticationWithProxyUserFilter.doFilter": "  protected void doFilter(FilterChain filterChain, HttpServletRequest request,\n      HttpServletResponse response) throws IOException, ServletException {\n\n    final String proxyUser = getDoAs(request);\n    if (proxyUser != null) {\n\n      // Change the remote user after proxy user is authorized.\n      final HttpServletRequest finalReq = request;\n      request = new HttpServletRequestWrapper(finalReq) {\n\n        private String getRemoteOrProxyUser() throws AuthorizationException {\n          UserGroupInformation realUser =\n              UserGroupInformation.createRemoteUser(finalReq.getRemoteUser());\n          UserGroupInformation proxyUserInfo =\n              UserGroupInformation.createProxyUser(proxyUser, realUser);\n          ProxyUsers.authorize(proxyUserInfo, finalReq.getRemoteAddr());\n          return proxyUserInfo.getUserName();\n        }\n\n        @Override\n        public String getRemoteUser() {\n          try {\n            return getRemoteOrProxyUser();\n          } catch (AuthorizationException ex) {\n            LOG.error(\"Unable to verify proxy user: \" + ex.getMessage(), ex);\n          }\n          return null;\n        }\n      };\n\n    }\n    filterChain.doFilter(request, response);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.AuthenticationWithProxyUserFilter.getRemoteOrProxyUser": "        private String getRemoteOrProxyUser() throws AuthorizationException {\n          UserGroupInformation realUser =\n              UserGroupInformation.createRemoteUser(finalReq.getRemoteUser());\n          UserGroupInformation proxyUserInfo =\n              UserGroupInformation.createProxyUser(proxyUser, realUser);\n          ProxyUsers.authorize(proxyUserInfo, finalReq.getRemoteAddr());\n          return proxyUserInfo.getUserName();\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.AuthenticationWithProxyUserFilter.getDoAs": "  public static String getDoAs(HttpServletRequest request) {\n    String queryString = request.getQueryString();\n    if (queryString == null) {\n      return null;\n    }\n    List<NameValuePair> list = URLEncodedUtils.parse(queryString, UTF8_CHARSET);\n    if (list != null) {\n      for (NameValuePair nv : list) {\n        if (DO_AS.equalsIgnoreCase(nv.getName())) {\n          return nv.getValue();\n        }\n      }\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.AuthenticationWithProxyUserFilter.getRemoteUser": "        public String getRemoteUser() {\n          try {\n            return getRemoteOrProxyUser();\n          } catch (AuthorizationException ex) {\n            LOG.error(\"Unable to verify proxy user: \" + ex.getMessage(), ex);\n          }\n          return null;\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.doFilter": "    public void doFilter(ServletRequest request,\n                         ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequestWrapper quoted =\n        new RequestQuoter((HttpServletRequest) request);\n      HttpServletResponse httpResponse = (HttpServletResponse) response;\n\n      String mime = inferMimeType(request);\n      if (mime == null) {\n        httpResponse.setContentType(\"text/plain; charset=utf-8\");\n      } else if (mime.startsWith(\"text/html\")) {\n        // HTML with unspecified encoding, we want to\n        // force HTML with utf-8 encoding\n        // This is to avoid the following security issue:\n        // http://openmya.hacker.jp/hasegawa/security/utf7cs.html\n        httpResponse.setContentType(\"text/html; charset=utf-8\");\n      } else if (mime.startsWith(\"application/xml\")) {\n        httpResponse.setContentType(\"text/xml; charset=utf-8\");\n      }\n\n      if(Boolean.valueOf(this.config.getInitParameter(X_FRAME_ENABLED))) {\n        httpResponse.addHeader(\"X-FRAME-OPTIONS\",\n            this.config.getInitParameter(X_FRAME_VALUE));\n      }\n      chain.doFilter(quoted, httpResponse);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.inferMimeType": "    private String inferMimeType(ServletRequest request) {\n      String path = ((HttpServletRequest)request).getRequestURI();\n      ServletContextHandler.Context sContext =\n          (ServletContextHandler.Context)config.getServletContext();\n      String mime = sContext.getMimeType(path);\n      return (mime == null) ? null : mime;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.NoCacheFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n                       FilterChain chain)\n    throws IOException, ServletException {\n    HttpServletResponse httpRes = (HttpServletResponse) res;\n    httpRes.setHeader(\"Cache-Control\", \"no-cache\");\n    long now = System.currentTimeMillis();\n    httpRes.addDateHeader(\"Expires\", now);\n    httpRes.addDateHeader(\"Date\", now);\n    httpRes.addHeader(\"Pragma\", \"no-cache\");\n    chain.doFilter(req, res);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.RegistrySecurity.aclsToString": "  public static String aclsToString(List<ACL> acls) {\n    StringBuilder builder = new StringBuilder();\n    if (acls == null) {\n      builder.append(\"null ACL\");\n    } else {\n      builder.append('\\n');\n      for (ACL acl : acls) {\n        builder.append(aclToString(acl))\n               .append(\" \");\n      }\n    }\n    return builder.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.RegistrySecurity.toString": "    public String toString() {\n      return aclsToString(acls);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.client.impl.zk.RegistrySecurity.aclToString": "  public static String aclToString(ACL acl) {\n    return String.format(Locale.ENGLISH,\n        \"0x%02x: %s\",\n        acl.getPerms(),\n        idToString(acl.getId())\n    );\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.checkIfStandbyRM": "  public void checkIfStandbyRM() {\n    standby = (rm.getRMContext().getHAServiceState() == HAServiceState.STANDBY);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.getRMContext": "  public RMContext getRMContext() {\n    return rm.getRMContext();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.getHAZookeeperConnectionState": "  public String getHAZookeeperConnectionState() {\n    return getRMContext().getHAZookeeperConnectionState();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.getRedirectPath": "  public String getRedirectPath() {\n    if (standby) {\n      return buildRedirectPath();\n    } else\n      return super.getRedirectPath();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.buildRedirectPath": "  private String buildRedirectPath() {\n    // make a copy of the original configuration so not to mutate it. Also use\n    // an YarnConfiguration to force loading of yarn-site.xml.\n    YarnConfiguration yarnConf = new YarnConfiguration(rm.getConfig());\n    String activeRMHAId = RMHAUtils.findActiveRMHAId(yarnConf);\n    String path = \"\";\n    if (activeRMHAId != null) {\n      yarnConf.set(YarnConfiguration.RM_HA_ID, activeRMHAId);\n\n      InetSocketAddress sock = YarnConfiguration.useHttps(yarnConf)\n          ? yarnConf.getSocketAddr(YarnConfiguration.RM_WEBAPP_HTTPS_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_HTTPS_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_HTTPS_PORT)\n          : yarnConf.getSocketAddr(YarnConfiguration.RM_WEBAPP_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_ADDRESS,\n              YarnConfiguration.DEFAULT_RM_WEBAPP_PORT);\n\n      path = sock.getHostName() + \":\" + Integer.toString(sock.getPort());\n      path = YarnConfiguration.useHttps(yarnConf)\n          ? \"https://\" + path\n          : \"http://\" + path;\n    }\n    return path;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebApp.isStandby": "  public boolean isStandby() {\n    return standby;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.createProxyUser": "  public static UserGroupInformation createProxyUser(String user,\n      UserGroupInformation realUser) {\n    if (user == null || user.isEmpty()) {\n      throw new IllegalArgumentException(\"Null user\");\n    }\n    if (realUser == null) {\n      throw new IllegalArgumentException(\"Null real user\");\n    }\n    Subject subject = new Subject();\n    Set<Principal> principals = subject.getPrincipals();\n    principals.add(new User(user));\n    principals.add(new RealUser(realUser));\n    UserGroupInformation result =new UserGroupInformation(subject, false);\n    result.setAuthenticationMethod(AuthenticationMethod.PROXY);\n    return result;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.setAuthenticationMethod": "  public void setAuthenticationMethod(AuthMethod authMethod) {\n    user.setAuthenticationMethod(AuthenticationMethod.valueOf(authMethod));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.getUserName": "  public String getUserName() {\n    return user.getName();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.getName": "    public String getName() {\n      return realUser.getUserName();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.createRemoteUser": "  public static UserGroupInformation createRemoteUser(String user, AuthMethod authMethod) {\n    if (user == null || user.isEmpty()) {\n      throw new IllegalArgumentException(\"Null user\");\n    }\n    Subject subject = new Subject();\n    subject.getPrincipals().add(new User(user));\n    UserGroupInformation result = new UserGroupInformation(subject, false);\n    result.setAuthenticationMethod(authMethod);\n    return result;\n  }"
        },
        "bug_report": {
            "Title": "Yarn ServiceClient does not not delete znode from secure ZooKeeper",
            "Description": "Even with sasl:rm:cdrwa set on the ZK node (from the registry system accounts property), the RM fails to remove the node with the below error. Also, the destroy call succeeds.\r\n\r\n{code}\r\n2018-02-16 15:49:29,691 WARN  client.ServiceClient (ServiceClient.java:actionDestroy(470)) - Error deleting registry entry /users/hbase/services/yarn-service/hbase-app-test\r\norg.apache.hadoop.registry.client.exceptions.NoPathPermissionsException: `/registry/users/hbase/services/yarn-service/hbase-app-test': Not authorized to access path; ACLs: [null ACL]: KeeperErrorCode = NoAuth for /registry/users/hbase/services/yarn-service/hbase-app-test\r\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.operationFailure(CuratorService.java:412)\r\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.operationFailure(CuratorService.java:390)\r\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.zkDelete(CuratorService.java:722)\r\n        at org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService.delete(RegistryOperationsService.java:162)\r\n        at org.apache.hadoop.yarn.service.client.ServiceClient.actionDestroy(ServiceClient.java:462)\r\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$4.run(ApiServer.java:253)\r\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$4.run(ApiServer.java:243)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at javax.security.auth.Subject.doAs(Subject.java:422)\r\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)\r\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.stopService(ApiServer.java:243)\r\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.deleteService(ApiServer.java:223)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\r\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\r\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\r\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\r\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\r\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\r\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\r\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\r\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\r\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\r\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89)\r\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:941)\r\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter(RMWebAppFilter.java:178)\r\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)\r\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\r\n        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:119)\r\n        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133)\r\n        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130)\r\n        at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203)\r\n        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.security.http.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:57)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.security.AuthenticationWithProxyUserFilter.doFilter(AuthenticationWithProxyUserFilter.java:101)\r\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1617)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\r\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\r\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\r\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\r\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\r\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\r\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n        at org.eclipse.jetty.server.Server.handle(Server.java:534)\r\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\r\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\r\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\r\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\r\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\r\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\r\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\r\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\r\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\r\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /registry/users/hbase/services/yarn-service/hbase-app-test\r\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:113)\r\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\r\n        at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)\r\n        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:250)\r\n        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:244)\r\n        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:109)\r\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:241)\r\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:225)\r\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:35)\r\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.zkDelete(CuratorService.java:718)\r\n        ... 75 more\r\n2018-02-16 15:49:29,694 INFO  client.ServiceClient (ServiceClient.java:actionDestroy(473)) - Successfully destroyed service hbase-app-test\r\n2018-02-16 15:49:29,694 INFO  webapp.ApiServer (ApiServer.java:run(254)) - Successfully deleted service hbase-app-test\r\n{code}"
        }
    },
    {
        "filename": "YARN-7692.json",
        "creation_time": "2017-12-29T06:00:34.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.checkAndGetApplicationPriority(CapacityScheduler.java:2348)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:396)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:358)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:567)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1390)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:771)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1143)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1183)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1179)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1179)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:320)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:894)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:473)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:611)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:510)\nCaused by: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.checkAndGetApplicationPriority": "  public Priority checkAndGetApplicationPriority(\n      Priority priorityRequestedByApp, UserGroupInformation user,\n      String queueName, ApplicationId applicationId) throws YarnException {\n    try {\n      readLock.lock();\n      Priority appPriority = priorityRequestedByApp;\n\n      // Verify the scenario where priority is null from submissionContext.\n      if (null == appPriority) {\n        // Verify whether submitted user has any default priority set. If so,\n        // user's default priority will get precedence over queue default.\n        // for updateApplicationPriority call flow, this check is done in\n        // CientRMService itself.\n        appPriority = this.appPriorityACLManager.getDefaultPriority(queueName,\n            user);\n\n        // Get the default priority for the Queue. If Queue is non-existent,\n        // then\n        // use default priority. Do it only if user doesn't have any default.\n        if (null == appPriority) {\n          appPriority = this.queueManager.getDefaultPriorityForQueue(queueName);\n        }\n\n        LOG.info(\n            \"Application '\" + applicationId + \"' is submitted without priority \"\n                + \"hence considering default queue/cluster priority: \"\n                + appPriority.getPriority());\n      }\n\n      // Verify whether submitted priority is lesser than max priority\n      // in the cluster. If it is out of found, defining a max cap.\n      if (appPriority.getPriority() > getMaxClusterLevelAppPriority()\n          .getPriority()) {\n        appPriority = Priority\n            .newInstance(getMaxClusterLevelAppPriority().getPriority());\n      }\n\n      // Lets check for ACLs here.\n      if (!appPriorityACLManager.checkAccess(user, queueName, appPriority)) {\n        throw new YarnException(new AccessControlException(\n            \"User \" + user + \" does not have permission to submit/update \"\n                + applicationId + \" for \" + appPriority));\n      }\n\n      LOG.info(\"Priority '\" + appPriority.getPriority()\n          + \"' is acceptable in queue : \" + queueName + \" for application: \"\n          + applicationId);\n\n      return appPriority;\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.checkAccess": "  public boolean checkAccess(UserGroupInformation callerUGI,\n      QueueACL acl, String queueName) {\n    CSQueue queue = getQueue(queueName);\n    if (queue == null) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"ACL not found for queue access-type \" + acl + \" for queue \"\n            + queueName);\n      }\n      return false;\n    }\n    return queue.hasAccess(acl, callerUGI);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp": "  private RMAppImpl createAndPopulateNewRMApp(\n      ApplicationSubmissionContext submissionContext, long submitTime,\n      String user, boolean isRecovery, long startTime) throws YarnException {\n\n    ApplicationPlacementContext placementContext = null;\n    try {\n      placementContext = placeApplication(rmContext, submissionContext, user);\n    } catch (YarnException e) {\n      String msg =\n          \"Failed to place application \" + submissionContext.getApplicationId()\n              + \" to queue and specified \" + \"queue is invalid : \"\n              + submissionContext.getQueue();\n      LOG.error(msg, e);\n      throw e;\n    }\n\n    // We only replace the queue when it's a new application\n    if (!isRecovery) {\n      replaceQueueFromPlacementContext(placementContext, submissionContext);\n\n      // fail the submission if configured application timeout value is invalid\n      RMServerUtils.validateApplicationTimeouts(\n          submissionContext.getApplicationTimeouts());\n    }\n\n    ApplicationId applicationId = submissionContext.getApplicationId();\n    List<ResourceRequest> amReqs = validateAndCreateResourceRequest(\n        submissionContext, isRecovery);\n\n    // Verify and get the update application priority and set back to\n    // submissionContext\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n    Priority appPriority = scheduler.checkAndGetApplicationPriority(\n        submissionContext.getPriority(), userUgi, submissionContext.getQueue(),\n        applicationId);\n    submissionContext.setPriority(appPriority);\n\n    // Since FairScheduler queue mapping is done inside scheduler,\n    // if FairScheduler is used and the queue doesn't exist, we should not\n    // fail here because queue will be created inside FS. Ideally, FS queue\n    // mapping should be done outside scheduler too like CS.\n    // For now, exclude FS for the acl check.\n    if (!isRecovery && YarnConfiguration.isAclEnabled(conf)\n        && scheduler instanceof CapacityScheduler) {\n      String queueName = submissionContext.getQueue();\n      String appName = submissionContext.getApplicationName();\n      CSQueue csqueue = ((CapacityScheduler) scheduler).getQueue(queueName);\n\n      if (csqueue == null && placementContext != null) {\n        //could be an auto created queue through queue mapping. Validate\n        // parent queue exists and has valid acls\n        String parentQueueName = placementContext.getParentQueue();\n        csqueue = ((CapacityScheduler) scheduler).getQueue(parentQueueName);\n      }\n\n      if (csqueue != null\n          && !authorizer.checkPermission(\n              new AccessRequest(csqueue.getPrivilegedEntity(), userUgi,\n                  SchedulerUtils.toAccessType(QueueACL.SUBMIT_APPLICATIONS),\n                  applicationId.toString(), appName, Server.getRemoteAddress(),\n                  null))\n          && !authorizer.checkPermission(\n              new AccessRequest(csqueue.getPrivilegedEntity(), userUgi,\n                  SchedulerUtils.toAccessType(QueueACL.ADMINISTER_QUEUE),\n                  applicationId.toString(), appName, Server.getRemoteAddress(),\n                  null))) {\n        throw RPCUtil.getRemoteException(new AccessControlException(\n            \"User \" + user + \" does not have permission to submit \"\n                + applicationId + \" to queue \" + submissionContext.getQueue()));\n      }\n    }\n\n    // Create RMApp\n    RMAppImpl application =\n        new RMAppImpl(applicationId, rmContext, this.conf,\n            submissionContext.getApplicationName(), user,\n            submissionContext.getQueue(),\n            submissionContext, this.scheduler, this.masterService,\n            submitTime, submissionContext.getApplicationType(),\n            submissionContext.getApplicationTags(), amReqs, placementContext,\n            startTime);\n    // Concurrent app submissions with same applicationId will fail here\n    // Concurrent app submissions with different applicationIds will not\n    // influence each other\n    if (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw new YarnException(message);\n    }\n\n    if (YarnConfiguration.timelineServiceV2Enabled(conf)) {\n      // Start timeline collector for the submitted app\n      application.startTimelineCollector();\n    }\n    // Inform the ACLs Manager\n    this.applicationACLsManager.addApplication(applicationId,\n        submissionContext.getAMContainerSpec().getApplicationACLs());\n    String appViewACLs = submissionContext.getAMContainerSpec()\n        .getApplicationACLs().get(ApplicationAccessType.VIEW_APP);\n    rmContext.getSystemMetricsPublisher().appACLsUpdated(\n        application, appViewACLs, System.currentTimeMillis());\n    return application;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest": "  private List<ResourceRequest> validateAndCreateResourceRequest(\n      ApplicationSubmissionContext submissionContext, boolean isRecovery)\n      throws InvalidResourceRequestException {\n    // Validation of the ApplicationSubmissionContext needs to be completed\n    // here. Only those fields that are dependent on RM's configuration are\n    // checked here as they have to be validated whether they are part of new\n    // submission or just being recovered.\n\n    // Check whether AM resource requirements are within required limits\n    if (!submissionContext.getUnmanagedAM()) {\n      List<ResourceRequest> amReqs =\n          submissionContext.getAMContainerResourceRequests();\n      if (amReqs == null || amReqs.isEmpty()) {\n        if (submissionContext.getResource() != null) {\n          amReqs = Collections.singletonList(BuilderUtils\n              .newResourceRequest(RMAppAttemptImpl.AM_CONTAINER_PRIORITY,\n                  ResourceRequest.ANY, submissionContext.getResource(), 1));\n        } else {\n          throw new InvalidResourceRequestException(\"Invalid resource request, \"\n              + \"no resources requested\");\n        }\n      }\n\n      try {\n        // Find the ANY request and ensure there's only one\n        ResourceRequest anyReq = null;\n        for (ResourceRequest amReq : amReqs) {\n          if (amReq.getResourceName().equals(ResourceRequest.ANY)) {\n            if (anyReq == null) {\n              anyReq = amReq;\n            } else {\n              throw new InvalidResourceRequestException(\"Invalid resource \"\n                  + \"request, only one resource request with \"\n                  + ResourceRequest.ANY + \" is allowed\");\n            }\n          }\n        }\n        if (anyReq == null) {\n          throw new InvalidResourceRequestException(\"Invalid resource request, \"\n              + \"no resource request specified with \" + ResourceRequest.ANY);\n        }\n\n        // Make sure that all of the requests agree with the ANY request\n        // and have correct values\n        for (ResourceRequest amReq : amReqs) {\n          amReq.setCapability(anyReq.getCapability());\n          amReq.setExecutionTypeRequest(\n              ExecutionTypeRequest.newInstance(ExecutionType.GUARANTEED));\n          amReq.setNumContainers(1);\n          amReq.setPriority(RMAppAttemptImpl.AM_CONTAINER_PRIORITY);\n        }\n\n        // set label expression for AM ANY request if not set\n        if (null == anyReq.getNodeLabelExpression()) {\n          anyReq.setNodeLabelExpression(submissionContext\n              .getNodeLabelExpression());\n        }\n\n        // Put ANY request at the front\n        if (!amReqs.get(0).equals(anyReq)) {\n          amReqs.remove(anyReq);\n          amReqs.add(0, anyReq);\n        }\n\n        // Normalize all requests\n        for (ResourceRequest amReq : amReqs) {\n          SchedulerUtils.normalizeAndValidateRequest(amReq,\n              scheduler.getMaximumResourceCapability(),\n              submissionContext.getQueue(), scheduler, isRecovery, rmContext);\n\n          amReq.setCapability(\n              scheduler.getNormalizedResource(amReq.getCapability()));\n        }\n        return amReqs;\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"RM app submission failed in validating AM resource request\"\n            + \" for application \" + submissionContext.getApplicationId(), e);\n        throw e;\n      }\n    }\n\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.placeApplication": "  ApplicationPlacementContext placeApplication(RMContext rmContext,\n      ApplicationSubmissionContext context, String user) throws YarnException {\n    ApplicationPlacementContext placementContext = null;\n    PlacementManager placementManager = rmContext.getQueuePlacementManager();\n\n    if (placementManager != null) {\n      placementContext = placementManager.placeApplication(context, user);\n    } else{\n      if ( context.getQueue() == null || context.getQueue().isEmpty()) {\n        final String msg = \"Queue Placement Manager is not set. Cannot place \"\n            + \"application : \" + context.getApplicationId() + \" to queue and \"\n            + \"specified queue is invalid \" + context.getQueue();\n        LOG.error(msg);\n        throw new YarnException(msg);\n      }\n    }\n\n    return placementContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.replaceQueueFromPlacementContext": "  void replaceQueueFromPlacementContext(\n      ApplicationPlacementContext placementContext,\n      ApplicationSubmissionContext context) {\n    // Set it to ApplicationSubmissionContext\n    //apply queue mapping only to new application submissions\n    if (placementContext != null && !StringUtils.equalsIgnoreCase(\n        context.getQueue(), placementContext.getQueue())) {\n      LOG.info(\"Placed application=\" + context.getApplicationId() +\n          \" to queue=\" + placementContext.getQueue() + \", original queue=\"\n          + context\n          .getQueue());\n      context.setQueue(placementContext.getQueue());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.toString": "      @Override public String toString() {\n        return buffer.toString();\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication": "  protected void recoverApplication(ApplicationStateData appState,\n      RMState rmState) throws Exception {\n    ApplicationSubmissionContext appContext =\n        appState.getApplicationSubmissionContext();\n    ApplicationId appId = appContext.getApplicationId();\n\n    // create and recover app.\n    RMAppImpl application =\n        createAndPopulateNewRMApp(appContext, appState.getSubmitTime(),\n            appState.getUser(), true, appState.getStartTime());\n\n    application.handle(new RMAppRecoverEvent(appId, rmState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch (event.getType()) {\n    case APP_COMPLETED :\n      finishApplication(applicationId);\n      logApplicationSummary(applicationId);\n      checkAppNumCompletedLimit();\n      break;\n    case APP_MOVE :\n      // moveAllApps from scheduler will fire this event for each of\n      // those applications which needed to be moved to a new queue.\n      // Use the standard move application api to do the same.\n      try {\n        moveApplicationAcrossQueue(applicationId,\n            event.getTargetQueueForMove());\n      } catch (YarnException e) {\n        LOG.warn(\"Move Application has failed: \" + e.getMessage());\n      }\n      break;\n    default :\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover": "  public void recover(RMState state) throws Exception {\n    RMStateStore store = rmContext.getStateStore();\n    assert store != null;\n    // recover applications\n    Map<ApplicationId, ApplicationStateData> appStates =\n        state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n\n    int count = 0;\n\n    try {\n      for (ApplicationStateData appState : appStates.values()) {\n        recoverApplication(appState, state);\n        count += 1;\n      }\n    } finally {\n      LOG.info(\"Successfully recovered \" + count  + \" out of \"\n          + appStates.size() + \" applications\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover reservations\n    if (reservationSystem != null) {\n      reservationSystem.recover(state);\n    }\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setSchedulerRecoveryStartAndWaitTime": "  private void setSchedulerRecoveryStartAndWaitTime(RMState state,\n      Configuration conf) {\n    if (!state.getApplicationState().isEmpty()) {\n      long waitTime =\n          conf.getLong(YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS,\n            YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS);\n      rmContext.setSchedulerRecoveryStartAndWaitTime(waitTime);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(false);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n    Map<String, String> serviceConfig = null;\n    Configuration conf = getConfig();\n\n    RMWebAppUtil.setupSecurityAndFilters(conf,\n        getClientRMService().rmDTSecretManager);\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .withCSRFProtection(YarnConfiguration.RM_CSRF_PREFIX)\n            .withXFSProtection(YarnConfiguration.RM_XFS_PREFIX)\n            .at(webAppAddress);\n    String proxyHostAndPort = rmContext.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n    }\n\n    WebAppContext uiWebAppContext = null;\n    if (getConfig().getBoolean(YarnConfiguration.YARN_WEBAPP_UI2_ENABLE,\n        YarnConfiguration.DEFAULT_YARN_WEBAPP_UI2_ENABLE)) {\n      String onDiskPath = getConfig()\n          .get(YarnConfiguration.YARN_WEBAPP_UI2_WARFILE_PATH);\n\n      uiWebAppContext = new WebAppContext();\n      uiWebAppContext.setContextPath(UI2_WEBAPP_NAME);\n\n      if (null == onDiskPath) {\n        String war = \"hadoop-yarn-ui-\" + VersionInfo.getVersion() + \".war\";\n        URLClassLoader cl = (URLClassLoader) ClassLoader.getSystemClassLoader();\n        URL url = cl.findResource(war);\n\n        if (null == url) {\n          onDiskPath = getWebAppsPath(\"ui2\");\n        } else {\n          onDiskPath = url.getFile();\n        }\n      }\n      if (onDiskPath == null || onDiskPath.isEmpty()) {\n          LOG.error(\"No war file or webapps found for ui2 !\");\n      } else {\n        if (onDiskPath.endsWith(\".war\")) {\n          uiWebAppContext.setWar(onDiskPath);\n          LOG.info(\"Using war file at: \" + onDiskPath);\n        } else {\n          uiWebAppContext.setResourceBase(onDiskPath);\n          LOG.info(\"Using webapps at: \" + onDiskPath);\n        }\n      }\n    }\n\n    if (getConfig().getBoolean(YarnConfiguration.YARN_API_SERVICES_ENABLE,\n        false)) {\n      serviceConfig = new HashMap<String, String>();\n      String apiPackages = \"org.apache.hadoop.yarn.service.webapp;\" +\n          \"org.apache.hadoop.yarn.webapp\";\n      serviceConfig.put(\"PackageName\", apiPackages);\n      serviceConfig.put(\"PathSpec\", \"/app/*\");\n    }\n    webApp = builder.start(new RMWebApp(this), uiWebAppContext, serviceConfig);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    HAServiceState state = rmContext.getHAServiceState();\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    if (state == HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, (Throwable) null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetRMContext();\n      createAndInitActiveServices(true);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive": "  public synchronized void transitionToActive(\n      HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {\n    if (isRMActive()) {\n      return;\n    }\n    // call refreshAdminAcls before HA state transition\n    // for the case that adminAcls have been updated in previous active RM\n    try {\n      refreshAdminAcls(false);\n    } catch (YarnException ex) {\n      throw new ServiceFailedException(\"Can not execute refreshAdminAcls\", ex);\n    }\n\n    UserGroupInformation user = checkAccess(\"transitionToActive\");\n    checkHaStateChange(reqInfo);\n\n    try {\n      // call all refresh*s for active RM to get the updated configurations.\n      refreshAll();\n    } catch (Exception e) {\n      rm.getRMContext()\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMFatalEvent(RMFatalEventType.TRANSITION_TO_ACTIVE_FAILED,\n                  e, \"failure to refresh configuration settings\"));\n      throw new ServiceFailedException(\n          \"Error on refreshAll during transition to Active\", e);\n    }\n\n    try {\n      rm.transitionToActive();\n    } catch (Exception e) {\n      RMAuditLogger.logFailure(user.getShortUserName(), \"transitionToActive\",\n          \"\", \"RM\",\n          \"Exception transitioning to active\");\n      throw new ServiceFailedException(\n          \"Error when transitioning to Active mode\", e);\n    }\n\n    RMAuditLogger.logSuccess(user.getShortUserName(), \"transitionToActive\",\n        \"RM\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.isRMActive": "  private synchronized boolean isRMActive() {\n    return HAServiceState.ACTIVE == rm.getRMContext().getHAServiceState();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkHaStateChange": "  private void checkHaStateChange(StateChangeRequestInfo req)\n      throws AccessControlException {\n    switch (req.getSource()) {\n      case REQUEST_BY_USER:\n        if (autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Manual failover for this ResourceManager is disallowed, \" +\n                  \"because automatic failover is enabled.\");\n        }\n        break;\n      case REQUEST_BY_USER_FORCED:\n        if (autoFailoverEnabled) {\n          LOG.warn(\"Allowing manual failover from \" +\n              org.apache.hadoop.ipc.Server.getRemoteAddress() +\n              \" even though automatic failover is enabled, because the user \" +\n              \"specified the force flag\");\n        }\n        break;\n      case REQUEST_BY_ZKFC:\n        if (!autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Request from ZK failover controller at \" +\n                  org.apache.hadoop.ipc.Server.getRemoteAddress() + \" denied \" +\n                  \"since automatic failover is not enabled\");\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess": "  private UserGroupInformation checkAccess(String method) throws IOException {\n    return RMServerUtils.verifyAdminAccess(authorizer, method, LOG);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll": "  void refreshAll() throws ServiceFailedException {\n    try {\n      checkAcls(\"refreshAll\");\n      if (isSchedulerMutable()) {\n        try {\n          ((MutableConfScheduler) rm.getRMContext().getScheduler())\n              .getMutableConfProvider().reloadConfigurationFromStore();\n        } catch (Exception e) {\n          throw new IOException(\"Failed to refresh configuration:\", e);\n        }\n      }\n      refreshQueues();\n      refreshNodes();\n      refreshSuperUserGroupsConfiguration();\n      refreshUserToGroupsMappings();\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls();\n      }\n      refreshClusterMaxPriority();\n    } catch (Exception ex) {\n      throw new ServiceFailedException(\"RefreshAll operation failed\", ex);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls": "  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    final String operation = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(operation);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), operation, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    authorizer.setAdmins(getAdminAclList(conf), daemonUser);\n    RMAuditLogger.logSuccess(user.getShortUserName(), operation,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive": "  public void becomeActive() throws ServiceFailedException {\n    cancelDisconnectTimer();\n\n    try {\n      rm.getRMContext().getRMAdminService().transitionToActive(req);\n    } catch (Exception e) {\n      throw new ServiceFailedException(\"RM could not transition to Active\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.cancelDisconnectTimer": "  private void cancelDisconnectTimer() {\n    synchronized (zkDisconnectLock) {\n      if (zkDisconnectTimer != null) {\n        zkDisconnectTimer.cancel();\n        zkDisconnectTimer = null;\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeActive": "  private boolean becomeActive() {\n    assert wantToBeInElection;\n    if (state == State.ACTIVE) {\n      // already active\n      return true;\n    }\n    try {\n      Stat oldBreadcrumbStat = fenceOldActive();\n      writeBreadCrumbNode(oldBreadcrumbStat);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming active for \" + this);\n      }\n      appClient.becomeActive();\n      state = State.ACTIVE;\n      return true;\n    } catch (Exception e) {\n      LOG.warn(\"Exception handling the winning of election\", e);\n      // Caller will handle quitting and rejoining the election.\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.writeBreadCrumbNode": "  private void writeBreadCrumbNode(Stat oldBreadcrumbStat)\n      throws KeeperException, InterruptedException {\n    Preconditions.checkState(appData != null, \"no appdata\");\n    \n    LOG.info(\"Writing znode \" + zkBreadCrumbPath +\n        \" to indicate that the local node is the most recent active...\");\n    if (oldBreadcrumbStat == null) {\n      // No previous active, just create the node\n      createWithRetries(zkBreadCrumbPath, appData, zkAcl,\n        CreateMode.PERSISTENT);\n    } else {\n      // There was a previous active, update the node\n      setDataWithRetries(zkBreadCrumbPath, appData, oldBreadcrumbStat.getVersion());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fenceOldActive": "  private Stat fenceOldActive() throws InterruptedException, KeeperException {\n    final Stat stat = new Stat();\n    byte[] data;\n    LOG.info(\"Checking for any old active which needs to be fenced...\");\n    try {\n      data = zkDoWithRetries(new ZKAction<byte[]>() {\n        @Override\n        public byte[] run() throws KeeperException, InterruptedException {\n          return zkClient.getData(zkBreadCrumbPath, false, stat);\n        }\n      });\n    } catch (KeeperException ke) {\n      if (isNodeDoesNotExist(ke.code())) {\n        LOG.info(\"No old node to fence\");\n        return null;\n      }\n      \n      // If we failed to read for any other reason, then likely we lost\n      // our session, or we don't have permissions, etc. In any case,\n      // we probably shouldn't become active, and failing the whole\n      // thing is the best bet.\n      throw ke;\n    }\n\n    LOG.info(\"Old node exists: \" + StringUtils.byteToHexString(data));\n    if (Arrays.equals(data, appData)) {\n      LOG.info(\"But old node has our own data, so don't need to fence it.\");\n    } else {\n      appClient.fenceOldActive(data);\n    }\n    return stat;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.processResult": "  public synchronized void processResult(int rc, String path, Object ctx,\n      Stat stat) {\n    if (isStaleClient(ctx)) return;\n    monitorLockNodePending = false;\n\n    assert wantToBeInElection :\n        \"Got a StatNode result after quitting election\";\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"StatNode result: \" + rc + \" for path: \" + path\n          + \" connectionState: \" + zkConnectionState + \" for \" + this);\n    }\n\n    Code code = Code.get(rc);\n    if (isSuccess(code)) {\n      // the following owner check completes verification in case the lock znode\n      // creation was retried\n      if (stat.getEphemeralOwner() == zkClient.getSessionId()) {\n        // we own the lock znode. so we are the leader\n        if (!becomeActive()) {\n          reJoinElectionAfterFailureToBecomeActive();\n        }\n      } else {\n        // we dont own the lock znode. so we are a standby.\n        becomeStandby();\n      }\n      // the watch set by us will notify about changes\n      return;\n    }\n\n    if (isNodeDoesNotExist(code)) {\n      // the lock znode disappeared before we started monitoring it\n      enterNeutralMode();\n      joinElectionInternal();\n      return;\n    }\n\n    String errorMessage = \"Received stat error from Zookeeper. code:\"\n        + code.toString();\n    LOG.debug(errorMessage);\n\n    if (shouldRetry(code)) {\n      if (statRetryCount < maxRetryNum) {\n        ++statRetryCount;\n        monitorLockNodeAsync();\n        return;\n      }\n      errorMessage = errorMessage\n          + \". Not retrying further znode monitoring connection errors.\";\n    } else if (isSessionExpired(code)) {\n      // This isn't fatal - the client Watcher will re-join the election\n      LOG.warn(\"Lock monitoring failed because session was lost\");\n      return;\n    }\n\n    fatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code, Code retryIfCode) {\n    return (retryIfCode == null ? false : retryIfCode == code);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.joinElectionInternal": "  private void joinElectionInternal() {\n    Preconditions.checkState(appData != null,\n        \"trying to join election without any app data\");\n    if (zkClient == null) {\n      if (!reEstablishSession()) {\n        fatalError(\"Failed to reEstablish connection with ZooKeeper\");\n        return;\n      }\n    }\n\n    createRetryCount = 0;\n    wantToBeInElection = true;\n    createLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createLockNodeAsync": "  private void createLockNodeAsync() {\n    zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,\n        this, zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSuccess": "  private static boolean isSuccess(Code code) {\n    return (code == Code.OK);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorActiveStatus": "  private void monitorActiveStatus() {\n    assert wantToBeInElection;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Monitoring active leader for \" + this);\n    }\n    statRetryCount = 0;\n    monitorLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeDoesNotExist": "  private static boolean isNodeDoesNotExist(Code code) {\n    return (code == Code.NONODE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.reJoinElectionAfterFailureToBecomeActive": "  private void reJoinElectionAfterFailureToBecomeActive() {\n    reJoinElection(SLEEP_AFTER_FAILURE_TO_BECOME_ACTIVE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.enterNeutralMode": "  private void enterNeutralMode() {\n    if (state != State.NEUTRAL) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Entering neutral mode for \" + this);\n      }\n      state = State.NEUTRAL;\n      appClient.enterNeutralMode();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorLockNodeAsync": "  private void monitorLockNodeAsync() {\n    if (monitorLockNodePending && monitorLockNodeClient == zkClient) {\n      LOG.info(\"Ignore duplicate monitor lock-node request.\");\n      return;\n    }\n    monitorLockNodePending = true;\n    monitorLockNodeClient = zkClient;\n    zkClient.exists(zkLockFilePath,\n        watcher, this,\n        zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSessionExpired": "  private static boolean isSessionExpired(Code code) {\n    return (code == Code.SESSIONEXPIRED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeStandby": "  private void becomeStandby() {\n    if (state != State.STANDBY) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming standby for \" + this);\n      }\n      state = State.STANDBY;\n      appClient.becomeStandby();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fatalError": "  private void fatalError(String errorMessage) {\n    LOG.error(errorMessage);\n    reset();\n    appClient.notifyFatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isStaleClient": "  private synchronized boolean isStaleClient(Object ctx) {\n    Preconditions.checkNotNull(ctx);\n    if (zkClient != (ZooKeeper)ctx) {\n      LOG.warn(\"Ignoring stale result from old client with sessionId \" +\n          String.format(\"0x%08x\", ((ZooKeeper)ctx).getSessionId()));\n      return true;\n    }\n    return false;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getSystemMetricsPublisher": "  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMApps": "  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateApplicationTimeouts": "  public static void validateApplicationTimeouts(\n      Map<ApplicationTimeoutType, Long> timeouts) throws YarnException {\n    if (timeouts != null) {\n      for (Map.Entry<ApplicationTimeoutType, Long> timeout : timeouts\n          .entrySet()) {\n        if (timeout.getValue() <= 0) {\n          String message = \"Invalid application timeout, value=\"\n              + timeout.getValue() + \" for type=\" + timeout.getKey();\n          throw new YarnException(message);\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getAMRMTokenSecretManager": "  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMDelegationTokenSecretManager": "  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Logger log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service {} : {}\", service.getName(), e, e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getLeaderElectorService": "  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElector.rejoinElection": "  void rejoinElection();\n\n  /**\n   * Get information about the elector's connection to Zookeeper.\n   *\n   * @return zookeeper connection state\n   */\n  String getZookeeperConnectionState();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description, ArgsBuilder args) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          args));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ArgsBuilder args) {\n    StringBuilder b = createStringBuilderForFailureLog(user,\n        operation, target, description, perm);\n    if(args != null) {\n      add(args, b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      InetAddress ip, ArgsBuilder args) {\n    StringBuilder b =\n        createStringBuilderForSuccessEvent(user, operation, target, ip);\n    if(args != null) {\n      add(args, b);\n    }\n    return b.toString();\n  }"
        },
        "bug_report": {
            "Title": "Skip validating priority acls while recovering applications",
            "Description": "Test scenario\r\n------------------\r\n1. A cluster is created, no ACLs are included\r\n2. Submit jobs with an existing user say 'user_a'\r\n3. Enable ACLs and create a priority ACL entry via the property yarn.scheduler.capacity.priority-acls. Do not include the user, 'user_a' in this ACL.\r\n4. Submit a job with the 'user_a'\r\n\r\nThe observed behavior in this case is that the job is rejected as 'user_a' does not have the permission to run the job which is expected behavior. But Resource Manager also goes down when it tries to recover previous applications and fails to recover them.\r\nBelow is the exception seen,\r\n{noformat}\r\n2017-12-27 10:52:30,064 INFO  conf.Configuration (Configuration.java:getConfResourceAsInputStream(2659)) - found resource yarn-site.xml at file:/etc/hadoop/3.0.0.0-636/0/yarn-site.xml\r\n2017-12-27 10:52:30,065 INFO  scheduler.AbstractYarnScheduler (AbstractYarnScheduler.java:setClusterMaxPriority(911)) - Updated the cluste max priority to maxClusterLevelAppPriority = 10\r\n2017-12-27 10:52:30,066 INFO  resourcemanager.ResourceManager (ResourceManager.java:transitionToActive(1177)) - Transitioning to active state\r\n2017-12-27 10:52:30,097 INFO  resourcemanager.ResourceManager (ResourceManager.java:serviceStart(765)) - Recovery started\r\n2017-12-27 10:52:30,102 INFO  recovery.RMStateStore (RMStateStore.java:checkVersion(747)) - Loaded RM state version info 1.5\r\n2017-12-27 10:52:30,375 INFO  security.RMDelegationTokenSecretManager (RMDelegationTokenSecretManager.java:recover(196)) - recovering RMDelegationTokenSecretManager.\r\n2017-12-27 10:52:30,380 INFO  resourcemanager.RMAppManager (RMAppManager.java:recover(561)) - Recovering 51 applications\r\n2017-12-27 10:52:30,432 INFO  resourcemanager.RMAppManager (RMAppManager.java:recover(571)) - Successfully recovered 0 out of 51 applications\r\n2017-12-27 10:52:30,432 ERROR resourcemanager.ResourceManager (ResourceManager.java:serviceStart(776)) - Failed to load/recover state\r\norg.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.checkAndGetApplicationPriority(CapacityScheduler.java:2348)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:396)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:358)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:567)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1390)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:771)\r\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1143)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1183)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1179)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at javax.security.auth.Subject.doAs(Subject.java:422)\r\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1179)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:320)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\r\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:894)\r\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:473)\r\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:611)\r\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:510)\r\nCaused by: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\r\n        ... 20 more\r\n2017-12-27 10:52:30,434 INFO  service.AbstractService (AbstractService.java:noteFailure(273)) - Service RMActiveServices failed in state STARTED; cause: org.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\r\norg.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.checkAndGetApplicationPriority(CapacityScheduler.java:2348)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:396)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:358)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:567)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1390)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:771)\r\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1143)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1183)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1179)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at javax.security.auth.Subject.doAs(Subject.java:422)\r\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1179)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:320)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\r\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:894)\r\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:473)\r\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:611)\r\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:510)\r\nCaused by: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\r\n        ... 20 more\r\n2017-12-27 10:52:30,435 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping ResourceManager metrics system...\r\n2017-12-27 10:52:30,435 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - ResourceManager metrics system stopped.\r\n2017-12-27 10:52:30,436 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - ResourceManager metrics system shutdown complete.\r\n2017-12-27 10:52:30,436 INFO  event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(155)) - AsyncDispatcher is draining to stop, ignoring any new events.\r\n2017-12-27 10:52:30,437 INFO  event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher\r\n2017-12-27 10:52:30,438 INFO  security.NMTokenSecretManagerInRM (NMTokenSecretManagerInRM.java:<init>(75)) - NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms\r\n2017-12-27 10:52:30,438 INFO  security.RMContainerTokenSecretManager (RMContainerTokenSecretManager.java:<init>(79)) - ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms\r\n2017-12-27 10:52:30,438 INFO  security.AMRMTokenSecretManager (AMRMTokenSecretManager.java:<init>(94)) - AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms\r\n2017-12-27 10:52:30,439 INFO  recovery.RMStateStoreFactory (RMStateStoreFactory.java:getStore(33)) - Using RMStateStore implementation - class org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore\r\n2017-12-27 10:52:30,439 INFO  event.AsyncDispatcher (AsyncDispatcher.java:register(223)) - Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler\r\n2017-12-27 10:52:30,439 WARN  curator.CuratorZookeeperClient (CuratorZookeeperClient.java:<init>(96)) - session timeout [10000] is less than connection timeout [15000]\r\n2017-12-27 10:52:30,440 INFO  imps.CuratorFrameworkImpl (CuratorFrameworkImpl.java:start(235)) - Starting\r\n{noformat}\r\n"
        }
    },
    {
        "filename": "YARN-3917.json",
        "creation_time": "2015-07-11T00:41:28.000+0000",
        "stack_trace": "```\njava.lang.UnsupportedOperationException: Could not determine OS\n        at org.apache.hadoop.util.SysInfo.newInstance(SysInfo.java:43)\n        at org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.<init>(ResourceCalculatorPlugin.java:37)\n        at org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.getResourceCalculatorPlugin(ResourceCalculatorPlugin.java:160)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.serviceInit(ContainersMonitorImpl.java:108)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:249)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:312)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:547)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:595)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.SysInfo.newInstance": "  public static SysInfo newInstance() {\n    if (Shell.LINUX) {\n      return new SysInfoLinux();\n    }\n    if (Shell.WINDOWS) {\n      return new SysInfoWindows();\n    }\n    throw new UnsupportedOperationException(\"Could not determine OS\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.getResourceCalculatorPlugin": "  public static ResourceCalculatorPlugin getResourceCalculatorPlugin(\n      Class<? extends ResourceCalculatorPlugin> clazz, Configuration conf) {\n\n    if (clazz != null) {\n      return ReflectionUtils.newInstance(clazz, conf);\n    }\n    try {\n      return new ResourceCalculatorPlugin();\n    } catch (SecurityException e) {\n      return null;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    this.monitoringInterval =\n        conf.getLong(YarnConfiguration.NM_CONTAINER_MON_INTERVAL_MS,\n            YarnConfiguration.DEFAULT_NM_CONTAINER_MON_INTERVAL_MS);\n\n    Class<? extends ResourceCalculatorPlugin> clazz =\n        conf.getClass(YarnConfiguration.NM_CONTAINER_MON_RESOURCE_CALCULATOR, null,\n            ResourceCalculatorPlugin.class);\n    this.resourceCalculatorPlugin =\n        ResourceCalculatorPlugin.getResourceCalculatorPlugin(clazz, conf);\n    LOG.info(\" Using ResourceCalculatorPlugin : \"\n        + this.resourceCalculatorPlugin);\n    processTreeClass = conf.getClass(YarnConfiguration.NM_CONTAINER_MON_PROCESS_TREE, null,\n            ResourceCalculatorProcessTree.class);\n    this.conf = conf;\n    LOG.info(\" Using ResourceCalculatorProcessTree : \"\n        + this.processTreeClass);\n\n    this.containerMetricsEnabled =\n        conf.getBoolean(YarnConfiguration.NM_CONTAINER_METRICS_ENABLE,\n            YarnConfiguration.DEFAULT_NM_CONTAINER_METRICS_ENABLE);\n    this.containerMetricsPeriodMs =\n        conf.getLong(YarnConfiguration.NM_CONTAINER_METRICS_PERIOD_MS,\n            YarnConfiguration.DEFAULT_NM_CONTAINER_METRICS_PERIOD_MS);\n\n    long configuredPMemForContainers =\n        NodeManagerHardwareUtils.getContainerMemoryMB(conf) * 1024 * 1024L;\n\n    long configuredVCoresForContainers =\n        NodeManagerHardwareUtils.getVCores(conf);\n\n    // Setting these irrespective of whether checks are enabled. Required in\n    // the UI.\n    // ///////// Physical memory configuration //////\n    this.maxPmemAllottedForContainers = configuredPMemForContainers;\n    this.maxVCoresAllottedForContainers = configuredVCoresForContainers;\n\n    // ///////// Virtual memory configuration //////\n    float vmemRatio = conf.getFloat(YarnConfiguration.NM_VMEM_PMEM_RATIO,\n        YarnConfiguration.DEFAULT_NM_VMEM_PMEM_RATIO);\n    Preconditions.checkArgument(vmemRatio > 0.99f,\n        YarnConfiguration.NM_VMEM_PMEM_RATIO + \" should be at least 1.0\");\n    this.maxVmemAllottedForContainers =\n        (long) (vmemRatio * configuredPMemForContainers);\n\n    pmemCheckEnabled = conf.getBoolean(YarnConfiguration.NM_PMEM_CHECK_ENABLED,\n        YarnConfiguration.DEFAULT_NM_PMEM_CHECK_ENABLED);\n    vmemCheckEnabled = conf.getBoolean(YarnConfiguration.NM_VMEM_CHECK_ENABLED,\n        YarnConfiguration.DEFAULT_NM_VMEM_CHECK_ENABLED);\n    LOG.info(\"Physical memory check enabled: \" + pmemCheckEnabled);\n    LOG.info(\"Virtual memory check enabled: \" + vmemCheckEnabled);\n\n    nodeCpuPercentageForYARN =\n        NodeManagerHardwareUtils.getNodeCpuPercentage(conf);\n\n    if (pmemCheckEnabled) {\n      // Logging if actual pmem cannot be determined.\n      long totalPhysicalMemoryOnNM = UNKNOWN_MEMORY_LIMIT;\n      if (this.resourceCalculatorPlugin != null) {\n        totalPhysicalMemoryOnNM = this.resourceCalculatorPlugin\n            .getPhysicalMemorySize();\n        if (totalPhysicalMemoryOnNM <= 0) {\n          LOG.warn(\"NodeManager's totalPmem could not be calculated. \"\n              + \"Setting it to \" + UNKNOWN_MEMORY_LIMIT);\n          totalPhysicalMemoryOnNM = UNKNOWN_MEMORY_LIMIT;\n        }\n      }\n\n      if (totalPhysicalMemoryOnNM != UNKNOWN_MEMORY_LIMIT &&\n          this.maxPmemAllottedForContainers > totalPhysicalMemoryOnNM * 0.80f) {\n        LOG.warn(\"NodeManager configured with \"\n            + TraditionalBinaryPrefix.long2String(maxPmemAllottedForContainers,\n                \"\", 1)\n            + \" physical memory allocated to containers, which is more than \"\n            + \"80% of the total physical memory available (\"\n            + TraditionalBinaryPrefix.long2String(totalPhysicalMemoryOnNM, \"\",\n                1) + \"). Thrashing might happen.\");\n      }\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": initing services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      service.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit": "  public void serviceInit(Configuration conf) throws Exception {\n    LogHandler logHandler =\n      createLogHandler(conf, this.context, this.deletionService);\n    addIfService(logHandler);\n    dispatcher.register(LogHandlerEventType.class, logHandler);\n    \n    // add the shared cache upload service (it will do nothing if the shared\n    // cache is disabled)\n    SharedCacheUploadService sharedCacheUploader =\n        createSharedCacheUploaderService();\n    addService(sharedCacheUploader);\n    dispatcher.register(SharedCacheUploadEventType.class, sharedCacheUploader);\n\n    waitForContainersOnShutdownMillis =\n        conf.getLong(YarnConfiguration.NM_SLEEP_DELAY_BEFORE_SIGKILL_MS,\n            YarnConfiguration.DEFAULT_NM_SLEEP_DELAY_BEFORE_SIGKILL_MS) +\n        conf.getLong(YarnConfiguration.NM_PROCESS_KILL_WAIT_MS,\n            YarnConfiguration.DEFAULT_NM_PROCESS_KILL_WAIT_MS) +\n        SHUTDOWN_CLEANUP_SLOP_MS;\n\n    super.serviceInit(conf);\n    recover();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover": "  private void recover() throws IOException, URISyntaxException {\n    NMStateStoreService stateStore = context.getNMStateStore();\n    if (stateStore.canRecover()) {\n      rsrcLocalizationSrvc.recoverLocalizedResources(\n          stateStore.loadLocalizationState());\n\n      RecoveredApplicationsState appsState = stateStore.loadApplicationsState();\n      for (ContainerManagerApplicationProto proto :\n           appsState.getApplications()) {\n        recoverApplication(proto);\n      }\n\n      for (RecoveredContainerState rcs : stateStore.loadContainersState()) {\n        recoverContainer(rcs);\n      }\n\n      String diagnostic = \"Application marked finished during recovery\";\n      for (ApplicationId appId : appsState.getFinishedApplications()) {\n        dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appId, diagnostic));\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createLogHandler": "  protected LogHandler createLogHandler(Configuration conf, Context context,\n      DeletionService deletionService) {\n    if (conf.getBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED,\n        YarnConfiguration.DEFAULT_LOG_AGGREGATION_ENABLED)) {\n      return new LogAggregationService(this.dispatcher, context,\n          deletionService, dirsHandler);\n    } else {\n      return new NonAggregatingLogHandler(this.dispatcher, deletionService,\n                                          dirsHandler,\n                                          context.getNMStateStore());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createSharedCacheUploaderService": "  protected SharedCacheUploadService createSharedCacheUploaderService() {\n    return new SharedCacheUploadService();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n\n    conf.setBoolean(Dispatcher.DISPATCHER_EXIT_ON_ERROR_KEY, true);\n\n    rmWorkPreservingRestartEnabled = conf.getBoolean(YarnConfiguration\n            .RM_WORK_PRESERVING_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_ENABLED);\n\n    initAndStartRecoveryStore(conf);\n\n    NMContainerTokenSecretManager containerTokenSecretManager =\n        new NMContainerTokenSecretManager(conf, nmStore);\n\n    NMTokenSecretManagerInNM nmTokenSecretManager =\n        new NMTokenSecretManagerInNM(nmStore);\n\n    recoverTokens(nmTokenSecretManager, containerTokenSecretManager);\n    \n    this.aclsManager = new ApplicationACLsManager(conf);\n\n    ContainerExecutor exec = ReflectionUtils.newInstance(\n        conf.getClass(YarnConfiguration.NM_CONTAINER_EXECUTOR,\n          DefaultContainerExecutor.class, ContainerExecutor.class), conf);\n    try {\n      exec.init();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to initialize container executor\", e);\n    }    \n    DeletionService del = createDeletionService(exec);\n    addService(del);\n\n    // NodeManager level dispatcher\n    this.dispatcher = new AsyncDispatcher();\n\n    dirsHandler = new LocalDirsHandlerService(metrics);\n    nodeHealthChecker =\n        new NodeHealthCheckerService(\n            getNodeHealthScriptRunner(conf), dirsHandler);\n    addService(nodeHealthChecker);\n\n    this.context = createNMContext(containerTokenSecretManager,\n        nmTokenSecretManager, nmStore);\n\n    nodeLabelsProvider = createNodeLabelsProvider(conf);\n\n    if (null == nodeLabelsProvider) {\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker);\n    } else {\n      addService(nodeLabelsProvider);\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker,\n              nodeLabelsProvider);\n    }\n\n    NodeResourceMonitor nodeResourceMonitor = createNodeResourceMonitor();\n    addService(nodeResourceMonitor);\n\n    containerManager =\n        createContainerManager(context, exec, del, nodeStatusUpdater,\n        this.aclsManager, dirsHandler);\n    addService(containerManager);\n    ((NMContext) context).setContainerManager(containerManager);\n\n    WebServer webServer = createWebServer(context, containerManager\n        .getContainersMonitor(), this.aclsManager, dirsHandler);\n    addService(webServer);\n    ((NMContext) context).setWebServer(webServer);\n\n    dispatcher.register(ContainerManagerEventType.class, containerManager);\n    dispatcher.register(NodeManagerEventType.class, this);\n    addService(dispatcher);\n    \n    DefaultMetricsSystem.initialize(\"NodeManager\");\n\n    // StatusUpdater should be added last so that it get started last \n    // so that we make sure everything is up before registering with RM. \n    addService(nodeStatusUpdater);\n    \n    super.serviceInit(conf);\n    // TODO add local dirs to del\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMContext": "  protected NMContext createNMContext(\n      NMContainerTokenSecretManager containerTokenSecretManager,\n      NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMStateStoreService stateStore) {\n    return new NMContext(containerTokenSecretManager, nmTokenSecretManager,\n        dirsHandler, aclsManager, stateStore);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.recoverTokens": "  private void recoverTokens(NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMContainerTokenSecretManager containerTokenSecretManager)\n          throws IOException {\n    if (nmStore.canRecover()) {\n      nmTokenSecretManager.recover();\n      containerTokenSecretManager.recover();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartRecoveryStore": "  private void initAndStartRecoveryStore(Configuration conf)\n      throws IOException {\n    boolean recoveryEnabled = conf.getBoolean(\n        YarnConfiguration.NM_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_NM_RECOVERY_ENABLED);\n    if (recoveryEnabled) {\n      FileSystem recoveryFs = FileSystem.getLocal(conf);\n      String recoveryDirName = conf.get(YarnConfiguration.NM_RECOVERY_DIR);\n      if (recoveryDirName == null) {\n        throw new IllegalArgumentException(\"Recovery is enabled but \" +\n            YarnConfiguration.NM_RECOVERY_DIR + \" is not set.\");\n      }\n      Path recoveryRoot = new Path(recoveryDirName);\n      recoveryFs.mkdirs(recoveryRoot, new FsPermission((short)0700));\n      nmStore = new NMLeveldbStateStoreService();\n    } else {\n      nmStore = new NMNullStateStoreService();\n    }\n    nmStore.init(conf);\n    nmStore.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeStatusUpdater": "  protected NodeStatusUpdater createNodeStatusUpdater(Context context,\n      Dispatcher dispatcher, NodeHealthCheckerService healthChecker,\n      NodeLabelsProvider nodeLabelsProvider) {\n    return new NodeStatusUpdaterImpl(context, dispatcher, healthChecker,\n        metrics, nodeLabelsProvider);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createWebServer": "  protected WebServer createWebServer(Context nmContext,\n      ResourceView resourceView, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new WebServer(nmContext, resourceView, aclsManager, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createContainerManager": "  protected ContainerManagerImpl createContainerManager(Context context,\n      ContainerExecutor exec, DeletionService del,\n      NodeStatusUpdater nodeStatusUpdater, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new ContainerManagerImpl(context, exec, del, nodeStatusUpdater,\n      metrics, aclsManager, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createDeletionService": "  protected DeletionService createDeletionService(ContainerExecutor exec) {\n    return new DeletionService(exec, nmStore);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeResourceMonitor": "  protected NodeResourceMonitor createNodeResourceMonitor() {\n    return new NodeResourceMonitorImpl();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeLabelsProvider": "  protected NodeLabelsProvider createNodeLabelsProvider(\n      Configuration conf) throws IOException {\n    // TODO as part of YARN-2729\n    // Need to get the implementation of provider service and return\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.getNodeHealthScriptRunner": "  public static NodeHealthScriptRunner getNodeHealthScriptRunner(Configuration conf) {\n    String nodeHealthScript = \n        conf.get(YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_PATH);\n    if(!NodeHealthScriptRunner.shouldRun(nodeHealthScript)) {\n      LOG.info(\"Node Manager health check script is not available \"\n          + \"or doesn't have execute permission, so not \"\n          + \"starting the node health script runner.\");\n      return null;\n    }\n    long nmCheckintervalTime = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS);\n    long scriptTimeout = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS);\n    String[] scriptArgs = conf.getStrings(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_OPTS, new String[] {});\n    return new NodeHealthScriptRunner(nodeHealthScript,\n        nmCheckintervalTime, scriptTimeout, scriptArgs);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager": "  private void initAndStartNodeManager(Configuration conf, boolean hasToReboot) {\n    try {\n\n      // Remove the old hook if we are rebooting.\n      if (hasToReboot && null != nodeManagerShutdownHook) {\n        ShutdownHookManager.get().removeShutdownHook(nodeManagerShutdownHook);\n      }\n\n      nodeManagerShutdownHook = new CompositeServiceShutdownHook(this);\n      ShutdownHookManager.get().addShutdownHook(nodeManagerShutdownHook,\n                                                SHUTDOWN_HOOK_PRIORITY);\n      // System exit should be called only when NodeManager is instantiated from\n      // main() funtion\n      this.shouldExitOnShutdownEvent = true;\n      this.init(conf);\n      this.start();\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting NodeManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.main": "  public static void main(String[] args) throws IOException {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(NodeManager.class, args, LOG);\n    NodeManager nodeManager = new NodeManager();\n    Configuration conf = new YarnConfiguration();\n    new GenericOptionsParser(conf, args);\n    nodeManager.initAndStartNodeManager(conf, false);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.init": "  void init(Configuration config);\n\n\n  /**\n   * Start the service.\n   *\n   * The transition MUST be from {@link STATE#INITED} to {@link STATE#STARTED}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.init": "  public abstract void init() throws IOException;\n\n  /**\n   * On Windows the ContainerLaunch creates a temporary special jar manifest of \n   * other jars to workaround the CLASSPATH length. In a  secure cluster this \n   * jar must be localized so that the container has access to it. \n   * This function localizes on-demand the jar.\n   * \n   * @param classPathJar\n   * @param owner\n   * @throws IOException\n   */\n  public Path localizeClasspathJar(Path classPathJar, Path pwd, String owner) \n      throws IOException {\n    // Non-secure executor simply use the classpath created \n    // in the NM fprivate folder\n    return classPathJar;\n  }"
        },
        "bug_report": {
            "Title": "getResourceCalculatorPlugin for the default should intercept all exceptions",
            "Description": "Since the user has not configured a specific plugin, any problems with the default resource calculator instantiation should be ignored.\n\n{code}\n2015-07-10 08:16:18,445 INFO org.apache.hadoop.service.AbstractService: Service containers-monitor failed in state INITED; cause: java.lang.UnsupportedOperationException: Could not determine OS\njava.lang.UnsupportedOperationException: Could not determine OS\n        at org.apache.hadoop.util.SysInfo.newInstance(SysInfo.java:43)\n        at org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.<init>(ResourceCalculatorPlugin.java:37)\n        at org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.getResourceCalculatorPlugin(ResourceCalculatorPlugin.java:160)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.serviceInit(ContainersMonitorImpl.java:108)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:249)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:312)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:547)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:595)\n{code}"
        }
    },
    {
        "filename": "YARN-3537.json",
        "creation_time": "2015-04-23T11:34:23.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stopRecoveryStore(NodeManager.java:181)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:326)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\tat org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.tearDown(TestNodeManagerShutdown.java:106)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.stopRecoveryStore": "  private void stopRecoveryStore() throws IOException {\n    nmStore.stop();\n    if (null != context) {\n      if (context.getDecommissioned() && nmStore.canRecover()) {\n        LOG.info(\"Removing state store due to decommission\");\n        Configuration conf = getConfig();\n        Path recoveryRoot =\n            new Path(conf.get(YarnConfiguration.NM_RECOVERY_DIR));\n        LOG.info(\"Removing state store at \" + recoveryRoot\n            + \" due to decommission\");\n        FileSystem recoveryFs = FileSystem.getLocal(conf);\n        if (!recoveryFs.delete(recoveryRoot, true)) {\n          LOG.warn(\"Unable to delete \" + recoveryRoot);\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.getDecommissioned": "    public boolean getDecommissioned() {\n      return isDecommissioned;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop": "  protected void serviceStop() throws Exception {\n    if (isStopping.getAndSet(true)) {\n      return;\n    }\n    super.serviceStop();\n    stopRecoveryStore();\n    DefaultMetricsSystem.shutdown();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.stop": "  public void stop() {\n    if (isInState(STATE.STOPPED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.STOPPED) != STATE.STOPPED) {\n        try {\n          serviceStop();\n        } catch (Exception e) {\n          //stop-time exceptions are logged if they are the first one,\n          noteFailure(e);\n          throw ServiceStateException.convert(e);\n        } finally {\n          //report that the service has terminated\n          terminationNotification.set(true);\n          synchronized (terminationNotification) {\n            terminationNotification.notifyAll();\n          }\n          //notify anything listening for events\n          notifyListeners();\n        }\n      } else {\n        //already stopped: note it\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring re-entrant call to stop()\");\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStop": "  protected void serviceStop() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "NPE when NodeManager.serviceInit fails and stopRecoveryStore invoked",
            "Description": "2015-04-23 19:30:34,961 INFO  [main] service.AbstractService (AbstractService.java:noteFailure(272)) - Service NodeManager failed in state STOPPED; cause: java.lang.NullPointerException\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stopRecoveryStore(NodeManager.java:181)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:326)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\tat org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.tearDown(TestNodeManagerShutdown.java:106)"
        }
    },
    {
        "filename": "YARN-7962.json",
        "creation_time": "2018-02-22T22:32:20.000+0000",
        "stack_trace": "```\njava.util.concurrent.RejectedExecutionException: Task org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable@39bddaf2 rejected from java.util.concurrent.ThreadPoolExecutor@5f71637b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15487]\n\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)\n\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1372)\n\tat org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.processDelegationTokenRenewerEvent(DelegationTokenRenewer.java:196)\n\tat org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.applicationFinished(DelegationTokenRenewer.java:734)\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.finishApplication(RMAppManager.java:199)\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:424)\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:65)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:177)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.finishApplication": "  protected synchronized void finishApplication(ApplicationId applicationId) {\n    if (applicationId == null) {\n      LOG.error(\"RMAppManager received completed appId of null, skipping\");\n    } else {\n      // Inform the DelegationTokenRenewer\n      if (UserGroupInformation.isSecurityEnabled()) {\n        rmContext.getDelegationTokenRenewer().applicationFinished(applicationId);\n      }\n      \n      completedApps.add(applicationId);\n      completedAppsInStateStore++;\n      writeAuditLog(applicationId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.writeAuditLog": "  protected void writeAuditLog(ApplicationId appId) {\n    RMApp app = rmContext.getRMApps().get(appId);\n    String operation = \"UNKONWN\";\n    boolean success = false;\n    switch (app.getState()) {\n      case FAILED: \n        operation = AuditConstants.FINISH_FAILED_APP;\n        break;\n      case FINISHED:\n        operation = AuditConstants.FINISH_SUCCESS_APP;\n        success = true;\n        break;\n      case KILLED: \n        operation = AuditConstants.FINISH_KILLED_APP;\n        success = true;\n        break;\n      default:\n        break;\n    }\n    \n    if (success) {\n      RMAuditLogger.logSuccess(app.getUser(), operation,\n          \"RMAppManager\", app.getApplicationId());\n    } else {\n      StringBuilder diag = app.getDiagnostics(); \n      String msg = diag == null ? null : diag.toString();\n      RMAuditLogger.logFailure(app.getUser(), operation, msg, \"RMAppManager\",\n          \"App failed with state: \" + app.getState(), appId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.add": "      SummaryBuilder add(SummaryBuilder summary) {\n        if (buffer.length() > 0) buffer.append(StringUtils.COMMA);\n        buffer.append(summary.buffer);\n        return this;\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch (event.getType()) {\n    case APP_COMPLETED :\n      finishApplication(applicationId);\n      logApplicationSummary(applicationId);\n      checkAppNumCompletedLimit();\n      break;\n    case APP_MOVE :\n      // moveAllApps from scheduler will fire this event for each of\n      // those applications which needed to be moved to a new queue.\n      // Use the standard move application api to do the same.\n      try {\n        moveApplicationAcrossQueue(applicationId,\n            event.getTargetQueueForMove());\n      } catch (YarnException e) {\n        LOG.warn(\"Move Application has failed: \" + e.getMessage());\n      }\n      break;\n    default :\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.logApplicationSummary": "  public void logApplicationSummary(ApplicationId appId) {\n    ApplicationSummary.logAppSummary(rmContext.getRMApps().get(appId));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.checkAppNumCompletedLimit": "  protected synchronized void checkAppNumCompletedLimit() {\n    // check apps kept in state store.\n    while (completedAppsInStateStore > this.maxCompletedAppsInStateStore) {\n      ApplicationId removeId =\n          completedApps.get(completedApps.size() - completedAppsInStateStore);\n      RMApp removeApp = rmContext.getRMApps().get(removeId);\n      LOG.info(\"Max number of completed apps kept in state store met:\"\n          + \" maxCompletedAppsInStateStore = \" + maxCompletedAppsInStateStore\n          + \", removing app \" + removeApp.getApplicationId()\n          + \" from state store.\");\n      rmContext.getStateStore().removeApplication(removeApp);\n      completedAppsInStateStore--;\n    }\n\n    // check apps kept in memorty.\n    while (completedApps.size() > this.maxCompletedAppsInMemory) {\n      ApplicationId removeId = completedApps.remove();\n      LOG.info(\"Application should be expired, max number of completed apps\"\n          + \" kept in memory met: maxCompletedAppsInMemory = \"\n          + this.maxCompletedAppsInMemory + \", removing app \" + removeId\n          + \" from memory: \");\n      rmContext.getRMApps().remove(removeId);\n      this.applicationACLsManager.removeApplication(removeId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.moveApplicationAcrossQueue": "  public void moveApplicationAcrossQueue(ApplicationId applicationId, String targetQueue)\n      throws YarnException {\n    RMApp app = this.rmContext.getRMApps().get(applicationId);\n\n    // Capacity scheduler will directly follow below approach.\n    // 1. Do a pre-validate check to ensure that changes are fine.\n    // 2. Update this information to state-store\n    // 3. Perform real move operation and update in-memory data structures.\n    synchronized (applicationId) {\n      if (app == null || app.isAppInCompletedStates()) {\n        return;\n      }\n\n      String sourceQueue = app.getQueue();\n      // 1. pre-validate move application request to check for any access\n      // violations or other errors. If there are any violations, YarnException\n      // will be thrown.\n      rmContext.getScheduler().preValidateMoveApplication(applicationId,\n          targetQueue);\n\n      // 2. Update to state store with new queue and throw exception is failed.\n      updateAppDataToStateStore(targetQueue, app, false);\n\n      // 3. Perform the real move application\n      String queue = \"\";\n      try {\n        queue = rmContext.getScheduler().moveApplication(applicationId,\n            targetQueue);\n      } catch (YarnException e) {\n        // Revert to source queue since in-memory move has failed. Chances\n        // of this is very rare as we have already done the pre-validation.\n        updateAppDataToStateStore(sourceQueue, app, true);\n        throw e;\n      }\n\n      // update in-memory\n      if (queue != null && !queue.isEmpty()) {\n        app.setQueue(queue);\n      }\n    }\n\n    rmContext.getSystemMetricsPublisher().appUpdated(app,\n        System.currentTimeMillis());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getDelegationTokenRenewer": "  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n\n  AllocationTagsManager getAllocationTagsManager();\n\n  void setAllocationTagsManager(AllocationTagsManager allocationTagsManager);\n\n  PlacementConstraintManager getPlacementConstraintManager();\n\n  void setPlacementConstraintManager(\n      PlacementConstraintManager placementConstraintManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Race Condition When Stopping DelegationTokenRenewer causes RM crash during failover",
            "Description": "[https://github.com/apache/hadoop/blob/69fa81679f59378fd19a2c65db8019393d7c05a2/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/DelegationTokenRenewer.java]\r\n{code:java}\r\n  private ThreadPoolExecutor renewerService;\r\n\r\n  private void processDelegationTokenRenewerEvent(\r\n      DelegationTokenRenewerEvent evt) {\r\n    serviceStateLock.readLock().lock();\r\n    try {\r\n      if (isServiceStarted) {\r\n        renewerService.execute(new DelegationTokenRenewerRunnable(evt));\r\n      } else {\r\n        pendingEventQueue.add(evt);\r\n      }\r\n    } finally {\r\n      serviceStateLock.readLock().unlock();\r\n    }\r\n  }\r\n\r\n  @Override\r\n  protected void serviceStop() {\r\n    if (renewalTimer != null) {\r\n      renewalTimer.cancel();\r\n    }\r\n    appTokens.clear();\r\n    allTokens.clear();\r\n    this.renewerService.shutdown();\r\n{code}\r\n{code:java}\r\n2018-02-21 11:18:16,253  FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\r\njava.util.concurrent.RejectedExecutionException: Task org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable@39bddaf2 rejected from java.util.concurrent.ThreadPoolExecutor@5f71637b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15487]\r\n\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)\r\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)\r\n\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1372)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.processDelegationTokenRenewerEvent(DelegationTokenRenewer.java:196)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.applicationFinished(DelegationTokenRenewer.java:734)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.finishApplication(RMAppManager.java:199)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:424)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:65)\r\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:177)\r\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n{code}\r\nWhat I think is going on here is that the\u00a0{{serviceStop}}\u00a0method is not setting the\u00a0{{isServiceStarted}}\u00a0flag to 'false'.\r\n\r\nPlease update so that the\u00a0{{serviceStop}}\u00a0method grabs the\u00a0{{serviceStateLock}}\u00a0and sets\u00a0{{isServiceStarted}}\u00a0to\u00a0_false_, before shutting down the\u00a0{{renewerService}}\u00a0thread pool,\u00a0to avoid this condition."
        }
    },
    {
        "filename": "YARN-8357.json",
        "creation_time": "2018-05-24T16:46:57.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\n        at org.apache.hadoop.yarn.service.client.ServiceClient.actionStart(ServiceClient.java:974)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$7.run(ApiServer.java:650)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$7.run(ApiServer.java:644)\n\n        at java.security.AccessController.doPrivileged(Native Method)\n\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1687)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.startService(ApiServer.java:644)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.updateService(ApiServer.java:449)\n\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\n        at java.lang.reflect.Method.invoke(Method.java:498)\n\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\n\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\n\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\n\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\n\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.actionStart": "  public int actionStart(String serviceName) throws YarnException, IOException {\n    ServiceApiUtil.validateNameFormat(serviceName, getConfig());\n    Service liveService = getStatus(serviceName);\n    if (liveService == null ||\n        !liveService.getState().equals(ServiceState.UPGRADING)) {\n      Path appDir = checkAppExistOnHdfs(serviceName);\n      Service service = ServiceApiUtil.loadService(fs, serviceName);\n      ServiceApiUtil.validateAndResolveService(service, fs, getConfig());\n      // see if it is actually running and bail out;\n      verifyNoLiveAppInRM(serviceName, \"start\");\n      ApplicationId appId = submitApp(service);\n      service.setId(appId.toString());\n      // write app definition on to hdfs\n      Path appJson = ServiceApiUtil.writeAppDefinition(fs, appDir, service);\n      LOG.info(\"Persisted service \" + service.getName() + \" at \" + appJson);\n      return 0;\n    } else {\n      LOG.info(\"Finalize service {} upgrade\");\n      ApplicationReport appReport =\n          yarnClient.getApplicationReport(getAppId(serviceName));\n      if (StringUtils.isEmpty(appReport.getHost())) {\n        throw new YarnException(serviceName + \" AM hostname is empty\");\n      }\n      ClientAMProtocol proxy = createAMProxy(serviceName, appReport);\n\n      RestartServiceRequestProto.Builder requestBuilder =\n          RestartServiceRequestProto.newBuilder();\n      proxy.restart(requestBuilder.build());\n      return 0;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.submitApp": "  ApplicationId submitApp(Service app) throws IOException, YarnException {\n    String serviceName = app.getName();\n    Configuration conf = getConfig();\n    Path appRootDir = fs.buildClusterDirPath(app.getName());\n\n    YarnClientApplication yarnApp = yarnClient.createApplication();\n    ApplicationSubmissionContext submissionContext =\n        yarnApp.getApplicationSubmissionContext();\n    ServiceApiUtil.validateCompResourceSize(\n        yarnApp.getNewApplicationResponse().getMaximumResourceCapability(),\n        app);\n\n    submissionContext.setKeepContainersAcrossApplicationAttempts(true);\n    if (app.getLifetime() > 0) {\n      Map<ApplicationTimeoutType, Long> appTimeout = new HashMap<>();\n      appTimeout.put(ApplicationTimeoutType.LIFETIME, app.getLifetime());\n      submissionContext.setApplicationTimeouts(appTimeout);\n    }\n    submissionContext.setMaxAppAttempts(YarnServiceConf\n        .getInt(YarnServiceConf.AM_RESTART_MAX, DEFAULT_AM_RESTART_MAX, app\n            .getConfiguration(), conf));\n\n    setLogAggregationContext(app, conf, submissionContext);\n\n    Map<String, LocalResource> localResources = new HashMap<>();\n\n    // copy local slideram-log4j.properties to hdfs and add to localResources\n    boolean hasAMLog4j =\n        addAMLog4jResource(serviceName, conf, localResources);\n    // copy jars to hdfs and add to localResources\n    addJarResource(serviceName, localResources);\n    // add keytab if in secure env\n    addKeytabResourceIfSecure(fs, localResources, app);\n    if (LOG.isDebugEnabled()) {\n      printLocalResources(localResources);\n    }\n    Map<String, String> env = addAMEnv();\n\n    // create AM CLI\n    String cmdStr = buildCommandLine(app, conf, appRootDir, hasAMLog4j);\n    submissionContext.setResource(Resource.newInstance(YarnServiceConf\n        .getLong(YarnServiceConf.AM_RESOURCE_MEM,\n            YarnServiceConf.DEFAULT_KEY_AM_RESOURCE_MEM, app.getConfiguration(),\n            conf), 1));\n    String queue = app.getQueue();\n    if (StringUtils.isEmpty(queue)) {\n      queue = conf.get(YARN_QUEUE, DEFAULT_YARN_QUEUE);\n    }\n    submissionContext.setQueue(queue);\n    submissionContext.setApplicationName(serviceName);\n    submissionContext.setApplicationType(YarnServiceConstants.APP_TYPE);\n    Set<String> appTags =\n        AbstractClientProvider.createApplicationTags(serviceName, null, null);\n    if (!appTags.isEmpty()) {\n      submissionContext.setApplicationTags(appTags);\n    }\n    ContainerLaunchContext amLaunchContext =\n        Records.newRecord(ContainerLaunchContext.class);\n    amLaunchContext.setCommands(Collections.singletonList(cmdStr));\n    amLaunchContext.setEnvironment(env);\n    amLaunchContext.setLocalResources(localResources);\n    addCredentials(amLaunchContext, app);\n    submissionContext.setAMContainerSpec(amLaunchContext);\n    yarnClient.submitApplication(submissionContext);\n    return submissionContext.getApplicationId();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.checkAppExistOnHdfs": "  private Path checkAppExistOnHdfs(String serviceName)\n      throws IOException, SliderException {\n    Path appDir = fs.buildClusterDirPath(serviceName);\n    fs.verifyPathExists(new Path(appDir, serviceName + \".json\"));\n    return appDir;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.verifyNoLiveAppInRM": "  private void verifyNoLiveAppInRM(String serviceName, String action)\n      throws IOException, YarnException {\n    Set<String> types = new HashSet<>(1);\n    types.add(YarnServiceConstants.APP_TYPE);\n    Set<String> tags = null;\n    if (serviceName != null) {\n      tags = Collections.singleton(ServiceUtils.createNameTag(serviceName));\n    }\n    GetApplicationsRequest request = GetApplicationsRequest.newInstance();\n    request.setApplicationTypes(types);\n    request.setApplicationTags(tags);\n    request.setApplicationStates(liveStates);\n    String user = UserGroupInformation.getCurrentUser().getUserName();\n    if (user != null) {\n      request.setUsers(Collections.singleton(user));\n    }\n    List<ApplicationReport> reports = yarnClient.getApplications(request);\n    if (!reports.isEmpty()) {\n      String message = \"\";\n      if (action.equals(\"destroy\")) {\n        message = \"Failed to destroy service \" + serviceName\n            + \", because it is still running.\";\n      } else {\n        message = \"Failed to \" + action + \" service \" + serviceName\n            + \", because it already exists.\";\n      }\n      throw new YarnException(message);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.getAppId": "  public synchronized ApplicationId getAppId(String serviceName)\n      throws IOException, YarnException {\n    if (cachedAppInfo.containsKey(serviceName)) {\n      return cachedAppInfo.get(serviceName).appId;\n    }\n    Service persistedService = ServiceApiUtil.loadService(fs, serviceName);\n    if (persistedService == null) {\n      throw new YarnException(\"Service \" + serviceName\n          + \" doesn't exist on hdfs. Please check if the app exists in RM\");\n    }\n    if (persistedService.getId() == null) {\n      return null;\n    }\n    ApplicationId currentAppId = ApplicationId.fromString(persistedService\n        .getId());\n    cachedAppInfo.put(serviceName, new AppInfo(currentAppId, persistedService\n        .getKerberosPrincipal().getPrincipalName()));\n    return currentAppId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.getStatus": "  public Service getStatus(String serviceName)\n      throws IOException, YarnException {\n    ServiceApiUtil.validateNameFormat(serviceName, getConfig());\n    Service appSpec = new Service();\n    appSpec.setName(serviceName);\n    ApplicationId currentAppId = getAppId(serviceName);\n    if (currentAppId == null) {\n      LOG.info(\"Service {} does not have an application ID\", serviceName);\n      return appSpec;\n    }\n    ApplicationReport appReport = yarnClient.getApplicationReport(currentAppId);\n    appSpec.setState(convertState(appReport.getYarnApplicationState()));\n    ApplicationTimeout lifetime =\n        appReport.getApplicationTimeouts().get(ApplicationTimeoutType.LIFETIME);\n    if (lifetime != null) {\n      appSpec.setLifetime(lifetime.getRemainingTime());\n    }\n\n    if (appReport.getYarnApplicationState() != RUNNING) {\n      LOG.info(\"Service {} is at {} state\", serviceName,\n          appReport.getYarnApplicationState());\n      return appSpec;\n    }\n    if (StringUtils.isEmpty(appReport.getHost())) {\n      LOG.warn(serviceName + \" AM hostname is empty\");\n      return appSpec;\n    }\n    ClientAMProtocol amProxy =\n        createAMProxy(serviceName, appReport);\n    GetStatusResponseProto response =\n        amProxy.getStatus(GetStatusRequestProto.newBuilder().build());\n    appSpec = jsonSerDeser.fromJson(response.getStatus());\n    if (lifetime != null) {\n      appSpec.setLifetime(lifetime.getRemainingTime());\n    }\n    return appSpec;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.createAMProxy": "  protected ClientAMProtocol createAMProxy(String serviceName,\n      ApplicationReport appReport) throws IOException, YarnException {\n\n    if (UserGroupInformation.isSecurityEnabled()) {\n      if (!cachedAppInfo.containsKey(serviceName)) {\n        Service persistedService  = ServiceApiUtil.loadService(fs, serviceName);\n        cachedAppInfo.put(serviceName, new AppInfo(appReport.getApplicationId(),\n            persistedService.getKerberosPrincipal().getPrincipalName()));\n      }\n      String principalName = cachedAppInfo.get(serviceName).principalName;\n      // Inject the principal into hadoop conf, because Hadoop\n      // SaslRpcClient#getServerPrincipal requires a config for the\n      // principal\n      if (!StringUtils.isEmpty(principalName)) {\n        getConfig().set(PRINCIPAL, principalName);\n      } else {\n        throw new YarnException(\"No principal specified in the persisted \" +\n            \"service definition, fail to connect to AM.\");\n      }\n    }\n    InetSocketAddress address =\n        NetUtils.createSocketAddrForHost(appReport.getHost(), appReport\n            .getRpcPort());\n    return ClientAMProxy.createProxy(getConfig(), ClientAMProtocol.class,\n        UserGroupInformation.getCurrentUser(), rpc, address);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }"
        },
        "bug_report": {
            "Title": "Yarn Service: NPE when service is saved first and then started.",
            "Description": "Line 972 in \\{{ServiceClient}} returns a service with state \\{{null}} which is why there is a NPE.\r\n{code:java}\r\n2018-05-24 04:39:22,911 INFO\u00a0 client.ServiceClient (ServiceClient.java:getStatus(1203)) - Service test1\u00a0does not have an application ID\r\n2018-05-24 04:39:22,911 ERROR webapp.ApiServer (ApiServer.java:updateService(480)) - Error while performing operation for app: test1\r\n\r\njava.lang.NullPointerException\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.service.client.ServiceClient.actionStart(ServiceClient.java:974)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.service.webapp.ApiServer$7.run(ApiServer.java:650)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.service.webapp.ApiServer$7.run(ApiServer.java:644)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.security.AccessController.doPrivileged(Native Method)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at javax.security.auth.Subject.doAs(Subject.java:422)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1687)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.service.webapp.ApiServer.startService(ApiServer.java:644)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.service.webapp.ApiServer.updateService(ApiServer.java:449)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.reflect.Method.invoke(Method.java:498)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\r\n{code}"
        }
    },
    {
        "filename": "YARN-6534.json",
        "creation_time": "2017-04-26T21:43:52.000+0000",
        "stack_trace": "```\norg.apache.hadoop.service.ServiceStateException: java.io.FileNotFoundException: /etc/security/clientKeys/all.jks (No such file or directory)\n        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:172)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit(TimelineClientImpl.java:131)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher.serviceInit(AbstractSystemMetricsPublisher.java:59)\n        at org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.serviceInit(TimelineServiceV1Publisher.java:67)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:344)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1453)\nCaused by: java.io.FileNotFoundException: /etc/security/clientKeys/all.jks (No such file or directory)\n        at java.io.FileInputStream.open0(Native Method)\n        at java.io.FileInputStream.open(FileInputStream.java:195)\n        at java.io.FileInputStream.<init>(FileInputStream.java:138)\n        at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.loadTrustManager(ReloadingX509TrustManager.java:168)\n        at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.<init>(ReloadingX509TrustManager.java:86)\n        at org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.init(FileBasedKeyStoresFactory.java:219)\n        at org.apache.hadoop.security.ssl.SSLFactory.init(SSLFactory.java:179)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineConnector.getSSLFactory(TimelineConnector.java:176)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineConnector.serviceInit(TimelineConnector.java:106)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": initing services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      service.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    timelineServiceVersion =\n        conf.getFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION,\n            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_VERSION);\n    LOG.info(\"Timeline service address: \" + getTimelineServiceAddress());\n    if (!YarnConfiguration.timelineServiceEnabled(conf)\n        || !((Float.compare(this.timelineServiceVersion, 1.0f) == 0)\n            || (Float.compare(this.timelineServiceVersion, 1.5f) == 0))) {\n      throw new IOException(\"Timeline V1 client is not properly configured. \"\n          + \"Either timeline service is not enabled or version is not set to\"\n          + \" 1.x\");\n    }\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\n    UserGroupInformation realUgi = ugi.getRealUser();\n    if (realUgi != null) {\n      authUgi = realUgi;\n      doAsUser = ugi.getShortUserName();\n    } else {\n      authUgi = ugi;\n      doAsUser = null;\n    }\n    token = new DelegationTokenAuthenticatedURL.Token();\n    connector = createTimelineConnector();\n\n    if (YarnConfiguration.useHttps(conf)) {\n      timelineServiceAddress =\n          conf.get(YarnConfiguration.TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS,\n              YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS);\n    } else {\n      timelineServiceAddress =\n          conf.get(YarnConfiguration.TIMELINE_SERVICE_WEBAPP_ADDRESS,\n              YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.createTimelineConnector": "  protected TimelineConnector createTimelineConnector() {\n    TimelineConnector newConnector =\n        new TimelineConnector(true, authUgi, doAsUser, token);\n    addIfService(newConnector);\n    return newConnector;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.getTimelineServiceAddress": "  private String getTimelineServiceAddress() {\n    return this.timelineServiceAddress;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    dispatcher =\n    new MultiThreadedDispatcher(getConfig().getInt(\n        YarnConfiguration.\n        RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE,\n        YarnConfiguration.\n        DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE));\n    dispatcher.setDrainEventsOnStop();\n    addIfService(dispatcher);\n    super.serviceInit(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher.setDrainEventsOnStop": "    public void setDrainEventsOnStop() {\n      for (AsyncDispatcher dispatcher : dispatchers) {\n        dispatcher.setDrainEventsOnStop();\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    client = TimelineClient.createTimelineClient();\n    addIfService(client);\n    super.serviceInit(conf);\n    getDispatcher().register(SystemMetricsEventType.class,\n        new TimelineV1EventHandler());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit": "    protected void serviceInit(Configuration configuration) throws Exception {\n      standByTransitionRunnable = new StandByTransitionRunnable();\n\n      activeServiceContext = new RMActiveServiceContext();\n      rmContext.setActiveServiceContext(activeServiceContext);\n\n      rmSecretManagerService = createRMSecretManagerService();\n      addService(rmSecretManagerService);\n\n      containerAllocationExpirer = new ContainerAllocationExpirer(rmDispatcher);\n      addService(containerAllocationExpirer);\n      rmContext.setContainerAllocationExpirer(containerAllocationExpirer);\n\n      AMLivelinessMonitor amLivelinessMonitor = createAMLivelinessMonitor();\n      addService(amLivelinessMonitor);\n      rmContext.setAMLivelinessMonitor(amLivelinessMonitor);\n\n      AMLivelinessMonitor amFinishingMonitor = createAMLivelinessMonitor();\n      addService(amFinishingMonitor);\n      rmContext.setAMFinishingMonitor(amFinishingMonitor);\n      \n      RMAppLifetimeMonitor rmAppLifetimeMonitor = createRMAppLifetimeMonitor();\n      addService(rmAppLifetimeMonitor);\n      rmContext.setRMAppLifetimeMonitor(rmAppLifetimeMonitor);\n\n      RMNodeLabelsManager nlm = createNodeLabelManager();\n      nlm.setRMContext(rmContext);\n      addService(nlm);\n      rmContext.setNodeLabelManager(nlm);\n\n      RMDelegatedNodeLabelsUpdater delegatedNodeLabelsUpdater =\n          createRMDelegatedNodeLabelsUpdater();\n      if (delegatedNodeLabelsUpdater != null) {\n        addService(delegatedNodeLabelsUpdater);\n        rmContext.setRMDelegatedNodeLabelsUpdater(delegatedNodeLabelsUpdater);\n      }\n\n      recoveryEnabled = conf.getBoolean(YarnConfiguration.RECOVERY_ENABLED,\n          YarnConfiguration.DEFAULT_RM_RECOVERY_ENABLED);\n\n      RMStateStore rmStore = null;\n      if (recoveryEnabled) {\n        rmStore = RMStateStoreFactory.getStore(conf);\n        boolean isWorkPreservingRecoveryEnabled =\n            conf.getBoolean(\n              YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_ENABLED,\n              YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_ENABLED);\n        rmContext\n            .setWorkPreservingRecoveryEnabled(isWorkPreservingRecoveryEnabled);\n      } else {\n        rmStore = new NullRMStateStore();\n      }\n\n      try {\n        rmStore.setResourceManager(rm);\n        rmStore.init(conf);\n        rmStore.setRMDispatcher(rmDispatcher);\n      } catch (Exception e) {\n        // the Exception from stateStore.init() needs to be handled for\n        // HA and we need to give up master status if we got fenced\n        LOG.error(\"Failed to init state store\", e);\n        throw e;\n      }\n      rmContext.setStateStore(rmStore);\n\n      if (UserGroupInformation.isSecurityEnabled()) {\n        delegationTokenRenewer = createDelegationTokenRenewer();\n        rmContext.setDelegationTokenRenewer(delegationTokenRenewer);\n      }\n\n      // Register event handler for NodesListManager\n      nodesListManager = new NodesListManager(rmContext);\n      rmDispatcher.register(NodesListManagerEventType.class, nodesListManager);\n      addService(nodesListManager);\n      rmContext.setNodesListManager(nodesListManager);\n\n      // Initialize the scheduler\n      scheduler = createScheduler();\n      scheduler.setRMContext(rmContext);\n      addIfService(scheduler);\n      rmContext.setScheduler(scheduler);\n\n      schedulerDispatcher = createSchedulerEventDispatcher();\n      addIfService(schedulerDispatcher);\n      rmDispatcher.register(SchedulerEventType.class, schedulerDispatcher);\n\n      // Register event handler for RmAppEvents\n      rmDispatcher.register(RMAppEventType.class,\n          new ApplicationEventDispatcher(rmContext));\n\n      // Register event handler for RmAppAttemptEvents\n      rmDispatcher.register(RMAppAttemptEventType.class,\n          new ApplicationAttemptEventDispatcher(rmContext));\n\n      // Register event handler for RmNodes\n      rmDispatcher.register(\n          RMNodeEventType.class, new NodeEventDispatcher(rmContext));\n\n      nmLivelinessMonitor = createNMLivelinessMonitor();\n      addService(nmLivelinessMonitor);\n\n      resourceTracker = createResourceTrackerService();\n      addService(resourceTracker);\n      rmContext.setResourceTrackerService(resourceTracker);\n\n      MetricsSystem ms = DefaultMetricsSystem.initialize(\"ResourceManager\");\n      if (fromActive) {\n        JvmMetrics.reattach(ms, jvmMetrics);\n        UserGroupInformation.reattachMetrics();\n      } else {\n        jvmMetrics = JvmMetrics.initSingleton(\"ResourceManager\", null);\n      }\n\n      JvmPauseMonitor pauseMonitor = new JvmPauseMonitor();\n      addService(pauseMonitor);\n      jvmMetrics.setPauseMonitor(pauseMonitor);\n\n      // Initialize the Reservation system\n      if (conf.getBoolean(YarnConfiguration.RM_RESERVATION_SYSTEM_ENABLE,\n          YarnConfiguration.DEFAULT_RM_RESERVATION_SYSTEM_ENABLE)) {\n        reservationSystem = createReservationSystem();\n        if (reservationSystem != null) {\n          reservationSystem.setRMContext(rmContext);\n          addIfService(reservationSystem);\n          rmContext.setReservationSystem(reservationSystem);\n          LOG.info(\"Initialized Reservation system\");\n        }\n      }\n\n      // creating monitors that handle preemption\n      createPolicyMonitors();\n\n      masterService = createApplicationMasterService();\n      addService(masterService) ;\n      rmContext.setApplicationMasterService(masterService);\n\n      applicationACLsManager = new ApplicationACLsManager(conf);\n\n      queueACLsManager = createQueueACLsManager(scheduler, conf);\n\n      rmAppManager = createRMAppManager();\n      // Register event handler for RMAppManagerEvents\n      rmDispatcher.register(RMAppManagerEventType.class, rmAppManager);\n\n      clientRM = createClientRMService();\n      addService(clientRM);\n      rmContext.setClientRMService(clientRM);\n\n      applicationMasterLauncher = createAMLauncher();\n      rmDispatcher.register(AMLauncherEventType.class,\n          applicationMasterLauncher);\n\n      addService(applicationMasterLauncher);\n      if (UserGroupInformation.isSecurityEnabled()) {\n        addService(delegationTokenRenewer);\n        delegationTokenRenewer.setRMContext(rmContext);\n      }\n\n      new RMNMInfo(rmContext, scheduler);\n\n      super.serviceInit(conf);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMApplicationHistoryWriter": "  protected RMApplicationHistoryWriter createRMApplicationHistoryWriter() {\n    return new RMApplicationHistoryWriter();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLivelinessMonitor": "  protected AMLivelinessMonitor createAMLivelinessMonitor() {\n    return new AMLivelinessMonitor(this.rmDispatcher);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices": "  protected void createAndInitActiveServices(boolean fromActive) {\n    activeServices = new RMActiveServices(this);\n    activeServices.fromActive = fromActive;\n    activeServices.init(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMAppManager": "  protected RMAppManager createRMAppManager() {\n    return new RMAppManager(this.rmContext, this.scheduler, this.masterService,\n      this.applicationACLsManager, this.conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createDelegationTokenRenewer": "  protected DelegationTokenRenewer createDelegationTokenRenewer() {\n    return new DelegationTokenRenewer();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMSecretManagerService": "  protected RMSecretManagerService createRMSecretManagerService() {\n    return new RMSecretManagerService(conf, rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNodeLabelManager": "  protected RMNodeLabelsManager createNodeLabelManager()\n      throws InstantiationException, IllegalAccessException {\n    return new RMNodeLabelsManager();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createScheduler": "  protected ResourceScheduler createScheduler() {\n    String schedulerClassName = conf.get(YarnConfiguration.RM_SCHEDULER,\n        YarnConfiguration.DEFAULT_RM_SCHEDULER);\n    LOG.info(\"Using Scheduler: \" + schedulerClassName);\n    try {\n      Class<?> schedulerClazz = Class.forName(schedulerClassName);\n      if (ResourceScheduler.class.isAssignableFrom(schedulerClazz)) {\n        return (ResourceScheduler) ReflectionUtils.newInstance(schedulerClazz,\n            this.conf);\n      } else {\n        throw new YarnRuntimeException(\"Class: \" + schedulerClassName\n            + \" not instance of \" + ResourceScheduler.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\"Could not instantiate Scheduler: \"\n          + schedulerClassName, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createEmbeddedElector": "  protected EmbeddedElector createEmbeddedElector() throws IOException {\n    EmbeddedElector elector;\n    curatorEnabled =\n        conf.getBoolean(YarnConfiguration.CURATOR_LEADER_ELECTOR,\n            YarnConfiguration.DEFAULT_CURATOR_LEADER_ELECTOR_ENABLED);\n    if (curatorEnabled) {\n      this.curator = createAndStartCurator(conf);\n      elector = new CuratorBasedElectorService(rmContext, this);\n    } else {\n      elector = new ActiveStandbyElectorBasedElectorService(rmContext);\n    }\n    return elector;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMDelegatedNodeLabelsUpdater": "  protected RMDelegatedNodeLabelsUpdater createRMDelegatedNodeLabelsUpdater() {\n    if (conf.getBoolean(YarnConfiguration.NODE_LABELS_ENABLED,\n            YarnConfiguration.DEFAULT_NODE_LABELS_ENABLED)\n        && YarnConfiguration.isDelegatedCentralizedNodeLabelConfiguration(\n            conf)) {\n      return new RMDelegatedNodeLabelsUpdater(rmContext);\n    } else {\n      return null;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createApplicationMasterService": "  protected ApplicationMasterService createApplicationMasterService() {\n    Configuration config = this.rmContext.getYarnConfiguration();\n    if (YarnConfiguration.isOpportunisticContainerAllocationEnabled(config)\n        || YarnConfiguration.isDistSchedulingEnabled(config)) {\n      if (YarnConfiguration.isDistSchedulingEnabled(config) &&\n          !YarnConfiguration\n              .isOpportunisticContainerAllocationEnabled(config)) {\n        throw new YarnRuntimeException(\n            \"Invalid parameters: opportunistic container allocation has to \" +\n                \"be enabled when distributed scheduling is enabled.\");\n      }\n      OpportunisticContainerAllocatorAMService\n          oppContainerAllocatingAMService =\n          new OpportunisticContainerAllocatorAMService(this.rmContext,\n              scheduler);\n      EventDispatcher oppContainerAllocEventDispatcher =\n          new EventDispatcher(oppContainerAllocatingAMService,\n              OpportunisticContainerAllocatorAMService.class.getName());\n      // Add an event dispatcher for the\n      // OpportunisticContainerAllocatorAMService to handle node\n      // additions, updates and removals. Since the SchedulerEvent is currently\n      // a super set of theses, we register interest for it.\n      addService(oppContainerAllocEventDispatcher);\n      rmDispatcher.register(SchedulerEventType.class,\n          oppContainerAllocEventDispatcher);\n      this.rmContext.setContainerQueueLimitCalculator(\n          oppContainerAllocatingAMService.getNodeManagerQueueLimitCalculator());\n      return oppContainerAllocatingAMService;\n    }\n    return new ApplicationMasterService(this.rmContext, scheduler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLauncher": "  protected ApplicationMasterLauncher createAMLauncher() {\n    return new ApplicationMasterLauncher(this.rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createReservationSystem": "  protected ReservationSystem createReservationSystem() {\n    String reservationClassName =\n        conf.get(YarnConfiguration.RM_RESERVATION_SYSTEM_CLASS,\n            AbstractReservationSystem.getDefaultReservationSystem(scheduler));\n    if (reservationClassName == null) {\n      return null;\n    }\n    LOG.info(\"Using ReservationSystem: \" + reservationClassName);\n    try {\n      Class<?> reservationClazz = Class.forName(reservationClassName);\n      if (ReservationSystem.class.isAssignableFrom(reservationClazz)) {\n        return (ReservationSystem) ReflectionUtils.newInstance(\n            reservationClazz, this.conf);\n      } else {\n        throw new YarnRuntimeException(\"Class: \" + reservationClassName\n            + \" not instance of \" + ReservationSystem.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\n          \"Could not instantiate ReservationSystem: \" + reservationClassName, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMTimelineCollectorManager": "  private RMTimelineCollectorManager createRMTimelineCollectorManager() {\n    return new RMTimelineCollectorManager(rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createPolicyMonitors": "    protected void createPolicyMonitors() {\n      if (scheduler instanceof PreemptableResourceScheduler\n          && conf.getBoolean(YarnConfiguration.RM_SCHEDULER_ENABLE_MONITORS,\n          YarnConfiguration.DEFAULT_RM_SCHEDULER_ENABLE_MONITORS)) {\n        LOG.info(\"Loading policy monitors\");\n        List<SchedulingEditPolicy> policies = conf.getInstances(\n            YarnConfiguration.RM_SCHEDULER_MONITOR_POLICIES,\n            SchedulingEditPolicy.class);\n        if (policies.size() > 0) {\n          for (SchedulingEditPolicy policy : policies) {\n            LOG.info(\"LOADING SchedulingEditPolicy:\" + policy.getPolicyName());\n            // periodically check whether we need to take action to guarantee\n            // constraints\n            SchedulingMonitor mon = new SchedulingMonitor(rmContext, policy);\n            addService(mon);\n          }\n        } else {\n          LOG.warn(\"Policy monitors configured (\" +\n              YarnConfiguration.RM_SCHEDULER_ENABLE_MONITORS +\n              \") but none specified (\" +\n              YarnConfiguration.RM_SCHEDULER_MONITOR_POLICIES + \")\");\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAdminService": "  protected AdminService createAdminService() {\n    return new AdminService(this, rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createClientRMService": "  protected ClientRMService createClientRMService() {\n    return new ClientRMService(this.rmContext, scheduler, this.rmAppManager,\n        this.applicationACLsManager, this.queueACLsManager,\n        this.rmContext.getRMDelegationTokenSecretManager());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setupDispatcher": "  private Dispatcher setupDispatcher() {\n    Dispatcher dispatcher = createDispatcher();\n    dispatcher.register(RMFatalEventType.class,\n        new ResourceManager.RMFatalEventDispatcher());\n    return dispatcher;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNMLivelinessMonitor": "  private NMLivelinessMonitor createNMLivelinessMonitor() {\n    return new NMLivelinessMonitor(this.rmContext\n        .getDispatcher());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createSystemMetricsPublisher": "  protected SystemMetricsPublisher createSystemMetricsPublisher() {\n    SystemMetricsPublisher publisher;\n    if (YarnConfiguration.timelineServiceEnabled(conf) &&\n        YarnConfiguration.systemMetricsPublisherEnabled(conf)) {\n      if (YarnConfiguration.timelineServiceV2Enabled(conf)) {\n        // we're dealing with the v.2.x publisher\n        LOG.info(\"system metrics publisher with the timeline service V2 is \" +\n            \"configured\");\n        publisher = new TimelineServiceV2Publisher(rmContext);\n      } else {\n        // we're dealing with the v.1.x publisher\n        LOG.info(\"system metrics publisher with the timeline service V1 is \" +\n            \"configured\");\n        publisher = new TimelineServiceV1Publisher();\n      }\n    } else {\n      LOG.info(\"TimelineServicePublisher is not configured\");\n      publisher = new NoOpSystemMetricPublisher();\n    }\n    return publisher;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createSchedulerEventDispatcher": "  protected EventHandler<SchedulerEvent> createSchedulerEventDispatcher() {\n    return new EventDispatcher(this.scheduler, \"SchedulerEventDispatcher\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.doSecureLogin": "  protected void doSecureLogin() throws IOException {\n\tInetSocketAddress socAddr = getBindAddress(conf);\n    SecurityUtil.login(this.conf, YarnConfiguration.RM_KEYTAB,\n        YarnConfiguration.RM_PRINCIPAL, socAddr.getHostName());\n\n    // if security is enable, set rmLoginUGI as UGI of loginUser\n    if (UserGroupInformation.isSecurityEnabled()) {\n      this.rmLoginUGI = UserGroupInformation.getLoginUser();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMAppLifetimeMonitor": "  protected RMAppLifetimeMonitor createRMAppLifetimeMonitor() {\n    return new RMAppLifetimeMonitor(this.rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createQueueACLsManager": "  protected QueueACLsManager createQueueACLsManager(ResourceScheduler scheduler,\n      Configuration conf) {\n    return new QueueACLsManager(scheduler, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createResourceTrackerService": "  protected ResourceTrackerService createResourceTrackerService() {\n    return new ResourceTrackerService(this.rmContext, this.nodesListManager,\n        this.nmLivelinessMonitor,\n        this.rmContext.getContainerTokenSecretManager(),\n        this.rmContext.getNMTokenSecretManager());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.validateConfigs": "  protected static void validateConfigs(Configuration conf) {\n    // validate max-attempts\n    int globalMaxAppAttempts =\n        conf.getInt(YarnConfiguration.RM_AM_MAX_ATTEMPTS,\n        YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS);\n    if (globalMaxAppAttempts <= 0) {\n      throw new YarnRuntimeException(\"Invalid global max attempts configuration\"\n          + \", \" + YarnConfiguration.RM_AM_MAX_ATTEMPTS\n          + \"=\" + globalMaxAppAttempts + \", it should be a positive integer.\");\n    }\n\n    // validate expireIntvl >= heartbeatIntvl\n    long expireIntvl = conf.getLong(YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_RM_NM_EXPIRY_INTERVAL_MS);\n    long heartbeatIntvl =\n        conf.getLong(YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS,\n            YarnConfiguration.DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS);\n    if (expireIntvl < heartbeatIntvl) {\n      throw new YarnRuntimeException(\"Nodemanager expiry interval should be no\"\n          + \" less than heartbeat interval, \"\n          + YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS + \"=\" + expireIntvl\n          + \", \" + YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS + \"=\"\n          + heartbeatIntvl);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main": "  public static void main(String argv[]) {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ResourceManager.class, argv, LOG);\n    try {\n      Configuration conf = new YarnConfiguration();\n      GenericOptionsParser hParser = new GenericOptionsParser(conf, argv);\n      argv = hParser.getRemainingArgs();\n      // If -format-state-store, then delete RMStateStore; else startup normally\n      if (argv.length >= 1) {\n        if (argv[0].equals(\"-format-state-store\")) {\n          deleteRMStateStore(conf);\n        } else if (argv[0].equals(\"-remove-application-from-state-store\")\n            && argv.length == 2) {\n          removeApplication(conf, argv[1]);\n        } else {\n          printUsage(System.err);\n        }\n      } else {\n        ResourceManager resourceManager = new ResourceManager();\n        ShutdownHookManager.get().addShutdownHook(\n          new CompositeServiceShutdownHook(resourceManager),\n          SHUTDOWN_HOOK_PRIORITY);\n        resourceManager.init(conf);\n        resourceManager.start();\n      }\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ResourceManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.removeApplication": "  static void removeApplication(Configuration conf, String applicationId)\n      throws Exception {\n    RMStateStore rmStore = RMStateStoreFactory.getStore(conf);\n    rmStore.setResourceManager(new ResourceManager());\n    rmStore.init(conf);\n    rmStore.start();\n    try {\n      ApplicationId removeAppId = ApplicationId.fromString(applicationId);\n      LOG.info(\"Deleting application \" + removeAppId + \" from state store\");\n      rmStore.removeApplication(removeAppId);\n      LOG.info(\"Application is deleted from state store\");\n    } finally {\n      rmStore.stop();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.printUsage": "  private static void printUsage(PrintStream out) {\n    out.println(\"Usage: yarn resourcemanager [-format-state-store]\");\n    out.println(\"                            \"\n        + \"[-remove-application-from-state-store <appId>]\" + \"\\n\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.deleteRMStateStore": "  static void deleteRMStateStore(Configuration conf) throws Exception {\n    RMStateStore rmStore = RMStateStoreFactory.getStore(conf);\n    rmStore.setResourceManager(new ResourceManager());\n    rmStore.init(conf);\n    rmStore.start();\n    try {\n      LOG.info(\"Deleting ResourceManager state store...\");\n      rmStore.deleteStore();\n      LOG.info(\"State store deleted\");\n    } finally {\n      rmStore.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.ReloadingX509TrustManager.loadTrustManager": "  X509TrustManager loadTrustManager()\n  throws IOException, GeneralSecurityException {\n    X509TrustManager trustManager = null;\n    KeyStore ks = KeyStore.getInstance(type);\n    FileInputStream in = new FileInputStream(file);\n    try {\n      ks.load(in, (password == null) ? null : password.toCharArray());\n      lastLoaded = file.lastModified();\n      LOG.debug(\"Loaded truststore '\" + file + \"'\");\n    } finally {\n      in.close();\n    }\n\n    TrustManagerFactory trustManagerFactory = \n      TrustManagerFactory.getInstance(SSLFactory.SSLCERTIFICATE);\n    trustManagerFactory.init(ks);\n    TrustManager[] trustManagers = trustManagerFactory.getTrustManagers();\n    for (TrustManager trustManager1 : trustManagers) {\n      if (trustManager1 instanceof X509TrustManager) {\n        trustManager = (X509TrustManager) trustManager1;\n        break;\n      }\n    }\n    return trustManager;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.ReloadingX509TrustManager.init": "  public void init() {\n    reloader = new Thread(this, \"Truststore reloader thread\");\n    reloader.setDaemon(true);\n    running =  true;\n    reloader.start();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.init": "  public void init(SSLFactory.Mode mode)\n    throws IOException, GeneralSecurityException {\n\n    boolean requireClientCert =\n      conf.getBoolean(SSLFactory.SSL_REQUIRE_CLIENT_CERT_KEY,\n          SSLFactory.SSL_REQUIRE_CLIENT_CERT_DEFAULT);\n\n    // certificate store\n    String keystoreType =\n      conf.get(resolvePropertyName(mode, SSL_KEYSTORE_TYPE_TPL_KEY),\n               DEFAULT_KEYSTORE_TYPE);\n    KeyStore keystore = KeyStore.getInstance(keystoreType);\n    String keystoreKeyPassword = null;\n    if (requireClientCert || mode == SSLFactory.Mode.SERVER) {\n      String locationProperty =\n        resolvePropertyName(mode, SSL_KEYSTORE_LOCATION_TPL_KEY);\n      String keystoreLocation = conf.get(locationProperty, \"\");\n      if (keystoreLocation.isEmpty()) {\n        throw new GeneralSecurityException(\"The property '\" + locationProperty +\n          \"' has not been set in the ssl configuration file.\");\n      }\n      String passwordProperty =\n        resolvePropertyName(mode, SSL_KEYSTORE_PASSWORD_TPL_KEY);\n      String keystorePassword = getPassword(conf, passwordProperty, \"\");\n      if (keystorePassword.isEmpty()) {\n        throw new GeneralSecurityException(\"The property '\" + passwordProperty +\n          \"' has not been set in the ssl configuration file.\");\n      }\n      String keyPasswordProperty =\n        resolvePropertyName(mode, SSL_KEYSTORE_KEYPASSWORD_TPL_KEY);\n      // Key password defaults to the same value as store password for\n      // compatibility with legacy configurations that did not use a separate\n      // configuration property for key password.\n      keystoreKeyPassword = getPassword(\n          conf, keyPasswordProperty, keystorePassword);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(mode.toString() + \" KeyStore: \" + keystoreLocation);\n      }\n\n      InputStream is = new FileInputStream(keystoreLocation);\n      try {\n        keystore.load(is, keystorePassword.toCharArray());\n      } finally {\n        is.close();\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(mode.toString() + \" Loaded KeyStore: \" + keystoreLocation);\n      }\n    } else {\n      keystore.load(null, null);\n    }\n    KeyManagerFactory keyMgrFactory = KeyManagerFactory\n        .getInstance(SSLFactory.SSLCERTIFICATE);\n      \n    keyMgrFactory.init(keystore, (keystoreKeyPassword != null) ?\n                                 keystoreKeyPassword.toCharArray() : null);\n    keyManagers = keyMgrFactory.getKeyManagers();\n\n    //trust store\n    String truststoreType =\n      conf.get(resolvePropertyName(mode, SSL_TRUSTSTORE_TYPE_TPL_KEY),\n               DEFAULT_KEYSTORE_TYPE);\n\n    String locationProperty =\n      resolvePropertyName(mode, SSL_TRUSTSTORE_LOCATION_TPL_KEY);\n    String truststoreLocation = conf.get(locationProperty, \"\");\n    if (!truststoreLocation.isEmpty()) {\n      String passwordProperty = resolvePropertyName(mode,\n          SSL_TRUSTSTORE_PASSWORD_TPL_KEY);\n      String truststorePassword = getPassword(conf, passwordProperty, \"\");\n      if (truststorePassword.isEmpty()) {\n        // An empty trust store password is legal; the trust store password\n        // is only required when writing to a trust store. Otherwise it's\n        // an optional integrity check.\n        truststorePassword = null;\n      }\n      long truststoreReloadInterval =\n          conf.getLong(\n              resolvePropertyName(mode, SSL_TRUSTSTORE_RELOAD_INTERVAL_TPL_KEY),\n              DEFAULT_SSL_TRUSTSTORE_RELOAD_INTERVAL);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(mode.toString() + \" TrustStore: \" + truststoreLocation);\n      }\n\n      trustManager = new ReloadingX509TrustManager(truststoreType,\n          truststoreLocation,\n          truststorePassword,\n          truststoreReloadInterval);\n      trustManager.init();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(mode.toString() + \" Loaded TrustStore: \" + truststoreLocation);\n      }\n      trustManagers = new TrustManager[]{trustManager};\n    } else {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The property '\" + locationProperty + \"' has not been set, \" +\n            \"no TrustStore will be loaded\");\n      }\n      trustManagers = null;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.getKeyManagers": "  public KeyManager[] getKeyManagers() {\n    return keyManagers;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.getPassword": "  String getPassword(Configuration conf, String alias, String defaultPass) {\n    String password = defaultPass;\n    try {\n      char[] passchars = conf.getPassword(alias);\n      if (passchars != null) {\n        password = new String(passchars);\n      }\n    }\n    catch (IOException ioe) {\n      LOG.warn(\"Exception while trying to get password for alias \" + alias +\n          \": \" + ioe.getMessage());\n    }\n    return password;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.resolvePropertyName": "  public static String resolvePropertyName(SSLFactory.Mode mode,\n                                           String template) {\n    return MessageFormat.format(\n        template, StringUtils.toLowerCase(mode.toString()));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.SSLFactory.init": "  public void init() throws GeneralSecurityException, IOException {\n    keystoresFactory.init(mode);\n    context = SSLContext.getInstance(\"TLS\");\n    context.init(keystoresFactory.getKeyManagers(),\n                 keystoresFactory.getTrustManagers(), null);\n    context.getDefaultSSLParameters().setProtocols(enabledProtocols);\n    hostnameVerifier = getHostnameVerifier(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.SSLFactory.getHostnameVerifier": "  public HostnameVerifier getHostnameVerifier() {\n    if (mode != Mode.CLIENT) {\n      throw new IllegalStateException(\n          \"Factory is not in CLIENT mode. Actual mode is \" + mode.toString());\n    }\n    return hostnameVerifier;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineConnector.getSSLFactory": "  protected SSLFactory getSSLFactory(Configuration conf)\n      throws GeneralSecurityException, IOException {\n    SSLFactory newSSLFactory = new SSLFactory(SSLFactory.Mode.CLIENT, conf);\n    newSSLFactory.init();\n    return newSSLFactory;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineConnector.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    super.serviceInit(conf);\n    ClientConfig cc = new DefaultClientConfig();\n    cc.getClasses().add(YarnJacksonJaxbJsonProvider.class);\n\n    sslFactory = getSSLFactory(conf);\n    connConfigurator = getConnConfigurator(sslFactory);\n\n    if (UserGroupInformation.isSecurityEnabled()) {\n      authenticator = new KerberosDelegationTokenAuthenticator();\n    } else {\n      authenticator = new PseudoDelegationTokenAuthenticator();\n    }\n    authenticator.setConnectionConfigurator(connConfigurator);\n\n    connectionRetry = new TimelineClientConnectionRetry(conf);\n    client =\n        new Client(\n            new URLConnectionClientHandler(new TimelineURLConnectionFactory(\n                authUgi, authenticator, connConfigurator, token, doAsUser)),\n            cc);\n    if (requireConnectionRetry) {\n      TimelineJerseyRetryFilter retryFilter =\n          new TimelineJerseyRetryFilter(connectionRetry);\n      client.addFilter(retryFilter);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineConnector.getConnConfigurator": "  private ConnectionConfigurator getConnConfigurator(SSLFactory sslFactoryObj) {\n    try {\n      return initSslConnConfigurator(DEFAULT_SOCKET_TIMEOUT, sslFactoryObj);\n    } catch (Exception e) {\n      LOG.debug(\"Cannot load customized ssl related configuration. \"\n          + \"Fallback to system-generic settings.\", e);\n      return DEFAULT_TIMEOUT_CONN_CONFIGURATOR;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.init": "  void init(Configuration config);\n\n\n  /**\n   * Start the service.\n   *\n   * The transition MUST be from {@link STATE#INITED} to {@link STATE#STARTED}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setNodeLabelManager": "  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setSystemMetricsPublisher": "  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setLeaderElectorService": "  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMTimelineCollectorManager": "  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMAppLifetimeMonitor": "  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.processRMProxyUsersConf": "  public static void processRMProxyUsersConf(Configuration conf) {\n    Map<String, String> rmProxyUsers = new HashMap<String, String>();\n    for (Map.Entry<String, String> entry : conf) {\n      String propName = entry.getKey();\n      if (propName.startsWith(YarnConfiguration.RM_PROXY_USER_PREFIX)) {\n        rmProxyUsers.put(ProxyUsers.CONF_HADOOP_PROXYUSER + \".\" +\n                propName.substring(YarnConfiguration.RM_PROXY_USER_PREFIX\n                    .length()),\n            entry.getValue());\n      }\n    }\n    for (Map.Entry<String, String> entry : rmProxyUsers.entrySet()) {\n      conf.set(entry.getKey(), entry.getValue());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setClientRMService": "  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMDelegatedNodeLabelsUpdater": "  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMApplicationHistoryWriter": "  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.keystoresFactory.getKeyManagers": "  public KeyManager[] getKeyManagers();\n\n  /**\n   * Returns the trustmanagers for trusted certificates.\n   *\n   * @return the trustmanagers for trusted certificates.\n   */\n  public TrustManager[] getTrustManagers();\n\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.ssl.keystoresFactory.getTrustManagers": "  public TrustManager[] getTrustManagers();\n\n}"
        },
        "bug_report": {
            "Title": "ResourceManager failed due to TimelineClient try to init SSLFactory even https is not enabled",
            "Description": "In a non-secured cluster, RM get failed consistently due to TimelineServiceV1Publisher tries to init TimelineClient with SSLFactory without any checking on if https get used.\n\n{noformat}\n2017-04-26 21:09:10,683 FATAL resourcemanager.ResourceManager (ResourceManager.java:main(1457)) - Error starting ResourceManager\norg.apache.hadoop.service.ServiceStateException: java.io.FileNotFoundException: /etc/security/clientKeys/all.jks (No such file or directory)\n        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:172)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit(TimelineClientImpl.java:131)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher.serviceInit(AbstractSystemMetricsPublisher.java:59)\n        at org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.serviceInit(TimelineServiceV1Publisher.java:67)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:344)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1453)\nCaused by: java.io.FileNotFoundException: /etc/security/clientKeys/all.jks (No such file or directory)\n        at java.io.FileInputStream.open0(Native Method)\n        at java.io.FileInputStream.open(FileInputStream.java:195)\n        at java.io.FileInputStream.<init>(FileInputStream.java:138)\n        at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.loadTrustManager(ReloadingX509TrustManager.java:168)\n        at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.<init>(ReloadingX509TrustManager.java:86)\n        at org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.init(FileBasedKeyStoresFactory.java:219)\n        at org.apache.hadoop.security.ssl.SSLFactory.init(SSLFactory.java:179)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineConnector.getSSLFactory(TimelineConnector.java:176)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineConnector.serviceInit(TimelineConnector.java:106)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        ... 11 more\n{noformat}\nCC [~rohithsharma] and [~gtCarrera9]"
        }
    },
    {
        "filename": "YARN-4227.json",
        "creation_time": "2015-10-06T04:59:10.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer(FairScheduler.java:849)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1273)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:122)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:585)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer": "  protected synchronized void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n    if (rmContainer == null) {\n      LOG.info(\"Container \" + containerStatus.getContainerId()\n          + \" completed with event \" + event);\n      return;\n    }\n\n    Container container = rmContainer.getContainer();\n\n    // Get the application for the finished container\n    FSAppAttempt application =\n        getCurrentAttemptForContainer(container.getId());\n    ApplicationId appId =\n        container.getId().getApplicationAttemptId().getApplicationId();\n    if (application == null) {\n      LOG.info(\"Container \" + container + \" of\" +\n          \" finished application \" + appId +\n          \" completed with event \" + event);\n      return;\n    }\n\n    // Get the node on which the container was allocated\n    FSSchedulerNode node = getFSSchedulerNode(container.getNodeId());\n\n    if (rmContainer.getState() == RMContainerState.RESERVED) {\n      application.unreserve(rmContainer.getReservedPriority(), node);\n    } else {\n      application.containerCompleted(rmContainer, containerStatus, event);\n      node.releaseContainer(container);\n      updateRootQueueMetrics();\n    }\n\n    LOG.info(\"Application attempt \" + application.getApplicationAttemptId()\n        + \" released container \" + container.getId() + \" on node: \" + node\n        + \" with event: \" + event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateRootQueueMetrics": "  private void updateRootQueueMetrics() {\n    rootMetrics.setAvailableResourcesToQueue(\n        Resources.subtract(\n            clusterResource, rootMetrics.getAllocatedResources()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getFSSchedulerNode": "  private FSSchedulerNode getFSSchedulerNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getContainerReports(),\n          nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName, appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n      break;\n    case NODE_RESOURCE_UPDATE:\n      if (!(event instanceof NodeResourceUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeResource(nodeResourceUpdatedEvent.getRMNode(),\n            nodeResourceUpdatedEvent.getResourceOption());\n      break;\n    case APP_ATTEMPT_ADDED:\n      if (!(event instanceof AppAttemptAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n      break;\n    case APP_ATTEMPT_REMOVED:\n      if (!(event instanceof AppAttemptRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      removeApplicationAttempt(\n          appAttemptRemovedEvent.getApplicationAttemptID(),\n          appAttemptRemovedEvent.getFinalAttemptState(),\n          appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    case CONTAINER_RESCHEDULED:\n      if (!(event instanceof ContainerRescheduledEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerRescheduledEvent containerRescheduledEvent =\n          (ContainerRescheduledEvent) event;\n      RMContainer container = containerRescheduledEvent.getContainer();\n      recoverResourceRequestForContainer(container);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addNode": "  private synchronized void addNode(List<NMContainerStatus> containerReports,\n      RMNode node) {\n    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, usePortForNodeName);\n    nodes.put(node.getNodeID(), schedulerNode);\n    Resources.addTo(clusterResource, node.getTotalCapability());\n    updateMaximumAllocation(schedulerNode, true);\n\n    triggerUpdate();\n\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n    LOG.info(\"Added node \" + node.getNodeAddress() +\n        \" cluster capacity: \" + clusterResource);\n\n    recoverContainersOnNode(containerReports, node);\n    updateRootQueueMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected synchronized void addApplication(ApplicationId applicationId,\n      String queueName, String user, boolean isAppRecovering) {\n    if (queueName == null || queueName.isEmpty()) {\n      String message = \"Reject application \" + applicationId +\n              \" submitted by user \" + user + \" with an empty queue name.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n\n    if (queueName.startsWith(\".\") || queueName.endsWith(\".\")) {\n      String message = \"Reject application \" + applicationId\n          + \" submitted by user \" + user + \" with an illegal queue name \"\n          + queueName + \". \"\n          + \"The queue name cannot start/end with period.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n\n    RMApp rmApp = rmContext.getRMApps().get(applicationId);\n    FSLeafQueue queue = assignToQueue(rmApp, queueName, user);\n    if (queue == null) {\n      return;\n    }\n\n    // Enforce ACLs\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n\n    if (!queue.hasAccess(QueueACL.SUBMIT_APPLICATIONS, userUgi)\n        && !queue.hasAccess(QueueACL.ADMINISTER_QUEUE, userUgi)) {\n      String msg = \"User \" + userUgi.getUserName() +\n              \" cannot submit applications to queue \" + queue.getName();\n      LOG.info(msg);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, msg));\n      return;\n    }\n  \n    SchedulerApplication<FSAppAttempt> application =\n        new SchedulerApplication<FSAppAttempt>(queue, user);\n    applications.put(applicationId, application);\n    queue.getMetrics().submitApp(user);\n\n    LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n        + \", in queue: \" + queueName + \", currently num of applications: \"\n        + applications.size());\n    if (isAppRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler()\n        .handle(new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt": "  private synchronized void removeApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    LOG.info(\"Application \" + applicationAttemptId + \" is done.\" +\n        \" finalState=\" + rmAppAttemptFinalState);\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    FSAppAttempt attempt = getSchedulerApp(applicationAttemptId);\n\n    if (attempt == null || application == null) {\n      LOG.info(\"Unknown application \" + applicationAttemptId + \" has completed!\");\n      return;\n    }\n\n    // Release all the running containers\n    for (RMContainer rmContainer : attempt.getLiveContainers()) {\n      if (keepContainers\n          && rmContainer.getState().equals(RMContainerState.RUNNING)) {\n        // do not kill the running container in the case of work-preserving AM\n        // restart.\n        LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n        continue;\n      }\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              SchedulerUtils.COMPLETED_APPLICATION),\n              RMContainerEventType.KILL);\n    }\n\n    // Release all reserved containers\n    for (RMContainer rmContainer : attempt.getReservedContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              \"Application Complete\"),\n              RMContainerEventType.KILL);\n    }\n    // Clean up pending requests, metrics etc.\n    attempt.stop(rmAppAttemptFinalState);\n\n    // Inform the queue\n    FSLeafQueue queue = queueMgr.getLeafQueue(attempt.getQueue()\n        .getQueueName(), false);\n    boolean wasRunnable = queue.removeApp(attempt);\n\n    if (wasRunnable) {\n      maxRunningEnforcer.untrackRunnableApp(attempt);\n      maxRunningEnforcer.updateRunnabilityOnAppRemoval(attempt,\n          attempt.getQueue());\n    } else {\n      maxRunningEnforcer.untrackNonRunnableApp(attempt);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start = getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node = getFSSchedulerNode(nm.getNodeID());\n    \n    List<UpdatedContainerInfo> containerInfoList = nm.pullContainerUpdates();\n    List<ContainerStatus> newlyLaunchedContainers = new ArrayList<ContainerStatus>();\n    List<ContainerStatus> completedContainers = new ArrayList<ContainerStatus>();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    long duration = getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication": "  private synchronized void removeApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationId);\n    if (application == null){\n      LOG.warn(\"Couldn't find application \" + applicationId);\n      return;\n    }\n    application.stop(finalState);\n    applications.remove(applicationId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.resolveReservationQueueName": "  private synchronized String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID) {\n    FSQueue queue = queueMgr.getQueue(queueName);\n    if ((queue == null) || !allocConf.isReservable(queue.getQueueName())) {\n      return queueName;\n    }\n    // Use fully specified name from now on (including root. prefix)\n    queueName = queue.getQueueName();\n    if (reservationID != null) {\n      String resQName = queueName + \".\" + reservationID.toString();\n      queue = queueMgr.getQueue(resQName);\n      if (queue == null) {\n        String message =\n            \"Application \"\n                + applicationId\n                + \" submitted to a reservation which is not yet currently active: \"\n                + resQName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, message));\n        return null;\n      }\n      if (!queue.getParent().getQueueName().equals(queueName)) {\n        String message =\n            \"Application: \" + applicationId + \" submitted to a reservation \"\n                + resQName + \" which does not belong to the specified queue: \"\n                + queueName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, message));\n        return null;\n      }\n      // use the reservation queue to run the app\n      queueName = resQName;\n    } else {\n      // use the default child queue of the plan for unreserved apps\n      queueName = getDefaultQueueForPlanQueue(queueName);\n    }\n    return queueName;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateNodeResource": "  public synchronized void updateNodeResource(RMNode nm, \n      ResourceOption resourceOption) {\n    super.updateNodeResource(nm, resourceOption);\n    updateRootQueueMetrics();\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplicationAttempt": "  protected synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    String user = application.getUser();\n    FSLeafQueue queue = (FSLeafQueue) application.getQueue();\n\n    FSAppAttempt attempt =\n        new FSAppAttempt(this, applicationAttemptId, user,\n            queue, new ActiveUsersManager(getRootQueueMetrics()),\n            rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n          .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    boolean runnable = maxRunningEnforcer.canAppBeRunnable(queue, user);\n    queue.addApp(attempt, runnable);\n    if (runnable) {\n      maxRunningEnforcer.trackRunnableApp(attempt);\n    } else {\n      maxRunningEnforcer.trackNonRunnableApp(attempt);\n    }\n    \n    queue.getMetrics().submitAppAttempt(user);\n\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user: \" + user);\n\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeNode": "  private synchronized void removeNode(RMNode rmNode) {\n    FSSchedulerNode node = getFSSchedulerNode(rmNode.getNodeID());\n    // This can occur when an UNHEALTHY node reconnects\n    if (node == null) {\n      return;\n    }\n    Resources.subtractFrom(clusterResource, rmNode.getTotalCapability());\n    updateRootQueueMetrics();\n\n    triggerUpdate();\n\n    // Remove running containers\n    List<RMContainer> runningContainers = node.getRunningContainers();\n    for (RMContainer container : runningContainers) {\n      completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    // Remove reservations, if any\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      completedContainer(reservedContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              reservedContainer.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    nodes.remove(rmNode.getNodeID());\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n    updateMaximumAllocation(node, false);\n    LOG.info(\"Removed node \" + rmNode.getNodeAddress() +\n        \" cluster capacity: \" + clusterResource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) throws Exception {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }"
        },
        "bug_report": {
            "Title": "Ignore expired containers from removed nodes in FairScheduler",
            "Description": "Under some circumstances the node is removed before an expired container event is processed causing the RM to exit:\n{code}\n2015-10-04 21:14:01,063 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: Expired:container_1436927988321_1307950_01_000012 Timed out after 600 secs\n2015-10-04 21:14:01,063 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1436927988321_1307950_01_000012 Container Transitioned from ACQUIRED to EXPIRED\n2015-10-04 21:14:01,063 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp: Completed container: container_1436927988321_1307950_01_000012 in state: EXPIRED event:EXPIRE\n2015-10-04 21:14:01,063 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=system_op\tOPERATION=AM Released Container\tTARGET=SchedulerApp\tRESULT=SUCCESS\tAPPID=application_1436927988321_1307950\tCONTAINERID=container_1436927988321_1307950_01_000012\n2015-10-04 21:14:01,063 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type CONTAINER_EXPIRED to the scheduler\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer(FairScheduler.java:849)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1273)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:122)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:585)\n\tat java.lang.Thread.run(Thread.java:745)\n2015-10-04 21:14:01,063 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Exiting, bbye..\n{code}\nThe stack trace is from 2.3.0 but the same issue has been observed in 2.5.0 and 2.6.0 by different customers."
        }
    },
    {
        "filename": "YARN-2649.json",
        "creation_time": "2014-10-06T22:57:46.000+0000",
        "stack_trace": "```\njunit.framework.AssertionFailedError: AppAttempt state is not correct (timedout) expected:<ALLOCATED> but was:<SCHEDULED>\n\tat junit.framework.Assert.fail(Assert.java:50)\n\tat junit.framework.Assert.failNotEquals(Assert.java:287)\n\tat junit.framework.Assert.assertEquals(Assert.java:67)\n\tat org.apache.hadoop.yarn.server.resourcemanager.MockAM.waitForState(MockAM.java:82)\n\tat org.apache.hadoop.yarn.server.resourcemanager.MockRM.sendAMLaunched(MockRM.java:382)\n\tat org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates.testAMRMUnusableNodes(TestAMRMRPCNodeUpdates.java:125)\n\nattempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(670)) - appattempt_1412569506932_0001_000001 State change from NEW to SUBMITTED\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.EventType: STATUS_UPDATE\nrmnode.RMNodeImpl (RMNodeImpl.java:handle(384)) - Processing 127.0.0.1:1234 of type STATUS_UPDATE\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptAddedSchedulerEvent.EventType: APP_ATTEMPT_ADDED\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeUpdateSchedulerEvent.EventType: NODE_UPDATE\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEvent.EventType: ATTEMPT_ADDED\nattempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(658)) - Processing event for appattempt_1412569506932_0001_000001 of type ATTEMPT_ADDED\nattempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(670)) - appattempt_1412569506932_0001_000001 State change from SUBMITTED to SCHEDULED\n```",
        "source_code": {},
        "bug_report": {
            "Title": "Flaky test TestAMRMRPCNodeUpdates",
            "Description": "Sometimes the test fails with the following error:\n\ntestAMRMUnusableNodes(org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates)  Time elapsed: 41.73 sec  <<< FAILURE!\njunit.framework.AssertionFailedError: AppAttempt state is not correct (timedout) expected:<ALLOCATED> but was:<SCHEDULED>\n\tat junit.framework.Assert.fail(Assert.java:50)\n\tat junit.framework.Assert.failNotEquals(Assert.java:287)\n\tat junit.framework.Assert.assertEquals(Assert.java:67)\n\tat org.apache.hadoop.yarn.server.resourcemanager.MockAM.waitForState(MockAM.java:82)\n\tat org.apache.hadoop.yarn.server.resourcemanager.MockRM.sendAMLaunched(MockRM.java:382)\n\tat org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates.testAMRMUnusableNodes(TestAMRMRPCNodeUpdates.java:125)\n\n\n\nWhen this happens, SchedulerEventType.NODE_UPDATE was processed before RMAppAttemptEvent.ATTEMPT_ADDED was processed. That is possible, given the test only waits for RMAppState.ACCEPTED before having NM sending heartbeat. This can be reproduced using custom AsyncDispatcher with CountDownLatch. Here is the log when this happens.\n\n{noformat}\nApp State is : ACCEPTED\n2014-10-05 21:25:07,305 INFO  [AsyncDispatcher event handler] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(670)) - appattempt_1412569506932_0001_000001 State change from NEW to SUBMITTED\n2014-10-05 21:25:07,305 DEBUG [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.EventType: STATUS_UPDATE\n2014-10-05 21:25:07,305 DEBUG [AsyncDispatcher event handler] rmnode.RMNodeImpl (RMNodeImpl.java:handle(384)) - Processing 127.0.0.1:1234 of type STATUS_UPDATE\nAppAttempt : appattempt_1412569506932_0001_000001 State is : SUBMITTED Waiting for state : ALLOCATED\n2014-10-05 21:25:07,306 DEBUG [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptAddedSchedulerEvent.EventType: APP_ATTEMPT_ADDED\n\n2014-10-05 21:25:07,328 DEBUG [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeUpdateSchedulerEvent.EventType: NODE_UPDATE\n\n2014-10-05 21:25:07,330 DEBUG [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEvent.EventType: ATTEMPT_ADDED\n2014-10-05 21:25:07,331 DEBUG [AsyncDispatcher event handler] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(658)) - Processing event for appattempt_1412569506932_0001_000\n001 of type ATTEMPT_ADDED\n\n2014-10-05 21:25:07,333 INFO  [AsyncDispatcher event handler] attempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(670)) - appattempt_1412569506932_0001_000001 State change from SUBMITTED to SCHEDULED\n\n{noformat}\n\n\n"
        }
    },
    {
        "filename": "YARN-4288.json",
        "creation_time": "2015-10-22T12:30:16.000+0000",
        "stack_trace": "```\njava.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1473)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1400)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy36.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy37.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:257)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:215)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager$2.run(NodeManager.java:304)\nCaused by: java.io.IOException: Connection reset by peer\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:197)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:514)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:254)\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)\n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:223)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager$2.run(NodeManager.java:304)\nCaused by: java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"ebdp-ch2-172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1473)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1400)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy36.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy37.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:257)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:215)\n        ... 1 more\nCaused by: java.io.IOException: Connection reset by peer\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:197)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:514)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:254)\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.wrapException": "  public static IOException wrapException(final String destHost,\n                                          final int destPort,\n                                          final String localHost,\n                                          final int localPort,\n                                          final IOException exception) {\n    if (exception instanceof BindException) {\n      return wrapWithMessage(exception,\n          \"Problem binding to [\"\n              + localHost\n              + \":\"\n              + localPort\n              + \"] \"\n              + exception\n              + \";\"\n              + see(\"BindException\"));\n    } else if (exception instanceof ConnectException) {\n      // connection refused; include the host:port in the error\n      return wrapWithMessage(exception, \n          \"Call From \"\n              + localHost\n              + \" to \"\n              + destHost\n              + \":\"\n              + destPort\n              + \" failed on connection exception: \"\n              + exception\n              + \";\"\n              + see(\"ConnectionRefused\"));\n    } else if (exception instanceof UnknownHostException) {\n      return wrapWithMessage(exception,\n          \"Invalid host name: \"\n              + getHostDetailsAsString(destHost, destPort, localHost)\n              + exception\n              + \";\"\n              + see(\"UnknownHost\"));\n    } else if (exception instanceof SocketTimeoutException) {\n      return wrapWithMessage(exception,\n          \"Call From \"\n              + localHost + \" to \" + destHost + \":\" + destPort\n              + \" failed on socket timeout exception: \" + exception\n              + \";\"\n              + see(\"SocketTimeout\"));\n    } else if (exception instanceof NoRouteToHostException) {\n      return wrapWithMessage(exception,\n          \"No Route to Host from  \"\n              + localHost + \" to \" + destHost + \":\" + destPort\n              + \" failed on socket timeout exception: \" + exception\n              + \";\"\n              + see(\"NoRouteToHost\"));\n    } else if (exception instanceof EOFException) {\n      return wrapWithMessage(exception,\n          \"End of File Exception between \"\n              + getHostDetailsAsString(destHost,  destPort, localHost)\n              + \": \" + exception\n              + \";\"\n              + see(\"EOFException\"));\n    }\n    else {\n      return (IOException) new IOException(\"Failed on local exception: \"\n                                               + exception\n                                               + \"; Host Details : \"\n                                               + getHostDetailsAsString(destHost, destPort, localHost))\n          .initCause(exception);\n\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.see": "  private static String see(final String entry) {\n    return FOR_MORE_DETAILS_SEE + HADOOP_WIKI + entry;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.getHostDetailsAsString": "  private static String getHostDetailsAsString(final String destHost,\n                                               final int destPort,\n                                               final String localHost) {\n    StringBuilder hostDetails = new StringBuilder(27);\n    hostDetails.append(\"local host is: \")\n        .append(quoteHost(localHost))\n        .append(\"; \");\n    hostDetails.append(\"destination host is: \").append(quoteHost(destHost))\n        .append(\":\")\n        .append(destPort).append(\"; \");\n    return hostDetails.toString();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.wrapWithMessage": "  private static <T extends IOException> T wrapWithMessage(\n      T exception, String msg) {\n    Class<? extends Throwable> clazz = exception.getClass();\n    try {\n      Constructor<? extends Throwable> ctor = clazz.getConstructor(String.class);\n      Throwable t = ctor.newInstance(msg);\n      return (T)(t.initCause(exception));\n    } catch (Throwable e) {\n      LOG.warn(\"Unable to wrap exception of type \" +\n          clazz + \": it has no (String) constructor\", e);\n      return exception;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.call": "  public Writable call(RPC.RpcKind rpcKind, Writable rpcRequest,\n      ConnectionId remoteId, int serviceClass,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    final Call call = createCall(rpcKind, rpcRequest);\n    Connection connection = getConnection(remoteId, call, serviceClass,\n      fallbackToSimpleAuth);\n    try {\n      connection.sendRpcRequest(call);                 // send the rpc request\n    } catch (RejectedExecutionException e) {\n      throw new IOException(\"connection has been closed\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      LOG.warn(\"interrupted waiting to send rpc request to server\", e);\n      throw new IOException(e);\n    }\n\n    synchronized (call) {\n      while (!call.done) {\n        try {\n          call.wait();                           // wait for the result\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\"Call interrupted\");\n        }\n      }\n\n      if (call.error != null) {\n        if (call.error instanceof RemoteException) {\n          call.error.fillInStackTrace();\n          throw call.error;\n        } else { // local exception\n          InetSocketAddress address = connection.getRemoteAddress();\n          throw NetUtils.wrapException(address.getHostName(),\n                  address.getPort(),\n                  NetUtils.getHostname(),\n                  0,\n                  call.error);\n        }\n      } else {\n        return call.getRpcResponse();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRpcResponse": "    public synchronized Writable getRpcResponse() {\n      return rpcResponse;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRemoteAddress": "    public InetSocketAddress getRemoteAddress() {\n      return server;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnection": "  private Connection getConnection(ConnectionId remoteId,\n      Call call, int serviceClass, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    while (true) {\n      // These lines below can be shorten with computeIfAbsent in Java8\n      connection = connections.get(remoteId);\n      if (connection == null) {\n        connection = new Connection(remoteId, serviceClass);\n        Connection existing = connections.putIfAbsent(remoteId, connection);\n        if (existing != null) {\n          connection = existing;\n        }\n      }\n\n      if (connection.addCall(call)) {\n        break;\n      } else {\n        // This connection is closed, should be removed. But other thread could\n        // have already known this closedConnection, and replace it with a new\n        // connection. So we should call conditional remove to make sure we only\n        // remove this closedConnection.\n        connections.remove(remoteId, connection);\n      }\n    }\n\n    // If the server happens to be slow, the method below will take longer to\n    // establish a connection.\n    connection.setupIOstreams(fallbackToSimpleAuth);\n    return connection;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnectionId": "    static ConnectionId getConnectionId(InetSocketAddress addr,\n        Class<?> protocol, UserGroupInformation ticket, int rpcTimeout,\n        RetryPolicy connectionRetryPolicy, Configuration conf) throws IOException {\n\n      if (connectionRetryPolicy == null) {\n        final int max = conf.getInt(\n            CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_KEY,\n            CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_DEFAULT);\n        final int retryInterval = conf.getInt(\n            CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_RETRY_INTERVAL_KEY,\n            CommonConfigurationKeysPublic\n                .IPC_CLIENT_CONNECT_RETRY_INTERVAL_DEFAULT);\n\n        connectionRetryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n            max, retryInterval, TimeUnit.MILLISECONDS);\n      }\n\n      return new ConnectionId(addr, protocol, ticket, rpcTimeout,\n          connectionRetryPolicy, conf);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.createCall": "  Call createCall(RPC.RpcKind rpcKind, Writable rpcRequest) {\n    return new Call(rpcKind, rpcRequest);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.sendRpcRequest": "    public void sendRpcRequest(final Call call)\n        throws InterruptedException, IOException {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n\n      // Serialize the call to be sent. This is done from the actual\n      // caller thread, rather than the sendParamsExecutor thread,\n      \n      // so that if the serialization throws an error, it is reported\n      // properly. This also parallelizes the serialization.\n      //\n      // Format of a call on the wire:\n      // 0) Length of rest below (1 + 2)\n      // 1) RpcRequestHeader  - is serialized Delimited hence contains length\n      // 2) RpcRequest\n      //\n      // Items '1' and '2' are prepared here. \n      final DataOutputBuffer d = new DataOutputBuffer();\n      RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader(\n          call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry,\n          clientId);\n      header.writeDelimitedTo(d);\n      call.rpcRequest.write(d);\n\n      synchronized (sendRpcRequestLock) {\n        Future<?> senderFuture = sendParamsExecutor.submit(new Runnable() {\n          @Override\n          public void run() {\n            try {\n              synchronized (Connection.this.out) {\n                if (shouldCloseConnection.get()) {\n                  return;\n                }\n                \n                if (LOG.isDebugEnabled())\n                  LOG.debug(getName() + \" sending #\" + call.id);\n         \n                byte[] data = d.getData();\n                int totalLength = d.getLength();\n                out.writeInt(totalLength); // Total Length\n                out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest\n                out.flush();\n              }\n            } catch (IOException e) {\n              // exception at this point would leave the connection in an\n              // unrecoverable state (eg half a call left on the wire).\n              // So, close the connection, killing any outstanding calls\n              markClosed(e);\n            } finally {\n              //the buffer is just an in-memory buffer, but it is still polite to\n              // close early\n              IOUtils.closeStream(d);\n            }\n          }\n        });\n      \n        try {\n          senderFuture.get();\n        } catch (ExecutionException e) {\n          Throwable cause = e.getCause();\n          \n          // cause should only be a RuntimeException as the Runnable above\n          // catches IOException\n          if (cause instanceof RuntimeException) {\n            throw (RuntimeException) cause;\n          } else {\n            throw new RuntimeException(\"unexpected checked exception\", cause);\n          }\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.invoke": "    public Object invoke(Object proxy, Method method, Object[] args)\n        throws ServiceException {\n      long startTime = 0;\n      if (LOG.isDebugEnabled()) {\n        startTime = Time.now();\n      }\n      \n      if (args.length != 2) { // RpcController + Message\n        throw new ServiceException(\"Too many parameters for request. Method: [\"\n            + method.getName() + \"]\" + \", Expected: 2, Actual: \"\n            + args.length);\n      }\n      if (args[1] == null) {\n        throw new ServiceException(\"null param while calling Method: [\"\n            + method.getName() + \"]\");\n      }\n\n      // if Tracing is on then start a new span for this rpc.\n      // guard it in the if statement to make sure there isn't\n      // any extra string manipulation.\n      Tracer tracer = Tracer.curThreadTracer();\n      TraceScope traceScope = null;\n      if (tracer != null) {\n        traceScope = tracer.newScope(RpcClientUtil.methodToTraceString(method));\n      }\n\n      RequestHeaderProto rpcRequestHeader = constructRpcRequestHeader(method);\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(Thread.currentThread().getId() + \": Call -> \" +\n            remoteId + \": \" + method.getName() +\n            \" {\" + TextFormat.shortDebugString((Message) args[1]) + \"}\");\n      }\n\n\n      Message theRequest = (Message) args[1];\n      final RpcResponseWrapper val;\n      try {\n        val = (RpcResponseWrapper) client.call(RPC.RpcKind.RPC_PROTOCOL_BUFFER,\n            new RpcRequestWrapper(rpcRequestHeader, theRequest), remoteId,\n            fallbackToSimpleAuth);\n\n      } catch (Throwable e) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Exception <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + e + \"}\");\n        }\n        if (traceScope != null) {\n          traceScope.addTimelineAnnotation(\"Call got exception: \" +\n              e.toString());\n        }\n        throw new ServiceException(e);\n      } finally {\n        if (traceScope != null) traceScope.close();\n      }\n\n      if (LOG.isDebugEnabled()) {\n        long callTime = Time.now() - startTime;\n        LOG.debug(\"Call: \" + method.getName() + \" took \" + callTime + \"ms\");\n      }\n      \n      Message prototype = null;\n      try {\n        prototype = getReturnProtoType(method);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      Message returnMessage;\n      try {\n        returnMessage = prototype.newBuilderForType()\n            .mergeFrom(val.theResponseRead).build();\n\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Response <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + TextFormat.shortDebugString(returnMessage) + \"}\");\n        }\n\n      } catch (Throwable e) {\n        throw new ServiceException(e);\n      }\n      return returnMessage;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getReturnProtoType": "    private Message getReturnProtoType(Method method) throws Exception {\n      if (returnTypes.containsKey(method.getName())) {\n        return returnTypes.get(method.getName());\n      }\n      \n      Class<?> returnType = method.getReturnType();\n      Method newInstMethod = returnType.getMethod(\"getDefaultInstance\");\n      newInstMethod.setAccessible(true);\n      Message prototype = (Message) newInstMethod.invoke(null, (Object[]) null);\n      returnTypes.put(method.getName(), prototype);\n      return prototype;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcRequestWrapper request = (RpcRequestWrapper) writableRequest;\n        RequestHeaderProto rpcRequest = request.requestHeader;\n        String methodName = rpcRequest.getMethodName();\n        \n        \n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = prototype.newBuilderForType()\n            .mergeFrom(request.theRequestRead).build();\n        \n        Message result;\n        long startTime = Time.now();\n        int qTime = (int) (startTime - receiveTime);\n        Exception exception = null;\n        try {\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n        } catch (ServiceException e) {\n          exception = (Exception) e.getCause();\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          exception = e;\n          throw e;\n        } finally {\n          int processingTime = (int) (Time.now() - startTime);\n          if (LOG.isDebugEnabled()) {\n            String msg = \"Served: \" + methodName + \" queueTime= \" + qTime +\n                \" procesingTime= \" + processingTime;\n            if (exception != null) {\n              msg += \" exception= \" + exception.getClass().getSimpleName();\n            }\n            LOG.debug(msg);\n          }\n          String detailedMetricsName = (exception == null) ?\n              methodName :\n              exception.getClass().getSimpleName();\n          server.rpcMetrics.addRpcQueueTime(qTime);\n          server.rpcMetrics.addRpcProcessingTime(processingTime);\n          server.rpcDetailedMetrics.addProcessingTime(detailedMetricsName,\n              processingTime);\n          if (server.isLogSlowRPC()) {\n            server.logSlowRpcCalls(methodName, processingTime);\n          }\n        }\n        return new RpcResponseWrapper(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.close": "    public void close() throws IOException {\n      if (!isClosed) {\n        isClosed = true;\n        CLIENTS.stopClient(client);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.toString": "    public String toString() {\n      return requestHeader.getDeclaringClassProtocolName() + \".\" +\n          requestHeader.getMethodName();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.constructRpcRequestHeader": "    private RequestHeaderProto constructRpcRequestHeader(Method method) {\n      RequestHeaderProto.Builder builder = RequestHeaderProto\n          .newBuilder();\n      builder.setMethodName(method.getName());\n     \n\n      // For protobuf, {@code protocol} used when creating client side proxy is\n      // the interface extending BlockingInterface, which has the annotations \n      // such as ProtocolName etc.\n      //\n      // Using Method.getDeclaringClass(), as in WritableEngine to get at\n      // the protocol interface will return BlockingInterface, from where \n      // the annotation ProtocolName and Version cannot be\n      // obtained.\n      //\n      // Hence we simply use the protocol class used to create the proxy.\n      // For PB this may limit the use of mixins on client side.\n      builder.setDeclaringClassProtocolName(protocolName);\n      builder.setClientProtocolVersion(clientProtocolVersion);\n      return builder.build();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-common.src.main.java.org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager": "  public RegisterNodeManagerResponse registerNodeManager(\n      RegisterNodeManagerRequest request) throws YarnException,\n      IOException {\n    RegisterNodeManagerRequestProto requestProto = ((RegisterNodeManagerRequestPBImpl)request).getProto();\n    try {\n      return new RegisterNodeManagerResponsePBImpl(proxy.registerNodeManager(null, requestProto));\n    } catch (ServiceException e) {\n      RPCUtil.unwrapAndThrowException(e);\n      return null;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod": "  protected Object invokeMethod(Method method, Object[] args) throws Throwable {\n    try {\n      if (!method.isAccessible()) {\n        method.setAccessible(true);\n      }\n      return method.invoke(currentProxy.proxy, args);\n    } catch (InvocationTargetException e) {\n      throw e.getCause();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invoke": "  public Object invoke(Object proxy, Method method, Object[] args)\n    throws Throwable {\n    RetryPolicy policy = methodNameToPolicyMap.get(method.getName());\n    if (policy == null) {\n      policy = defaultPolicy;\n    }\n    \n    // The number of times this method invocation has been failed over.\n    int invocationFailoverCount = 0;\n    final boolean isRpc = isRpcInvocation(currentProxy.proxy);\n    final int callId = isRpc? Client.nextCallId(): RpcConstants.INVALID_CALL_ID;\n    int retries = 0;\n    while (true) {\n      // The number of times this invocation handler has ever been failed over,\n      // before this method invocation attempt. Used to prevent concurrent\n      // failed method invocations from triggering multiple failover attempts.\n      long invocationAttemptFailoverCount;\n      synchronized (proxyProvider) {\n        invocationAttemptFailoverCount = proxyProviderFailoverCount;\n      }\n\n      if (isRpc) {\n        Client.setCallIdAndRetryCount(callId, retries);\n      }\n      try {\n        Object ret = invokeMethod(method, args);\n        hasMadeASuccessfulCall = true;\n        return ret;\n      } catch (Exception ex) {\n        if (Thread.currentThread().isInterrupted()) {\n          // If interrupted, do not retry.\n          throw ex;\n        }\n        boolean isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n            .getMethod(method.getName(), method.getParameterTypes())\n            .isAnnotationPresent(Idempotent.class);\n        if (!isIdempotentOrAtMostOnce) {\n          isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n              .getMethod(method.getName(), method.getParameterTypes())\n              .isAnnotationPresent(AtMostOnce.class);\n        }\n        List<RetryAction> actions = extractActions(policy, ex, retries++,\n                invocationFailoverCount, isIdempotentOrAtMostOnce);\n        RetryAction failAction = getFailAction(actions);\n        if (failAction != null) {\n          if (failAction.reason != null) {\n            LOG.warn(\"Exception while invoking \" + currentProxy.proxy.getClass()\n                + \".\" + method.getName() + \" over \" + currentProxy.proxyInfo\n                + \". Not retrying because \" + failAction.reason, ex);\n          }\n          throw ex;\n        } else { // retry or failover\n          // avoid logging the failover if this is the first call on this\n          // proxy object, and we successfully achieve the failover without\n          // any flip-flopping\n          boolean worthLogging = \n            !(invocationFailoverCount == 0 && !hasMadeASuccessfulCall);\n          worthLogging |= LOG.isDebugEnabled();\n          RetryAction failOverAction = getFailOverAction(actions);\n          long delay = getDelayMillis(actions);\n          if (failOverAction != null && worthLogging) {\n            String msg = \"Exception while invoking \" + method.getName()\n                + \" of class \" + currentProxy.proxy.getClass().getSimpleName()\n                + \" over \" + currentProxy.proxyInfo;\n\n            if (invocationFailoverCount > 0) {\n              msg += \" after \" + invocationFailoverCount + \" fail over attempts\"; \n            }\n            msg += \". Trying to fail over \" + formatSleepMessage(delay);\n            LOG.info(msg, ex);\n          } else {\n            if(LOG.isDebugEnabled()) {\n              LOG.debug(\"Exception while invoking \" + method.getName()\n                  + \" of class \" + currentProxy.proxy.getClass().getSimpleName()\n                  + \" over \" + currentProxy.proxyInfo + \". Retrying \"\n                  + formatSleepMessage(delay), ex);\n            }\n          }\n\n          if (delay > 0) {\n            Thread.sleep(delay);\n          }\n          \n          if (failOverAction != null) {\n            // Make sure that concurrent failed method invocations only cause a\n            // single actual fail over.\n            synchronized (proxyProvider) {\n              if (invocationAttemptFailoverCount == proxyProviderFailoverCount) {\n                proxyProvider.performFailover(currentProxy.proxy);\n                proxyProviderFailoverCount++;\n              } else {\n                LOG.warn(\"A failover has occurred since the start of this method\"\n                    + \" invocation attempt.\");\n              }\n              currentProxy = proxyProvider.getProxy();\n            }\n            invocationFailoverCount++;\n          }\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM": "  protected void registerWithRM()\n      throws YarnException, IOException {\n    RegisterNodeManagerResponse regNMResponse;\n    Set<NodeLabel> nodeLabels = nodeLabelsHandler.getNodeLabelsForRegistration();\n \n    // Synchronize NM-RM registration with\n    // ContainerManagerImpl#increaseContainersResource and\n    // ContainerManagerImpl#startContainers to avoid race condition\n    // during RM recovery\n    synchronized (this.context) {\n      List<NMContainerStatus> containerReports = getNMContainerStatuses();\n      RegisterNodeManagerRequest request =\n          RegisterNodeManagerRequest.newInstance(nodeId, httpPort, totalResource,\n              nodeManagerVersionId, containerReports, getRunningApplications(),\n              nodeLabels);\n      if (containerReports != null) {\n        LOG.info(\"Registering with RM using containers :\" + containerReports);\n      }\n      regNMResponse =\n          resourceTracker.registerNodeManager(request);\n      // Make sure rmIdentifier is set before we release the lock\n      this.rmIdentifier = regNMResponse.getRMIdentifier();\n    }\n\n    // if the Resource Manager instructs NM to shutdown.\n    if (NodeAction.SHUTDOWN.equals(regNMResponse.getNodeAction())) {\n      String message =\n          \"Message from ResourceManager: \"\n              + regNMResponse.getDiagnosticsMessage();\n      throw new YarnRuntimeException(\n        \"Recieved SHUTDOWN signal from Resourcemanager, Registration of NodeManager failed, \"\n            + message);\n    }\n\n    // if ResourceManager version is too old then shutdown\n    if (!minimumResourceManagerVersion.equals(\"NONE\")){\n      if (minimumResourceManagerVersion.equals(\"EqualToNM\")){\n        minimumResourceManagerVersion = nodeManagerVersionId;\n      }\n      String rmVersion = regNMResponse.getRMVersion();\n      if (rmVersion == null) {\n        String message = \"The Resource Manager's did not return a version. \"\n            + \"Valid version cannot be checked.\";\n        throw new YarnRuntimeException(\"Shutting down the Node Manager. \"\n            + message);\n      }\n      if (VersionUtil.compareVersions(rmVersion,minimumResourceManagerVersion) < 0) {\n        String message = \"The Resource Manager's version (\"\n            + rmVersion +\") is less than the minimum \"\n            + \"allowed version \" + minimumResourceManagerVersion;\n        throw new YarnRuntimeException(\"Shutting down the Node Manager on RM \"\n            + \"version error, \" + message);\n      }\n    }\n    this.registeredWithRM = true;\n    MasterKey masterKey = regNMResponse.getContainerTokenMasterKey();\n    // do this now so that its set before we start heartbeating to RM\n    // It is expected that status updater is started by this point and\n    // RM gives the shared secret in registration during\n    // StatusUpdater#start().\n    if (masterKey != null) {\n      this.context.getContainerTokenSecretManager().setMasterKey(masterKey);\n    }\n    \n    masterKey = regNMResponse.getNMTokenMasterKey();\n    if (masterKey != null) {\n      this.context.getNMTokenSecretManager().setMasterKey(masterKey);\n    }\n\n    StringBuilder successfullRegistrationMsg = new StringBuilder();\n    successfullRegistrationMsg.append(\"Registered with ResourceManager as \")\n        .append(this.nodeId).append(\" with total resource of \")\n        .append(this.totalResource);\n\n    successfullRegistrationMsg.append(nodeLabelsHandler\n        .verifyRMRegistrationResponseForNodeLabels(regNMResponse));\n\n    LOG.info(successfullRegistrationMsg);\n    LOG.info(\"Notifying ContainerManager to unblock new container-requests\");\n    ((ContainerManagerImpl) this.context.getContainerManager())\n      .setBlockNewContainerRequests(false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getRunningApplications": "  private List<ApplicationId> getRunningApplications() {\n    List<ApplicationId> runningApplications = new ArrayList<ApplicationId>();\n    runningApplications.addAll(this.context.getApplications().keySet());\n    return runningApplications;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getRMIdentifier": "  public long getRMIdentifier() {\n    return this.rmIdentifier;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getNMContainerStatuses": "  private List<NMContainerStatus> getNMContainerStatuses() throws IOException {\n    List<NMContainerStatus> containerStatuses =\n        new ArrayList<NMContainerStatus>();\n    for (Container container : this.context.getContainers().values()) {\n      ContainerId containerId = container.getContainerId();\n      ApplicationId applicationId = containerId.getApplicationAttemptId()\n          .getApplicationId();\n      if (!this.context.getApplications().containsKey(applicationId)) {\n        context.getContainers().remove(containerId);\n        continue;\n      }\n      NMContainerStatus status =\n          container.getNMContainerStatus();\n      containerStatuses.add(status);\n      if (status.getContainerState() == ContainerState.COMPLETE) {\n        // Adding to finished containers cache. Cache will keep it around at\n        // least for #durationToTrackStoppedContainers duration. In the\n        // subsequent call to stop container it will get removed from cache.\n        addCompletedContainer(containerId);\n      }\n    }\n    LOG.info(\"Sending out \" + containerStatuses.size()\n      + \" NM container statuses: \" + containerStatuses);\n    return containerStatuses;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.verifyRMRegistrationResponseForNodeLabels": "    public String verifyRMRegistrationResponseForNodeLabels(\n        RegisterNodeManagerResponse regNMResponse) {\n      StringBuilder successfulNodeLabelsRegistrationMsg = new StringBuilder(\"\");\n      if (regNMResponse.getAreNodeLabelsAcceptedByRM()) {\n        successfulNodeLabelsRegistrationMsg\n            .append(\" and with following Node label(s) : {\")\n            .append(StringUtils.join(\",\", previousNodeLabels)).append(\"}\");\n      } else {\n        // case where provider is set but RM did not accept the Node Labels\n        LOG.error(regNMResponse.getDiagnosticsMessage());\n      }\n      return successfulNodeLabelsRegistrationMsg.toString();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getNodeLabelsForRegistration": "    public Set<NodeLabel> getNodeLabelsForRegistration() {\n      Set<NodeLabel> nodeLabels = nodeLabelsProvider.getNodeLabels();\n      nodeLabels = (null == nodeLabels)\n          ? CommonNodeLabelsManager.EMPTY_NODELABEL_SET : nodeLabels;\n      previousNodeLabels = nodeLabels;\n      try {\n        validateNodeLabels(nodeLabels);\n      } catch (IOException e) {\n        nodeLabels = null;\n      }\n      return nodeLabels;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM": "  protected void rebootNodeStatusUpdaterAndRegisterWithRM() {\n    // Interrupt the updater.\n    this.isStopped = true;\n\n    try {\n      statusUpdater.join();\n      registerWithRM();\n      statusUpdater = new Thread(statusUpdaterRunnable, \"Node Status Updater\");\n      this.isStopped = false;\n      statusUpdater.start();\n      LOG.info(\"NodeStatusUpdater thread is reRegistered and restarted\");\n    } catch (Exception e) {\n      String errorMessage = \"Unexpected error rebooting NodeStatusUpdater\";\n      LOG.error(errorMessage, e);\n      throw new YarnRuntimeException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.run": "      public void run() {\n        try {\n          LOG.info(\"Notifying ContainerManager to block new container-requests\");\n          containerManager.setBlockNewContainerRequests(true);\n          if (!rmWorkPreservingRestartEnabled) {\n            LOG.info(\"Cleaning up running containers on resync\");\n            containerManager.cleanupContainersOnNMResync();\n          } else {\n            LOG.info(\"Preserving containers on resync\");\n          }\n          ((NodeStatusUpdaterImpl) nodeStatusUpdater)\n            .rebootNodeStatusUpdaterAndRegisterWithRM();\n        } catch (YarnRuntimeException e) {\n          LOG.fatal(\"Error while rebooting NodeStatusUpdater.\", e);\n          shutDown();\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.shutDown": "  protected void shutDown() {\n    new Thread() {\n      @Override\n      public void run() {\n        try {\n          NodeManager.this.stop();\n        } catch (Throwable t) {\n          LOG.error(\"Error while shutting down NodeManager\", t);\n        } finally {\n          if (shouldExitOnShutdownEvent\n              && !ShutdownHookManager.get().isShutdownInProgress()) {\n            ExitUtil.terminate(-1);\n          }\n        }\n      }\n    }.start();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketInputStream.performIO": "    int performIO(ByteBuffer buf) throws IOException {\n      return channel.read(buf);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketInputStream.read": "  public int read(ByteBuffer dst) throws IOException {\n    return reader.doIO(dst, SelectionKey.OP_READ);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.doIO": "  int doIO(ByteBuffer buf, int ops) throws IOException {\n    \n    /* For now only one thread is allowed. If user want to read or write\n     * from multiple threads, multiple streams could be created. In that\n     * case multiple threads work as well as underlying channel supports it.\n     */\n    if (!buf.hasRemaining()) {\n      throw new IllegalArgumentException(\"Buffer has no data left.\");\n      //or should we just return 0?\n    }\n\n    while (buf.hasRemaining()) {\n      if (closed) {\n        return -1;\n      }\n\n      try {\n        int n = performIO(buf);\n        if (n != 0) {\n          // successful io or an error.\n          return n;\n        }\n      } catch (IOException e) {\n        if (!channel.isOpen()) {\n          closed = true;\n        }\n        throw e;\n      }\n\n      //now wait for socket to be ready.\n      int count = 0;\n      try {\n        count = selector.select(channel, ops, timeout);  \n      } catch (IOException e) { //unexpected IOException.\n        closed = true;\n        throw e;\n      } \n\n      if (count == 0) {\n        throw new SocketTimeoutException(timeoutExceptionString(channel,\n                                                                timeout, ops));\n      }\n      // otherwise the socket should be ready for io.\n    }\n    \n    return 0; // does not reach here.\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.select": "    int select(SelectableChannel channel, int ops, long timeout) \n                                                   throws IOException {\n     \n      SelectorInfo info = get(channel);\n      \n      SelectionKey key = null;\n      int ret = 0;\n      \n      try {\n        while (true) {\n          long start = (timeout == 0) ? 0 : Time.now();\n\n          key = channel.register(info.selector, ops);\n          ret = info.selector.select(timeout);\n          \n          if (ret != 0) {\n            return ret;\n          }\n          \n          if (Thread.currentThread().isInterrupted()) {\n            throw new InterruptedIOException(\"Interrupted while waiting for \"\n                + \"IO on channel \" + channel + \". \" + timeout\n                + \" millis timeout left.\");\n          }\n\n          /* Sometimes select() returns 0 much before timeout for \n           * unknown reasons. So select again if required.\n           */\n          if (timeout > 0) {\n            timeout -= Time.now() - start;\n            if (timeout <= 0) {\n              return 0;\n            }\n          }\n          \n        }\n      } finally {\n        if (key != null) {\n          key.cancel();\n        }\n        \n        //clear the canceled key.\n        try {\n          info.selector.selectNow();\n        } catch (IOException e) {\n          LOG.info(\"Unexpected Exception while clearing selector : \", e);\n          // don't put the selector back.\n          info.close();\n          return ret; \n        }\n        \n        release(info);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.timeoutExceptionString": "  private static String timeoutExceptionString(SelectableChannel channel,\n                                               long timeout, int ops) {\n    \n    String waitingFor;\n    switch(ops) {\n    \n    case SelectionKey.OP_READ :\n      waitingFor = \"read\"; break;\n      \n    case SelectionKey.OP_WRITE :\n      waitingFor = \"write\"; break;      \n      \n    case SelectionKey.OP_CONNECT :\n      waitingFor = \"connect\"; break;\n      \n    default :\n      waitingFor = \"\" + ops;  \n    }\n    \n    return timeout + \" millis timeout while \" +\n           \"waiting for channel to be ready for \" + \n           waitingFor + \". ch : \" + channel;    \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.isOpen": "  boolean isOpen() {\n    return !closed && channel.isOpen();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.performIO": "  abstract int performIO(ByteBuffer buf) throws IOException;  \n  \n  /**\n   * Performs one IO and returns number of bytes read or written.\n   * It waits up to the specified timeout. If the channel is \n   * not read before the timeout, SocketTimeoutException is thrown.\n   * \n   * @param buf buffer for IO\n   * @param ops Selection Ops used for waiting. Suggested values: \n   *        SelectionKey.OP_READ while reading and SelectionKey.OP_WRITE while\n   *        writing. \n   *        \n   * @return number of bytes read or written. negative implies end of stream.\n   * @throws IOException\n   */\n  int doIO(ByteBuffer buf, int ops) throws IOException {\n    \n    /* For now only one thread is allowed. If user want to read or write\n     * from multiple threads, multiple streams could be created. In that\n     * case multiple threads work as well as underlying channel supports it.\n     */\n    if (!buf.hasRemaining()) {\n      throw new IllegalArgumentException(\"Buffer has no data left.\");\n      //or should we just return 0?\n    }\n\n    while (buf.hasRemaining()) {\n      if (closed) {\n        return -1;\n      }\n\n      try {\n        int n = performIO(buf);\n        if (n != 0) {\n          // successful io or an error.\n          return n;\n        }\n      } catch (IOException e) {\n        if (!channel.isOpen()) {\n          closed = true;\n        }\n        throw e;\n      }\n\n      //now wait for socket to be ready.\n      int count = 0;\n      try {\n        count = selector.select(channel, ops, timeout);  \n      } catch (IOException e) { //unexpected IOException.\n        closed = true;\n        throw e;\n      } \n\n      if (count == 0) {\n        throw new SocketTimeoutException(timeoutExceptionString(channel,\n                                                                timeout, ops));\n      }\n      // otherwise the socket should be ready for io.\n    }\n    \n    return 0; // does not reach here.\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.read": "      public int read(byte[] buf, int off, int len) throws IOException {\n        do {\n          try {\n            return super.read(buf, off, len);\n          } catch (SocketTimeoutException e) {\n            handleTimeout(e);\n          }\n        } while (true);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.handleTimeout": "      private void handleTimeout(SocketTimeoutException e) throws IOException {\n        if (shouldCloseConnection.get() || !running.get() || rpcTimeout > 0) {\n          throw e;\n        } else {\n          sendPing();\n        }\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.receiveRpcResponse": "    private void receiveRpcResponse() {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n      touch();\n      \n      try {\n        int totalLen = in.readInt();\n        RpcResponseHeaderProto header = \n            RpcResponseHeaderProto.parseDelimitedFrom(in);\n        checkResponse(header);\n\n        int headerLen = header.getSerializedSize();\n        headerLen += CodedOutputStream.computeRawVarint32Size(headerLen);\n\n        int callId = header.getCallId();\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \" got value #\" + callId);\n\n        Call call = calls.get(callId);\n        RpcStatusProto status = header.getStatus();\n        if (status == RpcStatusProto.SUCCESS) {\n          Writable value = ReflectionUtils.newInstance(valueClass, conf);\n          value.readFields(in);                 // read value\n          calls.remove(callId);\n          call.setRpcResponse(value);\n          \n          // verify that length was correct\n          // only for ProtobufEngine where len can be verified easily\n          if (call.getRpcResponse() instanceof ProtobufRpcEngine.RpcWrapper) {\n            ProtobufRpcEngine.RpcWrapper resWrapper = \n                (ProtobufRpcEngine.RpcWrapper) call.getRpcResponse();\n            if (totalLen != headerLen + resWrapper.getLength()) { \n              throw new RpcClientException(\n                  \"RPC response length mismatch on rpc success\");\n            }\n          }\n        } else { // Rpc Request failed\n          // Verify that length was correct\n          if (totalLen != headerLen) {\n            throw new RpcClientException(\n                \"RPC response length mismatch on rpc error\");\n          }\n          \n          final String exceptionClassName = header.hasExceptionClassName() ?\n                header.getExceptionClassName() : \n                  \"ServerDidNotSetExceptionClassName\";\n          final String errorMsg = header.hasErrorMsg() ? \n                header.getErrorMsg() : \"ServerDidNotSetErrorMsg\" ;\n          final RpcErrorCodeProto erCode = \n                    (header.hasErrorDetail() ? header.getErrorDetail() : null);\n          if (erCode == null) {\n             LOG.warn(\"Detailed error code not set by server on rpc error\");\n          }\n          RemoteException re = new RemoteException(exceptionClassName, errorMsg, erCode);\n          if (status == RpcStatusProto.ERROR) {\n            calls.remove(callId);\n            call.setException(re);\n          } else if (status == RpcStatusProto.FATAL) {\n            // Close the connection\n            markClosed(re);\n          }\n        }\n      } catch (IOException e) {\n        markClosed(e);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setException": "    public synchronized void setException(IOException error) {\n      this.error = error;\n      callComplete();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.checkResponse": "  void checkResponse(RpcResponseHeaderProto header) throws IOException {\n    if (header == null) {\n      throw new EOFException(\"Response is null.\");\n    }\n    if (header.hasClientId()) {\n      // check client IDs\n      final byte[] id = header.getClientId().toByteArray();\n      if (!Arrays.equals(id, RpcConstants.DUMMY_CLIENT_ID)) {\n        if (!Arrays.equals(id, clientId)) {\n          throw new IOException(\"Client IDs not matched: local ID=\"\n              + StringUtils.byteToHexString(clientId) + \", ID in response=\"\n              + StringUtils.byteToHexString(header.getClientId().toByteArray()));\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.markClosed": "    private synchronized void markClosed(IOException e) {\n      if (shouldCloseConnection.compareAndSet(false, true)) {\n        closeException = e;\n        notifyAll();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.touch": "    private void touch() {\n      lastActivity.set(Time.now());\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setRpcResponse": "    public synchronized void setRpcResponse(Writable rpcResponse) {\n      this.rpcResponse = rpcResponse;\n      callComplete();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.run": "          public void run() {\n            try {\n              synchronized (Connection.this.out) {\n                if (shouldCloseConnection.get()) {\n                  return;\n                }\n                \n                if (LOG.isDebugEnabled())\n                  LOG.debug(getName() + \" sending #\" + call.id);\n         \n                byte[] data = d.getData();\n                int totalLength = d.getLength();\n                out.writeInt(totalLength); // Total Length\n                out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest\n                out.flush();\n              }\n            } catch (IOException e) {\n              // exception at this point would leave the connection in an\n              // unrecoverable state (eg half a call left on the wire).\n              // So, close the connection, killing any outstanding calls\n              markClosed(e);\n            } finally {\n              //the buffer is just an in-memory buffer, but it is still polite to\n              // close early\n              IOUtils.closeStream(d);\n            }\n          }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.shouldAuthenticateOverKrb": "    private synchronized boolean shouldAuthenticateOverKrb() throws IOException {\n      UserGroupInformation loginUser = UserGroupInformation.getLoginUser();\n      UserGroupInformation currentUser = UserGroupInformation.getCurrentUser();\n      UserGroupInformation realUser = currentUser.getRealUser();\n      if (authMethod == AuthMethod.KERBEROS && loginUser != null &&\n      // Make sure user logged in using Kerberos either keytab or TGT\n          loginUser.hasKerberosCredentials() &&\n          // relogin only in case it is the login user (e.g. JT)\n          // or superuser (like oozie).\n          (loginUser.equals(currentUser) || loginUser.equals(realUser))) {\n        return true;\n      }\n      return false;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.close": "    private synchronized void close() {\n      if (!shouldCloseConnection.get()) {\n        LOG.error(\"The connection is not in the closed state\");\n        return;\n      }\n\n      // We have marked this connection as closed. Other thread could have\n      // already known it and replace this closedConnection with a new one.\n      // We should only remove this closedConnection.\n      connections.remove(remoteId, this);\n\n      // close the streams and therefore the socket\n      IOUtils.closeStream(out);\n      IOUtils.closeStream(in);\n      disposeSasl();\n\n      // clean up all calls\n      if (closeException == null) {\n        if (!calls.isEmpty()) {\n          LOG.warn(\n              \"A connection is closed for no cause and calls are not empty\");\n\n          // clean up calls anyway\n          closeException = new IOException(\"Unexpected closed connection\");\n          cleanupCalls();\n        }\n      } else {\n        // log the info\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"closing ipc connection to \" + server + \": \" +\n              closeException.getMessage(),closeException);\n        }\n\n        // cleanup calls\n        cleanupCalls();\n      }\n      closeConnection();\n      if (LOG.isDebugEnabled())\n        LOG.debug(getName() + \": closed\");\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.disposeSasl": "    private synchronized void disposeSasl() {\n      if (saslRpcClient != null) {\n        try {\n          saslRpcClient.dispose();\n          saslRpcClient = null;\n        } catch (IOException ignored) {\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.closeConnection": "    private void closeConnection() {\n      if (socket == null) {\n        return;\n      }\n      // close the current connection\n      try {\n        socket.close();\n      } catch (IOException e) {\n        LOG.warn(\"Not able to close a socket\", e);\n      }\n      // set socket to null so that the next call to setupIOstreams\n      // can start the process of connect all over again.\n      socket = null;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.waitForWork": "    private synchronized boolean waitForWork() {\n      if (calls.isEmpty() && !shouldCloseConnection.get()  && running.get())  {\n        long timeout = maxIdleTime-\n              (Time.now()-lastActivity.get());\n        if (timeout>0) {\n          try {\n            wait(timeout);\n          } catch (InterruptedException e) {}\n        }\n      }\n      \n      if (!calls.isEmpty() && !shouldCloseConnection.get() && running.get()) {\n        return true;\n      } else if (shouldCloseConnection.get()) {\n        return false;\n      } else if (calls.isEmpty()) { // idle connection closed or stopped\n        markClosed(null);\n        return false;\n      } else { // get stopped but there are still pending requests \n        markClosed((IOException)new IOException().initCause(\n            new InterruptedException()));\n        return false;\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupSaslConnection": "    private synchronized AuthMethod setupSaslConnection(final InputStream in2, \n        final OutputStream out2) throws IOException {\n      // Do not use Client.conf here! We must use ConnectionId.conf, since the\n      // Client object is cached and shared between all RPC clients, even those\n      // for separate services.\n      saslRpcClient = new SaslRpcClient(remoteId.getTicket(),\n          remoteId.getProtocol(), remoteId.getAddress(), remoteId.conf);\n      return saslRpcClient.saslConnect(in2, out2);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcClientUtil.methodToTraceString": "  public static String methodToTraceString(Method method) {\n    Class<?> clazz = method.getDeclaringClass();\n    while (true) {\n      Class<?> next = clazz.getEnclosingClass();\n      if (next == null || next.getEnclosingClass() == null) break;\n      clazz = next;\n    }\n    return clazz.getSimpleName() + \"#\" + method.getName();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getLength": "    public int getLength() {\n      int resLen;\n      if (theResponse != null) {\n        resLen = theResponse.getSerializedSize();\n      } else if (theResponseRead != null ) {\n        resLen = theResponseRead.length;\n      } else {\n        throw new IllegalArgumentException(\n            \"getLength on uninitialized RpcWrapper\");      \n      }\n      return CodedOutputStream.computeRawVarint32Size(resLen) + resLen;\n    }"
        },
        "bug_report": {
            "Title": "NodeManager restart should keep retrying to register to RM while connection exception happens during RM failed over.",
            "Description": "When NM get restarted, NodeStatusUpdaterImpl will try to register to RM with RPC which could throw following exceptions when RM get restarted at the same time, like following exception shows:\n{noformat}\n2015-08-17 14:35:59,434 ERROR nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:rebootNodeStatusUpdaterAndRegisterWithRM(222)) - Unexpected error rebooting NodeStatusUpdater\njava.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1473)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1400)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy36.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy37.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:257)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:215)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager$2.run(NodeManager.java:304)\nCaused by: java.io.IOException: Connection reset by peer\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:197)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:514)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:254)\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)\n2015-08-17 14:35:59,436 FATAL nodemanager.NodeManager (NodeManager.java:run(307)) - Error while rebooting NodeStatusUpdater.\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:223)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager$2.run(NodeManager.java:304)\nCaused by: java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"ebdp-ch2-172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1473)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1400)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy36.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy37.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:257)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:215)\n        ... 1 more\nCaused by: java.io.IOException: Connection reset by peer\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:197)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:514)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:254)\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)\n2015-08-17 14:35:59,445 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042\n2015-08-17 14:35:59,547 INFO  containermanager.ContainerManagerImpl (ContainerManagerImpl.java:cleanUpApplicationsOnNMShutDown(512)) - Applications still running : [application_1439417357296_45357, application_1439417357296_45403, application_1439417357296_45355, application_1439417357296_45111, application_1439417357296_45452, application_1439417357296_45350, application_1439417357296_45499, application_1439417357296_45205, application_1439417357296_21009]\n2015-08-17 14:35:59,548 INFO  ipc.Server (Server.java:stop(2469)) - Stopping server on 45454\n2015-08-17 14:35:59,551 INFO  ipc.Server (Server.java:run(717)) - Stopping IPC Server listener on 45454\n2015-08-17 14:35:59,551 INFO  logaggregation.LogAggregationService (LogAggregationService.java:serviceStop(141)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService waiting for pending aggregation during exit\n2015-08-17 14:35:59,552 INFO  ipc.Server (Server.java:run(843)) - Stopping IPC Server Responder\n{noformat}\nIt will make NM restart get failed. We should have a simple fix to allow this register to RM can retry with connection failures."
        }
    },
    {
        "filename": "YARN-1032.json",
        "creation_time": "2013-08-05T21:10:46.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:99)\n\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:92)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignMapsWithLocality(RMContainerAllocator.java:1039)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignContainers(RMContainerAllocator.java:925)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:861)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$400(RMContainerAllocator.java:681)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:219)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:243)\n\tat java.lang.Thread.run(Thread.java:722)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.RackResolver.coreResolve": "  private static Node coreResolve(String hostName) {\n    List <String> tmpList = new ArrayList<String>(1);\n    tmpList.add(hostName);\n    List <String> rNameList = dnsToSwitchMapping.resolve(tmpList);\n    String rName = rNameList.get(0);\n    LOG.info(\"Resolved \" + hostName + \" to \" + rName);\n    return new NodeBase(hostName, rName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.RackResolver.resolve": "  public static Node resolve(String hostName) {\n    if (!initCalled) {\n      throw new IllegalStateException(\"RackResolver class not yet initialized\");\n    }\n    return coreResolve(hostName);\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.assignMapsWithLocality": "    private void assignMapsWithLocality(List<Container> allocatedContainers) {\n      // try to assign to all nodes first to match node local\n      Iterator<Container> it = allocatedContainers.iterator();\n      while(it.hasNext() && maps.size() > 0){\n        Container allocated = it.next();        \n        Priority priority = allocated.getPriority();\n        assert PRIORITY_MAP.equals(priority);\n        // \"if (maps.containsKey(tId))\" below should be almost always true.\n        // hence this while loop would almost always have O(1) complexity\n        String host = allocated.getNodeId().getHost();\n        LinkedList<TaskAttemptId> list = mapsHostMapping.get(host);\n        while (list != null && list.size() > 0) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Host matched to the request list \" + host);\n          }\n          TaskAttemptId tId = list.removeFirst();\n          if (maps.containsKey(tId)) {\n            ContainerRequest assigned = maps.remove(tId);\n            containerAssigned(allocated, assigned);\n            it.remove();\n            JobCounterUpdateEvent jce =\n              new JobCounterUpdateEvent(assigned.attemptID.getTaskId().getJobId());\n            jce.addCounterUpdate(JobCounter.DATA_LOCAL_MAPS, 1);\n            eventHandler.handle(jce);\n            hostLocalAssigned++;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Assigned based on host match \" + host);\n            }\n            break;\n          }\n        }\n      }\n      \n      // try to match all rack local\n      it = allocatedContainers.iterator();\n      while(it.hasNext() && maps.size() > 0){\n        Container allocated = it.next();\n        Priority priority = allocated.getPriority();\n        assert PRIORITY_MAP.equals(priority);\n        // \"if (maps.containsKey(tId))\" below should be almost always true.\n        // hence this while loop would almost always have O(1) complexity\n        String host = allocated.getNodeId().getHost();\n        String rack = RackResolver.resolve(host).getNetworkLocation();\n        LinkedList<TaskAttemptId> list = mapsRackMapping.get(rack);\n        while (list != null && list.size() > 0) {\n          TaskAttemptId tId = list.removeFirst();\n          if (maps.containsKey(tId)) {\n            ContainerRequest assigned = maps.remove(tId);\n            containerAssigned(allocated, assigned);\n            it.remove();\n            JobCounterUpdateEvent jce =\n              new JobCounterUpdateEvent(assigned.attemptID.getTaskId().getJobId());\n            jce.addCounterUpdate(JobCounter.RACK_LOCAL_MAPS, 1);\n            eventHandler.handle(jce);\n            rackLocalAssigned++;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Assigned based on rack match \" + rack);\n            }\n            break;\n          }\n        }\n      }\n      \n      // assign remaining\n      it = allocatedContainers.iterator();\n      while(it.hasNext() && maps.size() > 0){\n        Container allocated = it.next();\n        Priority priority = allocated.getPriority();\n        assert PRIORITY_MAP.equals(priority);\n        TaskAttemptId tId = maps.keySet().iterator().next();\n        ContainerRequest assigned = maps.remove(tId);\n        containerAssigned(allocated, assigned);\n        it.remove();\n        JobCounterUpdateEvent jce =\n          new JobCounterUpdateEvent(assigned.attemptID.getTaskId().getJobId());\n        jce.addCounterUpdate(JobCounter.OTHER_LOCAL_MAPS, 1);\n        eventHandler.handle(jce);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Assigned based on * match\");\n        }\n      }\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.containerAssigned": "    private void containerAssigned(Container allocated, \n                                    ContainerRequest assigned) {\n      // Update resource requests\n      decContainerReq(assigned);\n\n      // send the container-assigned event to task attempt\n      eventHandler.handle(new TaskAttemptContainerAssignedEvent(\n          assigned.attemptID, allocated, applicationACLs));\n\n      assignedRequests.add(allocated, assigned.attemptID);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.info(\"Assigned container (\" + allocated + \") \"\n            + \" to task \" + assigned.attemptID + \" on node \"\n            + allocated.getNodeId().toString());\n      }\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getHost": "  private static String getHost(String contMgrAddress) {\n    String host = contMgrAddress;\n    String[] hostport = host.split(\":\");\n    if (hostport.length == 2) {\n      host = hostport[0];\n    }\n    return host;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.handle": "  public void handle(ContainerAllocatorEvent event) {\n    int qSize = eventQueue.size();\n    if (qSize != 0 && qSize % 1000 == 0) {\n      LOG.info(\"Size of event-queue in RMContainerAllocator is \" + qSize);\n    }\n    int remCapacity = eventQueue.remainingCapacity();\n    if (remCapacity < 1000) {\n      LOG.warn(\"Very low remaining capacity in the event-queue \"\n          + \"of RMContainerAllocator: \" + remCapacity);\n    }\n    try {\n      eventQueue.put(event);\n    } catch (InterruptedException e) {\n      throw new YarnRuntimeException(e);\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.get": "    ContainerId get(TaskAttemptId tId) {\n      Container taskContainer;\n      if (tId.getTaskId().getTaskType().equals(TaskType.MAP)) {\n        taskContainer = maps.get(tId);\n      } else {\n        taskContainer = reduces.get(tId);\n      }\n\n      if (taskContainer == null) {\n        return null;\n      } else {\n        return taskContainer.getId();\n      }\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.remove": "    boolean remove(TaskAttemptId tId) {\n      ContainerId containerId = null;\n      if (tId.getTaskId().getTaskType().equals(TaskType.MAP)) {\n        containerId = maps.remove(tId).getId();\n      } else {\n        containerId = reduces.remove(tId).getId();\n        if (containerId != null) {\n          boolean preempted = preemptionWaitingReduces.remove(tId);\n          if (preempted) {\n            LOG.info(\"Reduce preemption successful \" + tId);\n          }\n        }\n      }\n      \n      if (containerId != null) {\n        containerToAttemptMap.remove(containerId);\n        return true;\n      }\n      return false;\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.assignContainers": "    private void assignContainers(List<Container> allocatedContainers) {\n      Iterator<Container> it = allocatedContainers.iterator();\n      while (it.hasNext()) {\n        Container allocated = it.next();\n        ContainerRequest assigned = assignWithoutLocality(allocated);\n        if (assigned != null) {\n          containerAssigned(allocated, assigned);\n          it.remove();\n        }\n      }\n\n      assignMapsWithLocality(allocatedContainers);\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.assignWithoutLocality": "    private ContainerRequest assignWithoutLocality(Container allocated) {\n      ContainerRequest assigned = null;\n      \n      Priority priority = allocated.getPriority();\n      if (PRIORITY_FAST_FAIL_MAP.equals(priority)) {\n        LOG.info(\"Assigning container \" + allocated + \" to fast fail map\");\n        assigned = assignToFailedMap(allocated);\n      } else if (PRIORITY_REDUCE.equals(priority)) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Assigning container \" + allocated + \" to reduce\");\n        }\n        assigned = assignToReduce(allocated);\n      }\n        \n      return assigned;\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.assign": "    private void assign(List<Container> allocatedContainers) {\n      Iterator<Container> it = allocatedContainers.iterator();\n      LOG.info(\"Got allocated containers \" + allocatedContainers.size());\n      containersAllocated += allocatedContainers.size();\n      while (it.hasNext()) {\n        Container allocated = it.next();\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Assigning container \" + allocated.getId()\n              + \" with priority \" + allocated.getPriority() + \" to NM \"\n              + allocated.getNodeId());\n        }\n        \n        // check if allocated container meets memory requirements \n        // and whether we have any scheduled tasks that need \n        // a container to be assigned\n        boolean isAssignable = true;\n        Priority priority = allocated.getPriority();\n        int allocatedMemory = allocated.getResource().getMemory();\n        if (PRIORITY_FAST_FAIL_MAP.equals(priority) \n            || PRIORITY_MAP.equals(priority)) {\n          if (allocatedMemory < mapResourceReqt\n              || maps.isEmpty()) {\n            LOG.info(\"Cannot assign container \" + allocated \n                + \" for a map as either \"\n                + \" container memory less than required \" + mapResourceReqt\n                + \" or no pending map tasks - maps.isEmpty=\" \n                + maps.isEmpty()); \n            isAssignable = false; \n          }\n        } \n        else if (PRIORITY_REDUCE.equals(priority)) {\n          if (allocatedMemory < reduceResourceReqt\n              || reduces.isEmpty()) {\n            LOG.info(\"Cannot assign container \" + allocated \n                + \" for a reduce as either \"\n                + \" container memory less than required \" + reduceResourceReqt\n                + \" or no pending reduce tasks - reduces.isEmpty=\" \n                + reduces.isEmpty()); \n            isAssignable = false;\n          }\n        } else {\n          LOG.warn(\"Container allocated at unwanted priority: \" + priority + \n              \". Returning to RM...\");\n          isAssignable = false;\n        }\n        \n        if(!isAssignable) {\n          // release container if we could not assign it \n          containerNotAssigned(allocated);\n          it.remove();\n          continue;\n        }\n        \n        // do not assign if allocated container is on a  \n        // blacklisted host\n        String allocatedHost = allocated.getNodeId().getHost();\n        if (isNodeBlacklisted(allocatedHost)) {\n          // we need to request for a new container \n          // and release the current one\n          LOG.info(\"Got allocated container on a blacklisted \"\n              + \" host \"+allocatedHost\n              +\". Releasing container \" + allocated);\n\n          // find the request matching this allocated container \n          // and replace it with a new one \n          ContainerRequest toBeReplacedReq = \n              getContainerReqToReplace(allocated);\n          if (toBeReplacedReq != null) {\n            LOG.info(\"Placing a new container request for task attempt \" \n                + toBeReplacedReq.attemptID);\n            ContainerRequest newReq = \n                getFilteredContainerRequest(toBeReplacedReq);\n            decContainerReq(toBeReplacedReq);\n            if (toBeReplacedReq.attemptID.getTaskId().getTaskType() ==\n                TaskType.MAP) {\n              maps.put(newReq.attemptID, newReq);\n            }\n            else {\n              reduces.put(newReq.attemptID, newReq);\n            }\n            addContainerReq(newReq);\n          }\n          else {\n            LOG.info(\"Could not map allocated container to a valid request.\"\n                + \" Releasing allocated container \" + allocated);\n          }\n          \n          // release container if we could not assign it \n          containerNotAssigned(allocated);\n          it.remove();\n          continue;\n        }\n      }\n\n      assignContainers(allocatedContainers);\n       \n      // release container if we could not assign it \n      it = allocatedContainers.iterator();\n      while (it.hasNext()) {\n        Container allocated = it.next();\n        LOG.info(\"Releasing unassigned and invalid container \" \n            + allocated + \". RM may have assignment issues\");\n        containerNotAssigned(allocated);\n      }\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getContainerReqToReplace": "    private ContainerRequest getContainerReqToReplace(Container allocated) {\n      LOG.info(\"Finding containerReq for allocated container: \" + allocated);\n      Priority priority = allocated.getPriority();\n      ContainerRequest toBeReplaced = null;\n      if (PRIORITY_FAST_FAIL_MAP.equals(priority)) {\n        LOG.info(\"Replacing FAST_FAIL_MAP container \" + allocated.getId());\n        Iterator<TaskAttemptId> iter = earlierFailedMaps.iterator();\n        while (toBeReplaced == null && iter.hasNext()) {\n          toBeReplaced = maps.get(iter.next());\n        }\n        LOG.info(\"Found replacement: \" + toBeReplaced);\n        return toBeReplaced;\n      }\n      else if (PRIORITY_MAP.equals(priority)) {\n        LOG.info(\"Replacing MAP container \" + allocated.getId());\n        // allocated container was for a map\n        String host = allocated.getNodeId().getHost();\n        LinkedList<TaskAttemptId> list = mapsHostMapping.get(host);\n        if (list != null && list.size() > 0) {\n          TaskAttemptId tId = list.removeLast();\n          if (maps.containsKey(tId)) {\n            toBeReplaced = maps.remove(tId);\n          }\n        }\n        else {\n          TaskAttemptId tId = maps.keySet().iterator().next();\n          toBeReplaced = maps.remove(tId);          \n        }        \n      }\n      else if (PRIORITY_REDUCE.equals(priority)) {\n        TaskAttemptId tId = reduces.keySet().iterator().next();\n        toBeReplaced = reduces.remove(tId);    \n      }\n      LOG.info(\"Found replacement: \" + toBeReplaced);\n      return toBeReplaced;\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.containerNotAssigned": "    private void containerNotAssigned(Container allocated) {\n      containersReleased++;\n      release(allocated.getId());      \n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat": "  protected synchronized void heartbeat() throws Exception {\n    scheduleStats.updateAndLogIfChanged(\"Before Scheduling: \");\n    List<Container> allocatedContainers = getResources();\n    if (allocatedContainers.size() > 0) {\n      scheduledRequests.assign(allocatedContainers);\n    }\n\n    int completedMaps = getJob().getCompletedMaps();\n    int completedTasks = completedMaps + getJob().getCompletedReduces();\n    if (lastCompletedTasks != completedTasks) {\n      lastCompletedTasks = completedTasks;\n      recalculateReduceSchedule = true;\n    }\n\n    if (recalculateReduceSchedule) {\n      preemptReducesIfNeeded();\n      scheduleReduces(\n          getJob().getTotalMaps(), completedMaps,\n          scheduledRequests.maps.size(), scheduledRequests.reduces.size(), \n          assignedRequests.maps.size(), assignedRequests.reduces.size(),\n          mapResourceReqt, reduceResourceReqt,\n          pendingReduces.size(), \n          maxReduceRampupLimit, reduceSlowStart);\n      recalculateReduceSchedule = false;\n    }\n\n    scheduleStats.updateAndLogIfChanged(\"After Scheduling: \");\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.scheduleReduces": "  public void scheduleReduces(\n      int totalMaps, int completedMaps,\n      int scheduledMaps, int scheduledReduces,\n      int assignedMaps, int assignedReduces,\n      int mapResourceReqt, int reduceResourceReqt,\n      int numPendingReduces,\n      float maxReduceRampupLimit, float reduceSlowStart) {\n    \n    if (numPendingReduces == 0) {\n      return;\n    }\n    \n    int headRoom = getAvailableResources() != null ?\n        getAvailableResources().getMemory() : 0;\n    LOG.info(\"Recalculating schedule, headroom=\" + headRoom);\n    \n    //check for slow start\n    if (!getIsReduceStarted()) {//not set yet\n      int completedMapsForReduceSlowstart = (int)Math.ceil(reduceSlowStart * \n                      totalMaps);\n      if(completedMaps < completedMapsForReduceSlowstart) {\n        LOG.info(\"Reduce slow start threshold not met. \" +\n              \"completedMapsForReduceSlowstart \" + \n            completedMapsForReduceSlowstart);\n        return;\n      } else {\n        LOG.info(\"Reduce slow start threshold reached. Scheduling reduces.\");\n        setIsReduceStarted(true);\n      }\n    }\n    \n    //if all maps are assigned, then ramp up all reduces irrespective of the\n    //headroom\n    if (scheduledMaps == 0 && numPendingReduces > 0) {\n      LOG.info(\"All maps assigned. \" +\n          \"Ramping up all remaining reduces:\" + numPendingReduces);\n      scheduleAllReduces();\n      return;\n    }\n\n    float completedMapPercent = 0f;\n    if (totalMaps != 0) {//support for 0 maps\n      completedMapPercent = (float)completedMaps/totalMaps;\n    } else {\n      completedMapPercent = 1;\n    }\n    \n    int netScheduledMapMem = \n        (scheduledMaps + assignedMaps) * mapResourceReqt;\n\n    int netScheduledReduceMem = \n        (scheduledReduces + assignedReduces) * reduceResourceReqt;\n\n    int finalMapMemLimit = 0;\n    int finalReduceMemLimit = 0;\n    \n    // ramp up the reduces based on completed map percentage\n    int totalMemLimit = getMemLimit();\n    int idealReduceMemLimit = \n        Math.min(\n            (int)(completedMapPercent * totalMemLimit),\n            (int) (maxReduceRampupLimit * totalMemLimit));\n    int idealMapMemLimit = totalMemLimit - idealReduceMemLimit;\n\n    // check if there aren't enough maps scheduled, give the free map capacity\n    // to reduce\n    if (idealMapMemLimit > netScheduledMapMem) {\n      int unusedMapMemLimit = idealMapMemLimit - netScheduledMapMem;\n      finalReduceMemLimit = idealReduceMemLimit + unusedMapMemLimit;\n      finalMapMemLimit = totalMemLimit - finalReduceMemLimit;\n    } else {\n      finalMapMemLimit = idealMapMemLimit;\n      finalReduceMemLimit = idealReduceMemLimit;\n    }\n    \n    LOG.info(\"completedMapPercent \" + completedMapPercent +\n        \" totalMemLimit:\" + totalMemLimit +\n        \" finalMapMemLimit:\" + finalMapMemLimit +\n        \" finalReduceMemLimit:\" + finalReduceMemLimit + \n        \" netScheduledMapMem:\" + netScheduledMapMem +\n        \" netScheduledReduceMem:\" + netScheduledReduceMem);\n    \n    int rampUp = \n        (finalReduceMemLimit - netScheduledReduceMem) / reduceResourceReqt;\n    \n    if (rampUp > 0) {\n      rampUp = Math.min(rampUp, numPendingReduces);\n      LOG.info(\"Ramping up \" + rampUp);\n      rampUpReduces(rampUp);\n    } else if (rampUp < 0){\n      int rampDown = -1 * rampUp;\n      rampDown = Math.min(rampDown, scheduledReduces);\n      LOG.info(\"Ramping down \" + rampDown);\n      rampDownReduces(rampDown);\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.preemptReducesIfNeeded": "  private void preemptReducesIfNeeded() {\n    if (reduceResourceReqt == 0) {\n      return; //no reduces\n    }\n    //check if reduces have taken over the whole cluster and there are \n    //unassigned maps\n    if (scheduledRequests.maps.size() > 0) {\n      int memLimit = getMemLimit();\n      int availableMemForMap = memLimit - ((assignedRequests.reduces.size() -\n          assignedRequests.preemptionWaitingReduces.size()) * reduceResourceReqt);\n      //availableMemForMap must be sufficient to run atleast 1 map\n      if (availableMemForMap < mapResourceReqt) {\n        //to make sure new containers are given to maps and not reduces\n        //ramp down all scheduled reduces if any\n        //(since reduces are scheduled at higher priority than maps)\n        LOG.info(\"Ramping down all scheduled reduces:\" + scheduledRequests.reduces.size());\n        for (ContainerRequest req : scheduledRequests.reduces.values()) {\n          pendingReduces.add(req);\n        }\n        scheduledRequests.reduces.clear();\n        \n        //preempt for making space for atleast one map\n        int premeptionLimit = Math.max(mapResourceReqt, \n            (int) (maxReducePreemptionLimit * memLimit));\n        \n        int preemptMem = Math.min(scheduledRequests.maps.size() * mapResourceReqt, \n            premeptionLimit);\n        \n        int toPreempt = (int) Math.ceil((float) preemptMem/reduceResourceReqt);\n        toPreempt = Math.min(toPreempt, assignedRequests.reduces.size());\n        \n        LOG.info(\"Going to preempt \" + toPreempt);\n        assignedRequests.preemptReduce(toPreempt);\n      }\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources": "  private List<Container> getResources() throws Exception {\n    int headRoom = getAvailableResources() != null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response = makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime = System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime >= retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() != null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn't recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg =\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    int newHeadRoom = getAvailableResources() != null ? getAvailableResources().getMemory() : 0;\n    List<Container> newContainers = response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() != null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n    \n    List<ContainerStatus> finishedContainers = response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() > 0 || headRoom != newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule = true;\n      if (LOG.isDebugEnabled() && headRoom != newHeadRoom) {\n        LOG.debug(\"headroom=\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID = assignedRequests.get(cont.getContainerId());\n      if (attemptID == null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics = StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.updateAndLogIfChanged": "    public void updateAndLogIfChanged(String msgPrefix) {\n      boolean changed = false;\n\n      // synchronized to fix findbug warnings\n      synchronized (RMContainerAllocator.this) {\n        changed |= (numPendingReduces != pendingReduces.size());\n        numPendingReduces = pendingReduces.size();\n        changed |= (numScheduledMaps != scheduledRequests.maps.size());\n        numScheduledMaps = scheduledRequests.maps.size();\n        changed |= (numScheduledReduces != scheduledRequests.reduces.size());\n        numScheduledReduces = scheduledRequests.reduces.size();\n        changed |= (numAssignedMaps != assignedRequests.maps.size());\n        numAssignedMaps = assignedRequests.maps.size();\n        changed |= (numAssignedReduces != assignedRequests.reduces.size());\n        numAssignedReduces = assignedRequests.reduces.size();\n        changed |= (numCompletedMaps != getJob().getCompletedMaps());\n        numCompletedMaps = getJob().getCompletedMaps();\n        changed |= (numCompletedReduces != getJob().getCompletedReduces());\n        numCompletedReduces = getJob().getCompletedReduces();\n        changed |= (numContainersAllocated != containersAllocated);\n        numContainersAllocated = containersAllocated;\n        changed |= (numContainersReleased != containersReleased);\n        numContainersReleased = containersReleased;\n      }\n\n      if (changed) {\n        log(msgPrefix);\n      }\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.run": "      public void run() {\n        while (!stopped.get() && !Thread.currentThread().isInterrupted()) {\n          try {\n            Thread.sleep(rmPollInterval);\n            try {\n              heartbeat();\n            } catch (YarnRuntimeException e) {\n              LOG.error(\"Error communicating with RM: \" + e.getMessage() , e);\n              return;\n            } catch (Exception e) {\n              LOG.error(\"ERROR IN CONTACTING RM. \", e);\n              continue;\n              // TODO: for other exceptions\n            }\n\n            lastHeartbeatTime = context.getClock().getTime();\n            executeHeartbeatCallbacks();\n          } catch (InterruptedException e) {\n            if (!stopped.get()) {\n              LOG.warn(\"Allocated thread interrupted. Returning.\");\n            }\n            return;\n          }\n        }\n      }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.heartbeat": "  protected abstract void heartbeat() throws Exception;\n\n  private void executeHeartbeatCallbacks() {\n    Runnable callback = null;\n    while ((callback = heartbeatCallbacks.poll()) != null) {\n      callback.run();\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.executeHeartbeatCallbacks": "  private void executeHeartbeatCallbacks() {\n    Runnable callback = null;\n    while ((callback = heartbeatCallbacks.poll()) != null) {\n      callback.run();\n    }\n  }"
        },
        "bug_report": {
            "Title": "NPE in RackResolve",
            "Description": "We found a case where our rack resolve script was not returning rack due to problem with resolving host address. This exception was see in RackResolver.java as NPE, ultimately caught in RMContainerAllocator. \n\n{noformat}\n2013-08-01 07:11:37,708 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. \njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:99)\n\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:92)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignMapsWithLocality(RMContainerAllocator.java:1039)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignContainers(RMContainerAllocator.java:925)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:861)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$400(RMContainerAllocator.java:681)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:219)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:243)\n\tat java.lang.Thread.run(Thread.java:722)\n\n{noformat}"
        }
    },
    {
        "filename": "YARN-5837.json",
        "creation_time": "2016-11-04T16:06:59.000+0000",
        "stack_trace": "```\nException in thread \"main\" java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.printNodeStatus(NodeCLI.java:296)\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.run(NodeCLI.java:116)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.main(NodeCLI.java:63)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.cli.NodeCLI.printNodeStatus": "  private void printNodeStatus(String nodeIdStr) throws YarnException,\n      IOException {\n    NodeId nodeId = NodeId.fromString(nodeIdStr);\n    List<NodeReport> nodesReport = client.getNodeReports();\n    // Use PrintWriter.println, which uses correct platform line ending.\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    PrintWriter nodeReportStr = new PrintWriter(\n        new OutputStreamWriter(baos, Charset.forName(\"UTF-8\")));\n    NodeReport nodeReport = null;\n    for (NodeReport report : nodesReport) {\n      if (!report.getNodeId().equals(nodeId)) {\n        continue;\n      }\n      nodeReport = report;\n      nodeReportStr.println(\"Node Report : \");\n      nodeReportStr.print(\"\\tNode-Id : \");\n      nodeReportStr.println(nodeReport.getNodeId());\n      nodeReportStr.print(\"\\tRack : \");\n      nodeReportStr.println(nodeReport.getRackName());\n      nodeReportStr.print(\"\\tNode-State : \");\n      nodeReportStr.println(nodeReport.getNodeState());\n      nodeReportStr.print(\"\\tNode-Http-Address : \");\n      nodeReportStr.println(nodeReport.getHttpAddress());\n      nodeReportStr.print(\"\\tLast-Health-Update : \");\n      nodeReportStr.println(DateFormatUtils.format(\n          new Date(nodeReport.getLastHealthReportTime()),\n            \"E dd/MMM/yy hh:mm:ss:SSzz\"));\n      nodeReportStr.print(\"\\tHealth-Report : \");\n      nodeReportStr\n          .println(nodeReport.getHealthReport());\n      nodeReportStr.print(\"\\tContainers : \");\n      nodeReportStr.println(nodeReport.getNumContainers());\n      nodeReportStr.print(\"\\tMemory-Used : \");\n      nodeReportStr.println((nodeReport.getUsed() == null) ? \"0MB\"\n          : (nodeReport.getUsed().getMemorySize() + \"MB\"));\n      nodeReportStr.print(\"\\tMemory-Capacity : \");\n      nodeReportStr.println(nodeReport.getCapability().getMemorySize() + \"MB\");\n      nodeReportStr.print(\"\\tCPU-Used : \");\n      nodeReportStr.println((nodeReport.getUsed() == null) ? \"0 vcores\"\n          : (nodeReport.getUsed().getVirtualCores() + \" vcores\"));\n      nodeReportStr.print(\"\\tCPU-Capacity : \");\n      nodeReportStr.println(nodeReport.getCapability().getVirtualCores() + \" vcores\");\n      nodeReportStr.print(\"\\tNode-Labels : \");\n      \n      // Create a List for node labels since we need it get sorted\n      List<String> nodeLabelsList =\n          new ArrayList<String>(report.getNodeLabels());\n      Collections.sort(nodeLabelsList);\n      nodeReportStr.println(StringUtils.join(nodeLabelsList.iterator(), ','));\n\n      nodeReportStr.print(\"\\tResource Utilization by Node : \");\n      if (nodeReport.getNodeUtilization() != null) {\n        nodeReportStr.print(\"PMem:\"\n            + nodeReport.getNodeUtilization().getPhysicalMemory()\n            + \" MB, VMem:\" + nodeReport.getNodeUtilization().getVirtualMemory()\n            + \" MB, VCores:\" + nodeReport.getNodeUtilization().getCPU());\n      }\n      nodeReportStr.println();\n\n      nodeReportStr.print(\"\\tResource Utilization by Containers : \");\n      if (nodeReport.getAggregatedContainersUtilization() != null) {\n        nodeReportStr.print(\"PMem:\"\n            + nodeReport.getAggregatedContainersUtilization()\n                .getPhysicalMemory()\n            + \" MB, VMem:\"\n            + nodeReport.getAggregatedContainersUtilization()\n                .getVirtualMemory() + \" MB, VCores:\"\n            + nodeReport.getAggregatedContainersUtilization().getCPU());\n      }\n      nodeReportStr.println();\n    }\n\n    if (nodeReport == null) {\n      nodeReportStr.print(\"Could not find the node report for node id : \"\n          + nodeIdStr);\n    }\n    nodeReportStr.close();\n    sysout.println(baos.toString(\"UTF-8\"));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.cli.NodeCLI.run": "  public int run(String[] args) throws Exception {\n\n    Options opts = new Options();\n    opts.addOption(HELP_CMD, false, \"Displays help for all commands.\");\n    opts.addOption(STATUS_CMD, true, \"Prints the status report of the node.\");\n    opts.addOption(LIST_CMD, false, \"List all running nodes. \" +\n        \"Supports optional use of -states to filter nodes \" +\n        \"based on node state, all -all to list all nodes, \" +\n        \"-showDetails to display more details about each node.\");\n    Option nodeStateOpt = new Option(NODE_STATE_CMD, true,\n        \"Works with -list to filter nodes based on input comma-separated \" +\n        \"list of node states. \" + getAllValidNodeStates());\n    nodeStateOpt.setValueSeparator(',');\n    nodeStateOpt.setArgs(Option.UNLIMITED_VALUES);\n    nodeStateOpt.setArgName(\"States\");\n    opts.addOption(nodeStateOpt);\n    Option allOpt = new Option(NODE_ALL, false,\n        \"Works with -list to list all nodes.\");\n    opts.addOption(allOpt);\n    Option showDetailsOpt = new Option(NODE_SHOW_DETAILS, false,\n        \"Works with -list to show more details about each node.\");\n    opts.addOption(showDetailsOpt);\n    opts.getOption(STATUS_CMD).setArgName(\"NodeId\");\n\n    if (args != null && args.length > 0) {\n      for (int i = args.length - 1; i >= 0; i--) {\n        if (args[i].equalsIgnoreCase(\"-\" + NODE_ALL)) {\n          args[i] = \"-\" + NODE_ALL;\n        }\n      }\n    }\n\n    int exitCode = -1;\n    CommandLine cliParser = null;\n    try {\n      cliParser = new GnuParser().parse(opts, args);\n    } catch (MissingArgumentException ex) {\n      sysout.println(\"Missing argument for options\");\n      printUsage(opts);\n      return exitCode;\n    }\n\n    if (cliParser.hasOption(\"status\")) {\n      if (args.length != 2) {\n        printUsage(opts);\n        return exitCode;\n      }\n      printNodeStatus(cliParser.getOptionValue(\"status\"));\n    } else if (cliParser.hasOption(\"list\")) {\n      Set<NodeState> nodeStates = new HashSet<NodeState>();\n      if (cliParser.hasOption(NODE_ALL)) {\n        for (NodeState state : NodeState.values()) {\n          nodeStates.add(state);\n        }\n      } else if (cliParser.hasOption(NODE_STATE_CMD)) {\n        String[] types = cliParser.getOptionValues(NODE_STATE_CMD);\n        if (types != null) {\n          for (String type : types) {\n            if (!type.trim().isEmpty()) {\n              try {\n                nodeStates.add(NodeState.valueOf(\n                    org.apache.hadoop.util.StringUtils.toUpperCase(\n                            type.trim())));\n              } catch (IllegalArgumentException ex) {\n                sysout.println(\"The node state \" + type + \" is invalid.\");\n                sysout.println(getAllValidNodeStates());\n                return exitCode;\n              }\n            }\n          }\n        }\n      } else {\n        nodeStates.add(NodeState.RUNNING);\n      }\n\n      // List all node details with more information.\n      if (cliParser.hasOption(NODE_SHOW_DETAILS)) {\n        listDetailedClusterNodes(nodeStates);\n      } else {\n        listClusterNodes(nodeStates);\n      }\n    } else if (cliParser.hasOption(HELP_CMD)) {\n      printUsage(opts);\n      return 0;\n    } else {\n      syserr.println(\"Invalid Command Usage : \");\n      printUsage(opts);\n    }\n    return 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.cli.NodeCLI.listDetailedClusterNodes": "  private void listDetailedClusterNodes(Set<NodeState> nodeStates)\n      throws YarnException, IOException {\n    PrintWriter writer = new PrintWriter(new OutputStreamWriter(sysout,\n        Charset.forName(\"UTF-8\")));\n    List<NodeReport> nodesReport = client.getNodeReports(nodeStates\n        .toArray(new NodeState[0]));\n    writer.println(\"Total Nodes:\" + nodesReport.size());\n    writer.printf(NODES_PATTERN, \"Node-Id\", \"Node-State\", \"Node-Http-Address\",\n        \"Number-of-Running-Containers\");\n    for (NodeReport nodeReport : nodesReport) {\n      writer.printf(NODES_PATTERN, nodeReport.getNodeId(),\n          nodeReport.getNodeState(), nodeReport.getHttpAddress(),\n          nodeReport.getNumContainers());\n      writer.println(\"Detailed Node Information :\");\n      writer.print(\"\\tConfigured Resources : \");\n      writer.println(nodeReport.getCapability());\n      writer.print(\"\\tAllocated Resources : \");\n      if (nodeReport.getUsed() != null) {\n        writer.print(nodeReport.getUsed());\n      }\n      writer.println();\n\n      writer.print(\"\\tResource Utilization by Node : \");\n      if (nodeReport.getNodeUtilization() != null) {\n        writer.print(\"PMem:\"\n            + nodeReport.getNodeUtilization().getPhysicalMemory()\n            + \" MB, VMem:\" + nodeReport.getNodeUtilization().getVirtualMemory()\n            + \" MB, VCores:\" + nodeReport.getNodeUtilization().getCPU());\n      }\n      writer.println();\n\n      writer.print(\"\\tResource Utilization by Containers : \");\n      if (nodeReport.getAggregatedContainersUtilization() != null) {\n        writer.print(\"PMem:\"\n            + nodeReport.getAggregatedContainersUtilization()\n                .getPhysicalMemory()\n            + \" MB, VMem:\"\n            + nodeReport.getAggregatedContainersUtilization()\n                .getVirtualMemory() + \" MB, VCores:\"\n            + nodeReport.getAggregatedContainersUtilization().getCPU());\n      }\n      writer.println();\n\n      writer.print(\"\\tNode-Labels : \");\n      // Create a List for node labels since we need it get sorted\n      List<String> nodeLabelsList = new ArrayList<String>(\n          nodeReport.getNodeLabels());\n      Collections.sort(nodeLabelsList);\n      writer.println(StringUtils.join(nodeLabelsList.iterator(), ','));\n    }\n    writer.flush();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.cli.NodeCLI.listClusterNodes": "  private void listClusterNodes(Set<NodeState> nodeStates) \n            throws YarnException, IOException {\n    PrintWriter writer = new PrintWriter(\n        new OutputStreamWriter(sysout, Charset.forName(\"UTF-8\")));\n    List<NodeReport> nodesReport = client.getNodeReports(\n                                       nodeStates.toArray(new NodeState[0]));\n    writer.println(\"Total Nodes:\" + nodesReport.size());\n    writer.printf(NODES_PATTERN, \"Node-Id\", \"Node-State\", \"Node-Http-Address\",\n        \"Number-of-Running-Containers\");\n    for (NodeReport nodeReport : nodesReport) {\n      writer.printf(NODES_PATTERN, nodeReport.getNodeId(), nodeReport\n          .getNodeState(), nodeReport.getHttpAddress(), nodeReport\n          .getNumContainers());\n    }\n    writer.flush();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.cli.NodeCLI.getAllValidNodeStates": "  private String getAllValidNodeStates() {\n    StringBuilder sb = new StringBuilder();\n    sb.append(\"The valid node state can be one of the following: \");\n    for (NodeState state : NodeState.values()) {\n      sb.append(state).append(\",\");\n    }\n    String output = sb.toString();\n    return output.substring(0, output.length() - 1) + \".\";\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.cli.NodeCLI.printUsage": "  private void printUsage(Options opts) {\n    new HelpFormatter().printHelp(\"node\", opts);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ToolRunner.run": "  public static int run(Tool tool, String[] args) \n    throws Exception{\n    return run(tool.getConf(), tool, args);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.cli.NodeCLI.main": "  public static void main(String[] args) throws Exception {\n    NodeCLI cli = new NodeCLI();\n    cli.setSysOutPrintStream(System.out);\n    cli.setSysErrPrintStream(System.err);\n    int res = ToolRunner.run(cli, args);\n    cli.stop();\n    System.exit(res);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.GenericOptionsParser.getRemainingArgs": "  public String[] getRemainingArgs() {\n    return (commandLine == null) ? new String[]{} : commandLine.getArgs();\n  }"
        },
        "bug_report": {
            "Title": "NPE when getting node status of a decommissioned node after an RM restart",
            "Description": "If you decommission a node, the {{yarn node}} command shows it like this:\n{noformat}\n>> bin/yarn node -list -all\n2016-11-04 08:54:37,169 INFO client.RMProxy: Connecting to ResourceManager at 0.0.0.0/0.0.0.0:8032\nTotal Nodes:1\n         Node-Id\t     Node-State\tNode-Http-Address\tNumber-of-Running-Containers\n192.168.1.69:57560\t DECOMMISSIONED\t192.168.1.69:8042\t                           0\n{noformat}\nAnd a full report like this:\n{noformat}\n>> bin/yarn node -status 192.168.1.69:57560\n2016-11-04 08:55:08,928 INFO client.RMProxy: Connecting to ResourceManager at 0.0.0.0/0.0.0.0:8032\nNode Report :\n\tNode-Id : 192.168.1.69:57560\n\tRack : /default-rack\n\tNode-State : DECOMMISSIONED\n\tNode-Http-Address : 192.168.1.69:8042\n\tLast-Health-Update : Fri 04/Nov/16 08:53:58:802PDT\n\tHealth-Report :\n\tContainers : 0\n\tMemory-Used : 0MB\n\tMemory-Capacity : 8192MB\n\tCPU-Used : 0 vcores\n\tCPU-Capacity : 8 vcores\n\tNode-Labels :\n\tResource Utilization by Node :\n\tResource Utilization by Containers : PMem:0 MB, VMem:0 MB, VCores:0.0\n{noformat}\n\nIf you then restart the ResourceManager, you get this report:\n{noformat}\n>> bin/yarn node -list -all\n2016-11-04 08:57:18,512 INFO client.RMProxy: Connecting to ResourceManager at 0.0.0.0/0.0.0.0:8032\nTotal Nodes:4\n         Node-Id\t     Node-State\tNode-Http-Address\tNumber-of-Running-Containers\n 192.168.1.69:-1\t DECOMMISSIONED\t  192.168.1.69:-1\t                           0\n{noformat}\nAnd when you try to get the full report on the now \"-1\" node, you get an NPE:\n{noformat}\n>> bin/yarn node -status 192.168.1.69:-1\n2016-11-04 08:57:57,385 INFO client.RMProxy: Connecting to ResourceManager at 0.0.0.0/0.0.0.0:8032\nException in thread \"main\" java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.printNodeStatus(NodeCLI.java:296)\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.run(NodeCLI.java:116)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.main(NodeCLI.java:63)\n{noformat}"
        }
    },
    {
        "filename": "YARN-6827.json",
        "creation_time": "2017-07-15T05:14:25.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:178)\n\tat org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.putEntity(TimelineServiceV1Publisher.java:368)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities": "  public TimelinePutResponse putEntities(ApplicationAttemptId appAttemptId,\n      TimelineEntityGroupId groupId, TimelineEntity... entities)\n      throws IOException, YarnException {\n    if (Float.compare(this.timelineServiceVersion, 1.5f) != 0) {\n      throw new YarnException(\n        \"This API is not supported under current Timeline Service Version: \"\n            + timelineServiceVersion);\n    }\n\n    return timelineWriter.putEntities(appAttemptId, groupId, entities);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.putEntity": "  private void putEntity(TimelineEntity entity) {\n    try {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Publishing the entity \" + entity.getEntityId()\n            + \", JSON-style content: \"\n            + TimelineUtils.dumpTimelineRecordtoJSON(entity));\n      }\n      client.putEntities(entity);\n    } catch (Exception e) {\n      LOG.error(\"Error when publishing entity [\" + entity.getEntityType() + \",\"\n          + entity.getEntityId() + \"]\", e);\n    }\n  }"
        },
        "bug_report": {
            "Title": "[ATS1/1.5] NPE exception while publishing recovering applications into ATS during RM restart.",
            "Description": "While recovering application, it is observed that NPE exception is thrown as below.\r\n{noformat}\r\n017-07-13 14:08:12,476 ERROR org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher: Error when publishing entity [YARN_APPLICATION,application_1499929227397_0001]\r\njava.lang.NullPointerException\r\n\tat org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:178)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.putEntity(TimelineServiceV1Publisher.java:368)\r\n{noformat}\r\nThis is because in RM service start, active services are started first in Non HA case and later ATSv1 services are started. In HA case, tansitionToActive event has come first before ATS service are started.\r\n\r\nThis gives sufficient time to active services recover the applications which tries to publish into ATSv1 while recovering. Since ATS services are not started yet, it throws NPE."
        }
    },
    {
        "filename": "YARN-3832.json",
        "creation_time": "2015-06-19T13:31:18.000+0000",
        "stack_trace": "```\njava.io.IOException: Rename cannot overwrite non empty destination directory /opt/hdfsdata/HA/nmlocal/usercache/root/filecache/39\nat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:735)\nat org.apache.hadoop.fs.FilterFs.renameInternal(FilterFs.java:244)\nat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:678)\nat org.apache.hadoop.fs.FileContext.rename(FileContext.java:958)\nat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:366)\nat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:62)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.renameInternal": "  public void renameInternal(final Path src, final Path dst,\n      boolean overwrite) throws AccessControlException,\n      FileAlreadyExistsException, FileNotFoundException,\n      ParentNotDirectoryException, UnresolvedLinkException, IOException {\n    // Default implementation deals with overwrite in a non-atomic way\n    final FileStatus srcStatus = getFileLinkStatus(src);\n\n    FileStatus dstStatus;\n    try {\n      dstStatus = getFileLinkStatus(dst);\n    } catch (IOException e) {\n      dstStatus = null;\n    }\n    if (dstStatus != null) {\n      if (dst.equals(src)) {\n        throw new FileAlreadyExistsException(\n            \"The source \"+src+\" and destination \"+dst+\" are the same\");\n      }\n      if (srcStatus.isSymlink() && dst.equals(srcStatus.getSymlink())) {\n        throw new FileAlreadyExistsException(\n            \"Cannot rename symlink \"+src+\" to its target \"+dst);\n      }\n      // It's OK to rename a file to a symlink and vice versa\n      if (srcStatus.isDirectory() != dstStatus.isDirectory()) {\n        throw new IOException(\"Source \" + src + \" and destination \" + dst\n            + \" must both be directories\");\n      }\n      if (!overwrite) {\n        throw new FileAlreadyExistsException(\"Rename destination \" + dst\n            + \" already exists.\");\n      }\n      // Delete the destination that is a file or an empty directory\n      if (dstStatus.isDirectory()) {\n        RemoteIterator<FileStatus> list = listStatusIterator(dst);\n        if (list != null && list.hasNext()) {\n          throw new IOException(\n              \"Rename cannot overwrite non empty destination directory \" + dst);\n        }\n      }\n      delete(dst, false);\n    } else {\n      final Path parent = dst.getParent();\n      final FileStatus parentStatus = getFileStatus(parent);\n      if (parentStatus.isFile()) {\n        throw new ParentNotDirectoryException(\"Rename destination parent \"\n            + parent + \" is a file.\");\n      }\n    }\n    renameInternal(src, dst);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.getFileStatus": "  public abstract FileStatus getFileStatus(final Path f)\n      throws AccessControlException, FileNotFoundException,\n      UnresolvedLinkException, IOException;\n\n  /**\n   * The specification of this method matches that of\n   * {@link FileContext#access(Path, FsAction)}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.hasNext": "      public boolean hasNext() throws IOException {\n        return itor.hasNext();\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.equals": "  public boolean equals(Object other) {\n    if (other == null || !(other instanceof AbstractFileSystem)) {\n      return false;\n    }\n    return myUri.equals(((AbstractFileSystem) other).myUri);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.delete": "  public abstract boolean delete(final Path f, final boolean recursive)\n      throws AccessControlException, FileNotFoundException,\n      UnresolvedLinkException, IOException;\n\n  /**\n   * The specification of this method matches that of\n   * {@link FileContext#open(Path)} except that Path f must be for this",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.listStatusIterator": "  public RemoteIterator<FileStatus> listStatusIterator(final Path f)\n      throws AccessControlException, FileNotFoundException,\n      UnresolvedLinkException, IOException {\n    return new RemoteIterator<FileStatus>() {\n      private int i = 0;\n      private FileStatus[] statusList = listStatus(f);\n      \n      @Override\n      public boolean hasNext() {\n        return i < statusList.length;\n      }\n      \n      @Override\n      public FileStatus next() {\n        if (!hasNext()) {\n          throw new NoSuchElementException();\n        }\n        return statusList[i++];\n      }\n    };\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.getFileLinkStatus": "  public FileStatus getFileLinkStatus(final Path f)\n      throws AccessControlException, FileNotFoundException,\n      UnsupportedFileSystemException, IOException {\n    return getFileStatus(f);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FilterFs.renameInternal": "  public void renameInternal(final Path src, final Path dst,\n      boolean overwrite) throws AccessControlException,\n      FileAlreadyExistsException, FileNotFoundException,\n      ParentNotDirectoryException, UnresolvedLinkException, IOException {\n    myFs.renameInternal(src, dst, overwrite);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FilterFs.checkPath": "  public void checkPath(Path path) {\n    myFs.checkPath(path);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.rename": "  public final void rename(final Path src, final Path dst,\n      final Options.Rename... options) throws AccessControlException,\n      FileAlreadyExistsException, FileNotFoundException,\n      ParentNotDirectoryException, UnresolvedLinkException, IOException {\n    boolean overwrite = false;\n    if (null != options) {\n      for (Rename option : options) {\n        if (option == Rename.OVERWRITE) {\n          overwrite = true;\n        }\n      }\n    }\n    renameInternal(src, dst, overwrite);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.rename": "  public void rename(final Path src, final Path dst,\n      final Options.Rename... options) throws AccessControlException,\n      FileAlreadyExistsException, FileNotFoundException,\n      ParentNotDirectoryException, UnsupportedFileSystemException,\n      IOException {\n    final Path absSrc = fixRelativePart(src);\n    final Path absDst = fixRelativePart(dst);\n    AbstractFileSystem srcFS = getFSofPath(absSrc);\n    AbstractFileSystem dstFS = getFSofPath(absDst);\n    if(!srcFS.getUri().equals(dstFS.getUri())) {\n      throw new IOException(\"Renames across AbstractFileSystems not supported\");\n    }\n    try {\n      srcFS.rename(absSrc, absDst, options);\n    } catch (UnresolvedLinkException e) {\n      /* We do not know whether the source or the destination path\n       * was unresolved. Resolve the source path up until the final\n       * path component, then fully resolve the destination. \n       */\n      final Path source = resolveIntermediate(absSrc);    \n      new FSLinkResolver<Void>() {\n        @Override\n        public Void next(final AbstractFileSystem fs, final Path p) \n          throws IOException, UnresolvedLinkException {\n          fs.rename(source, p, options);\n          return null;\n        }\n      }.resolve(this, absDst);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.getFSofPath": "  protected AbstractFileSystem getFSofPath(final Path absOrFqPath)\n      throws UnsupportedFileSystemException, IOException {\n    absOrFqPath.checkNotSchemeWithRelative();\n    absOrFqPath.checkNotRelative();\n\n    try { \n      // Is it the default FS for this FileContext?\n      defaultFS.checkPath(absOrFqPath);\n      return defaultFS;\n    } catch (Exception e) { // it is different FileSystem\n      return getAbstractFileSystem(ugi, absOrFqPath.toUri(), conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.fixRelativePart": "  Path fixRelativePart(Path p) {\n    if (p.isUriPathAbsolute()) {\n      return p;\n    } else {\n      return new Path(workingDir, p);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.resolve": "  protected Path resolve(final Path f) throws FileNotFoundException,\n      UnresolvedLinkException, AccessControlException, IOException {\n    return new FSLinkResolver<Path>() {\n      @Override\n      public Path next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.resolvePath(p);\n      }\n    }.resolve(this, f);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileContext.resolveIntermediate": "  protected Path resolveIntermediate(final Path f) throws IOException {\n    return new FSLinkResolver<FileStatus>() {\n      @Override\n      public FileStatus next(final AbstractFileSystem fs, final Path p) \n        throws IOException, UnresolvedLinkException {\n        return fs.getFileLinkStatus(p);\n      }\n    }.resolve(this, f).getPath();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.call": "  public Path call() throws Exception {\n    final Path sCopy;\n    try {\n      sCopy = ConverterUtils.getPathFromYarnURL(resource.getResource());\n    } catch (URISyntaxException e) {\n      throw new IOException(\"Invalid resource\", e);\n    }\n    createDir(destDirPath, cachePerms);\n    final Path dst_work = new Path(destDirPath + \"_tmp\");\n    createDir(dst_work, cachePerms);\n    Path dFinal = files.makeQualified(new Path(dst_work, sCopy.getName()));\n    try {\n      Path dTmp = null == userUgi ? files.makeQualified(copy(sCopy, dst_work))\n          : userUgi.doAs(new PrivilegedExceptionAction<Path>() {\n            public Path run() throws Exception {\n              return files.makeQualified(copy(sCopy, dst_work));\n            };\n          });\n      unpack(new File(dTmp.toUri()), new File(dFinal.toUri()));\n      changePermissions(dFinal.getFileSystem(conf), dFinal);\n      files.rename(dst_work, destDirPath, Rename.OVERWRITE);\n    } catch (Exception e) {\n      try {\n        files.delete(destDirPath, true);\n      } catch (IOException ignore) {\n      }\n      throw e;\n    } finally {\n      try {\n        files.delete(dst_work, true);\n      } catch (FileNotFoundException ignore) {\n      }\n      conf = null;\n      resource = null;\n    }\n    return files.makeQualified(new Path(destDirPath, sCopy.getName()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.unpack": "  private long unpack(File localrsrc, File dst) throws IOException {\n    switch (resource.getType()) {\n    case ARCHIVE: {\n      String lowerDst = StringUtils.toLowerCase(dst.getName());\n      if (lowerDst.endsWith(\".jar\")) {\n        RunJar.unJar(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".zip\")) {\n        FileUtil.unZip(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".tar.gz\") ||\n                 lowerDst.endsWith(\".tgz\") ||\n                 lowerDst.endsWith(\".tar\")) {\n        FileUtil.unTar(localrsrc, dst);\n      } else {\n        LOG.warn(\"Cannot unpack \" + localrsrc);\n        if (!localrsrc.renameTo(dst)) {\n            throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + dst + \"]\");\n        }\n      }\n    }\n    break;\n    case PATTERN: {\n      String lowerDst = StringUtils.toLowerCase(dst.getName());\n      if (lowerDst.endsWith(\".jar\")) {\n        String p = resource.getPattern();\n        RunJar.unJar(localrsrc, dst,\n            p == null ? RunJar.MATCH_ANY : Pattern.compile(p));\n        File newDst = new File(dst, dst.getName());\n        if (!dst.exists() && !dst.mkdir()) {\n          throw new IOException(\"Unable to create directory: [\" + dst + \"]\");\n        }\n        if (!localrsrc.renameTo(newDst)) {\n          throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + newDst + \"]\");\n        }\n      } else if (lowerDst.endsWith(\".zip\")) {\n        LOG.warn(\"Treating [\" + localrsrc + \"] as an archive even though it \" +\n        \t\t\"was specified as PATTERN\");\n        FileUtil.unZip(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".tar.gz\") ||\n                 lowerDst.endsWith(\".tgz\") ||\n                 lowerDst.endsWith(\".tar\")) {\n        LOG.warn(\"Treating [\" + localrsrc + \"] as an archive even though it \" +\n        \"was specified as PATTERN\");\n        FileUtil.unTar(localrsrc, dst);\n      } else {\n        LOG.warn(\"Cannot unpack \" + localrsrc);\n        if (!localrsrc.renameTo(dst)) {\n          throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + dst + \"]\");\n        }\n      }\n    }\n    break;\n    case FILE:\n    default:\n      if (!localrsrc.renameTo(dst)) {\n        throw new IOException(\"Unable to rename file: [\" + localrsrc\n          + \"] to [\" + dst + \"]\");\n      }\n      break;\n    }\n    if(localrsrc.isFile()){\n      try {\n        files.delete(new Path(localrsrc.toString()), false);\n      } catch (IOException ignore) {\n      }\n    }\n    return 0;\n    // TODO Should calculate here before returning\n    //return FileUtil.getDU(destDir);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.changePermissions": "  private void changePermissions(FileSystem fs, final Path path)\n      throws IOException, InterruptedException {\n    File f = new File(path.toUri());\n    if (FileUtils.isSymlink(f)) {\n      // avoid following symlinks when changing permissions\n      return;\n    }\n    boolean isDir = f.isDirectory();\n    FsPermission perm = cachePerms;\n    // set public perms as 755 or 555 based on dir or file\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      perm = isDir ? PUBLIC_DIR_PERMS : PUBLIC_FILE_PERMS;\n    }\n    // set private perms as 700 or 500\n    else {\n      // PRIVATE:\n      // APPLICATION:\n      perm = isDir ? PRIVATE_DIR_PERMS : PRIVATE_FILE_PERMS;\n    }\n    LOG.debug(\"Changing permissions for path \" + path\n        + \" to perm \" + perm);\n    final FsPermission fPerm = perm;\n    if (null == userUgi) {\n      files.setPermission(path, perm);\n    }\n    else {\n      userUgi.doAs(new PrivilegedExceptionAction<Void>() {\n        public Void run() throws Exception {\n          files.setPermission(path, fPerm);\n          return null;\n        }\n      });\n    }\n    if (isDir) {\n      FileStatus[] statuses = fs.listStatus(path);\n      for (FileStatus status : statuses) {\n        changePermissions(fs, status.getPath());\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.getResource": "  LocalResource getResource() {\n    return resource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.copy": "  private Path copy(Path sCopy, Path dstdir) throws IOException {\n    FileSystem sourceFs = sCopy.getFileSystem(conf);\n    Path dCopy = new Path(dstdir, \"tmp_\"+sCopy.getName());\n    FileStatus sStat = sourceFs.getFileStatus(sCopy);\n    if (sStat.getModificationTime() != resource.getTimestamp()) {\n      throw new IOException(\"Resource \" + sCopy +\n          \" changed on src filesystem (expected \" + resource.getTimestamp() +\n          \", was \" + sStat.getModificationTime());\n    }\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      if (!isPublic(sourceFs, sCopy, sStat, statCache)) {\n        throw new IOException(\"Resource \" + sCopy +\n            \" is not publicly accessable and as such cannot be part of the\" +\n            \" public cache.\");\n      }\n    }\n\n    FileUtil.copy(sourceFs, sStat, FileSystem.getLocal(conf), dCopy, false,\n        true, conf);\n    return dCopy;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.createDir": "  private void createDir(Path path, FsPermission perm) throws IOException {\n    files.mkdir(path, perm, false);\n    if (!perm.equals(files.getUMask().applyUMask(perm))) {\n      files.setPermission(path, perm);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.getSymlink": "  public Path getSymlink() throws IOException {\n    if (!isSymlink()) {\n      throw new IOException(\"Path \" + path + \" is not a symbolic link\");\n    }\n    return symlink;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.isSymlink": "  public boolean isSymlink() {\n    return symlink != null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.isFile": "  public boolean isFile() {\n    return !isdir && !isSymlink();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.isDirectory": "  public boolean isDirectory() {\n    return isdir;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.getUri": "  public URI getUri() {\n    return myUri;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.AbstractFileSystem.checkScheme": "  public void checkScheme(URI uri, String supportedScheme) {\n    String scheme = uri.getScheme();\n    if (scheme == null) {\n      throw new HadoopIllegalArgumentException(\"Uri without scheme: \" + uri);\n    }\n    if (!scheme.equals(supportedScheme)) {\n      throw new HadoopIllegalArgumentException(\"Uri scheme \" + uri\n          + \" does not match the scheme \" + supportedScheme);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.ConverterUtils.getPathFromYarnURL": "  public static Path getPathFromYarnURL(URL url) throws URISyntaxException {\n    String scheme = url.getScheme() == null ? \"\" : url.getScheme();\n    \n    String authority = \"\";\n    if (url.getHost() != null) {\n      authority = url.getHost();\n      if (url.getUserInfo() != null) {\n        authority = url.getUserInfo() + \"@\" + authority;\n      }\n      if (url.getPort() > 0) {\n        authority += \":\" + url.getPort();\n      }\n    }\n    \n    return new Path(\n        (new URI(scheme, authority, url.getFile(), null, null)).normalize());\n  }"
        },
        "bug_report": {
            "Title": "Resource Localization fails on a cluster due to existing cache directories",
            "Description": " *We have found resource localization fails on a cluster with following error.* \n \nGot this error in hadoop-2.7.0 release which was fixed in 2.6.0 (YARN-2624)\n\n{noformat}\nApplication application_1434703279149_0057 failed 2 times due to AM Container for appattempt_1434703279149_0057_000002 exited with exitCode: -1000\nFor more detailed output, check application tracking page:http://S0559LDPag68:45020/cluster/app/application_1434703279149_0057Then, click on links to logs of each attempt.\nDiagnostics: Rename cannot overwrite non empty destination directory /opt/hdfsdata/HA/nmlocal/usercache/root/filecache/39\njava.io.IOException: Rename cannot overwrite non empty destination directory /opt/hdfsdata/HA/nmlocal/usercache/root/filecache/39\nat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:735)\nat org.apache.hadoop.fs.FilterFs.renameInternal(FilterFs.java:244)\nat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:678)\nat org.apache.hadoop.fs.FileContext.rename(FileContext.java:958)\nat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:366)\nat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:62)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\nFailing this attempt. Failing the application.\n{noformat}"
        }
    },
    {
        "filename": "YARN-2409.json",
        "creation_time": "2014-08-12T10:53:06.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: STATUS_UPDATE at LAUNCHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:697)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:105)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:779)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:760)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_ALLOCATED at LAUNCHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:697)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:105)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:779)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:760)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:662)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getAppAttemptState()) {\n        LOG.info(appAttemptID + \" State change from \" + oldState + \" to \"\n            + getAppAttemptState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      if (initialize) {\n        resetDispatcher();\n        createAndInitActiveServices();\n      }\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          drained = eventQueue.isEmpty();\n          // blockNewEvents is only set when dispatcher is draining to stop,\n          // adding this check is to avoid the overhead of acquiring the lock\n          // and calling notify every time in the normal run of the loop.\n          if (blockNewEvents) {\n            synchronized (waitForDrained) {\n              if (drained) {\n                waitForDrained.notify();\n              }\n            }\n          }\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<String, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  int getEpoch();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Active to StandBy transition does not stop rmDispatcher that causes 1 AsyncDispatcher thread leak. ",
            "Description": "{code}\n\tat java.lang.Thread.run(Thread.java:662)\n2014-08-12 07:03:00,839 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: STATUS_UPDATE at LAUNCHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:697)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:105)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:779)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:760)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:662)\n2014-08-12 07:03:00,839 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_ALLOCATED at LAUNCHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:697)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:105)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:779)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:760)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:662)\n2014-08-12 07:03:00,839 ERROR org.apache.hadoop.ya\n{code}"
        }
    },
    {
        "filename": "YARN-8116.json",
        "creation_time": "2018-04-04T15:30:52.000+0000",
        "stack_trace": "```\njava.lang.NumberFormatException: For input string: \"\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Long.parseLong(Long.java:601)\n\tat java.lang.Long.parseLong(Long.java:631)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainerState(NMLeveldbStateStoreService.java:350)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainersState(NMLeveldbStateStoreService.java:253)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover(ContainerManagerImpl.java:365)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:464)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:899)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:960)\n\njava.lang.NumberFormatException: For input string: \"\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Long.parseLong(Long.java:601)\n\tat java.lang.Long.parseLong(Long.java:631)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainerState(NMLeveldbStateStoreService.java:350)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainersState(NMLeveldbStateStoreService.java:253)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover(ContainerManagerImpl.java:365)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:464)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:899)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:960)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainerState": "  private RecoveredContainerState loadContainerState(ContainerId containerId,\n      LeveldbIterator iter, String keyPrefix) throws IOException {\n    RecoveredContainerState rcs = new RecoveredContainerState();\n    rcs.status = RecoveredContainerStatus.REQUESTED;\n    while (iter.hasNext()) {\n      Entry<byte[],byte[]> entry = iter.peekNext();\n      String key = asString(entry.getKey());\n      if (!key.startsWith(keyPrefix)) {\n        break;\n      }\n      iter.next();\n\n      String suffix = key.substring(keyPrefix.length()-1);  // start with '/'\n      if (suffix.equals(CONTAINER_REQUEST_KEY_SUFFIX)) {\n        rcs.startRequest = new StartContainerRequestPBImpl(\n            StartContainerRequestProto.parseFrom(entry.getValue()));\n      } else if (suffix.equals(CONTAINER_VERSION_KEY_SUFFIX)) {\n        rcs.version = Integer.parseInt(asString(entry.getValue()));\n      } else if (suffix.equals(CONTAINER_START_TIME_KEY_SUFFIX)) {\n        rcs.setStartTime(Long.parseLong(asString(entry.getValue())));\n      } else if (suffix.equals(CONTAINER_DIAGS_KEY_SUFFIX)) {\n        rcs.diagnostics = asString(entry.getValue());\n      } else if (suffix.equals(CONTAINER_QUEUED_KEY_SUFFIX)) {\n        if (rcs.status == RecoveredContainerStatus.REQUESTED) {\n          rcs.status = RecoveredContainerStatus.QUEUED;\n        }\n      } else if (suffix.equals(CONTAINER_PAUSED_KEY_SUFFIX)) {\n        if ((rcs.status == RecoveredContainerStatus.LAUNCHED)\n            ||(rcs.status == RecoveredContainerStatus.QUEUED)\n            ||(rcs.status == RecoveredContainerStatus.REQUESTED)) {\n          rcs.status = RecoveredContainerStatus.PAUSED;\n        }\n      } else if (suffix.equals(CONTAINER_LAUNCHED_KEY_SUFFIX)) {\n        if ((rcs.status == RecoveredContainerStatus.REQUESTED)\n            || (rcs.status == RecoveredContainerStatus.QUEUED)\n            ||(rcs.status == RecoveredContainerStatus.PAUSED)) {\n          rcs.status = RecoveredContainerStatus.LAUNCHED;\n        }\n      } else if (suffix.equals(CONTAINER_KILLED_KEY_SUFFIX)) {\n        rcs.killed = true;\n      } else if (suffix.equals(CONTAINER_EXIT_CODE_KEY_SUFFIX)) {\n        rcs.status = RecoveredContainerStatus.COMPLETED;\n        rcs.exitCode = Integer.parseInt(asString(entry.getValue()));\n      } else if (suffix.equals(CONTAINER_UPDATE_TOKEN_SUFFIX)) {\n        ContainerTokenIdentifierProto tokenIdentifierProto =\n            ContainerTokenIdentifierProto.parseFrom(entry.getValue());\n        Token currentToken = rcs.getStartRequest().getContainerToken();\n        Token updatedToken = Token\n            .newInstance(tokenIdentifierProto.toByteArray(),\n                ContainerTokenIdentifier.KIND.toString(),\n                currentToken.getPassword().array(), currentToken.getService());\n        rcs.startRequest.setContainerToken(updatedToken);\n        rcs.capability = new ResourcePBImpl(tokenIdentifierProto.getResource());\n        rcs.version = tokenIdentifierProto.getVersion();\n      } else if (suffix.equals(CONTAINER_REMAIN_RETRIES_KEY_SUFFIX)) {\n        rcs.setRemainingRetryAttempts(\n            Integer.parseInt(asString(entry.getValue())));\n      } else if (suffix.equals(CONTAINER_RESTART_TIMES_SUFFIX)) {\n        String value = asString(entry.getValue());\n        // parse the string format of List<Long>, e.g. [34, 21, 22]\n        String[] unparsedRestartTimes =\n            value.substring(1, value.length() - 1).split(\", \");\n        List<Long> restartTimes = new ArrayList<>();\n        for (String restartTime : unparsedRestartTimes) {\n          restartTimes.add(Long.parseLong(restartTime));\n        }\n        rcs.setRestartTimes(restartTimes);\n      } else if (suffix.equals(CONTAINER_WORK_DIR_KEY_SUFFIX)) {\n        rcs.setWorkDir(asString(entry.getValue()));\n      } else if (suffix.equals(CONTAINER_LOG_DIR_KEY_SUFFIX)) {\n        rcs.setLogDir(asString(entry.getValue()));\n      } else if (suffix.startsWith(CONTAINER_ASSIGNED_RESOURCES_KEY_SUFFIX)) {\n        String resourceType = suffix.substring(\n            CONTAINER_ASSIGNED_RESOURCES_KEY_SUFFIX.length());\n        ResourceMappings.AssignedResources assignedResources =\n            ResourceMappings.AssignedResources.fromBytes(entry.getValue());\n        rcs.getResourceMappings().addAssignedResources(resourceType,\n            assignedResources);\n      } else {\n        LOG.warn(\"the container \" + containerId\n            + \" will be killed because of the unknown key \" + key\n            + \" during recovery.\");\n        containerUnknownKeySuffixes.put(containerId, suffix);\n        rcs.setRecoveryType(RecoveredContainerType.KILL);\n      }\n    }\n    return rcs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainersState": "  public List<RecoveredContainerState> loadContainersState()\n      throws IOException {\n    ArrayList<RecoveredContainerState> containers =\n        new ArrayList<RecoveredContainerState>();\n    ArrayList<ContainerId> containersToRemove =\n              new ArrayList<ContainerId>();\n    LeveldbIterator iter = null;\n    try {\n      iter = new LeveldbIterator(db);\n      iter.seek(bytes(CONTAINERS_KEY_PREFIX));\n\n      while (iter.hasNext()) {\n        Entry<byte[],byte[]> entry = iter.peekNext();\n        String key = asString(entry.getKey());\n        if (!key.startsWith(CONTAINERS_KEY_PREFIX)) {\n          break;\n        }\n\n        int idEndPos = key.indexOf('/', CONTAINERS_KEY_PREFIX.length());\n        if (idEndPos < 0) {\n          throw new IOException(\"Unable to determine container in key: \" + key);\n        }\n        ContainerId containerId = ContainerId.fromString(\n            key.substring(CONTAINERS_KEY_PREFIX.length(), idEndPos));\n        String keyPrefix = key.substring(0, idEndPos+1);\n        RecoveredContainerState rcs = loadContainerState(containerId,\n            iter, keyPrefix);\n        // Don't load container without StartContainerRequest\n        if (rcs.startRequest != null) {\n          containers.add(rcs);\n        } else {\n          containersToRemove.add(containerId);\n        }\n      }\n    } catch (DBException e) {\n      throw new IOException(e);\n    } finally {\n      if (iter != null) {\n        iter.close();\n      }\n    }\n\n    // remove container without StartContainerRequest\n    for (ContainerId containerId : containersToRemove) {\n      LOG.warn(\"Remove container \" + containerId +\n          \" with incomplete records\");\n      try {\n        removeContainer(containerId);\n        // TODO: kill and cleanup the leaked container\n      } catch (IOException e) {\n        LOG.error(\"Unable to remove container \" + containerId +\n            \" in store\", e);\n      }\n    }\n\n    return containers;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.removeContainer": "  public void removeContainer(ContainerId containerId)\n      throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"removeContainer: containerId=\" + containerId);\n    }\n\n    String keyPrefix = CONTAINERS_KEY_PREFIX + containerId.toString();\n    try {\n      WriteBatch batch = db.createWriteBatch();\n      try {\n        batch.delete(bytes(keyPrefix + CONTAINER_REQUEST_KEY_SUFFIX));\n        batch.delete(bytes(keyPrefix + CONTAINER_DIAGS_KEY_SUFFIX));\n        batch.delete(bytes(keyPrefix + CONTAINER_LAUNCHED_KEY_SUFFIX));\n        batch.delete(bytes(keyPrefix + CONTAINER_QUEUED_KEY_SUFFIX));\n        batch.delete(bytes(keyPrefix + CONTAINER_PAUSED_KEY_SUFFIX));\n        batch.delete(bytes(keyPrefix + CONTAINER_KILLED_KEY_SUFFIX));\n        batch.delete(bytes(keyPrefix + CONTAINER_EXIT_CODE_KEY_SUFFIX));\n        batch.delete(bytes(keyPrefix + CONTAINER_UPDATE_TOKEN_SUFFIX));\n        List<String> unknownKeysForContainer = containerUnknownKeySuffixes\n            .removeAll(containerId);\n        for (String unknownKeySuffix : unknownKeysForContainer) {\n          batch.delete(bytes(keyPrefix + unknownKeySuffix));\n        }\n        db.write(batch);\n      } finally {\n        batch.close();\n      }\n    } catch (DBException e) {\n      markStoreUnHealthy(e);\n      throw new IOException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover": "  private void recover() throws IOException, URISyntaxException {\n    NMStateStoreService stateStore = context.getNMStateStore();\n    if (stateStore.canRecover()) {\n      rsrcLocalizationSrvc.recoverLocalizedResources(\n          stateStore.loadLocalizationState());\n\n      RecoveredApplicationsState appsState = stateStore.loadApplicationsState();\n      for (ContainerManagerApplicationProto proto :\n           appsState.getApplications()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Recovering application with state: \" + proto.toString());\n        }\n        recoverApplication(proto);\n      }\n\n      for (RecoveredContainerState rcs : stateStore.loadContainersState()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Recovering container with state: \" + rcs);\n        }\n        recoverContainer(rcs);\n      }\n\n      // Recovery AMRMProxy state after apps and containers are recovered\n      if (this.amrmProxyEnabled) {\n        this.getAMRMProxyService().recover();\n      }\n\n      //Dispatching the RECOVERY_COMPLETED event through the dispatcher\n      //so that all the paused, scheduled and queued containers will\n      //be scheduled for execution on availability of resources.\n      dispatcher.getEventHandler().handle(\n          new ContainerSchedulerEvent(null,\n              ContainerSchedulerEventType.RECOVERY_COMPLETED));\n    } else {\n      LOG.info(\"Not a recoverable state store. Nothing to recover.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recoverContainer": "  private void recoverContainer(RecoveredContainerState rcs)\n      throws IOException {\n    StartContainerRequest req = rcs.getStartRequest();\n    ContainerLaunchContext launchContext = req.getContainerLaunchContext();\n    ContainerTokenIdentifier token;\n    if(rcs.getCapability() != null) {\n      ContainerTokenIdentifier originalToken =\n          BuilderUtils.newContainerTokenIdentifier(req.getContainerToken());\n      token = new ContainerTokenIdentifier(originalToken.getContainerID(),\n          originalToken.getVersion(), originalToken.getNmHostAddress(),\n          originalToken.getApplicationSubmitter(), rcs.getCapability(),\n          originalToken.getExpiryTimeStamp(), originalToken.getMasterKeyId(),\n          originalToken.getRMIdentifier(), originalToken.getPriority(),\n          originalToken.getCreationTime(),\n          originalToken.getLogAggregationContext(),\n          originalToken.getNodeLabelExpression(),\n          originalToken.getContainerType(), originalToken.getExecutionType(),\n          originalToken.getAllocationRequestId(),\n          originalToken.getAllcationTags());\n\n    } else {\n      token = BuilderUtils.newContainerTokenIdentifier(req.getContainerToken());\n    }\n\n    ContainerId containerId = token.getContainerID();\n    ApplicationId appId =\n        containerId.getApplicationAttemptId().getApplicationId();\n\n    LOG.info(\"Recovering \" + containerId + \" in state \" + rcs.getStatus()\n        + \" with exit code \" + rcs.getExitCode());\n\n    Application app = context.getApplications().get(appId);\n    if (app != null) {\n      recoverActiveContainer(app, launchContext, token, rcs);\n      if (rcs.getRecoveryType() == RecoveredContainerType.KILL) {\n        dispatcher.getEventHandler().handle(\n            new ContainerKillEvent(containerId, ContainerExitStatus.ABORTED,\n                \"Due to invalid StateStore info container was killed\"\n                    + \" during recovery\"));\n      }\n    } else {\n      if (rcs.getStatus() != RecoveredContainerStatus.COMPLETED) {\n        LOG.warn(containerId + \" has no corresponding application!\");\n      }\n      LOG.info(\"Adding \" + containerId + \" to recently stopped containers\");\n      nodeStatusUpdater.addCompletedContainer(containerId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.getAMRMProxyService": "  public AMRMProxyService getAMRMProxyService() {\n    return this.amrmProxyService;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        Application app = this.context.getApplications().get(appID);\n        if (app == null) {\n          LOG.info(\"couldn't find application \" + appID + \" while processing\"\n              + \" FINISH_APPS event. The ResourceManager allocated resources\"\n              + \" for this application to the NodeManager but no active\"\n              + \" containers were found to process.\");\n          continue;\n        }\n\n        boolean shouldDropEvent = false;\n        for (Container container : app.getContainers().values()) {\n          if (container.isRecovering()) {\n            LOG.info(\"drop FINISH_APPS event to \" + appID + \" because \"\n                + \"container \" + container.getContainerId()\n                + \" is recovering\");\n            shouldDropEvent = true;\n            break;\n          }\n        }\n        if (shouldDropEvent) {\n          continue;\n        }\n\n        String diagnostic = \"\";\n        if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Application killed on shutdown\";\n        } else if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Application killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                diagnostic));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId containerId : containersFinishedEvent\n          .getContainersToCleanup()) {\n        ApplicationId appId =\n            containerId.getApplicationAttemptId().getApplicationId();\n        Application app = this.context.getApplications().get(appId);\n        if (app == null) {\n          LOG.warn(\"couldn't find app \" + appId + \" while processing\"\n              + \" FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        Container container = app.getContainers().get(containerId);\n        if (container == null) {\n          LOG.warn(\"couldn't find container \" + containerId\n              + \" while processing FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        if (container.isRecovering()) {\n          LOG.info(\"drop FINISH_CONTAINERS event to \" + containerId\n              + \" because container is recovering\");\n          continue;\n        }\n\n        this.dispatcher.getEventHandler().handle(\n              new ContainerKillEvent(containerId,\n                  ContainerExitStatus.KILLED_BY_RESOURCEMANAGER,\n                  \"Container Killed by ResourceManager\"));\n      }\n      break;\n    case UPDATE_CONTAINERS:\n      CMgrUpdateContainersEvent containersDecreasedEvent =\n          (CMgrUpdateContainersEvent) event;\n      for (org.apache.hadoop.yarn.api.records.Container container\n          : containersDecreasedEvent.getContainersToUpdate()) {\n        try {\n          ContainerTokenIdentifier containerTokenIdentifier =\n              BuilderUtils.newContainerTokenIdentifier(\n                  container.getContainerToken());\n          updateContainerInternal(container.getId(),\n              containerTokenIdentifier);\n        } catch (YarnException e) {\n          LOG.error(\"Unable to decrease container resource\", e);\n        } catch (IOException e) {\n          LOG.error(\"Unable to update container resource in store\", e);\n        }\n      }\n      break;\n    case SIGNAL_CONTAINERS:\n      CMgrSignalContainersEvent containersSignalEvent =\n          (CMgrSignalContainersEvent) event;\n      for (SignalContainerRequest request : containersSignalEvent\n          .getContainersToSignal()) {\n        internalSignalToContainer(request, \"ResourceManager\");\n      }\n      break;\n    default:\n        throw new YarnRuntimeException(\n            \"Got an unknown ContainerManagerEvent type: \" + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recoverApplication": "  private void recoverApplication(ContainerManagerApplicationProto p)\n      throws IOException {\n    ApplicationId appId = new ApplicationIdPBImpl(p.getId());\n    Credentials creds = new Credentials();\n    creds.readTokenStorageStream(\n        new DataInputStream(p.getCredentials().newInput()));\n\n    List<ApplicationACLMapProto> aclProtoList = p.getAclsList();\n    Map<ApplicationAccessType, String> acls =\n        new HashMap<ApplicationAccessType, String>(aclProtoList.size());\n    for (ApplicationACLMapProto aclProto : aclProtoList) {\n      acls.put(ProtoUtils.convertFromProtoFormat(aclProto.getAccessType()),\n          aclProto.getAcl());\n    }\n\n    LogAggregationContext logAggregationContext = null;\n    if (p.getLogAggregationContext() != null) {\n      logAggregationContext =\n          new LogAggregationContextPBImpl(p.getLogAggregationContext());\n    }\n\n    FlowContext fc = null;\n    if (p.getFlowContext() != null) {\n      FlowContextProto fcp = p.getFlowContext();\n      fc = new FlowContext(fcp.getFlowName(), fcp.getFlowVersion(),\n          fcp.getFlowRunId());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            \"Recovering Flow context: \" + fc + \" for an application \" + appId);\n      }\n    } else {\n      // in upgrade situations, where there is no prior existing flow context,\n      // default would be used.\n      fc = new FlowContext(TimelineUtils.generateDefaultFlowName(null, appId),\n          YarnConfiguration.DEFAULT_FLOW_VERSION, appId.getClusterTimestamp());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            \"No prior existing flow context found. Using default Flow context: \"\n                + fc + \" for an application \" + appId);\n      }\n    }\n\n    LOG.info(\"Recovering application \" + appId);\n    ApplicationImpl app = new ApplicationImpl(dispatcher, p.getUser(), fc,\n        appId, creds, context, p.getAppLogAggregationInitedTime());\n    context.getApplications().put(appId, app);\n    app.handle(new ApplicationInitEvent(appId, acls, logAggregationContext));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit": "  public void serviceInit(Configuration conf) throws Exception {\n\n    LogHandler logHandler =\n      createLogHandler(conf, this.context, this.deletionService);\n    addIfService(logHandler);\n    dispatcher.register(LogHandlerEventType.class, logHandler);\n    \n    // add the shared cache upload service (it will do nothing if the shared\n    // cache is disabled)\n    SharedCacheUploadService sharedCacheUploader =\n        createSharedCacheUploaderService();\n    addService(sharedCacheUploader);\n    dispatcher.register(SharedCacheUploadEventType.class, sharedCacheUploader);\n\n    createAMRMProxyService(conf);\n\n    waitForContainersOnShutdownMillis =\n        conf.getLong(YarnConfiguration.NM_SLEEP_DELAY_BEFORE_SIGKILL_MS,\n            YarnConfiguration.DEFAULT_NM_SLEEP_DELAY_BEFORE_SIGKILL_MS) +\n        conf.getLong(YarnConfiguration.NM_PROCESS_KILL_WAIT_MS,\n            YarnConfiguration.DEFAULT_NM_PROCESS_KILL_WAIT_MS) +\n        SHUTDOWN_CLEANUP_SLOP_MS;\n\n    super.serviceInit(conf);\n    recover();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createAMRMProxyService": "  protected void createAMRMProxyService(Configuration conf) {\n    this.amrmProxyEnabled =\n        conf.getBoolean(YarnConfiguration.AMRM_PROXY_ENABLED,\n            YarnConfiguration.DEFAULT_AMRM_PROXY_ENABLED) ||\n            conf.getBoolean(YarnConfiguration.DIST_SCHEDULING_ENABLED,\n                YarnConfiguration.DEFAULT_DIST_SCHEDULING_ENABLED);\n\n    if (amrmProxyEnabled) {\n      LOG.info(\"AMRMProxyService is enabled. \"\n          + \"All the AM->RM requests will be intercepted by the proxy\");\n      this.setAMRMProxyService(\n          new AMRMProxyService(this.context, this.dispatcher));\n      addService(this.getAMRMProxyService());\n    } else {\n      LOG.info(\"AMRMProxyService is disabled\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createLogHandler": "  protected LogHandler createLogHandler(Configuration conf, Context context,\n      DeletionService deletionService) {\n    if (conf.getBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED,\n        YarnConfiguration.DEFAULT_LOG_AGGREGATION_ENABLED)) {\n      return new LogAggregationService(this.dispatcher, context,\n          deletionService, dirsHandler);\n    } else {\n      return new NonAggregatingLogHandler(this.dispatcher, deletionService,\n                                          dirsHandler,\n                                          context.getNMStateStore());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.createSharedCacheUploaderService": "  protected SharedCacheUploadService createSharedCacheUploaderService() {\n    return new SharedCacheUploadService();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of {}\", this, e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      LOG.debug(\"Service: {} entered state {}\", getName(), getServiceState());\n\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    LOG.debug(\"noteFailure {}\" + exception);\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service {} failed in state {}\",\n            getName(), failureState, exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": initing services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      service.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    rmWorkPreservingRestartEnabled = conf.getBoolean(YarnConfiguration\n            .RM_WORK_PRESERVING_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_ENABLED);\n\n    try {\n      initAndStartRecoveryStore(conf);\n    } catch (IOException e) {\n      String recoveryDirName = conf.get(YarnConfiguration.NM_RECOVERY_DIR);\n      throw new\n          YarnRuntimeException(\"Unable to initialize recovery directory at \"\n              + recoveryDirName, e);\n    }\n\n    NMContainerTokenSecretManager containerTokenSecretManager =\n        new NMContainerTokenSecretManager(conf, nmStore);\n\n    NMTokenSecretManagerInNM nmTokenSecretManager =\n        new NMTokenSecretManagerInNM(nmStore);\n\n    recoverTokens(nmTokenSecretManager, containerTokenSecretManager);\n    \n    this.aclsManager = new ApplicationACLsManager(conf);\n\n    this.dirsHandler = new LocalDirsHandlerService(metrics);\n\n    boolean isDistSchedulingEnabled =\n        conf.getBoolean(YarnConfiguration.DIST_SCHEDULING_ENABLED,\n            YarnConfiguration.DEFAULT_DIST_SCHEDULING_ENABLED);\n\n    this.context = createNMContext(containerTokenSecretManager,\n        nmTokenSecretManager, nmStore, isDistSchedulingEnabled, conf);\n\n    ResourcePluginManager pluginManager = createResourcePluginManager();\n    pluginManager.initialize(context);\n    ((NMContext)context).setResourcePluginManager(pluginManager);\n\n    ContainerExecutor exec = createContainerExecutor(conf);\n    try {\n      exec.init(context);\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to initialize container executor\", e);\n    }    \n    DeletionService del = createDeletionService(exec);\n    addService(del);\n\n    // NodeManager level dispatcher\n    this.dispatcher = new AsyncDispatcher(\"NM Event dispatcher\");\n\n    nodeHealthChecker =\n        new NodeHealthCheckerService(\n            getNodeHealthScriptRunner(conf), dirsHandler);\n    addService(nodeHealthChecker);\n\n\n    ((NMContext)context).setContainerExecutor(exec);\n    ((NMContext)context).setDeletionService(del);\n\n    nodeLabelsProvider = createNodeLabelsProvider(conf);\n\n    if (null == nodeLabelsProvider) {\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker);\n    } else {\n      addIfService(nodeLabelsProvider);\n      nodeStatusUpdater =\n          createNodeStatusUpdater(context, dispatcher, nodeHealthChecker,\n              nodeLabelsProvider);\n    }\n\n    nodeResourceMonitor = createNodeResourceMonitor();\n    addService(nodeResourceMonitor);\n    ((NMContext) context).setNodeResourceMonitor(nodeResourceMonitor);\n\n    containerManager =\n        createContainerManager(context, exec, del, nodeStatusUpdater,\n        this.aclsManager, dirsHandler);\n    addService(containerManager);\n    ((NMContext) context).setContainerManager(containerManager);\n\n    this.nmLogAggregationStatusTracker = createNMLogAggregationStatusTracker(\n        context);\n    addService(nmLogAggregationStatusTracker);\n    ((NMContext)context).setNMLogAggregationStatusTracker(\n        this.nmLogAggregationStatusTracker);\n\n    WebServer webServer = createWebServer(context, containerManager\n        .getContainersMonitor(), this.aclsManager, dirsHandler);\n    addService(webServer);\n    ((NMContext) context).setWebServer(webServer);\n\n    ((NMContext) context).setQueueableContainerAllocator(\n        new OpportunisticContainerAllocator(\n            context.getContainerTokenSecretManager()));\n\n    dispatcher.register(ContainerManagerEventType.class, containerManager);\n    dispatcher.register(NodeManagerEventType.class, this);\n    addService(dispatcher);\n\n    pauseMonitor = new JvmPauseMonitor();\n    addService(pauseMonitor);\n    metrics.getJvmMetrics().setPauseMonitor(pauseMonitor);\n\n    DefaultMetricsSystem.initialize(\"NodeManager\");\n\n    if (YarnConfiguration.timelineServiceV2Enabled(conf)) {\n      this.nmCollectorService = createNMCollectorService(context);\n      addService(nmCollectorService);\n    }\n\n    // StatusUpdater should be added last so that it get started last \n    // so that we make sure everything is up before registering with RM. \n    addService(nodeStatusUpdater);\n    ((NMContext) context).setNodeStatusUpdater(nodeStatusUpdater);\n    nmStore.setNodeStatusUpdater(nodeStatusUpdater);\n\n    // Do secure login before calling init for added services.\n    try {\n      doSecureLogin();\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed NodeManager login\", e);\n    }\n\n    super.serviceInit(conf);\n    // TODO add local dirs to del\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createContainerExecutor": "  protected ContainerExecutor createContainerExecutor(Configuration conf) {\n    return ReflectionUtils.newInstance(\n        conf.getClass(YarnConfiguration.NM_CONTAINER_EXECUTOR,\n            DefaultContainerExecutor.class, ContainerExecutor.class), conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMCollectorService": "  protected NMCollectorService createNMCollectorService(Context ctxt) {\n    return new NMCollectorService(ctxt);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMContext": "  protected NMContext createNMContext(\n      NMContainerTokenSecretManager containerTokenSecretManager,\n      NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMStateStoreService stateStore, boolean isDistSchedulerEnabled,\n      Configuration conf) {\n    List<ContainerStateTransitionListener> listeners =\n        conf.getInstances(\n            YarnConfiguration.NM_CONTAINER_STATE_TRANSITION_LISTENERS,\n        ContainerStateTransitionListener.class);\n    NMContext nmContext = new NMContext(containerTokenSecretManager,\n        nmTokenSecretManager, dirsHandler, aclsManager, stateStore,\n        isDistSchedulerEnabled, conf);\n    nmContext.setNodeManagerMetrics(metrics);\n    DefaultContainerStateListener defaultListener =\n        new DefaultContainerStateListener();\n    nmContext.setContainerStateTransitionListener(defaultListener);\n    defaultListener.init(nmContext);\n    for (ContainerStateTransitionListener listener : listeners) {\n      listener.init(nmContext);\n      defaultListener.addListener(listener);\n    }\n    return nmContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.recoverTokens": "  private void recoverTokens(NMTokenSecretManagerInNM nmTokenSecretManager,\n      NMContainerTokenSecretManager containerTokenSecretManager)\n          throws IOException {\n    if (nmStore.canRecover()) {\n      nmTokenSecretManager.recover();\n      containerTokenSecretManager.recover();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartRecoveryStore": "  private void initAndStartRecoveryStore(Configuration conf)\n      throws IOException {\n    boolean recoveryEnabled = conf.getBoolean(\n        YarnConfiguration.NM_RECOVERY_ENABLED,\n        YarnConfiguration.DEFAULT_NM_RECOVERY_ENABLED);\n    if (recoveryEnabled) {\n      FileSystem recoveryFs = FileSystem.getLocal(conf);\n      String recoveryDirName = conf.get(YarnConfiguration.NM_RECOVERY_DIR);\n      if (recoveryDirName == null) {\n        throw new IllegalArgumentException(\"Recovery is enabled but \" +\n            YarnConfiguration.NM_RECOVERY_DIR + \" is not set.\");\n      }\n      Path recoveryRoot = new Path(recoveryDirName);\n      recoveryFs.mkdirs(recoveryRoot, new FsPermission((short)0700));\n      nmStore = new NMLeveldbStateStoreService();\n    } else {\n      nmStore = new NMNullStateStoreService();\n    }\n    nmStore.init(conf);\n    nmStore.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeStatusUpdater": "  protected NodeStatusUpdater createNodeStatusUpdater(Context context,\n      Dispatcher dispatcher, NodeHealthCheckerService healthChecker,\n      NodeLabelsProvider nodeLabelsProvider) {\n    return new NodeStatusUpdaterImpl(context, dispatcher, healthChecker,\n        metrics, nodeLabelsProvider);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.init": "    public void init(Context context) {}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createWebServer": "  protected WebServer createWebServer(Context nmContext,\n      ResourceView resourceView, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new WebServer(nmContext, resourceView, aclsManager, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.setNodeStatusUpdater": "    public void setNodeStatusUpdater(NodeStatusUpdater nodeStatusUpdater) {\n      this.nodeStatusUpdater = nodeStatusUpdater;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.doSecureLogin": "  protected void doSecureLogin() throws IOException {\n    SecurityUtil.login(getConfig(), YarnConfiguration.NM_KEYTAB,\n        YarnConfiguration.NM_PRINCIPAL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createContainerManager": "  protected ContainerManagerImpl createContainerManager(Context context,\n      ContainerExecutor exec, DeletionService del,\n      NodeStatusUpdater nodeStatusUpdater, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new ContainerManagerImpl(context, exec, del, nodeStatusUpdater,\n        metrics, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createDeletionService": "  protected DeletionService createDeletionService(ContainerExecutor exec) {\n    return new DeletionService(exec, nmStore);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createResourcePluginManager": "  protected ResourcePluginManager createResourcePluginManager() {\n    return new ResourcePluginManager();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeResourceMonitor": "  protected NodeResourceMonitor createNodeResourceMonitor() {\n    return new NodeResourceMonitorImpl(context);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeLabelsProvider": "  protected NodeLabelsProvider createNodeLabelsProvider(Configuration conf)\n      throws IOException {\n    NodeLabelsProvider provider = null;\n    String providerString =\n        conf.get(YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG, null);\n    if (providerString == null || providerString.trim().length() == 0) {\n      // Seems like Distributed Node Labels configuration is not enabled\n      return provider;\n    }\n    switch (providerString.trim().toLowerCase()) {\n    case YarnConfiguration.CONFIG_NODE_LABELS_PROVIDER:\n      provider = new ConfigurationNodeLabelsProvider();\n      break;\n    case YarnConfiguration.SCRIPT_NODE_LABELS_PROVIDER:\n      provider = new ScriptBasedNodeLabelsProvider();\n      break;\n    default:\n      try {\n        Class<? extends NodeLabelsProvider> labelsProviderClass =\n            conf.getClass(YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG,\n                null, NodeLabelsProvider.class);\n        provider = labelsProviderClass.newInstance();\n      } catch (InstantiationException | IllegalAccessException\n          | RuntimeException e) {\n        LOG.error(\"Failed to create NodeLabelsProvider based on Configuration\",\n            e);\n        throw new IOException(\n            \"Failed to create NodeLabelsProvider : \" + e.getMessage(), e);\n      }\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Distributed Node Labels is enabled\"\n          + \" with provider class as : \" + provider.getClass().toString());\n    }\n    return provider;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.getNodeHealthScriptRunner": "  public static NodeHealthScriptRunner getNodeHealthScriptRunner(Configuration conf) {\n    String nodeHealthScript = \n        conf.get(YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_PATH);\n    if(!NodeHealthScriptRunner.shouldRun(nodeHealthScript)) {\n      LOG.info(\"Node Manager health check script is not available \"\n          + \"or doesn't have execute permission, so not \"\n          + \"starting the node health script runner.\");\n      return null;\n    }\n    long nmCheckintervalTime = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS);\n    long scriptTimeout = conf.getLong(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS,\n        YarnConfiguration.DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS);\n    String[] scriptArgs = conf.getStrings(\n        YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_OPTS, new String[] {});\n    return new NodeHealthScriptRunner(nodeHealthScript,\n        nmCheckintervalTime, scriptTimeout, scriptArgs);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNMLogAggregationStatusTracker": "  private NMLogAggregationStatusTracker createNMLogAggregationStatusTracker(\n      Context ctxt) {\n    return new NMLogAggregationStatusTracker(ctxt);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager": "  private void initAndStartNodeManager(Configuration conf, boolean hasToReboot) {\n    try {\n      // Failed to start if we're a Unix based system but we don't have bash.\n      // Bash is necessary to launch containers under Unix-based systems.\n      if (!Shell.WINDOWS) {\n        if (!Shell.checkIsBashSupported()) {\n          String message =\n              \"Failing NodeManager start since we're on a \"\n                  + \"Unix-based system but bash doesn't seem to be available.\";\n          LOG.error(message);\n          throw new YarnRuntimeException(message);\n        }\n      }\n\n      // Remove the old hook if we are rebooting.\n      if (hasToReboot && null != nodeManagerShutdownHook) {\n        ShutdownHookManager.get().removeShutdownHook(nodeManagerShutdownHook);\n      }\n\n      nodeManagerShutdownHook = new CompositeServiceShutdownHook(this);\n      ShutdownHookManager.get().addShutdownHook(nodeManagerShutdownHook,\n                                                SHUTDOWN_HOOK_PRIORITY);\n      // System exit should be called only when NodeManager is instantiated from\n      // main() funtion\n      this.shouldExitOnShutdownEvent = true;\n      this.init(conf);\n      this.start();\n    } catch (Throwable t) {\n      LOG.error(\"Error starting NodeManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.main": "  public static void main(String[] args) throws IOException {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(NodeManager.class, args, LOG);\n    @SuppressWarnings(\"resource\")\n    NodeManager nodeManager = new NodeManager();\n    Configuration conf = new YarnConfiguration();\n    new GenericOptionsParser(conf, args);\n    nodeManager.initAndStartNodeManager(conf, false);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Logger log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service {}\", service.getName(), e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.init": "  void init(Configuration config);\n\n\n  /**\n   * Start the service.\n   *\n   * The transition MUST be from {@link STATE#INITED} to {@link STATE#STARTED}"
        },
        "bug_report": {
            "Title": "Nodemanager fails with NumberFormatException: For input string: \"\"",
            "Description": "Steps followed.\r\n1) Update nodemanager debug delay config\r\n{code}\r\n<property>\r\n      <name>yarn.nodemanager.delete.debug-delay-sec</name>\r\n      <value>350</value>\r\n    </property>{code}\r\n2) Launch distributed shell application multiple times\r\n{code}\r\n/usr/hdp/current/hadoop-yarn-client/bin/yarn  jar hadoop-yarn-applications-distributedshell-*.jar  -shell_command \"sleep 120\" -num_containers 1 -shell_env YARN_CONTAINER_RUNTIME_TYPE=docker -shell_env YARN_CONTAINER_RUNTIME_DOCKER_IMAGE=centos/httpd-24-centos7:latest -shell_env YARN_CONTAINER_RUNTIME_DOCKER_DELAYED_REMOVAL=true -jar hadoop-yarn-applications-distributedshell-*.jar{code}\r\n3) restart NM\r\n\r\nNodemanager fails to start with below error.\r\n{code}\r\n\r\n{code:title=NM log}\r\n2018-03-23 21:32:14,437 INFO  monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:serviceInit(181)) - ContainersMonitor enabled: true\r\n2018-03-23 21:32:14,439 INFO  logaggregation.LogAggregationService (LogAggregationService.java:serviceInit(130)) - rollingMonitorInterval is set as 3600. The logs will be aggregated every 3600 seconds\r\n2018-03-23 21:32:14,455 INFO  service.AbstractService (AbstractService.java:noteFailure(267)) - Service org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl failed in state INITED\r\njava.lang.NumberFormatException: For input string: \"\"\r\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\r\n\tat java.lang.Long.parseLong(Long.java:601)\r\n\tat java.lang.Long.parseLong(Long.java:631)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainerState(NMLeveldbStateStoreService.java:350)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainersState(NMLeveldbStateStoreService.java:253)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover(ContainerManagerImpl.java:365)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:464)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:899)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:960)\r\n2018-03-23 21:32:14,458 INFO  logaggregation.LogAggregationService (LogAggregationService.java:serviceStop(148)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService waiting for pending aggregation during exit\r\n2018-03-23 21:32:14,460 INFO  service.AbstractService (AbstractService.java:noteFailure(267)) - Service NodeManager failed in state INITED\r\njava.lang.NumberFormatException: For input string: \"\"\r\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\r\n\tat java.lang.Long.parseLong(Long.java:601)\r\n\tat java.lang.Long.parseLong(Long.java:631)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainerState(NMLeveldbStateStoreService.java:350)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainersState(NMLeveldbStateStoreService.java:253)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover(ContainerManagerImpl.java:365)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:464)\r\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:899)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:960)\r\n2018-03-23 21:32:14,463 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NodeManager metrics system...\r\n2018-03-23 21:32:14,464 INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - timeline thread interrupted.\r\n2018-03-23 21:32:14,468 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NodeManager metrics system stopped.\r\n2018-03-23 21:32:14,508 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NodeManager metrics system shutdown complete.{code}"
        }
    },
    {
        "filename": "YARN-8403.json",
        "creation_time": "2018-06-06T22:34:42.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnException: Download and unpack failed\n        at org.apache.hadoop.yarn.util.FSDownload.downloadAndUnpack(FSDownload.java:306)\n        at org.apache.hadoop.yarn.util.FSDownload.verifyAndCopy(FSDownload.java:283)\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:409)\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:66)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: /grid/0/hadoop/yarn/local/filecache/28_tmp/InputDir/input1.txt (Permission denied)\n        at java.io.FileOutputStream.open0(Native Method)\n        at java.io.FileOutputStream.open(FileOutputStream.java:270)\n        at java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:236)\n        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)\n        at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)\n        at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)\n        at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)\n        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)\n        at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)\n        at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1149)\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1038)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:408)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:399)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:381)\n        at org.apache.hadoop.yarn.util.FSDownload.downloadAndUnpack(FSDownload.java:298)\n        ... 9 more\n\njava.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\nCaused by: java.lang.InterruptedException\n        at java.lang.Object.wait(Native Method)\n        at java.lang.Object.wait(Object.java:502)\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\n        ... 5 more\n\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:183)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\nCaused by: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\n        ... 2 more\nCaused by: java.lang.InterruptedException\n        at java.lang.Object.wait(Native Method)\n        at java.lang.Object.wait(Object.java:502)\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\n        ... 5 more\n\njava.io.IOException: Application application_1528246317583_0048 initialization failed (exitCode=-1) with output: null\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:411)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\nCaused by: org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:183)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\n        ... 1 more\nCaused by: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\n        ... 2 more\nCaused by: java.lang.InterruptedException\n        at java.lang.Object.wait(Native Method)\n        at java.lang.Object.wait(Object.java:502)\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.downloadAndUnpack": "  private void downloadAndUnpack(Path source, Path destination)\n      throws YarnException {\n    try {\n      FileSystem sourceFileSystem = source.getFileSystem(conf);\n      FileSystem destinationFileSystem = destination.getFileSystem(conf);\n      if (sourceFileSystem.getFileStatus(source).isDirectory()) {\n        FileUtil.copy(\n            sourceFileSystem, source,\n            destinationFileSystem, destination, false,\n            true, conf);\n      } else {\n        unpack(source, destination, sourceFileSystem, destinationFileSystem);\n      }\n    } catch (Exception e) {\n      throw new YarnException(\"Download and unpack failed\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.unpack": "  private void unpack(Path source, Path destination,\n                      FileSystem sourceFileSystem,\n                      FileSystem destinationFileSystem)\n      throws IOException, InterruptedException, ExecutionException {\n    try (InputStream inputStream = sourceFileSystem.open(source)) {\n      File dst = new File(destination.toUri());\n      String lowerDst = StringUtils.toLowerCase(dst.getName());\n      switch (resource.getType()) {\n      case ARCHIVE:\n        if (lowerDst.endsWith(\".jar\")) {\n          RunJar.unJar(inputStream, dst, RunJar.MATCH_ANY);\n        } else if (lowerDst.endsWith(\".zip\")) {\n          FileUtil.unZip(inputStream, dst);\n        } else if (lowerDst.endsWith(\".tar.gz\") ||\n            lowerDst.endsWith(\".tgz\") ||\n            lowerDst.endsWith(\".tar\")) {\n          FileUtil.unTar(inputStream, dst, lowerDst.endsWith(\"gz\"));\n        } else {\n          LOG.warn(\"Cannot unpack \" + source);\n          try (OutputStream outputStream =\n                   destinationFileSystem.create(destination, true)) {\n            IOUtils.copy(inputStream, outputStream);\n          }\n        }\n        break;\n      case PATTERN:\n        if (lowerDst.endsWith(\".jar\")) {\n          String p = resource.getPattern();\n          if (!dst.exists() && !dst.mkdir()) {\n            throw new IOException(\"Unable to create directory: [\" + dst + \"]\");\n          }\n          RunJar.unJarAndSave(inputStream, dst, source.getName(),\n              p == null ? RunJar.MATCH_ANY : Pattern.compile(p));\n        } else if (lowerDst.endsWith(\".zip\")) {\n          LOG.warn(\"Treating [\" + source + \"] as an archive even though it \" +\n              \"was specified as PATTERN\");\n          FileUtil.unZip(inputStream, dst);\n        } else if (lowerDst.endsWith(\".tar.gz\") ||\n            lowerDst.endsWith(\".tgz\") ||\n            lowerDst.endsWith(\".tar\")) {\n          LOG.warn(\"Treating [\" + source + \"] as an archive even though it \" +\n              \"was specified as PATTERN\");\n          FileUtil.unTar(inputStream, dst, lowerDst.endsWith(\"gz\"));\n        } else {\n          LOG.warn(\"Cannot unpack \" + source);\n          try (OutputStream outputStream =\n                   destinationFileSystem.create(destination, true)) {\n            IOUtils.copy(inputStream, outputStream);\n          }\n        }\n        break;\n      case FILE:\n      default:\n        try (OutputStream outputStream =\n                 destinationFileSystem.create(destination, true)) {\n          IOUtils.copy(inputStream, outputStream);\n        }\n        break;\n      }\n      // TODO Should calculate here before returning\n      //return FileUtil.getDU(destDir);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.getFileStatus": "  private static FileStatus getFileStatus(final FileSystem fs, final Path path,\n      LoadingCache<Path,Future<FileStatus>> statCache) throws IOException {\n    // if the stat cache does not exist, simply query the filesystem\n    if (statCache == null) {\n      return fs.getFileStatus(path);\n    }\n\n    try {\n      // get or load it from the cache\n      return statCache.get(path).get();\n    } catch (ExecutionException e) {\n      Throwable cause = e.getCause();\n      // the underlying exception should normally be IOException\n      if (cause instanceof IOException) {\n        throw (IOException)cause;\n      } else {\n        throw new IOException(cause);\n      }\n    } catch (InterruptedException e) { // should not happen\n      Thread.currentThread().interrupt();\n      throw new IOException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.verifyAndCopy": "  private void verifyAndCopy(Path destination)\n      throws IOException, YarnException {\n    final Path sCopy;\n    try {\n      sCopy = resource.getResource().toPath();\n    } catch (URISyntaxException e) {\n      throw new IOException(\"Invalid resource\", e);\n    }\n    FileSystem sourceFs = sCopy.getFileSystem(conf);\n    FileStatus sStat = sourceFs.getFileStatus(sCopy);\n    if (sStat.getModificationTime() != resource.getTimestamp()) {\n      throw new IOException(\"Resource \" + sCopy +\n          \" changed on src filesystem (expected \" + resource.getTimestamp() +\n          \", was \" + sStat.getModificationTime());\n    }\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      if (!isPublic(sourceFs, sCopy, sStat, statCache)) {\n        throw new IOException(\"Resource \" + sCopy +\n            \" is not publicly accessible and as such cannot be part of the\" +\n            \" public cache.\");\n      }\n    }\n\n    downloadAndUnpack(sCopy, destination);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.isPublic": "  public static boolean isPublic(FileSystem fs, Path current, FileStatus sStat,\n      LoadingCache<Path,Future<FileStatus>> statCache) throws IOException {\n    current = fs.makeQualified(current);\n    //the leaf level file should be readable by others\n    if (!checkPublicPermsForAll(fs, sStat, FsAction.READ_EXECUTE, FsAction.READ)) {\n      return false;\n    }\n\n    if (Shell.WINDOWS && fs instanceof LocalFileSystem) {\n      // Relax the requirement for public cache on LFS on Windows since default\n      // permissions are \"700\" all the way up to the drive letter. In this\n      // model, the only requirement for a user is to give EVERYONE group\n      // permission on the file and the file will be considered public.\n      // This code path is only hit when fs.default.name is file:/// (mainly\n      // in tests).\n      return true;\n    }\n    return ancestorsHaveExecutePermissions(fs, current.getParent(), statCache);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.getResource": "  LocalResource getResource() {\n    return resource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.call": "  public Path call() throws Exception {\n    final Path sCopy;\n    try {\n      sCopy = resource.getResource().toPath();\n    } catch (URISyntaxException e) {\n      throw new IOException(\"Invalid resource\", e);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(String.format(\"Starting to download %s %s %s\",\n          sCopy,\n          resource.getType(),\n          resource.getPattern()));\n    }\n\n    final Path destinationTmp = new Path(destDirPath + \"_tmp\");\n    createDir(destinationTmp, cachePerms);\n    Path dFinal =\n        files.makeQualified(new Path(destinationTmp, sCopy.getName()));\n    try {\n      if (userUgi == null) {\n        verifyAndCopy(dFinal);\n      } else {\n        userUgi.doAs(new PrivilegedExceptionAction<Void>() {\n          @Override\n          public Void run() throws Exception {\n            verifyAndCopy(dFinal);\n            return null;\n          }\n        });\n      }\n      changePermissions(dFinal.getFileSystem(conf), dFinal);\n      files.rename(destinationTmp, destDirPath, Rename.OVERWRITE);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(String.format(\"File has been downloaded to %s from %s\",\n            new Path(destDirPath, sCopy.getName()), sCopy));\n      }\n    } catch (Exception e) {\n      try {\n        files.delete(destDirPath, true);\n      } catch (IOException ignore) {\n      }\n      throw e;\n    } finally {\n      try {\n        files.delete(destinationTmp, true);\n      } catch (FileNotFoundException ignore) {\n      }\n      conf = null;\n      resource = null;\n    }\n    return files.makeQualified(new Path(destDirPath, sCopy.getName()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.changePermissions": "  private void changePermissions(FileSystem fs, final Path path)\n      throws IOException, InterruptedException {\n    File f = new File(path.toUri());\n    if (FileUtils.isSymlink(f)) {\n      // avoid following symlinks when changing permissions\n      return;\n    }\n    boolean isDir = f.isDirectory();\n    FsPermission perm = cachePerms;\n    // set public perms as 755 or 555 based on dir or file\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      perm = isDir ? PUBLIC_DIR_PERMS : PUBLIC_FILE_PERMS;\n    }\n    // set private perms as 700 or 500\n    else {\n      // PRIVATE:\n      // APPLICATION:\n      perm = isDir ? PRIVATE_DIR_PERMS : PRIVATE_FILE_PERMS;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Changing permissions for path \" + path + \" to perm \" + perm);\n    }\n\n    final FsPermission fPerm = perm;\n    if (null == userUgi) {\n      files.setPermission(path, perm);\n    }\n    else {\n      userUgi.doAs(new PrivilegedExceptionAction<Void>() {\n        public Void run() throws Exception {\n          files.setPermission(path, fPerm);\n          return null;\n        }\n      });\n    }\n    if (isDir) {\n      FileStatus[] statuses = fs.listStatus(path);\n      for (FileStatus status : statuses) {\n        changePermissions(fs, status.getPath());\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.createDir": "  private void createDir(Path path, FsPermission perm) throws IOException {\n    files.mkdir(path, perm, false);\n    if (!perm.equals(files.getUMask().applyUMask(perm))) {\n      files.setPermission(path, perm);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode": "  protected OutputStream createOutputStreamWithMode(Path f, boolean append,\n      FsPermission permission) throws IOException {\n    return new LocalFSFileOutputStream(f, append, permission);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.create": "  public FSDataOutputStream create(Path f, FsPermission permission,\n    boolean overwrite, int bufferSize, short replication, long blockSize,\n    Progressable progress) throws IOException {\n\n    FSDataOutputStream out = create(f, overwrite, true, bufferSize, replication,\n        blockSize, progress, permission);\n    return out;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.mkdirs": "  public boolean mkdirs(Path f, FsPermission permission) throws IOException {\n    return mkdirsWithOptionalPermission(f, permission);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.toString": "  public String toString() {\n    return \"LocalFS\";\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.ChecksumFileSystem.create": "  private FSDataOutputStream create(Path f, FsPermission permission,\n      boolean overwrite, boolean createParent, int bufferSize,\n      short replication, long blockSize,\n      Progressable progress) throws IOException {\n    Path parent = f.getParent();\n    if (parent != null) {\n      if (!createParent && !exists(parent)) {\n        throw new FileNotFoundException(\"Parent directory doesn't exist: \"\n            + parent);\n      } else if (!mkdirs(parent)) {\n        throw new IOException(\"Mkdirs failed to create \" + parent\n            + \" (exists=\" + exists(parent) + \", cwd=\" + getWorkingDirectory()\n            + \")\");\n      }\n    }\n    final FSDataOutputStream out;\n    if (writeChecksum) {\n      out = new FSDataOutputStream(\n          new ChecksumFSOutputSummer(this, f, overwrite, bufferSize, replication,\n              blockSize, progress, permission), null);\n    } else {\n      out = fs.create(f, permission, overwrite, bufferSize, replication,\n          blockSize, progress);\n      // remove the checksum file since we aren't writing one\n      Path checkFile = getChecksumFile(f);\n      if (fs.exists(checkFile)) {\n        fs.delete(checkFile, true);\n      }\n    }\n    return out;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.ChecksumFileSystem.delete": "  public boolean delete(Path f, boolean recursive) throws IOException{\n    FileStatus fstatus = null;\n    try {\n      fstatus = fs.getFileStatus(f);\n    } catch(FileNotFoundException e) {\n      return false;\n    }\n    if (fstatus.isDirectory()) {\n      //this works since the crcs are in the same\n      //directories and the files. so we just delete\n      //everything in the underlying filesystem\n      return fs.delete(f, recursive);\n    } else {\n      Path checkFile = getChecksumFile(f);\n      if (fs.exists(checkFile)) {\n        fs.delete(checkFile, true);\n      }\n      return fs.delete(f, true);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.ChecksumFileSystem.getChecksumFile": "  public Path getChecksumFile(Path file) {\n    return new Path(file.getParent(), \".\" + file.getName() + \".crc\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.ChecksumFileSystem.mkdirs": "  public boolean mkdirs(Path f) throws IOException {\n    return fs.mkdirs(f);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.create": "  public FSDataOutputStream create(Path f,\n      FsPermission permission,\n      EnumSet<CreateFlag> flags,\n      int bufferSize,\n      short replication,\n      long blockSize,\n      Progressable progress,\n      ChecksumOpt checksumOpt) throws IOException {\n    // Checksum options are ignored by default. The file systems that\n    // implement checksum need to override this method. The full\n    // support is currently only available in DFS.\n    return create(f, permission, flags.contains(CreateFlag.OVERWRITE),\n        bufferSize, replication, blockSize, progress);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.setPermission": "  public void setPermission(Path p, FsPermission permission\n      ) throws IOException {\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getDefaultBlockSize": "  public long getDefaultBlockSize(Path f) {\n    return getDefaultBlockSize();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getDefaultReplication": "  public short getDefaultReplication(Path path) {\n    return getDefaultReplication();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileUtil.copy": "  private static boolean copy(FileSystem srcFS, FileStatus srcStatus,\n                              File dst, boolean deleteSource,\n                              Configuration conf) throws IOException {\n    Path src = srcStatus.getPath();\n    if (srcStatus.isDirectory()) {\n      if (!dst.mkdirs()) {\n        return false;\n      }\n      FileStatus contents[] = srcFS.listStatus(src);\n      for (int i = 0; i < contents.length; i++) {\n        copy(srcFS, contents[i],\n             new File(dst, contents[i].getPath().getName()),\n             deleteSource, conf);\n      }\n    } else {\n      InputStream in = srcFS.open(src);\n      IOUtils.copyBytes(in, new FileOutputStream(dst), conf);\n    }\n    if (deleteSource) {\n      return srcFS.delete(src, true);\n    } else {\n      return true;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileUtil.fullyDelete": "  public static void fullyDelete(FileSystem fs, Path dir)\n  throws IOException {\n    fs.delete(dir, true);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileUtil.checkDest": "  private static Path checkDest(String srcName, FileSystem dstFS, Path dst,\n      boolean overwrite) throws IOException {\n    FileStatus sdst;\n    try {\n      sdst = dstFS.getFileStatus(dst);\n    } catch (FileNotFoundException e) {\n      sdst = null;\n    }\n    if (null != sdst) {\n      if (sdst.isDirectory()) {\n        if (null == srcName) {\n          throw new PathIsDirectoryException(dst.toString());\n        }\n        return checkDest(null, dstFS, new Path(dst, srcName), overwrite);\n      } else if (!overwrite) {\n        throw new PathExistsException(dst.toString(),\n            \"Target \" + dst + \" already exists\");\n      }\n    }\n    return dst;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileUtil.canRead": "  public static boolean canRead(File f) {\n    if (Shell.WINDOWS) {\n      try {\n        return NativeIO.Windows.access(f.getCanonicalPath(),\n            NativeIO.Windows.AccessRight.ACCESS_READ);\n      } catch (IOException e) {\n        return false;\n      }\n    } else {\n      return f.canRead();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileUtil.checkDependencies": "  private static void checkDependencies(FileSystem srcFS,\n                                        Path src,\n                                        FileSystem dstFS,\n                                        Path dst)\n                                        throws IOException {\n    if (srcFS == dstFS) {\n      String srcq = srcFS.makeQualified(src).toString() + Path.SEPARATOR;\n      String dstq = dstFS.makeQualified(dst).toString() + Path.SEPARATOR;\n      if (dstq.startsWith(srcq)) {\n        if (srcq.length() == dstq.length()) {\n          throw new IOException(\"Cannot copy \" + src + \" to itself.\");\n        } else {\n          throw new IOException(\"Cannot copy \" + src + \" to its subdirectory \" +\n                                dst);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileUtil.listFiles": "  public static File[] listFiles(File dir) throws IOException {\n    File[] files = dir.listFiles();\n    if(files == null) {\n      throw new IOException(\"Invalid directory or I/O error occurred for dir: \"\n                + dir.toString());\n    }\n    return files;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.runCommand": "  private void runCommand() throws IOException {\n    ProcessBuilder builder = new ProcessBuilder(getExecString());\n    Timer timeOutTimer = null;\n    ShellTimeoutTimerTask timeoutTimerTask = null;\n    timedOut.set(false);\n    completed.set(false);\n\n    // Remove all env vars from the Builder to prevent leaking of env vars from\n    // the parent process.\n    if (!inheritParentEnv) {\n      builder.environment().clear();\n    }\n\n    if (environment != null) {\n      builder.environment().putAll(this.environment);\n    }\n\n    if (dir != null) {\n      builder.directory(this.dir);\n    }\n\n    builder.redirectErrorStream(redirectErrorStream);\n\n    if (Shell.WINDOWS) {\n      synchronized (WindowsProcessLaunchLock) {\n        // To workaround the race condition issue with child processes\n        // inheriting unintended handles during process launch that can\n        // lead to hangs on reading output and error streams, we\n        // serialize process creation. More info available at:\n        // http://support.microsoft.com/kb/315939\n        process = builder.start();\n      }\n    } else {\n      process = builder.start();\n    }\n\n    waitingThread = Thread.currentThread();\n    CHILD_SHELLS.put(this, null);\n\n    if (timeOutInterval > 0) {\n      timeOutTimer = new Timer(\"Shell command timeout\");\n      timeoutTimerTask = new ShellTimeoutTimerTask(\n          this);\n      //One time scheduling.\n      timeOutTimer.schedule(timeoutTimerTask, timeOutInterval);\n    }\n    final BufferedReader errReader =\n            new BufferedReader(new InputStreamReader(\n                process.getErrorStream(), Charset.defaultCharset()));\n    BufferedReader inReader =\n            new BufferedReader(new InputStreamReader(\n                process.getInputStream(), Charset.defaultCharset()));\n    final StringBuffer errMsg = new StringBuffer();\n\n    // read error and input streams as this would free up the buffers\n    // free the error stream buffer\n    Thread errThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          String line = errReader.readLine();\n          while((line != null) && !isInterrupted()) {\n            errMsg.append(line);\n            errMsg.append(System.getProperty(\"line.separator\"));\n            line = errReader.readLine();\n          }\n        } catch(IOException ioe) {\n          // Its normal to observe a \"Stream closed\" I/O error on\n          // command timeouts destroying the underlying process\n          // so only log a WARN if the command didn't time out\n          if (!isTimedOut()) {\n            LOG.warn(\"Error reading the error stream\", ioe);\n          } else {\n            LOG.debug(\"Error reading the error stream due to shell \"\n                + \"command timeout\", ioe);\n          }\n        }\n      }\n    };\n    try {\n      errThread.start();\n    } catch (IllegalStateException ise) {\n    } catch (OutOfMemoryError oe) {\n      LOG.error(\"Caught \" + oe + \". One possible reason is that ulimit\"\n          + \" setting of 'max user processes' is too low. If so, do\"\n          + \" 'ulimit -u <largerNum>' and try again.\");\n      throw oe;\n    }\n    try {\n      parseExecResult(inReader); // parse the output\n      // clear the input stream buffer\n      String line = inReader.readLine();\n      while(line != null) {\n        line = inReader.readLine();\n      }\n      // wait for the process to finish and check the exit code\n      exitCode  = process.waitFor();\n      // make sure that the error thread exits\n      joinThread(errThread);\n      completed.set(true);\n      //the timeout thread handling\n      //taken care in finally block\n      if (exitCode != 0) {\n        throw new ExitCodeException(exitCode, errMsg.toString());\n      }\n    } catch (InterruptedException ie) {\n      InterruptedIOException iie = new InterruptedIOException(ie.toString());\n      iie.initCause(ie);\n      throw iie;\n    } finally {\n      if (timeOutTimer != null) {\n        timeOutTimer.cancel();\n      }\n      // close the input stream\n      try {\n        // JDK 7 tries to automatically drain the input streams for us\n        // when the process exits, but since close is not synchronized,\n        // it creates a race if we close the stream first and the same\n        // fd is recycled.  the stream draining thread will attempt to\n        // drain that fd!!  it may block, OOM, or cause bizarre behavior\n        // see: https://bugs.openjdk.java.net/browse/JDK-8024521\n        //      issue is fixed in build 7u60\n        InputStream stdout = process.getInputStream();\n        synchronized (stdout) {\n          inReader.close();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Error while closing the input stream\", ioe);\n      }\n      if (!completed.get()) {\n        errThread.interrupt();\n        joinThread(errThread);\n      }\n      try {\n        InputStream stderr = process.getErrorStream();\n        synchronized (stderr) {\n          errReader.close();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Error while closing the error stream\", ioe);\n      }\n      process.destroy();\n      waitingThread = null;\n      CHILD_SHELLS.remove(this);\n      lastTime = Time.monotonicNow();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.parseExecResult": "    protected void parseExecResult(BufferedReader lines) throws IOException {\n      output = new StringBuffer();\n      char[] buf = new char[512];\n      int nRead;\n      while ( (nRead = lines.read(buf, 0, buf.length)) > 0 ) {\n        output.append(buf, 0, nRead);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.close": "    public void close() {\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.joinThread": "  private static void joinThread(Thread t) {\n    while (t.isAlive()) {\n      try {\n        t.join();\n      } catch (InterruptedException ie) {\n        if (LOG.isWarnEnabled()) {\n          LOG.warn(\"Interrupted while joining on: \" + t, ie);\n        }\n        t.interrupt(); // propagate interrupt\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.toString": "    public String toString() {\n      StringBuilder builder = new StringBuilder();\n      String[] args = getExecString();\n      for (String s : args) {\n        if (s.indexOf(' ') >= 0) {\n          builder.append('\"').append(s).append('\"');\n        } else {\n          builder.append(s);\n        }\n        builder.append(' ');\n      }\n      return builder.toString();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.getExecString": "    public String[] getExecString() {\n      return command;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.isTimedOut": "  public boolean isTimedOut() {\n    return timedOut.get();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.run": "    public void run() {\n      Process p = shell.getProcess();\n      try {\n        p.exitValue();\n      } catch (Exception e) {\n        //Process has not terminated.\n        //So check if it has completed\n        //if not just destroy it.\n        if (p != null && !shell.completed.get()) {\n          shell.setTimedOut();\n          p.destroy();\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.setTimedOut": "  private void setTimedOut() {\n    this.timedOut.set(true);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.getProcess": "  public Process getProcess() {\n    return process;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.execute": "    public void execute() throws IOException {\n      for (String s : command) {\n        if (s == null) {\n          throw new IOException(\"(null) entry in command string: \"\n              + StringUtils.join(\" \", command));\n        }\n      }\n      this.run();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation": "  public String executePrivilegedOperation(PrivilegedOperation operation,\n      boolean grabOutput) throws PrivilegedOperationException {\n    return executePrivilegedOperation(null, operation, null, null, grabOutput,\n        false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.getPrivilegedOperationExecutionCommand": "  public String[] getPrivilegedOperationExecutionCommand(List<String>\n      prefixCommands,\n      PrivilegedOperation operation) {\n    List<String> fullCommand = new ArrayList<String>();\n\n    if (prefixCommands != null && !prefixCommands.isEmpty()) {\n      fullCommand.addAll(prefixCommands);\n    }\n\n    fullCommand.add(containerExecutorExe);\n\n    String cliSwitch = operation.getOperationType().getOption();\n\n    if (!cliSwitch.isEmpty()) {\n      fullCommand.add(cliSwitch);\n    }\n\n    fullCommand.addAll(operation.getArguments());\n\n    String[] fullCommandArray =\n        fullCommand.toArray(new String[fullCommand.size()]);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Privileged Execution Command Array: \" +\n          Arrays.toString(fullCommandArray));\n    }\n\n    return fullCommandArray;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer": "  public void startLocalizer(LocalizerStartContext ctx)\n      throws IOException, InterruptedException {\n    Path nmPrivateContainerTokensPath = ctx.getNmPrivateContainerTokens();\n    InetSocketAddress nmAddr = ctx.getNmAddr();\n    String user = ctx.getUser();\n    String appId = ctx.getAppId();\n    String locId = ctx.getLocId();\n    LocalDirsHandlerService dirsHandler = ctx.getDirsHandler();\n    List<String> localDirs = dirsHandler.getLocalDirs();\n    List<String> logDirs = dirsHandler.getLogDirs();\n\n    verifyUsernamePattern(user);\n    String runAsUser = getRunAsUser(user);\n    PrivilegedOperation initializeContainerOp = new PrivilegedOperation(\n        PrivilegedOperation.OperationType.INITIALIZE_CONTAINER);\n    List<String> prefixCommands = new ArrayList<>();\n\n    addSchedPriorityCommand(prefixCommands);\n    initializeContainerOp.appendArgs(\n        runAsUser,\n        user,\n        Integer.toString(\n            PrivilegedOperation.RunAsUserCommand.INITIALIZE_CONTAINER\n                .getValue()),\n        appId,\n        locId,\n        nmPrivateContainerTokensPath.toUri().getPath().toString(),\n        StringUtils.join(PrivilegedOperation.LINUX_FILE_PATH_SEPARATOR,\n            localDirs),\n        StringUtils.join(PrivilegedOperation.LINUX_FILE_PATH_SEPARATOR,\n            logDirs));\n\n    File jvm =                                  // use same jvm as parent\n        new File(new File(System.getProperty(\"java.home\"), \"bin\"), \"java\");\n    initializeContainerOp.appendArgs(jvm.toString());\n    initializeContainerOp.appendArgs(\"-classpath\");\n    initializeContainerOp.appendArgs(System.getProperty(\"java.class.path\"));\n    String javaLibPath = System.getProperty(\"java.library.path\");\n    if (javaLibPath != null) {\n      initializeContainerOp.appendArgs(\"-Djava.library.path=\" + javaLibPath);\n    }\n\n    initializeContainerOp.appendArgs(ContainerLocalizer.getJavaOpts(getConf()));\n\n    List<String> localizerArgs = new ArrayList<>();\n\n    buildMainArgs(localizerArgs, user, appId, locId, nmAddr, localDirs);\n\n    Path containerLogDir = getContainerLogDir(dirsHandler, appId, locId);\n    localizerArgs = replaceWithContainerLogDir(localizerArgs, containerLogDir);\n\n    initializeContainerOp.appendArgs(localizerArgs);\n\n    try {\n      Configuration conf = super.getConf();\n      PrivilegedOperationExecutor privilegedOperationExecutor =\n          getPrivilegedOperationExecutor();\n\n      privilegedOperationExecutor.executePrivilegedOperation(prefixCommands,\n          initializeContainerOp, null, null, false, true);\n\n    } catch (PrivilegedOperationException e) {\n      int exitCode = e.getExitCode();\n      LOG.warn(\"Exit code from container \" + locId + \" startLocalizer is : \"\n          + exitCode, e);\n\n      throw new IOException(\"Application \" + appId + \" initialization failed\" +\n          \" (exitCode=\" + exitCode + \") with output: \" + e.getOutput(), e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getRunAsUser": "  String getRunAsUser(String user) {\n    if (UserGroupInformation.isSecurityEnabled() ||\n        !containerLimitUsers) {\n      return user;\n    } else {\n      return nonsecureLocalUser;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getExitCode": "    public int getExitCode() {\n      return code;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.toString": "    public String toString() {\n      return String.valueOf(code);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getPrivilegedOperationExecutor": "  protected PrivilegedOperationExecutor getPrivilegedOperationExecutor() {\n    return PrivilegedOperationExecutor.getInstance(getConf());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.addSchedPriorityCommand": "  protected void addSchedPriorityCommand(List<String> command) {\n    if (containerSchedPriorityIsSet) {\n      command.addAll(Arrays.asList(\"nice\", \"-n\",\n          Integer.toString(containerSchedPriorityAdjustment)));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getContainerLogDir": "  private Path getContainerLogDir(LocalDirsHandlerService dirsHandler,\n      String appId, String containerId) throws IOException {\n    String relativeContainerLogDir = ContainerLaunch\n        .getRelativeContainerLogDir(appId, containerId);\n\n    return dirsHandler.getLogPathForWrite(relativeContainerLogDir,\n        false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.replaceWithContainerLogDir": "  private List<String> replaceWithContainerLogDir(List<String> commands,\n      Path containerLogDir) {\n    List<String> newCmds = new ArrayList<>(commands.size());\n\n    for (String item : commands) {\n      newCmds.add(item.replace(ApplicationConstants.LOG_DIR_EXPANSION_VAR,\n          containerLogDir.toString()));\n    }\n\n    return newCmds;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.buildMainArgs": "  public void buildMainArgs(List<String> command, String user, String appId,\n      String locId, InetSocketAddress nmAddr, List<String> localDirs) {\n    ContainerLocalizer.buildMainArgs(command, user, appId, locId, nmAddr,\n        localDirs, super.getConf());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.verifyUsernamePattern": "  void verifyUsernamePattern(String user) {\n    if (!UserGroupInformation.isSecurityEnabled() &&\n        !nonsecureLocalUserPattern.matcher(user).matches()) {\n      throw new IllegalArgumentException(\"Invalid user name '\" + user + \"',\" +\n          \" it must match '\" + nonsecureLocalUserPattern.pattern() + \"'\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.run": "    public void run() {\n      dispatcher.getEventHandler().handle(\n          new LocalizationEvent(LocalizationEventType.CACHE_CLEANUP));\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.writeCredentials": "    private void writeCredentials(Path nmPrivateCTokensPath)\n        throws IOException {\n      DataOutputStream tokenOut = null;\n      try {\n        Credentials credentials = context.getCredentials();\n        if (UserGroupInformation.isSecurityEnabled()) {\n          Credentials systemCredentials =\n              getSystemCredentialsSentFromRM(context);\n          if (systemCredentials != null) {\n            credentials = systemCredentials;\n          }\n        }\n\n        FileContext lfs = getLocalFileContext(getConfig());\n        tokenOut =\n            lfs.create(nmPrivateCTokensPath, EnumSet.of(CREATE, OVERWRITE));\n        LOG.info(\"Writing credentials to the nmPrivate file \"\n            + nmPrivateCTokensPath.toString());\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Credentials list in \" + nmPrivateCTokensPath.toString()\n              + \": \");\n          for (Token<? extends TokenIdentifier> tk : credentials\n              .getAllTokens()) {\n            LOG.debug(tk + \" : \" + buildTokenFingerprint(tk));\n          }\n        }\n        if (UserGroupInformation.isSecurityEnabled()) {\n          credentials = new Credentials(credentials);\n          LocalizerTokenIdentifier id = secretManager.createIdentifier();\n          Token<LocalizerTokenIdentifier> localizerToken =\n              new Token<LocalizerTokenIdentifier>(id, secretManager);\n          credentials.addToken(id.getKind(), localizerToken);\n        }\n        credentials.writeTokenStorageToStream(tokenOut);\n      } finally {\n        if (tokenOut != null) {\n          tokenOut.close();\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle": "    public void handle(LocalizerEvent event) {\n      String locId = event.getLocalizerId();\n      switch (event.getType()) {\n      case REQUEST_RESOURCE_LOCALIZATION:\n        // 0) find running localizer or start new thread\n        LocalizerResourceRequestEvent req =\n          (LocalizerResourceRequestEvent)event;\n        switch (req.getVisibility()) {\n        case PUBLIC:\n          publicLocalizer.addResource(req);\n          break;\n        case PRIVATE:\n        case APPLICATION:\n          synchronized (privLocalizers) {\n            LocalizerRunner localizer = privLocalizers.get(locId);\n            if (localizer != null && localizer.killContainerLocalizer.get()) {\n              // Old localizer thread has been stopped, remove it and creates\n              // a new localizer thread.\n              LOG.info(\"New \" + event.getType() + \" localize request for \"\n                  + locId + \", remove old private localizer.\");\n              cleanupPrivLocalizers(locId);\n              localizer = null;\n            }\n            if (null == localizer) {\n              LOG.info(\"Created localizer for \" + locId);\n              localizer = new LocalizerRunner(req.getContext(), locId);\n              privLocalizers.put(locId, localizer);\n              localizer.start();\n            }\n            // 1) propagate event\n            localizer.addResource(req);\n          }\n          break;\n        }\n        break;\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.exists": "  public boolean exists(Path f) throws IOException {\n    try {\n      return getFileStatus(f) != null;\n    } catch (FileNotFoundException e) {\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getFileStatus": "  public abstract FileStatus getFileStatus(Path f) throws IOException;\n\n  /**\n   * Checks if the user can access a path.  The mode specifies which access\n   * checks to perform.  If the requested permissions are granted, then the\n   * method returns normally.  If access is denied, then the method throws an\n   * {@link AccessControlException}.",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.Path.toString": "  public String toString() {\n    // we can't use uri.toString(), which escapes everything, because we want\n    // illegal characters unescaped in the string, for glob processing, etc.\n    StringBuilder buffer = new StringBuilder();\n    if (uri.getScheme() != null) {\n      buffer.append(uri.getScheme());\n      buffer.append(\":\");\n    }\n    if (uri.getAuthority() != null) {\n      buffer.append(\"//\");\n      buffer.append(uri.getAuthority());\n    }\n    if (uri.getPath() != null) {\n      String path = uri.getPath();\n      if (path.indexOf('/')==0 &&\n          hasWindowsDrive(path) &&                // has windows drive\n          uri.getScheme() == null &&              // but no scheme\n          uri.getAuthority() == null)             // or authority\n        path = path.substring(1);                 // remove slash before drive\n      buffer.append(path);\n    }\n    if (uri.getFragment() != null) {\n      buffer.append(\"#\");\n      buffer.append(uri.getFragment());\n    }\n    return buffer.toString();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.Path.hasWindowsDrive": "  private static boolean hasWindowsDrive(String path) {\n    return (WINDOWS && HAS_DRIVE_LETTER_SPECIFIER.matcher(path).find());\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.Path.getName": "  public String getName() {\n    String path = uri.getPath();\n    int slash = path.lastIndexOf(SEPARATOR);\n    return path.substring(slash+1);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileStatus.isDirectory": "  public boolean isDirectory() {\n    return isdir;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Time.monotonicNow": "  public static long monotonicNow() {\n    return System.nanoTime() / NANOSECONDS_PER_MILLISECOND;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.StringUtils.join": "  public static String join(char separator, String[] strings) {\n    return join(separator + \"\", strings);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.getLocalDirs": "  public List<String> getLocalDirs() {\n    return localDirs.getGoodDirs();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.getLogDirs": "  public List<String> getLogDirs() {\n    return logDirs.getGoodDirs();\n  }"
        },
        "bug_report": {
            "Title": "Nodemanager logs failed to download file with INFO level",
            "Description": "Some of the container execution related stack traces are printing in INFO or WARN level. \r\n\r\n{code}\r\n2018-06-06 03:10:40,077 INFO  localizer.ResourceLocalizationService (ResourceLocalizationService.java:writeCredentials(1312)) - Writing credentials to the nmPrivate file /grid/0/hadoop/yarn/local/nmPrivate/container_e02_1528246317583_0048_01_000001.tokens\r\n2018-06-06 03:10:40,087 INFO  localizer.ResourceLocalizationService (ResourceLocalizationService.java:run(975)) - Failed to download resource { { hdfs://mycluster.example.com:8020/user/hrt_qa/Streaming/InputDir, 1528254452720, FILE, null },pending,[(container_e02_1528246317583_0048_01_000001)],6074418082915225,DOWNLOADING}\r\norg.apache.hadoop.yarn.exceptions.YarnException: Download and unpack failed\r\n        at org.apache.hadoop.yarn.util.FSDownload.downloadAndUnpack(FSDownload.java:306)\r\n        at org.apache.hadoop.yarn.util.FSDownload.verifyAndCopy(FSDownload.java:283)\r\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:409)\r\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:66)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.io.FileNotFoundException: /grid/0/hadoop/yarn/local/filecache/28_tmp/InputDir/input1.txt (Permission denied)\r\n        at java.io.FileOutputStream.open0(Native Method)\r\n        at java.io.FileOutputStream.open(FileOutputStream.java:270)\r\n        at java.io.FileOutputStream.<init>(FileOutputStream.java:213)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:236)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)\r\n        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)\r\n        at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)\r\n        at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\r\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)\r\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1149)\r\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1038)\r\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:408)\r\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:399)\r\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:381)\r\n        at org.apache.hadoop.yarn.util.FSDownload.downloadAndUnpack(FSDownload.java:298)\r\n        ... 9 more\r\n{code}\r\n\r\n{code}\r\n2018-06-06 03:10:41,547 WARN  privileged.PrivilegedOperationExecutor (PrivilegedOperationExecutor.java:executePrivilegedOperation(182)) - IOException executing command:\r\njava.io.InterruptedIOException: java.lang.InterruptedException\r\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\r\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\r\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\r\nCaused by: java.lang.InterruptedException\r\n        at java.lang.Object.wait(Native Method)\r\n        at java.lang.Object.wait(Object.java:502)\r\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\r\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\r\n        ... 5 more\r\n2018-06-06 03:10:41,548 WARN  nodemanager.LinuxContainerExecutor (LinuxContainerExecutor.java:startLocalizer(407)) - Exit code from container container_e02_1528246317583_0048_01_000001 startLocalizer is : -1\r\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: java.io.InterruptedIOException: java.lang.InterruptedException\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:183)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\r\nCaused by: java.io.InterruptedIOException: java.lang.InterruptedException\r\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\r\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\r\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\r\n        ... 2 more\r\nCaused by: java.lang.InterruptedException\r\n        at java.lang.Object.wait(Native Method)\r\n        at java.lang.Object.wait(Object.java:502)\r\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\r\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\r\n        ... 5 more\r\n2018-06-06 03:10:41,548 INFO  localizer.ResourceLocalizationService (ResourceLocalizationService.java:run(1249)) - Localizer failed for container_e02_1528246317583_0048_01_000001\r\njava.io.IOException: Application application_1528246317583_0048 initialization failed (exitCode=-1) with output: null\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:411)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\r\nCaused by: org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: java.io.InterruptedIOException: java.lang.InterruptedException\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:183)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\r\n... 1 more\r\nCaused by: java.io.InterruptedIOException: java.lang.InterruptedException\r\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\r\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\r\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\r\n        ... 2 more\r\nCaused by: java.lang.InterruptedException\r\n        at java.lang.Object.wait(Native Method)\r\n        at java.lang.Object.wait(Object.java:502)\r\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\r\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\r\n        ... 5 more\r\n{code}\r\n\r\nThese logs are only present in NM. ( It does not show up in AM log) \r\nThese stacktraces are in WARN or INFO level. Ideally, exception should be printed in ERROR log level. "
        }
    },
    {
        "filename": "YARN-1458.json",
        "creation_time": "2013-11-29T03:31:39.000+0000",
        "stack_trace": "```\njava.lang.Thread.State: BLOCKED (on object monitor)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication(FairScheduler.java:671)\n        - waiting to lock <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1023)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:112)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:440)\n        at java.lang.Thread.run(Thread.java:744)\n\njava.lang.Thread.State: RUNNABLE\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getAppWeight(FairScheduler.java:545)\n        - locked <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getWeights(AppSchedulable.java:129)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShare(ComputeFairShares.java:143)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.resourceUsedWithWeightToResourceRatio(ComputeFairShares.java:131)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShares(ComputeFairShares.java:102)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.FairSharePolicy.computeShares(FairSharePolicy.java:119)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.recomputeShares(FSLeafQueue.java:100)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.recomputeShares(FSParentQueue.java:62)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update(FairScheduler.java:282)\n        - locked <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$UpdateThread.run(FairScheduler.java:255)\n        at java.lang.Thread.run(Thread.java:744)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication": "  private synchronized void removeApplication(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState) {\n    LOG.info(\"Application \" + applicationAttemptId + \" is done.\" +\n        \" finalState=\" + rmAppAttemptFinalState);\n\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n\n    if (application == null) {\n      LOG.info(\"Unknown application \" + applicationAttemptId + \" has completed!\");\n      return;\n    }\n\n    // Release all the running containers\n    for (RMContainer rmContainer : application.getLiveContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              SchedulerUtils.COMPLETED_APPLICATION),\n              RMContainerEventType.KILL);\n    }\n\n    // Release all reserved containers\n    for (RMContainer rmContainer : application.getReservedContainers()) {\n      completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              \"Application Complete\"),\n          RMContainerEventType.KILL);\n    }\n\n    // Clean up pending requests, metrics etc.\n    application.stop(rmAppAttemptFinalState);\n\n    // Inform the queue\n    FSLeafQueue queue = queueMgr.getLeafQueue(application.getQueue()\n        .getQueueName(), false);\n    queue.removeApp(application);\n\n    // Remove from our data-structure\n    applications.remove(applicationAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer": "  private synchronized void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n    if (rmContainer == null) {\n      LOG.info(\"Null container completed...\");\n      return;\n    }\n\n    Container container = rmContainer.getContainer();\n\n    // Get the application for the finished container\n    ApplicationAttemptId applicationAttemptId = container.getId().getApplicationAttemptId();\n    FSSchedulerApp application = applications.get(applicationAttemptId);\n    if (application == null) {\n      LOG.info(\"Container \" + container + \" of\" +\n          \" unknown application \" + applicationAttemptId +\n          \" completed with event \" + event);\n      return;\n    }\n\n    // Get the node on which the container was allocated\n    FSSchedulerNode node = nodes.get(container.getNodeId());\n\n    if (rmContainer.getState() == RMContainerState.RESERVED) {\n      application.unreserve(node, rmContainer.getReservedPriority());\n      node.unreserveResource(application);\n    } else {\n      application.containerCompleted(rmContainer, containerStatus, event);\n      node.releaseContainer(container);\n      updateRootQueueMetrics();\n    }\n\n    LOG.info(\"Application \" + applicationAttemptId +\n        \" released container \" + container.getId() +\n        \" on node: \" + node +\n        \" with event: \" + event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent)event;\n      String queue = appAddedEvent.getQueue();\n      addApplication(appAddedEvent.getApplicationAttemptId(), queue,\n          appAddedEvent.getUser());\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationAttemptID(),\n          appRemovedEvent.getFinalAttemptState());\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addNode": "  private synchronized void addNode(RMNode node) {\n    nodes.put(node.getNodeID(), new FSSchedulerNode(node, usePortForNodeName));\n    Resources.addTo(clusterCapacity, node.getTotalCapability());\n    updateRootQueueMetrics();\n\n    LOG.info(\"Added node \" + node.getNodeAddress() +\n        \" cluster capacity: \" + clusterCapacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected synchronized void addApplication(\n      ApplicationAttemptId applicationAttemptId, String queueName, String user) {\n    if (queueName == null || queueName.isEmpty()) {\n      String message = \"Reject application \" + applicationAttemptId +\n              \" submitted by user \" + user + \" with an empty queue name.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppAttemptRejectedEvent(applicationAttemptId, message));\n      return;\n    }\n\n    RMApp rmApp = rmContext.getRMApps().get(\n        applicationAttemptId.getApplicationId());\n    FSLeafQueue queue = assignToQueue(rmApp, queueName, user);\n    if (queue == null) {\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppAttemptRejectedEvent(applicationAttemptId,\n              \"Application rejected by queue placement policy\"));\n      return;\n    }\n\n    FSSchedulerApp schedulerApp =\n        new FSSchedulerApp(applicationAttemptId, user,\n            queue, new ActiveUsersManager(getRootQueueMetrics()),\n            rmContext);\n\n    // Enforce ACLs\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n\n    if (!queue.hasAccess(QueueACL.SUBMIT_APPLICATIONS, userUgi)\n        && !queue.hasAccess(QueueACL.ADMINISTER_QUEUE, userUgi)) {\n      String msg = \"User \" + userUgi.getUserName() +\n    \t        \" cannot submit applications to queue \" + queue.getName();\n      LOG.info(msg);\n      rmContext.getDispatcher().getEventHandler().handle(\n    \t        new RMAppAttemptRejectedEvent(applicationAttemptId, msg));\n      return;\n    }\n\n    queue.addApp(schedulerApp);\n    queue.getMetrics().submitApp(user, applicationAttemptId.getAttemptId());\n\n    applications.put(applicationAttemptId, schedulerApp);\n\n    LOG.info(\"Application Submission: \" + applicationAttemptId +\n        \", user: \"+ user +\n        \", currently active: \" + applications.size());\n\n    rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.APP_ACCEPTED));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getRMContainer": "  private RMContainer getRMContainer(ContainerId containerId) {\n    FSSchedulerApp application = \n        applications.get(containerId.getApplicationAttemptId());\n    return (application == null) ? null : application.getRMContainer(containerId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node = nodes.get(nm.getNodeID());\n\n    // Update resource if any change\n    SchedulerUtils.updateResourceIfChanged(node, nm, clusterCapacity, LOG);\n    \n    List<UpdatedContainerInfo> containerInfoList = nm.pullContainerUpdates();\n    List<ContainerStatus> newlyLaunchedContainers = new ArrayList<ContainerStatus>();\n    List<ContainerStatus> completedContainers = new ArrayList<ContainerStatus>();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeNode": "  private synchronized void removeNode(RMNode rmNode) {\n    FSSchedulerNode node = nodes.get(rmNode.getNodeID());\n    // This can occur when an UNHEALTHY node reconnects\n    if (node == null) {\n      return;\n    }\n    Resources.subtractFrom(clusterCapacity, rmNode.getTotalCapability());\n    updateRootQueueMetrics();\n\n    // Remove running containers\n    List<RMContainer> runningContainers = node.getRunningContainers();\n    for (RMContainer container : runningContainers) {\n      completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    // Remove reservations, if any\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      completedContainer(reservedContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              reservedContainer.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    nodes.remove(rmNode.getNodeID());\n    LOG.info(\"Removed node \" + rmNode.getNodeAddress() +\n        \" cluster capacity: \" + clusterCapacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public void run() {\n\n        SchedulerEvent event;\n\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          try {\n            event = eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.error(\"Returning, interrupted : \" + e);\n            return; // TODO: Kill RM.\n          }\n\n          try {\n            scheduler.handle(event);\n          } catch (Throwable t) {\n            // An error occurred, but we are shutting down anyway.\n            // If it was an InterruptedException, the very act of \n            // shutdown could have caused it and is probably harmless.\n            if (stopped) {\n              LOG.warn(\"Exception during shutdown: \", t);\n              break;\n            }\n            LOG.fatal(\"Error in handling event type \" + event.getType()\n                + \" to the scheduler\", t);\n            if (shouldExitOnError\n                && !ShutdownHookManager.get().isShutdownInProgress()) {\n              LOG.info(\"Exiting, bbye..\");\n              System.exit(-1);\n            }\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getAppWeight": "  public synchronized ResourceWeights getAppWeight(AppSchedulable app) {\n    if (!app.getRunnable()) {\n      // Job won't launch tasks, but don't return 0 to avoid division errors\n      return ResourceWeights.NEUTRAL;\n    } else {\n      double weight = 1.0;\n      if (sizeBasedWeight) {\n        // Set weight based on current memory demand\n        weight = Math.log1p(app.getDemand().getMemory()) / Math.log(2);\n      }\n      weight *= app.getPriority().getPriority();\n      if (weightAdjuster != null) {\n        // Run weight through the user-supplied weightAdjuster\n        weight = weightAdjuster.adjustWeight(app, weight);\n      }\n      return new ResourceWeights((float)weight);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getWeights": "  public ResourceWeights getWeights() {\n    return scheduler.getAppWeight(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShare": "  private static int computeShare(Schedulable sched, double w2rRatio,\n      ResourceType type) {\n    double share = sched.getWeights().getWeight(type) * w2rRatio;\n    share = Math.max(share, getResourceValue(sched.getMinShare(), type));\n    share = Math.min(share, getResourceValue(sched.getMaxShare(), type));\n    return (int) share;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.getResourceValue": "  private static int getResourceValue(Resource resource, ResourceType type) {\n    switch (type) {\n    case MEMORY:\n      return resource.getMemory();\n    case CPU:\n      return resource.getVirtualCores();\n    default:\n      throw new IllegalArgumentException(\"Invalid resource\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.resourceUsedWithWeightToResourceRatio": "  private static int resourceUsedWithWeightToResourceRatio(double w2rRatio,\n      Collection<? extends Schedulable> schedulables, ResourceType type) {\n    int resourcesTaken = 0;\n    for (Schedulable sched : schedulables) {\n      int share = computeShare(sched, w2rRatio, type);\n      resourcesTaken += share;\n    }\n    return resourcesTaken;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShares": "  public static void computeShares(\n      Collection<? extends Schedulable> schedulables, Resource totalResources,\n      ResourceType type) {\n    if (schedulables.isEmpty()) {\n      return;\n    }\n    // Find an upper bound on R that we can use in our binary search. We start\n    // at R = 1 and double it until we have either used all the resources or we\n    // have met all Schedulables' max shares.\n    int totalMaxShare = 0;\n    for (Schedulable sched : schedulables) {\n      int maxShare = getResourceValue(sched.getMaxShare(), type);\n      if (maxShare == Integer.MAX_VALUE) {\n        totalMaxShare = Integer.MAX_VALUE;\n        break;\n      } else {\n        totalMaxShare += maxShare;\n      }\n    }\n    int totalResource = Math.min(totalMaxShare,\n        getResourceValue(totalResources, type));\n    \n    double rMax = 1.0;\n    while (resourceUsedWithWeightToResourceRatio(rMax, schedulables, type)\n        < totalResource) {\n      rMax *= 2.0;\n    }\n    // Perform the binary search for up to COMPUTE_FAIR_SHARES_ITERATIONS steps\n    double left = 0;\n    double right = rMax;\n    for (int i = 0; i < COMPUTE_FAIR_SHARES_ITERATIONS; i++) {\n      double mid = (left + right) / 2.0;\n      if (resourceUsedWithWeightToResourceRatio(mid, schedulables, type) <\n          totalResource) {\n        left = mid;\n      } else {\n        right = mid;\n      }\n    }\n    // Set the fair shares based on the value of R we've converged to\n    for (Schedulable sched : schedulables) {\n      setResourceValue(computeShare(sched, right, type), sched.getFairShare(), type);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.setResourceValue": "  private static void setResourceValue(int val, Resource resource, ResourceType type) {\n    switch (type) {\n    case MEMORY:\n      resource.setMemory(val);\n      break;\n    case CPU:\n      resource.setVirtualCores(val);\n      break;\n    default:\n      throw new IllegalArgumentException(\"Invalid resource\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.FairSharePolicy.computeShares": "  public void computeShares(Collection<? extends Schedulable> schedulables,\n      Resource totalResources) {\n    ComputeFairShares.computeShares(schedulables, totalResources, ResourceType.MEMORY);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.recomputeShares": "  public void recomputeShares() {\n    policy.computeShares(getAppSchedulables(), getFairShare());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.getAppSchedulables": "  public Collection<AppSchedulable> getAppSchedulables() {\n    return appScheds;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.recomputeShares": "  public void recomputeShares() {\n    policy.computeShares(childQueues, getFairShare());\n    for (FSQueue childQueue : childQueues) {\n      childQueue.getMetrics().setFairShare(childQueue.getFairShare());\n      childQueue.recomputeShares();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update": "  protected synchronized void update() {\n    queueMgr.reloadAllocsIfNecessary(); // Relaod alloc file\n    updateRunnability(); // Set job runnability based on user/queue limits\n    updatePreemptionVariables(); // Determine if any queues merit preemption\n\n    FSQueue rootQueue = queueMgr.getRootQueue();\n\n    // Recursively update demands for all queues\n    rootQueue.updateDemand();\n\n    rootQueue.setFairShare(clusterCapacity);\n    // Recursively compute fair shares for all queues\n    // and update metrics\n    rootQueue.recomputeShares();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateRunnability": "  private void updateRunnability() {\n    List<AppSchedulable> apps = new ArrayList<AppSchedulable>();\n\n    // Start by marking everything as not runnable\n    for (FSLeafQueue leafQueue : queueMgr.getLeafQueues()) {\n      for (AppSchedulable a : leafQueue.getAppSchedulables()) {\n        a.setRunnable(false);\n        apps.add(a);\n      }\n    }\n    // Create a list of sorted jobs in order of start time and priority\n    Collections.sort(apps, new FifoAppComparator());\n    // Mark jobs as runnable in order of start time and priority, until\n    // user or queue limits have been reached.\n    Map<String, Integer> userApps = new HashMap<String, Integer>();\n    Map<String, Integer> queueApps = new HashMap<String, Integer>();\n\n    for (AppSchedulable app : apps) {\n      String user = app.getApp().getUser();\n      String queue = app.getApp().getQueueName();\n      int userCount = userApps.containsKey(user) ? userApps.get(user) : 0;\n      int queueCount = queueApps.containsKey(queue) ? queueApps.get(queue) : 0;\n      if (userCount < queueMgr.getUserMaxApps(user) &&\n          queueCount < queueMgr.getQueueMaxApps(queue)) {\n        userApps.put(user, userCount + 1);\n        queueApps.put(queue, queueCount + 1);\n        app.setRunnable(true);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updatePreemptionVariables": "  private void updatePreemptionVariables() {\n    long now = clock.getTime();\n    lastPreemptionUpdateTime = now;\n    for (FSLeafQueue sched : queueMgr.getLeafQueues()) {\n      if (!isStarvedForMinShare(sched)) {\n        sched.setLastTimeAtMinShare(now);\n      }\n      if (!isStarvedForFairShare(sched)) {\n        sched.setLastTimeAtHalfFairShare(now);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.run": "            public void run() {\n              continuousScheduling();\n            }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousScheduling": "  private void continuousScheduling() {\n    while (true) {\n      List<NodeId> nodeIdList = new ArrayList<NodeId>(nodes.keySet());\n      Collections.sort(nodeIdList, nodeAvailableResourceComparator);\n\n      // iterate all nodes\n      for (NodeId nodeId : nodeIdList) {\n        if (nodes.containsKey(nodeId)) {\n          FSSchedulerNode node = nodes.get(nodeId);\n          try {\n            if (Resources.fitsIn(minimumAllocation,\n                    node.getAvailableResource())) {\n              attemptScheduling(node);\n            }\n          } catch (Throwable ex) {\n            LOG.warn(\"Error while attempting scheduling for node \" + node +\n                    \": \" + ex.toString(), ex);\n          }\n        }\n      }\n      try {\n        Thread.sleep(getContinuousSchedulingSleepMs());\n      } catch (InterruptedException e) {\n        LOG.warn(\"Error while doing sleep in continuous scheduling: \" +\n                e.toString(), e);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.preemptTasksIfNecessary": "  protected synchronized void preemptTasksIfNecessary() {\n    if (!preemptionEnabled) {\n      return;\n    }\n\n    long curTime = clock.getTime();\n    if (curTime - lastPreemptCheckTime < preemptionInterval) {\n      return;\n    }\n    lastPreemptCheckTime = curTime;\n\n    Resource resToPreempt = Resources.none();\n\n    for (FSLeafQueue sched : queueMgr.getLeafQueues()) {\n      resToPreempt = Resources.add(resToPreempt, resToPreempt(sched, curTime));\n    }\n    if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity, resToPreempt,\n        Resources.none())) {\n      preemptResources(queueMgr.getLeafQueues(), resToPreempt);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.weightAdjuster.adjustWeight": "  public double adjustWeight(AppSchedulable app, double curWeight);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue.recomputeShares": "  public abstract void recomputeShares();\n  \n  /**\n   * Gets the children of this queue, if any.\n   */\n  public abstract Collection<FSQueue> getChildQueues();\n\n  /**\n   * Helper method to check if the queue should attempt assigning resources\n   * \n   * @return true if check passes (can assign) or false otherwise\n   */\n  protected boolean assignContainerPreCheck(FSSchedulerNode node) {\n    if (!Resources.fitsIn(getResourceUsage(),\n        queueMgr.getMaxResources(getName()))\n        || node.getReservedContainer() != null) {\n      return false;\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue.setFairShare": "  public void setFairShare(Resource fairShare) {\n    super.setFairShare(fairShare);\n    metrics.setFairShare(fairShare);\n  }"
        },
        "bug_report": {
            "Title": "FairScheduler: Zero weight can lead to livelock",
            "Description": "The ResourceManager$SchedulerEventDispatcher$EventProcessor blocked when clients submit lots jobs, it is not easy to reapear. We run the test cluster for days to reapear it. The output of  jstack command on resourcemanager pid:\n{code}\n \"ResourceManager Event Processor\" prio=10 tid=0x00002aaab0c5f000 nid=0x5dd3 waiting for monitor entry [0x0000000043aa9000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication(FairScheduler.java:671)\n        - waiting to lock <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1023)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:112)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:440)\n        at java.lang.Thread.run(Thread.java:744)\n\u2026\u2026\n\"FairSchedulerUpdateThread\" daemon prio=10 tid=0x00002aaab0a2c800 nid=0x5dc8 runnable [0x00000000433a2000]\n   java.lang.Thread.State: RUNNABLE\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getAppWeight(FairScheduler.java:545)\n        - locked <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getWeights(AppSchedulable.java:129)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShare(ComputeFairShares.java:143)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.resourceUsedWithWeightToResourceRatio(ComputeFairShares.java:131)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShares(ComputeFairShares.java:102)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.FairSharePolicy.computeShares(FairSharePolicy.java:119)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.recomputeShares(FSLeafQueue.java:100)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.recomputeShares(FSParentQueue.java:62)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update(FairScheduler.java:282)\n        - locked <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$UpdateThread.run(FairScheduler.java:255)\n        at java.lang.Thread.run(Thread.java:744)\n{code}\n"
        }
    },
    {
        "filename": "YARN-8209.json",
        "creation_time": "2018-04-26T00:22:23.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerClient.writeCommandToTempFile(DockerClient.java:109)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeDockerCommand(DockerCommandExecutor.java:85)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeStatusCommand(DockerCommandExecutor.java:192)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.getContainerStatus(DockerCommandExecutor.java:128)\n\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.removeDockerContainer(LinuxContainerExecutor.java:935)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DockerContainerDeletionTask.run(DockerContainerDeletionTask.java:61)\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\n        at java.lang.Thread.run(Thread.java:748)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerClient.writeCommandToTempFile": "  public String writeCommandToTempFile(DockerCommand cmd, Container container,\n      Context nmContext) throws ContainerExecutionException {\n    ContainerId containerId = container.getContainerId();\n    String filePrefix = containerId.toString();\n    ApplicationId appId = containerId.getApplicationAttemptId()\n        .getApplicationId();\n    File dockerCommandFile;\n    String cmdDir = null;\n\n    if(nmContext == null || nmContext.getLocalDirsHandler() == null) {\n      throw new ContainerExecutionException(\n          \"Unable to write temporary docker command\");\n    }\n\n    try {\n      cmdDir = nmContext.getLocalDirsHandler().getLocalPathForWrite(\n          ResourceLocalizationService.NM_PRIVATE_DIR + Path.SEPARATOR +\n          appId + Path.SEPARATOR + filePrefix + Path.SEPARATOR).toString();\n\n      dockerCommandFile = File.createTempFile(TMP_FILE_PREFIX + filePrefix,\n          TMP_FILE_SUFFIX, new File(cmdDir));\n\n      Writer writer = new OutputStreamWriter(\n          new FileOutputStream(dockerCommandFile.toString()), \"UTF-8\");\n      PrintWriter printWriter = new PrintWriter(writer);\n      printWriter.println(\"[docker-command-execution]\");\n      for (Map.Entry<String, List<String>> entry :\n          cmd.getDockerCommandWithArguments().entrySet()) {\n        if (entry.getKey().contains(\"=\")) {\n          throw new ContainerExecutionException(\n              \"'=' found in entry for docker command file, key = \" + entry\n                  .getKey() + \"; value = \" + entry.getValue());\n        }\n        if (entry.getValue().contains(\"\\n\")) {\n          throw new ContainerExecutionException(\n              \"'\\\\n' found in entry for docker command file, key = \" + entry\n                  .getKey() + \"; value = \" + entry.getValue());\n        }\n        printWriter.println(\"  \" + entry.getKey() + \"=\" + StringUtils\n            .join(\",\", entry.getValue()));\n      }\n      printWriter.close();\n\n      return dockerCommandFile.toString();\n    } catch (IOException e) {\n      LOG.warn(\"Unable to write docker command to \" + cmdDir);\n      throw new ContainerExecutionException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeDockerCommand": "  public static String executeDockerCommand(DockerCommand dockerCommand,\n      String containerId, Map<String, String> env, Configuration conf,\n      PrivilegedOperationExecutor privilegedOperationExecutor,\n      boolean disableFailureLogging, Context nmContext)\n      throws ContainerExecutionException {\n    DockerClient dockerClient = new DockerClient(conf);\n    String commandFile =\n        dockerClient.writeCommandToTempFile(dockerCommand,\n        nmContext.getContainers().get(ContainerId.fromString(containerId)),\n        nmContext);\n    PrivilegedOperation dockerOp = new PrivilegedOperation(\n        PrivilegedOperation.OperationType.RUN_DOCKER_CMD);\n    dockerOp.appendArgs(commandFile);\n    if (disableFailureLogging) {\n      dockerOp.disableFailureLogging();\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Running docker command: \" + dockerCommand);\n    }\n    try {\n      String result = privilegedOperationExecutor\n          .executePrivilegedOperation(null, dockerOp, null,\n              env, true, false);\n      if (result != null && !result.isEmpty()) {\n        result = result.trim();\n      }\n      return result;\n    } catch (PrivilegedOperationException e) {\n      throw new ContainerExecutionException(\"Docker operation failed\",\n          e.getExitCode(), e.getOutput(), e.getErrorOutput());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeStatusCommand": "  private static String executeStatusCommand(String containerId,\n      Configuration conf,\n      PrivilegedOperationExecutor privilegedOperationExecutor,\n      Context nmContext)\n      throws ContainerExecutionException {\n    DockerInspectCommand dockerInspectCommand =\n        new DockerInspectCommand(containerId).getContainerStatus();\n    try {\n      return DockerCommandExecutor.executeDockerCommand(dockerInspectCommand,\n          containerId, null, conf, privilegedOperationExecutor, true,\n          nmContext);\n    } catch (ContainerExecutionException e) {\n      throw new ContainerExecutionException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.getContainerStatus": "  public static DockerContainerStatus getContainerStatus(String containerId,\n      Configuration conf,\n      PrivilegedOperationExecutor privilegedOperationExecutor,\n      Context nmContext) {\n    try {\n      DockerContainerStatus dockerContainerStatus;\n      String currentContainerStatus =\n          executeStatusCommand(containerId, conf,\n          privilegedOperationExecutor, nmContext);\n      if (currentContainerStatus == null) {\n        dockerContainerStatus = DockerContainerStatus.UNKNOWN;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.CREATED.getName())) {\n        dockerContainerStatus = DockerContainerStatus.CREATED;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.RUNNING.getName())) {\n        dockerContainerStatus = DockerContainerStatus.RUNNING;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.STOPPED.getName())) {\n        dockerContainerStatus = DockerContainerStatus.STOPPED;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.RESTARTING.getName())) {\n        dockerContainerStatus = DockerContainerStatus.RESTARTING;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.REMOVING.getName())) {\n        dockerContainerStatus = DockerContainerStatus.REMOVING;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.DEAD.getName())) {\n        dockerContainerStatus = DockerContainerStatus.DEAD;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.EXITED.getName())) {\n        dockerContainerStatus = DockerContainerStatus.EXITED;\n      } else if (currentContainerStatus\n          .equals(DockerContainerStatus.NONEXISTENT.getName())) {\n        dockerContainerStatus = DockerContainerStatus.NONEXISTENT;\n      } else {\n        dockerContainerStatus = DockerContainerStatus.UNKNOWN;\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Container Status: \" + dockerContainerStatus.getName()\n            + \" ContainerId: \" + containerId);\n      }\n      return dockerContainerStatus;\n    } catch (ContainerExecutionException e) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Container Status: \"\n            + DockerContainerStatus.NONEXISTENT.getName()\n            + \" ContainerId: \" + containerId);\n      }\n      return DockerContainerStatus.NONEXISTENT;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.removeDockerContainer": "  public void removeDockerContainer(String containerId) {\n    try {\n      PrivilegedOperationExecutor privOpExecutor =\n          PrivilegedOperationExecutor.getInstance(super.getConf());\n      if (DockerCommandExecutor.isRemovable(\n          DockerCommandExecutor.getContainerStatus(containerId,\n              super.getConf(), privOpExecutor, nmContext))) {\n        LOG.info(\"Removing Docker container : \" + containerId);\n        DockerRmCommand dockerRmCommand = new DockerRmCommand(containerId);\n        DockerCommandExecutor.executeDockerCommand(dockerRmCommand, containerId,\n            null, super.getConf(), privOpExecutor, false, nmContext);\n      }\n    } catch (ContainerExecutionException e) {\n      LOG.warn(\"Unable to remove docker container: \" + containerId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DockerContainerDeletionTask.run": "  public void run() {\n    if (LOG.isDebugEnabled()) {\n      String msg = String.format(\"Running DeletionTask : %s\", toString());\n      LOG.debug(msg);\n    }\n    LinuxContainerExecutor exec = ((LinuxContainerExecutor)\n        getDeletionService().getContainerExecutor());\n    exec.removeDockerContainer(containerId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DockerContainerDeletionTask.toString": "  public String toString() {\n    StringBuffer sb = new StringBuffer(\"DockerContainerDeletionTask : \");\n    sb.append(\"  id : \").append(this.getTaskId());\n    sb.append(\"  containerId : \").append(this.containerId);\n    return sb.toString().trim();\n  }"
        },
        "bug_report": {
            "Title": "NPE in DeletionService",
            "Description": "{code:java}\r\n2018-04-25 23:38:41,039 WARN\u00a0 concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(63)) - Caught exception in thread DeletionService #1:\r\n\r\njava.lang.NullPointerException\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerClient.writeCommandToTempFile(DockerClient.java:109)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeDockerCommand(DockerCommandExecutor.java:85)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeStatusCommand(DockerCommandExecutor.java:192)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.getContainerStatus(DockerCommandExecutor.java:128)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.removeDockerContainer(LinuxContainerExecutor.java:935)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DockerContainerDeletionTask.run(DockerContainerDeletionTask.java:61)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(Thread.java:748){code}"
        }
    },
    {
        "filename": "YARN-3804.json",
        "creation_time": "2015-06-15T08:54:42.000+0000",
        "stack_trace": "```\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:128)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:645)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:518)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Can not execute refreshAdminAcls\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        ... 4 more\nCaused by: org.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User yarn doesn't have permission to call 'refreshAdminAcls'\n        at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:38)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls(AdminService.java:230)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls(AdminService.java:465)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:295)\n        ... 5 more\nCaused by: org.apache.hadoop.security.AccessControlException: User yarn doesn't have permission to call 'refreshAdminAcls'\n        at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.verifyAdminAccess(RMServerUtils.java:182)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.verifyAdminAccess(RMServerUtils.java:148)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess(AdminService.java:223)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls(AdminService.java:228)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive": "  public void becomeActive() throws ServiceFailedException {\n    try {\n      rmContext.getRMAdminService().transitionToActive(req);\n    } catch (Exception e) {\n      throw new ServiceFailedException(\"RM could not transition to Active\", e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeActive": "  private boolean becomeActive() {\n    assert wantToBeInElection;\n    if (state == State.ACTIVE) {\n      // already active\n      return true;\n    }\n    try {\n      Stat oldBreadcrumbStat = fenceOldActive();\n      writeBreadCrumbNode(oldBreadcrumbStat);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming active for \" + this);\n      }\n      appClient.becomeActive();\n      state = State.ACTIVE;\n      return true;\n    } catch (Exception e) {\n      LOG.warn(\"Exception handling the winning of election\", e);\n      // Caller will handle quitting and rejoining the election.\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.writeBreadCrumbNode": "  private void writeBreadCrumbNode(Stat oldBreadcrumbStat)\n      throws KeeperException, InterruptedException {\n    Preconditions.checkState(appData != null, \"no appdata\");\n    \n    LOG.info(\"Writing znode \" + zkBreadCrumbPath +\n        \" to indicate that the local node is the most recent active...\");\n    if (oldBreadcrumbStat == null) {\n      // No previous active, just create the node\n      createWithRetries(zkBreadCrumbPath, appData, zkAcl,\n        CreateMode.PERSISTENT);\n    } else {\n      // There was a previous active, update the node\n      setDataWithRetries(zkBreadCrumbPath, appData, oldBreadcrumbStat.getVersion());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fenceOldActive": "  private Stat fenceOldActive() throws InterruptedException, KeeperException {\n    final Stat stat = new Stat();\n    byte[] data;\n    LOG.info(\"Checking for any old active which needs to be fenced...\");\n    try {\n      data = zkDoWithRetries(new ZKAction<byte[]>() {\n        @Override\n        public byte[] run() throws KeeperException, InterruptedException {\n          return zkClient.getData(zkBreadCrumbPath, false, stat);\n        }\n      });\n    } catch (KeeperException ke) {\n      if (isNodeDoesNotExist(ke.code())) {\n        LOG.info(\"No old node to fence\");\n        return null;\n      }\n      \n      // If we failed to read for any other reason, then likely we lost\n      // our session, or we don't have permissions, etc. In any case,\n      // we probably shouldn't become active, and failing the whole\n      // thing is the best bet.\n      throw ke;\n    }\n\n    LOG.info(\"Old node exists: \" + StringUtils.byteToHexString(data));\n    if (Arrays.equals(data, appData)) {\n      LOG.info(\"But old node has our own data, so don't need to fence it.\");\n    } else {\n      appClient.fenceOldActive(data);\n    }\n    return stat;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.processResult": "  public synchronized void processResult(int rc, String path, Object ctx,\n      Stat stat) {\n    if (isStaleClient(ctx)) return;\n    \n    assert wantToBeInElection :\n        \"Got a StatNode result after quitting election\";\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"StatNode result: \" + rc + \" for path: \" + path\n          + \" connectionState: \" + zkConnectionState + \" for \" + this);\n    }\n\n    Code code = Code.get(rc);\n    if (isSuccess(code)) {\n      // the following owner check completes verification in case the lock znode\n      // creation was retried\n      if (stat.getEphemeralOwner() == zkClient.getSessionId()) {\n        // we own the lock znode. so we are the leader\n        if (!becomeActive()) {\n          reJoinElectionAfterFailureToBecomeActive();\n        }\n      } else {\n        // we dont own the lock znode. so we are a standby.\n        becomeStandby();\n      }\n      // the watch set by us will notify about changes\n      return;\n    }\n\n    if (isNodeDoesNotExist(code)) {\n      // the lock znode disappeared before we started monitoring it\n      enterNeutralMode();\n      joinElectionInternal();\n      return;\n    }\n\n    String errorMessage = \"Received stat error from Zookeeper. code:\"\n        + code.toString();\n    LOG.debug(errorMessage);\n\n    if (shouldRetry(code)) {\n      if (statRetryCount < maxRetryNum) {\n        ++statRetryCount;\n        monitorLockNodeAsync();\n        return;\n      }\n      errorMessage = errorMessage\n          + \". Not retrying further znode monitoring connection errors.\";\n    } else if (isSessionExpired(code)) {\n      // This isn't fatal - the client Watcher will re-join the election\n      LOG.warn(\"Lock monitoring failed because session was lost\");\n      return;\n    }\n\n    fatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code) {\n    return code == Code.CONNECTIONLOSS || code == Code.OPERATIONTIMEOUT;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.joinElectionInternal": "  private void joinElectionInternal() {\n    Preconditions.checkState(appData != null,\n        \"trying to join election without any app data\");\n    if (zkClient == null) {\n      if (!reEstablishSession()) {\n        fatalError(\"Failed to reEstablish connection with ZooKeeper\");\n        return;\n      }\n    }\n\n    createRetryCount = 0;\n    wantToBeInElection = true;\n    createLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createLockNodeAsync": "  private void createLockNodeAsync() {\n    zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,\n        this, zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSuccess": "  private static boolean isSuccess(Code code) {\n    return (code == Code.OK);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorActiveStatus": "  private void monitorActiveStatus() {\n    assert wantToBeInElection;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Monitoring active leader for \" + this);\n    }\n    statRetryCount = 0;\n    monitorLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeDoesNotExist": "  private static boolean isNodeDoesNotExist(Code code) {\n    return (code == Code.NONODE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.reJoinElectionAfterFailureToBecomeActive": "  private void reJoinElectionAfterFailureToBecomeActive() {\n    reJoinElection(SLEEP_AFTER_FAILURE_TO_BECOME_ACTIVE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.enterNeutralMode": "  private void enterNeutralMode() {\n    if (state != State.NEUTRAL) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Entering neutral mode for \" + this);\n      }\n      state = State.NEUTRAL;\n      appClient.enterNeutralMode();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorLockNodeAsync": "  private void monitorLockNodeAsync() {\n    zkClient.exists(zkLockFilePath, \n        watcher, this,\n        zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSessionExpired": "  private static boolean isSessionExpired(Code code) {\n    return (code == Code.SESSIONEXPIRED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeStandby": "  private void becomeStandby() {\n    if (state != State.STANDBY) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming standby for \" + this);\n      }\n      state = State.STANDBY;\n      appClient.becomeStandby();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fatalError": "  private void fatalError(String errorMessage) {\n    LOG.fatal(errorMessage);\n    reset();\n    appClient.notifyFatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isStaleClient": "  private synchronized boolean isStaleClient(Object ctx) {\n    Preconditions.checkNotNull(ctx);\n    if (zkClient != (ZooKeeper)ctx) {\n      LOG.warn(\"Ignoring stale result from old client with sessionId \" +\n          String.format(\"0x%08x\", ((ZooKeeper)ctx).getSessionId()));\n      return true;\n    }\n    return false;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive": "  public synchronized void transitionToActive(\n      HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {\n    // call refreshAdminAcls before HA state transition\n    // for the case that adminAcls have been updated in previous active RM\n    try {\n      refreshAdminAcls(false);\n    } catch (YarnException ex) {\n      throw new ServiceFailedException(\"Can not execute refreshAdminAcls\", ex);\n    }\n\n    UserGroupInformation user = checkAccess(\"transitionToActive\");\n    checkHaStateChange(reqInfo);\n    try {\n      rm.transitionToActive();\n      // call all refresh*s for active RM to get the updated configurations.\n      refreshAll();\n      RMAuditLogger.logSuccess(user.getShortUserName(),\n          \"transitionToActive\", \"RMHAProtocolService\");\n    } catch (Exception e) {\n      RMAuditLogger.logFailure(user.getShortUserName(), \"transitionToActive\",\n          \"\", \"RMHAProtocolService\",\n          \"Exception transitioning to active\");\n      throw new ServiceFailedException(\n          \"Error when transitioning to Active mode\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkHaStateChange": "  private void checkHaStateChange(StateChangeRequestInfo req)\n      throws AccessControlException {\n    switch (req.getSource()) {\n      case REQUEST_BY_USER:\n        if (autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Manual failover for this ResourceManager is disallowed, \" +\n                  \"because automatic failover is enabled.\");\n        }\n        break;\n      case REQUEST_BY_USER_FORCED:\n        if (autoFailoverEnabled) {\n          LOG.warn(\"Allowing manual failover from \" +\n              org.apache.hadoop.ipc.Server.getRemoteAddress() +\n              \" even though automatic failover is enabled, because the user \" +\n              \"specified the force flag\");\n        }\n        break;\n      case REQUEST_BY_ZKFC:\n        if (!autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Request from ZK failover controller at \" +\n                  org.apache.hadoop.ipc.Server.getRemoteAddress() + \" denied \" +\n                  \"since automatic failover is not enabled\");\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess": "  private UserGroupInformation checkAccess(String method) throws IOException {\n    return RMServerUtils.verifyAdminAccess(authorizer, method, LOG);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll": "  private void refreshAll() throws ServiceFailedException {\n    try {\n      refreshQueues(RefreshQueuesRequest.newInstance());\n      refreshNodes(RefreshNodesRequest.newInstance(DecommissionType.NORMAL));\n      refreshSuperUserGroupsConfiguration(\n          RefreshSuperUserGroupsConfigurationRequest.newInstance());\n      refreshUserToGroupsMappings(\n          RefreshUserToGroupsMappingsRequest.newInstance());\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls(RefreshServiceAclsRequest.newInstance());\n      }\n    } catch (Exception ex) {\n      throw new ServiceFailedException(ex.getMessage());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls": "  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    String argName = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), argName, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    authorizer.setAdmins(new AccessControlList(conf.get(\n      YarnConfiguration.YARN_ADMIN_ACL,\n        YarnConfiguration.DEFAULT_YARN_ADMIN_ACL)), UserGroupInformation\n        .getCurrentUser());\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException": "  public static YarnException getRemoteException(String message) {\n    return new YarnException(message);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls": "  private UserGroupInformation checkAcls(String method) throws YarnException {\n    try {\n      return checkAccess(method);\n    } catch (IOException ioe) {\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.verifyAdminAccess": "  public static UserGroupInformation verifyAdminAccess(\n      YarnAuthorizationProvider authorizer, String method, String module,\n      final Log LOG)\n      throws IOException {\n    UserGroupInformation user;\n    try {\n      user = UserGroupInformation.getCurrentUser();\n    } catch (IOException ioe) {\n      LOG.warn(\"Couldn't get current user\", ioe);\n      RMAuditLogger.logFailure(\"UNKNOWN\", method, \"\",\n          \"AdminService\", \"Couldn't get current user\");\n      throw ioe;\n    }\n\n    if (!authorizer.isAdmin(user)) {\n      LOG.warn(\"User \" + user.getShortUserName() + \" doesn't have permission\" +\n          \" to call '\" + method + \"'\");\n\n      RMAuditLogger.logFailure(user.getShortUserName(), method, \"\", module,\n        RMAuditLogger.AuditConstants.UNAUTHORIZED_USER);\n\n      throw new AccessControlException(\"User \" + user.getShortUserName() +\n              \" doesn't have permission\" +\n              \" to call '\" + method + \"'\");\n    }\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(method + \" invoked by user \" + user.getShortUserName());\n    }\n    return user;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMAdminService": "  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ApplicationId appId,\n      ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.FAILURE, b);\n    add(Keys.DESCRIPTION, description, b);\n    add(Keys.PERMISSIONS, perm, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      ApplicationId appId, ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.SUCCESS, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }"
        },
        "bug_report": {
            "Title": "Both RM are on standBy state when kerberos user not in yarn.admin.acl",
            "Description": "Steps to reproduce\n================\n1. Configure cluster in secure mode\n2. On  RM Configure yarn.admin.acl=dsperf\n3. Configure in arn.resourcemanager.principal=yarn\n4. Start Both RM \n\nBoth RM will be in Standby forever\n\n{code}\n\n2015-06-15 12:20:21,556 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=yarn     OPERATION=refreshAdminAcls      TARGET=AdminService     RESULT=FAILURE  DESCRIPTION=Unauthorized userPERMISSIONS=\n2015-06-15 12:20:21,556 WARN org.apache.hadoop.ha.ActiveStandbyElector: Exception handling the winning of election\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:128)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:645)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:518)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Can not execute refreshAdminAcls\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        ... 4 more\nCaused by: org.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User yarn doesn't have permission to call 'refreshAdminAcls'\n        at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:38)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls(AdminService.java:230)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls(AdminService.java:465)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:295)\n        ... 5 more\nCaused by: org.apache.hadoop.security.AccessControlException: User yarn doesn't have permission to call 'refreshAdminAcls'\n        at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.verifyAdminAccess(RMServerUtils.java:182)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.verifyAdminAccess(RMServerUtils.java:148)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess(AdminService.java:223)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls(AdminService.java:228)\n        ... 7 more\n{code}\n\n\n\n*Analysis*\n\nOn each RM attempt to switch to Active refreshACl is called and acl permission not available for the user\nInfinite retry for the same switch to Active and always false returned from \n{{ActiveStandbyElector#becomeActive()}}\n \n\n*Expected*\n\nRM should get shutdown event after few retry or even at first attempt\nSince at runtime user from which it retries for refreshacl can never be updated.\n\n*States from commands*\n\n ./yarn rmadmin -getServiceState rm2\n*standby*\n ./yarn rmadmin -getServiceState rm1\n*standby*\n\n ./yarn rmadmin -checkHealth rm1\n*echo $? = 0*\n ./yarn rmadmin -checkHealth rm2\n*echo $? = 0*\n"
        }
    },
    {
        "filename": "YARN-1839.json",
        "creation_time": "2014-03-14T23:52:29.000+0000",
        "stack_trace": "```\norg.apache.hadoop.security.token.SecretManager$InvalidToken: No NMToken sent for <host>:45454\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:206)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:196)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:117)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:403)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:138)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:369)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:722)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.newProxy": "    protected ContainerManagementProtocol newProxy(final YarnRPC rpc,\n        String containerManagerBindAddr, ContainerId containerId, Token token)\n        throws InvalidToken {\n\n      if (token == null) {\n        throw new InvalidToken(\"No NMToken sent for \"\n            + containerManagerBindAddr);\n      }\n      \n      final InetSocketAddress cmAddr =\n          NetUtils.createSocketAddr(containerManagerBindAddr);\n      LOG.info(\"Opening proxy : \" + containerManagerBindAddr);\n      // the user in createRemoteUser in this context has to be ContainerID\n      UserGroupInformation user =\n          UserGroupInformation.createRemoteUser(containerId\n              .getApplicationAttemptId().toString());\n\n      org.apache.hadoop.security.token.Token<NMTokenIdentifier> nmToken =\n          ConverterUtils.convertFromYarn(token, cmAddr);\n      user.addToken(nmToken);\n\n      ContainerManagementProtocol proxy = user\n          .doAs(new PrivilegedAction<ContainerManagementProtocol>() {\n\n            @Override\n            public ContainerManagementProtocol run() {\n              return (ContainerManagementProtocol) rpc.getProxy(\n                  ContainerManagementProtocol.class, cmAddr, conf);\n            }\n          });\n      return proxy;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy": "  public synchronized ContainerManagementProtocolProxyData getProxy(\n      String containerManagerBindAddr, ContainerId containerId)\n      throws InvalidToken {\n    \n    // This get call will update the map which is working as LRU cache.\n    ContainerManagementProtocolProxyData proxy =\n        cmProxy.get(containerManagerBindAddr);\n\n    while (proxy != null\n        && !proxy.token.getIdentifier().equals(\n            nmTokenCache.getToken(containerManagerBindAddr).getIdentifier())) {\n      LOG.info(\"Refreshing proxy as NMToken got updated for node : \"\n          + containerManagerBindAddr);\n      // Token is updated. check if anyone has already tried closing it.\n      if (!proxy.scheduledForClose) {\n        // try closing the proxy. Here if someone is already using it\n        // then we might not close it. In which case we will wait.\n        removeProxy(proxy);\n      } else {\n        try {\n          this.wait();\n        } catch (InterruptedException e) {\n          e.printStackTrace();\n        }\n      }\n      if (proxy.activeCallers < 0) {\n        proxy = cmProxy.get(containerManagerBindAddr);\n      }\n    }\n    \n    if (proxy == null) {\n      proxy =\n          new ContainerManagementProtocolProxyData(rpc, containerManagerBindAddr,\n              containerId, nmTokenCache.getToken(containerManagerBindAddr));\n      if (cmProxy.size() > maxConnectedNMs) {\n        // Number of existing proxy exceed the limit.\n        String cmAddr = cmProxy.keySet().iterator().next();\n        removeProxy(cmProxy.get(cmAddr));\n      }\n      \n      cmProxy.put(containerManagerBindAddr, proxy);\n    }\n    // This is to track active users of this proxy.\n    proxy.activeCallers++;\n    updateLRUCache(containerManagerBindAddr);\n    \n    return proxy;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy": "  public ContainerManagementProtocolProxy.ContainerManagementProtocolProxyData\n      getCMProxy(String containerMgrBindAddr, ContainerId containerId)\n          throws IOException {\n    return cmProxy.getProxy(containerMgrBindAddr, containerId);\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.launch": "    public synchronized void launch(ContainerRemoteLaunchEvent event) {\n      LOG.info(\"Launching \" + taskAttemptID);\n      if(this.state == ContainerState.KILLED_BEFORE_LAUNCH) {\n        state = ContainerState.DONE;\n        sendContainerLaunchFailedMsg(taskAttemptID, \n            \"Container was killed before it was launched\");\n        return;\n      }\n      \n      ContainerManagementProtocolProxyData proxy = null;\n      try {\n\n        proxy = getCMProxy(containerMgrAddress, containerID);\n\n        // Construct the actual Container\n        ContainerLaunchContext containerLaunchContext =\n          event.getContainerLaunchContext();\n\n        // Now launch the actual container\n        StartContainerRequest startRequest =\n            StartContainerRequest.newInstance(containerLaunchContext,\n              event.getContainerToken());\n        List<StartContainerRequest> list = new ArrayList<StartContainerRequest>();\n        list.add(startRequest);\n        StartContainersRequest requestList = StartContainersRequest.newInstance(list);\n        StartContainersResponse response =\n            proxy.getContainerManagementProtocol().startContainers(requestList);\n        if (response.getFailedRequests() != null\n            && response.getFailedRequests().containsKey(containerID)) {\n          throw response.getFailedRequests().get(containerID).deSerialize();\n        }\n        ByteBuffer portInfo =\n            response.getAllServicesMetaData().get(\n                ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID);\n        int port = -1;\n        if(portInfo != null) {\n          port = ShuffleHandler.deserializeMetaData(portInfo);\n        }\n        LOG.info(\"Shuffle port returned by ContainerManager for \"\n            + taskAttemptID + \" : \" + port);\n\n        if(port < 0) {\n          this.state = ContainerState.FAILED;\n          throw new IllegalStateException(\"Invalid shuffle port number \"\n              + port + \" returned for \" + taskAttemptID);\n        }\n\n        // after launching, send launched event to task attempt to move\n        // it from ASSIGNED to RUNNING state\n        context.getEventHandler().handle(\n            new TaskAttemptContainerLaunchedEvent(taskAttemptID, port));\n        this.state = ContainerState.RUNNING;\n      } catch (Throwable t) {\n        String message = \"Container launch failed for \" + containerID + \" : \"\n            + StringUtils.stringifyException(t);\n        this.state = ContainerState.FAILED;\n        sendContainerLaunchFailedMsg(taskAttemptID, message);\n      } finally {\n        if (proxy != null) {\n          cmProxy.mayBeCloseProxy(proxy);\n        }\n      }\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.sendContainerLaunchFailedMsg": "  void sendContainerLaunchFailedMsg(TaskAttemptId taskAttemptID,\n      String message) {\n    LOG.error(message);\n    context.getEventHandler().handle(\n        new TaskAttemptDiagnosticsUpdateEvent(taskAttemptID, message));\n    context.getEventHandler().handle(\n        new TaskAttemptEvent(taskAttemptID,\n            TaskAttemptEventType.TA_CONTAINER_LAUNCH_FAILED));\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.handle": "  public void handle(ContainerLauncherEvent event) {\n    try {\n      eventQueue.put(event);\n    } catch (InterruptedException e) {\n      throw new YarnRuntimeException(e);\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.run": "    public void run() {\n      LOG.info(\"Processing the event \" + event.toString());\n\n      // Load ContainerManager tokens before creating a connection.\n      // TODO: Do it only once per NodeManager.\n      ContainerId containerID = event.getContainerID();\n\n      Container c = getContainer(event);\n      switch(event.getType()) {\n\n      case CONTAINER_REMOTE_LAUNCH:\n        ContainerRemoteLaunchEvent launchEvent\n            = (ContainerRemoteLaunchEvent) event;\n        c.launch(launchEvent);\n        break;\n\n      case CONTAINER_REMOTE_CLEANUP:\n        c.kill();\n        break;\n      }\n      removeContainerIfDone(containerID);\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.kill": "    public synchronized void kill() {\n\n      if(this.state == ContainerState.PREP) {\n        this.state = ContainerState.KILLED_BEFORE_LAUNCH;\n      } else if (!isCompletelyDone()) {\n        LOG.info(\"KILLING \" + taskAttemptID);\n\n        ContainerManagementProtocolProxyData proxy = null;\n        try {\n          proxy = getCMProxy(this.containerMgrAddress, this.containerID);\n\n          // kill the remote container if already launched\n          List<ContainerId> ids = new ArrayList<ContainerId>();\n          ids.add(this.containerID);\n          StopContainersRequest request = StopContainersRequest.newInstance(ids);\n          StopContainersResponse response =\n              proxy.getContainerManagementProtocol().stopContainers(request);\n          if (response.getFailedRequests() != null\n              && response.getFailedRequests().containsKey(this.containerID)) {\n            throw response.getFailedRequests().get(this.containerID)\n              .deSerialize();\n          }\n        } catch (Throwable t) {\n          // ignore the cleanup failure\n          String message = \"cleanup failed for container \"\n              + this.containerID + \" : \"\n              + StringUtils.stringifyException(t);\n          context.getEventHandler()\n              .handle(\n                  new TaskAttemptDiagnosticsUpdateEvent(this.taskAttemptID,\n                      message));\n          LOG.warn(message);\n        } finally {\n          if (proxy != null) {\n            cmProxy.mayBeCloseProxy(proxy);\n          }\n        }\n        this.state = ContainerState.DONE;\n      }\n      // after killing, send killed event to task attempt\n      context.getEventHandler().handle(\n          new TaskAttemptEvent(this.taskAttemptID,\n              TaskAttemptEventType.TA_CONTAINER_CLEANED));\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.removeContainerIfDone": "  private void removeContainerIfDone(ContainerId id) {\n    Container c = containers.get(id);\n    if(c != null && c.isCompletelyDone()) {\n      containers.remove(id);\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getContainer": "  private Container getContainer(ContainerLauncherEvent event) {\n    ContainerId id = event.getContainerID();\n    Container c = containers.get(id);\n    if(c == null) {\n      c = new Container(event.getTaskAttemptID(), event.getContainerID(),\n          event.getContainerMgrAddress());\n      Container old = containers.putIfAbsent(id, c);\n      if(old != null) {\n        c = old;\n      }\n    }\n    return c;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.createEventProcessor": "  protected EventProcessor createEventProcessor(ContainerLauncherEvent event) {\n    return new EventProcessor(event);\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent.getContainerToken": "  public Token getContainerToken() {\n    return containerToken;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent.toString": "  public String toString() {\n    return super.toString() + \" for container \" + containerID + \" taskAttempt \"\n        + taskAttemptID;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent.getContainerMgrAddress": "  public String getContainerMgrAddress() {\n    return containerMgrAddress;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent.getContainerID": "  public ContainerId getContainerID() {\n    return containerID;\n  }"
        },
        "bug_report": {
            "Title": "Capacity scheduler preempts an AM out. AM attempt 2 fails to launch task container with SecretManager$InvalidToken: No NMToken sent",
            "Description": "Use single-node cluster. Turn on capacity scheduler preemption. Run MR sleep job as app 1. Take entire cluster. Run MR sleep job as app 2. Preempt app1 out. Wait till app 2 finishes. App 1 AM attempt 2 will start. It won't be able to launch a task container with this error stack trace in AM logs:\n\n{code}\n2014-03-13 20:13:50,254 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1394741557066_0001_m_000000_1009: Container launch failed for container_1394741557066_0001_02_000021 : org.apache.hadoop.security.token.SecretManager$InvalidToken: No NMToken sent for <host>:45454\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:206)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:196)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:117)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:403)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:138)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:369)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:722)\n{code}\n\n"
        }
    },
    {
        "filename": "YARN-6714.json",
        "creation_time": "2017-06-15T09:56:15.000+0000",
        "stack_trace": "```\njava.lang.IllegalStateException: Trying to unreserve  for application appattempt_1495188831758_0121_000002 when currently reserved  for application application_1495188831758_0121 on node host: node1:45454 #containers=2 available=... used=...\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.unreserveResource(FiCaSchedulerNode.java:123)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.unreserve(FiCaSchedulerApp.java:845)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer(LeafQueue.java:1787)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal(CapacityScheduler.java:1957)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer(AbstractYarnScheduler.java:586)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt(CapacityScheduler.java:966)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1740)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:152)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:822)\n        at java.lang.Thread.run(Thread.java:834)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.unreserveResource": "  public synchronized void unreserveResource(\n      SchedulerApplicationAttempt application) {\n    // adding NP checks as this can now be called for preemption\n    if (getReservedContainer() != null\n        && getReservedContainer().getContainer() != null\n        && getReservedContainer().getContainer().getId() != null\n        && getReservedContainer().getContainer().getId()\n          .getApplicationAttemptId() != null) {\n\n      // Cannot unreserve for wrong application...\n      ApplicationAttemptId reservedApplication =\n          getReservedContainer().getContainer().getId()\n            .getApplicationAttemptId();\n      if (!reservedApplication.equals(\n          application.getApplicationAttemptId())) {\n        throw new IllegalStateException(\"Trying to unreserve \" +\n            \" for application \" + application.getApplicationAttemptId() +\n            \" when currently reserved \" +\n            \" for application \" + reservedApplication.getApplicationId() +\n            \" on node \" + this);\n      }\n    }\n    setReservedContainer(null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.unreserve": "  public boolean unreserve(SchedulerRequestKey schedulerKey,\n      FiCaSchedulerNode node, RMContainer rmContainer) {\n    try {\n      writeLock.lock();\n      // Done with the reservation?\n      if (internalUnreserve(node, schedulerKey)) {\n        node.unreserveResource(this);\n\n        // Update reserved metrics\n        queue.getMetrics().unreserveResource(getUser(),\n            rmContainer.getReservedResource());\n        queue.decReservedResource(node.getPartition(),\n            rmContainer.getReservedResource());\n        return true;\n      }\n      return false;\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.internalUnreserve": "  private boolean internalUnreserve(FiCaSchedulerNode node,\n      SchedulerRequestKey schedulerKey) {\n    Map<NodeId, RMContainer> reservedContainers =\n        this.reservedContainers.get(schedulerKey);\n\n    if (reservedContainers != null) {\n      RMContainer reservedContainer =\n          reservedContainers.remove(node.getNodeID());\n\n      // unreserve is now triggered in new scenarios (preemption)\n      // as a consequence reservedcontainer might be null, adding NP-checks\n      if (reservedContainer != null\n          && reservedContainer.getContainer() != null\n          && reservedContainer.getContainer().getResource() != null) {\n\n        if (reservedContainers.isEmpty()) {\n          this.reservedContainers.remove(schedulerKey);\n        }\n        // Reset the re-reservation count\n        resetReReservations(schedulerKey);\n\n        Resource resource = reservedContainer.getReservedResource();\n        this.attemptResourceUsage.decReserved(node.getPartition(), resource);\n\n        LOG.info(\"Application \" + getApplicationId() + \" unreserved \"\n            + \" on node \" + node + \", currently has \"\n            + reservedContainers.size()\n            + \" at priority \" + schedulerKey.getPriority()\n            + \"; currentReservation \" + this.attemptResourceUsage.getReserved()\n            + \" on node-label=\" + node.getPartition());\n        return true;\n      }\n    }\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer": "  public void completedContainer(Resource clusterResource, \n      FiCaSchedulerApp application, FiCaSchedulerNode node, RMContainer rmContainer, \n      ContainerStatus containerStatus, RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues) {\n    // Update SchedulerHealth for released / preempted container\n    updateSchedulerHealthForCompletedContainer(rmContainer, containerStatus);\n\n    if (application != null) {\n      boolean removed = false;\n\n      // Careful! Locking order is important!\n      try {\n        writeLock.lock();\n        Container container = rmContainer.getContainer();\n\n        // Inform the application & the node\n        // Note: It's safe to assume that all state changes to RMContainer\n        // happen under scheduler's lock...\n        // So, this is, in effect, a transaction across application & node\n        if (rmContainer.getState() == RMContainerState.RESERVED) {\n          removed = application.unreserve(rmContainer.getReservedSchedulerKey(),\n              node, rmContainer);\n        } else{\n          removed = application.containerCompleted(rmContainer, containerStatus,\n              event, node.getPartition());\n\n          node.releaseContainer(rmContainer.getContainerId(), false);\n        }\n\n        // Book-keeping\n        if (removed) {\n\n          // Inform the ordering policy\n          orderingPolicy.containerReleased(application, rmContainer);\n\n          releaseResource(clusterResource, application, container.getResource(),\n              node.getPartition(), rmContainer);\n        }\n      } finally {\n        writeLock.unlock();\n      }\n\n\n      if (removed) {\n        // Inform the parent queue _outside_ of the leaf-queue lock\n        getParent().completedContainer(clusterResource, application, node,\n          rmContainer, null, event, this, sortQueues);\n      }\n    }\n\n    // Notify PreemptionManager\n    csContext.getPreemptionManager().removeKillableContainer(\n        new KillableContainer(rmContainer, node.getPartition(), queueName));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.releaseResource": "  void releaseResource(Resource clusterResource,\n      FiCaSchedulerApp application, Resource resource, String nodePartition,\n      RMContainer rmContainer) {\n    try {\n      writeLock.lock();\n      super.releaseResource(clusterResource, resource, nodePartition);\n\n      // handle ignore exclusivity container\n      if (null != rmContainer && rmContainer.getNodeLabelExpression().equals(\n          RMNodeLabelsManager.NO_LABEL) && !nodePartition.equals(\n          RMNodeLabelsManager.NO_LABEL)) {\n        if (ignorePartitionExclusivityRMContainers.containsKey(nodePartition)) {\n          Set<RMContainer> rmContainers =\n              ignorePartitionExclusivityRMContainers.get(nodePartition);\n          rmContainers.remove(rmContainer);\n          if (rmContainers.isEmpty()) {\n            ignorePartitionExclusivityRMContainers.remove(nodePartition);\n          }\n        }\n      }\n\n      // Update user metrics\n      String userName = application.getUser();\n      User user = usersManager.updateUserResourceUsage(userName, resource,\n          nodePartition, false);\n\n      metrics.setAvailableResourcesToUser(userName, application.getHeadroom());\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            getQueueName() + \" used=\" + queueUsage.getUsed() + \" numContainers=\"\n                + numContainers + \" user=\" + userName + \" user-resources=\"\n                + user.getUsed());\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.updateSchedulerHealthForCompletedContainer": "  private void updateSchedulerHealthForCompletedContainer(\n      RMContainer rmContainer, ContainerStatus containerStatus) {\n    // Update SchedulerHealth for released / preempted container\n    SchedulerHealth schedulerHealth = csContext.getSchedulerHealth();\n    if (null == schedulerHealth) {\n      // Only do update if we have schedulerHealth\n      return;\n    }\n\n    if (containerStatus.getExitStatus() == ContainerExitStatus.PREEMPTED) {\n      schedulerHealth.updatePreemption(Time.now(), rmContainer.getAllocatedNode(),\n          rmContainer.getContainerId(), getQueuePath());\n      schedulerHealth.updateSchedulerPreemptionCounts(1);\n    } else {\n      schedulerHealth.updateRelease(csContext.getLastNodeUpdateTime(),\n          rmContainer.getAllocatedNode(), rmContainer.getContainerId(),\n          getQueuePath());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal": "  protected void completedContainerInternal(\n      RMContainer rmContainer, ContainerStatus containerStatus,\n      RMContainerEventType event) {\n    Container container = rmContainer.getContainer();\n    ContainerId containerId = container.getId();\n\n    // Get the application for the finished container\n    FiCaSchedulerApp application = getCurrentAttemptForContainer(\n        container.getId());\n    ApplicationId appId =\n        containerId.getApplicationAttemptId().getApplicationId();\n    if (application == null) {\n      LOG.info(\n          \"Container \" + container + \" of\" + \" finished application \" + appId\n              + \" completed with event \" + event);\n      return;\n    }\n\n    // Get the node on which the container was allocated\n    FiCaSchedulerNode node = getNode(container.getNodeId());\n    if (null == node) {\n      LOG.info(\"Container \" + container + \" of\" + \" removed node \" + container\n          .getNodeId() + \" completed with event \" + event);\n      return;\n    }\n\n    // Inform the queue\n    LeafQueue queue = (LeafQueue) application.getQueue();\n    queue.completedContainer(getClusterResource(), application, node,\n        rmContainer, containerStatus, event, null, true);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getNode": "  public FiCaSchedulerNode getNode(NodeId nodeId) {\n    return nodeTracker.getNode(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return this.queueManager.getQueue(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer": "  public void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n\n    if (rmContainer == null) {\n      LOG.info(\"Container \" + containerStatus.getContainerId()\n          + \" completed with event \" + event\n          + \", but corresponding RMContainer doesn't exist.\");\n      return;\n    }\n\n    if (rmContainer.getExecutionType() == ExecutionType.GUARANTEED) {\n      completedContainerInternal(rmContainer, containerStatus, event);\n      completeOustandingUpdatesWhichAreReserved(\n          rmContainer, containerStatus, event);\n    } else {\n      ContainerId containerId = rmContainer.getContainerId();\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerFinishedEvent(containerId, containerStatus, event));\n      SchedulerApplicationAttempt schedulerAttempt =\n          getCurrentAttemptForContainer(containerId);\n      if (schedulerAttempt != null) {\n        schedulerAttempt.removeRMContainer(containerId);\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Completed container: \" + rmContainer.getContainerId() +\n            \" in state: \" + rmContainer.getState() + \" event:\" + event);\n      }\n      getSchedulerNode(rmContainer.getNodeId()).releaseContainer(\n          rmContainer.getContainerId(), false);\n    }\n\n    // If the container is getting killed in ACQUIRED state, the requester (AM\n    // for regular containers and RM itself for AM container) will not know what\n    // happened. Simply add the ResourceRequest back again so that requester\n    // doesn't need to do anything conditionally.\n    recoverResourceRequestForContainer(rmContainer);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainerInternal": "  protected abstract void completedContainerInternal(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event);\n\n  protected void releaseContainers(List<ContainerId> containers,\n      SchedulerApplicationAttempt attempt) {\n    for (ContainerId containerId : containers) {\n      RMContainer rmContainer = getRMContainer(containerId);\n      if (rmContainer == null) {\n        if (System.currentTimeMillis() - ResourceManager.getClusterTimeStamp()\n            < nmExpireInterval) {\n          LOG.info(containerId + \" doesn't exist. Add the container\"\n              + \" to the release request cache as it maybe on recovery.\");\n          attempt.getPendingRelease().add(containerId);\n        } else {\n          RMAuditLogger.logFailure(attempt.getUser(),\n            AuditConstants.RELEASE_CONTAINER,\n            \"Unauthorized access or invalid container\", \"Scheduler\",\n            \"Trying to release container not owned by app or with invalid id.\",\n            attempt.getApplicationId(), containerId, null);\n        }\n      }\n      completedContainer(rmContainer,\n        SchedulerUtils.createAbnormalContainerStatus(containerId,\n          SchedulerUtils.RELEASED_CONTAINER), RMContainerEventType.RELEASED);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getCurrentAttemptForContainer": "  public T getCurrentAttemptForContainer(ContainerId containerId) {\n    return getApplicationAttempt(containerId.getApplicationAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getSchedulerNode": "  public N getSchedulerNode(NodeId nodeId) {\n    return nodeTracker.getNode(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.recoverResourceRequestForContainer": "  private void recoverResourceRequestForContainer(RMContainer rmContainer) {\n    List<ResourceRequest> requests = rmContainer.getResourceRequests();\n\n    // If container state is moved to ACQUIRED, request will be empty.\n    if (requests == null) {\n      return;\n    }\n\n    // Add resource request back to Scheduler ApplicationAttempt.\n\n    // We lookup the application-attempt here again using\n    // getCurrentApplicationAttempt() because there is only one app-attempt at\n    // any point in the scheduler. But in corner cases, AMs can crash,\n    // corresponding containers get killed and recovered to the same-attempt,\n    // but because the app-attempt is extinguished right after, the recovered\n    // requests don't serve any purpose, but that's okay.\n    SchedulerApplicationAttempt schedulerAttempt =\n        getCurrentAttemptForContainer(rmContainer.getContainerId());\n    if (schedulerAttempt != null) {\n      schedulerAttempt.recoverResourceRequestsForContainer(requests);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completeOustandingUpdatesWhichAreReserved": "  private void completeOustandingUpdatesWhichAreReserved(\n      RMContainer rmContainer, ContainerStatus containerStatus,\n      RMContainerEventType event) {\n    N schedulerNode = getSchedulerNode(rmContainer.getNodeId());\n    if (schedulerNode != null &&\n        schedulerNode.getReservedContainer() != null) {\n      RMContainer resContainer = schedulerNode.getReservedContainer();\n      if (resContainer.getReservedSchedulerKey() != null) {\n        ContainerId containerToUpdate = resContainer\n            .getReservedSchedulerKey().getContainerToUpdate();\n        if (containerToUpdate != null &&\n            containerToUpdate.equals(containerStatus.getContainerId())) {\n          completedContainerInternal(resContainer,\n              ContainerStatus.newInstance(resContainer.getContainerId(),\n                  containerStatus.getState(), containerStatus\n                      .getDiagnostics(),\n                  containerStatus.getExitStatus()), event);\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt": "  private void doneApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    try {\n      writeLock.lock();\n      LOG.info(\"Application Attempt \" + applicationAttemptId + \" is done.\"\n          + \" finalState=\" + rmAppAttemptFinalState);\n\n      FiCaSchedulerApp attempt = getApplicationAttempt(applicationAttemptId);\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n\n      if (application == null || attempt == null) {\n        LOG.info(\n            \"Unknown application \" + applicationAttemptId + \" has completed!\");\n        return;\n      }\n\n      // Release all the allocated, acquired, running containers\n      for (RMContainer rmContainer : attempt.getLiveContainers()) {\n        if (keepContainers && rmContainer.getState().equals(\n            RMContainerState.RUNNING)) {\n          // do not kill the running container in the case of work-preserving AM\n          // restart.\n          LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n          continue;\n        }\n        super.completedContainer(rmContainer, SchedulerUtils\n                .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                    SchedulerUtils.COMPLETED_APPLICATION),\n            RMContainerEventType.KILL);\n      }\n\n      // Release all reserved containers\n      for (RMContainer rmContainer : attempt.getReservedContainers()) {\n        super.completedContainer(rmContainer, SchedulerUtils\n            .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                \"Application Complete\"), RMContainerEventType.KILL);\n      }\n\n      // Clean up pending requests, metrics etc.\n      attempt.stop(rmAppAttemptFinalState);\n\n      // Inform the queue\n      String queueName = attempt.getQueue().getQueueName();\n      CSQueue queue = this.getQueue(queueName);\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\n            \"Cannot finish application \" + \"from non-leaf queue: \" + queueName);\n      } else{\n        queue.finishApplicationAttempt(attempt, queue.getQueueName());\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getApplicationAttempt": "  public FiCaSchedulerApp getApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId) {\n    return super.getApplicationAttempt(applicationAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent =\n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_LABELS_UPDATE:\n    {\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent =\n          (NodeLabelsUpdateSchedulerEvent) event;\n      \n      updateNodeLabelsAndQueueResource(labelUpdateEvent);\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName = resolveReservationQueueName(appAddedEvent.getQueue(),\n          appAddedEvent.getApplicationId(), appAddedEvent.getReservationID(),\n          appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        if (!appAddedEvent.getIsAppRecovering()) {\n          addApplication(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        } else {\n          addApplicationOnRecovery(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        }\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      if (containerExpiredEvent.isIncrease()) {\n        rollbackContainerUpdate(containerId);\n      } else {\n        completedContainer(getRMContainer(containerId),\n            SchedulerUtils.createAbnormalContainerStatus(\n                containerId,\n                SchedulerUtils.EXPIRED_CONTAINER),\n            RMContainerEventType.EXPIRE);\n      }\n    }\n    break;\n    case KILL_RESERVED_CONTAINER:\n    {\n      ContainerPreemptEvent killReservedContainerEvent =\n          (ContainerPreemptEvent) event;\n      RMContainer container = killReservedContainerEvent.getContainer();\n      killReservedContainer(container);\n    }\n    break;\n    case MARK_CONTAINER_FOR_PREEMPTION:\n    {\n      ContainerPreemptEvent preemptContainerEvent =\n          (ContainerPreemptEvent)event;\n      ApplicationAttemptId aid = preemptContainerEvent.getAppId();\n      RMContainer containerToBePreempted = preemptContainerEvent.getContainer();\n      markContainerForPreemption(aid, containerToBePreempted);\n    }\n    break;\n    case MARK_CONTAINER_FOR_KILLABLE:\n    {\n      ContainerPreemptEvent containerKillableEvent = (ContainerPreemptEvent)event;\n      RMContainer killableContainer = containerKillableEvent.getContainer();\n      markContainerForKillable(killableContainer);\n    }\n    break;\n    case MARK_CONTAINER_FOR_NONKILLABLE:\n    {\n      if (isLazyPreemptionEnabled) {\n        ContainerPreemptEvent cancelKillContainerEvent =\n            (ContainerPreemptEvent) event;\n        markContainerForNonKillable(cancelKillContainerEvent.getContainer());\n      }\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addNode": "  private void addNode(RMNode nodeManager) {\n    try {\n      writeLock.lock();\n      FiCaSchedulerNode schedulerNode = new FiCaSchedulerNode(nodeManager,\n          usePortForNodeName, nodeManager.getNodeLabels());\n      nodeTracker.addNode(schedulerNode);\n\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.activateNode(nodeManager.getNodeID(),\n            schedulerNode.getTotalResource());\n      }\n\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n\n      LOG.info(\n          \"Added node \" + nodeManager.getNodeAddress() + \" clusterResource: \"\n              + clusterResource);\n\n      if (scheduleAsynchronously && getNumClusterNodes() == 1) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.beginSchedule();\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplication": "  private void addApplication(ApplicationId applicationId,\n      String queueName, String user, Priority priority) {\n    try {\n      writeLock.lock();\n      if (isSystemAppsLimitReached()) {\n        String message = \"Maximum system application limit reached,\"\n            + \"cannot accept submission of application: \" + applicationId;\n        this.rmContext.getDispatcher().getEventHandler().handle(new RMAppEvent(\n            applicationId, RMAppEventType.APP_REJECTED, message));\n        return;\n      }\n      // Sanity checks.\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to unknown queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      if (!(queue instanceof LeafQueue)) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to non-leaf queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        LOG.info(\"Failed to submit application \" + applicationId + \" to queue \"\n            + queueName + \" from user \" + user, ace);\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                ace.toString()));\n        return;\n      }\n      // update the metrics\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeLabelsAndQueueResource": "  private void updateNodeLabelsAndQueueResource(\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent) {\n    try {\n      writeLock.lock();\n      for (Entry<NodeId, Set<String>> entry : labelUpdateEvent\n          .getUpdatedNodeToLabels().entrySet()) {\n        NodeId id = entry.getKey();\n        Set<String> labels = entry.getValue();\n        updateLabelsOnNode(id, labels);\n      }\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplication": "  private void doneApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationId);\n      if (application == null) {\n        // The AppRemovedSchedulerEvent maybe sent on recovery for completed\n        // apps, ignore it.\n        LOG.warn(\"Couldn't find application \" + applicationId);\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\"Cannot finish application \" + \"from non-leaf queue: \" + queue\n            .getQueueName());\n      } else{\n        queue.finishApplication(applicationId, application.getUser());\n      }\n      application.stop(finalState);\n      applications.remove(applicationId);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate": "  protected void nodeUpdate(RMNode rmNode) {\n    try {\n      readLock.lock();\n      setLastNodeUpdateTime(Time.now());\n      super.nodeUpdate(rmNode);\n    } finally {\n      readLock.unlock();\n    }\n\n    // Try to do scheduling\n    if (!scheduleAsynchronously) {\n      try {\n        writeLock.lock();\n        ActivitiesLogger.NODE.startNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n\n        // reset allocation and reservation stats before we start doing any\n        // work\n        updateSchedulerHealth(lastNodeUpdateTime, rmNode.getNodeID(),\n            CSAssignment.NULL_ASSIGNMENT);\n\n        allocateContainersToNode(rmNode.getNodeID(), true);\n        ActivitiesLogger.NODE.finishNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n      } finally {\n        writeLock.unlock();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.resolveReservationQueueName": "  private String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID,\n      boolean isRecovering) {\n    try {\n      readLock.lock();\n      CSQueue queue = getQueue(queueName);\n      // Check if the queue is a plan queue\n      if ((queue == null) || !(queue instanceof PlanQueue)) {\n        return queueName;\n      }\n      if (reservationID != null) {\n        String resQName = reservationID.toString();\n        queue = getQueue(resQName);\n        if (queue == null) {\n          // reservation has terminated during failover\n          if (isRecovering && conf.getMoveOnExpiry(\n              getQueue(queueName).getQueuePath())) {\n            // move to the default child queue of the plan\n            return getDefaultReservationQueueName(queueName);\n          }\n          String message = \"Application \" + applicationId\n              + \" submitted to a reservation which is not currently active: \"\n              + resQName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        if (!queue.getParent().getQueueName().equals(queueName)) {\n          String message =\n              \"Application: \" + applicationId + \" submitted to a reservation \"\n                  + resQName + \" which does not belong to the specified queue: \"\n                  + queueName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        // use the reservation queue to run the app\n        queueName = resQName;\n      } else{\n        // use the default child queue of the plan for unreserved apps\n        queueName = getDefaultReservationQueueName(queueName);\n      }\n      return queueName;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationOnRecovery": "  private void addApplicationOnRecovery(\n      ApplicationId applicationId, String queueName, String user,\n      Priority priority) {\n    try {\n      writeLock.lock();\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        //During a restart, this indicates a queue was removed, which is\n        //not presently supported\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName + \" which no longer exists after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" missing during application recovery.\"\n              + \" Queue removal during recovery is not presently \"\n              + \"supported by the capacity scheduler, please \"\n              + \"restart with all queues configured\"\n              + \" which were present before shutdown/restart.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      if (!(queue instanceof LeafQueue)) {\n        // During RM restart, this means leaf queue was converted to a parent\n        // queue, which is not supported for running apps.\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName\n                      + \" which is no longer a leaf queue after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" is no longer a leaf queue during application recovery.\"\n              + \" Changing a leaf queue to a parent queue during recovery is\"\n              + \" not presently supported by the capacity scheduler. Please\"\n              + \" restart with leaf queues before shutdown/restart continuing\"\n              + \" as leaf queues.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        // Ignore the exception for recovered app as the app was previously\n        // accepted.\n      }\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForKillable": "  public void markContainerForKillable(\n      RMContainer killableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE + \": container\"\n            + killableContainer.toString());\n      }\n\n      if (!isLazyPreemptionEnabled) {\n        super.completedContainer(killableContainer, SchedulerUtils\n            .createPreemptedContainerStatus(killableContainer.getContainerId(),\n                SchedulerUtils.PREEMPTED_CONTAINER), RMContainerEventType.KILL);\n      } else{\n        FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n            killableContainer.getAllocatedNode());\n\n        FiCaSchedulerApp application = getCurrentAttemptForContainer(\n            killableContainer.getContainerId());\n\n        node.markContainerToKillable(killableContainer.getContainerId());\n\n        // notify PreemptionManager\n        // Get the application for the finished container\n        if (null != application) {\n          String leafQueueName = application.getCSLeafQueue().getQueueName();\n          getPreemptionManager().addKillableContainer(\n              new KillableContainer(killableContainer, node.getPartition(),\n                  leafQueueName));\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForNonKillable": "  private void markContainerForNonKillable(\n      RMContainer nonKillableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            SchedulerEventType.MARK_CONTAINER_FOR_NONKILLABLE + \": container\"\n                + nonKillableContainer.toString());\n      }\n\n      FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n          nonKillableContainer.getAllocatedNode());\n\n      FiCaSchedulerApp application = getCurrentAttemptForContainer(\n          nonKillableContainer.getContainerId());\n\n      node.markContainerToNonKillable(nonKillableContainer.getContainerId());\n\n      // notify PreemptionManager\n      // Get the application for the finished container\n      if (null != application) {\n        String leafQueueName = application.getCSLeafQueue().getQueueName();\n        getPreemptionManager().removeKillableContainer(\n            new KillableContainer(nonKillableContainer, node.getPartition(),\n                leafQueueName));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForPreemption": "  public void markContainerForPreemption(ApplicationAttemptId aid,\n      RMContainer cont) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION\n            + \": appAttempt:\" + aid.toString() + \" container: \"\n            + cont.toString());\n    }\n    FiCaSchedulerApp app = getApplicationAttempt(aid);\n    if (app != null) {\n      app.markContainerForPreemption(cont.getContainerId());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeAndQueueResource": "  private void updateNodeAndQueueResource(RMNode nm,\n      ResourceOption resourceOption) {\n    try {\n      writeLock.lock();\n      updateNodeResource(nm, resourceOption);\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.killReservedContainer": "  public void killReservedContainer(RMContainer container) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.KILL_RESERVED_CONTAINER + \":\"\n          + container.toString());\n    }\n    // To think: What happens if this is no longer a reserved container, for\n    // e.g if the reservation became an allocation.\n    super.completedContainer(container,\n        SchedulerUtils.createAbnormalContainerStatus(\n            container.getContainerId(),\n            SchedulerUtils.UNRESERVED_CONTAINER),\n        RMContainerEventType.KILL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n      if (application == null) {\n        LOG.warn(\"Application \" + applicationAttemptId.getApplicationId()\n            + \" cannot be found in scheduler.\");\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n\n      FiCaSchedulerApp attempt = new FiCaSchedulerApp(applicationAttemptId,\n          application.getUser(), queue, queue.getAbstractUsersManager(),\n          rmContext, application.getPriority(), isAttemptRecovering,\n          activitiesManager);\n      if (transferStateFromPreviousAttempt) {\n        attempt.transferStateFromPreviousAttempt(\n            application.getCurrentAppAttempt());\n      }\n      application.setCurrentAppAttempt(attempt);\n\n      // Update attempt priority to the latest to avoid race condition i.e\n      // SchedulerApplicationAttempt is created with old priority but it is not\n      // set to SchedulerApplication#setCurrentAppAttempt.\n      // Scenario would occur is\n      // 1. SchdulerApplicationAttempt is created with old priority.\n      // 2. updateApplicationPriority() updates SchedulerApplication. Since\n      // currentAttempt is null, it just return.\n      // 3. ScheduelerApplcationAttempt is set in\n      // SchedulerApplication#setCurrentAppAttempt.\n      attempt.setPriority(application.getPriority());\n\n      queue.submitApplicationAttempt(attempt, application.getUser());\n      LOG.info(\"Added Application Attempt \" + applicationAttemptId\n          + \" to scheduler from user \" + application.getUser() + \" in queue \"\n          + queue.getQueueName());\n      if (isAttemptRecovering) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(applicationAttemptId\n              + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n        }\n      } else{\n        rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppAttemptEvent(applicationAttemptId,\n                RMAppAttemptEventType.ATTEMPT_ADDED));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.removeNode": "  private void removeNode(RMNode nodeInfo) {\n    try {\n      writeLock.lock();\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.deactivateNode(nodeInfo.getNodeID());\n      }\n\n      NodeId nodeId = nodeInfo.getNodeID();\n      FiCaSchedulerNode node = nodeTracker.getNode(nodeId);\n      if (node == null) {\n        LOG.error(\"Attempting to remove non-existent node \" + nodeId);\n        return;\n      }\n\n      // Remove running containers\n      List<RMContainer> runningContainers =\n          node.getCopiedListOfRunningContainers();\n      for (RMContainer container : runningContainers) {\n        super.completedContainer(container, SchedulerUtils\n            .createAbnormalContainerStatus(container.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      // Remove reservations, if any\n      RMContainer reservedContainer = node.getReservedContainer();\n      if (reservedContainer != null) {\n        super.completedContainer(reservedContainer, SchedulerUtils\n            .createAbnormalContainerStatus(reservedContainer.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      nodeTracker.removeNode(nodeId);\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n      int numNodes = nodeTracker.nodeCount();\n\n      if (scheduleAsynchronously && numNodes == 0) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.suspendSchedule();\n        }\n      }\n\n      LOG.info(\n          \"Removed node \" + nodeInfo.getNodeAddress() + \" clusterResource: \"\n              + getClusterResource());\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices(true);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    HAServiceState state = rmContext.getHAServiceState();\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    if (state == HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.completedContainer": "  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   * @param resourceLimits the current ResourceLimits\n   */\n  public void updateClusterResource(Resource clusterResource,\n      ResourceLimits resourceLimits);\n  \n  /**\n   * Get the {@link AbstractUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.removeRMContainer": "  public void removeRMContainer(ContainerId containerId) {\n    try {\n      writeLock.lock();\n      RMContainer rmContainer = liveContainers.remove(containerId);\n      if (rmContainer != null) {\n        if (rmContainer.getExecutionType() == ExecutionType.OPPORTUNISTIC) {\n          this.attemptOpportunisticResourceUsage\n              .decUsed(rmContainer.getAllocatedResource());\n        }\n        if (rmContainer.isRemotelyAllocated()) {\n          this.attemptResourceUsageAllocatedRemotely\n              .decUsed(rmContainer.getAllocatedResource());\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.finishApplicationAttempt": "  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param ps {@link PlacementSet} of nodes which resources are available",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n\n  public PrivilegedEntity getPrivilegedEntity();\n\n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param ps {@link PlacementSet} of nodes which resources are available",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getLeaderElectorService": "  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElector.rejoinElection": "  void rejoinElection();\n\n  /**\n   * Get information about the elector's connection to Zookeeper.\n   *\n   * @return zookeeper connection state\n   */\n  String getZookeeperConnectionState();\n}"
        },
        "bug_report": {
            "Title": "IllegalStateException while handling APP_ATTEMPT_REMOVED event when async-scheduling enabled in CapacityScheduler",
            "Description": "Currently in async-scheduling mode of CapacityScheduler, after AM failover and unreserve all reserved containers, it still have chance to get and commit the outdated reserve proposal of the failed app attempt. This problem happened on an app in our cluster, when this app stopped, it unreserved all reserved containers and compared these appAttemptId with current appAttemptId, if not match it will throw IllegalStateException and make RM crashed.\n\nError log:\n{noformat}\n2017-06-08 11:02:24,339 FATAL [ResourceManager Event Processor] org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type APP_ATTEMPT_REMOVED to the scheduler\njava.lang.IllegalStateException: Trying to unreserve  for application appattempt_1495188831758_0121_000002 when currently reserved  for application application_1495188831758_0121 on node host: node1:45454 #containers=2 available=... used=...\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.unreserveResource(FiCaSchedulerNode.java:123)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.unreserve(FiCaSchedulerApp.java:845)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer(LeafQueue.java:1787)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal(CapacityScheduler.java:1957)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer(AbstractYarnScheduler.java:586)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt(CapacityScheduler.java:966)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1740)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:152)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:822)\n        at java.lang.Thread.run(Thread.java:834)\n{noformat}\n\nWhen async-scheduling enabled, CapacityScheduler#doneApplicationAttempt and CapacityScheduler#tryCommit both need to get write_lock before executing, so we can check the app attempt state in commit process to avoid committing outdated proposals.\n"
        }
    },
    {
        "filename": "YARN-3351.json",
        "creation_time": "2015-03-16T14:19:59.000+0000",
        "stack_trace": "```\njava.net.BindException: Cannot assign requested address\n\tat java.net.PlainSocketImpl.socketBind(Native Method)\n\tat java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)\n\tat java.net.Socket.bind(Socket.java:631)\n\tat java.net.Socket.<init>(Socket.java:423)\n\tat java.net.Socket.<init>(Socket.java:280)\n\tat org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)\n\tat org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)\n\tat org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)\n\tat org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink(WebAppProxyServlet.java:188)\n\tat org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(WebAppProxyServlet.java:345)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink": "  private static void proxyLink(HttpServletRequest req, \n      HttpServletResponse resp, URI link, Cookie c, String proxyHost)\n      throws IOException {\n    DefaultHttpClient client = new DefaultHttpClient();\n    client\n        .getParams()\n        .setParameter(ClientPNames.COOKIE_POLICY,\n            CookiePolicy.BROWSER_COMPATIBILITY)\n        .setBooleanParameter(ClientPNames.ALLOW_CIRCULAR_REDIRECTS, true);\n    // Make sure we send the request from the proxy address in the config\n    // since that is what the AM filter checks against. IP aliasing or\n    // similar could cause issues otherwise.\n    InetAddress localAddress = InetAddress.getByName(proxyHost);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"local InetAddress for proxy host: {}\", localAddress);\n    }\n    client.getParams()\n        .setParameter(ConnRoutePNames.LOCAL_ADDRESS, localAddress);\n    HttpGet httpGet = new HttpGet(link);\n    @SuppressWarnings(\"unchecked\")\n    Enumeration<String> names = req.getHeaderNames();\n    while(names.hasMoreElements()) {\n      String name = names.nextElement();\n      if(passThroughHeaders.contains(name)) {\n        String value = req.getHeader(name);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"REQ HEADER: {} : {}\", name, value);\n        }\n        httpGet.setHeader(name, value);\n      }\n    }\n\n    String user = req.getRemoteUser();\n    if (user != null && !user.isEmpty()) {\n      httpGet.setHeader(\"Cookie\",\n          PROXY_USER_COOKIE_NAME + \"=\" + URLEncoder.encode(user, \"ASCII\"));\n    }\n    OutputStream out = resp.getOutputStream();\n    try {\n      HttpResponse httpResp = client.execute(httpGet);\n      resp.setStatus(httpResp.getStatusLine().getStatusCode());\n      for (Header header : httpResp.getAllHeaders()) {\n        resp.setHeader(header.getName(), header.getValue());\n      }\n      if (c != null) {\n        resp.addCookie(c);\n      }\n      InputStream in = httpResp.getEntity().getContent();\n      if (in != null) {\n        IOUtils.copyBytes(in, out, 4096, true);\n      }\n    } finally {\n      httpGet.releaseConnection();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet": "  protected void doGet(HttpServletRequest req, HttpServletResponse resp) \n  throws IOException{\n    try {\n      String userApprovedParamS = \n        req.getParameter(ProxyUriUtils.PROXY_APPROVAL_PARAM);\n      boolean userWasWarned = false;\n      boolean userApproved = Boolean.valueOf(userApprovedParamS);\n      boolean securityEnabled = isSecurityEnabled();\n      final String remoteUser = req.getRemoteUser();\n      final String pathInfo = req.getPathInfo();\n\n      String[] parts = pathInfo.split(\"/\", 3);\n      if(parts.length < 2) {\n        LOG.warn(\"{} gave an invalid proxy path {}\", remoteUser,  pathInfo);\n        notFound(resp, \"Your path appears to be formatted incorrectly.\");\n        return;\n      }\n      //parts[0] is empty because path info always starts with a /\n      String appId = parts[1];\n      String rest = parts.length > 2 ? parts[2] : \"\";\n      ApplicationId id = Apps.toAppID(appId);\n      if(id == null) {\n        LOG.warn(\"{} attempting to access {} that is invalid\",\n            remoteUser, appId);\n        notFound(resp, appId + \" appears to be formatted incorrectly.\");\n        return;\n      }\n      \n      if(securityEnabled) {\n        String cookieName = getCheckCookieName(id); \n        Cookie[] cookies = req.getCookies();\n        if (cookies != null) {\n          for (Cookie c : cookies) {\n            if (cookieName.equals(c.getName())) {\n              userWasWarned = true;\n              userApproved = userApproved || Boolean.valueOf(c.getValue());\n              break;\n            }\n          }\n        }\n      }\n      \n      boolean checkUser = securityEnabled && (!userWasWarned || !userApproved);\n\n      ApplicationReport applicationReport;\n      try {\n        applicationReport = getApplicationReport(id);\n      } catch (ApplicationNotFoundException e) {\n        applicationReport = null;\n      }\n      if(applicationReport == null) {\n        LOG.warn(\"{} attempting to access {} that was not found\",\n            remoteUser, id);\n\n        URI toFetch =\n            ProxyUriUtils\n                .getUriFromTrackingPlugins(id, this.trackingUriPlugins);\n        if (toFetch != null) {\n          ProxyUtils.sendRedirect(req, resp, toFetch.toString());\n          return;\n        }\n\n        notFound(resp, \"Application \" + appId + \" could not be found, \" +\n                       \"please try the history server\");\n        return;\n      }\n      String original = applicationReport.getOriginalTrackingUrl();\n      URI trackingUri;\n      // fallback to ResourceManager's app page if no tracking URI provided\n      if(original == null || original.equals(\"N/A\")) {\n        ProxyUtils.sendRedirect(req, resp, \n            StringHelper.pjoin(rmAppPageUrlBase, id.toString()));\n        return;\n      } else {\n        if (ProxyUriUtils.getSchemeFromUrl(original).isEmpty()) {\n          trackingUri = ProxyUriUtils.getUriFromAMUrl(\n              WebAppUtils.getHttpSchemePrefix(conf), original);\n        } else {\n          trackingUri = new URI(original);\n        }\n      }\n\n      String runningUser = applicationReport.getUser();\n      if(checkUser && !runningUser.equals(remoteUser)) {\n        LOG.info(\"Asking {} if they want to connect to the \"\n            + \"app master GUI of {} owned by {}\",\n            remoteUser, appId, runningUser);\n        warnUserPage(resp, ProxyUriUtils.getPathAndQuery(id, rest, \n            req.getQueryString(), true), runningUser, id);\n        return;\n      }\n\n      // Append the user-provided path and query parameter to the original\n      // tracking url.\n      List<NameValuePair> queryPairs =\n          URLEncodedUtils.parse(req.getQueryString(), null);\n      UriBuilder builder = UriBuilder.fromUri(trackingUri);\n      for (NameValuePair pair : queryPairs) {\n        builder.queryParam(pair.getName(), pair.getValue());\n      }\n      URI toFetch = builder.path(rest).build();\n\n      LOG.info(\"{} is accessing unchecked {}\"\n          + \" which is the app master GUI of {} owned by {}\",\n          remoteUser, toFetch, appId, runningUser);\n\n      switch (applicationReport.getYarnApplicationState()) {\n        case KILLED:\n        case FINISHED:\n        case FAILED:\n          ProxyUtils.sendRedirect(req, resp, toFetch.toString());\n          return;\n        default:\n          // fall out of the switch\n      }\n      Cookie c = null;\n      if (userWasWarned && userApproved) {\n        c = makeCheckCookie(id, true);\n      }\n      proxyLink(req, resp, toFetch, c, getProxyHost());\n\n    } catch(URISyntaxException | YarnException e) {\n      throw new IOException(e); \n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.isSecurityEnabled": "  private boolean isSecurityEnabled() {\n    Boolean b = (Boolean) getServletContext()\n        .getAttribute(WebAppProxy.IS_SECURITY_ENABLED_ATTRIBUTE);\n    return b != null ? b : false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.getProxyHost": "  private String getProxyHost() throws IOException {\n    return ((String) getServletContext()\n        .getAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.makeCheckCookie": "  private static Cookie makeCheckCookie(ApplicationId id, boolean isSet) {\n    Cookie c = new Cookie(getCheckCookieName(id),String.valueOf(isSet));\n    c.setPath(ProxyUriUtils.getPath(id));\n    c.setMaxAge(60 * 60 * 2); //2 hours in seconds\n    return c;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.notFound": "  private static void notFound(HttpServletResponse resp, String message) \n    throws IOException {\n    ProxyUtils.notFound(resp, message);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.getCheckCookieName": "  private static String getCheckCookieName(ApplicationId id){\n    return \"checked_\"+id;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.getApplicationReport": "  private ApplicationReport getApplicationReport(ApplicationId id)\n      throws IOException, YarnException {\n    return ((AppReportFetcher) getServletContext()\n        .getAttribute(WebAppProxy.FETCHER_ATTRIBUTE)).getApplicationReport(id);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.warnUserPage": "  private static void warnUserPage(HttpServletResponse resp, String link, \n      String user, ApplicationId id) throws IOException {\n    //Set the cookie when we warn which overrides the query parameter\n    //This is so that if a user passes in the approved query parameter without\n    //having first visited this page then this page will still be displayed \n    resp.addCookie(makeCheckCookie(id, false));\n    resp.setContentType(MimeType.HTML);\n    Page p = new Page(resp.getWriter());\n    p.html().\n      h1(\"WARNING: The following page may not be safe!\").\n      h3().\n      _(\"click \").a(link, \"here\").\n      _(\" to continue to an Application Master web interface owned by \", user).\n      _().\n    _();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUriUtils.getPathAndQuery": "  public static String getPathAndQuery(ApplicationId id, String path, \n      String query, boolean approved) {\n    StringBuilder newp = new StringBuilder();\n    newp.append(getPath(id, path));\n    boolean first = appendQuery(newp, query, true);\n    if(approved) {\n      appendQuery(newp, PROXY_APPROVAL_PARAM+\"=true\", first);\n    }\n    return newp.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUriUtils.appendQuery": "  private static boolean appendQuery(StringBuilder builder, String query, \n      boolean first) {\n    if(query != null && !query.isEmpty()) {\n      if(first && !query.startsWith(\"?\")) {\n        builder.append('?');\n      }\n      if(!first && !query.startsWith(\"&\")) {\n        builder.append('&');\n      }\n      builder.append(query);\n      return false;\n    }\n    return first;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUriUtils.getPath": "  public static String getPath(ApplicationId id, String path) {\n    if(path == null) {\n      return getPath(id);\n    } else {\n      return ujoin(getPath(id), path);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUriUtils.getUriFromTrackingPlugins": "  public static URI getUriFromTrackingPlugins(ApplicationId id,\n      List<TrackingUriPlugin> trackingUriPlugins)\n      throws URISyntaxException {\n    URI toRet = null;\n    for(TrackingUriPlugin plugin : trackingUriPlugins)\n    {\n      toRet = plugin.getTrackingUri(id);\n      if (toRet != null)\n      {\n        return toRet;\n      }\n    }\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUtils.sendRedirect": "  public static void sendRedirect(HttpServletRequest request,\n      HttpServletResponse response,\n      String target)\n      throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Redirecting {} {} to {}\",\n          request.getMethod(), \n          request.getRequestURI(),\n          target);\n    }\n    String location = response.encodeRedirectURL(target);\n    response.setStatus(HttpServletResponse.SC_FOUND);\n    response.setHeader(LOCATION, location);\n    response.setContentType(MimeType.HTML);\n    PrintWriter writer = response.getWriter();\n    Page p = new Page(writer);\n    p.html()\n        .head().title(\"Moved\")._()\n        .body()\n        .h1(\"Moved\")\n        .div()\n          ._(\"Content has moved \")\n          .a(location, \"here\")._()\n        ._()._();\n    writer.close();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUtils.html": "    public HTML<ProxyUtils._> html() {\n      return new HTML<>(\"html\", null, EnumSet.of(EOpt.ENDTAG));\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUriUtils.getSchemeFromUrl": "  public static String getSchemeFromUrl(String url) {\n    int index = 0;\n    if (url != null) {\n      index = url.indexOf(\"://\");\n    }\n    if (index > 0) {\n      return url.substring(0, index);\n    } else {\n      return \"\";\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.ProxyUriUtils.getUriFromAMUrl": "  public static URI getUriFromAMUrl(String scheme, String noSchemeUrl)\n      throws URISyntaxException {\n      if (getSchemeFromUrl(noSchemeUrl).isEmpty()) {\n        /*\n         * check is made to make sure if AM reports with scheme then it will be\n         * used by default otherwise it will default to the one configured using\n         * \"yarn.http.policy\".\n         */\n        return new URI(scheme + noSchemeUrl);\n      } else {\n        return new URI(noSchemeUrl);\n      }\n    }"
        },
        "bug_report": {
            "Title": "AppMaster tracking URL is broken in HA",
            "Description": "After YARN-2713, the AppMaster link is broken in HA.  To repro \na) setup RM HA and ensure the first RM is not active,\nb) run a long sleep job and view the tracking url on the RM applications page\n\nThe log and full stack trace is shown below\n{noformat}\n2015-02-05 20:47:43,478 WARN org.mortbay.log: /proxy/application_1423182188062_0002/: java.net.BindException: Cannot assign requested address\n{noformat}\n{noformat}\njava.net.BindException: Cannot assign requested address\n\tat java.net.PlainSocketImpl.socketBind(Native Method)\n\tat java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)\n\tat java.net.Socket.bind(Socket.java:631)\n\tat java.net.Socket.<init>(Socket.java:423)\n\tat java.net.Socket.<init>(Socket.java:280)\n\tat org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)\n\tat org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)\n\tat org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)\n\tat org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink(WebAppProxyServlet.java:188)\n\tat org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(WebAppProxyServlet.java:345)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)\n{noformat}"
        }
    },
    {
        "filename": "YARN-2813.json",
        "creation_time": "2014-11-05T22:29:46.000+0000",
        "stack_trace": "```\njavax.ws.rs.WebApplicationException: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getDomains(TimelineWebServices.java:356)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n        at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:96)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:572)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:269)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:542)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1204)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n        at org.mortbay.jetty.Server.handle(Server.java:326)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n        at org.mortbay.jetty.security.SslSocketConnector$SslConnection.run(SslSocketConnector.java:713)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore.getDomains(MemoryTimelineStore.java:244)\n        at org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getDomains(TimelineDataManager.java:383)\n        at org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getDomains(TimelineWebServices.java:353)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getDomains": "  public TimelineDomains getDomains(\n      @Context HttpServletRequest req,\n      @Context HttpServletResponse res,\n      @QueryParam(\"owner\") String owner) {\n    init(res);\n    owner = parseStr(owner);\n    UserGroupInformation callerUGI = getUser(req);\n    if (owner == null || owner.length() == 0) {\n      if (callerUGI == null) {\n        throw new BadRequestException(\"Domain owner is not specified.\");\n      } else {\n        // By default it's going to list the caller's domains\n        owner = callerUGI.getShortUserName();\n      }\n    }\n    try {\n      return timelineDataManager.getDomains(owner, callerUGI);\n    } catch (Exception e) {\n      LOG.error(\"Error getting domains\", e);\n      throw new WebApplicationException(e,\n          Response.Status.INTERNAL_SERVER_ERROR);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.parseStr": "  private static String parseStr(String str) {\n    return str == null ? null : str.trim();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.init": "  private void init(HttpServletResponse response) {\n    response.setContentType(null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getUser": "  private static UserGroupInformation getUser(HttpServletRequest req) {\n    String remoteUser = req.getRemoteUser();\n    UserGroupInformation callerUGI = null;\n    if (remoteUser != null) {\n      callerUGI = UserGroupInformation.createRemoteUser(remoteUser);\n    }\n    return callerUGI;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.lib.StaticUserWebFilter.doFilter": "    public void doFilter(ServletRequest request, ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequest httpRequest = (HttpServletRequest) request;\n      // if the user is already authenticated, don't override it\n      if (httpRequest.getRemoteUser() != null) {\n        chain.doFilter(request, response);\n      } else {\n        HttpServletRequestWrapper wrapper = \n            new HttpServletRequestWrapper(httpRequest) {\n          @Override\n          public Principal getUserPrincipal() {\n            return user;\n          }\n          @Override\n          public String getRemoteUser() {\n            return username;\n          }\n        };\n        chain.doFilter(wrapper, response);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.lib.StaticUserWebFilter.getRemoteUser": "          public String getRemoteUser() {\n            return username;\n          }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter": "  protected void doFilter(FilterChain filterChain, HttpServletRequest request,\n      HttpServletResponse response) throws IOException, ServletException {\n    boolean requestCompleted = false;\n    UserGroupInformation ugi = null;\n    AuthenticationToken authToken = (AuthenticationToken)\n        request.getUserPrincipal();\n    if (authToken != null && authToken != AuthenticationToken.ANONYMOUS) {\n      // if the request was authenticated because of a delegation token,\n      // then we ignore proxyuser (this is the same as the RPC behavior).\n      ugi = (UserGroupInformation) request.getAttribute(\n          DelegationTokenAuthenticationHandler.DELEGATION_TOKEN_UGI_ATTRIBUTE);\n      if (ugi == null) {\n        String realUser = request.getUserPrincipal().getName();\n        ugi = UserGroupInformation.createRemoteUser(realUser,\n            handlerAuthMethod);\n        String doAsUser = getDoAs(request);\n        if (doAsUser != null) {\n          ugi = UserGroupInformation.createProxyUser(doAsUser, ugi);\n          try {\n            ProxyUsers.authorize(ugi, request.getRemoteHost());\n          } catch (AuthorizationException ex) {\n            HttpExceptionUtils.createServletExceptionResponse(response,\n                HttpServletResponse.SC_FORBIDDEN, ex);\n            requestCompleted = true;\n          }\n        }\n      }\n      UGI_TL.set(ugi);\n    }\n    if (!requestCompleted) {\n      final UserGroupInformation ugiF = ugi;\n      try {\n        request = new HttpServletRequestWrapper(request) {\n\n          @Override\n          public String getAuthType() {\n            return (ugiF != null) ? handlerAuthMethod.toString() : null;\n          }\n\n          @Override\n          public String getRemoteUser() {\n            return (ugiF != null) ? ugiF.getShortUserName() : null;\n          }\n\n          @Override\n          public Principal getUserPrincipal() {\n            return (ugiF != null) ? new Principal() {\n              @Override\n              public String getName() {\n                return ugiF.getUserName();\n              }\n            } : null;\n          }\n        };\n        super.doFilter(filterChain, request, response);\n      } finally {\n        UGI_TL.remove();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.getDoAs": "  static String getDoAs(HttpServletRequest request) {\n    List<NameValuePair> list = URLEncodedUtils.parse(request.getQueryString(),\n        UTF8_CHARSET);\n    if (list != null) {\n      for (NameValuePair nv : list) {\n        if (DelegationTokenAuthenticatedURL.DO_AS.\n            equalsIgnoreCase(nv.getName())) {\n          return nv.getValue();\n        }\n      }\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.getUserPrincipal": "          public Principal getUserPrincipal() {\n            return (ugiF != null) ? new Principal() {\n              @Override\n              public String getName() {\n                return ugiF.getUserName();\n              }\n            } : null;\n          }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.getName": "              public String getName() {\n                return ugiF.getUserName();\n              }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.doFilter": "    public void doFilter(ServletRequest request,\n                         ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequestWrapper quoted =\n        new RequestQuoter((HttpServletRequest) request);\n      HttpServletResponse httpResponse = (HttpServletResponse) response;\n\n      String mime = inferMimeType(request);\n      if (mime == null) {\n        httpResponse.setContentType(\"text/plain; charset=utf-8\");\n      } else if (mime.startsWith(\"text/html\")) {\n        // HTML with unspecified encoding, we want to\n        // force HTML with utf-8 encoding\n        // This is to avoid the following security issue:\n        // http://openmya.hacker.jp/hasegawa/security/utf7cs.html\n        httpResponse.setContentType(\"text/html; charset=utf-8\");\n      } else if (mime.startsWith(\"application/xml\")) {\n        httpResponse.setContentType(\"text/xml; charset=utf-8\");\n      }\n      chain.doFilter(quoted, httpResponse);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.inferMimeType": "    private String inferMimeType(ServletRequest request) {\n      String path = ((HttpServletRequest)request).getRequestURI();\n      ContextHandler.SContext sContext = (ContextHandler.SContext)config.getServletContext();\n      MimeTypes mimes = sContext.getContextHandler().getMimeTypes();\n      Buffer mimeBuffer = mimes.getMimeByExtension(path);\n      return (mimeBuffer == null) ? null : mimeBuffer.toString();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.NoCacheFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n                       FilterChain chain)\n    throws IOException, ServletException {\n    HttpServletResponse httpRes = (HttpServletResponse) res;\n    httpRes.setHeader(\"Cache-Control\", \"no-cache\");\n    long now = System.currentTimeMillis();\n    httpRes.addDateHeader(\"Expires\", now);\n    httpRes.addDateHeader(\"Date\", now);\n    httpRes.addHeader(\"Pragma\", \"no-cache\");\n    chain.doFilter(req, res);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore.getDomains": "  public TimelineDomains getDomains(String owner)\n      throws IOException {\n    List<TimelineDomain> domains = new ArrayList<TimelineDomain>();\n    for (TimelineDomain domain : domainsByOwner.get(owner)) {\n      TimelineDomain domainToReturn = createTimelineDomain(\n          domain.getId(),\n          domain.getDescription(),\n          domain.getOwner(),\n          domain.getReaders(),\n          domain.getWriters(),\n          domain.getCreatedTime(),\n          domain.getModifiedTime());\n      domains.add(domainToReturn);\n    }\n    Collections.sort(domains, new Comparator<TimelineDomain>() {\n      @Override\n      public int compare(\n          TimelineDomain domain1, TimelineDomain domain2) {\n         int result = domain2.getCreatedTime().compareTo(\n             domain1.getCreatedTime());\n         if (result == 0) {\n           return domain2.getModifiedTime().compareTo(\n               domain1.getModifiedTime());\n         } else {\n           return result;\n         }\n      }\n    });\n    TimelineDomains domainsToReturn = new TimelineDomains();\n    domainsToReturn.addDomains(domains);\n    return domainsToReturn;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore.createTimelineDomain": "  private static TimelineDomain createTimelineDomain(\n      String id, String description, String owner,\n      String readers, String writers,\n      Long createdTime, Long modifiedTime) {\n    TimelineDomain domainToStore = new TimelineDomain();\n    domainToStore.setId(id);\n    domainToStore.setDescription(description);\n    domainToStore.setOwner(owner);\n    domainToStore.setReaders(readers);\n    domainToStore.setWriters(writers);\n    domainToStore.setCreatedTime(createdTime);\n    domainToStore.setModifiedTime(modifiedTime);\n    return domainToStore;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getDomains": "  public TimelineDomains getDomains(String owner,\n      UserGroupInformation callerUGI) throws YarnException, IOException {\n    TimelineDomains domains = store.getDomains(owner);\n    boolean hasAccess = true;\n    if (domains.getDomains().size() > 0) {\n      // The owner for each domain is the same, just need to check one\n      hasAccess = timelineACLsManager.checkAccess(\n          callerUGI, domains.getDomains().get(0));\n    }\n    if (hasAccess) {\n      return domains;\n    } else {\n      return new TimelineDomains();\n    }\n  }"
        },
        "bug_report": {
            "Title": "NPE from MemoryTimelineStore.getDomains",
            "Description": "{code}\n2014-11-04 20:50:05,146 WARN org.apache.hadoop.yarn.webapp.GenericExceptionHandler: INTERNAL_SERVER_ERROR\njavax.ws.rs.WebApplicationException: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getDomains(TimelineWebServices.java:356)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n        at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:96)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:572)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:269)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:542)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1204)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n        at org.mortbay.jetty.Server.handle(Server.java:326)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n        at org.mortbay.jetty.security.SslSocketConnector$SslConnection.run(SslSocketConnector.java:713)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore.getDomains(MemoryTimelineStore.java:244)\n        at org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getDomains(TimelineDataManager.java:383)\n        at org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getDomains(TimelineWebServices.java:353)\n        ... 54 more\n{code}"
        }
    },
    {
        "filename": "YARN-1550.json",
        "creation_time": "2013-12-30T03:58:32.000+0000",
        "stack_trace": "```\njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        ....\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock.render(FairSchedulerAppsBlock.java:96)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:66)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:76)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock.render": "  @Override public void render(Block html) {\n    TBODY<TABLE<Hamlet>> tbody = html.\n      table(\"#apps\").\n        thead().\n          tr().\n            th(\".id\", \"ID\").\n            th(\".user\", \"User\").\n            th(\".name\", \"Name\").\n            th(\".queue\", \"Queue\").\n            th(\".fairshare\", \"Fair Share\").\n            th(\".starttime\", \"StartTime\").\n            th(\".finishtime\", \"FinishTime\").\n            th(\".state\", \"State\").\n            th(\".finalstatus\", \"FinalStatus\").\n            th(\".progress\", \"Progress\").\n            th(\".ui\", \"Tracking UI\")._()._().\n        tbody();\n    Collection<YarnApplicationState> reqAppStates = null;\n    String reqStateString = $(APP_STATE);\n    if (reqStateString != null && !reqStateString.isEmpty()) {\n      String[] appStateStrings = reqStateString.split(\",\");\n      reqAppStates = new HashSet<YarnApplicationState>(appStateStrings.length);\n      for(String stateString : appStateStrings) {\n        reqAppStates.add(YarnApplicationState.valueOf(stateString));\n      }\n    }\n    StringBuilder appsTableData = new StringBuilder(\"[\\n\");\n    for (RMApp app : apps.values()) {\n      if (reqAppStates != null && !reqAppStates.contains(app.getState())) {\n        continue;\n      }\n      AppInfo appInfo = new AppInfo(app, true);\n      String percent = String.format(\"%.1f\", appInfo.getProgress());\n      ApplicationAttemptId attemptId = app.getCurrentAppAttempt().getAppAttemptId();\n      int fairShare = fsinfo.getAppFairShare(attemptId);\n      //AppID numerical value parsed by parseHadoopID in yarn.dt.plugins.js\n      appsTableData.append(\"[\\\"<a href='\")\n      .append(url(\"app\", appInfo.getAppId())).append(\"'>\")\n      .append(appInfo.getAppId()).append(\"</a>\\\",\\\"\")\n      .append(StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(\n        appInfo.getUser()))).append(\"\\\",\\\"\")\n      .append(StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(\n        appInfo.getName()))).append(\"\\\",\\\"\")\n      .append(StringEscapeUtils.escapeJavaScript(StringEscapeUtils.escapeHtml(\n        appInfo.getQueue()))).append(\"\\\",\\\"\")\n      .append(fairShare).append(\"\\\",\\\"\")\n      .append(appInfo.getStartTime()).append(\"\\\",\\\"\")\n      .append(appInfo.getFinishTime()).append(\"\\\",\\\"\")\n      .append(appInfo.getState()).append(\"\\\",\\\"\")\n      .append(appInfo.getFinalStatus()).append(\"\\\",\\\"\")\n      // Progress bar\n      .append(\"<br title='\").append(percent)\n      .append(\"'> <div class='\").append(C_PROGRESSBAR).append(\"' title='\")\n      .append(join(percent, '%')).append(\"'> \").append(\"<div class='\")\n      .append(C_PROGRESSBAR_VALUE).append(\"' style='\")\n      .append(join(\"width:\", percent, '%')).append(\"'> </div> </div>\")\n      .append(\"\\\",\\\"<a href='\");\n\n      String trackingURL =\n        !appInfo.isTrackingUrlReady()? \"#\" : appInfo.getTrackingUrlPretty();\n      \n      appsTableData.append(trackingURL).append(\"'>\")\n      .append(appInfo.getTrackingUI()).append(\"</a>\\\"],\\n\");\n\n    }\n    if(appsTableData.charAt(appsTableData.length() - 2) == ',') {\n      appsTableData.delete(appsTableData.length()-2, appsTableData.length()-1);\n    }\n    appsTableData.append(\"]\");\n    html.script().$type(\"text/javascript\").\n    _(\"var appsTableData=\" + appsTableData)._();\n\n    tbody._()._();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.render": "  protected abstract void render(Block html);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.block": "  private Block block() {\n    if (block == null) {\n      block = new Block(writer(), context().nestLevel(), context().wasInline());\n    }\n    return block;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial": "  public void renderPartial() {\n    render();\n  }"
        },
        "bug_report": {
            "Title": "NPE in FairSchedulerAppsBlock#render",
            "Description": "three Steps :\n1\u3001debug at RMAppManager#submitApplication after code\nif (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw RPCUtil.getRemoteException(message);\n    }\n\n2\u3001submit one application:hadoop jar ~/hadoop-current/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.0.0-ydh2.2.0-tests.jar sleep -Dhadoop.job.ugi=test2,#111111 -Dmapreduce.job.queuename=p1 -m 1 -mt 1 -r 1\n\n3\u3001go in page :http://ip:50030/cluster/scheduler and find 500 ERROR\uff01\n\nthe log:\n{noformat}\n2013-12-30 11:51:43,795 ERROR org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /cluster/scheduler\njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        ....\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock.render(FairSchedulerAppsBlock.java:96)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:66)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:76)\n{noformat}"
        }
    },
    {
        "filename": "YARN-5006.json",
        "creation_time": "2016-04-28T08:26:38.000+0000",
        "stack_trace": "```\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.run": "    public void run() {\n      try {\n        while (true) {\n          if(isFencedState()) {\n            break;\n          }\n          // Create and delete fencing node\n          new SafeTransaction().commit();\n          Thread.sleep(zkSessionTimeout);\n        }\n      } catch (InterruptedException ie) {\n        LOG.info(VerifyActiveStatusThread.class.getName() + \" thread \" +\n            \"interrupted! Exiting!\");\n      } catch (Exception e) {\n        notifyStoreOperationFailed(new StoreFencedException());\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.commit": "    public void commit() throws Exception {\n      transactionFinal = transactionFinal.delete()\n          .forPath(fencingNodePath).and();\n      transactionFinal.commit();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal": "  public synchronized void storeApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateDataPB) throws Exception {\n    String nodeCreatePath = getNodePath(rmAppRoot, appId.toString());\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Storing info for app: \" + appId + \" at: \" + nodeCreatePath);\n    }\n    byte[] appStateData = appStateDataPB.getProto().toByteArray();\n    safeCreate(nodeCreatePath, appStateData, zkAcl,\n        CreateMode.PERSISTENT);\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.safeCreate": "  private void safeCreate(String path, byte[] data, List<ACL> acl,\n      CreateMode mode) throws Exception {\n    if (!exists(path)) {\n      SafeTransaction transaction = new SafeTransaction();\n      transaction.create(path, data, acl, mode);\n      transaction.commit();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getNodePath": "  String getNodePath(String root, String nodeName) {\n    return (root + \"/\" + nodeName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.transition": "    public RMStateStoreState transition(RMStateStore store,\n        RMStateStoreEvent event) {\n      if (!(event instanceof RMStateStoreRemoveAppAttemptEvent)) {\n        // should never happen\n        LOG.error(\"Illegal event type: \" + event.getClass());\n        return RMStateStoreState.ACTIVE;\n      }\n      boolean isFenced = false;\n      ApplicationAttemptId attemptId =\n          ((RMStateStoreRemoveAppAttemptEvent) event).getApplicationAttemptId();\n      ApplicationId appId = attemptId.getApplicationId();\n      LOG.info(\"Removing attempt \" + attemptId + \" from app: \" + appId);\n      try {\n        store.removeApplicationAttemptInternal(attemptId);\n      } catch (Exception e) {\n        LOG.error(\"Error removing attempt: \" + attemptId, e);\n        isFenced = store.notifyStoreOperationFailedInternal(e);\n      }\n      return finalState(isFenced);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeRMDelegationTokenState": "  protected abstract void storeRMDelegationTokenState(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate)\n      throws Exception;\n\n  /**\n   * RMDTSecretManager call this to remove the state of a delegation token\n   */\n  public void removeRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, null,\n        RMStateStoreEventType.REMOVE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationAttemptStateInternal": "  protected abstract void updateApplicationAttemptStateInternal(\n      ApplicationAttemptId attemptId,\n      ApplicationAttemptStateData attemptStateData) throws Exception;\n\n  /**\n   * RMDTSecretManager call this to store the state of a delegation token\n   * and sequence number\n   */\n  public void storeRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, renewDate,\n        RMStateStoreEventType.STORE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeApplicationAttemptInternal": "  protected abstract void removeApplicationAttemptInternal(\n      ApplicationAttemptId attemptId) throws Exception;\n\n\n  // TODO: This should eventually become cluster-Id + \"AM_RM_TOKEN_SERVICE\". See\n  // YARN-1779\n  public static final Text AM_RM_TOKEN_SERVICE = new Text(\n    \"AM_RM_TOKEN_SERVICE\");\n\n  public static final Text AM_CLIENT_TOKEN_MASTER_KEY_NAME =\n      new Text(\"YARN_CLIENT_TOKEN_MASTER_KEY\");\n  \n  public Credentials getCredentialsFromAppAttempt(RMAppAttempt appAttempt) {\n    Credentials credentials = new Credentials();\n\n    SecretKey clientTokenMasterKey =\n        appAttempt.getClientTokenMasterKey();\n    if(clientTokenMasterKey != null){\n      credentials.addSecretKey(AM_CLIENT_TOKEN_MASTER_KEY_NAME,\n          clientTokenMasterKey.getEncoded());\n    }\n    return credentials;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeApplicationStateInternal": "  protected abstract void removeApplicationStateInternal(\n      ApplicationStateData appState) throws Exception;\n\n  /**\n   * Non-blocking API\n   * ResourceManager services call this to remove an attempt from the state\n   * store\n   * This does not block the dispatcher threads\n   * There is no notification of completion for this operation.\n   */\n  @SuppressWarnings(\"unchecked\")\n  public synchronized void removeApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId) {\n    dispatcher.getEventHandler().handle(\n        new RMStateStoreRemoveAppAttemptEvent(applicationAttemptId));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeReservationState": "  protected abstract void storeReservationState(\n      ReservationAllocationStateProto reservationAllocation, String planName,\n      String reservationIdName) throws Exception;\n\n  /**\n   * Blocking API\n   * Derived classes must implement this method to remove the state of\n   * a reservation allocation.\n   */\n  protected abstract void removeReservationState(String planName,\n      String reservationIdName) throws Exception;\n\n  /**\n   * Blocking API\n   * Derived classes must implement this method to remove the state of\n   * DelegationToken Master Key\n   */\n  protected abstract void removeRMDTMasterKeyState(DelegationKey delegationKey)\n      throws Exception;\n\n  /**\n   * Blocking API Derived classes must implement this method to store or update\n   * the state of AMRMToken Master Key\n   */\n  protected abstract void storeOrUpdateAMRMTokenSecretManagerState(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate)\n      throws Exception;\n\n  /**\n   * Store or Update state of AMRMToken Master Key\n   */\n  public void storeOrUpdateAMRMTokenSecretManager(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate) {\n    handleStoreEvent(new RMStateStoreAMRMTokenEvent(\n        amrmTokenSecretManagerState, isUpdate,\n        RMStateStoreEventType.UPDATE_AMRM_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeRMDTMasterKeyState": "  protected abstract void removeRMDTMasterKeyState(DelegationKey delegationKey)\n      throws Exception;\n\n  /**\n   * Blocking API Derived classes must implement this method to store or update\n   * the state of AMRMToken Master Key\n   */\n  protected abstract void storeOrUpdateAMRMTokenSecretManagerState(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate)\n      throws Exception;\n\n  /**\n   * Store or Update state of AMRMToken Master Key\n   */\n  public void storeOrUpdateAMRMTokenSecretManager(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate) {\n    handleStoreEvent(new RMStateStoreAMRMTokenEvent(\n        amrmTokenSecretManagerState, isUpdate,\n        RMStateStoreEventType.UPDATE_AMRM_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.notifyApplication": "  private void notifyApplication(RMAppEvent event) {\n    rmDispatcher.getEventHandler().handle(event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeApplicationStateInternal": "  protected abstract void storeApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateData) throws Exception;\n\n  protected abstract void updateApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateData) throws Exception;\n  \n  @SuppressWarnings(\"unchecked\")\n  /**\n   * Non-blocking API\n   * ResourceManager services call this to store state on an application attempt\n   * This does not block the dispatcher threads\n   * RMAppAttemptStoredEvent will be sent on completion to notify the RMAppAttempt\n   */\n  public void storeNewApplicationAttempt(RMAppAttempt appAttempt) {\n    Credentials credentials = getCredentialsFromAppAttempt(appAttempt);\n\n    AggregateAppResourceUsage resUsage =\n        appAttempt.getRMAppAttemptMetrics().getAggregateAppResourceUsage();\n    ApplicationAttemptStateData attemptState =\n        ApplicationAttemptStateData.newInstance(\n            appAttempt.getAppAttemptId(),\n            appAttempt.getMasterContainer(),\n            credentials, appAttempt.getStartTime(),\n            resUsage.getMemorySeconds(),\n            resUsage.getVcoreSeconds());\n\n    dispatcher.getEventHandler().handle(\n      new RMStateStoreAppAttemptEvent(attemptState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeApplicationAttemptStateInternal": "  protected abstract void storeApplicationAttemptStateInternal(\n      ApplicationAttemptId attemptId,\n      ApplicationAttemptStateData attemptStateData) throws Exception;\n\n  protected abstract void updateApplicationAttemptStateInternal(\n      ApplicationAttemptId attemptId,\n      ApplicationAttemptStateData attemptStateData) throws Exception;\n\n  /**\n   * RMDTSecretManager call this to store the state of a delegation token\n   * and sequence number\n   */\n  public void storeRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, renewDate,\n        RMStateStoreEventType.STORE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.notifyApplicationAttempt": "  private void notifyApplicationAttempt(RMAppAttemptEvent event) {\n    rmDispatcher.getEventHandler().handle(event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeOrUpdateAMRMTokenSecretManagerState": "  protected abstract void storeOrUpdateAMRMTokenSecretManagerState(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate)\n      throws Exception;\n\n  /**\n   * Store or Update state of AMRMToken Master Key\n   */\n  public void storeOrUpdateAMRMTokenSecretManager(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate) {\n    handleStoreEvent(new RMStateStoreAMRMTokenEvent(\n        amrmTokenSecretManagerState, isUpdate,\n        RMStateStoreEventType.UPDATE_AMRM_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.finalState": "  private static RMStateStoreState finalState(boolean isFenced) {\n    return isFenced ? RMStateStoreState.FENCED : RMStateStoreState.ACTIVE;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationStateInternal": "  protected abstract void updateApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateData) throws Exception;\n  \n  @SuppressWarnings(\"unchecked\")\n  /**\n   * Non-blocking API\n   * ResourceManager services call this to store state on an application attempt\n   * This does not block the dispatcher threads\n   * RMAppAttemptStoredEvent will be sent on completion to notify the RMAppAttempt\n   */\n  public void storeNewApplicationAttempt(RMAppAttempt appAttempt) {\n    Credentials credentials = getCredentialsFromAppAttempt(appAttempt);\n\n    AggregateAppResourceUsage resUsage =\n        appAttempt.getRMAppAttemptMetrics().getAggregateAppResourceUsage();\n    ApplicationAttemptStateData attemptState =\n        ApplicationAttemptStateData.newInstance(\n            appAttempt.getAppAttemptId(),\n            appAttempt.getMasterContainer(),\n            credentials, appAttempt.getStartTime(),\n            resUsage.getMemorySeconds(),\n            resUsage.getVcoreSeconds());\n\n    dispatcher.getEventHandler().handle(\n      new RMStateStoreAppAttemptEvent(attemptState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeRMDTMasterKeyState": "  protected abstract void storeRMDTMasterKeyState(DelegationKey delegationKey)\n      throws Exception;\n\n  /**\n   * RMDTSecretManager call this to remove the state of a master key\n   */\n  public void removeRMDTMasterKey(DelegationKey delegationKey) {\n    handleStoreEvent(new RMStateStoreRMDTMasterKeyEvent(delegationKey,\n        RMStateStoreEventType.REMOVE_MASTERKEY));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeReservationState": "  protected abstract void removeReservationState(String planName,\n      String reservationIdName) throws Exception;\n\n  /**\n   * Blocking API\n   * Derived classes must implement this method to remove the state of\n   * DelegationToken Master Key\n   */\n  protected abstract void removeRMDTMasterKeyState(DelegationKey delegationKey)\n      throws Exception;\n\n  /**\n   * Blocking API Derived classes must implement this method to store or update\n   * the state of AMRMToken Master Key\n   */\n  protected abstract void storeOrUpdateAMRMTokenSecretManagerState(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate)\n      throws Exception;\n\n  /**\n   * Store or Update state of AMRMToken Master Key\n   */\n  public void storeOrUpdateAMRMTokenSecretManager(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate) {\n    handleStoreEvent(new RMStateStoreAMRMTokenEvent(\n        amrmTokenSecretManagerState, isUpdate,\n        RMStateStoreEventType.UPDATE_AMRM_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeRMDelegationTokenState": "  protected abstract void removeRMDelegationTokenState(\n      RMDelegationTokenIdentifier rmDTIdentifier) throws Exception;\n\n  /**\n   * RMDTSecretManager call this to update the state of a delegation token\n   * and sequence number\n   */\n  public void updateRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, renewDate,\n        RMStateStoreEventType.UPDATE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.notifyStoreOperationFailedInternal": "  private boolean notifyStoreOperationFailedInternal(\n      Exception failureCause) {\n    boolean isFenced = false;\n    LOG.error(\"State store operation failed \", failureCause);\n    if (HAUtil.isHAEnabled(getConfig())) {\n      LOG.warn(\"State-store fenced ! Transitioning RM to standby\");\n      isFenced = true;\n      Thread standByTransitionThread =\n          new Thread(new StandByTransitionThread());\n      standByTransitionThread.setName(\"StandByTransitionThread Handler\");\n      standByTransitionThread.start();\n    } else if (YarnConfiguration.shouldRMFailFast(getConfig())) {\n      LOG.fatal(\"Fail RM now due to state-store error!\");\n      rmDispatcher.getEventHandler().handle(\n          new RMFatalEvent(RMFatalEventType.STATE_STORE_OP_FAILED,\n              failureCause));\n    } else {\n      LOG.warn(\"Skip the state-store error.\");\n    }\n    return isFenced;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateRMDelegationTokenState": "  protected abstract void updateRMDelegationTokenState(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate)\n      throws Exception;\n\n  /**\n   * RMDTSecretManager call this to store the state of a master key\n   */\n  public void storeRMDTMasterKey(DelegationKey delegationKey) {\n    handleStoreEvent(new RMStateStoreRMDTMasterKeyEvent(delegationKey,\n        RMStateStoreEventType.STORE_MASTERKEY));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent": "  protected void handleStoreEvent(RMStateStoreEvent event) {\n    this.writeLock.lock();\n    try {\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing event of type \" + event.getType());\n      }\n\n      final RMStateStoreState oldState = getRMStateStoreState();\n\n      this.stateMachine.doTransition(event.getType(), event);\n\n      if (oldState != getRMStateStoreState()) {\n        LOG.info(\"RMStateStore state change from \" + oldState + \" to \"\n            + getRMStateStoreState());\n      }\n\n    } catch (InvalidStateTransitionException e) {\n      LOG.error(\"Can't handle this event at current state\", e);\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.getRMStateStoreState": "  public RMStateStoreState getRMStateStoreState() {\n    this.readLock.lock();\n    try {\n      return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handle": "    public void handle(RMStateStoreEvent event) {\n      handleStoreEvent(event);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreAMRMTokenEvent.isUpdate": "  public boolean isUpdate() {\n    return isUpdate;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreStoreReservationEvent.getReservationAllocation": "  public ReservationAllocationStateProto getReservationAllocation() {\n    return reservationAllocation;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreStoreReservationEvent.getPlanName": "  public String getPlanName() {\n    return planName;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreAMRMTokenEvent.getAmrmTokenSecretManagerState": "  public AMRMTokenSecretManagerState getAmrmTokenSecretManagerState() {\n    return amrmTokenSecretManagerState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreRMDTEvent.getRmDTIdentifier": "  public RMDelegationTokenIdentifier getRmDTIdentifier() {\n    return rmDTIdentifier;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreStoreReservationEvent.getReservationIdName": "  public String getReservationIdName() {\n    return reservationIdName;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreRMDTEvent.getRenewDate": "  public Long getRenewDate() {\n    return renewDate;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "ResourceManager quit due to ApplicationStateData exceed the limit  size of znode in zk",
            "Description": "Client submit a job, this job add 10000 file into DistributedCache. when the job is submitted, ResourceManager sotre ApplicationStateData into zk. ApplicationStateData  is exceed the limit size of znode. RM exit 1.   \n\nThe related code in RMStateStore.java :\n{code}\n  private static class StoreAppTransition\n      implements SingleArcTransition<RMStateStore, RMStateStoreEvent> {\n    @Override\n    public void transition(RMStateStore store, RMStateStoreEvent event) {\n      if (!(event instanceof RMStateStoreAppEvent)) {\n        // should never happen\n        LOG.error(\"Illegal event type: \" + event.getClass());\n        return;\n      }\n      ApplicationState appState = ((RMStateStoreAppEvent) event).getAppState();\n      ApplicationId appId = appState.getAppId();\n      ApplicationStateData appStateData = ApplicationStateData\n          .newInstance(appState);\n      LOG.info(\"Storing info for app: \" + appId);\n      try {  \n        store.storeApplicationStateInternal(appId, appStateData);  //store the appStateData\n        store.notifyApplication(new RMAppEvent(appId,\n               RMAppEventType.APP_NEW_SAVED));\n      } catch (Exception e) {\n        LOG.error(\"Error storing app: \" + appId, e);\n        store.notifyStoreOperationFailed(e);   //handle fail event, system exit \n      }\n    };\n  }\n{code}\n\nThe Exception log:\n{code}\n ...\n2016-04-20 11:26:35,732 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore AsyncDispatcher event handler: Maxed out ZK retries. Giving up!\n\n2016-04-20 11:26:35,732 ERROR org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore AsyncDispatcher event handler: Error storing app: application_1461061795989_17671\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n\n   ...\n2016-04-20 11:26:45,613 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager AsyncDispatcher event handler: Received a org.apache.hadoop.yarn.server.resourcemanager.RMFatalEvent of type STATE_STORE_OP_FAILED. Cause:\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore\n.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n2016-04-20 11:26:45,615 INFO org.apache.hadoop.util.ExitUtil AsyncDispatcher event handler: Exiting with status 1\n2016-04-20 11:26:45,622 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager Thread[Thread-17,5,main]: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\n2016-04-20 11:26:45,623 INFO org.mortbay.log Thread-1: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.0.0.1:9088\n2016-04-20 11:26:45,623 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager Thread[Thread-21,5,main]: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\n2016-04-20 11:26:45,624 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager Thread[Thread-19,5,main]: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\n2016-04-20 11:26:45,724 INFO org.apache.hadoop.ipc.Server Thread-1: Stopping server on 9033\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ipc.Server IPC Server listener on 9033: Stopping IPC Server listener on 9033\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ha.ActiveStandbyElector Thread-1: Yielding from election\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ipc.Server IPC Server Responder: Stopping IPC Server Responder\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ha.ActiveStandbyElector Thread-1: Deleting bread-crumb of active node...\n2016-04-20 11:26:45,729 INFO org.apache.zookeeper.ZooKeeper Thread-1: Session: 0x2504c1df9409094 closed\n2016-04-20 11:26:45,729 WARN org.apache.hadoop.ha.ActiveStandbyElector main-EventThread: Ignoring stale result from old client with sessionId 0x2504c1df9409094\n2016-04-20 11:26:45,729 INFO org.apache.zookeeper.ClientCnxn main-EventThread: EventThread shut down\n\n{code}\n"
        }
    },
    {
        "filename": "YARN-5728.json",
        "creation_time": "2016-10-13T05:16:28.000+0000",
        "stack_trace": "```\njava.lang.Exception: test timed out after 60000 milliseconds\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:130)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)\n\tat com.sun.proxy.$Proxy85.nodeHeartbeat(Unknown Source)\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.testUpdateNodeUtilization(TestMiniYarnClusterNodeUtilization.java:113)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.processWaitTimeAndRetryInfo": "    CallReturn processWaitTimeAndRetryInfo() throws InterruptedIOException {\n      final Long waitTime = getWaitTime(Time.monotonicNow());\n      LOG.trace(\"#{} processRetryInfo: retryInfo={}, waitTime={}\",\n          callId, retryInfo, waitTime);\n      if (waitTime != null && waitTime > 0) {\n        try {\n          Thread.sleep(retryInfo.delay);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.warn(\"Interrupted while waiting to retry\", e);\n          InterruptedIOException intIOE = new InterruptedIOException(\n              \"Retry interrupted\");\n          intIOE.initCause(e);\n          throw intIOE;\n        }\n      }\n      processRetryInfo();\n      return CallReturn.RETRY;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.getWaitTime": "    synchronized Long getWaitTime(final long now) {\n      return retryInfo == null? null: retryInfo.retryTime - now;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.processRetryInfo": "    synchronized void processRetryInfo() {\n      counters.retries++;\n      if (retryInfo.isFailover()) {\n        retryInvocationHandler.proxyDescriptor.failover(\n            retryInfo.expectedFailoverCount, method, callId);\n        counters.failovers++;\n      }\n      retryInfo = null;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invokeOnce": "    synchronized CallReturn invokeOnce() {\n      try {\n        if (retryInfo != null) {\n          return processWaitTimeAndRetryInfo();\n        }\n\n        // The number of times this invocation handler has ever been failed over\n        // before this method invocation attempt. Used to prevent concurrent\n        // failed method invocations from triggering multiple failover attempts.\n        final long failoverCount = retryInvocationHandler.getFailoverCount();\n        try {\n          return invoke();\n        } catch (Exception e) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(toString(), e);\n          }\n          if (Thread.currentThread().isInterrupted()) {\n            // If interrupted, do not retry.\n            throw e;\n          }\n\n          retryInfo = retryInvocationHandler.handleException(\n              method, callId, retryPolicy, counters, failoverCount, e);\n          return processWaitTimeAndRetryInfo();\n        }\n      } catch(Throwable t) {\n        return new CallReturn(t);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.handleException": "  private RetryInfo handleException(final Method method, final int callId,\n      final RetryPolicy policy, final Counters counters,\n      final long expectFailoverCount, final Exception e) throws Exception {\n    final RetryInfo retryInfo = RetryInfo.newRetryInfo(policy, e,\n        counters, proxyDescriptor.idempotentOrAtMostOnce(method),\n        expectFailoverCount);\n    if (retryInfo.isFail()) {\n      // fail.\n      if (retryInfo.action.reason != null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Exception while invoking call #\" + callId + \" \"\n              + proxyDescriptor.getProxyInfo().getString(method.getName())\n              + \". Not retrying because \" + retryInfo.action.reason, e);\n        }\n      }\n      throw e;\n    }\n\n    log(method, retryInfo.isFailover(), counters.failovers, retryInfo.delay, e);\n    return retryInfo;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invoke": "  public Object invoke(Object proxy, Method method, Object[] args)\n      throws Throwable {\n    final boolean isRpc = isRpcInvocation(proxyDescriptor.getProxy());\n    final int callId = isRpc? Client.nextCallId(): RpcConstants.INVALID_CALL_ID;\n\n    final Call call = newCall(method, args, isRpc, callId);\n    while (true) {\n      final CallReturn c = call.invokeOnce();\n      final CallReturn.State state = c.getState();\n      if (state == CallReturn.State.ASYNC_INVOKED) {\n        return null; // return null for async calls\n      } else if (c.getState() != CallReturn.State.RETRY) {\n        return c.getReturnValue();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.getFailoverCount": "  private long getFailoverCount() {\n    return proxyDescriptor.getFailoverCount();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.toString": "    public String toString() {\n      return getClass().getSimpleName() + \"#\" + callId + \": \"\n          + method.getDeclaringClass().getSimpleName() + \".\" + method.getName()\n          + \"(\" + (args == null || args.length == 0? \"\": Arrays.toString(args))\n          +  \")\";\n    }"
        },
        "bug_report": {
            "Title": "TestMiniYarnClusterNodeUtilization.testUpdateNodeUtilization timeout",
            "Description": "TestMiniYARNClusterNodeUtilization.testUpdateNodeUtilization is failing by timeout.\nhttps://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/192/testReport/junit/org.apache.hadoop.yarn.server/TestMiniYarnClusterNodeUtilization/testUpdateNodeUtilization/\n{noformat}\njava.lang.Exception: test timed out after 60000 milliseconds\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:130)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)\n\tat com.sun.proxy.$Proxy85.nodeHeartbeat(Unknown Source)\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.testUpdateNodeUtilization(TestMiniYarnClusterNodeUtilization.java:113)\n{noformat}"
        }
    },
    {
        "filename": "YARN-2805.json",
        "creation_time": "2014-11-04T20:37:09.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to login\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:211)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1229)\nCaused by: java.io.IOException: Login failure for rm/IP@EXAMPLE.COM from keytab /etc/security/keytabs/rm.service.keytab: javax.security.auth.login.LoginException: Unable to obtain password from user\n\n\tat org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:935)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit": "    protected void serviceInit(Configuration conf) throws Exception {\n      this.shouldExitOnError =\n          conf.getBoolean(Dispatcher.DISPATCHER_EXIT_ON_ERROR_KEY,\n            Dispatcher.DEFAULT_DISPATCHER_EXIT_ON_ERROR);\n      super.serviceInit(conf);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createPolicyMonitors": "    protected void createPolicyMonitors() {\n      if (scheduler instanceof PreemptableResourceScheduler\n          && conf.getBoolean(YarnConfiguration.RM_SCHEDULER_ENABLE_MONITORS,\n          YarnConfiguration.DEFAULT_RM_SCHEDULER_ENABLE_MONITORS)) {\n        LOG.info(\"Loading policy monitors\");\n        List<SchedulingEditPolicy> policies = conf.getInstances(\n            YarnConfiguration.RM_SCHEDULER_MONITOR_POLICIES,\n            SchedulingEditPolicy.class);\n        if (policies.size() > 0) {\n          rmDispatcher.register(ContainerPreemptEventType.class,\n              new RMContainerPreemptEventDispatcher(\n                  (PreemptableResourceScheduler) scheduler));\n          for (SchedulingEditPolicy policy : policies) {\n            LOG.info(\"LOADING SchedulingEditPolicy:\" + policy.getPolicyName());\n            // periodically check whether we need to take action to guarantee\n            // constraints\n            SchedulingMonitor mon = new SchedulingMonitor(rmContext, policy);\n            addService(mon);\n          }\n        } else {\n          LOG.warn(\"Policy monitors configured (\" +\n              YarnConfiguration.RM_SCHEDULER_ENABLE_MONITORS +\n              \") but none specified (\" +\n              YarnConfiguration.RM_SCHEDULER_MONITOR_POLICIES + \")\");\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAdminService": "  protected AdminService createAdminService() {\n    return new AdminService(this, rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createClientRMService": "  protected ClientRMService createClientRMService() {\n    return new ClientRMService(this.rmContext, scheduler, this.rmAppManager,\n        this.applicationACLsManager, this.queueACLsManager,\n        this.rmContext.getRMDelegationTokenSecretManager());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMApplicationHistoryWriter": "  protected RMApplicationHistoryWriter createRMApplicationHistoryWriter() {\n    return new RMApplicationHistoryWriter();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createReservationSystem": "  protected ReservationSystem createReservationSystem() {\n    String reservationClassName =\n        conf.get(YarnConfiguration.RM_RESERVATION_SYSTEM_CLASS,\n            AbstractReservationSystem.getDefaultReservationSystem(scheduler));\n    if (reservationClassName == null) {\n      return null;\n    }\n    LOG.info(\"Using ReservationSystem: \" + reservationClassName);\n    try {\n      Class<?> reservationClazz = Class.forName(reservationClassName);\n      if (ReservationSystem.class.isAssignableFrom(reservationClazz)) {\n        return (ReservationSystem) ReflectionUtils.newInstance(\n            reservationClazz, this.conf);\n      } else {\n        throw new YarnRuntimeException(\"Class: \" + reservationClassName\n            + \" not instance of \" + ReservationSystem.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\n          \"Could not instantiate ReservationSystem: \" + reservationClassName, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createSystemMetricsPublisher": "  protected SystemMetricsPublisher createSystemMetricsPublisher() {\n    return new SystemMetricsPublisher(); \n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMSecretManagerService": "  protected RMSecretManagerService createRMSecretManagerService() {\n    return new RMSecretManagerService(conf, rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLivelinessMonitor": "  protected AMLivelinessMonitor createAMLivelinessMonitor() {\n    return new AMLivelinessMonitor(this.rmDispatcher);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices": "  protected void createAndInitActiveServices() throws Exception {\n    activeServices = new RMActiveServices();\n    activeServices.init(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNodeLabelManager": "  protected RMNodeLabelsManager createNodeLabelManager()\n      throws InstantiationException, IllegalAccessException {\n    Class<? extends RMNodeLabelsManager> nlmCls =\n        conf.getClass(YarnConfiguration.RM_NODE_LABELS_MANAGER_CLASS,\n            MemoryRMNodeLabelsManager.class, RMNodeLabelsManager.class);\n    return nlmCls.newInstance();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.doSecureLogin": "  protected void doSecureLogin() throws IOException {\n\tInetSocketAddress socAddr = getBindAddress(conf);\n    SecurityUtil.login(this.conf, YarnConfiguration.RM_KEYTAB,\n        YarnConfiguration.RM_PRINCIPAL, socAddr.getHostName());\n\n    // if security is enable, set rmLoginUGI as UGI of loginUser\n    if (UserGroupInformation.isSecurityEnabled()) {\n      this.rmLoginUGI = UserGroupInformation.getLoginUser();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createScheduler": "  protected ResourceScheduler createScheduler() {\n    String schedulerClassName = conf.get(YarnConfiguration.RM_SCHEDULER,\n        YarnConfiguration.DEFAULT_RM_SCHEDULER);\n    LOG.info(\"Using Scheduler: \" + schedulerClassName);\n    try {\n      Class<?> schedulerClazz = Class.forName(schedulerClassName);\n      if (ResourceScheduler.class.isAssignableFrom(schedulerClazz)) {\n        return (ResourceScheduler) ReflectionUtils.newInstance(schedulerClazz,\n            this.conf);\n      } else {\n        throw new YarnRuntimeException(\"Class: \" + schedulerClassName\n            + \" not instance of \" + ResourceScheduler.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\"Could not instantiate Scheduler: \"\n          + schedulerClassName, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createSchedulerEventDispatcher": "  protected EventHandler<SchedulerEvent> createSchedulerEventDispatcher() {\n    return new SchedulerEventDispatcher(this.scheduler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNMLivelinessMonitor": "  private NMLivelinessMonitor createNMLivelinessMonitor() {\n    return new NMLivelinessMonitor(this.rmContext\n        .getDispatcher());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setupDispatcher": "  private Dispatcher setupDispatcher() {\n    Dispatcher dispatcher = createDispatcher();\n    dispatcher.register(RMFatalEventType.class,\n        new ResourceManager.RMFatalEventDispatcher(this.rmContext, this));\n    return dispatcher;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createApplicationMasterService": "  protected ApplicationMasterService createApplicationMasterService() {\n    return new ApplicationMasterService(this.rmContext, scheduler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createQueueACLsManager": "  protected QueueACLsManager createQueueACLsManager(ResourceScheduler scheduler,\n      Configuration conf) {\n    return new QueueACLsManager(scheduler, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMAppManager": "  protected RMAppManager createRMAppManager() {\n    return new RMAppManager(this.rmContext, this.scheduler, this.masterService,\n      this.applicationACLsManager, this.conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLauncher": "  protected ApplicationMasterLauncher createAMLauncher() {\n    return new ApplicationMasterLauncher(this.rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createResourceTrackerService": "  protected ResourceTrackerService createResourceTrackerService() {\n    return new ResourceTrackerService(this.rmContext, this.nodesListManager,\n        this.nmLivelinessMonitor,\n        this.rmContext.getContainerTokenSecretManager(),\n        this.rmContext.getNMTokenSecretManager());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.validateConfigs": "  protected static void validateConfigs(Configuration conf) {\n    // validate max-attempts\n    int globalMaxAppAttempts =\n        conf.getInt(YarnConfiguration.RM_AM_MAX_ATTEMPTS,\n        YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS);\n    if (globalMaxAppAttempts <= 0) {\n      throw new YarnRuntimeException(\"Invalid global max attempts configuration\"\n          + \", \" + YarnConfiguration.RM_AM_MAX_ATTEMPTS\n          + \"=\" + globalMaxAppAttempts + \", it should be a positive integer.\");\n    }\n\n    // validate expireIntvl >= heartbeatIntvl\n    long expireIntvl = conf.getLong(YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_RM_NM_EXPIRY_INTERVAL_MS);\n    long heartbeatIntvl =\n        conf.getLong(YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS,\n            YarnConfiguration.DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS);\n    if (expireIntvl < heartbeatIntvl) {\n      throw new YarnRuntimeException(\"Nodemanager expiry interval should be no\"\n          + \" less than heartbeat interval, \"\n          + YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS + \"=\" + expireIntvl\n          + \", \" + YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS + \"=\"\n          + heartbeatIntvl);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createDelegationTokenRenewer": "  protected DelegationTokenRenewer createDelegationTokenRenewer() {\n    return new DelegationTokenRenewer();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main": "  public static void main(String argv[]) {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ResourceManager.class, argv, LOG);\n    try {\n      Configuration conf = new YarnConfiguration();\n      // If -format-state-store, then delete RMStateStore; else startup normally\n      if (argv.length == 1 && argv[0].equals(\"-format-state-store\")) {\n        deleteRMStateStore(conf);\n      } else {\n        ResourceManager resourceManager = new ResourceManager();\n        ShutdownHookManager.get().addShutdownHook(\n          new CompositeServiceShutdownHook(resourceManager),\n          SHUTDOWN_HOOK_PRIORITY);\n        resourceManager.init(conf);\n        resourceManager.start();\n      }\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ResourceManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.deleteRMStateStore": "  private static void deleteRMStateStore(Configuration conf) throws Exception {\n    RMStateStore rmStore = RMStateStoreFactory.getStore(conf);\n    rmStore.init(conf);\n    rmStore.start();\n    try {\n      LOG.info(\"Deleting ResourceManager state store...\");\n      rmStore.deleteStore();\n      LOG.info(\"State store deleted\");\n    } finally {\n      rmStore.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab": "  static void loginUserFromKeytab(String user,\n                                  String path\n                                  ) throws IOException {\n    if (!isSecurityEnabled())\n      return;\n\n    keytabFile = path;\n    keytabPrincipal = user;\n    Subject subject = new Subject();\n    LoginContext login; \n    long start = 0;\n    try {\n      login = newLoginContext(HadoopConfiguration.KEYTAB_KERBEROS_CONFIG_NAME,\n            subject, new HadoopConfiguration());\n      start = Time.now();\n      login.login();\n      metrics.loginSuccess.add(Time.now() - start);\n      loginUser = new UserGroupInformation(subject);\n      loginUser.setLogin(login);\n      loginUser.setAuthenticationMethod(AuthenticationMethod.KERBEROS);\n    } catch (LoginException le) {\n      if (start > 0) {\n        metrics.loginFailure.add(Time.now() - start);\n      }\n      throw new IOException(\"Login failure for \" + user + \" from keytab \" + \n                            path+ \": \" + le, le);\n    }\n    LOG.info(\"Login successful for user \" + keytabPrincipal\n        + \" using keytab file \" + keytabFile);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.login": "    public boolean login() throws LoginException {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"hadoop login\");\n      }\n      return true;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.isSecurityEnabled": "  public static boolean isSecurityEnabled() {\n    return !isAuthenticationMethodEnabled(AuthenticationMethod.SIMPLE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.setAuthenticationMethod": "  public void setAuthenticationMethod(AuthMethod authMethod) {\n    user.setAuthenticationMethod(AuthenticationMethod.valueOf(authMethod));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.setLogin": "  private void setLogin(LoginContext login) {\n    user.setLogin(login);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.newLoginContext": "  private static LoginContext\n  newLoginContext(String appName, Subject subject,\n    javax.security.auth.login.Configuration loginConf)\n      throws LoginException {\n    // Temporarily switch the thread's ContextClassLoader to match this\n    // class's classloader, so that we can properly load HadoopLoginModule\n    // from the JAAS libraries.\n    Thread t = Thread.currentThread();\n    ClassLoader oldCCL = t.getContextClassLoader();\n    t.setContextClassLoader(HadoopLoginModule.class.getClassLoader());\n    try {\n      return new LoginContext(appName, subject, null, loginConf);\n    } finally {\n      t.setContextClassLoader(oldCCL);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.processRMProxyUsersConf": "  public static void processRMProxyUsersConf(Configuration conf) {\n    Map<String, String> rmProxyUsers = new HashMap<String, String>();\n    for (Map.Entry<String, String> entry : conf) {\n      String propName = entry.getKey();\n      if (propName.startsWith(YarnConfiguration.RM_PROXY_USER_PREFIX)) {\n        rmProxyUsers.put(ProxyUsers.CONF_HADOOP_PROXYUSER + \".\" +\n            propName.substring(YarnConfiguration.RM_PROXY_USER_PREFIX.length()),\n            entry.getValue());\n      }\n    }\n    for (Map.Entry<String, String> entry : rmProxyUsers.entrySet()) {\n      conf.set(entry.getKey(), entry.getValue());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setSystemMetricsPublisher": "  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setNodeLabelManager": "  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setClientRMService": "  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMApplicationHistoryWriter": "  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "RM2 in HA setup tries to login using the RM1's kerberos principal",
            "Description": "{code}\n2014-11-04 08:41:08,705 INFO  resourcemanager.ResourceManager (SignalLogger.java:register(91)) - registered UNIX signal handlers for [TERM, HUP, INT]\n2014-11-04 08:41:10,636 INFO  service.AbstractService (AbstractService.java:noteFailure(272)) - Service ResourceManager failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to login\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to login\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:211)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1229)\nCaused by: java.io.IOException: Login failure for rm/IP@EXAMPLE.COM from keytab /etc/security/keytabs/rm.service.keytab: javax.security.auth.login.LoginException: Unable to obtain password from user\n\n\tat org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:935)\n\n{code}"
        }
    },
    {
        "filename": "YARN-4744.json",
        "creation_time": "2016-02-29T10:08:57.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=9:\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:173)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.signalContainer(DefaultLinuxContainerRuntime.java:132)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.signalContainer(DelegatingLinuxContainerRuntime.java:109)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.signalContainer(LinuxContainerExecutor.java:513)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer(ContainerLaunch.java:520)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:139)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:55)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: ExitCodeException exitCode=9:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:927)\n        at org.apache.hadoop.util.Shell.run(Shell.java:838)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1117)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:150)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation": "  public String executePrivilegedOperation(PrivilegedOperation operation,\n      boolean grabOutput) throws PrivilegedOperationException {\n    return executePrivilegedOperation(null, operation, null, null, grabOutput);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.getPrivilegedOperationExecutionCommand": "  public String[] getPrivilegedOperationExecutionCommand(List<String>\n      prefixCommands,\n      PrivilegedOperation operation) {\n    List<String> fullCommand = new ArrayList<String>();\n\n    if (prefixCommands != null && !prefixCommands.isEmpty()) {\n      fullCommand.addAll(prefixCommands);\n    }\n\n    fullCommand.add(containerExecutorExe);\n\n    String cliSwitch = operation.getOperationType().getOption();\n\n    if (!cliSwitch.isEmpty()) {\n      fullCommand.add(cliSwitch);\n    }\n\n    fullCommand.addAll(operation.getArguments());\n\n    String[] fullCommandArray =\n        fullCommand.toArray(new String[fullCommand.size()]);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Privileged Execution Command Array: \" +\n          Arrays.toString(fullCommandArray));\n    }\n\n    return fullCommandArray;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.signalContainer": "  public void signalContainer(ContainerRuntimeContext ctx)\n      throws ContainerExecutionException {\n    Container container = ctx.getContainer();\n    PrivilegedOperation signalOp = new PrivilegedOperation(\n        PrivilegedOperation.OperationType.SIGNAL_CONTAINER, (String) null);\n\n    signalOp.appendArgs(ctx.getExecutionAttribute(RUN_AS_USER),\n        ctx.getExecutionAttribute(USER),\n        Integer.toString(PrivilegedOperation.RunAsUserCommand\n            .SIGNAL_CONTAINER.getValue()),\n        ctx.getExecutionAttribute(PID),\n        Integer.toString(ctx.getExecutionAttribute(SIGNAL).getValue()));\n\n    try {\n      PrivilegedOperationExecutor executor = PrivilegedOperationExecutor\n          .getInstance(conf);\n\n      executor.executePrivilegedOperation(null,\n          signalOp, null, container.getLaunchContext().getEnvironment(),\n          false);\n    } catch (PrivilegedOperationException e) {\n      LOG.warn(\"Signal container failed. Exception: \", e);\n\n      throw new ContainerExecutionException(\"Signal container failed\", e\n          .getExitCode(), e.getOutput(), e.getErrorOutput());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.signalContainer": "  public void signalContainer(ContainerRuntimeContext ctx)\n      throws ContainerExecutionException {\n    Container container = ctx.getContainer();\n    LinuxContainerRuntime runtime = pickContainerRuntime(container);\n\n    runtime.signalContainer(ctx);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.pickContainerRuntime": "  private LinuxContainerRuntime pickContainerRuntime(Container container) {\n    Map<String, String> env = container.getLaunchContext().getEnvironment();\n    LinuxContainerRuntime runtime;\n\n    if (DockerLinuxContainerRuntime.isDockerContainerRequested(env)){\n      runtime = dockerLinuxContainerRuntime;\n    } else  {\n      runtime = defaultLinuxContainerRuntime;\n    }\n\n    if (LOG.isInfoEnabled()) {\n      LOG.info(\"Using container runtime: \" + runtime.getClass()\n          .getSimpleName());\n    }\n\n    return runtime;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.signalContainer": "  public boolean signalContainer(ContainerSignalContext ctx)\n      throws IOException {\n    Container container = ctx.getContainer();\n    String user = ctx.getUser();\n    String pid = ctx.getPid();\n    Signal signal = ctx.getSignal();\n\n    verifyUsernamePattern(user);\n    String runAsUser = getRunAsUser(user);\n\n    ContainerRuntimeContext runtimeContext = new ContainerRuntimeContext\n        .Builder(container)\n        .setExecutionAttribute(RUN_AS_USER, runAsUser)\n        .setExecutionAttribute(USER, user)\n        .setExecutionAttribute(PID, pid)\n        .setExecutionAttribute(SIGNAL, signal)\n        .build();\n\n    try {\n      linuxContainerRuntime.signalContainer(runtimeContext);\n    } catch (ContainerExecutionException e) {\n      int retCode = e.getExitCode();\n      if (retCode == PrivilegedOperation.ResultCode.INVALID_CONTAINER_PID\n          .getValue()) {\n        return false;\n      }\n      LOG.warn(\"Error in signalling container \" + pid + \" with \" + signal\n          + \"; exit = \" + retCode, e);\n      logOutput(e.getOutput());\n      throw new IOException(\"Problem signalling container \" + pid + \" with \"\n          + signal + \"; output: \" + e.getOutput() + \" and exitCode: \"\n          + retCode, e);\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getRunAsUser": "  String getRunAsUser(String user) {\n    if (UserGroupInformation.isSecurityEnabled() ||\n        !containerLimitUsers) {\n      return user;\n    } else {\n      return nonsecureLocalUser;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.verifyUsernamePattern": "  void verifyUsernamePattern(String user) {\n    if (!UserGroupInformation.isSecurityEnabled() &&\n        !nonsecureLocalUserPattern.matcher(user).matches()) {\n      throw new IllegalArgumentException(\"Invalid user name '\" + user + \"',\" +\n          \" it must match '\" + nonsecureLocalUserPattern.pattern() + \"'\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer": "  public void cleanupContainer() throws IOException {\n    ContainerId containerId = container.getContainerId();\n    String containerIdStr = ConverterUtils.toString(containerId);\n    LOG.info(\"Cleaning up container \" + containerIdStr);\n\n    try {\n      context.getNMStateStore().storeContainerKilled(containerId);\n    } catch (IOException e) {\n      LOG.error(\"Unable to mark container \" + containerId\n          + \" killed in store\", e);\n    }\n\n    // launch flag will be set to true if process already launched\n    boolean alreadyLaunched = !shouldLaunchContainer.compareAndSet(false, true);\n    if (!alreadyLaunched) {\n      LOG.info(\"Container \" + containerIdStr + \" not launched.\"\n          + \" No cleanup needed to be done\");\n      return;\n    }\n\n    LOG.debug(\"Marking container \" + containerIdStr + \" as inactive\");\n    // this should ensure that if the container process has not launched \n    // by this time, it will never be launched\n    exec.deactivateContainer(containerId);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Getting pid for container \" + containerIdStr + \" to kill\"\n          + \" from pid file \" \n          + (pidFilePath != null ? pidFilePath.toString() : \"null\"));\n    }\n    \n    // however the container process may have already started\n    try {\n\n      // get process id from pid file if available\n      // else if shell is still active, get it from the shell\n      String processId = null;\n      if (pidFilePath != null) {\n        processId = getContainerPid(pidFilePath);\n      }\n\n      // kill process\n      if (processId != null) {\n        String user = container.getUser();\n        LOG.debug(\"Sending signal to pid \" + processId\n            + \" as user \" + user\n            + \" for container \" + containerIdStr);\n\n        final Signal signal = sleepDelayBeforeSigKill > 0\n          ? Signal.TERM\n          : Signal.KILL;\n\n        boolean result = exec.signalContainer(\n            new ContainerSignalContext.Builder()\n                .setContainer(container)\n                .setUser(user)\n                .setPid(processId)\n                .setSignal(signal)\n                .build());\n\n        LOG.debug(\"Sent signal \" + signal + \" to pid \" + processId\n          + \" as user \" + user\n          + \" for container \" + containerIdStr\n          + \", result=\" + (result? \"success\" : \"failed\"));\n\n        if (sleepDelayBeforeSigKill > 0) {\n          new DelayedProcessKiller(container, user,\n              processId, sleepDelayBeforeSigKill, Signal.KILL, exec).start();\n        }\n      }\n    } catch (Exception e) {\n      String message =\n          \"Exception when trying to cleanup container \" + containerIdStr\n              + \": \" + StringUtils.stringifyException(e);\n      LOG.warn(message);\n      dispatcher.getEventHandler().handle(\n        new ContainerDiagnosticsUpdateEvent(containerId, message));\n    } finally {\n      // cleanup pid file if present\n      if (pidFilePath != null) {\n        FileContext lfs = FileContext.getLocalFSFileContext();\n        lfs.delete(pidFilePath, false);\n        lfs.delete(pidFilePath.suffix(EXIT_CODE_FILE_SUFFIX), false);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.signalContainer": "  public void signalContainer(SignalContainerCommand command)\n      throws IOException {\n    ContainerId containerId =\n        container.getContainerTokenIdentifier().getContainerID();\n    String containerIdStr = ConverterUtils.toString(containerId);\n    String user = container.getUser();\n    Signal signal = translateCommandToSignal(command);\n    if (signal.equals(Signal.NULL)) {\n      LOG.info(\"ignore signal command \" + command);\n      return;\n    }\n\n    LOG.info(\"Sending signal \" + command + \" to container \" + containerIdStr);\n\n    boolean alreadyLaunched = !shouldLaunchContainer.compareAndSet(false, true);\n    if (!alreadyLaunched) {\n      LOG.info(\"Container \" + containerIdStr + \" not launched.\"\n          + \" Not sending the signal\");\n      return;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Getting pid for container \" + containerIdStr\n          + \" to send signal to from pid file \"\n          + (pidFilePath != null ? pidFilePath.toString() : \"null\"));\n    }\n\n    try {\n      // get process id from pid file if available\n      // else if shell is still active, get it from the shell\n      String processId = null;\n      if (pidFilePath != null) {\n        processId = getContainerPid(pidFilePath);\n      }\n\n      if (processId != null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Sending signal to pid \" + processId\n              + \" as user \" + user\n              + \" for container \" + containerIdStr);\n        }\n\n        boolean result = exec.signalContainer(\n            new ContainerSignalContext.Builder()\n                .setContainer(container)\n                .setUser(user)\n                .setPid(processId)\n                .setSignal(signal)\n                .build());\n\n        String diagnostics = \"Sent signal \" + command\n            + \" (\" + signal + \") to pid \" + processId\n            + \" as user \" + user\n            + \" for container \" + containerIdStr\n            + \", result=\" + (result ? \"success\" : \"failed\");\n        LOG.info(diagnostics);\n\n        dispatcher.getEventHandler().handle(\n            new ContainerDiagnosticsUpdateEvent(containerId, diagnostics));\n      }\n    } catch (Exception e) {\n      String message =\n          \"Exception when sending signal to container \" + containerIdStr\n              + \": \" + StringUtils.stringifyException(e);\n      LOG.warn(message);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerPid": "  private String getContainerPid(Path pidFilePath) throws Exception {\n    String containerIdStr = \n        ConverterUtils.toString(container.getContainerId());\n    String processId = null;\n    LOG.debug(\"Accessing pid for container \" + containerIdStr\n        + \" from pid file \" + pidFilePath);\n    int sleepCounter = 0;\n    final int sleepInterval = 100;\n\n    // loop waiting for pid file to show up \n    // until our timer expires in which case we admit defeat\n    while (true) {\n      processId = ProcessIdFileReader.getProcessId(pidFilePath);\n      if (processId != null) {\n        LOG.debug(\"Got pid \" + processId + \" for container \"\n            + containerIdStr);\n        break;\n      }\n      else if ((sleepCounter*sleepInterval) > maxKillWaitTime) {\n        LOG.info(\"Could not get pid for \" + containerIdStr\n        \t\t+ \". Waited for \" + maxKillWaitTime + \" ms.\");\n        break;\n      }\n      else {\n        ++sleepCounter;\n        Thread.sleep(sleepInterval);\n      }\n    }\n    return processId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.toString": "    public String toString() {\n      return sb.toString();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle": "  public void handle(ContainersLauncherEvent event) {\n    // TODO: ContainersLauncher launches containers one by one!!\n    Container container = event.getContainer();\n    ContainerId containerId = container.getContainerId();\n    switch (event.getType()) {\n      case LAUNCH_CONTAINER:\n        Application app =\n          context.getApplications().get(\n              containerId.getApplicationAttemptId().getApplicationId());\n\n        ContainerLaunch launch =\n            new ContainerLaunch(context, getConfig(), dispatcher, exec, app,\n              event.getContainer(), dirsHandler, containerManager);\n        containerLauncher.submit(launch);\n        running.put(containerId, launch);\n        break;\n      case RECOVER_CONTAINER:\n        app = context.getApplications().get(\n            containerId.getApplicationAttemptId().getApplicationId());\n        launch = new RecoveredContainerLaunch(context, getConfig(), dispatcher,\n            exec, app, event.getContainer(), dirsHandler, containerManager);\n        containerLauncher.submit(launch);\n        running.put(containerId, launch);\n        break;\n      case CLEANUP_CONTAINER:\n        ContainerLaunch launcher = running.remove(containerId);\n        if (launcher == null) {\n          // Container not launched. So nothing needs to be done.\n          return;\n        }\n\n        // Cleanup a container whether it is running/killed/completed, so that\n        // no sub-processes are alive.\n        try {\n          launcher.cleanupContainer();\n        } catch (IOException e) {\n          LOG.warn(\"Got exception while cleaning container \" + containerId\n              + \". Ignoring.\");\n        }\n        break;\n      case SIGNAL_CONTAINER:\n        SignalContainersLauncherEvent signalEvent =\n            (SignalContainersLauncherEvent) event;\n        ContainerLaunch runningContainer = running.get(containerId);\n        if (runningContainer == null) {\n          // Container not launched. So nothing needs to be done.\n          LOG.info(\"Container \" + containerId + \" not running, nothing to signal.\");\n          return;\n        }\n\n        try {\n          runningContainer.signalContainer(signalEvent.getCommand());\n        } catch (IOException e) {\n          LOG.warn(\"Got exception while signaling container \" + containerId\n              + \" with command \" + signalEvent.getCommand());\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.runCommand": "  private void runCommand() throws IOException { \n    ProcessBuilder builder = new ProcessBuilder(getExecString());\n    Timer timeOutTimer = null;\n    ShellTimeoutTimerTask timeoutTimerTask = null;\n    timedOut.set(false);\n    completed.set(false);\n\n    if (environment != null) {\n      builder.environment().putAll(this.environment);\n    }\n    if (dir != null) {\n      builder.directory(this.dir);\n    }\n\n    builder.redirectErrorStream(redirectErrorStream);\n    \n    if (Shell.WINDOWS) {\n      synchronized (WindowsProcessLaunchLock) {\n        // To workaround the race condition issue with child processes\n        // inheriting unintended handles during process launch that can\n        // lead to hangs on reading output and error streams, we\n        // serialize process creation. More info available at:\n        // http://support.microsoft.com/kb/315939\n        process = builder.start();\n      }\n    } else {\n      process = builder.start();\n    }\n\n    if (timeOutInterval > 0) {\n      timeOutTimer = new Timer(\"Shell command timeout\");\n      timeoutTimerTask = new ShellTimeoutTimerTask(\n          this);\n      //One time scheduling.\n      timeOutTimer.schedule(timeoutTimerTask, timeOutInterval);\n    }\n    final BufferedReader errReader = \n            new BufferedReader(new InputStreamReader(\n                process.getErrorStream(), Charset.defaultCharset()));\n    BufferedReader inReader =\n            new BufferedReader(new InputStreamReader(\n                process.getInputStream(), Charset.defaultCharset()));\n    final StringBuffer errMsg = new StringBuffer();\n\n    // read error and input streams as this would free up the buffers\n    // free the error stream buffer\n    Thread errThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          String line = errReader.readLine();\n          while((line != null) && !isInterrupted()) {\n            errMsg.append(line);\n            errMsg.append(System.getProperty(\"line.separator\"));\n            line = errReader.readLine();\n          }\n        } catch(IOException ioe) {\n          LOG.warn(\"Error reading the error stream\", ioe);\n        }\n      }\n    };\n    try {\n      errThread.start();\n    } catch (IllegalStateException ise) {\n    } catch (OutOfMemoryError oe) {\n      LOG.error(\"Caught \" + oe + \". One possible reason is that ulimit\"\n          + \" setting of 'max user processes' is too low. If so, do\"\n          + \" 'ulimit -u <largerNum>' and try again.\");\n      throw oe;\n    }\n    try {\n      parseExecResult(inReader); // parse the output\n      // clear the input stream buffer\n      String line = inReader.readLine();\n      while(line != null) { \n        line = inReader.readLine();\n      }\n      // wait for the process to finish and check the exit code\n      exitCode  = process.waitFor();\n      // make sure that the error thread exits\n      joinThread(errThread);\n      completed.set(true);\n      //the timeout thread handling\n      //taken care in finally block\n      if (exitCode != 0) {\n        throw new ExitCodeException(exitCode, errMsg.toString());\n      }\n    } catch (InterruptedException ie) {\n      InterruptedIOException iie = new InterruptedIOException(ie.toString());\n      iie.initCause(ie);\n      throw iie;\n    } finally {\n      if (timeOutTimer != null) {\n        timeOutTimer.cancel();\n      }\n      // close the input stream\n      try {\n        // JDK 7 tries to automatically drain the input streams for us\n        // when the process exits, but since close is not synchronized,\n        // it creates a race if we close the stream first and the same\n        // fd is recycled.  the stream draining thread will attempt to\n        // drain that fd!!  it may block, OOM, or cause bizarre behavior\n        // see: https://bugs.openjdk.java.net/browse/JDK-8024521\n        //      issue is fixed in build 7u60\n        InputStream stdout = process.getInputStream();\n        synchronized (stdout) {\n          inReader.close();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Error while closing the input stream\", ioe);\n      }\n      if (!completed.get()) {\n        errThread.interrupt();\n        joinThread(errThread);\n      }\n      try {\n        InputStream stderr = process.getErrorStream();\n        synchronized (stderr) {\n          errReader.close();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Error while closing the error stream\", ioe);\n      }\n      process.destroy();\n      lastTime = Time.monotonicNow();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.parseExecResult": "    protected void parseExecResult(BufferedReader lines) throws IOException {\n      output = new StringBuffer();\n      char[] buf = new char[512];\n      int nRead;\n      while ( (nRead = lines.read(buf, 0, buf.length)) > 0 ) {\n        output.append(buf, 0, nRead);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.close": "    public void close() {\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.joinThread": "  private static void joinThread(Thread t) {\n    while (t.isAlive()) {\n      try {\n        t.join();\n      } catch (InterruptedException ie) {\n        if (LOG.isWarnEnabled()) {\n          LOG.warn(\"Interrupted while joining on: \" + t, ie);\n        }\n        t.interrupt(); // propagate interrupt\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.toString": "    public String toString() {\n      StringBuilder builder = new StringBuilder();\n      String[] args = getExecString();\n      for (String s : args) {\n        if (s.indexOf(' ') >= 0) {\n          builder.append('\"').append(s).append('\"');\n        } else {\n          builder.append(s);\n        }\n        builder.append(' ');\n      }\n      return builder.toString();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.getExecString": "    public String[] getExecString() {\n      return command;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.run": "    public void run() {\n      Process p = shell.getProcess();\n      try {\n        p.exitValue();\n      } catch (Exception e) {\n        //Process has not terminated.\n        //So check if it has completed \n        //if not just destroy it.\n        if (p != null && !shell.completed.get()) {\n          shell.setTimedOut();\n          p.destroy();\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.setTimedOut": "  private void setTimedOut() {\n    this.timedOut.set(true);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.getProcess": "  public Process getProcess() {\n    return process;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.execute": "    public void execute() throws IOException {\n      for (String s : command) {\n        if (s == null) {\n          throw new IOException(\"(null) entry in command string: \"\n              + StringUtils.join(\" \", command));\n        }\n      }\n      this.run();    \n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.SignalContainersLauncherEvent.getCommand": "  public SignalContainerCommand getCommand() {\n    return command;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Time.monotonicNow": "  public static long monotonicNow() {\n    return System.nanoTime() / NANOSECONDS_PER_MILLISECOND;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.StringUtils.join": "  public static String join(char separator, String[] strings) {\n    return join(separator + \"\", strings);\n  }"
        },
        "bug_report": {
            "Title": "Too many signal to container failure in case of LCE",
            "Description": "Install HA cluster in secure mode\nEnable LCE with cgroups\nStart server with dsperf user\nSubmit mapreduce application terasort/teragen with user yarn/dsperf \nToo many signal to container failure \n\nSubmit with user the exception is thrown\n\n{noformat}\n2014-03-02 09:20:38,689 INFO SecurityLogger.org.apache.hadoop.security.authorize.ServiceAuthorizationManager: Authorization successful for testing (auth:TOKEN) for protocol=interface org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB\n2014-03-02 09:20:40,158 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: KILL_CONTAINER sent to absent container container_e02_1393731146548_0001_01_000013\n2014-03-02 09:20:43,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_e02_1393731146548_0001_01_000009 succeeded\n2014-03-02 09:20:43,072 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_e02_1393731146548_0001_01_000009 transitioned from RUNNING to EXITED_WITH_SUCCESS\n2014-03-02 09:20:43,073 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_e02_1393731146548_0001_01_000009\n2014-03-02 09:20:43,075 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime: Using container runtime: DefaultLinuxContainerRuntime\n2014-03-02 09:20:43,081 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor: Shell execution returned exit code: 9. Privileged Execution Operation Output:\nmain : command provided 2\nmain : run as user is yarn\nmain : requested yarn user is yarn\nFull command array for failed execution:\n[/opt/bibin/dsperf/HAINSTALL/install/hadoop/nodemanager/bin/container-executor, yarn, yarn, 2, 9370, 15]\n2014-03-02 09:20:43,081 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime: Signal container failed. Exception:\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=9:\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:173)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.signalContainer(DefaultLinuxContainerRuntime.java:132)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.signalContainer(DelegatingLinuxContainerRuntime.java:109)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.signalContainer(LinuxContainerExecutor.java:513)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer(ContainerLaunch.java:520)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:139)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:55)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: ExitCodeException exitCode=9:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:927)\n        at org.apache.hadoop.util.Shell.run(Shell.java:838)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1117)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:150)\n        ... 9 more\n2014-03-02 09:20:43,113 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=yarn OPERATION=Container Finished - Succeeded        TARGET=ContainerImpl    RESULT=SUCCESS  APPID=application_1393731146548_0001    CONTAINERID=container_e02_1393731146548_0001_01_000009\n2014-03-02 09:20:43,115 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_e02_1393731146548_0001_01_000009 transitioned from EXITED_WITH_SUCCESS to DONE\n2014-03-02 09:20:43,115 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_e02_1393731146548_0001_01_000009 from application application_1393731146548_0001\n\n{noformat}\n\n\nChecked the same scenario in 2.7.2 version (not available)\n\n"
        }
    },
    {
        "filename": "YARN-1752.json",
        "creation_time": "2014-02-22T05:51:42.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: UNREGISTERED at LAUNCHED\n  at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n  at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n  at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n  at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:647)\n  at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:103)\n  at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n  at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:714)\n  at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n  at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n  at java.lang.Thread.run(Thread.java:695)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getAppAttemptState()) {\n        LOG.info(appAttemptID + \" State change from \" + oldState + \" to \"\n            + getAppAttemptState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      if (initialize) {\n        resetDispatcher();\n        createAndInitActiveServices();\n      }\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          drained = eventQueue.isEmpty();\n          // blockNewEvents is only set when dispatcher is draining to stop,\n          // adding this check is to avoid the overhead of acquiring the lock\n          // and calling notify every time in the normal run of the loop.\n          if (blockNewEvents) {\n            synchronized (waitForDrained) {\n              if (drained) {\n                waitForDrained.notify();\n              }\n            }\n          }\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<String, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  ConfigurationProvider getConfigurationProvider();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Unexpected Unregistered event at Attempt Launched state",
            "Description": "{code}\n2014-02-21 14:56:03,453 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: UNREGISTERED at LAUNCHED\n  at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n  at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n  at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n  at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:647)\n  at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:103)\n  at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n  at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:714)\n  at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n  at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n  at java.lang.Thread.run(Thread.java:695)\n{code}\n\n"
        }
    },
    {
        "filename": "YARN-6629.json",
        "creation_time": "2017-05-22T08:31:16.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:446)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.apply(FiCaSchedulerApp.java:516)\n        at org.apache.hadoop.yarn.client.TestNegativePendingResource$1.answer(TestNegativePendingResource.java:225)\n        at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)\n        at org.mockito.internal.MockHandler.handle(MockHandler.java:97)\n        at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp$$EnhancerByMockitoWithCGLIB$$29eb8afc.apply(<generated>)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.tryCommit(CapacityScheduler.java:2396)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.submitResourceCommitRequest(CapacityScheduler.java:2281)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers(CapacityScheduler.java:1247)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode(CapacityScheduler.java:1236)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1325)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1112)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:987)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1367)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:143)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate": "  public List<ResourceRequest> allocate(NodeType type,\n      SchedulerNode node, SchedulerRequestKey schedulerKey,\n      Container containerAllocated) {\n    try {\n      writeLock.lock();\n\n      if (null != containerAllocated) {\n        updateMetricsForAllocatedContainer(type, containerAllocated);\n      }\n\n      return schedulerKeyToPlacementSets.get(schedulerKey).allocate(\n          schedulerKey, type, node);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.updateMetricsForAllocatedContainer": "  private void updateMetricsForAllocatedContainer(\n    NodeType type, Container containerAllocated) {\n    QueueMetrics metrics = queue.getMetrics();\n    if (pending) {\n      // once an allocation is done we assume the application is\n      // running from scheduler's POV.\n      pending = false;\n      metrics.runAppAttempt(applicationId, user);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationId=\" + applicationId + \" container=\"\n          + containerAllocated.getId() + \" host=\" + containerAllocated\n          .getNodeId().toString() + \" user=\" + user + \" resource=\"\n          + containerAllocated.getResource() + \" type=\"\n          + type);\n    }\n    metrics.allocateResources(user, 1, containerAllocated.getResource(),\n        true);\n    metrics.incrNodeTypeAggregations(user, type);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.apply": "  public void apply(Resource cluster,\n      ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request) {\n    boolean reReservation = false;\n\n    try {\n      writeLock.lock();\n\n      // If we allocated something\n      if (request.anythingAllocatedOrReserved()) {\n        ContainerAllocationProposal<FiCaSchedulerApp, FiCaSchedulerNode>\n            allocation = request.getFirstAllocatedOrReservedContainer();\n        SchedulerContainer<FiCaSchedulerApp, FiCaSchedulerNode>\n            schedulerContainer = allocation.getAllocatedOrReservedContainer();\n        RMContainer rmContainer = schedulerContainer.getRmContainer();\n\n        reReservation =\n            (!schedulerContainer.isAllocated()) && (rmContainer.getState()\n                == RMContainerState.RESERVED);\n\n        // Generate new containerId if it is not an allocation for increasing\n        // Or re-reservation\n        if (rmContainer.getContainer().getId() == null) {\n          rmContainer.setContainerId(BuilderUtils\n              .newContainerId(getApplicationAttemptId(),\n                  getNewContainerId()));\n        }\n        ContainerId containerId = rmContainer.getContainerId();\n\n        if (schedulerContainer.isAllocated()) {\n          // This allocation is from a reserved container\n          // Unreserve it first\n          if (allocation.getAllocateFromReservedContainer() != null) {\n            RMContainer reservedContainer =\n                allocation.getAllocateFromReservedContainer().getRmContainer();\n            // Handling container allocation\n            // Did we previously reserve containers at this 'priority'?\n            unreserve(schedulerContainer.getSchedulerRequestKey(),\n                schedulerContainer.getSchedulerNode(), reservedContainer);\n          }\n\n          // Allocate a new container\n          addToNewlyAllocatedContainers(\n              schedulerContainer.getSchedulerNode(), rmContainer);\n          liveContainers.put(containerId, rmContainer);\n\n          // Deduct pending resource requests\n          List<ResourceRequest> requests = appSchedulingInfo.allocate(\n              allocation.getAllocationLocalityType(),\n              schedulerContainer.getSchedulerNode(),\n              schedulerContainer.getSchedulerRequestKey(),\n              schedulerContainer.getRmContainer().getContainer());\n          ((RMContainerImpl) rmContainer).setResourceRequests(requests);\n\n          attemptResourceUsage.incUsed(schedulerContainer.getNodePartition(),\n              allocation.getAllocatedOrReservedResource());\n\n          rmContainer.handle(\n              new RMContainerEvent(containerId, RMContainerEventType.START));\n\n          // Inform the node\n          schedulerContainer.getSchedulerNode().allocateContainer(\n              rmContainer);\n\n          // update locality statistics,\n          incNumAllocatedContainers(allocation.getAllocationLocalityType(),\n              allocation.getRequestLocalityType());\n\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"allocate: applicationAttemptId=\" + containerId\n                .getApplicationAttemptId() + \" container=\" + containerId\n                + \" host=\" + rmContainer.getAllocatedNode().getHost()\n                + \" type=\" + allocation.getAllocationLocalityType());\n          }\n          RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n              \"SchedulerApp\", getApplicationId(), containerId,\n              allocation.getAllocatedOrReservedResource());\n        } else {\n          // If the rmContainer's state is already updated to RESERVED, this is\n          // a reReservation\n          reserve(schedulerContainer.getSchedulerRequestKey(),\n              schedulerContainer.getSchedulerNode(),\n              schedulerContainer.getRmContainer(),\n              schedulerContainer.getRmContainer().getContainer(),\n              reReservation);\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n\n    // Don't bother CS leaf queue if it is a re-reservation\n    if (!reReservation) {\n      getCSLeafQueue().apply(cluster, request);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate": "  public RMContainer allocate(FiCaSchedulerNode node,\n      SchedulerRequestKey schedulerKey, Container container) {\n    try {\n      readLock.lock();\n\n      if (isStopped) {\n        return null;\n      }\n\n      // Required sanity check - AM can call 'allocate' to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) <= 0) {\n        return null;\n      }\n\n      SchedulingPlacementSet<FiCaSchedulerNode> ps =\n          appSchedulingInfo.getSchedulingPlacementSet(schedulerKey);\n      if (null == ps) {\n        LOG.warn(\"Failed to get \" + SchedulingPlacementSet.class.getName()\n            + \" for application=\" + getApplicationId() + \" schedulerRequestKey=\"\n            + schedulerKey);\n        return null;\n      }\n\n      // Create RMContainer\n      RMContainer rmContainer = new RMContainerImpl(container, schedulerKey,\n          this.getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), this.rmContext,\n          ps.getPrimaryRequestedNodePartition());\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // FIXME, should set when confirmed\n      updateAMContainerDiagnostics(AMState.ASSIGNED, null);\n\n      return rmContainer;\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.reserve": "  public void reserve(SchedulerRequestKey schedulerKey, FiCaSchedulerNode node,\n      RMContainer rmContainer, Container container, boolean reReservation) {\n    // Update reserved metrics if this is the first reservation\n    // rmContainer will be moved to reserved in the super.reserve\n    if (!reReservation) {\n      queue.getMetrics().reserveResource(\n          getUser(), container.getResource());\n    }\n\n    // Inform the application\n    rmContainer = super.reserve(node, schedulerKey, rmContainer, container);\n\n    // Update the node\n    node.reserveResource(this, schedulerKey, rmContainer);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.getCSLeafQueue": "  public LeafQueue getCSLeafQueue() {\n    return (LeafQueue)queue;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.unreserve": "  public boolean unreserve(SchedulerRequestKey schedulerKey,\n      FiCaSchedulerNode node, RMContainer rmContainer) {\n    try {\n      writeLock.lock();\n      // Done with the reservation?\n      if (internalUnreserve(node, schedulerKey)) {\n        node.unreserveResource(this);\n\n        // Update reserved metrics\n        queue.getMetrics().unreserveResource(getUser(),\n            rmContainer.getReservedResource());\n        queue.decReservedResource(node.getPartition(),\n            rmContainer.getReservedResource());\n        return true;\n      }\n      return false;\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.tryCommit": "  public void tryCommit(Resource cluster, ResourceCommitRequest r) {\n    ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request =\n        (ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode>) r;\n\n    ApplicationAttemptId attemptId = null;\n\n    // We need to update unconfirmed allocated resource of application when\n    // any container allocated.\n    boolean updateUnconfirmedAllocatedResource =\n        request.getContainersToAllocate() != null && !request\n            .getContainersToAllocate().isEmpty();\n\n    // find the application to accept and apply the ResourceCommitRequest\n    if (request.anythingAllocatedOrReserved()) {\n      ContainerAllocationProposal<FiCaSchedulerApp, FiCaSchedulerNode> c =\n          request.getFirstAllocatedOrReservedContainer();\n      attemptId =\n          c.getAllocatedOrReservedContainer().getSchedulerApplicationAttempt()\n              .getApplicationAttemptId();\n    } else {\n      if (!request.getContainersToRelease().isEmpty()) {\n        attemptId = request.getContainersToRelease().get(0)\n            .getSchedulerApplicationAttempt().getApplicationAttemptId();\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Try to commit allocation proposal=\" + request);\n    }\n\n    if (attemptId != null) {\n      FiCaSchedulerApp app = getApplicationAttempt(attemptId);\n      if (app != null) {\n        if (app.accept(cluster, request)) {\n          app.apply(cluster, request);\n          LOG.info(\"Allocation proposal accepted\");\n        } else{\n          LOG.info(\"Failed to accept allocation proposal\");\n        }\n\n        // Update unconfirmed allocated resource.\n        if (updateUnconfirmedAllocatedResource) {\n          app.decUnconfirmedRes(request.getTotalAllocatedResource());\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getApplicationAttempt": "  public FiCaSchedulerApp getApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId) {\n    return super.getApplicationAttempt(applicationAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.submitResourceCommitRequest": "  public void submitResourceCommitRequest(Resource cluster,\n      CSAssignment csAssignment) {\n    ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request =\n        createResourceCommitRequest(csAssignment);\n\n    if (null == request) {\n      return;\n    }\n\n    if (scheduleAsynchronously) {\n      // Submit to a commit thread and commit it async-ly\n      resourceCommitterService.addNewCommitRequest(request);\n    } else{\n      // Otherwise do it sync-ly.\n      tryCommit(cluster, request);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addNewCommitRequest": "    public void addNewCommitRequest(\n        ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> proposal) {\n      backlogs.add(proposal);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.createResourceCommitRequest": "  public ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode>\n      createResourceCommitRequest(CSAssignment csAssignment) {\n    ContainerAllocationProposal<FiCaSchedulerApp, FiCaSchedulerNode> allocated =\n        null;\n    ContainerAllocationProposal<FiCaSchedulerApp, FiCaSchedulerNode> reserved =\n        null;\n    List<SchedulerContainer<FiCaSchedulerApp, FiCaSchedulerNode>> released =\n        null;\n\n    if (Resources.greaterThan(calculator, getClusterResource(),\n        csAssignment.getResource(), Resources.none())) {\n      // Allocated something\n      List<AssignmentInformation.AssignmentDetails> allocations =\n          csAssignment.getAssignmentInformation().getAllocationDetails();\n      if (!allocations.isEmpty()) {\n        RMContainer rmContainer = allocations.get(0).rmContainer;\n        allocated = new ContainerAllocationProposal<>(\n            getSchedulerContainer(rmContainer, true),\n            getSchedulerContainersToRelease(csAssignment),\n            getSchedulerContainer(csAssignment.getFulfilledReservedContainer(),\n                false), csAssignment.getType(),\n            csAssignment.getRequestLocalityType(),\n            csAssignment.getSchedulingMode() != null ?\n                csAssignment.getSchedulingMode() :\n                SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY,\n            csAssignment.getResource());\n      }\n\n      // Reserved something\n      List<AssignmentInformation.AssignmentDetails> reservation =\n          csAssignment.getAssignmentInformation().getReservationDetails();\n      if (!reservation.isEmpty()) {\n        RMContainer rmContainer = reservation.get(0).rmContainer;\n        reserved = new ContainerAllocationProposal<>(\n            getSchedulerContainer(rmContainer, false),\n            getSchedulerContainersToRelease(csAssignment),\n            getSchedulerContainer(csAssignment.getFulfilledReservedContainer(),\n                false), csAssignment.getType(),\n            csAssignment.getRequestLocalityType(),\n            csAssignment.getSchedulingMode() != null ?\n                csAssignment.getSchedulingMode() :\n                SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY,\n            csAssignment.getResource());\n      }\n    }\n\n    // When we don't need to allocate/reserve anything, we can feel free to\n    // kill all to-release containers in the request.\n    if (null == allocated && null == reserved) {\n      released = getSchedulerContainersToRelease(csAssignment);\n    }\n\n    if (null != allocated || null != reserved || (null != released && !released\n        .isEmpty())) {\n      List<ContainerAllocationProposal<FiCaSchedulerApp, FiCaSchedulerNode>>\n          allocationsList = null;\n      if (allocated != null) {\n        allocationsList = new ArrayList<>();\n        allocationsList.add(allocated);\n      }\n\n      List<ContainerAllocationProposal<FiCaSchedulerApp, FiCaSchedulerNode>>\n          reservationsList = null;\n      if (reserved != null) {\n        reservationsList = new ArrayList<>();\n        reservationsList.add(reserved);\n      }\n\n      return new ResourceCommitRequest<>(allocationsList, reservationsList,\n          released);\n    }\n\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers": "  private CSAssignment allocateOrReserveNewContainers(\n      PlacementSet<FiCaSchedulerNode> ps, boolean withNodeHeartbeat) {\n    CSAssignment assignment = getRootQueue().assignContainers(\n        getClusterResource(), ps, new ResourceLimits(labelManager\n            .getResourceByLabel(ps.getPartition(), getClusterResource())),\n        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n\n    assignment.setSchedulingMode(SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n    submitResourceCommitRequest(getClusterResource(), assignment);\n\n    if (Resources.greaterThan(calculator, getClusterResource(),\n        assignment.getResource(), Resources.none())) {\n      if (withNodeHeartbeat) {\n        updateSchedulerHealth(lastNodeUpdateTime,\n            PlacementSetUtils.getSingleNode(ps).getNodeID(), assignment);\n      }\n      return assignment;\n    }\n\n    // Only do non-exclusive allocation when node has node-labels.\n    if (StringUtils.equals(ps.getPartition(), RMNodeLabelsManager.NO_LABEL)) {\n      return null;\n    }\n\n    // Only do non-exclusive allocation when the node-label supports that\n    try {\n      if (rmContext.getNodeLabelManager().isExclusiveNodeLabel(\n          ps.getPartition())) {\n        return null;\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception when trying to get exclusivity of node label=\" + ps\n          .getPartition(), e);\n      return null;\n    }\n\n    // Try to use NON_EXCLUSIVE\n    assignment = getRootQueue().assignContainers(getClusterResource(), ps,\n        // TODO, now we only consider limits for parent for non-labeled\n        // resources, should consider labeled resources as well.\n        new ResourceLimits(labelManager\n            .getResourceByLabel(RMNodeLabelsManager.NO_LABEL,\n                getClusterResource())),\n        SchedulingMode.IGNORE_PARTITION_EXCLUSIVITY);\n    assignment.setSchedulingMode(SchedulingMode.IGNORE_PARTITION_EXCLUSIVITY);\n    submitResourceCommitRequest(getClusterResource(), assignment);\n\n    return assignment;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateSchedulerHealth": "  private void updateSchedulerHealth(long now, NodeId nodeId,\n      CSAssignment assignment) {\n    List<AssignmentInformation.AssignmentDetails> allocations =\n        assignment.getAssignmentInformation().getAllocationDetails();\n    List<AssignmentInformation.AssignmentDetails> reservations =\n        assignment.getAssignmentInformation().getReservationDetails();\n    if (!allocations.isEmpty()) {\n      ContainerId allocatedContainerId =\n          allocations.get(allocations.size() - 1).containerId;\n      String allocatedQueue = allocations.get(allocations.size() - 1).queue;\n      schedulerHealth.updateAllocation(now, nodeId, allocatedContainerId,\n        allocatedQueue);\n    }\n    if (!reservations.isEmpty()) {\n      ContainerId reservedContainerId =\n          reservations.get(reservations.size() - 1).containerId;\n      String reservedQueue = reservations.get(reservations.size() - 1).queue;\n      schedulerHealth.updateReservation(now, nodeId, reservedContainerId,\n        reservedQueue);\n    }\n    schedulerHealth.updateSchedulerReservationCounts(assignment\n      .getAssignmentInformation().getNumReservations());\n    schedulerHealth.updateSchedulerAllocationCounts(assignment\n      .getAssignmentInformation().getNumAllocations());\n    schedulerHealth.updateSchedulerRunDetails(now, assignment\n      .getAssignmentInformation().getAllocated(), assignment\n      .getAssignmentInformation().getReserved());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getRootQueue": "  public CSQueue getRootQueue() {\n    return queueManager.getRootQueue();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode": "  private CSAssignment allocateContainerOnSingleNode(PlacementSet<FiCaSchedulerNode> ps,\n      FiCaSchedulerNode node, boolean withNodeHeartbeat) {\n    // Backward compatible way to make sure previous behavior which allocation\n    // driven by node heartbeat works.\n    if (getNode(node.getNodeID()) != node) {\n      LOG.error(\"Trying to schedule on a removed node, please double check.\");\n      return null;\n    }\n\n    CSAssignment assignment;\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      FiCaSchedulerApp reservedApplication = getCurrentAttemptForContainer(\n          reservedContainer.getContainerId());\n\n      // Try to fulfill the reservation\n      LOG.info(\n          \"Trying to fulfill reservation for application \" + reservedApplication\n              .getApplicationId() + \" on node: \" + node.getNodeID());\n\n      LeafQueue queue = ((LeafQueue) reservedApplication.getQueue());\n      assignment = queue.assignContainers(getClusterResource(), ps,\n          // TODO, now we only consider limits for parent for non-labeled\n          // resources, should consider labeled resources as well.\n          new ResourceLimits(labelManager\n              .getResourceByLabel(RMNodeLabelsManager.NO_LABEL,\n                  getClusterResource())),\n          SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n\n      if (assignment.isFulfilledReservation()) {\n        if (withNodeHeartbeat) {\n          // Only update SchedulerHealth in sync scheduling, existing\n          // Data structure of SchedulerHealth need to be updated for\n          // Async mode\n          updateSchedulerHealth(lastNodeUpdateTime, node.getNodeID(),\n              assignment);\n        }\n\n        schedulerHealth.updateSchedulerFulfilledReservationCounts(1);\n\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            queue.getParent().getQueueName(), queue.getQueueName(),\n            ActivityState.ACCEPTED, ActivityDiagnosticConstant.EMPTY);\n        ActivitiesLogger.NODE.finishAllocatedNodeAllocation(activitiesManager,\n            node, reservedContainer.getContainerId(),\n            AllocationState.ALLOCATED_FROM_RESERVED);\n      } else{\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            queue.getParent().getQueueName(), queue.getQueueName(),\n            ActivityState.ACCEPTED, ActivityDiagnosticConstant.EMPTY);\n        ActivitiesLogger.NODE.finishAllocatedNodeAllocation(activitiesManager,\n            node, reservedContainer.getContainerId(), AllocationState.SKIPPED);\n      }\n\n      assignment.setSchedulingMode(\n          SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n      submitResourceCommitRequest(getClusterResource(), assignment);\n    }\n\n    // Do not schedule if there are any reservations to fulfill on the node\n    if (node.getReservedContainer() != null) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Skipping scheduling since node \" + node.getNodeID()\n            + \" is reserved by application \" + node.getReservedContainer()\n            .getContainerId().getApplicationAttemptId());\n      }\n      return null;\n    }\n\n    // First check if we can schedule\n    // When this time look at one node only, try schedule if the node\n    // has any available or killable resource\n    if (calculator.computeAvailableContainers(Resources\n            .add(node.getUnallocatedResource(), node.getTotalKillableResources()),\n        minimumAllocation) <= 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"This node or this node partition doesn't have available or\"\n            + \"killable resource\");\n      }\n      return null;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Trying to schedule on node: \" + node.getNodeName() + \", available: \"\n              + node.getUnallocatedResource());\n    }\n\n    return allocateOrReserveNewContainers(ps, withNodeHeartbeat);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return this.queueManager.getQueue(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getNode": "  public FiCaSchedulerNode getNode(NodeId nodeId) {\n    return nodeTracker.getNode(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode": "  CSAssignment allocateContainersToNode(PlacementSet<FiCaSchedulerNode> ps,\n      boolean withNodeHeartbeat) {\n    if (rmContext.isWorkPreservingRecoveryEnabled() && !rmContext\n        .isSchedulerReadyForAllocatingContainers()) {\n      return null;\n    }\n\n    // Backward compatible way to make sure previous behavior which allocation\n    // driven by node heartbeat works.\n    FiCaSchedulerNode node = PlacementSetUtils.getSingleNode(ps);\n\n    // We have two different logics to handle allocation on single node / multi\n    // nodes.\n    if (null != node) {\n      return allocateContainerOnSingleNode(ps, node, withNodeHeartbeat);\n    } else {\n      return allocateContainersOnMultiNodes(ps);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersOnMultiNodes": "  private CSAssignment allocateContainersOnMultiNodes(\n      PlacementSet<FiCaSchedulerNode> ps) {\n    // When this time look at multiple nodes, try schedule if the\n    // partition has any available resource or killable resource\n    if (getRootQueue().getQueueCapacities().getUsedCapacity(\n        ps.getPartition()) >= 1.0f && preemptionManager.getKillableResource(\n        CapacitySchedulerConfiguration.ROOT, ps.getPartition()) == Resources\n        .none()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"This node or this node partition doesn't have available or\"\n            + \"killable resource\");\n      }\n      return null;\n    }\n\n    return allocateOrReserveNewContainers(ps, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.canAllocateMore": "  private boolean canAllocateMore(CSAssignment assignment, int offswitchCount) {\n    if (null != assignment && Resources.greaterThan(getResourceCalculator(),\n        getClusterResource(), assignment.getResource(), Resources.none())\n        && offswitchCount < offswitchPerHeartbeatLimit) {\n      // And it should not be a reserved container\n      if (assignment.getAssignmentInformation().getNumReservations() == 0) {\n        return true;\n      }\n    }\n\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate": "  protected void nodeUpdate(RMNode rmNode) {\n    try {\n      readLock.lock();\n      setLastNodeUpdateTime(Time.now());\n      super.nodeUpdate(rmNode);\n    } finally {\n      readLock.unlock();\n    }\n\n    // Try to do scheduling\n    if (!scheduleAsynchronously) {\n      try {\n        writeLock.lock();\n        ActivitiesLogger.NODE.startNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n\n        // reset allocation and reservation stats before we start doing any\n        // work\n        updateSchedulerHealth(lastNodeUpdateTime, rmNode.getNodeID(),\n            CSAssignment.NULL_ASSIGNMENT);\n\n        allocateContainersToNode(rmNode.getNodeID(), true);\n        ActivitiesLogger.NODE.finishNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n      } finally {\n        writeLock.unlock();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent =\n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_LABELS_UPDATE:\n    {\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent =\n          (NodeLabelsUpdateSchedulerEvent) event;\n      \n      updateNodeLabelsAndQueueResource(labelUpdateEvent);\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName = resolveReservationQueueName(appAddedEvent.getQueue(),\n          appAddedEvent.getApplicationId(), appAddedEvent.getReservationID(),\n          appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        if (!appAddedEvent.getIsAppRecovering()) {\n          addApplication(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        } else {\n          addApplicationOnRecovery(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        }\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      if (containerExpiredEvent.isIncrease()) {\n        rollbackContainerUpdate(containerId);\n      } else {\n        completedContainer(getRMContainer(containerId),\n            SchedulerUtils.createAbnormalContainerStatus(\n                containerId,\n                SchedulerUtils.EXPIRED_CONTAINER),\n            RMContainerEventType.EXPIRE);\n      }\n    }\n    break;\n    case KILL_RESERVED_CONTAINER:\n    {\n      ContainerPreemptEvent killReservedContainerEvent =\n          (ContainerPreemptEvent) event;\n      RMContainer container = killReservedContainerEvent.getContainer();\n      killReservedContainer(container);\n    }\n    break;\n    case MARK_CONTAINER_FOR_PREEMPTION:\n    {\n      ContainerPreemptEvent preemptContainerEvent =\n          (ContainerPreemptEvent)event;\n      ApplicationAttemptId aid = preemptContainerEvent.getAppId();\n      RMContainer containerToBePreempted = preemptContainerEvent.getContainer();\n      markContainerForPreemption(aid, containerToBePreempted);\n    }\n    break;\n    case MARK_CONTAINER_FOR_KILLABLE:\n    {\n      ContainerPreemptEvent containerKillableEvent = (ContainerPreemptEvent)event;\n      RMContainer killableContainer = containerKillableEvent.getContainer();\n      markContainerForKillable(killableContainer);\n    }\n    break;\n    case MARK_CONTAINER_FOR_NONKILLABLE:\n    {\n      if (isLazyPreemptionEnabled) {\n        ContainerPreemptEvent cancelKillContainerEvent =\n            (ContainerPreemptEvent) event;\n        markContainerForNonKillable(cancelKillContainerEvent.getContainer());\n      }\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addNode": "  private void addNode(RMNode nodeManager) {\n    try {\n      writeLock.lock();\n      FiCaSchedulerNode schedulerNode = new FiCaSchedulerNode(nodeManager,\n          usePortForNodeName, nodeManager.getNodeLabels());\n      nodeTracker.addNode(schedulerNode);\n\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.activateNode(nodeManager.getNodeID(),\n            schedulerNode.getTotalResource());\n      }\n\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n\n      LOG.info(\n          \"Added node \" + nodeManager.getNodeAddress() + \" clusterResource: \"\n              + clusterResource);\n\n      if (scheduleAsynchronously && getNumClusterNodes() == 1) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.beginSchedule();\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplication": "  private void addApplication(ApplicationId applicationId,\n      String queueName, String user, Priority priority) {\n    try {\n      writeLock.lock();\n      if (isSystemAppsLimitReached()) {\n        String message = \"Maximum system application limit reached,\"\n            + \"cannot accept submission of application: \" + applicationId;\n        this.rmContext.getDispatcher().getEventHandler().handle(new RMAppEvent(\n            applicationId, RMAppEventType.APP_REJECTED, message));\n        return;\n      }\n      // Sanity checks.\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to unknown queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      if (!(queue instanceof LeafQueue)) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to non-leaf queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        LOG.info(\"Failed to submit application \" + applicationId + \" to queue \"\n            + queueName + \" from user \" + user, ace);\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                ace.toString()));\n        return;\n      }\n      // update the metrics\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeLabelsAndQueueResource": "  private void updateNodeLabelsAndQueueResource(\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent) {\n    try {\n      writeLock.lock();\n      for (Entry<NodeId, Set<String>> entry : labelUpdateEvent\n          .getUpdatedNodeToLabels().entrySet()) {\n        NodeId id = entry.getKey();\n        Set<String> labels = entry.getValue();\n        updateLabelsOnNode(id, labels);\n      }\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplication": "  private void doneApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationId);\n      if (application == null) {\n        // The AppRemovedSchedulerEvent maybe sent on recovery for completed\n        // apps, ignore it.\n        LOG.warn(\"Couldn't find application \" + applicationId);\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\"Cannot finish application \" + \"from non-leaf queue: \" + queue\n            .getQueueName());\n      } else{\n        queue.finishApplication(applicationId, application.getUser());\n      }\n      application.stop(finalState);\n      applications.remove(applicationId);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.resolveReservationQueueName": "  private String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID,\n      boolean isRecovering) {\n    try {\n      readLock.lock();\n      CSQueue queue = getQueue(queueName);\n      // Check if the queue is a plan queue\n      if ((queue == null) || !(queue instanceof PlanQueue)) {\n        return queueName;\n      }\n      if (reservationID != null) {\n        String resQName = reservationID.toString();\n        queue = getQueue(resQName);\n        if (queue == null) {\n          // reservation has terminated during failover\n          if (isRecovering && conf.getMoveOnExpiry(\n              getQueue(queueName).getQueuePath())) {\n            // move to the default child queue of the plan\n            return getDefaultReservationQueueName(queueName);\n          }\n          String message = \"Application \" + applicationId\n              + \" submitted to a reservation which is not currently active: \"\n              + resQName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        if (!queue.getParent().getQueueName().equals(queueName)) {\n          String message =\n              \"Application: \" + applicationId + \" submitted to a reservation \"\n                  + resQName + \" which does not belong to the specified queue: \"\n                  + queueName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        // use the reservation queue to run the app\n        queueName = resQName;\n      } else{\n        // use the default child queue of the plan for unreserved apps\n        queueName = getDefaultReservationQueueName(queueName);\n      }\n      return queueName;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt": "  private void doneApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    try {\n      writeLock.lock();\n      LOG.info(\"Application Attempt \" + applicationAttemptId + \" is done.\"\n          + \" finalState=\" + rmAppAttemptFinalState);\n\n      FiCaSchedulerApp attempt = getApplicationAttempt(applicationAttemptId);\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n\n      if (application == null || attempt == null) {\n        LOG.info(\n            \"Unknown application \" + applicationAttemptId + \" has completed!\");\n        return;\n      }\n\n      // Release all the allocated, acquired, running containers\n      for (RMContainer rmContainer : attempt.getLiveContainers()) {\n        if (keepContainers && rmContainer.getState().equals(\n            RMContainerState.RUNNING)) {\n          // do not kill the running container in the case of work-preserving AM\n          // restart.\n          LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n          continue;\n        }\n        super.completedContainer(rmContainer, SchedulerUtils\n                .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                    SchedulerUtils.COMPLETED_APPLICATION),\n            RMContainerEventType.KILL);\n      }\n\n      // Release all reserved containers\n      for (RMContainer rmContainer : attempt.getReservedContainers()) {\n        super.completedContainer(rmContainer, SchedulerUtils\n            .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                \"Application Complete\"), RMContainerEventType.KILL);\n      }\n\n      // Clean up pending requests, metrics etc.\n      attempt.stop(rmAppAttemptFinalState);\n\n      // Inform the queue\n      String queueName = attempt.getQueue().getQueueName();\n      CSQueue queue = this.getQueue(queueName);\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\n            \"Cannot finish application \" + \"from non-leaf queue: \" + queueName);\n      } else{\n        queue.finishApplicationAttempt(attempt, queue.getQueueName());\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationOnRecovery": "  private void addApplicationOnRecovery(\n      ApplicationId applicationId, String queueName, String user,\n      Priority priority) {\n    try {\n      writeLock.lock();\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        //During a restart, this indicates a queue was removed, which is\n        //not presently supported\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName + \" which no longer exists after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" missing during application recovery.\"\n              + \" Queue removal during recovery is not presently \"\n              + \"supported by the capacity scheduler, please \"\n              + \"restart with all queues configured\"\n              + \" which were present before shutdown/restart.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      if (!(queue instanceof LeafQueue)) {\n        // During RM restart, this means leaf queue was converted to a parent\n        // queue, which is not supported for running apps.\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName\n                      + \" which is no longer a leaf queue after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" is no longer a leaf queue during application recovery.\"\n              + \" Changing a leaf queue to a parent queue during recovery is\"\n              + \" not presently supported by the capacity scheduler. Please\"\n              + \" restart with leaf queues before shutdown/restart continuing\"\n              + \" as leaf queues.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        // Ignore the exception for recovered app as the app was previously\n        // accepted.\n      }\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForKillable": "  public void markContainerForKillable(\n      RMContainer killableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE + \": container\"\n            + killableContainer.toString());\n      }\n\n      if (!isLazyPreemptionEnabled) {\n        super.completedContainer(killableContainer, SchedulerUtils\n            .createPreemptedContainerStatus(killableContainer.getContainerId(),\n                SchedulerUtils.PREEMPTED_CONTAINER), RMContainerEventType.KILL);\n      } else{\n        FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n            killableContainer.getAllocatedNode());\n\n        FiCaSchedulerApp application = getCurrentAttemptForContainer(\n            killableContainer.getContainerId());\n\n        node.markContainerToKillable(killableContainer.getContainerId());\n\n        // notify PreemptionManager\n        // Get the application for the finished container\n        if (null != application) {\n          String leafQueueName = application.getCSLeafQueue().getQueueName();\n          getPreemptionManager().addKillableContainer(\n              new KillableContainer(killableContainer, node.getPartition(),\n                  leafQueueName));\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForNonKillable": "  private void markContainerForNonKillable(\n      RMContainer nonKillableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            SchedulerEventType.MARK_CONTAINER_FOR_NONKILLABLE + \": container\"\n                + nonKillableContainer.toString());\n      }\n\n      FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n          nonKillableContainer.getAllocatedNode());\n\n      FiCaSchedulerApp application = getCurrentAttemptForContainer(\n          nonKillableContainer.getContainerId());\n\n      node.markContainerToNonKillable(nonKillableContainer.getContainerId());\n\n      // notify PreemptionManager\n      // Get the application for the finished container\n      if (null != application) {\n        String leafQueueName = application.getCSLeafQueue().getQueueName();\n        getPreemptionManager().removeKillableContainer(\n            new KillableContainer(nonKillableContainer, node.getPartition(),\n                leafQueueName));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForPreemption": "  public void markContainerForPreemption(ApplicationAttemptId aid,\n      RMContainer cont) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION\n            + \": appAttempt:\" + aid.toString() + \" container: \"\n            + cont.toString());\n    }\n    FiCaSchedulerApp app = getApplicationAttempt(aid);\n    if (app != null) {\n      app.markContainerForPreemption(cont.getContainerId());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeAndQueueResource": "  private void updateNodeAndQueueResource(RMNode nm,\n      ResourceOption resourceOption) {\n    try {\n      writeLock.lock();\n      updateNodeResource(nm, resourceOption);\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.killReservedContainer": "  public void killReservedContainer(RMContainer container) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.KILL_RESERVED_CONTAINER + \":\"\n          + container.toString());\n    }\n    // To think: What happens if this is no longer a reserved container, for\n    // e.g if the reservation became an allocation.\n    super.completedContainer(container,\n        SchedulerUtils.createAbnormalContainerStatus(\n            container.getContainerId(),\n            SchedulerUtils.UNRESERVED_CONTAINER),\n        RMContainerEventType.KILL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n      if (application == null) {\n        LOG.warn(\"Application \" + applicationAttemptId.getApplicationId()\n            + \" cannot be found in scheduler.\");\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n\n      FiCaSchedulerApp attempt = new FiCaSchedulerApp(applicationAttemptId,\n          application.getUser(), queue, queue.getAbstractUsersManager(),\n          rmContext, application.getPriority(), isAttemptRecovering,\n          activitiesManager);\n      if (transferStateFromPreviousAttempt) {\n        attempt.transferStateFromPreviousAttempt(\n            application.getCurrentAppAttempt());\n      }\n      application.setCurrentAppAttempt(attempt);\n\n      // Update attempt priority to the latest to avoid race condition i.e\n      // SchedulerApplicationAttempt is created with old priority but it is not\n      // set to SchedulerApplication#setCurrentAppAttempt.\n      // Scenario would occur is\n      // 1. SchdulerApplicationAttempt is created with old priority.\n      // 2. updateApplicationPriority() updates SchedulerApplication. Since\n      // currentAttempt is null, it just return.\n      // 3. ScheduelerApplcationAttempt is set in\n      // SchedulerApplication#setCurrentAppAttempt.\n      attempt.setPriority(application.getPriority());\n\n      queue.submitApplicationAttempt(attempt, application.getUser());\n      LOG.info(\"Added Application Attempt \" + applicationAttemptId\n          + \" to scheduler from user \" + application.getUser() + \" in queue \"\n          + queue.getQueueName());\n      if (isAttemptRecovering) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(applicationAttemptId\n              + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n        }\n      } else{\n        rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppAttemptEvent(applicationAttemptId,\n                RMAppAttemptEventType.ATTEMPT_ADDED));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.removeNode": "  private void removeNode(RMNode nodeInfo) {\n    try {\n      writeLock.lock();\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.deactivateNode(nodeInfo.getNodeID());\n      }\n\n      NodeId nodeId = nodeInfo.getNodeID();\n      FiCaSchedulerNode node = nodeTracker.getNode(nodeId);\n      if (node == null) {\n        LOG.error(\"Attempting to remove non-existent node \" + nodeId);\n        return;\n      }\n\n      // Remove running containers\n      List<RMContainer> runningContainers =\n          node.getCopiedListOfRunningContainers();\n      for (RMContainer container : runningContainers) {\n        super.completedContainer(container, SchedulerUtils\n            .createAbnormalContainerStatus(container.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      // Remove reservations, if any\n      RMContainer reservedContainer = node.getReservedContainer();\n      if (reservedContainer != null) {\n        super.completedContainer(reservedContainer, SchedulerUtils\n            .createAbnormalContainerStatus(reservedContainer.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      nodeTracker.removeNode(nodeId);\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n      int numNodes = nodeTracker.nodeCount();\n\n      if (scheduleAsynchronously && numNodes == 0) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.suspendSchedule();\n        }\n      }\n\n      LOG.info(\n          \"Removed node \" + nodeInfo.getNodeAddress() + \" clusterResource: \"\n              + getClusterResource());\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.EventDispatcher.run": "    public void run() {\n\n      T event;\n\n      while (!stopped && !Thread.currentThread().isInterrupted()) {\n        try {\n          event = eventQueue.take();\n        } catch (InterruptedException e) {\n          LOG.error(\"Returning, interrupted : \" + e);\n          return; // TODO: Kill RM.\n        }\n\n        try {\n          handler.handle(event);\n        } catch (Throwable t) {\n          // An error occurred, but we are shutting down anyway.\n          // If it was an InterruptedException, the very act of\n          // shutdown could have caused it and is probably harmless.\n          if (stopped) {\n            LOG.warn(\"Exception during shutdown: \", t);\n            break;\n          }\n          LOG.fatal(\"Error in handling event type \" + event.getType()\n              + \" to the Event Dispatcher\", t);\n          if (shouldExitOnError\n              && !ShutdownHookManager.get().isShutdownInProgress()) {\n            LOG.info(\"Exiting, bbye..\");\n            System.exit(-1);\n          }\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.EventDispatcher.handle": "  public void handle(T event) {\n    try {\n      int qSize = eventQueue.size();\n      if (qSize !=0 && qSize %1000 == 0) {\n        LOG.info(\"Size of \" + getName() + \" event-queue is \" + qSize);\n      }\n      int remCapacity = eventQueue.remainingCapacity();\n      if (remCapacity < 1000) {\n        LOG.info(\"Very low remaining capacity on \" + getName() + \"\" +\n            \"event queue: \" + remCapacity);\n      }\n      this.eventQueue.put(event);\n    } catch (InterruptedException e) {\n      LOG.info(\"Interrupted. Trying to exit gracefully.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.setSchedulingMode": "  public void setSchedulingMode(SchedulingMode schedulingMode) {\n    this.schedulingMode = schedulingMode;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getResource": "  public Resource getResource() {\n    return resource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getParent": "  public CSQueue getParent();\n\n  /**\n   * Set the parent <code>Queue</code>.\n   * @param newParentQueue new parent queue\n   */\n  public void setParent(CSQueue newParentQueue);\n\n  /**\n   * Get the queue name.\n   * @return the queue name\n   */\n  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n\n  public PrivilegedEntity getPrivilegedEntity();\n\n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param ps {@link PlacementSet} of nodes which resources are available",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.assignContainers": "  CSAssignment assignContainers(Resource clusterResource,\n      FiCaSchedulerNode node, ResourceLimits resourceLimits,\n      SchedulingMode schedulingMode);\n\n  boolean accept(Resource cluster,\n      ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request);\n\n  void apply(Resource cluster,\n      ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request);\n\n  /**\n   * Get readLock associated with the Queue.\n   * @return readLock of corresponding queue.\n   */\n  public ReentrantReadWriteLock.ReadLock getReadLock();\n\n  /**\n   * Validate submitApplication api so that moveApplication do a pre-check.\n   * @param applicationId Application ID\n   * @param userName User Name\n   * @param queue Queue Name\n   * @throws AccessControlException if any acl violation is there.\n   */\n  public void validateSubmitApplication(ApplicationId applicationId,\n      String userName, String queue) throws AccessControlException;\n\n  /**\n   * Get priority of queue\n   * @return queue priority\n   */\n  Priority getPriority();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.isFulfilledReservation": "  public boolean isFulfilledReservation() {\n    return this.fulfilledReservation;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n\n  public PrivilegedEntity getPrivilegedEntity();\n\n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param ps {@link PlacementSet} of nodes which resources are available",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getType": "  public NodeType getType() {\n    return type;\n  }"
        },
        "bug_report": {
            "Title": "NPE occurred when container allocation proposal is applied but its resource requests are removed before",
            "Description": "I wrote a test case to reproduce another problem for branch-2 and found new NPE error,  log: \n{code}\nFATAL event.EventDispatcher (EventDispatcher.java:run(75)) - Error in handling event type NODE_UPDATE to the Event Dispatcher\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:446)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.apply(FiCaSchedulerApp.java:516)\n        at org.apache.hadoop.yarn.client.TestNegativePendingResource$1.answer(TestNegativePendingResource.java:225)\n        at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)\n        at org.mockito.internal.MockHandler.handle(MockHandler.java:97)\n        at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp$$EnhancerByMockitoWithCGLIB$$29eb8afc.apply(<generated>)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.tryCommit(CapacityScheduler.java:2396)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.submitResourceCommitRequest(CapacityScheduler.java:2281)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers(CapacityScheduler.java:1247)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode(CapacityScheduler.java:1236)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1325)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1112)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:987)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1367)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:143)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:745)\n{code}\n\nReproduce this error in chronological order:\n1. AM started and requested 1 container with schedulerRequestKey#1 : \nApplicationMasterService#allocate -->  CapacityScheduler#allocate --> SchedulerApplicationAttempt#updateResourceRequests --> AppSchedulingInfo#updateResourceRequests \nAdded schedulerRequestKey#1 into schedulerKeyToPlacementSets\n2. Scheduler allocatd 1 container for this request and accepted the proposal\n3. AM removed this request\nApplicationMasterService#allocate -->  CapacityScheduler#allocate --> SchedulerApplicationAttempt#updateResourceRequests --> AppSchedulingInfo#updateResourceRequests --> AppSchedulingInfo#addToPlacementSets --> AppSchedulingInfo#updatePendingResources\nRemoved schedulerRequestKey#1 from schedulerKeyToPlacementSets)\n4. Scheduler applied this proposal\nCapacityScheduler#tryCommit --> FiCaSchedulerApp#apply --> AppSchedulingInfo#allocate \nThrow NPE when called schedulerKeyToPlacementSets.get(schedulerRequestKey).allocate(schedulerKey, type, node);"
        }
    },
    {
        "filename": "YARN-3493.json",
        "creation_time": "2015-04-15T22:03:19.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:204)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:385)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:317)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:422)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1187)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:574)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:204)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:385)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:317)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:422)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1187)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:574)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop(AsyncDispatcher.java:142)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStop(ResourceManager.java:601)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:203)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest": "  public static void validateResourceRequest(ResourceRequest resReq,\n      Resource maximumResource, String queueName, YarnScheduler scheduler)\n      throws InvalidResourceRequestException {\n    if (resReq.getCapability().getMemory() < 0 ||\n        resReq.getCapability().getMemory() > maximumResource.getMemory()) {\n      throw new InvalidResourceRequestException(\"Invalid resource request\"\n          + \", requested memory < 0\"\n          + \", or requested memory > max configured\"\n          + \", requestedMemory=\" + resReq.getCapability().getMemory()\n          + \", maxMemory=\" + maximumResource.getMemory());\n    }\n    if (resReq.getCapability().getVirtualCores() < 0 ||\n        resReq.getCapability().getVirtualCores() >\n        maximumResource.getVirtualCores()) {\n      throw new InvalidResourceRequestException(\"Invalid resource request\"\n          + \", requested virtual cores < 0\"\n          + \", or requested virtual cores > max configured\"\n          + \", requestedVirtualCores=\"\n          + resReq.getCapability().getVirtualCores()\n          + \", maxVirtualCores=\" + maximumResource.getVirtualCores());\n    }\n    \n    // Get queue from scheduler\n    QueueInfo queueInfo = null;\n    try {\n      queueInfo = scheduler.getQueueInfo(queueName, false, false);\n    } catch (IOException e) {\n      // it is possible queue cannot get when queue mapping is set, just ignore\n      // the queueInfo here, and move forward\n    }\n\n    // check labels in the resource request.\n    String labelExp = resReq.getNodeLabelExpression();\n    \n    // if queue has default label expression, and RR doesn't have, use the\n    // default label expression of queue\n    if (labelExp == null && queueInfo != null\n        && ResourceRequest.ANY.equals(resReq.getResourceName())) {\n      labelExp = queueInfo.getDefaultNodeLabelExpression();\n    }\n    \n    // If labelExp still equals to null, set it to be NO_LABEL\n    resReq\n        .setNodeLabelExpression(labelExp == null ? RMNodeLabelsManager.NO_LABEL\n            : labelExp);\n    \n    // we don't allow specify label expression other than resourceName=ANY now\n    if (!ResourceRequest.ANY.equals(resReq.getResourceName())\n        && labelExp != null && !labelExp.trim().isEmpty()) {\n      throw new InvalidResourceRequestException(\n          \"Invailid resource request, queue=\" + queueInfo.getQueueName()\n              + \" specified node label expression in a \"\n              + \"resource request has resource name = \"\n              + resReq.getResourceName());\n    }\n    \n    // we don't allow specify label expression with more than one node labels now\n    if (labelExp != null && labelExp.contains(\"&&\")) {\n      throw new InvalidResourceRequestException(\n          \"Invailid resource request, queue=\" + queueInfo.getQueueName()\n              + \" specified more than one node label \"\n              + \"in a node label expression, node label expression = \"\n              + labelExp);\n    }\n    \n    if (labelExp != null && !labelExp.trim().isEmpty() && queueInfo != null) {\n      if (!checkQueueLabelExpression(queueInfo.getAccessibleNodeLabels(),\n          labelExp)) {\n        throw new InvalidResourceRequestException(\"Invalid resource request\"\n            + \", queue=\"\n            + queueInfo.getQueueName()\n            + \" doesn't have permission to access all labels \"\n            + \"in resource request. labelExpression of resource request=\"\n            + labelExp\n            + \". Queue labels=\"\n            + (queueInfo.getAccessibleNodeLabels() == null ? \"\" : StringUtils.join(queueInfo\n                .getAccessibleNodeLabels().iterator(), ',')));\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.checkQueueLabelExpression": "  public static boolean checkQueueLabelExpression(Set<String> queueLabels,\n      String labelExpression) {\n    if (queueLabels != null && queueLabels.contains(RMNodeLabelsManager.ANY)) {\n      return true;\n    }\n    // if label expression is empty, we can allocate container on any node\n    if (labelExpression == null) {\n      return true;\n    }\n    for (String str : labelExpression.split(\"&&\")) {\n      if (!str.trim().isEmpty()\n          && (queueLabels == null || !queueLabels.contains(str.trim()))) {\n        return false;\n      }\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest": "  private ResourceRequest validateAndCreateResourceRequest(\n      ApplicationSubmissionContext submissionContext)\n      throws InvalidResourceRequestException {\n    // Validation of the ApplicationSubmissionContext needs to be completed\n    // here. Only those fields that are dependent on RM's configuration are\n    // checked here as they have to be validated whether they are part of new\n    // submission or just being recovered.\n\n    // Check whether AM resource requirements are within required limits\n    if (!submissionContext.getUnmanagedAM()) {\n      ResourceRequest amReq;\n      if (submissionContext.getAMContainerResourceRequest() != null) {\n        amReq = submissionContext.getAMContainerResourceRequest();\n      } else {\n        amReq =\n            BuilderUtils.newResourceRequest(\n                RMAppAttemptImpl.AM_CONTAINER_PRIORITY, ResourceRequest.ANY,\n                submissionContext.getResource(), 1);\n      }\n      \n      // set label expression for AM container\n      if (null == amReq.getNodeLabelExpression()) {\n        amReq.setNodeLabelExpression(submissionContext\n            .getNodeLabelExpression());\n      }\n\n      try {\n        SchedulerUtils.validateResourceRequest(amReq,\n            scheduler.getMaximumResourceCapability(),\n            submissionContext.getQueue(), scheduler);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"RM app submission failed in validating AM resource request\"\n            + \" for application \" + submissionContext.getApplicationId(), e);\n        throw e;\n      }\n      SchedulerUtils.normalizeRequest(amReq, scheduler.getResourceCalculator(),\n          scheduler.getClusterResource(),\n          scheduler.getMinimumResourceCapability(),\n          scheduler.getMaximumResourceCapability(),\n          scheduler.getMinimumResourceCapability());\n      return amReq;\n    }\n    \n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp": "  private RMAppImpl createAndPopulateNewRMApp(\n      ApplicationSubmissionContext submissionContext,\n      long submitTime, String user)\n      throws YarnException {\n    ApplicationId applicationId = submissionContext.getApplicationId();\n    ResourceRequest amReq = validateAndCreateResourceRequest(submissionContext);\n    // Create RMApp\n    RMAppImpl application =\n        new RMAppImpl(applicationId, rmContext, this.conf,\n            submissionContext.getApplicationName(), user,\n            submissionContext.getQueue(),\n            submissionContext, this.scheduler, this.masterService,\n            submitTime, submissionContext.getApplicationType(),\n            submissionContext.getApplicationTags(), amReq);\n\n    // Concurrent app submissions with same applicationId will fail here\n    // Concurrent app submissions with different applicationIds will not\n    // influence each other\n    if (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw RPCUtil.getRemoteException(message);\n    }\n    // Inform the ACLs Manager\n    this.applicationACLsManager.addApplication(applicationId,\n        submissionContext.getAMContainerSpec().getApplicationACLs());\n    String appViewACLs = submissionContext.getAMContainerSpec()\n        .getApplicationACLs().get(ApplicationAccessType.VIEW_APP);\n    rmContext.getSystemMetricsPublisher().appACLsUpdated(\n        application, appViewACLs, System.currentTimeMillis());\n    return application;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication": "  protected void recoverApplication(ApplicationStateData appState,\n      RMState rmState) throws Exception {\n    ApplicationSubmissionContext appContext =\n        appState.getApplicationSubmissionContext();\n    ApplicationId appId = appContext.getApplicationId();\n\n    // create and recover app.\n    RMAppImpl application =\n        createAndPopulateNewRMApp(appContext, appState.getSubmitTime(),\n          appState.getUser());\n    application.handle(new RMAppRecoverEvent(appId, rmState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch(event.getType()) {\n      case APP_COMPLETED: \n      {\n        finishApplication(applicationId);\n        logApplicationSummary(applicationId);\n        checkAppNumCompletedLimit(); \n      } \n      break;\n      default:\n        LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n      }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover": "  public void recover(RMState state) throws Exception {\n    RMStateStore store = rmContext.getStateStore();\n    assert store != null;\n    // recover applications\n    Map<ApplicationId, ApplicationStateData> appStates =\n        state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationStateData appState : appStates.values()) {\n      recoverApplication(appState, state);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setSchedulerRecoveryStartAndWaitTime": "  private void setSchedulerRecoveryStartAndWaitTime(RMState state,\n      Configuration conf) {\n    if (!state.getApplicationState().isEmpty()) {\n      long waitTime =\n          conf.getLong(YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS,\n            YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS);\n      rmContext.setSchedulerRecoveryStartAndWaitTime(waitTime);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(true);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n\n    // Use the customized yarn filter instead of the standard kerberos filter to\n    // allow users to authenticate using delegation tokens\n    // 4 conditions need to be satisfied -\n    // 1. security is enabled\n    // 2. http auth type is set to kerberos\n    // 3. \"yarn.resourcemanager.webapp.use-yarn-filter\" override is set to true\n    // 4. hadoop.http.filter.initializers container AuthenticationFilterInitializer\n\n    Configuration conf = getConfig();\n    boolean useYarnAuthenticationFilter =\n        conf.getBoolean(\n          YarnConfiguration.RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER);\n    String authPrefix = \"hadoop.http.authentication.\";\n    String authTypeKey = authPrefix + \"type\";\n    String filterInitializerConfKey = \"hadoop.http.filter.initializers\";\n    String actualInitializers = \"\";\n    Class<?>[] initializersClasses =\n        conf.getClasses(filterInitializerConfKey);\n\n    boolean hasHadoopAuthFilterInitializer = false;\n    boolean hasRMAuthFilterInitializer = false;\n    if (initializersClasses != null) {\n      for (Class<?> initializer : initializersClasses) {\n        if (initializer.getName().equals(\n          AuthenticationFilterInitializer.class.getName())) {\n          hasHadoopAuthFilterInitializer = true;\n        }\n        if (initializer.getName().equals(\n          RMAuthenticationFilterInitializer.class.getName())) {\n          hasRMAuthFilterInitializer = true;\n        }\n      }\n      if (UserGroupInformation.isSecurityEnabled()\n          && useYarnAuthenticationFilter\n          && hasHadoopAuthFilterInitializer\n          && conf.get(authTypeKey, \"\").equals(\n            KerberosAuthenticationHandler.TYPE)) {\n        ArrayList<String> target = new ArrayList<String>();\n        for (Class<?> filterInitializer : initializersClasses) {\n          if (filterInitializer.getName().equals(\n            AuthenticationFilterInitializer.class.getName())) {\n            if (hasRMAuthFilterInitializer == false) {\n              target.add(RMAuthenticationFilterInitializer.class.getName());\n            }\n            continue;\n          }\n          target.add(filterInitializer.getName());\n        }\n        actualInitializers = StringUtils.join(\",\", target);\n\n        LOG.info(\"Using RM authentication filter(kerberos/delegation-token)\"\n            + \" for RM webapp authentication\");\n        RMAuthenticationFilter\n          .setDelegationTokenSecretManager(getClientRMService().rmDTSecretManager);\n        conf.set(filterInitializerConfKey, actualInitializers);\n      }\n    }\n\n    // if security is not enabled and the default filter initializer has not \n    // been set, set the initializer to include the\n    // RMAuthenticationFilterInitializer which in turn will set up the simple\n    // auth filter.\n\n    String initializers = conf.get(filterInitializerConfKey);\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      if (initializersClasses == null || initializersClasses.length == 0) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName());\n        conf.set(authTypeKey, \"simple\");\n      } else if (initializers.equals(StaticUserWebFilter.class.getName())) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName() + \",\"\n              + initializers);\n        conf.set(authTypeKey, \"simple\");\n      }\n    }\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .at(webAppAddress);\n    String proxyHostAndPort = WebAppUtils.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n\n    }\n    webApp = builder.start(new RMWebApp(this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) throws Exception {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main": "  public static void main(String argv[]) {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ResourceManager.class, argv, LOG);\n    try {\n      Configuration conf = new YarnConfiguration();\n      GenericOptionsParser hParser = new GenericOptionsParser(conf, argv);\n      argv = hParser.getRemainingArgs();\n      // If -format-state-store, then delete RMStateStore; else startup normally\n      if (argv.length == 1 && argv[0].equals(\"-format-state-store\")) {\n        deleteRMStateStore(conf);\n      } else {\n        ResourceManager resourceManager = new ResourceManager();\n        ShutdownHookManager.get().addShutdownHook(\n          new CompositeServiceShutdownHook(resourceManager),\n          SHUTDOWN_HOOK_PRIORITY);\n        resourceManager.init(conf);\n        resourceManager.start();\n      }\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ResourceManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.deleteRMStateStore": "  private static void deleteRMStateStore(Configuration conf) throws Exception {\n    RMStateStore rmStore = RMStateStoreFactory.getStore(conf);\n    rmStore.init(conf);\n    rmStore.start();\n    try {\n      LOG.info(\"Deleting ResourceManager state store...\");\n      rmStore.deleteStore();\n      LOG.info(\"State store deleted\");\n    } finally {\n      rmStore.stop();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop": "  protected void serviceStop() throws Exception {\n    if (drainEventsOnStop) {\n      blockNewEvents = true;\n      LOG.info(\"AsyncDispatcher is draining to stop, igonring any new events.\");\n      synchronized (waitForDrained) {\n        while (!drained && eventHandlingThread.isAlive()) {\n          waitForDrained.wait(1000);\n          LOG.info(\"Waiting for AsyncDispatcher to drain.\");\n        }\n      }\n    }\n    stopped = true;\n    if (eventHandlingThread != null) {\n      eventHandlingThread.interrupt();\n      try {\n        eventHandlingThread.join();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted Exception while stopping\", ie);\n      }\n    }\n\n    // stop all the components\n    super.serviceStop();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.stop": "  public void stop() {\n    if (isInState(STATE.STOPPED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.STOPPED) != STATE.STOPPED) {\n        try {\n          serviceStop();\n        } catch (Exception e) {\n          //stop-time exceptions are logged if they are the first one,\n          noteFailure(e);\n          throw ServiceStateException.convert(e);\n        } finally {\n          //report that the service has terminated\n          terminationNotification.set(true);\n          synchronized (terminationNotification) {\n            terminationNotification.notifyAll();\n          }\n          //notify anything listening for events\n          notifyListeners();\n        }\n      } else {\n        //already stopped: note it\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring re-entrant call to stop()\");\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStop": "  protected void serviceStop() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.stop": "  private void stop(int numOfServicesStarted, boolean stopOnlyStartedServices) {\n    // stop in reverse order of start\n    Exception firstException = null;\n    List<Service> services = getServices();\n    for (int i = numOfServicesStarted - 1; i >= 0; i--) {\n      Service service = services.get(i);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Stopping service #\" + i + \": \" + service);\n      }\n      STATE state = service.getServiceState();\n      //depending on the stop police\n      if (state == STATE.STARTED \n         || (!stopOnlyStartedServices && state == STATE.INITED)) {\n        Exception ex = ServiceOperations.stopQuietly(LOG, service);\n        if (ex != null && firstException == null) {\n          firstException = ex;\n        }\n      }\n    }\n    //after stopping all services, rethrow the first exception raised\n    if (firstException != null) {\n      throw ServiceStateException.convert(firstException);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceStop": "  protected void serviceStop() throws Exception {\n    //stop all services that were started\n    int numOfServicesToStop = serviceList.size();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": stopping services, size=\" + numOfServicesToStop);\n    }\n    stop(numOfServicesToStop, STOP_ONLY_STARTED_SERVICES);\n    super.serviceStop();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStop": "  protected void serviceStop() throws Exception {\n    if (webApp != null) {\n      webApp.stop();\n    }\n    if (fetcher != null) {\n      fetcher.stop();\n    }\n    if (configurationProvider != null) {\n      configurationProvider.close();\n    }\n    super.serviceStop();\n    transitionToStandby(false);\n    rmContext.setHAServiceState(HAServiceState.STOPPING);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMApps": "  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getSystemMetricsPublisher": "  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getAMRMTokenSecretManager": "  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMDelegationTokenSecretManager": "  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.service.getName": "  String getName();\n\n  /**\n   * Get the configuration of this service.\n   * This is normally not a clone and may be manipulated, though there are no\n   * guarantees as to what the consequences of such actions may be\n   * @return the current configuration, unless a specific implentation chooses\n   * otherwise.\n   */\n  Configuration getConfig();\n\n  /**\n   * Get the current service state\n   * @return the state of the service\n   */\n  STATE getServiceState();\n\n  /**\n   * Get the service start time\n   * @return the start time of the service. This will be zero if the service\n   * has not yet been started.\n   */\n  long getStartTime();\n\n  /**\n   * Query to see if the service is in a specific state.\n   * In a multi-threaded system, the state may not hold for very long.\n   * @param state the expected state\n   * @return true if, at the time of invocation, the service was in that state.\n   */\n  boolean isInState(STATE state);\n\n  /**\n   * Get the first exception raised during the service failure. If null,\n   * no exception was logged\n   * @return the failure logged during a transition to the stopped state\n   */\n  Throwable getFailureCause();\n\n  /**\n   * Get the state in which the failure in {@link #getFailureCause()} occurred.",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.getServiceState": "  STATE getServiceState();\n\n  /**\n   * Get the service start time\n   * @return the start time of the service. This will be zero if the service\n   * has not yet been started.\n   */\n  long getStartTime();\n\n  /**\n   * Query to see if the service is in a specific state.\n   * In a multi-threaded system, the state may not hold for very long.\n   * @param state the expected state\n   * @return true if, at the time of invocation, the service was in that state.\n   */\n  boolean isInState(STATE state);\n\n  /**\n   * Get the first exception raised during the service failure. If null,\n   * no exception was logged\n   * @return the failure logged during a transition to the stopped state\n   */\n  Throwable getFailureCause();\n\n  /**\n   * Get the state in which the failure in {@link #getFailureCause()} occurred."
        },
        "bug_report": {
            "Title": "RM fails to come up with error \"Failed to load/recover state\" when  mem settings are changed",
            "Description": "RM fails to come up for the following case:\n1. Change yarn.nodemanager.resource.memory-mb and yarn.scheduler.maximum-allocation-mb to 4000 in yarn-site.xml\n2. Start a randomtextwriter job with mapreduce.map.memory.mb=4000 in background and wait for the job to reach running state\n3. Restore yarn-site.xml to have yarn.scheduler.maximum-allocation-mb to 2048 before the above job completes\n4. Restart RM\n5. RM fails to come up with the below error\n{code:title= RM error for Mem settings changed}\n - RM app submission failed in validating AM resource request for application application_1429094976272_0008\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:204)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:385)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:317)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:422)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1187)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:574)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n2015-04-15 13:19:18,623 ERROR resourcemanager.ResourceManager (ResourceManager.java:serviceStart(579)) - Failed to load/recover state\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:204)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:385)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:317)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:422)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1187)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:574)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\nat java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n2015-04-15 13:19:18,624 INFO  service.AbstractService (AbstractService.java:noteFailure(272)) - Service RMActiveServices failed in state STARTED; cause: org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:204)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:385)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:317)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:422)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1187)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:574)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n2015-04-15 13:19:18,625 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(211)) - Stopping ResourceManager metrics system...\n2015-04-15 13:19:18,626 INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - timeline thread interrupted.\n2015-04-15 13:19:18,626 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(217)) - ResourceManager metrics system stopped.\n2015-04-15 13:19:18,627 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(606)) - ResourceManager metrics system shutdown complete.\n2015-04-15 13:19:18,627 INFO  event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(140)) - AsyncDispatcher is draining to stop, igonring any new events.\n2015-04-15 13:19:18,633 INFO  zookeeper.ZooKeeper (ZooKeeper.java:close(684)) - Session: 0x44cbc922670001c closed\n2015-04-15 13:19:18,633 INFO  zookeeper.ClientCnxn (ClientCnxn.java:run(512)) - EventThread shut down\n2015-04-15 13:19:18,634 INFO  event.AsyncDispatcher (AsyncDispatcher.java:serviceStop(140)) - AsyncDispatcher is draining to stop, igonring any new events.\n2015-04-15 13:19:18,634 INFO  service.AbstractService (AbstractService.java:noteFailure(272)) - Service Dispatcher failed in state STOPPED; cause: java.lang.NullPointerException\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop(AsyncDispatcher.java:142)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\nat org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStop(ResourceManager.java:601)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:203)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n{code}\n\n"
        }
    },
    {
        "filename": "YARN-7645.json",
        "creation_time": "2017-12-12T21:19:53.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: Attempt state is not correct (timeout). expected:<ALLOCATED> but was:<SCHEDULED>\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage.amRestartTests(TestContainerResourceUsage.java:275)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage.testUsageAfterAMRestartWithMultipleContainers(TestContainerResourceUsage.java:254)\n```",
        "source_code": {},
        "bug_report": {
            "Title": "TestContainerResourceUsage#testUsageAfterAMRestartWithMultipleContainers is flakey with FairScheduler",
            "Description": "We've noticed some flakiness in {{TestContainerResourceUsage#testUsageAfterAMRestartWithMultipleContainers}} when using {{FairScheduler}}:\r\n{noformat}\r\njava.lang.AssertionError: Attempt state is not correct (timeout). expected:<ALLOCATED> but was:<SCHEDULED>\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage.amRestartTests(TestContainerResourceUsage.java:275)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage.testUsageAfterAMRestartWithMultipleContainers(TestContainerResourceUsage.java:254)\r\n{noformat}"
        }
    },
    {
        "filename": "YARN-6054.json",
        "creation_time": "2017-01-04T20:58:59.000+0000",
        "stack_trace": "```\norg.apache.hadoop.service.ServiceStateException: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelineserver/leveldb-timeline-store.ldb/127897.sst\n        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:172)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.serviceInit(ApplicationHistoryServer.java:104)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.launchAppHistoryServer(ApplicationHistoryServer.java:172)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.main(ApplicationHistoryServer.java:182)\nCaused by: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelineserver/leveldb-timeline-store.ldb/127897.sst\n        at org.fusesource.leveldbjni.internal.NativeDB.checkStatus(NativeDB.java:200)\n        at org.fusesource.leveldbjni.internal.NativeDB.open(NativeDB.java:218)\n        at org.fusesource.leveldbjni.JniDBFactory.open(JniDBFactory.java:168)\n        at org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore.serviceInit(LeveldbTimelineStore.java:229)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": initing services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      service.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return new ArrayList<Service>(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n\n    // do security login first.\n    try {\n      doSecureLogin(conf);\n    } catch(IOException ie) {\n      throw new YarnRuntimeException(\"Failed to login\", ie);\n    }\n    // init timeline services\n    timelineStore = createTimelineStore(conf);\n    addIfService(timelineStore);\n    secretManagerService = createTimelineDelegationTokenSecretManagerService(conf);\n    addService(secretManagerService);\n    timelineDataManager = createTimelineDataManager(conf);\n    addService(timelineDataManager);\n\n    // init generic history service afterwards\n    aclsManager = createApplicationACLsManager(conf);\n    historyManager = createApplicationHistoryManager(conf);\n    ahsClientService = createApplicationHistoryClientService(historyManager);\n    addService(ahsClientService);\n    addService((Service) historyManager);\n\n    DefaultMetricsSystem.initialize(\"ApplicationHistoryServer\");\n    JvmMetrics jm = JvmMetrics.initSingleton(\"ApplicationHistoryServer\", null);\n    pauseMonitor = new JvmPauseMonitor();\n    addService(pauseMonitor);\n    jm.setPauseMonitor(pauseMonitor);\n    super.serviceInit(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.doSecureLogin": "  private void doSecureLogin(Configuration conf) throws IOException {\n    InetSocketAddress socAddr = getBindAddress(conf);\n    SecurityUtil.login(conf, YarnConfiguration.TIMELINE_SERVICE_KEYTAB,\n        YarnConfiguration.TIMELINE_SERVICE_PRINCIPAL, socAddr.getHostName());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.createApplicationHistoryClientService": "  private ApplicationHistoryClientService\n      createApplicationHistoryClientService(\n          ApplicationHistoryManager historyManager) {\n    return new ApplicationHistoryClientService(historyManager);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.createApplicationHistoryManager": "  private ApplicationHistoryManager createApplicationHistoryManager(\n      Configuration conf) {\n    // Backward compatibility:\n    // APPLICATION_HISTORY_STORE is neither null nor empty, it means that the\n    // user has enabled it explicitly.\n    if (conf.get(YarnConfiguration.APPLICATION_HISTORY_STORE) == null ||\n        conf.get(YarnConfiguration.APPLICATION_HISTORY_STORE).length() == 0 ||\n        conf.get(YarnConfiguration.APPLICATION_HISTORY_STORE).equals(\n            NullApplicationHistoryStore.class.getName())) {\n      return new ApplicationHistoryManagerOnTimelineStore(\n          timelineDataManager, aclsManager);\n    } else {\n      LOG.warn(\"The filesystem based application history store is deprecated.\");\n      return new ApplicationHistoryManagerImpl();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.createTimelineDelegationTokenSecretManagerService": "  private TimelineDelegationTokenSecretManagerService\n      createTimelineDelegationTokenSecretManagerService(Configuration conf) {\n    return new TimelineDelegationTokenSecretManagerService();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.createTimelineDataManager": "  private TimelineDataManager createTimelineDataManager(Configuration conf) {\n    TimelineACLsManager aclsMgr = new TimelineACLsManager(conf);\n    aclsMgr.setTimelineStore(timelineStore);\n    return new TimelineDataManager(timelineStore, aclsMgr);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.createTimelineStore": "  private TimelineStore createTimelineStore(\n      Configuration conf) {\n    return ReflectionUtils.newInstance(conf.getClass(\n        YarnConfiguration.TIMELINE_SERVICE_STORE, LeveldbTimelineStore.class,\n        TimelineStore.class), conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.createApplicationACLsManager": "  private ApplicationACLsManager createApplicationACLsManager(\n      Configuration conf) {\n    return new ApplicationACLsManager(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.launchAppHistoryServer": "  static ApplicationHistoryServer launchAppHistoryServer(String[] args) {\n    Thread\n      .setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ApplicationHistoryServer.class, args,\n      LOG);\n    ApplicationHistoryServer appHistoryServer = null;\n    try {\n      appHistoryServer = new ApplicationHistoryServer();\n      ShutdownHookManager.get().addShutdownHook(\n        new CompositeServiceShutdownHook(appHistoryServer),\n        SHUTDOWN_HOOK_PRIORITY);\n      YarnConfiguration conf = new YarnConfiguration();\n      new GenericOptionsParser(conf, args);\n      appHistoryServer.init(conf);\n      appHistoryServer.start();\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ApplicationHistoryServer\", t);\n      ExitUtil.terminate(-1, \"Error starting ApplicationHistoryServer\");\n    }\n    return appHistoryServer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.main": "  public static void main(String[] args) {\n    launchAppHistoryServer(args);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    Preconditions.checkArgument(conf.getLong(\n        YarnConfiguration.TIMELINE_SERVICE_TTL_MS,\n        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_TTL_MS) > 0,\n        \"%s property value should be greater than zero\",\n        YarnConfiguration.TIMELINE_SERVICE_TTL_MS);\n    Preconditions.checkArgument(conf.getLong(\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS) > 0,\n        \"%s property value should be greater than zero\",\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS);\n    Preconditions.checkArgument(conf.getLong(\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE,\n        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE) >= 0,\n        \"%s property value should be greater than or equal to zero\",\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE);\n    Preconditions.checkArgument(conf.getLong(\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE,\n        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE) > 0,\n        \" %s property value should be greater than zero\",\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE);\n    Preconditions.checkArgument(conf.getLong(\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE,\n        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE) > 0,\n        \"%s property value should be greater than zero\",\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE);\n\n    Options options = new Options();\n    options.createIfMissing(true);\n    options.cacheSize(conf.getLong(\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE,\n        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE));\n    JniDBFactory factory = new JniDBFactory();\n    Path dbPath = new Path(\n        conf.get(YarnConfiguration.TIMELINE_SERVICE_LEVELDB_PATH), FILENAME);\n    FileSystem localFS = null;\n    try {\n      localFS = FileSystem.getLocal(conf);\n      if (!localFS.exists(dbPath)) {\n        if (!localFS.mkdirs(dbPath)) {\n          throw new IOException(\"Couldn't create directory for leveldb \" +\n              \"timeline store \" + dbPath);\n        }\n        localFS.setPermission(dbPath, LEVELDB_DIR_UMASK);\n      }\n    } finally {\n      IOUtils.cleanup(LOG, localFS);\n    }\n    LOG.info(\"Using leveldb path \" + dbPath);\n    db = factory.open(new File(dbPath.toString()), options);\n    checkVersion();\n    startTimeWriteCache =\n        Collections.synchronizedMap(new LRUMap(getStartTimeWriteCacheSize(\n            conf)));\n    startTimeReadCache =\n        Collections.synchronizedMap(new LRUMap(getStartTimeReadCacheSize(\n            conf)));\n\n    if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_TTL_ENABLE, true)) {\n      deletionThread = new EntityDeletionThread(conf);\n      deletionThread.start();\n    }\n\n    super.serviceInit(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore.getStartTimeWriteCacheSize": "  static int getStartTimeWriteCacheSize(Configuration conf) {\n    return conf.getInt(\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE,\n        YarnConfiguration.\n            DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore.checkVersion": "  private void checkVersion() throws IOException {\n    Version loadedVersion = loadVersion();\n    LOG.info(\"Loaded timeline store version info \" + loadedVersion);\n    if (loadedVersion.equals(getCurrentVersion())) {\n      return;\n    }\n    if (loadedVersion.isCompatibleTo(getCurrentVersion())) {\n      LOG.info(\"Storing timeline store version info \" + getCurrentVersion());\n      dbStoreVersion(CURRENT_VERSION_INFO);\n    } else {\n      String incompatibleMessage = \n          \"Incompatible version for timeline store: expecting version \" \n              + getCurrentVersion() + \", but loading version \" + loadedVersion;\n      LOG.fatal(incompatibleMessage);\n      throw new IOException(incompatibleMessage);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore.getStartTimeReadCacheSize": "  static int getStartTimeReadCacheSize(Configuration conf) {\n    return conf.getInt(\n        YarnConfiguration.TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE,\n        YarnConfiguration.\n            DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.init": "  void init(Configuration config);\n\n\n  /**\n   * Start the service.\n   *\n   * The transition MUST be from {@link STATE#INITED} to {@link STATE#STARTED}"
        },
        "bug_report": {
            "Title": "TimelineServer fails to start when some LevelDb state files are missing.",
            "Description": "We encountered an issue recently where the TimelineServer failed to start because some state files went missing.\n\n{code}\n2016-11-21 20:46:43,134 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer failed in state INITED\n; cause: org.apache.hadoop.service.ServiceStateException: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelines\nerver/leveldb-timeline-store.ldb/127897.sst\norg.apache.hadoop.service.ServiceStateException: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelineserver/lev\neldb-timeline-store.ldb/127897.sst\n\n2016-11-21 20:46:43,135 FATAL org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer: Error starting ApplicationHistoryServer\norg.apache.hadoop.service.ServiceStateException: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelineserver/leveldb-timeline-store.ldb/127897.sst\n        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:172)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.serviceInit(ApplicationHistoryServer.java:104)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.launchAppHistoryServer(ApplicationHistoryServer.java:172)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.main(ApplicationHistoryServer.java:182)\nCaused by: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelineserver/leveldb-timeline-store.ldb/127897.sst\n        at org.fusesource.leveldbjni.internal.NativeDB.checkStatus(NativeDB.java:200)\n        at org.fusesource.leveldbjni.internal.NativeDB.open(NativeDB.java:218)\n        at org.fusesource.leveldbjni.JniDBFactory.open(JniDBFactory.java:168)\n        at org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore.serviceInit(LeveldbTimelineStore.java:229)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        ... 5 more\n2016-11-21 20:46:43,136 INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1\n{code}\nIdeally we shouldn't have any missing state files. However I'd posit that the TimelineServer should have graceful degradation instead of failing to start at all."
        }
    },
    {
        "filename": "YARN-196.json",
        "creation_time": "2012-01-16T09:52:45.000+0000",
        "stack_trace": "```\norg.apache.avro.AvroRuntimeException: java.lang.reflect.UndeclaredThrowableException\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:149)\n\tat org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:167)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:242)\nCaused by: java.lang.reflect.UndeclaredThrowableException\n\tat org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:66)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:182)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:145)\n\t... 3 more\nCaused by: com.google.protobuf.ServiceException: java.net.ConnectException: Call From HOST-10-18-52-230/10.18.52.230 to HOST-10-18-52-250:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:131)\n\tat $Proxy23.registerNodeManager(Unknown Source)\n\tat org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)\n\t... 5 more\nCaused by: java.net.ConnectException: Call From HOST-10-18-52-230/10.18.52.230 to HOST-10-18-52-250:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:857)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1141)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1100)\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:128)\n\t... 7 more\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:659)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:469)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:563)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:211)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1247)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1117)\n\t... 9 more\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1934)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:76)\n\tat java.lang.Thread.run(Thread.java:619)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.wrapException": "  public static IOException wrapException(final String destHost,\n                                          final int destPort,\n                                          final String localHost,\n                                          final int localPort,\n                                          final IOException exception) {\n    if (exception instanceof BindException) {\n      return new BindException(\n          \"Problem binding to [\"\n              + localHost\n              + \":\"\n              + localPort\n              + \"] \"\n              + exception\n              + \";\"\n              + see(\"BindException\"));\n    } else if (exception instanceof ConnectException) {\n      // connection refused; include the host:port in the error\n      return (ConnectException) new ConnectException(\n          \"Call From \"\n              + localHost\n              + \" to \"\n              + destHost\n              + \":\"\n              + destPort\n              + \" failed on connection exception: \"\n              + exception\n              + \";\"\n              + see(\"ConnectionRefused\"))\n          .initCause(exception);\n    } else if (exception instanceof UnknownHostException) {\n      return (UnknownHostException) new UnknownHostException(\n          \"Invalid host name: \"\n              + getHostDetailsAsString(destHost, destPort, localHost)\n              + exception\n              + \";\"\n              + see(\"UnknownHost\"))\n          .initCause(exception);\n    } else if (exception instanceof SocketTimeoutException) {\n      return (SocketTimeoutException) new SocketTimeoutException(\n          \"Call From \"\n              + localHost + \" to \" + destHost + \":\" + destPort\n              + \" failed on socket timeout exception: \" + exception\n              + \";\"\n              + see(\"SocketTimeout\"))\n          .initCause(exception);\n    } else if (exception instanceof NoRouteToHostException) {\n      return (NoRouteToHostException) new NoRouteToHostException(\n          \"No Route to Host from  \"\n              + localHost + \" to \" + destHost + \":\" + destPort\n              + \" failed on socket timeout exception: \" + exception\n              + \";\"\n              + see(\"NoRouteToHost\"))\n          .initCause(exception);\n    }\n    else {\n      return (IOException) new IOException(\"Failed on local exception: \"\n                                               + exception\n                                               + \"; Host Details : \"\n                                               + getHostDetailsAsString(destHost, destPort, localHost))\n          .initCause(exception);\n\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.see": "  private static String see(final String entry) {\n    return FOR_MORE_DETAILS_SEE + HADOOP_WIKI + entry;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.getHostDetailsAsString": "  private static String getHostDetailsAsString(final String destHost,\n                                               final int destPort,\n                                               final String localHost) {\n    StringBuilder hostDetails = new StringBuilder(27);\n    hostDetails.append(\"local host is: \")\n        .append(quoteHost(localHost))\n        .append(\"; \");\n    hostDetails.append(\"destination host is: \\\"\").append(quoteHost(destHost))\n        .append(\":\")\n        .append(destPort).append(\"; \");\n    return hostDetails.toString();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.call": "  public Writable[] call(Writable[] params, InetSocketAddress[] addresses,\n      Class<?> protocol, UserGroupInformation ticket, Configuration conf)\n      throws IOException, InterruptedException {\n    if (addresses.length == 0) return new Writable[0];\n\n    ParallelResults results = new ParallelResults(params.length);\n    synchronized (results) {\n      for (int i = 0; i < params.length; i++) {\n        ParallelCall call = new ParallelCall(params[i], results, i);\n        try {\n          ConnectionId remoteId = ConnectionId.getConnectionId(addresses[i],\n              protocol, ticket, 0, conf);\n          Connection connection = getConnection(remoteId, call);\n          connection.sendParam(call);             // send each parameter\n        } catch (IOException e) {\n          // log errors\n          LOG.info(\"Calling \"+addresses[i]+\" caught: \" + \n                   e.getMessage(),e);\n          results.size--;                         //  wait for one fewer result\n        }\n      }\n      while (results.count != results.size) {\n        try {\n          results.wait();                    // wait for all results\n        } catch (InterruptedException e) {}\n      }\n\n      return results.values;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.sendParam": "    public void sendParam(Call call) {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n\n      DataOutputBuffer d=null;\n      try {\n        synchronized (this.out) {\n          if (LOG.isDebugEnabled())\n            LOG.debug(getName() + \" sending #\" + call.id);\n          \n          //for serializing the\n          //data to be written\n          d = new DataOutputBuffer();\n          RpcPayloadHeader header = new RpcPayloadHeader(\n              call.rpcKind, RpcPayloadOperation.RPC_FINAL_PAYLOAD, call.id);\n          header.write(d);\n          call.rpcRequest.write(d);\n          byte[] data = d.getData();\n          int dataLength = d.getLength();\n          out.writeInt(dataLength);      //first put the data length\n          out.write(data, 0, dataLength);//write the data\n          out.flush();\n        }\n      } catch(IOException e) {\n        markClosed(e);\n      } finally {\n        //the buffer is just an in-memory buffer, but it is still polite to\n        // close early\n        IOUtils.closeStream(d);\n      }\n    }  ",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnection": "  private Connection getConnection(ConnectionId remoteId,\n                                   Call call)\n                                   throws IOException, InterruptedException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    do {\n      synchronized (connections) {\n        connection = connections.get(remoteId);\n        if (connection == null) {\n          connection = new Connection(remoteId);\n          connections.put(remoteId, connection);\n        }\n      }\n    } while (!connection.addCall(call));\n    \n    //we don't invoke the method below inside \"synchronized (connections)\"\n    //block above. The reason for that is if the server happens to be slow,\n    //it will take longer to establish a connection and that will slow the\n    //entire system down.\n    connection.setupIOstreams();\n    return connection;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnectionId": "    public static ConnectionId getConnectionId(InetSocketAddress addr,\n        Class<?> protocol, UserGroupInformation ticket, int rpcTimeout,\n        Configuration conf) throws IOException {\n      String remotePrincipal = getRemotePrincipal(conf, addr, protocol);\n      boolean doPing =\n        conf.getBoolean(CommonConfigurationKeys.IPC_CLIENT_PING_KEY, true);\n      return new ConnectionId(addr, protocol, ticket,\n          rpcTimeout, remotePrincipal,\n          conf.getInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,\n              CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_DEFAULT),\n          conf.getInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_KEY,\n              CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_DEFAULT),\n          conf.getBoolean(CommonConfigurationKeysPublic.IPC_CLIENT_TCPNODELAY_KEY,\n              CommonConfigurationKeysPublic.IPC_CLIENT_TCPNODELAY_DEFAULT),\n          doPing, \n          (doPing ? Client.getPingInterval(conf) : 0));\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getAddress": "    InetSocketAddress getAddress() {\n      return address;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.connect": "  static void connect(SocketChannel channel, \n                      SocketAddress endpoint, int timeout) throws IOException {\n    \n    boolean blockingOn = channel.isBlocking();\n    if (blockingOn) {\n      channel.configureBlocking(false);\n    }\n    \n    try { \n      if (channel.connect(endpoint)) {\n        return;\n      }\n\n      long timeoutLeft = timeout;\n      long endTime = (timeout > 0) ? (System.currentTimeMillis() + timeout): 0;\n      \n      while (true) {\n        // we might have to call finishConnect() more than once\n        // for some channels (with user level protocols)\n        \n        int ret = selector.select((SelectableChannel)channel, \n                                  SelectionKey.OP_CONNECT, timeoutLeft);\n        \n        if (ret > 0 && channel.finishConnect()) {\n          return;\n        }\n        \n        if (ret == 0 ||\n            (timeout > 0 &&  \n              (timeoutLeft = (endTime - System.currentTimeMillis())) <= 0)) {\n          throw new SocketTimeoutException(\n                    timeoutExceptionString(channel, timeout, \n                                           SelectionKey.OP_CONNECT));\n        }\n      }\n    } catch (IOException e) {\n      // javadoc for SocketChannel.connect() says channel should be closed.\n      try {\n        channel.close();\n      } catch (IOException ignored) {}\n      throw e;\n    } finally {\n      if (blockingOn && channel.isOpen()) {\n        channel.configureBlocking(true);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.close": "      void close() {\n        if (selector != null) {\n          try {\n            selector.close();\n          } catch (IOException e) {\n            LOG.warn(\"Unexpected exception while closing selector : \", e);\n          }\n        }\n      }    ",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.select": "    int select(SelectableChannel channel, int ops, long timeout) \n                                                   throws IOException {\n     \n      SelectorInfo info = get(channel);\n      \n      SelectionKey key = null;\n      int ret = 0;\n      \n      try {\n        while (true) {\n          long start = (timeout == 0) ? 0 : System.currentTimeMillis();\n\n          key = channel.register(info.selector, ops);\n          ret = info.selector.select(timeout);\n          \n          if (ret != 0) {\n            return ret;\n          }\n          \n          /* Sometimes select() returns 0 much before timeout for \n           * unknown reasons. So select again if required.\n           */\n          if (timeout > 0) {\n            timeout -= System.currentTimeMillis() - start;\n            if (timeout <= 0) {\n              return 0;\n            }\n          }\n          \n          if (Thread.currentThread().isInterrupted()) {\n            throw new InterruptedIOException(\"Interruped while waiting for \" +\n                                             \"IO on channel \" + channel +\n                                             \". \" + timeout + \n                                             \" millis timeout left.\");\n          }\n        }\n      } finally {\n        if (key != null) {\n          key.cancel();\n        }\n        \n        //clear the canceled key.\n        try {\n          info.selector.selectNow();\n        } catch (IOException e) {\n          LOG.info(\"Unexpected Exception while clearing selector : \", e);\n          // don't put the selector back.\n          info.close();\n          return ret; \n        }\n        \n        release(info);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.timeoutExceptionString": "  private static String timeoutExceptionString(SelectableChannel channel,\n                                               long timeout, int ops) {\n    \n    String waitingFor;\n    switch(ops) {\n    \n    case SelectionKey.OP_READ :\n      waitingFor = \"read\"; break;\n      \n    case SelectionKey.OP_WRITE :\n      waitingFor = \"write\"; break;      \n      \n    case SelectionKey.OP_CONNECT :\n      waitingFor = \"connect\"; break;\n      \n    default :\n      waitingFor = \"\" + ops;  \n    }\n    \n    return timeout + \" millis timeout while \" +\n           \"waiting for channel to be ready for \" + \n           waitingFor + \". ch : \" + channel;    \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.SocketIOWithTimeout.isOpen": "  boolean isOpen() {\n    return !closed && channel.isOpen();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.connect": "  public static void connect(Socket socket, \n                             SocketAddress endpoint, \n                             int timeout) throws IOException {\n    if (socket == null || endpoint == null || timeout < 0) {\n      throw new IllegalArgumentException(\"Illegal argument for connect()\");\n    }\n    \n    SocketChannel ch = socket.getChannel();\n    \n    if (ch == null) {\n      // let the default implementation handle it.\n      socket.connect(endpoint, timeout);\n    } else {\n      SocketIOWithTimeout.connect(ch, endpoint, timeout);\n    }\n\n    // There is a very rare case allowed by the TCP specification, such that\n    // if we are trying to connect to an endpoint on the local machine,\n    // and we end up choosing an ephemeral port equal to the destination port,\n    // we will actually end up getting connected to ourself (ie any data we\n    // send just comes right back). This is only possible if the target\n    // daemon is down, so we'll treat it like connection refused.\n    if (socket.getLocalPort() == socket.getPort() &&\n        socket.getLocalAddress().equals(socket.getInetAddress())) {\n      LOG.info(\"Detected a loopback TCP socket, disconnecting it\");\n      socket.close();\n      throw new ConnectException(\n        \"Localhost targeted connection resulted in a loopback. \" +\n        \"No daemon is listening on the target port.\");\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupConnection": "    private synchronized void setupConnection() throws IOException {\n      short ioFailures = 0;\n      short timeoutFailures = 0;\n      while (true) {\n        try {\n          this.socket = socketFactory.createSocket();\n          this.socket.setTcpNoDelay(tcpNoDelay);\n          \n          /*\n           * Bind the socket to the host specified in the principal name of the\n           * client, to ensure Server matching address of the client connection\n           * to host name in principal passed.\n           */\n          if (UserGroupInformation.isSecurityEnabled()) {\n            KerberosInfo krbInfo = \n              remoteId.getProtocol().getAnnotation(KerberosInfo.class);\n            if (krbInfo != null && krbInfo.clientPrincipal() != null) {\n              String host = \n                SecurityUtil.getHostFromPrincipal(remoteId.getTicket().getUserName());\n              \n              // If host name is a valid local address then bind socket to it\n              InetAddress localAddr = NetUtils.getLocalInetAddress(host);\n              if (localAddr != null) {\n                this.socket.bind(new InetSocketAddress(localAddr, 0));\n              }\n            }\n          }\n          \n          // connection time out is 20s\n          NetUtils.connect(this.socket, server, 20000);\n          if (rpcTimeout > 0) {\n            pingInterval = rpcTimeout;  // rpcTimeout overwrites pingInterval\n          }\n          this.socket.setSoTimeout(pingInterval);\n          return;\n        } catch (SocketTimeoutException toe) {\n          /* Check for an address change and update the local reference.\n           * Reset the failure counter if the address was changed\n           */\n          if (updateAddress()) {\n            timeoutFailures = ioFailures = 0;\n          }\n          /*\n           * The max number of retries is 45, which amounts to 20s*45 = 15\n           * minutes retries.\n           */\n          handleConnectionFailure(timeoutFailures++, 45, toe);\n        } catch (IOException ie) {\n          if (updateAddress()) {\n            timeoutFailures = ioFailures = 0;\n          }\n          handleConnectionFailure(ioFailures++, maxRetries, ie);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getTicket": "    UserGroupInformation getTicket() {\n      return ticket;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.handleConnectionFailure": "    private void handleConnectionFailure(\n        int curRetries, int maxRetries, IOException ioe) throws IOException {\n\n      closeConnection();\n\n      // throw the exception if the maximum number of retries is reached\n      if (curRetries >= maxRetries) {\n        throw ioe;\n      }\n\n      // otherwise back off and retry\n      try {\n        Thread.sleep(1000);\n      } catch (InterruptedException ignored) {}\n      \n      LOG.info(\"Retrying connect to server: \" + server + \n          \". Already tried \" + curRetries + \" time(s).\");\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.updateAddress": "    private synchronized boolean updateAddress() throws IOException {\n      // Do a fresh lookup with the old host name.\n      InetSocketAddress currentAddr = NetUtils.createSocketAddrForHost(\n                               server.getHostName(), server.getPort());\n\n      if (!server.equals(currentAddr)) {\n        LOG.warn(\"Address change detected. Old: \" + server.toString() +\n                                 \" New: \" + currentAddr.toString());\n        server = currentAddr;\n        return true;\n      }\n      return false;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getProtocol": "    Class<?> getProtocol() {\n      return protocol;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupIOstreams": "    private synchronized void setupIOstreams() throws InterruptedException {\n      if (socket != null || shouldCloseConnection.get()) {\n        return;\n      } \n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to \"+server);\n        }\n        short numRetries = 0;\n        final short MAX_RETRIES = 5;\n        Random rand = null;\n        while (true) {\n          setupConnection();\n          InputStream inStream = NetUtils.getInputStream(socket);\n          OutputStream outStream = NetUtils.getOutputStream(socket);\n          writeRpcHeader(outStream);\n          if (useSasl) {\n            final InputStream in2 = inStream;\n            final OutputStream out2 = outStream;\n            UserGroupInformation ticket = remoteId.getTicket();\n            if (authMethod == AuthMethod.KERBEROS) {\n              if (ticket.getRealUser() != null) {\n                ticket = ticket.getRealUser();\n              }\n            }\n            boolean continueSasl = false;\n            try {\n              continueSasl = ticket\n                  .doAs(new PrivilegedExceptionAction<Boolean>() {\n                    @Override\n                    public Boolean run() throws IOException {\n                      return setupSaslConnection(in2, out2);\n                    }\n                  });\n            } catch (Exception ex) {\n              if (rand == null) {\n                rand = new Random();\n              }\n              handleSaslConnectionFailure(numRetries++, MAX_RETRIES, ex, rand,\n                  ticket);\n              continue;\n            }\n            if (continueSasl) {\n              // Sasl connect is successful. Let's set up Sasl i/o streams.\n              inStream = saslRpcClient.getInputStream(inStream);\n              outStream = saslRpcClient.getOutputStream(outStream);\n            } else {\n              // fall back to simple auth because server told us so.\n              authMethod = AuthMethod.SIMPLE;\n              header = new ConnectionHeader(header.getProtocol(), header\n                  .getUgi(), authMethod);\n              useSasl = false;\n            }\n          }\n        \n          if (doPing) {\n            this.in = new DataInputStream(new BufferedInputStream(\n                new PingInputStream(inStream)));\n          } else {\n            this.in = new DataInputStream(new BufferedInputStream(inStream));\n          }\n          this.out = new DataOutputStream(new BufferedOutputStream(outStream));\n          writeHeader();\n\n          // update last activity time\n          touch();\n\n          // start the receiver thread after the socket connection has been set\n          // up\n          start();\n          return;\n        }\n      } catch (Throwable t) {\n        if (t instanceof IOException) {\n          markClosed((IOException)t);\n        } else {\n          markClosed(new IOException(\"Couldn't set up IO streams\", t));\n        }\n        close();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.close": "    private synchronized void close() {\n      if (!shouldCloseConnection.get()) {\n        LOG.error(\"The connection is not in the closed state\");\n        return;\n      }\n\n      // release the resources\n      // first thing to do;take the connection out of the connection list\n      synchronized (connections) {\n        if (connections.get(remoteId) == this) {\n          connections.remove(remoteId);\n        }\n      }\n\n      // close the streams and therefore the socket\n      IOUtils.closeStream(out);\n      IOUtils.closeStream(in);\n      disposeSasl();\n\n      // clean up all calls\n      if (closeException == null) {\n        if (!calls.isEmpty()) {\n          LOG.warn(\n              \"A connection is closed for no cause and calls are not empty\");\n\n          // clean up calls anyway\n          closeException = new IOException(\"Unexpected closed connection\");\n          cleanupCalls();\n        }\n      } else {\n        // log the info\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"closing ipc connection to \" + server + \": \" +\n              closeException.getMessage(),closeException);\n        }\n\n        // cleanup calls\n        cleanupCalls();\n      }\n      if (LOG.isDebugEnabled())\n        LOG.debug(getName() + \": closed\");\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.handleSaslConnectionFailure": "    private synchronized void handleSaslConnectionFailure(\n        final int currRetries, final int maxRetries, final Exception ex,\n        final Random rand, final UserGroupInformation ugi) throws IOException,\n        InterruptedException {\n      ugi.doAs(new PrivilegedExceptionAction<Object>() {\n        public Object run() throws IOException, InterruptedException {\n          final short MAX_BACKOFF = 5000;\n          closeConnection();\n          disposeSasl();\n          if (shouldAuthenticateOverKrb()) {\n            if (currRetries < maxRetries) {\n              if(LOG.isDebugEnabled()) {\n                LOG.debug(\"Exception encountered while connecting to \"\n                    + \"the server : \" + ex);\n              }\n              // try re-login\n              if (UserGroupInformation.isLoginKeytabBased()) {\n                UserGroupInformation.getLoginUser().reloginFromKeytab();\n              } else {\n                UserGroupInformation.getLoginUser().reloginFromTicketCache();\n              }\n              // have granularity of milliseconds\n              //we are sleeping with the Connection lock held but since this\n              //connection instance is being used for connecting to the server\n              //in question, it is okay\n              Thread.sleep((rand.nextInt(MAX_BACKOFF) + 1));\n              return null;\n            } else {\n              String msg = \"Couldn't setup connection for \"\n                  + UserGroupInformation.getLoginUser().getUserName() + \" to \"\n                  + serverPrincipal;\n              LOG.warn(msg);\n              throw (IOException) new IOException(msg).initCause(ex);\n            }\n          } else {\n            LOG.warn(\"Exception encountered while connecting to \"\n                + \"the server : \" + ex);\n          }\n          if (ex instanceof RemoteException)\n            throw (RemoteException) ex;\n          throw new IOException(ex);\n        }\n      });\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.markClosed": "    private synchronized void markClosed(IOException e) {\n      if (shouldCloseConnection.compareAndSet(false, true)) {\n        closeException = e;\n        notifyAll();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.writeRpcHeader": "    private void writeRpcHeader(OutputStream outStream) throws IOException {\n      DataOutputStream out = new DataOutputStream(new BufferedOutputStream(outStream));\n      // Write out the header, version and authentication method\n      out.write(Server.HEADER.array());\n      out.write(Server.CURRENT_VERSION);\n      authMethod.write(out);\n      out.flush();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupSaslConnection": "    private synchronized boolean setupSaslConnection(final InputStream in2, \n        final OutputStream out2) \n        throws IOException {\n      saslRpcClient = new SaslRpcClient(authMethod, token, serverPrincipal);\n      return saslRpcClient.saslConnect(in2, out2);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.touch": "    private void touch() {\n      lastActivity.set(System.currentTimeMillis());\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.writeHeader": "    private void writeHeader() throws IOException {\n      // Write out the ConnectionHeader\n      DataOutputBuffer buf = new DataOutputBuffer();\n      header.write(buf);\n      \n      // Write out the payload length\n      int bufLen = buf.getLength();\n      out.writeInt(bufLen);\n      out.write(buf.getData(), 0, bufLen);\n    }"
        },
        "bug_report": {
            "Title": "Nodemanager should be more robust in handling connection failure  to ResourceManager when a cluster is started",
            "Description": "If NM is started before starting the RM ,NM is shutting down with the following error\n{code}\nERROR org.apache.hadoop.yarn.service.CompositeService: Error starting services org.apache.hadoop.yarn.server.nodemanager.NodeManager\norg.apache.avro.AvroRuntimeException: java.lang.reflect.UndeclaredThrowableException\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:149)\n\tat org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:167)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:242)\nCaused by: java.lang.reflect.UndeclaredThrowableException\n\tat org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:66)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:182)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:145)\n\t... 3 more\nCaused by: com.google.protobuf.ServiceException: java.net.ConnectException: Call From HOST-10-18-52-230/10.18.52.230 to HOST-10-18-52-250:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:131)\n\tat $Proxy23.registerNodeManager(Unknown Source)\n\tat org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)\n\t... 5 more\nCaused by: java.net.ConnectException: Call From HOST-10-18-52-230/10.18.52.230 to HOST-10-18-52-250:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:857)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1141)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1100)\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:128)\n\t... 7 more\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:659)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:469)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:563)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:211)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1247)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1117)\n\t... 9 more\n2012-01-16 15:04:13,336 WARN org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher thread interrupted\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1934)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:76)\n\tat java.lang.Thread.run(Thread.java:619)\n2012-01-16 15:04:13,337 INFO org.apache.hadoop.yarn.service.AbstractService: Service:Dispatcher is stopped.\n2012-01-16 15:04:13,392 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:9999\n2012-01-16 15:04:13,493 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer is stopped.\n2012-01-16 15:04:13,493 INFO org.apache.hadoop.ipc.Server: Stopping server on 24290\n2012-01-16 15:04:13,494 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 24290\n2012-01-16 15:04:13,495 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder\n2012-01-16 15:04:13,496 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler is stopped.\n2012-01-16 15:04:13,496 WARN org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher thread interrupted\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1934)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:76)\n\tat java.lang.Thread.run(Thread.java:619)\n{code}"
        }
    },
    {
        "filename": "YARN-8508.json",
        "creation_time": "2018-07-09T23:37:49.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerException: Failed to find enough GPUs, requestor=container_e20_1530854311763_0007_01_000002, #RequestedGPUs=2, #availableGpus=1\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.internalAssignGpus(GpuResourceAllocator.java:225)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.assignGpus(GpuResourceAllocator.java:173)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceHandlerImpl.preStart(GpuResourceHandlerImpl.java:98)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.preStart(ResourceHandlerChain.java:75)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:509)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:479)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:494)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:306)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:103)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\njava.io.IOException: ResourceHandlerChain.preStart() failed!\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:551)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:479)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:494)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:306)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:103)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerException: Failed to find enough GPUs, requestor=container_e20_1530854311763_0007_01_000002, #RequestedGPUs=2, #availableGpus=1\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.internalAssignGpus(GpuResourceAllocator.java:225)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.assignGpus(GpuResourceAllocator.java:173)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceHandlerImpl.preStart(GpuResourceHandlerImpl.java:98)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.preStart(ResourceHandlerChain.java:75)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:509)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.internalAssignGpus": "  private synchronized GpuAllocation internalAssignGpus(Container container)\n      throws ResourceHandlerException {\n    Resource requestedResource = container.getResource();\n    ContainerId containerId = container.getContainerId();\n    int numRequestedGpuDevices = getRequestedGpus(requestedResource);\n    // Assign Gpus to container if requested some.\n    if (numRequestedGpuDevices > 0) {\n      if (numRequestedGpuDevices > getAvailableGpus()) {\n        // If there are some devices which are getting released, wait for few\n        // seconds to get it.\n        if (numRequestedGpuDevices <= getReleasingGpus() + getAvailableGpus()) {\n          return null;\n        }\n      }\n\n      if (numRequestedGpuDevices > getAvailableGpus()) {\n        throw new ResourceHandlerException(\n            getResourceHandlerExceptionMessage(numRequestedGpuDevices,\n                containerId));\n      }\n\n      Set<GpuDevice> assignedGpus = new TreeSet<>();\n\n      for (GpuDevice gpu : allowedGpuDevices) {\n        if (!usedDevices.containsKey(gpu)) {\n          usedDevices.put(gpu, containerId);\n          assignedGpus.add(gpu);\n          if (assignedGpus.size() == numRequestedGpuDevices) {\n            break;\n          }\n        }\n      }\n\n      // Record in state store if we allocated anything\n      if (!assignedGpus.isEmpty()) {\n        try {\n          // Update state store.\n          nmContext.getNMStateStore().storeAssignedResources(container, GPU_URI,\n              new ArrayList<>(assignedGpus));\n        } catch (IOException e) {\n          cleanupAssignGpus(containerId);\n          throw new ResourceHandlerException(e);\n        }\n      }\n\n      return new GpuAllocation(assignedGpus,\n          Sets.difference(allowedGpuDevices, assignedGpus));\n    }\n    return new GpuAllocation(null, allowedGpuDevices);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.getRequestedGpus": "  public static int getRequestedGpus(Resource requestedResource) {\n    try {\n      return Long.valueOf(requestedResource.getResourceValue(\n          GPU_URI)).intValue();\n    } catch (ResourceNotFoundException e) {\n      return 0;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.cleanupAssignGpus": "  public synchronized void cleanupAssignGpus(ContainerId containerId) {\n    Iterator<Map.Entry<GpuDevice, ContainerId>> iter =\n        usedDevices.entrySet().iterator();\n    while (iter.hasNext()) {\n      if (iter.next().getValue().equals(containerId)) {\n        iter.remove();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.getReleasingGpus": "  private synchronized long getReleasingGpus() {\n    long releasingGpus = 0;\n    Iterator<Map.Entry<GpuDevice, ContainerId>> iter = usedDevices.entrySet()\n        .iterator();\n    while (iter.hasNext()) {\n      ContainerId containerId = iter.next().getValue();\n      Container container;\n      if ((container = nmContext.getContainers().get(containerId)) != null) {\n        if (container.isContainerInFinalStates()) {\n          releasingGpus = releasingGpus + container.getResource()\n              .getResourceInformation(ResourceInformation.GPU_URI).getValue();\n        }\n      }\n    }\n    return releasingGpus;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.getResourceHandlerExceptionMessage": "  private String getResourceHandlerExceptionMessage(int numRequestedGpuDevices,\n      ContainerId containerId) {\n    return \"Failed to find enough GPUs, requestor=\" + containerId\n        + \", #RequestedGPUs=\" + numRequestedGpuDevices + \", #availableGpus=\"\n        + getAvailableGpus();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.getAvailableGpus": "  public synchronized int getAvailableGpus() {\n    return allowedGpuDevices.size() - usedDevices.size();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.assignGpus": "  public GpuAllocation assignGpus(Container container)\n      throws ResourceHandlerException {\n    GpuAllocation allocation = internalAssignGpus(container);\n\n    // Wait for a maximum of 120 seconds if no available GPU are there which\n    // are yet to be released.\n    final int timeoutMsecs = 120 * WAIT_MS_PER_LOOP;\n    int timeWaiting = 0;\n    while (allocation == null) {\n      if (timeWaiting >= timeoutMsecs) {\n        break;\n      }\n\n      // Sleep for 1 sec to ensure there are some free GPU devices which are\n      // getting released.\n      try {\n        LOG.info(\"Container : \" + container.getContainerId()\n            + \" is waiting for free GPU devices.\");\n        Thread.sleep(WAIT_MS_PER_LOOP);\n        timeWaiting += WAIT_MS_PER_LOOP;\n        allocation = internalAssignGpus(container);\n      } catch (InterruptedException e) {\n        // On any interrupt, break the loop and continue execution.\n        break;\n      }\n    }\n\n    if(allocation == null) {\n      String message = \"Could not get valid GPU device for container '\" +\n          container.getContainerId()\n          + \"' as some other containers might not releasing GPUs.\";\n      LOG.warn(message);\n      throw new ResourceHandlerException(message);\n    }\n    return allocation;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceHandlerImpl.preStart": "  public synchronized List<PrivilegedOperation> preStart(Container container)\n      throws ResourceHandlerException {\n    String containerIdStr = container.getContainerId().toString();\n\n    // Assign Gpus to container if requested some.\n    GpuResourceAllocator.GpuAllocation allocation = gpuAllocator.assignGpus(\n        container);\n\n    // Create device cgroups for the container\n    cGroupsHandler.createCGroup(CGroupsHandler.CGroupController.DEVICES,\n        containerIdStr);\n    if (!DockerLinuxContainerRuntime.isDockerContainerRequested(\n        container.getLaunchContext().getEnvironment())) {\n      // Write to devices cgroup only for non-docker container. The reason is\n      // docker engine runtime runc do the devices cgroups initialize in the\n      // pre-hook, see:\n      //   https://github.com/opencontainers/runc/blob/master/libcontainer/configs/device_defaults.go\n      //\n      // YARN by default runs docker container inside cgroup, if we setup cgroups\n      // devices.deny for the parent cgroup for launched container, we can see\n      // errors like: failed to write c *:* m to devices.allow:\n      // write path-to-parent-cgroup/<container-id>/devices.allow:\n      // operation not permitted.\n      //\n      // To avoid this happen, if docker is requested when container being\n      // launched, we will not setup devices.deny for the container. Instead YARN\n      // will pass --device parameter to docker engine. See NvidiaDockerV1CommandPlugin\n      try {\n        // Execute c-e to setup GPU isolation before launch the container\n        PrivilegedOperation privilegedOperation = new PrivilegedOperation(\n            PrivilegedOperation.OperationType.GPU,\n            Arrays.asList(CONTAINER_ID_CLI_OPTION, containerIdStr));\n        if (!allocation.getDeniedGPUs().isEmpty()) {\n          List<Integer> minorNumbers = new ArrayList<>();\n          for (GpuDevice deniedGpu : allocation.getDeniedGPUs()) {\n            minorNumbers.add(deniedGpu.getMinorNumber());\n          }\n          privilegedOperation.appendArgs(Arrays.asList(EXCLUDED_GPUS_CLI_OPTION,\n              StringUtils.join(\",\", minorNumbers)));\n        }\n\n        privilegedOperationExecutor.executePrivilegedOperation(\n            privilegedOperation, true);\n      } catch (PrivilegedOperationException e) {\n        cGroupsHandler.deleteCGroup(CGroupsHandler.CGroupController.DEVICES,\n            containerIdStr);\n        LOG.warn(\"Could not update cgroup for container\", e);\n        throw new ResourceHandlerException(e);\n      }\n\n      List<PrivilegedOperation> ret = new ArrayList<>();\n      ret.add(new PrivilegedOperation(\n          PrivilegedOperation.OperationType.ADD_PID_TO_CGROUP,\n          PrivilegedOperation.CGROUP_ARG_PREFIX + cGroupsHandler\n              .getPathForCGroupTasks(CGroupsHandler.CGroupController.DEVICES,\n                  containerIdStr)));\n\n      return ret;\n    }\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.preStart": "  public List<PrivilegedOperation> preStart(Container container)\n      throws ResourceHandlerException {\n    List<PrivilegedOperation> allOperations = new\n        ArrayList<PrivilegedOperation>();\n\n    for (ResourceHandler resourceHandler : resourceHandlers) {\n      List<PrivilegedOperation> handlerOperations =\n          resourceHandler.preStart(container);\n\n      if (handlerOperations != null) {\n        allOperations.addAll(handlerOperations);\n      }\n\n    }\n    return allOperations;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType": "  private int handleLaunchForLaunchType(ContainerStartContext ctx,\n      ApplicationConstants.ContainerLaunchType type) throws IOException,\n      ConfigurationException {\n    Container container = ctx.getContainer();\n    String user = ctx.getUser();\n\n    verifyUsernamePattern(user);\n\n    ContainerId containerId = container.getContainerId();\n\n    resourcesHandler.preExecute(containerId,\n            container.getResource());\n    String resourcesOptions = resourcesHandler.getResourcesOption(containerId);\n    String tcCommandFile = null;\n    List<String> numaArgs = null;\n\n    try {\n      if (resourceHandlerChain != null) {\n        List<PrivilegedOperation> ops = resourceHandlerChain\n            .preStart(container);\n\n        if (ops != null) {\n          List<PrivilegedOperation> resourceOps = new ArrayList<>();\n\n          resourceOps.add(new PrivilegedOperation(\n              PrivilegedOperation.OperationType.ADD_PID_TO_CGROUP,\n                  resourcesOptions));\n\n          for (PrivilegedOperation op : ops) {\n            switch (op.getOperationType()) {\n            case ADD_PID_TO_CGROUP:\n              resourceOps.add(op);\n              break;\n            case TC_MODIFY_STATE:\n              tcCommandFile = op.getArguments().get(0);\n              break;\n            case ADD_NUMA_PARAMS:\n              numaArgs = op.getArguments();\n              break;\n            default:\n              LOG.warn(\"PrivilegedOperation type unsupported in launch: \"\n                  + op.getOperationType());\n            }\n          }\n\n          if (resourceOps.size() > 1) {\n            //squash resource operations\n            try {\n              PrivilegedOperation operation = PrivilegedOperationExecutor\n                  .squashCGroupOperations(resourceOps);\n              resourcesOptions = operation.getArguments().get(0);\n            } catch (PrivilegedOperationException e) {\n              LOG.error(\"Failed to squash cgroup operations!\", e);\n              throw new ResourceHandlerException(\n                  \"Failed to squash cgroup operations!\");\n            }\n          }\n        }\n      }\n    } catch (ResourceHandlerException e) {\n      LOG.error(\"ResourceHandlerChain.preStart() failed!\", e);\n      throw new IOException(\"ResourceHandlerChain.preStart() failed!\", e);\n    }\n\n    try {\n      Path pidFilePath = getPidFilePath(containerId);\n      if (pidFilePath != null) {\n\n        ContainerRuntimeContext runtimeContext = buildContainerRuntimeContext(\n            ctx, pidFilePath, resourcesOptions, tcCommandFile, numaArgs);\n\n        if (type.equals(ApplicationConstants.ContainerLaunchType.RELAUNCH)) {\n          linuxContainerRuntime.relaunchContainer(runtimeContext);\n        } else {\n          linuxContainerRuntime.launchContainer(runtimeContext);\n        }\n\n      } else {\n        LOG.info(\n            \"Container was marked as inactive. Returning terminated error\");\n        return ContainerExecutor.ExitCode.TERMINATED.getExitCode();\n      }\n    } catch (ContainerExecutionException e) {\n      return handleExitCode(e, container, containerId);\n    } finally {\n      resourcesHandler.postExecute(containerId);\n\n      try {\n        if (resourceHandlerChain != null) {\n          resourceHandlerChain.postComplete(containerId);\n        }\n      } catch (ResourceHandlerException e) {\n        LOG.warn(\"ResourceHandlerChain.postComplete failed for \" +\n            \"containerId: \" + containerId + \". Exception: \" + e);\n      }\n    }\n\n    return 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.buildContainerRuntimeContext": "  private ContainerRuntimeContext buildContainerRuntimeContext(\n      ContainerStartContext ctx, Path pidFilePath, String resourcesOptions,\n      String tcCommandFile, List<String> numaArgs) {\n\n    List<String> prefixCommands = new ArrayList<>();\n    addSchedPriorityCommand(prefixCommands);\n    addNumaArgsToCommand(prefixCommands, numaArgs);\n\n    Container container = ctx.getContainer();\n\n    ContainerRuntimeContext.Builder builder = new ContainerRuntimeContext\n            .Builder(container);\n    if (prefixCommands.size() > 0) {\n      builder.setExecutionAttribute(CONTAINER_LAUNCH_PREFIX_COMMANDS,\n              prefixCommands);\n    }\n\n    builder.setExecutionAttribute(LOCALIZED_RESOURCES,\n        ctx.getLocalizedResources())\n      .setExecutionAttribute(RUN_AS_USER, getRunAsUser(ctx.getUser()))\n      .setExecutionAttribute(USER, ctx.getUser())\n      .setExecutionAttribute(APPID, ctx.getAppId())\n      .setExecutionAttribute(CONTAINER_ID_STR,\n        container.getContainerId().toString())\n      .setExecutionAttribute(CONTAINER_WORK_DIR, ctx.getContainerWorkDir())\n      .setExecutionAttribute(NM_PRIVATE_CONTAINER_SCRIPT_PATH,\n        ctx.getNmPrivateContainerScriptPath())\n      .setExecutionAttribute(NM_PRIVATE_TOKENS_PATH,\n        ctx.getNmPrivateTokensPath())\n      .setExecutionAttribute(PID_FILE_PATH, pidFilePath)\n      .setExecutionAttribute(LOCAL_DIRS, ctx.getLocalDirs())\n      .setExecutionAttribute(LOG_DIRS, ctx.getLogDirs())\n      .setExecutionAttribute(FILECACHE_DIRS, ctx.getFilecacheDirs())\n      .setExecutionAttribute(USER_LOCAL_DIRS, ctx.getUserLocalDirs())\n      .setExecutionAttribute(CONTAINER_LOCAL_DIRS, ctx.getContainerLocalDirs())\n      .setExecutionAttribute(USER_FILECACHE_DIRS, ctx.getUserFilecacheDirs())\n      .setExecutionAttribute(APPLICATION_LOCAL_DIRS,\n          ctx.getApplicationLocalDirs())\n      .setExecutionAttribute(CONTAINER_LOG_DIRS, ctx.getContainerLogDirs())\n      .setExecutionAttribute(RESOURCES_OPTIONS, resourcesOptions);\n\n    if (tcCommandFile != null) {\n      builder.setExecutionAttribute(TC_COMMAND_FILE, tcCommandFile);\n    }\n\n    return builder.build();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer": "  public int launchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    return handleLaunchForLaunchType(ctx,\n        ApplicationConstants.ContainerLaunchType.LAUNCH);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.relaunchContainer": "  public int relaunchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    return handleLaunchForLaunchType(ctx,\n        ApplicationConstants.ContainerLaunchType.RELAUNCH);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleExitCode": "  private int handleExitCode(ContainerExecutionException e, Container container,\n      ContainerId containerId) throws ConfigurationException {\n    int exitCode = e.getExitCode();\n    LOG.warn(\"Exit code from container \" + containerId + \" is : \" + exitCode);\n    // 143 (SIGTERM) and 137 (SIGKILL) exit codes means the container was\n    // terminated/killed forcefully. In all other cases, log the\n    // output\n    if (exitCode != ContainerExecutor.ExitCode.FORCE_KILLED.getExitCode()\n        && exitCode != ContainerExecutor.ExitCode.TERMINATED.getExitCode()) {\n      LOG.warn(\"Exception from container-launch with container ID: \"\n          + containerId + \" and exit code: \" + exitCode, e);\n\n      StringBuilder builder = new StringBuilder();\n      builder.append(\"Exception from container-launch.\\n\");\n      builder.append(\"Container id: \" + containerId + \"\\n\");\n      builder.append(\"Exit code: \" + exitCode + \"\\n\");\n      builder.append(\"Exception message: \" + e.getMessage() + \"\\n\");\n      if (!Optional.fromNullable(e.getErrorOutput()).or(\"\").isEmpty()) {\n        builder.append(\"Shell error output: \" + e.getErrorOutput() + \"\\n\");\n      }\n      //Skip stack trace\n      String output = e.getOutput();\n      if (output != null && !output.isEmpty()) {\n        builder.append(\"Shell output: \" + output + \"\\n\");\n      }\n      String diagnostics = builder.toString();\n      logOutput(diagnostics);\n      container.handle(new ContainerDiagnosticsUpdateEvent(containerId,\n          diagnostics));\n      if (exitCode ==\n          ExitCode.INVALID_CONTAINER_EXEC_PERMISSIONS.getExitCode() ||\n          exitCode ==\n              ExitCode.INVALID_CONFIG_FILE.getExitCode() ||\n          exitCode ==\n              ExitCode.COULD_NOT_CREATE_SCRIPT_COPY.getExitCode() ||\n          exitCode ==\n              ExitCode.COULD_NOT_CREATE_CREDENTIALS_FILE.getExitCode() ||\n          exitCode ==\n              ExitCode.COULD_NOT_CREATE_WORK_DIRECTORIES.getExitCode() ||\n          exitCode ==\n              ExitCode.COULD_NOT_CREATE_APP_LOG_DIRECTORIES.getExitCode() ||\n          exitCode ==\n              ExitCode.COULD_NOT_CREATE_TMP_DIRECTORIES.getExitCode()) {\n        throw new ConfigurationException(\n            \"Linux Container Executor reached unrecoverable exception\", e);\n      }\n    } else {\n      container.handle(new ContainerDiagnosticsUpdateEvent(containerId,\n          \"Container killed on request. Exit code is \" + exitCode));\n    }\n    return exitCode;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.verifyUsernamePattern": "  void verifyUsernamePattern(String user) {\n    if (!UserGroupInformation.isSecurityEnabled() &&\n        !nonsecureLocalUserPattern.matcher(user).matches()) {\n      throw new IllegalArgumentException(\"Invalid user name '\" + user + \"',\" +\n          \" it must match '\" + nonsecureLocalUserPattern.pattern() + \"'\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer": "  protected int launchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    int launchPrep = prepareForLaunch(ctx);\n    if (launchPrep == 0) {\n      return exec.launchContainer(ctx);\n    }\n    return launchPrep;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.prepareForLaunch": "  protected int prepareForLaunch(ContainerStartContext ctx) throws IOException {\n    ContainerId containerId = container.getContainerId();\n    if (container.isMarkedForKilling()) {\n      LOG.info(\"Container \" + containerId + \" not launched as it has already \"\n          + \"been marked for Killing\");\n      this.killedBeforeStart = true;\n      return ExitCode.TERMINATED.getExitCode();\n    }\n    // LaunchContainer is a blocking call. We are here almost means the\n    // container is launched, so send out the event.\n    dispatcher.getEventHandler().handle(new ContainerEvent(\n        containerId,\n        ContainerEventType.CONTAINER_LAUNCHED));\n    context.getNMStateStore().storeContainerLaunched(containerId);\n\n    // Check if the container is signalled to be killed.\n    if (!containerAlreadyLaunched.compareAndSet(false, true)) {\n      LOG.info(\"Container \" + containerId + \" not launched as \"\n          + \"cleanup already called\");\n      return ExitCode.TERMINATED.getExitCode();\n    } else {\n      exec.activateContainer(containerId, pidFilePath);\n    }\n    return ExitCode.SUCCESS.getExitCode();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call": "  public Integer call() {\n    if (!validateContainerState()) {\n      return 0;\n    }\n\n    final ContainerLaunchContext launchContext = container.getLaunchContext();\n    ContainerId containerID = container.getContainerId();\n    String containerIdStr = containerID.toString();\n    final List<String> command = launchContext.getCommands();\n    int ret = -1;\n\n    Path containerLogDir;\n    try {\n      Map<Path, List<String>> localResources = getLocalizedResources();\n\n      final String user = container.getUser();\n      // /////////////////////////// Variable expansion\n      // Before the container script gets written out.\n      List<String> newCmds = new ArrayList<String>(command.size());\n      String appIdStr = app.getAppId().toString();\n      String relativeContainerLogDir = ContainerLaunch\n          .getRelativeContainerLogDir(appIdStr, containerIdStr);\n      containerLogDir =\n          dirsHandler.getLogPathForWrite(relativeContainerLogDir, false);\n      recordContainerLogDir(containerID, containerLogDir.toString());\n      for (String str : command) {\n        // TODO: Should we instead work via symlinks without this grammar?\n        newCmds.add(expandEnvironment(str, containerLogDir));\n      }\n      launchContext.setCommands(newCmds);\n\n      Map<String, String> environment = expandAllEnvironmentVars(\n          launchContext, containerLogDir);\n      // /////////////////////////// End of variable expansion\n\n      // Use this to track variables that are added to the environment by nm.\n      LinkedHashSet<String> nmEnvVars = new LinkedHashSet<String>();\n\n      FileContext lfs = FileContext.getLocalFSFileContext();\n\n      Path nmPrivateContainerScriptPath = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n              + CONTAINER_SCRIPT);\n      Path nmPrivateTokensPath = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n              + String.format(ContainerLocalizer.TOKEN_FILE_NAME_FMT,\n              containerIdStr));\n      Path nmPrivateClasspathJarDir = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr));\n\n      // Select the working directory for the container\n      Path containerWorkDir = deriveContainerWorkDir();\n      recordContainerWorkDir(containerID, containerWorkDir.toString());\n\n      String pidFileSubpath = getPidFileSubpath(appIdStr, containerIdStr);\n      // pid file should be in nm private dir so that it is not\n      // accessible by users\n      pidFilePath = dirsHandler.getLocalPathForWrite(pidFileSubpath);\n      List<String> localDirs = dirsHandler.getLocalDirs();\n      List<String> logDirs = dirsHandler.getLogDirs();\n      List<String> filecacheDirs = getNMFilecacheDirs(localDirs);\n      List<String> userLocalDirs = getUserLocalDirs(localDirs);\n      List<String> containerLocalDirs = getContainerLocalDirs(localDirs);\n      List<String> containerLogDirs = getContainerLogDirs(logDirs);\n      List<String> userFilecacheDirs = getUserFilecacheDirs(localDirs);\n      List<String> applicationLocalDirs = getApplicationLocalDirs(localDirs,\n          appIdStr);\n\n      if (!dirsHandler.areDisksHealthy()) {\n        ret = ContainerExitStatus.DISKS_FAILED;\n        throw new IOException(\"Most of the disks failed. \"\n            + dirsHandler.getDisksHealthReport(false));\n      }\n      List<Path> appDirs = new ArrayList<Path>(localDirs.size());\n      for (String localDir : localDirs) {\n        Path usersdir = new Path(localDir, ContainerLocalizer.USERCACHE);\n        Path userdir = new Path(usersdir, user);\n        Path appsdir = new Path(userdir, ContainerLocalizer.APPCACHE);\n        appDirs.add(new Path(appsdir, appIdStr));\n      }\n\n      // Set the token location too.\n      addToEnvMap(environment, nmEnvVars,\n          ApplicationConstants.CONTAINER_TOKEN_FILE_ENV_NAME,\n          new Path(containerWorkDir,\n              FINAL_CONTAINER_TOKENS_FILE).toUri().getPath());\n\n      // /////////// Write out the container-script in the nmPrivate space.\n      try (DataOutputStream containerScriptOutStream =\n               lfs.create(nmPrivateContainerScriptPath,\n                   EnumSet.of(CREATE, OVERWRITE))) {\n        // Sanitize the container's environment\n        sanitizeEnv(environment, containerWorkDir, appDirs, userLocalDirs,\n            containerLogDirs, localResources, nmPrivateClasspathJarDir,\n            nmEnvVars);\n\n        prepareContainer(localResources, containerLocalDirs);\n\n        // Write out the environment\n        exec.writeLaunchEnv(containerScriptOutStream, environment,\n            localResources, launchContext.getCommands(),\n            containerLogDir, user, nmEnvVars);\n      }\n      // /////////// End of writing out container-script\n\n      // /////////// Write out the container-tokens in the nmPrivate space.\n      try (DataOutputStream tokensOutStream =\n               lfs.create(nmPrivateTokensPath, EnumSet.of(CREATE, OVERWRITE))) {\n        Credentials creds = container.getCredentials();\n        creds.writeTokenStorageToStream(tokensOutStream);\n      }\n      // /////////// End of writing out container-tokens\n\n      ret = launchContainer(new ContainerStartContext.Builder()\n          .setContainer(container)\n          .setLocalizedResources(localResources)\n          .setNmPrivateContainerScriptPath(nmPrivateContainerScriptPath)\n          .setNmPrivateTokensPath(nmPrivateTokensPath)\n          .setUser(user)\n          .setAppId(appIdStr)\n          .setContainerWorkDir(containerWorkDir)\n          .setLocalDirs(localDirs)\n          .setLogDirs(logDirs)\n          .setFilecacheDirs(filecacheDirs)\n          .setUserLocalDirs(userLocalDirs)\n          .setContainerLocalDirs(containerLocalDirs)\n          .setContainerLogDirs(containerLogDirs)\n          .setUserFilecacheDirs(userFilecacheDirs)\n          .setApplicationLocalDirs(applicationLocalDirs).build());\n    } catch (ConfigurationException e) {\n      LOG.error(\"Failed to launch container due to configuration error.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerID, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      // Mark the node as unhealthy\n      context.getNodeStatusUpdater().reportException(e);\n      return ret;\n    } catch (Throwable e) {\n      LOG.warn(\"Failed to launch container.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerID, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      return ret;\n    } finally {\n      setContainerCompletedStatus(ret);\n    }\n\n    handleContainerExitCode(ret, containerLogDir);\n    return ret;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerPrivateDir": "  protected String getContainerPrivateDir(String appIdStr,\n      String containerIdStr) {\n    return getAppPrivateDir(appIdStr) + Path.SEPARATOR + containerIdStr\n        + Path.SEPARATOR;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getPidFileSubpath": "  protected String getPidFileSubpath(String appIdStr, String containerIdStr) {\n    return getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n        + String.format(ContainerLaunch.PID_FILE_NAME_FMT, containerIdStr);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerLogDirs": "  protected List<String> getContainerLogDirs(List<String> logDirs) {\n    List<String> containerLogDirs = new ArrayList<>(logDirs.size());\n    String appIdStr = app.getAppId().toString();\n    String containerIdStr = container.getContainerId().toString();\n    String relativeContainerLogDir = ContainerLaunch\n        .getRelativeContainerLogDir(appIdStr, containerIdStr);\n\n    for (String logDir : logDirs) {\n      containerLogDirs.add(logDir + Path.SEPARATOR + relativeContainerLogDir);\n    }\n\n    return containerLogDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.prepareContainer": "  private void prepareContainer(Map<Path, List<String>> localResources,\n      List<String> containerLocalDirs) throws IOException {\n\n    exec.prepareContainer(new ContainerPrepareContext.Builder()\n        .setContainer(container)\n        .setLocalizedResources(localResources)\n        .setUser(container.getUser())\n        .setContainerLocalDirs(containerLocalDirs)\n        .setCommands(container.getLaunchContext().getCommands())\n        .build());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.setContainerCompletedStatus": "  protected void setContainerCompletedStatus(int exitCode) {\n    ContainerId containerId = container.getContainerId();\n    completed.set(true);\n    exec.deactivateContainer(containerId);\n    try {\n      if (!container.shouldRetry(exitCode)) {\n        context.getNMStateStore().storeContainerCompleted(containerId,\n            exitCode);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Unable to set exit code for container \" + containerId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.deriveContainerWorkDir": "  private Path deriveContainerWorkDir() throws IOException {\n\n    final String containerWorkDirPath =\n        ContainerLocalizer.USERCACHE +\n        Path.SEPARATOR +\n        container.getUser() +\n        Path.SEPARATOR +\n        ContainerLocalizer.APPCACHE +\n        Path.SEPARATOR +\n        app.getAppId().toString() +\n        Path.SEPARATOR +\n        container.getContainerId().toString();\n\n    final Path containerWorkDir =\n        dirsHandler.getLocalPathForWrite(\n          containerWorkDirPath,\n          LocalDirAllocator.SIZE_UNKNOWN, false);\n\n    return containerWorkDir;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.toString": "    public String toString() {\n      return sb.toString();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getLocalizedResources": "  protected Map<Path, List<String>> getLocalizedResources()\n      throws YarnException {\n    Map<Path, List<String>> localResources = container.getLocalizedResources();\n    if (localResources == null) {\n      throw RPCUtil.getRemoteException(\n          \"Unable to get local resources when Container \" + container\n              + \" is at \" + container.getContainerState());\n    }\n    return localResources;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.addToEnvMap": "  private static void addToEnvMap(\n      Map<String, String> envMap, Set<String> envSet,\n      String envName, String envValue) {\n    envMap.put(envName, envValue);\n    envSet.add(envName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.recordContainerLogDir": "  private void recordContainerLogDir(ContainerId containerId,\n      String logDir) throws IOException{\n    container.setLogDir(logDir);\n    if (container.isRetryContextSet()) {\n      context.getNMStateStore().storeContainerLogDir(containerId, logDir);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getUserFilecacheDirs": "  protected List<String> getUserFilecacheDirs(List<String> localDirs) {\n    List<String> userFilecacheDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n    for (String localDir : localDirs) {\n      String userFilecacheDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.USERCACHE + Path.SEPARATOR + user\n          + Path.SEPARATOR + ContainerLocalizer.FILECACHE;\n      userFilecacheDirs.add(userFilecacheDir);\n    }\n    return userFilecacheDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.expandEnvironment": "  public static String expandEnvironment(String var,\n      Path containerLogDir) {\n    var = var.replace(ApplicationConstants.LOG_DIR_EXPANSION_VAR,\n      containerLogDir.toString());\n    var = var.replace(ApplicationConstants.CLASS_PATH_SEPARATOR,\n      File.pathSeparator);\n\n    // replace parameter expansion marker. e.g. {{VAR}} on Windows is replaced\n    // as %VAR% and on Linux replaced as \"$VAR\"\n    if (Shell.WINDOWS) {\n      var = var.replaceAll(\"(\\\\{\\\\{)|(\\\\}\\\\})\", \"%\");\n    } else {\n      var = var.replace(ApplicationConstants.PARAMETER_EXPANSION_LEFT, \"$\");\n      var = var.replace(ApplicationConstants.PARAMETER_EXPANSION_RIGHT, \"\");\n    }\n    return var;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.expandAllEnvironmentVars": "  private Map<String, String> expandAllEnvironmentVars(\n      ContainerLaunchContext launchContext, Path containerLogDir) {\n    Map<String, String> environment = launchContext.getEnvironment();\n    for (Entry<String, String> entry : environment.entrySet()) {\n      String value = entry.getValue();\n      value = expandEnvironment(value, containerLogDir);\n      entry.setValue(value);\n    }\n    return environment;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getApplicationLocalDirs": "  protected List<String> getApplicationLocalDirs(List<String> localDirs,\n      String appIdStr) {\n    List<String> applicationLocalDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n    for (String localDir : localDirs) {\n      String appLocalDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.USERCACHE + Path.SEPARATOR + user\n          + Path.SEPARATOR + ContainerLocalizer.APPCACHE\n          + Path.SEPARATOR + appIdStr;\n      applicationLocalDirs.add(appLocalDir);\n    }\n    return applicationLocalDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getNMFilecacheDirs": "  protected List<String> getNMFilecacheDirs(List<String> localDirs) {\n    List<String> filecacheDirs = new ArrayList<>(localDirs.size());\n\n    for (String localDir : localDirs) {\n      String filecacheDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.FILECACHE;\n\n      filecacheDirs.add(filecacheDir);\n    }\n\n    return filecacheDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.sanitizeEnv": "  public void sanitizeEnv(Map<String, String> environment, Path pwd,\n      List<Path> appDirs, List<String> userLocalDirs, List<String>\n      containerLogDirs, Map<Path, List<String>> resources,\n      Path nmPrivateClasspathJarDir,\n      Set<String> nmVars) throws IOException {\n    // Based on discussion in YARN-7654, for ENTRY_POINT enabled\n    // docker container, we forward user defined environment variables\n    // without node manager environment variables.  This is the reason\n    // that we skip sanitizeEnv method.\n    boolean overrideDisable = Boolean.parseBoolean(\n        environment.get(\n            Environment.\n                YARN_CONTAINER_RUNTIME_DOCKER_RUN_OVERRIDE_DISABLE.\n                    name()));\n    if (overrideDisable) {\n      environment.remove(\"WORK_DIR\");\n      return;\n    }\n\n    /**\n     * Non-modifiable environment variables\n     */\n\n    addToEnvMap(environment, nmVars, Environment.CONTAINER_ID.name(),\n        container.getContainerId().toString());\n\n    addToEnvMap(environment, nmVars, Environment.NM_PORT.name(),\n      String.valueOf(this.context.getNodeId().getPort()));\n\n    addToEnvMap(environment, nmVars, Environment.NM_HOST.name(),\n        this.context.getNodeId().getHost());\n\n    addToEnvMap(environment, nmVars, Environment.NM_HTTP_PORT.name(),\n      String.valueOf(this.context.getHttpPort()));\n\n    addToEnvMap(environment, nmVars, Environment.LOCAL_DIRS.name(),\n        StringUtils.join(\",\", appDirs));\n\n    addToEnvMap(environment, nmVars, Environment.LOCAL_USER_DIRS.name(),\n        StringUtils.join(\",\", userLocalDirs));\n\n    addToEnvMap(environment, nmVars, Environment.LOG_DIRS.name(),\n      StringUtils.join(\",\", containerLogDirs));\n\n    addToEnvMap(environment, nmVars, Environment.USER.name(),\n        container.getUser());\n\n    addToEnvMap(environment, nmVars, Environment.LOGNAME.name(),\n        container.getUser());\n\n    addToEnvMap(environment, nmVars, Environment.HOME.name(),\n        conf.get(\n            YarnConfiguration.NM_USER_HOME_DIR, \n            YarnConfiguration.DEFAULT_NM_USER_HOME_DIR\n            )\n        );\n\n    addToEnvMap(environment, nmVars, Environment.PWD.name(), pwd.toString());\n\n    if (!Shell.WINDOWS) {\n      addToEnvMap(environment, nmVars, \"JVM_PID\", \"$$\");\n    }\n\n    // variables here will be forced in, even if the container has\n    // specified them.\n    String defEnvStr = conf.get(YarnConfiguration.DEFAULT_NM_ADMIN_USER_ENV);\n    Apps.setEnvFromInputProperty(environment,\n        YarnConfiguration.NM_ADMIN_USER_ENV, defEnvStr, conf,\n        File.pathSeparator);\n    nmVars.addAll(Apps.getEnvVarsFromInputProperty(\n        YarnConfiguration.NM_ADMIN_USER_ENV, defEnvStr, conf));\n\n    // TODO: Remove Windows check and use this approach on all platforms after\n    // additional testing.  See YARN-358.\n    if (Shell.WINDOWS) {\n\n      sanitizeWindowsEnv(environment, pwd,\n          resources, nmPrivateClasspathJarDir);\n    }\n    // put AuxiliaryService data to environment\n    for (Map.Entry<String, ByteBuffer> meta : containerManager\n        .getAuxServiceMetaData().entrySet()) {\n      AuxiliaryServiceHelper.setServiceDataIntoEnv(\n          meta.getKey(), meta.getValue(), environment);\n      nmVars.add(AuxiliaryServiceHelper.getPrefixServiceName(meta.getKey()));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitCode": "  protected void handleContainerExitCode(int exitCode, Path containerLogDir) {\n    ContainerId containerId = container.getContainerId();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Container \" + containerId + \" completed with exit code \"\n          + exitCode);\n    }\n\n    StringBuilder diagnosticInfo =\n        new StringBuilder(\"Container exited with a non-zero exit code \");\n    diagnosticInfo.append(exitCode);\n    diagnosticInfo.append(\". \");\n    if (exitCode == ExitCode.FORCE_KILLED.getExitCode()\n        || exitCode == ExitCode.TERMINATED.getExitCode()) {\n      // If the process was killed, Send container_cleanedup_after_kill and\n      // just break out of this method.\n\n      // If Container was killed before starting... NO need to do this.\n      if (!killedBeforeStart) {\n        dispatcher.getEventHandler().handle(\n            new ContainerExitEvent(containerId,\n                ContainerEventType.CONTAINER_KILLED_ON_REQUEST, exitCode,\n                diagnosticInfo.toString()));\n      }\n    } else if (exitCode != 0) {\n      handleContainerExitWithFailure(containerId, exitCode, containerLogDir,\n          diagnosticInfo);\n    } else {\n      LOG.info(\"Container \" + containerId + \" succeeded \");\n      dispatcher.getEventHandler().handle(\n          new ContainerEvent(containerId,\n              ContainerEventType.CONTAINER_EXITED_WITH_SUCCESS));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.validateContainerState": "  protected boolean validateContainerState() {\n    // CONTAINER_KILLED_ON_REQUEST should not be missed if the container\n    // is already at KILLING\n    if (container.getContainerState() == ContainerState.KILLING) {\n      dispatcher.getEventHandler().handle(\n          new ContainerExitEvent(container.getContainerId(),\n              ContainerEventType.CONTAINER_KILLED_ON_REQUEST,\n              Shell.WINDOWS ? ExitCode.FORCE_KILLED.getExitCode() :\n                  ExitCode.TERMINATED.getExitCode(),\n              \"Container terminated before launch.\"));\n      return false;\n    }\n\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.create": "    public static ShellScriptBuilder create(Shell.OSType osType) {\n      return (osType == Shell.OSType.OS_TYPE_WIN) ?\n          new WindowsShellScriptBuilder() :\n          new UnixShellScriptBuilder();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerLocalDirs": "  protected List<String> getContainerLocalDirs(List<String> localDirs) {\n    List<String> containerLocalDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n    String appIdStr = app.getAppId().toString();\n    String relativeContainerLocalDir = ContainerLocalizer.USERCACHE\n        + Path.SEPARATOR + user + Path.SEPARATOR + ContainerLocalizer.APPCACHE\n        + Path.SEPARATOR + appIdStr + Path.SEPARATOR;\n\n    for (String localDir : localDirs) {\n      containerLocalDirs.add(localDir + Path.SEPARATOR\n          + relativeContainerLocalDir);\n    }\n\n    return containerLocalDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.recordContainerWorkDir": "  private void recordContainerWorkDir(ContainerId containerId,\n      String workDir) throws IOException{\n    container.setWorkDir(workDir);\n    if (container.isRetryContextSet()) {\n      context.getNMStateStore().storeContainerWorkDir(containerId, workDir);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getRelativeContainerLogDir": "  public static String getRelativeContainerLogDir(String appIdStr,\n      String containerIdStr) {\n    return appIdStr + Path.SEPARATOR + containerIdStr;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getUserLocalDirs": "  protected List<String> getUserLocalDirs(List<String> localDirs) {\n    List<String> userLocalDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n\n    for (String localDir : localDirs) {\n      String userLocalDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.USERCACHE + Path.SEPARATOR + user\n          + Path.SEPARATOR;\n\n      userLocalDirs.add(userLocalDir);\n    }\n\n    return userLocalDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.getDeniedGPUs": "    public Set<GpuDevice> getDeniedGPUs() {\n      return denied;\n    }"
        },
        "bug_report": {
            "Title": "On NodeManager container gets cleaned up before its pid file is created",
            "Description": "GPU failed to release even though the container using it is being killed\r\n{Code}\r\n2018-07-06 05:22:26,201 INFO  container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_e20_1530854311763_0006_01_000001 transitioned from RUNNING to KILLING\r\n2018-07-06 05:22:26,250 INFO  container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_e20_1530854311763_0006_01_000002 transitioned from RUNNING to KILLING\r\n2018-07-06 05:22:26,251 INFO  application.ApplicationImpl (ApplicationImpl.java:handle(632)) - Application application_1530854311763_0006 transitioned from RUNNING to FINISHING_CONTAINERS_WAIT\r\n2018-07-06 05:22:26,251 INFO  launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(734)) - Cleaning up container container_e20_1530854311763_0006_01_000002\r\n2018-07-06 05:22:31,358 INFO  launcher.ContainerLaunch (ContainerLaunch.java:getContainerPid(1102)) - Could not get pid for container_e20_1530854311763_0006_01_000002. Waited for 5000 ms.\r\n2018-07-06 05:22:31,358 WARN  launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(784)) - Container clean up before pid file created container_e20_1530854311763_0006_01_000002\r\n2018-07-06 05:22:31,359 INFO  launcher.ContainerLaunch (ContainerLaunch.java:reapDockerContainerNoPid(940)) - Unable to obtain pid, but docker container request detected. Attempting to reap container container_e20_1530854311763_0006_01_000002\r\n2018-07-06 05:22:31,494 INFO  nodemanager.LinuxContainerExecutor (LinuxContainerExecutor.java:deleteAsUser(828)) - Deleting absolute path : /grid/0/hadoop/yarn/local/usercache/hrt_qa/appcache/application_1530854311763_0006/container_e20_1530854311763_0006_01_000002/launch_container.sh\r\n2018-07-06 05:22:31,500 INFO  nodemanager.LinuxContainerExecutor (LinuxContainerExecutor.java:deleteAsUser(828)) - Deleting absolute path : /grid/0/hadoop/yarn/local/usercache/hrt_qa/appcache/application_1530854311763_0006/container_e20_1530854311763_0006_01_000002/container_tokens\r\n2018-07-06 05:22:31,510 INFO  container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_e20_1530854311763_0006_01_000001 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\r\n2018-07-06 05:22:31,510 INFO  container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_e20_1530854311763_0006_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\r\n2018-07-06 05:22:31,512 INFO  container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_e20_1530854311763_0006_01_000001 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\r\n2018-07-06 05:22:31,513 INFO  container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_e20_1530854311763_0006_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\r\n2018-07-06 05:22:38,955 INFO  container.ContainerImpl (ContainerImpl.java:handle(2093)) - Container container_e20_1530854311763_0007_01_000002 transitioned from NEW to SCHEDULED\r\n\r\n{Code}\r\n\r\nNew container requesting for GPU fails to launch\r\n{code}\r\n2018-07-06 05:22:39,048 ERROR nodemanager.LinuxContainerExecutor (LinuxContainerExecutor.java:handleLaunchForLaunchType(550)) - ResourceHandlerChain.preStart() failed!\r\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerException: Failed to find enough GPUs, requestor=container_e20_1530854311763_0007_01_000002, #RequestedGPUs=2, #availableGpus=1\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.internalAssignGpus(GpuResourceAllocator.java:225)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.assignGpus(GpuResourceAllocator.java:173)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceHandlerImpl.preStart(GpuResourceHandlerImpl.java:98)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.preStart(ResourceHandlerChain.java:75)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:509)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:479)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:494)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:306)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:103)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n2018-07-06 05:22:39,049 WARN  launcher.ContainerLaunch (ContainerLaunch.java:call(331)) - Failed to launch container.\r\njava.io.IOException: ResourceHandlerChain.preStart() failed!\r\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:551)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:479)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:494)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:306)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:103)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerException: Failed to find enough GPUs, requestor=container_e20_1530854311763_0007_01_000002, #RequestedGPUs=2, #availableGpus=1\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.internalAssignGpus(GpuResourceAllocator.java:225)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.assignGpus(GpuResourceAllocator.java:173)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceHandlerImpl.preStart(GpuResourceHandlerImpl.java:98)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.preStart(ResourceHandlerChain.java:75)\r\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:509)\r\n\t... 8 more\r\n{code}\r\n"
        }
    },
    {
        "filename": "YARN-2308.json",
        "creation_time": "2014-07-17T10:01:57.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:566)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:922)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:594)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:654)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:85)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:698)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:682)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    CSQueue queue = (CSQueue) application.getQueue();\n\n    FiCaSchedulerApp attempt =\n        new FiCaSchedulerApp(applicationAttemptId, application.getUser(),\n          queue, queue.getActiveUsersManager(), rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n        .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    queue.submitApplicationAttempt(attempt, application.getUser());\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user \" + application.getUser() + \" in queue \"\n        + queue.getQueueName());\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  synchronized CSQueue getQueue(String queueName) {\n    return queues.get(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      RMNode node = nodeUpdatedEvent.getRMNode();\n      nodeUpdate(node);\n      if (!scheduleAsynchronously) {\n        allocateContainersToNode(getNode(node.getNodeID()));\n      }\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      addApplication(appAddedEvent.getApplicationId(),\n        appAddedEvent.getQueue(), appAddedEvent.getUser(),\n        appAddedEvent.getIsAppRecovering());\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent = \n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId), \n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId, \n              SchedulerUtils.EXPIRED_CONTAINER), \n          RMContainerEventType.EXPIRE);\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        startActiveServices();\n        return null;\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle": "  public void handle(RMAppEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId appID = event.getApplicationId();\n      LOG.debug(\"Processing event for \" + appID + \" of type \"\n          + event.getType());\n      final RMAppState oldState = getState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getState()) {\n        LOG.info(appID + \" State change from \" + oldState + \" to \"\n            + getState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getState": "  public RMAppState getState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          drained = eventQueue.isEmpty();\n          // blockNewEvents is only set when dispatcher is draining to stop,\n          // adding this check is to avoid the overhead of acquiring the lock\n          // and calling notify every time in the normal run of the loop.\n          if (blockNewEvents) {\n            synchronized (waitForDrained) {\n              if (drained) {\n                waitForDrained.notify();\n              }\n            }\n          }\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n  \n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Get the current used capacity of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n  \n  /**\n   * Set used capacity of the queue.\n   * @param usedCapacity used capacity of the queue\n   */\n  public void setUsedCapacity(float usedCapacity);\n  \n  /**\n   * Set absolute used capacity of the queue.\n   * @param absUsedCapacity absolute used capacity of the queue\n   */\n  public void setAbsoluteUsedCapacity(float absUsedCapacity);\n\n  /**\n   * Get the currently utilized resources in the cluster \n   * by the queue and children (if any).\n   * @return used resources by the queue and it's children \n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getActiveUsersManager": "  public ActiveUsersManager getActiveUsersManager();\n  \n  /**\n   * Adds all applications in the queue and its subqueues to the given collection.\n   * @param apps the collection to add the applications to\n   */\n  public void collectSchedulerApplications(Collection<ApplicationAttemptId> apps);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.submitApplicationAttempt": "  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @return the assignment\n   */\n  public CSAssignment assignContainers(\n      Resource clusterResource, FiCaSchedulerNode node);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   */\n  public void updateClusterResource(Resource clusterResource);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "NPE happened when RM restart after CapacityScheduler queue configuration changed ",
            "Description": "I encountered a NPE when RM restart\n{code}\n2014-07-16 07:22:46,957 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type APP_ATTEMPT_ADDED to the scheduler\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:566)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:922)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:594)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:654)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:85)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:698)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:682)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n{code}\nAnd RM will be failed to restart.\n\nThis is caused by queue configuration changed, I removed some queues and added new queues. So when RM restarts, it tries to recover history applications, and when any of queues of these applications removed, NPE will be raised."
        }
    },
    {
        "filename": "YARN-933.json",
        "creation_time": "2013-07-17T12:29:28.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: LAUNCH_FAILED at FAILED\n at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)\n at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:630)\n at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:99)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:495)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:476)\n at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)\n at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)\n at java.lang.Thread.run(Thread.java:662)\n\nCaused by: org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=host-10-18-40-15/10.18.40.59:8020]\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:573)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getAppAttemptState()) {\n        LOG.info(appAttemptID + \" State change from \" + oldState + \" to \"\n            + getAppAttemptState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n      return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.connect": "  public static void connect(Socket socket, \n                             SocketAddress endpoint,\n                             SocketAddress localAddr,\n                             int timeout) throws IOException {\n    if (socket == null || endpoint == null || timeout < 0) {\n      throw new IllegalArgumentException(\"Illegal argument for connect()\");\n    }\n    \n    SocketChannel ch = socket.getChannel();\n    \n    if (localAddr != null) {\n      Class localClass = localAddr.getClass();\n      Class remoteClass = endpoint.getClass();\n      Preconditions.checkArgument(localClass.equals(remoteClass),\n          \"Local address %s must be of same family as remote address %s.\",\n          localAddr, endpoint);\n      socket.bind(localAddr);\n    }\n\n    try {\n      if (ch == null) {\n        // let the default implementation handle it.\n        socket.connect(endpoint, timeout);\n      } else {\n        SocketIOWithTimeout.connect(ch, endpoint, timeout);\n      }\n    } catch (SocketTimeoutException ste) {\n      throw new ConnectTimeoutException(ste.getMessage());\n    }\n\n    // There is a very rare case allowed by the TCP specification, such that\n    // if we are trying to connect to an endpoint on the local machine,\n    // and we end up choosing an ephemeral port equal to the destination port,\n    // we will actually end up getting connected to ourself (ie any data we\n    // send just comes right back). This is only possible if the target\n    // daemon is down, so we'll treat it like connection refused.\n    if (socket.getLocalPort() == socket.getPort() &&\n        socket.getLocalAddress().equals(socket.getInetAddress())) {\n      LOG.info(\"Detected a loopback TCP socket, disconnecting it\");\n      socket.close();\n      throw new ConnectException(\n        \"Localhost targeted connection resulted in a loopback. \" +\n        \"No daemon is listening on the target port.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Potential InvalidStateTransitonException: Invalid event: LAUNCHED at FINAL_SAVING",
            "Description": "am max retries configured as 3 at client and RM side.\n\nStep 1: Install cluster with NM on 2 Machines \nStep 2: Make Ping using ip from RM machine to NM1 machine as successful ,But using Hostname should fail\nStep 3: Execute a job\nStep 4: After AM [ AppAttempt_1 ] allocation to NM1 machine is done , connection loss happened.\n\nObservation :\n==========\nAfter AppAttempt_1 has moved to failed state ,release of container for AppAttempt_1 and Application removal are successful. New AppAttempt_2 is sponed.\n\n1. Then again retry for AppAttempt_1 happens.\n2. Again RM side it is trying to launch AppAttempt_1, hence fails with InvalidStateTransitonException\n3. Client got exited after AppAttempt_1 is been finished [But actually job is still running ], while the appattempts configured is 3 and rest appattempts are all sponed and running.\n\n\nRMLogs:\n======\n2013-07-17 16:22:51,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1373952096466_0056_000001 State change from SCHEDULED to ALLOCATED\n2013-07-17 16:35:48,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-10-18-40-15/10.18.40.59:8048. Already tried 36 time(s); maxRetries=45\n2013-07-17 16:36:07,091 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: Expired:container_1373952096466_0056_01_000001 Timed out after 600 secs\n2013-07-17 16:36:07,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1373952096466_0056_01_000001 Container Transitioned from ACQUIRED to EXPIRED\n\n2013-07-17 16:36:07,093 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering appattempt_1373952096466_0056_000002\n\n2013-07-17 16:36:07,131 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application appattempt_1373952096466_0056_000001 is done. finalState=FAILED\n2013-07-17 16:36:07,131 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1373952096466_0056 user: Rex leaf-queue of parent: root #applications: 35\n\n2013-07-17 16:36:07,132 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Submission: appattempt_1373952096466_0056_000002, \n2013-07-17 16:36:07,138 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1373952096466_0056_000002 State change from SUBMITTED to SCHEDULED\n\n2013-07-17 16:36:30,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-10-18-40-15/10.18.40.59:8048. Already tried 38 time(s); maxRetries=45\n2013-07-17 16:38:36,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-10-18-40-15/10.18.40.59:8048. Already tried 44 time(s); maxRetries=45\n2013-07-17 16:38:56,207 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1373952096466_0056_000001. Got exception: java.lang.reflect.UndeclaredThrowableException\n2013-07-17 16:38:56,207 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: LAUNCH_FAILED at FAILED\n at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)\n at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:630)\n at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:99)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:495)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:476)\n at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)\n at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)\n at java.lang.Thread.run(Thread.java:662)\n\nClient Logs\n========\nCaused by: org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=host-10-18-40-15/10.18.40.59:8020]\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:573)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)\n2013-07-17 16:37:05,987 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:Rex (auth:SIMPLE) cause:org.apache.hadoop.net.ConnectTimeoutException: Call From HOST-10-18-91-55/10.18.40.57 to host-10-18-40-15:8020 failed on socket timeout exception: org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=host-10-18-40-15/10.18.40.59:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout\n\n\n\n"
        }
    },
    {
        "filename": "YARN-1374.json",
        "creation_time": "2013-10-30T11:49:49.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n\tat java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:187)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:944)\n\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n\tat java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:187)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:944)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    List<Service> services = getServices();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(getName() + \": initing services, size=\" + services.size());\n    }\n    for (Service service : services) {\n      service.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.CompositeService.getServices": "  public List<Service> getServices() {\n    synchronized (serviceList) {\n      return Collections.unmodifiableList(serviceList);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit": "    protected void serviceInit(Configuration conf) throws Exception {\n      this.shouldExitOnError =\n          conf.getBoolean(Dispatcher.DISPATCHER_EXIT_ON_ERROR_KEY,\n            Dispatcher.DEFAULT_DISPATCHER_EXIT_ON_ERROR);\n      super.serviceInit(conf);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMHAProtocolService": "  protected RMHAProtocolService createRMHAProtocolService() {\n    return new RMHAProtocolService(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createPolicyMonitors": "  protected void createPolicyMonitors() {\n    if (scheduler instanceof PreemptableResourceScheduler\n        && conf.getBoolean(YarnConfiguration.RM_SCHEDULER_ENABLE_MONITORS,\n          YarnConfiguration.DEFAULT_RM_SCHEDULER_ENABLE_MONITORS)) {\n      LOG.info(\"Loading policy monitors\");\n      List<SchedulingEditPolicy> policies = conf.getInstances(\n              YarnConfiguration.RM_SCHEDULER_MONITOR_POLICIES,\n              SchedulingEditPolicy.class);\n      if (policies.size() > 0) {\n        this.rmDispatcher.register(ContainerPreemptEventType.class,\n          new RMContainerPreemptEventDispatcher(\n            (PreemptableResourceScheduler) scheduler));\n        for (SchedulingEditPolicy policy : policies) {\n          LOG.info(\"LOADING SchedulingEditPolicy:\" + policy.getPolicyName());\n          policy.init(conf, this.rmContext.getDispatcher().getEventHandler(),\n              (PreemptableResourceScheduler) scheduler);\n          // periodically check whether we need to take action to guarantee\n          // constraints\n          SchedulingMonitor mon = new SchedulingMonitor(policy);\n          addService(mon);\n\n        }\n      } else {\n        LOG.warn(\"Policy monitors configured (\" +\n            YarnConfiguration.RM_SCHEDULER_ENABLE_MONITORS +\n            \") but none specified (\" +\n            YarnConfiguration.RM_SCHEDULER_MONITOR_POLICIES + \")\");\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAdminService": "  protected AdminService createAdminService(\n      ClientRMService clientRMService, \n      ApplicationMasterService applicationMasterService,\n      ResourceTrackerService resourceTrackerService) {\n    return new AdminService(this.conf, scheduler, rmContext,\n        this.nodesListManager, clientRMService, applicationMasterService,\n        resourceTrackerService);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createClientRMService": "  protected ClientRMService createClientRMService() {\n    return new ClientRMService(this.rmContext, scheduler, this.rmAppManager,\n        this.applicationACLsManager, this.queueACLsManager,\n        this.rmDTSecretManager);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMRMTokenSecretManager": "  protected AMRMTokenSecretManager createAMRMTokenSecretManager(\n      Configuration conf) {\n    return new AMRMTokenSecretManager(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLivelinessMonitor": "  protected AMLivelinessMonitor createAMLivelinessMonitor() {\n    return new AMLivelinessMonitor(this.rmDispatcher);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMDelegationTokenSecretManager": "  protected RMDelegationTokenSecretManager\n               createRMDelegationTokenSecretManager(RMContext rmContext) {\n    long secretKeyInterval = \n        conf.getLong(YarnConfiguration.DELEGATION_KEY_UPDATE_INTERVAL_KEY, \n            YarnConfiguration.DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT);\n    long tokenMaxLifetime =\n        conf.getLong(YarnConfiguration.DELEGATION_TOKEN_MAX_LIFETIME_KEY,\n            YarnConfiguration.DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT);\n    long tokenRenewInterval =\n        conf.getLong(YarnConfiguration.DELEGATION_TOKEN_RENEW_INTERVAL_KEY, \n            YarnConfiguration.DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT);\n\n    return new RMDelegationTokenSecretManager(secretKeyInterval, \n        tokenMaxLifetime, tokenRenewInterval, 3600000, rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createScheduler": "  protected ResourceScheduler createScheduler() {\n    String schedulerClassName = conf.get(YarnConfiguration.RM_SCHEDULER,\n        YarnConfiguration.DEFAULT_RM_SCHEDULER);\n    LOG.info(\"Using Scheduler: \" + schedulerClassName);\n    try {\n      Class<?> schedulerClazz = Class.forName(schedulerClassName);\n      if (ResourceScheduler.class.isAssignableFrom(schedulerClazz)) {\n        return (ResourceScheduler) ReflectionUtils.newInstance(schedulerClazz,\n            this.conf);\n      } else {\n        throw new YarnRuntimeException(\"Class: \" + schedulerClassName\n            + \" not instance of \" + ResourceScheduler.class.getCanonicalName());\n      }\n    } catch (ClassNotFoundException e) {\n      throw new YarnRuntimeException(\"Could not instantiate Scheduler: \"\n          + schedulerClassName, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createSchedulerEventDispatcher": "  protected EventHandler<SchedulerEvent> createSchedulerEventDispatcher() {\n    return new SchedulerEventDispatcher(this.scheduler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createDispatcher": "  protected Dispatcher createDispatcher() {\n    return new AsyncDispatcher();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNMLivelinessMonitor": "  private NMLivelinessMonitor createNMLivelinessMonitor() {\n    return new NMLivelinessMonitor(this.rmContext\n        .getDispatcher());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createApplicationMasterService": "  protected ApplicationMasterService createApplicationMasterService() {\n    return new ApplicationMasterService(this.rmContext, scheduler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createQueueACLsManager": "  protected QueueACLsManager createQueueACLsManager(ResourceScheduler scheduler,\n      Configuration conf) {\n    return new QueueACLsManager(scheduler, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createRMAppManager": "  protected RMAppManager createRMAppManager() {\n    return new RMAppManager(this.rmContext, this.scheduler, this.masterService,\n      this.applicationACLsManager, this.conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createNMTokenSecretManager": "  protected NMTokenSecretManagerInRM createNMTokenSecretManager(\n      Configuration conf) {\n    return new NMTokenSecretManagerInRM(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createContainerTokenSecretManager": "  protected RMContainerTokenSecretManager createContainerTokenSecretManager(\n      Configuration conf) {\n    return new RMContainerTokenSecretManager(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAMLauncher": "  protected ApplicationMasterLauncher createAMLauncher() {\n    return new ApplicationMasterLauncher(this.rmContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createResourceTrackerService": "  protected ResourceTrackerService createResourceTrackerService() {\n    return new ResourceTrackerService(this.rmContext, this.nodesListManager,\n        this.nmLivelinessMonitor, this.containerTokenSecretManager,\n        this.nmTokenSecretManager);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.validateConfigs": "  protected static void validateConfigs(Configuration conf) {\n    // validate max-attempts\n    int globalMaxAppAttempts =\n        conf.getInt(YarnConfiguration.RM_AM_MAX_ATTEMPTS,\n        YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS);\n    if (globalMaxAppAttempts <= 0) {\n      throw new YarnRuntimeException(\"Invalid global max attempts configuration\"\n          + \", \" + YarnConfiguration.RM_AM_MAX_ATTEMPTS\n          + \"=\" + globalMaxAppAttempts + \", it should be a positive integer.\");\n    }\n\n    // validate expireIntvl >= heartbeatIntvl\n    long expireIntvl = conf.getLong(YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_RM_NM_EXPIRY_INTERVAL_MS);\n    long heartbeatIntvl =\n        conf.getLong(YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS,\n            YarnConfiguration.DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS);\n    if (expireIntvl < heartbeatIntvl) {\n      throw new YarnRuntimeException(\"Nodemanager expiry interval should be no\"\n          + \" less than heartbeat interval, \"\n          + YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS + \"=\" + expireIntvl\n          + \", \" + YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS + \"=\"\n          + heartbeatIntvl);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createDelegationTokenRenewer": "  protected DelegationTokenRenewer createDelegationTokenRenewer() {\n    return new DelegationTokenRenewer();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.init": "  public void init(Configuration conf) {\n    if (conf == null) {\n      throw new ServiceStateException(\"Cannot initialize service \"\n                                      + getName() + \": null configuration\");\n    }\n    if (isInState(STATE.INITED)) {\n      return;\n    }\n    synchronized (stateChangeLock) {\n      if (enterState(STATE.INITED) != STATE.INITED) {\n        setConfig(conf);\n        try {\n          serviceInit(config);\n          if (isInState(STATE.INITED)) {\n            //if the service ended up here during init,\n            //notify the listeners\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceInit": "  protected void serviceInit(Configuration conf) throws Exception {\n    if (conf != config) {\n      LOG.debug(\"Config has been overridden during init\");\n      setConfig(conf);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.setConfig": "  protected void setConfig(Configuration conf) {\n    this.config = conf;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main": "  public static void main(String argv[]) {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ResourceManager.class, argv, LOG);\n    try {\n      Configuration conf = new YarnConfiguration();\n      ResourceManager resourceManager = new ResourceManager();\n      ShutdownHookManager.get().addShutdownHook(\n        new CompositeServiceShutdownHook(resourceManager),\n        SHUTDOWN_HOOK_PRIORITY);\n      setHttpPolicy(conf);\n      resourceManager.init(conf);\n      resourceManager.start();\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ResourceManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setHttpPolicy": "  private static void setHttpPolicy(Configuration conf) {\n    HttpConfig.setPolicy(Policy.fromString(conf.get(\n      YarnConfiguration.YARN_HTTP_POLICY_KEY,\n      YarnConfiguration.YARN_HTTP_POLICY_DEFAULT)));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.Service.init": "  void init(Configuration config);\n\n\n  /**\n   * Start the service.\n   *\n   * The transition MUST be from {@link STATE#INITED} to {@link STATE#STARTED}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setClientRMService": "  void setClientRMService(ClientRMService clientRMService);\n  \n  ClientRMService getClientRMService();\n  \n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.setRMDelegationTokenSecretManager": "  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "Resource Manager fails to start due to ConcurrentModificationException",
            "Description": "Resource Manager is failing to start with the below ConcurrentModificationException.\n\n{code:xml}\n2013-10-30 20:22:42,371 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list\n2013-10-30 20:22:42,376 INFO org.apache.hadoop.service.AbstractService: Service ResourceManager failed in state INITED; cause: java.util.ConcurrentModificationException\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n\tat java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:187)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:944)\n2013-10-30 20:22:42,378 INFO org.apache.hadoop.yarn.server.resourcemanager.RMHAProtocolService: Transitioning to standby\n2013-10-30 20:22:42,378 INFO org.apache.hadoop.yarn.server.resourcemanager.RMHAProtocolService: Transitioned to standby\n2013-10-30 20:22:42,378 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error starting ResourceManager\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n\tat java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:187)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:944)\n2013-10-30 20:22:42,379 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down ResourceManager at HOST-10-18-40-24/10.18.40.24\n************************************************************/\n{code}"
        }
    },
    {
        "filename": "YARN-174.json",
        "creation_time": "2012-10-19T17:25:40.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.YarnException: ${yarn.log.dir}/userlogs is not a valid path. Path should be with file scheme or without scheme\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.validatePaths(LocalDirsHandlerService.java:321)\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService$MonitoringTimerTask.<init>(LocalDirsHandlerService.java:95)\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.init(LocalDirsHandlerService.java:123)\n        at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeHealthCheckerService.init(NodeHealthCheckerService.java:48)\n        at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.init(NodeManager.java:165)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:274)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.stateChanged(NodeManager.java:256)\n        at org.apache.hadoop.yarn.service.AbstractService.changeState(AbstractService.java:163)\n        at org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:112)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stop(NodeStatusUpdaterImpl.java:149)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.reboot(NodeStatusUpdaterImpl.java:157)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.access$900(NodeStatusUpdaterImpl.java:63)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl$1.run(NodeStatusUpdaterImpl.java:357)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.validatePaths": "  public static String[] validatePaths(String[] paths) {\n    ArrayList<String> validPaths = new ArrayList<String>();\n    for (int i = 0; i < paths.length; ++i) {\n      try {\n        URI uriPath = new URI(paths[i]);\n        if (uriPath.getScheme() == null\n            || uriPath.getScheme().equals(FILE_SCHEME)) {\n          validPaths.add(uriPath.getPath());\n        } else {\n          LOG.warn(paths[i] + \" is not a valid path. Path should be with \"\n              + FILE_SCHEME + \" scheme or without scheme\");\n          throw new YarnException(paths[i]\n              + \" is not a valid path. Path should be with \" + FILE_SCHEME\n              + \" scheme or without scheme\");\n        }\n      } catch (URISyntaxException e) {\n        LOG.warn(e.getMessage());\n        throw new YarnException(paths[i]\n            + \" is not a valid path. Path should be with \" + FILE_SCHEME\n            + \" scheme or without scheme\");\n      }\n    }\n    String[] arrValidPaths = new String[validPaths.size()];\n    validPaths.toArray(arrValidPaths);\n    return arrValidPaths;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.init": "  public void init(Configuration config) {\n    // Clone the configuration as we may do modifications to dirs-list\n    Configuration conf = new Configuration(config);\n    diskHealthCheckInterval = conf.getLong(\n        YarnConfiguration.NM_DISK_HEALTH_CHECK_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_NM_DISK_HEALTH_CHECK_INTERVAL_MS);\n    monitoringTimerTask = new MonitoringTimerTask(conf);\n    isDiskHealthCheckerEnabled = conf.getBoolean(\n        YarnConfiguration.NM_DISK_HEALTH_CHECK_ENABLE, true);\n    minNeededHealthyDisksFactor = conf.getFloat(\n        YarnConfiguration.NM_MIN_HEALTHY_DISKS_FRACTION,\n        YarnConfiguration.DEFAULT_NM_MIN_HEALTHY_DISKS_FRACTION);\n    lastDisksCheckTime = System.currentTimeMillis();\n    super.init(conf);\n\n    FileContext localFs;\n    try {\n      localFs = FileContext.getLocalFSFileContext(config);\n    } catch (IOException e) {\n      throw new YarnException(\"Unable to get the local filesystem\", e);\n    }\n    FsPermission perm = new FsPermission((short)0755);\n    boolean createSucceeded = localDirs.createNonExistentDirs(localFs, perm);\n    createSucceeded &= logDirs.createNonExistentDirs(localFs, perm);\n    if (!createSucceeded) {\n      updateDirsAfterFailure();\n    }\n\n    // Check the disk health immediately to weed out bad directories\n    // before other init code attempts to use them.\n    checkDirs();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.updateDirsAfterFailure": "  private void updateDirsAfterFailure() {\n    LOG.info(\"Disk(s) failed. \" + getDisksHealthReport());\n    Configuration conf = getConfig();\n    List<String> localDirs = getLocalDirs();\n    conf.setStrings(YarnConfiguration.NM_LOCAL_DIRS,\n                    localDirs.toArray(new String[localDirs.size()]));\n    List<String> logDirs = getLogDirs();\n    conf.setStrings(YarnConfiguration.NM_LOG_DIRS,\n                      logDirs.toArray(new String[logDirs.size()]));\n    if (!areDisksHealthy()) {\n      // Just log.\n      LOG.error(\"Most of the disks failed. \" + getDisksHealthReport());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.checkDirs": "  private void checkDirs() {\n      boolean newFailure = false;\n      if (localDirs.checkDirs()) {\n        newFailure = true;\n      }\n      if (logDirs.checkDirs()) {\n        newFailure = true;\n      }\n\n      if (newFailure) {\n        updateDirsAfterFailure();\n      }\n      lastDisksCheckTime = System.currentTimeMillis();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.service.CompositeService.init": "  public synchronized void init(Configuration conf) {\n    for (Service service : serviceList) {\n      service.init(conf);\n    }\n    super.init(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeHealthCheckerService.init": "  public void init(Configuration conf) {\n    if (NodeHealthScriptRunner.shouldRun(conf)) {\n      nodeHealthScriptRunner = new NodeHealthScriptRunner();\n      addService(nodeHealthScriptRunner);\n    }\n    addService(dirsHandler);\n    super.init(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.init": "  public void init(Configuration conf) {\n\n    conf.setBoolean(Dispatcher.DISPATCHER_EXIT_ON_ERROR_KEY, true);\n\n    // Create the secretManager if need be.\n    NMContainerTokenSecretManager containerTokenSecretManager = null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      LOG.info(\"Security is enabled on NodeManager. \"\n          + \"Creating ContainerTokenSecretManager\");\n      containerTokenSecretManager = new NMContainerTokenSecretManager(conf);\n    }\n\n    Context context = new NMContext(containerTokenSecretManager);\n\n    this.aclsManager = new ApplicationACLsManager(conf);\n\n    ContainerExecutor exec = ReflectionUtils.newInstance(\n        conf.getClass(YarnConfiguration.NM_CONTAINER_EXECUTOR,\n          DefaultContainerExecutor.class, ContainerExecutor.class), conf);\n    try {\n      exec.init();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed to initialize container executor\", e);\n    }    \n    DeletionService del = new DeletionService(exec);\n    addService(del);\n\n    // NodeManager level dispatcher\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\n\n    nodeHealthChecker = new NodeHealthCheckerService();\n    addService(nodeHealthChecker);\n    dirsHandler = nodeHealthChecker.getDiskHandler();\n\n    NodeStatusUpdater nodeStatusUpdater =\n        createNodeStatusUpdater(context, dispatcher, nodeHealthChecker);\n    nodeStatusUpdater.register(this);\n\n    NodeResourceMonitor nodeResourceMonitor = createNodeResourceMonitor();\n    addService(nodeResourceMonitor);\n\n    ContainerManagerImpl containerManager =\n        createContainerManager(context, exec, del, nodeStatusUpdater,\n        this.aclsManager, dirsHandler);\n    addService(containerManager);\n\n    Service webServer = createWebServer(context, containerManager\n        .getContainersMonitor(), this.aclsManager, dirsHandler);\n    addService(webServer);\n\n    dispatcher.register(ContainerManagerEventType.class, containerManager);\n    addService(dispatcher);\n\n    DefaultMetricsSystem.initialize(\"NodeManager\");\n\n    // StatusUpdater should be added last so that it get started last \n    // so that we make sure everything is up before registering with RM. \n    addService(nodeStatusUpdater);\n\n    super.init(conf);\n    // TODO add local dirs to del\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeResourceMonitor": "  protected NodeResourceMonitor createNodeResourceMonitor() {\n    return new NodeResourceMonitorImpl();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createContainerManager": "  protected ContainerManagerImpl createContainerManager(Context context,\n      ContainerExecutor exec, DeletionService del,\n      NodeStatusUpdater nodeStatusUpdater, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new ContainerManagerImpl(context, exec, del, nodeStatusUpdater,\n      metrics, aclsManager, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNodeStatusUpdater": "  protected NodeStatusUpdater createNodeStatusUpdater(Context context,\n      Dispatcher dispatcher, NodeHealthCheckerService healthChecker) {\n    return new NodeStatusUpdaterImpl(context, dispatcher, healthChecker,\n      metrics);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createWebServer": "  protected WebServer createWebServer(Context nmContext,\n      ResourceView resourceView, ApplicationACLsManager aclsManager,\n      LocalDirsHandlerService dirsHandler) {\n    return new WebServer(nmContext, resourceView, aclsManager, dirsHandler);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager": "  private void initAndStartNodeManager(boolean hasToReboot) {\n    try {\n\n      // Remove the old hook if we are rebooting.\n      if (hasToReboot && null != nodeManagerShutdownHook) {\n        ShutdownHookManager.get().removeShutdownHook(nodeManagerShutdownHook);\n      }\n\n      nodeManagerShutdownHook = new CompositeServiceShutdownHook(this);\n      ShutdownHookManager.get().addShutdownHook(nodeManagerShutdownHook,\n                                                SHUTDOWN_HOOK_PRIORITY);\n\n      YarnConfiguration conf = new YarnConfiguration();\n      this.init(conf);\n      this.start();\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting NodeManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.start": "  public void start() {\n    try {\n      doSecureLogin();\n    } catch (IOException e) {\n      throw new YarnException(\"Failed NodeManager login\", e);\n    }\n    super.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.stateChanged": "  public void stateChanged(Service service) {\n    if (NodeStatusUpdaterImpl.class.getName().equals(service.getName())\n        && STATE.STOPPED.equals(service.getServiceState())) {\n\n      boolean hasToReboot = ((NodeStatusUpdaterImpl) service).hasToRebootNode();\n\n      // Shutdown the Nodemanager when the NodeStatusUpdater is stopped.      \n      stop();\n\n      // Reboot the whole node-manager if NodeStatusUpdater got a reboot command\n      // from the RM.\n      if (hasToReboot) {\n        LOG.info(\"Rebooting the node manager.\");\n        NodeManager nodeManager = createNewNodeManager();\n        nodeManager.initAndStartNodeManager(hasToReboot);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop": "  public void stop() {\n    super.stop();\n    DefaultMetricsSystem.shutdown();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeManager.createNewNodeManager": "  NodeManager createNewNodeManager() {\n    return new NodeManager();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.service.AbstractService.changeState": "  private void changeState(STATE newState) {\n    state = newState;\n    //notify listeners\n    for (ServiceStateChangeListener l : listeners) {\n      l.stateChanged(this);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.service.AbstractService.stop": "  public synchronized void stop() {\n    if (state == STATE.STOPPED ||\n        state == STATE.INITED ||\n        state == STATE.NOTINITED) {\n      // already stopped, or else it was never\n      // started (eg another service failing canceled startup)\n      return;\n    }\n    ensureCurrentState(STATE.STARTED);\n    changeState(STATE.STOPPED);\n    LOG.info(\"Service:\" + getName() + \" is stopped.\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.service.AbstractService.ensureCurrentState": "  private void ensureCurrentState(STATE currentState) {\n    ServiceOperations.ensureCurrentState(state, currentState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stop": "  public synchronized void stop() {\n    // Interrupt the updater.\n    this.isStopped = true;\n    super.stop();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.reboot": "  private synchronized void reboot() {\n    this.hasToRebootNode = true;\n    // Stop the status-updater. This will trigger a sub-service state change in\n    // the NodeManager which will then decide to reboot or not based on\n    // isRebooted.\n    this.stop();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.run": "      public void run() {\n        int lastHeartBeatID = 0;\n        while (!isStopped) {\n          // Send heartbeat\n          try {\n            synchronized (heartbeatMonitor) {\n              heartbeatMonitor.wait(heartBeatInterval);\n            }\n            NodeStatus nodeStatus = getNodeStatus();\n            nodeStatus.setResponseId(lastHeartBeatID);\n            \n            NodeHeartbeatRequest request = recordFactory\n                .newRecordInstance(NodeHeartbeatRequest.class);\n            request.setNodeStatus(nodeStatus);\n            if (isSecurityEnabled()) {\n              request.setLastKnownMasterKey(NodeStatusUpdaterImpl.this.context\n                .getContainerTokenSecretManager().getCurrentKey());\n            }\n            HeartbeatResponse response =\n              resourceTracker.nodeHeartbeat(request).getHeartbeatResponse();\n\n            // See if the master-key has rolled over\n            if (isSecurityEnabled()) {\n              MasterKey updatedMasterKey = response.getMasterKey();\n              if (updatedMasterKey != null) {\n                // Will be non-null only on roll-over on RM side\n                context.getContainerTokenSecretManager().setMasterKey(\n                  updatedMasterKey);\n              }\n            }\n\n            if (response.getNodeAction() == NodeAction.SHUTDOWN) {\n              LOG\n                  .info(\"Recieved SHUTDOWN signal from Resourcemanager as part of heartbeat,\" +\n                  \t\t\" hence shutting down.\");\n              NodeStatusUpdaterImpl.this.stop();\n              break;\n            }\n            if (response.getNodeAction() == NodeAction.REBOOT) {\n              LOG.info(\"Node is out of sync with ResourceManager,\"\n                  + \" hence rebooting.\");\n              NodeStatusUpdaterImpl.this.reboot();\n              break;\n            }\n\n            lastHeartBeatID = response.getResponseId();\n            List<ContainerId> containersToCleanup = response\n                .getContainersToCleanupList();\n            if (containersToCleanup.size() != 0) {\n              dispatcher.getEventHandler().handle(\n                  new CMgrCompletedContainersEvent(containersToCleanup));\n            }\n            List<ApplicationId> appsToCleanup =\n                response.getApplicationsToCleanupList();\n            //Only start tracking for keepAlive on FINISH_APP\n            trackAppsForKeepAlive(appsToCleanup);\n            if (appsToCleanup.size() != 0) {\n              dispatcher.getEventHandler().handle(\n                  new CMgrCompletedAppsEvent(appsToCleanup));\n            }\n          } catch (Throwable e) {\n            // TODO Better error handling. Thread can die with the rest of the\n            // NM still running.\n            LOG.error(\"Caught exception in status-updater\", e);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.isSecurityEnabled": "  private boolean isSecurityEnabled() {\n    return UserGroupInformation.isSecurityEnabled();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getNodeStatus": "  private NodeStatus getNodeStatus() {\n\n    NodeStatus nodeStatus = recordFactory.newRecordInstance(NodeStatus.class);\n    nodeStatus.setNodeId(this.nodeId);\n\n    int numActiveContainers = 0;\n    List<ContainerStatus> containersStatuses = new ArrayList<ContainerStatus>();\n    for (Iterator<Entry<ContainerId, Container>> i =\n        this.context.getContainers().entrySet().iterator(); i.hasNext();) {\n      Entry<ContainerId, Container> e = i.next();\n      ContainerId containerId = e.getKey();\n      Container container = e.getValue();\n\n      // Clone the container to send it to the RM\n      org.apache.hadoop.yarn.api.records.ContainerStatus containerStatus = \n          container.cloneAndGetContainerStatus();\n      containersStatuses.add(containerStatus);\n      ++numActiveContainers;\n      LOG.info(\"Sending out status for container: \" + containerStatus);\n\n      if (containerStatus.getState() == ContainerState.COMPLETE) {\n        // Remove\n        i.remove();\n\n        LOG.info(\"Removed completed container \" + containerId);\n      }\n    }\n    nodeStatus.setContainersStatuses(containersStatuses);\n\n    LOG.debug(this.nodeId + \" sending out status for \"\n        + numActiveContainers + \" containers\");\n\n    NodeHealthStatus nodeHealthStatus = this.context.getNodeHealthStatus();\n    nodeHealthStatus.setHealthReport(healthChecker.getHealthReport());\n    nodeHealthStatus.setIsNodeHealthy(healthChecker.isHealthy());\n    nodeHealthStatus.setLastHealthReportTime(\n        healthChecker.getLastHealthReportTime());\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Node's health-status : \" + nodeHealthStatus.getIsNodeHealthy()\n                + \", \" + nodeHealthStatus.getHealthReport());\n    }\n    nodeStatus.setNodeHealthStatus(nodeHealthStatus);\n\n    List<ApplicationId> keepAliveAppIds = createKeepAliveApplicationList();\n    nodeStatus.setKeepAliveApplications(keepAliveAppIds);\n    \n    return nodeStatus;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.trackAppsForKeepAlive": "  private void trackAppsForKeepAlive(List<ApplicationId> appIds) {\n    if (tokenKeepAliveEnabled && appIds != null && appIds.size() > 0) {\n      for (ApplicationId appId : appIds) {\n        trackAppForKeepAlive(appId);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.NodeHealthScriptRunner.shouldRun": "  public static boolean shouldRun(Configuration conf) {\n    String nodeHealthScript = \n      conf.get(YarnConfiguration.NM_HEALTH_CHECK_SCRIPT_PATH);\n    if (nodeHealthScript == null || nodeHealthScript.trim().isEmpty()) {\n      return false;\n    }\n    File f = new File(nodeHealthScript);\n    return f.exists() && f.canExecute();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.context.getContainerTokenSecretManager": "  NMContainerTokenSecretManager getContainerTokenSecretManager();\n\n  NodeHealthStatus getNodeHealthStatus();\n}"
        },
        "bug_report": {
            "Title": "TestNodeStatusUpdater is failing in trunk",
            "Description": "{noformat}\n2012-10-19 12:18:23,941 FATAL [Node Status Updater] nodemanager.NodeManager (NodeManager.java:initAndStartNodeManager(277)) - Error starting NodeManager\norg.apache.hadoop.yarn.YarnException: ${yarn.log.dir}/userlogs is not a valid path. Path should be with file scheme or without scheme\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.validatePaths(LocalDirsHandlerService.java:321)\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService$MonitoringTimerTask.<init>(LocalDirsHandlerService.java:95)\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.init(LocalDirsHandlerService.java:123)\n        at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeHealthCheckerService.init(NodeHealthCheckerService.java:48)\n        at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.init(NodeManager.java:165)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:274)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.stateChanged(NodeManager.java:256)\n        at org.apache.hadoop.yarn.service.AbstractService.changeState(AbstractService.java:163)\n        at org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:112)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stop(NodeStatusUpdaterImpl.java:149)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.reboot(NodeStatusUpdaterImpl.java:157)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.access$900(NodeStatusUpdaterImpl.java:63)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl$1.run(NodeStatusUpdaterImpl.java:357)\n{noformat}\n\nThe NM then calls System.exit(-1), which makes the unit test exit and produces an error that is hard to track down."
        }
    },
    {
        "filename": "YARN-6448.json",
        "creation_time": "2017-04-05T18:39:49.000+0000",
        "stack_trace": "```\njava.lang.IllegalArgumentException: Comparison method violates its general contract!\n        at java.util.TimSort.mergeHi(TimSort.java:899)\n        at java.util.TimSort.mergeAt(TimSort.java:516)\n        at java.util.TimSort.mergeForceCollapse(TimSort.java:457)\n        at java.util.TimSort.sort(TimSort.java:254)\n        at java.util.Arrays.sort(Arrays.java:1512)\n        at java.util.ArrayList.sort(ArrayList.java:1454)\n        at java.util.Collections.sort(Collections.java:175)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker.sortedNodeList(ClusterNodeTracker.java:306)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:884)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:316)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker.sortedNodeList": "  public List<N> sortedNodeList(Comparator<N> comparator) {\n    List<N> sortedList = null;\n    readLock.lock();\n    try {\n      sortedList = new ArrayList(nodes.values());\n    } finally {\n      readLock.unlock();\n    }\n    Collections.sort(sortedList, comparator);\n    return sortedList;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt": "  void continuousSchedulingAttempt() throws InterruptedException {\n    long start = getClock().getTime();\n    List<FSSchedulerNode> nodeIdList =\n        nodeTracker.sortedNodeList(nodeAvailableResourceComparator);\n\n    // iterate all nodes\n    for (FSSchedulerNode node : nodeIdList) {\n      try {\n        if (Resources.fitsIn(minimumAllocation,\n            node.getUnallocatedResource())) {\n          attemptScheduling(node);\n        }\n      } catch (Throwable ex) {\n        LOG.error(\"Error while attempting scheduling for node \" + node +\n            \": \" + ex.toString(), ex);\n        if ((ex instanceof YarnRuntimeException) &&\n            (ex.getCause() instanceof InterruptedException)) {\n          // AsyncDispatcher translates InterruptedException to\n          // YarnRuntimeException with cause InterruptedException.\n          // Need to throw InterruptedException to stop schedulingThread.\n          throw (InterruptedException)ex.getCause();\n        }\n      }\n    }\n\n    long duration = getClock().getTime() - start;\n    fsOpDurations.addContinuousSchedulingRunDuration(duration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling": "  void attemptScheduling(FSSchedulerNode node) {\n    try {\n      writeLock.lock();\n      if (rmContext.isWorkPreservingRecoveryEnabled() && !rmContext\n          .isSchedulerReadyForAllocatingContainers()) {\n        return;\n      }\n\n      final NodeId nodeID = node.getNodeID();\n      if (!nodeTracker.exists(nodeID)) {\n        // The node might have just been removed while this thread was waiting\n        // on the synchronized lock before it entered this synchronized method\n        LOG.info(\n            \"Skipping scheduling as the node \" + nodeID + \" has been removed\");\n        return;\n      }\n\n      // Assign new containers...\n      // 1. Check for reserved applications\n      // 2. Schedule if there are no reservations\n\n      boolean validReservation = false;\n      FSAppAttempt reservedAppSchedulable = node.getReservedAppSchedulable();\n      if (reservedAppSchedulable != null) {\n        validReservation = reservedAppSchedulable.assignReservedContainer(node);\n      }\n      if (!validReservation) {\n        // No reservation, schedule at queue which is farthest below fair share\n        int assignedContainers = 0;\n        Resource assignedResource = Resources.clone(Resources.none());\n        Resource maxResourcesToAssign = Resources.multiply(\n            node.getUnallocatedResource(), 0.5f);\n        while (node.getReservedContainer() == null) {\n          boolean assignedContainer = false;\n          Resource assignment = queueMgr.getRootQueue().assignContainer(node);\n          if (!assignment.equals(Resources.none())) {\n            assignedContainers++;\n            assignedContainer = true;\n            Resources.addTo(assignedResource, assignment);\n          }\n          if (!assignedContainer) {\n            break;\n          }\n          if (!shouldContinueAssigning(assignedContainers, maxResourcesToAssign,\n              assignedResource)) {\n            break;\n          }\n        }\n      }\n      updateRootQueueMetrics();\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.run": "    public void run() {\n      while (!Thread.currentThread().isInterrupted()) {\n        try {\n          continuousSchedulingAttempt();\n          Thread.sleep(getContinuousSchedulingSleepMs());\n        } catch (InterruptedException e) {\n          LOG.warn(\"Continuous scheduling thread interrupted. Exiting.\", e);\n          return;\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getContinuousSchedulingSleepMs": "  public int getContinuousSchedulingSleepMs() {\n    return continuousSchedulingSleepMs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update": "  public void update() {\n    try {\n      writeLock.lock();\n\n      FSQueue rootQueue = queueMgr.getRootQueue();\n\n      // Recursively update demands for all queues\n      rootQueue.updateDemand();\n\n      Resource clusterResource = getClusterResource();\n      rootQueue.update(clusterResource, shouldAttemptPreemption());\n\n      // Update metrics\n      updateRootQueueMetrics();\n\n      if (LOG.isDebugEnabled()) {\n        if (--updatesToSkipForDebug < 0) {\n          updatesToSkipForDebug = UPDATE_DEBUG_FREQUENCY;\n          dumpSchedulerState();\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.fsOpDurations.addContinuousSchedulingRunDuration": "  public void addContinuousSchedulingRunDuration(long value) {\n    continuousSchedulingRun.add(value);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.fsOpDurations.addUpdateThreadRunDuration": "  public void addUpdateThreadRunDuration(long value) {\n    updateThreadRun.add(value);\n  }"
        },
        "bug_report": {
            "Title": "Continuous scheduling thread crashes while sorting nodes",
            "Description": "YARN-4719 remove the lock in continuous scheduling while sorting nodes. It breaks the order in comparison if nodes changes while sorting.\n{code}\n2017-04-04 23:42:26,123 FATAL org.apache.hadoop.yarn.server.resourcemanager.RMCriticalThreadUncaughtExceptionHandler: Critical thread FairSchedulerContinuousScheduling crashed!\njava.lang.IllegalArgumentException: Comparison method violates its general contract!\n        at java.util.TimSort.mergeHi(TimSort.java:899)\n        at java.util.TimSort.mergeAt(TimSort.java:516)\n        at java.util.TimSort.mergeForceCollapse(TimSort.java:457)\n        at java.util.TimSort.sort(TimSort.java:254)\n        at java.util.Arrays.sort(Arrays.java:1512)\n        at java.util.ArrayList.sort(ArrayList.java:1454)\n        at java.util.Collections.sort(Collections.java:175)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker.sortedNodeList(ClusterNodeTracker.java:306)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:884)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:316)\n{code}"
        }
    },
    {
        "filename": "YARN-4530.json",
        "creation_time": "2015-12-30T15:19:19.000+0000",
        "stack_trace": "```\njava.io.IOException: Resource hdfs://ns3/user/username/projects/user_insight/lookalike/oozie/workflow/lib/unilever_support_udf-0.0.1-SNAPSHOT.jar changed on src filesystem (expected 1451380519452, was 1451380611793\n\tat org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:176)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:276)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:50)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$PublicLocalizer.run(ResourceLocalizationService.java:712)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.copy": "  private Path copy(Path sCopy, Path dstdir) throws IOException {\n    FileSystem sourceFs = sCopy.getFileSystem(conf);\n    Path dCopy = new Path(dstdir, \"tmp_\"+sCopy.getName());\n    FileStatus sStat = sourceFs.getFileStatus(sCopy);\n    if (sStat.getModificationTime() != resource.getTimestamp()) {\n      throw new IOException(\"Resource \" + sCopy +\n          \" changed on src filesystem (expected \" + resource.getTimestamp() +\n          \", was \" + sStat.getModificationTime());\n    }\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      if (!isPublic(sourceFs, sCopy, sStat, statCache)) {\n        throw new IOException(\"Resource \" + sCopy +\n            \" is not publicly accessable and as such cannot be part of the\" +\n            \" public cache.\");\n      }\n    }\n\n    FileUtil.copy(sourceFs, sStat, FileSystem.getLocal(conf), dCopy, false,\n        true, conf);\n    return dCopy;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.isPublic": "  public static boolean isPublic(FileSystem fs, Path current, FileStatus sStat,\n      LoadingCache<Path,Future<FileStatus>> statCache) throws IOException {\n    current = fs.makeQualified(current);\n    //the leaf level file should be readable by others\n    if (!checkPublicPermsForAll(fs, sStat, FsAction.READ_EXECUTE, FsAction.READ)) {\n      return false;\n    }\n\n    if (Shell.WINDOWS && fs instanceof LocalFileSystem) {\n      // Relax the requirement for public cache on LFS on Windows since default\n      // permissions are \"700\" all the way up to the drive letter. In this\n      // model, the only requirement for a user is to give EVERYONE group\n      // permission on the file and the file will be considered public.\n      // This code path is only hit when fs.default.name is file:/// (mainly\n      // in tests).\n      return true;\n    }\n    return ancestorsHaveExecutePermissions(fs, current.getParent(), statCache);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.getFileStatus": "  private static FileStatus getFileStatus(final FileSystem fs, final Path path,\n      LoadingCache<Path,Future<FileStatus>> statCache) throws IOException {\n    // if the stat cache does not exist, simply query the filesystem\n    if (statCache == null) {\n      return fs.getFileStatus(path);\n    }\n\n    try {\n      // get or load it from the cache\n      return statCache.get(path).get();\n    } catch (ExecutionException e) {\n      Throwable cause = e.getCause();\n      // the underlying exception should normally be IOException\n      if (cause instanceof IOException) {\n        throw (IOException)cause;\n      } else {\n        throw new IOException(cause);\n      }\n    } catch (InterruptedException e) { // should not happen\n      Thread.currentThread().interrupt();\n      throw new IOException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.call": "  public Path call() throws Exception {\n    final Path sCopy;\n    try {\n      sCopy = ConverterUtils.getPathFromYarnURL(resource.getResource());\n    } catch (URISyntaxException e) {\n      throw new IOException(\"Invalid resource\", e);\n    }\n    createDir(destDirPath, cachePerms);\n    final Path dst_work = new Path(destDirPath + \"_tmp\");\n    createDir(dst_work, cachePerms);\n    Path dFinal = files.makeQualified(new Path(dst_work, sCopy.getName()));\n    try {\n      Path dTmp = null == userUgi ? files.makeQualified(copy(sCopy, dst_work))\n          : userUgi.doAs(new PrivilegedExceptionAction<Path>() {\n            public Path run() throws Exception {\n              return files.makeQualified(copy(sCopy, dst_work));\n            };\n          });\n      unpack(new File(dTmp.toUri()), new File(dFinal.toUri()));\n      changePermissions(dFinal.getFileSystem(conf), dFinal);\n      files.rename(dst_work, destDirPath, Rename.OVERWRITE);\n    } catch (Exception e) {\n      try {\n        files.delete(destDirPath, true);\n      } catch (IOException ignore) {\n      }\n      throw e;\n    } finally {\n      try {\n        files.delete(dst_work, true);\n      } catch (FileNotFoundException ignore) {\n      }\n      conf = null;\n      resource = null;\n    }\n    return files.makeQualified(new Path(destDirPath, sCopy.getName()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.unpack": "  private long unpack(File localrsrc, File dst) throws IOException {\n    switch (resource.getType()) {\n    case ARCHIVE: {\n      String lowerDst = StringUtils.toLowerCase(dst.getName());\n      if (lowerDst.endsWith(\".jar\")) {\n        RunJar.unJar(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".zip\")) {\n        FileUtil.unZip(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".tar.gz\") ||\n                 lowerDst.endsWith(\".tgz\") ||\n                 lowerDst.endsWith(\".tar\")) {\n        FileUtil.unTar(localrsrc, dst);\n      } else {\n        LOG.warn(\"Cannot unpack \" + localrsrc);\n        if (!localrsrc.renameTo(dst)) {\n            throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + dst + \"]\");\n        }\n      }\n    }\n    break;\n    case PATTERN: {\n      String lowerDst = StringUtils.toLowerCase(dst.getName());\n      if (lowerDst.endsWith(\".jar\")) {\n        String p = resource.getPattern();\n        RunJar.unJar(localrsrc, dst,\n            p == null ? RunJar.MATCH_ANY : Pattern.compile(p));\n        File newDst = new File(dst, dst.getName());\n        if (!dst.exists() && !dst.mkdir()) {\n          throw new IOException(\"Unable to create directory: [\" + dst + \"]\");\n        }\n        if (!localrsrc.renameTo(newDst)) {\n          throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + newDst + \"]\");\n        }\n      } else if (lowerDst.endsWith(\".zip\")) {\n        LOG.warn(\"Treating [\" + localrsrc + \"] as an archive even though it \" +\n        \t\t\"was specified as PATTERN\");\n        FileUtil.unZip(localrsrc, dst);\n      } else if (lowerDst.endsWith(\".tar.gz\") ||\n                 lowerDst.endsWith(\".tgz\") ||\n                 lowerDst.endsWith(\".tar\")) {\n        LOG.warn(\"Treating [\" + localrsrc + \"] as an archive even though it \" +\n        \"was specified as PATTERN\");\n        FileUtil.unTar(localrsrc, dst);\n      } else {\n        LOG.warn(\"Cannot unpack \" + localrsrc);\n        if (!localrsrc.renameTo(dst)) {\n          throw new IOException(\"Unable to rename file: [\" + localrsrc\n              + \"] to [\" + dst + \"]\");\n        }\n      }\n    }\n    break;\n    case FILE:\n    default:\n      if (!localrsrc.renameTo(dst)) {\n        throw new IOException(\"Unable to rename file: [\" + localrsrc\n          + \"] to [\" + dst + \"]\");\n      }\n      break;\n    }\n    if(localrsrc.isFile()){\n      try {\n        files.delete(new Path(localrsrc.toString()), false);\n      } catch (IOException ignore) {\n      }\n    }\n    return 0;\n    // TODO Should calculate here before returning\n    //return FileUtil.getDU(destDir);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.changePermissions": "  private void changePermissions(FileSystem fs, final Path path)\n      throws IOException, InterruptedException {\n    File f = new File(path.toUri());\n    if (FileUtils.isSymlink(f)) {\n      // avoid following symlinks when changing permissions\n      return;\n    }\n    boolean isDir = f.isDirectory();\n    FsPermission perm = cachePerms;\n    // set public perms as 755 or 555 based on dir or file\n    if (resource.getVisibility() == LocalResourceVisibility.PUBLIC) {\n      perm = isDir ? PUBLIC_DIR_PERMS : PUBLIC_FILE_PERMS;\n    }\n    // set private perms as 700 or 500\n    else {\n      // PRIVATE:\n      // APPLICATION:\n      perm = isDir ? PRIVATE_DIR_PERMS : PRIVATE_FILE_PERMS;\n    }\n    LOG.debug(\"Changing permissions for path \" + path\n        + \" to perm \" + perm);\n    final FsPermission fPerm = perm;\n    if (null == userUgi) {\n      files.setPermission(path, perm);\n    }\n    else {\n      userUgi.doAs(new PrivilegedExceptionAction<Void>() {\n        public Void run() throws Exception {\n          files.setPermission(path, fPerm);\n          return null;\n        }\n      });\n    }\n    if (isDir) {\n      FileStatus[] statuses = fs.listStatus(path);\n      for (FileStatus status : statuses) {\n        changePermissions(fs, status.getPath());\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.getResource": "  LocalResource getResource() {\n    return resource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.FSDownload.createDir": "  private void createDir(Path path, FsPermission perm) throws IOException {\n    files.mkdir(path, perm, false);\n    if (!perm.equals(files.getUMask().applyUMask(perm))) {\n      files.setPermission(path, perm);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.run": "    public void run() {\n      dispatcher.getEventHandler().handle(\n          new LocalizationEvent(LocalizationEventType.CACHE_CLEANUP));\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.writeCredentials": "    private void writeCredentials(Path nmPrivateCTokensPath)\n        throws IOException {\n      DataOutputStream tokenOut = null;\n      try {\n        Credentials credentials = context.getCredentials();\n        if (UserGroupInformation.isSecurityEnabled()) {\n          Credentials systemCredentials =\n              getSystemCredentialsSentFromRM(context);\n          if (systemCredentials != null) {\n            credentials = systemCredentials;\n          }\n        }\n\n        FileContext lfs = getLocalFileContext(getConfig());\n        tokenOut =\n            lfs.create(nmPrivateCTokensPath, EnumSet.of(CREATE, OVERWRITE));\n        LOG.info(\"Writing credentials to the nmPrivate file \"\n            + nmPrivateCTokensPath.toString() + \". Credentials list: \");\n        if (LOG.isDebugEnabled()) {\n          for (Token<? extends TokenIdentifier> tk : credentials\n              .getAllTokens()) {\n            LOG.debug(tk + \" : \" + buildTokenFingerprint(tk));\n          }\n        }\n        if (UserGroupInformation.isSecurityEnabled()) {\n          credentials = new Credentials(credentials);\n          LocalizerTokenIdentifier id = secretManager.createIdentifier();\n          Token<LocalizerTokenIdentifier> localizerToken =\n              new Token<LocalizerTokenIdentifier>(id, secretManager);\n          credentials.addToken(id.getKind(), localizerToken);\n        }\n        credentials.writeTokenStorageToStream(tokenOut);\n      } finally {\n        if (tokenOut != null) {\n          tokenOut.close();\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle": "    public void handle(LocalizerEvent event) {\n      String locId = event.getLocalizerId();\n      switch (event.getType()) {\n      case REQUEST_RESOURCE_LOCALIZATION:\n        // 0) find running localizer or start new thread\n        LocalizerResourceRequestEvent req =\n          (LocalizerResourceRequestEvent)event;\n        switch (req.getVisibility()) {\n        case PUBLIC:\n          publicLocalizer.addResource(req);\n          break;\n        case PRIVATE:\n        case APPLICATION:\n          synchronized (privLocalizers) {\n            LocalizerRunner localizer = privLocalizers.get(locId);\n            if (null == localizer) {\n              LOG.info(\"Created localizer for \" + locId);\n              localizer = new LocalizerRunner(req.getContext(), locId);\n              privLocalizers.put(locId, localizer);\n              localizer.start();\n            }\n            // 1) propagate event\n            localizer.addResource(req);\n          }\n          break;\n        }\n        break;\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.ConverterUtils.getPathFromYarnURL": "  public static Path getPathFromYarnURL(URL url) throws URISyntaxException {\n    String scheme = url.getScheme() == null ? \"\" : url.getScheme();\n    \n    String authority = \"\";\n    if (url.getHost() != null) {\n      authority = url.getHost();\n      if (url.getUserInfo() != null) {\n        authority = url.getUserInfo() + \"@\" + authority;\n      }\n      if (url.getPort() > 0) {\n        authority += \":\" + url.getPort();\n      }\n    }\n    \n    return new Path(\n        (new URI(scheme, authority, url.getFile(), null, null)).normalize());\n  }"
        },
        "bug_report": {
            "Title": "LocalizedResource trigger a NPE Cause the NodeManager exit",
            "Description": "In our cluster, I found that LocalizedResource download failed trigger a NPE Cause the NodeManager shutdown.\n\n{noformat}\n2015-12-29 17:18:33,706 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ns3:8020/user/username/projects/user_insight/lookalike/oozie/workflow/conf/hive-site.xml transitioned from DOWNLOADING to FAILED\n2015-12-29 17:18:33,708 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Downloading public rsrc:{ hdfs://ns3/user/username/projects/user_insight/lookalike/oozie/workflow/lib/user_insight_pig_udf-0.0.1-SNAPSHOT-jar-with-dependencies.jar, 1451380519635, FILE, null }\n2015-12-29 17:18:33,710 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Failed to download rsrc { { hdfs://ns3/user/username/projects/user_insight/lookalike/oozie/workflow/lib/unilever_support_udf-0.0.1-SNAPSHOT.jar, 1451380519452, FILE, null },pending,[(container_1451039893865_261670_01_000578)],42332661980495938,DOWNLOADING}\njava.io.IOException: Resource hdfs://ns3/user/username/projects/user_insight/lookalike/oozie/workflow/lib/unilever_support_udf-0.0.1-SNAPSHOT.jar changed on src filesystem (expected 1451380519452, was 1451380611793\n\tat org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:176)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:276)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:50)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n2015-12-29 17:18:33,710 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ns3/user/username/projects/user_insight/lookalike/oozie/workflow/lib/unilever_support_udf-0.0.1-SNAPSHOT.jar transitioned from DOWNLOADING to FAILED\n2015-12-29 17:18:33,710 FATAL org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Error: Shutting down\njava.lang.NullPointerException at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$PublicLocalizer.run(ResourceLocalizationService.java:712)\n2015-12-29 17:18:33,710 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting\n{noformat}"
        }
    },
    {
        "filename": "YARN-7737.json",
        "creation_time": "2018-01-11T19:35:01.000+0000",
        "stack_trace": "```\njava.io.FileNotFoundException: File /grid/b/tmp/userlogs/application_1515190594800_1766/container_e39_1515190594800_1766_01_000002/prelaunch.err does not exist\n        at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:641)\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:930)\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:631)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitWithFailure(ContainerLaunch.java:545)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitCode(ContainerLaunch.java:511)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:319)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:93)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus": "  private FileStatus deprecatedGetFileStatus(Path f) throws IOException {\n    File path = pathToFile(f);\n    if (path.exists()) {\n      return new DeprecatedRawLocalFileStatus(pathToFile(f),\n          getDefaultBlockSize(f), this);\n    } else {\n      throw new FileNotFoundException(\"File \" + f + \" does not exist\");\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.pathToFile": "  public File pathToFile(Path path) {\n    checkPath(path);\n    if (!path.isAbsolute()) {\n      path = new Path(getWorkingDirectory(), path);\n    }\n    return new File(path.toUri().getPath());\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal": "  private FileStatus getFileLinkStatusInternal(final Path f,\n      boolean dereference) throws IOException {\n    if (!useDeprecatedFileStatus) {\n      return getNativeFileLinkStatus(f, dereference);\n    } else if (dereference) {\n      return deprecatedGetFileStatus(f);\n    } else {\n      return deprecatedGetFileLinkStatusInternal(f);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal": "  private FileStatus deprecatedGetFileLinkStatusInternal(final Path f)\n      throws IOException {\n    String target = FileUtil.readLink(new File(f.toString()));\n\n    try {\n      FileStatus fs = getFileStatus(f);\n      // If f refers to a regular file or directory\n      if (target.isEmpty()) {\n        return fs;\n      }\n      // Otherwise f refers to a symlink\n      return new FileStatus(fs.getLen(),\n          false,\n          fs.getReplication(),\n          fs.getBlockSize(),\n          fs.getModificationTime(),\n          fs.getAccessTime(),\n          fs.getPermission(),\n          fs.getOwner(),\n          fs.getGroup(),\n          new Path(target),\n          f);\n    } catch (FileNotFoundException e) {\n      /* The exists method in the File class returns false for dangling\n       * links so we can get a FileNotFoundException for links that exist.\n       * It's also possible that we raced with a delete of the link. Use\n       * the readBasicFileAttributes method in java.nio.file.attributes\n       * when available.\n       */\n      if (!target.isEmpty()) {\n        return new FileStatus(0, false, 0, 0, 0, 0, FsPermission.getDefault(),\n            \"\", \"\", new Path(target), f);\n      }\n      // f refers to a file or directory that does not exist\n      throw e;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.getNativeFileLinkStatus": "  private FileStatus getNativeFileLinkStatus(final Path f,\n      boolean dereference) throws IOException {\n    checkPath(f);\n    Stat stat = new Stat(f, getDefaultBlockSize(f), dereference, this);\n    FileStatus status = stat.getFileStatus();\n    return status;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus": "  public FileStatus getFileStatus(Path f) throws IOException {\n    return getFileLinkStatusInternal(f, true);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitWithFailure": "  protected void handleContainerExitWithFailure(ContainerId containerID,\n      int ret, Path containerLogDir, StringBuilder diagnosticInfo) {\n    LOG.warn(\"Container launch failed : \" + diagnosticInfo.toString());\n\n    FileSystem fileSystem = null;\n    long tailSizeInBytes =\n        conf.getLong(YarnConfiguration.NM_CONTAINER_STDERR_BYTES,\n            YarnConfiguration.DEFAULT_NM_CONTAINER_STDERR_BYTES);\n\n    // Append container prelaunch stderr to diagnostics\n    try {\n      fileSystem = FileSystem.getLocal(conf).getRaw();\n      FileStatus preLaunchErrorFileStatus = fileSystem\n          .getFileStatus(new Path(containerLogDir, ContainerLaunch.CONTAINER_PRE_LAUNCH_STDERR));\n\n      Path errorFile = preLaunchErrorFileStatus.getPath();\n      long fileSize = preLaunchErrorFileStatus.getLen();\n\n      diagnosticInfo.append(\"Error file: \")\n          .append(ContainerLaunch.CONTAINER_PRE_LAUNCH_STDERR).append(\".\\n\");\n      ;\n\n      byte[] tailBuffer = tailFile(errorFile, fileSize, tailSizeInBytes);\n      diagnosticInfo.append(\"Last \").append(tailSizeInBytes)\n          .append(\" bytes of \").append(errorFile.getName()).append(\" :\\n\")\n          .append(new String(tailBuffer, StandardCharsets.UTF_8));\n    } catch (IOException e) {\n      LOG.error(\"Failed to get tail of the container's prelaunch error log file\", e);\n    }\n\n    // Append container stderr to diagnostics\n    String errorFileNamePattern =\n        conf.get(YarnConfiguration.NM_CONTAINER_STDERR_PATTERN,\n            YarnConfiguration.DEFAULT_NM_CONTAINER_STDERR_PATTERN);\n\n    try {\n      if (fileSystem == null) {\n        fileSystem = FileSystem.getLocal(conf).getRaw();\n      }\n      FileStatus[] errorFileStatuses = fileSystem\n          .globStatus(new Path(containerLogDir, errorFileNamePattern));\n      if (errorFileStatuses != null && errorFileStatuses.length != 0) {\n        Path errorFile = errorFileStatuses[0].getPath();\n        long fileSize = errorFileStatuses[0].getLen();\n\n        // if more than one file matches the stderr pattern, take the latest\n        // modified file, and also append the file names in the diagnosticInfo\n        if (errorFileStatuses.length > 1) {\n          String[] errorFileNames = new String[errorFileStatuses.length];\n          long latestModifiedTime = errorFileStatuses[0].getModificationTime();\n          errorFileNames[0] = errorFileStatuses[0].getPath().getName();\n          for (int i = 1; i < errorFileStatuses.length; i++) {\n            errorFileNames[i] = errorFileStatuses[i].getPath().getName();\n            if (errorFileStatuses[i]\n                .getModificationTime() > latestModifiedTime) {\n              latestModifiedTime = errorFileStatuses[i].getModificationTime();\n              errorFile = errorFileStatuses[i].getPath();\n              fileSize = errorFileStatuses[i].getLen();\n            }\n          }\n          diagnosticInfo.append(\"Error files: \")\n              .append(StringUtils.join(\", \", errorFileNames)).append(\".\\n\");\n        }\n\n        byte[] tailBuffer = tailFile(errorFile, fileSize, tailSizeInBytes);\n        String tailBufferMsg = new String(tailBuffer, StandardCharsets.UTF_8);\n        diagnosticInfo.append(\"Last \").append(tailSizeInBytes)\n            .append(\" bytes of \").append(errorFile.getName()).append(\" :\\n\")\n            .append(tailBufferMsg).append(\"\\n\")\n            .append(analysesErrorMsgOfContainerExitWithFailure(tailBufferMsg));\n\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed to get tail of the container's error log file\", e);\n    }\n    this.dispatcher.getEventHandler()\n        .handle(new ContainerExitEvent(containerID,\n            ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n            diagnosticInfo.toString()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.tailFile": "  private byte[] tailFile(Path filePath, long fileSize, long tailSizeInBytes) throws IOException {\n    FSDataInputStream errorFileIS = null;\n    FileSystem fileSystem = FileSystem.getLocal(conf).getRaw();\n    try {\n      long startPosition =\n          (fileSize < tailSizeInBytes) ? 0 : fileSize - tailSizeInBytes;\n      int bufferSize =\n          (int) ((fileSize < tailSizeInBytes) ? fileSize : tailSizeInBytes);\n      byte[] tailBuffer = new byte[bufferSize];\n      errorFileIS = fileSystem.open(filePath);\n      errorFileIS.readFully(startPosition, tailBuffer);\n      return tailBuffer;\n    } finally {\n      IOUtils.cleanupWithLogger(LOG, errorFileIS);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.analysesErrorMsgOfContainerExitWithFailure": "  private String analysesErrorMsgOfContainerExitWithFailure(String errorMsg) {\n    StringBuilder analysis = new StringBuilder();\n    if (errorMsg.indexOf(\"Error: Could not find or load main class\"\n        + \" org.apache.hadoop.mapreduce\") != -1) {\n      analysis.append(\"Please check whether your etc/hadoop/mapred-site.xml \"\n          + \"contains the below configuration:\\n\");\n      analysis.append(\"<property>\\n\")\n          .append(\"  <name>yarn.app.mapreduce.am.env</name>\\n\")\n          .append(\"  <value>HADOOP_MAPRED_HOME=${full path of your hadoop \"\n              + \"distribution directory}</value>\\n\")\n          .append(\"</property>\\n<property>\\n\")\n          .append(\"  <name>mapreduce.map.env</name>\\n\")\n          .append(\"  <value>HADOOP_MAPRED_HOME=${full path of your hadoop \"\n              + \"distribution directory}</value>\\n\")\n          .append(\"</property>\\n<property>\\n\")\n          .append(\"  <name>mapreduce.reduce.env</name>\\n\")\n          .append(\"  <value>HADOOP_MAPRED_HOME=${full path of your hadoop \"\n              + \"distribution directory}</value>\\n\")\n          .append(\"</property>\\n\");\n    }\n    return analysis.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.toString": "    public String toString() {\n      return sb.toString();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitCode": "  protected void handleContainerExitCode(int exitCode, Path containerLogDir) {\n    ContainerId containerId = container.getContainerId();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Container \" + containerId + \" completed with exit code \"\n          + exitCode);\n    }\n\n    StringBuilder diagnosticInfo =\n        new StringBuilder(\"Container exited with a non-zero exit code \");\n    diagnosticInfo.append(exitCode);\n    diagnosticInfo.append(\". \");\n    if (exitCode == ExitCode.FORCE_KILLED.getExitCode()\n        || exitCode == ExitCode.TERMINATED.getExitCode()) {\n      // If the process was killed, Send container_cleanedup_after_kill and\n      // just break out of this method.\n\n      // If Container was killed before starting... NO need to do this.\n      if (!killedBeforeStart) {\n        dispatcher.getEventHandler().handle(\n            new ContainerExitEvent(containerId,\n                ContainerEventType.CONTAINER_KILLED_ON_REQUEST, exitCode,\n                diagnosticInfo.toString()));\n      }\n    } else if (exitCode != 0) {\n      handleContainerExitWithFailure(containerId, exitCode, containerLogDir,\n          diagnosticInfo);\n    } else {\n      LOG.info(\"Container \" + containerId + \" succeeded \");\n      dispatcher.getEventHandler().handle(\n          new ContainerEvent(containerId,\n              ContainerEventType.CONTAINER_EXITED_WITH_SUCCESS));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call": "  public Integer call() {\n    if (!validateContainerState()) {\n      return 0;\n    }\n\n    final ContainerLaunchContext launchContext = container.getLaunchContext();\n    ContainerId containerID = container.getContainerId();\n    String containerIdStr = containerID.toString();\n    final List<String> command = launchContext.getCommands();\n    int ret = -1;\n\n    Path containerLogDir;\n    try {\n      Map<Path, List<String>> localResources = getLocalizedResources();\n\n      final String user = container.getUser();\n      // /////////////////////////// Variable expansion\n      // Before the container script gets written out.\n      List<String> newCmds = new ArrayList<String>(command.size());\n      String appIdStr = app.getAppId().toString();\n      String relativeContainerLogDir = ContainerLaunch\n          .getRelativeContainerLogDir(appIdStr, containerIdStr);\n      containerLogDir =\n          dirsHandler.getLogPathForWrite(relativeContainerLogDir, false);\n      recordContainerLogDir(containerID, containerLogDir.toString());\n      for (String str : command) {\n        // TODO: Should we instead work via symlinks without this grammar?\n        newCmds.add(expandEnvironment(str, containerLogDir));\n      }\n      launchContext.setCommands(newCmds);\n\n      Map<String, String> environment = launchContext.getEnvironment();\n      // Make a copy of env to iterate & do variable expansion\n      for (Entry<String, String> entry : environment.entrySet()) {\n        String value = entry.getValue();\n        value = expandEnvironment(value, containerLogDir);\n        entry.setValue(value);\n      }\n      // /////////////////////////// End of variable expansion\n\n      FileContext lfs = FileContext.getLocalFSFileContext();\n\n      Path nmPrivateContainerScriptPath = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n              + CONTAINER_SCRIPT);\n      Path nmPrivateTokensPath = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n              + String.format(ContainerLocalizer.TOKEN_FILE_NAME_FMT,\n              containerIdStr));\n      Path nmPrivateClasspathJarDir = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr));\n\n      // Select the working directory for the container\n      Path containerWorkDir = deriveContainerWorkDir();\n      recordContainerWorkDir(containerID, containerWorkDir.toString());\n\n      String pidFileSubpath = getPidFileSubpath(appIdStr, containerIdStr);\n      // pid file should be in nm private dir so that it is not\n      // accessible by users\n      pidFilePath = dirsHandler.getLocalPathForWrite(pidFileSubpath);\n      List<String> localDirs = dirsHandler.getLocalDirs();\n      List<String> logDirs = dirsHandler.getLogDirs();\n      List<String> filecacheDirs = getNMFilecacheDirs(localDirs);\n      List<String> userLocalDirs = getUserLocalDirs(localDirs);\n      List<String> containerLocalDirs = getContainerLocalDirs(localDirs);\n      List<String> containerLogDirs = getContainerLogDirs(logDirs);\n\n      if (!dirsHandler.areDisksHealthy()) {\n        ret = ContainerExitStatus.DISKS_FAILED;\n        throw new IOException(\"Most of the disks failed. \"\n            + dirsHandler.getDisksHealthReport(false));\n      }\n      List<Path> appDirs = new ArrayList<Path>(localDirs.size());\n      for (String localDir : localDirs) {\n        Path usersdir = new Path(localDir, ContainerLocalizer.USERCACHE);\n        Path userdir = new Path(usersdir, user);\n        Path appsdir = new Path(userdir, ContainerLocalizer.APPCACHE);\n        appDirs.add(new Path(appsdir, appIdStr));\n      }\n\n      // Set the token location too.\n      environment.put(\n          ApplicationConstants.CONTAINER_TOKEN_FILE_ENV_NAME,\n          new Path(containerWorkDir,\n              FINAL_CONTAINER_TOKENS_FILE).toUri().getPath());\n\n      // /////////// Write out the container-script in the nmPrivate space.\n      try (DataOutputStream containerScriptOutStream =\n               lfs.create(nmPrivateContainerScriptPath,\n                   EnumSet.of(CREATE, OVERWRITE))) {\n        // Sanitize the container's environment\n        sanitizeEnv(environment, containerWorkDir, appDirs, userLocalDirs,\n            containerLogDirs, localResources, nmPrivateClasspathJarDir);\n\n        prepareContainer(localResources, containerLocalDirs);\n\n        // Write out the environment\n        exec.writeLaunchEnv(containerScriptOutStream, environment,\n            localResources, launchContext.getCommands(),\n            new Path(containerLogDirs.get(0)), user);\n      }\n      // /////////// End of writing out container-script\n\n      // /////////// Write out the container-tokens in the nmPrivate space.\n      try (DataOutputStream tokensOutStream =\n               lfs.create(nmPrivateTokensPath, EnumSet.of(CREATE, OVERWRITE))) {\n        Credentials creds = container.getCredentials();\n        creds.writeTokenStorageToStream(tokensOutStream);\n      }\n      // /////////// End of writing out container-tokens\n\n      ret = launchContainer(new ContainerStartContext.Builder()\n          .setContainer(container)\n          .setLocalizedResources(localResources)\n          .setNmPrivateContainerScriptPath(nmPrivateContainerScriptPath)\n          .setNmPrivateTokensPath(nmPrivateTokensPath)\n          .setUser(user)\n          .setAppId(appIdStr)\n          .setContainerWorkDir(containerWorkDir)\n          .setLocalDirs(localDirs)\n          .setLogDirs(logDirs)\n          .setFilecacheDirs(filecacheDirs)\n          .setUserLocalDirs(userLocalDirs)\n          .setContainerLocalDirs(containerLocalDirs)\n          .setContainerLogDirs(containerLogDirs).build());\n    } catch (ConfigurationException e) {\n      LOG.error(\"Failed to launch container due to configuration error.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerID, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      // Mark the node as unhealthy\n      context.getNodeStatusUpdater().reportException(e);\n      return ret;\n    } catch (Throwable e) {\n      LOG.warn(\"Failed to launch container.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerID, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      return ret;\n    } finally {\n      setContainerCompletedStatus(ret);\n    }\n\n    handleContainerExitCode(ret, containerLogDir);\n    return ret;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerPrivateDir": "  protected String getContainerPrivateDir(String appIdStr,\n      String containerIdStr) {\n    return getAppPrivateDir(appIdStr) + Path.SEPARATOR + containerIdStr\n        + Path.SEPARATOR;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getPidFileSubpath": "  protected String getPidFileSubpath(String appIdStr, String containerIdStr) {\n    return getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n        + String.format(ContainerLaunch.PID_FILE_NAME_FMT, containerIdStr);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerLogDirs": "  protected List<String> getContainerLogDirs(List<String> logDirs) {\n    List<String> containerLogDirs = new ArrayList<>(logDirs.size());\n    String appIdStr = app.getAppId().toString();\n    String containerIdStr = container.getContainerId().toString();\n    String relativeContainerLogDir = ContainerLaunch\n        .getRelativeContainerLogDir(appIdStr, containerIdStr);\n\n    for (String logDir : logDirs) {\n      containerLogDirs.add(logDir + Path.SEPARATOR + relativeContainerLogDir);\n    }\n\n    return containerLogDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.prepareContainer": "  private void prepareContainer(Map<Path, List<String>> localResources,\n      List<String> containerLocalDirs) throws IOException {\n\n    exec.prepareContainer(new ContainerPrepareContext.Builder()\n        .setContainer(container)\n        .setLocalizedResources(localResources)\n        .setUser(container.getUser())\n        .setContainerLocalDirs(containerLocalDirs)\n        .setCommands(container.getLaunchContext().getCommands())\n        .build());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.setContainerCompletedStatus": "  protected void setContainerCompletedStatus(int exitCode) {\n    ContainerId containerId = container.getContainerId();\n    completed.set(true);\n    exec.deactivateContainer(containerId);\n    try {\n      if (!container.shouldRetry(exitCode)) {\n        context.getNMStateStore().storeContainerCompleted(containerId,\n            exitCode);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Unable to set exit code for container \" + containerId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.deriveContainerWorkDir": "  private Path deriveContainerWorkDir() throws IOException {\n\n    final String containerWorkDirPath =\n        ContainerLocalizer.USERCACHE +\n        Path.SEPARATOR +\n        container.getUser() +\n        Path.SEPARATOR +\n        ContainerLocalizer.APPCACHE +\n        Path.SEPARATOR +\n        app.getAppId().toString() +\n        Path.SEPARATOR +\n        container.getContainerId().toString();\n\n    final Path containerWorkDir =\n        dirsHandler.getLocalPathForWrite(\n          containerWorkDirPath,\n          LocalDirAllocator.SIZE_UNKNOWN, false);\n\n    return containerWorkDir;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getLocalizedResources": "  protected Map<Path, List<String>> getLocalizedResources()\n      throws YarnException {\n    Map<Path, List<String>> localResources = container.getLocalizedResources();\n    if (localResources == null) {\n      throw RPCUtil.getRemoteException(\n          \"Unable to get local resources when Container \" + container\n              + \" is at \" + container.getContainerState());\n    }\n    return localResources;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.recordContainerLogDir": "  private void recordContainerLogDir(ContainerId containerId,\n      String logDir) throws IOException{\n    container.setLogDir(logDir);\n    if (container.isRetryContextSet()) {\n      context.getNMStateStore().storeContainerLogDir(containerId, logDir);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.expandEnvironment": "  public static String expandEnvironment(String var,\n      Path containerLogDir) {\n    var = var.replace(ApplicationConstants.LOG_DIR_EXPANSION_VAR,\n      containerLogDir.toString());\n    var = var.replace(ApplicationConstants.CLASS_PATH_SEPARATOR,\n      File.pathSeparator);\n\n    // replace parameter expansion marker. e.g. {{VAR}} on Windows is replaced\n    // as %VAR% and on Linux replaced as \"$VAR\"\n    if (Shell.WINDOWS) {\n      var = var.replaceAll(\"(\\\\{\\\\{)|(\\\\}\\\\})\", \"%\");\n    } else {\n      var = var.replace(ApplicationConstants.PARAMETER_EXPANSION_LEFT, \"$\");\n      var = var.replace(ApplicationConstants.PARAMETER_EXPANSION_RIGHT, \"\");\n    }\n    return var;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer": "  protected int launchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    ContainerId containerId = container.getContainerId();\n    if (container.isMarkedForKilling()) {\n      LOG.info(\"Container \" + containerId + \" not launched as it has already \"\n          + \"been marked for Killing\");\n      this.killedBeforeStart = true;\n      return ExitCode.TERMINATED.getExitCode();\n    }\n    // LaunchContainer is a blocking call. We are here almost means the\n    // container is launched, so send out the event.\n    dispatcher.getEventHandler().handle(new ContainerEvent(\n        containerId,\n        ContainerEventType.CONTAINER_LAUNCHED));\n    context.getNMStateStore().storeContainerLaunched(containerId);\n\n    // Check if the container is signalled to be killed.\n    if (!containerAlreadyLaunched.compareAndSet(false, true)) {\n      LOG.info(\"Container \" + containerId + \" not launched as \"\n          + \"cleanup already called\");\n      return ExitCode.TERMINATED.getExitCode();\n    } else {\n      exec.activateContainer(containerId, pidFilePath);\n      return exec.launchContainer(ctx);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getNMFilecacheDirs": "  protected List<String> getNMFilecacheDirs(List<String> localDirs) {\n    List<String> filecacheDirs = new ArrayList<>(localDirs.size());\n\n    for (String localDir : localDirs) {\n      String filecacheDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.FILECACHE;\n\n      filecacheDirs.add(filecacheDir);\n    }\n\n    return filecacheDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.sanitizeEnv": "  public void sanitizeEnv(Map<String, String> environment, Path pwd,\n      List<Path> appDirs, List<String> userLocalDirs, List<String>\n      containerLogDirs,\n      Map<Path, List<String>> resources,\n      Path nmPrivateClasspathJarDir) throws IOException {\n    /**\n     * Non-modifiable environment variables\n     */\n\n    environment.put(Environment.CONTAINER_ID.name(), container\n        .getContainerId().toString());\n\n    environment.put(Environment.NM_PORT.name(),\n      String.valueOf(this.context.getNodeId().getPort()));\n\n    environment.put(Environment.NM_HOST.name(), this.context.getNodeId()\n      .getHost());\n\n    environment.put(Environment.NM_HTTP_PORT.name(),\n      String.valueOf(this.context.getHttpPort()));\n\n    environment.put(Environment.LOCAL_DIRS.name(),\n        StringUtils.join(\",\", appDirs));\n\n    environment.put(Environment.LOCAL_USER_DIRS.name(), StringUtils.join(\",\",\n        userLocalDirs));\n\n    environment.put(Environment.LOG_DIRS.name(),\n      StringUtils.join(\",\", containerLogDirs));\n\n    environment.put(Environment.USER.name(), container.getUser());\n    \n    environment.put(Environment.LOGNAME.name(), container.getUser());\n\n    environment.put(Environment.HOME.name(),\n        conf.get(\n            YarnConfiguration.NM_USER_HOME_DIR, \n            YarnConfiguration.DEFAULT_NM_USER_HOME_DIR\n            )\n        );\n    \n    environment.put(Environment.PWD.name(), pwd.toString());\n    \n    putEnvIfAbsent(environment, Environment.HADOOP_CONF_DIR.name());\n\n    if (!Shell.WINDOWS) {\n      environment.put(\"JVM_PID\", \"$$\");\n    }\n\n    // variables here will be forced in, even if the container has specified them.\n    Apps.setEnvFromInputString(environment, conf.get(\n      YarnConfiguration.NM_ADMIN_USER_ENV,\n      YarnConfiguration.DEFAULT_NM_ADMIN_USER_ENV), File.pathSeparator);\n\n    // TODO: Remove Windows check and use this approach on all platforms after\n    // additional testing.  See YARN-358.\n    if (Shell.WINDOWS) {\n\n      sanitizeWindowsEnv(environment, pwd,\n          resources, nmPrivateClasspathJarDir);\n    }\n    // put AuxiliaryService data to environment\n    for (Map.Entry<String, ByteBuffer> meta : containerManager\n        .getAuxServiceMetaData().entrySet()) {\n      AuxiliaryServiceHelper.setServiceDataIntoEnv(\n          meta.getKey(), meta.getValue(), environment);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.validateContainerState": "  protected boolean validateContainerState() {\n    // CONTAINER_KILLED_ON_REQUEST should not be missed if the container\n    // is already at KILLING\n    if (container.getContainerState() == ContainerState.KILLING) {\n      dispatcher.getEventHandler().handle(\n          new ContainerExitEvent(container.getContainerId(),\n              ContainerEventType.CONTAINER_KILLED_ON_REQUEST,\n              Shell.WINDOWS ? ExitCode.FORCE_KILLED.getExitCode() :\n                  ExitCode.TERMINATED.getExitCode(),\n              \"Container terminated before launch.\"));\n      return false;\n    }\n\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.create": "    public static ShellScriptBuilder create() {\n      return Shell.WINDOWS ? new WindowsShellScriptBuilder() :\n        new UnixShellScriptBuilder();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerLocalDirs": "  protected List<String> getContainerLocalDirs(List<String> localDirs) {\n    List<String> containerLocalDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n    String appIdStr = app.getAppId().toString();\n    String relativeContainerLocalDir = ContainerLocalizer.USERCACHE\n        + Path.SEPARATOR + user + Path.SEPARATOR + ContainerLocalizer.APPCACHE\n        + Path.SEPARATOR + appIdStr + Path.SEPARATOR;\n\n    for (String localDir : localDirs) {\n      containerLocalDirs.add(localDir + Path.SEPARATOR\n          + relativeContainerLocalDir);\n    }\n\n    return containerLocalDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.recordContainerWorkDir": "  private void recordContainerWorkDir(ContainerId containerId,\n      String workDir) throws IOException{\n    container.setWorkDir(workDir);\n    if (container.isRetryContextSet()) {\n      context.getNMStateStore().storeContainerWorkDir(containerId, workDir);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getRelativeContainerLogDir": "  public static String getRelativeContainerLogDir(String appIdStr,\n      String containerIdStr) {\n    return appIdStr + Path.SEPARATOR + containerIdStr;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getUserLocalDirs": "  protected List<String> getUserLocalDirs(List<String> localDirs) {\n    List<String> userLocalDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n\n    for (String localDir : localDirs) {\n      String userLocalDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.USERCACHE + Path.SEPARATOR + user\n          + Path.SEPARATOR;\n\n      userLocalDirs.add(userLocalDir);\n    }\n\n    return userLocalDirs;\n  }"
        },
        "bug_report": {
            "Title": "prelaunch.err file not found exception on container failure",
            "Description": "Hit this exception when a container failed:{noformat}2018-01-11 19:04:08,036 ERROR org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Failed to get tail of the container's prelaunch error log file\r\njava.io.FileNotFoundException: File /grid/b/tmp/userlogs/application_1515190594800_1766/container_e39_1515190594800_1766_01_000002/prelaunch.err does not exist\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:641)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:930)\r\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:631)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitWithFailure(ContainerLaunch.java:545)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitCode(ContainerLaunch.java:511)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:319)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:93)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745){noformat}\r\ncontainerLogDir is picked on container launch via {{LocalDirAllocator#getLocalPathForWrite}}, which is where it looks for {{prelaunch.err}} when the container fails. But prelaunch.err (and prelaunch.out) are created in the first log dir (in {{ContainerLaunch#call}}: {noformat}        exec.writeLaunchEnv(containerScriptOutStream, environment,\r\n            localResources, launchContext.getCommands(),\r\n            new Path(containerLogDirs.get(0)), user);{noformat}"
        }
    },
    {
        "filename": "YARN-5136.json",
        "creation_time": "2016-05-24T15:34:28.000+0000",
        "stack_trace": "```\njava.lang.IllegalStateException: Given app to remove org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt@ea94c3b does not exist in queue [root.bdp_xx.bdp_mart_xx_formal, demand=<memory:28672000, vCores:14000>, running=<memory:28647424, vCores:13422>, share=<memory:28672000, vCores:0>, w=<memory weight=1.0, cpu weight=1.0>]\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.removeApp(FSLeafQueue.java:119)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt(FairScheduler.java:779)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1231)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:114)\n    at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:680)\n    at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.removeApp": "  public boolean removeApp(FSAppAttempt app) {\n    boolean runnable = false;\n\n    // Remove app from runnable/nonRunnable list while holding the write lock\n    writeLock.lock();\n    try {\n      runnable = runnableApps.remove(app);\n      if (!runnable) {\n        // removeNonRunnableApp acquires the write lock again, which is fine\n        if (!removeNonRunnableApp(app)) {\n          throw new IllegalStateException(\"Given app to remove \" + app +\n              \" does not exist in queue \" + this);\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n\n    // Update AM resource usage if needed. If isAMRunning is true, we're not\n    // running an unmanaged AM.\n    if (runnable && app.isAmRunning()) {\n      Resources.subtractFrom(amResourceUsage, app.getAMResource());\n    }\n\n    return runnable;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.removeNonRunnableApp": "  public boolean removeNonRunnableApp(FSAppAttempt app) {\n    writeLock.lock();\n    try {\n      return nonRunnableApps.remove(app);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt": "  private synchronized void removeApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    LOG.info(\"Application \" + applicationAttemptId + \" is done.\" +\n        \" finalState=\" + rmAppAttemptFinalState);\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    FSAppAttempt attempt = getSchedulerApp(applicationAttemptId);\n\n    if (attempt == null || application == null) {\n      LOG.info(\"Unknown application \" + applicationAttemptId + \" has completed!\");\n      return;\n    }\n\n    // Release all the running containers\n    for (RMContainer rmContainer : attempt.getLiveContainers()) {\n      if (keepContainers\n          && rmContainer.getState().equals(RMContainerState.RUNNING)) {\n        // do not kill the running container in the case of work-preserving AM\n        // restart.\n        LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n        continue;\n      }\n      super.completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              SchedulerUtils.COMPLETED_APPLICATION),\n              RMContainerEventType.KILL);\n    }\n\n    // Release all reserved containers\n    for (RMContainer rmContainer : attempt.getReservedContainers()) {\n      super.completedContainer(rmContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              rmContainer.getContainerId(),\n              \"Application Complete\"),\n              RMContainerEventType.KILL);\n    }\n    // Clean up pending requests, metrics etc.\n    attempt.stop(rmAppAttemptFinalState);\n\n    // Inform the queue\n    FSLeafQueue queue = queueMgr.getLeafQueue(attempt.getQueue()\n        .getQueueName(), false);\n    boolean wasRunnable = queue.removeApp(attempt);\n\n    if (wasRunnable) {\n      maxRunningEnforcer.untrackRunnableApp(attempt);\n      maxRunningEnforcer.updateRunnabilityOnAppRemoval(attempt,\n          attempt.getQueue());\n    } else {\n      maxRunningEnforcer.untrackNonRunnableApp(attempt);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getSchedulerApp": "  public FSAppAttempt getSchedulerApp(ApplicationAttemptId appAttemptId) {\n    return super.getApplicationAttempt(appAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getContainerReports(),\n          nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID(),\n              appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName, appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n      break;\n    case NODE_RESOURCE_UPDATE:\n      if (!(event instanceof NodeResourceUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeResource(nodeResourceUpdatedEvent.getRMNode(),\n            nodeResourceUpdatedEvent.getResourceOption());\n      break;\n    case APP_ATTEMPT_ADDED:\n      if (!(event instanceof AppAttemptAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n      break;\n    case APP_ATTEMPT_REMOVED:\n      if (!(event instanceof AppAttemptRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      removeApplicationAttempt(\n          appAttemptRemovedEvent.getApplicationAttemptID(),\n          appAttemptRemovedEvent.getFinalAttemptState(),\n          appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      super.completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addNode": "  private synchronized void addNode(List<NMContainerStatus> containerReports,\n      RMNode node) {\n    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, usePortForNodeName);\n    nodeTracker.addNode(schedulerNode);\n\n    triggerUpdate();\n\n    Resource clusterResource = getClusterResource();\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n    LOG.info(\"Added node \" + node.getNodeAddress() +\n        \" cluster capacity: \" + clusterResource);\n\n    recoverContainersOnNode(containerReports, node);\n    updateRootQueueMetrics();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected synchronized void addApplication(ApplicationId applicationId,\n      String queueName, String user, boolean isAppRecovering) {\n    if (queueName == null || queueName.isEmpty()) {\n      String message = \"Reject application \" + applicationId +\n              \" submitted by user \" + user + \" with an empty queue name.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppEvent(applicationId,\n              RMAppEventType.APP_REJECTED, message));\n      return;\n    }\n\n    if (queueName.startsWith(\".\") || queueName.endsWith(\".\")) {\n      String message = \"Reject application \" + applicationId\n          + \" submitted by user \" + user + \" with an illegal queue name \"\n          + queueName + \". \"\n          + \"The queue name cannot start/end with period.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppEvent(applicationId,\n              RMAppEventType.APP_REJECTED, message));\n      return;\n    }\n\n    RMApp rmApp = rmContext.getRMApps().get(applicationId);\n    FSLeafQueue queue = assignToQueue(rmApp, queueName, user);\n    if (queue == null) {\n      return;\n    }\n\n    // Enforce ACLs\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n\n    if (!queue.hasAccess(QueueACL.SUBMIT_APPLICATIONS, userUgi)\n        && !queue.hasAccess(QueueACL.ADMINISTER_QUEUE, userUgi)) {\n      String msg = \"User \" + userUgi.getUserName() +\n              \" cannot submit applications to queue \" + queue.getName() +\n              \"(requested queuename is \" + queueName + \")\";\n      LOG.info(msg);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppEvent(applicationId,\n              RMAppEventType.APP_REJECTED, msg));\n      return;\n    }\n  \n    SchedulerApplication<FSAppAttempt> application =\n        new SchedulerApplication<FSAppAttempt>(queue, user);\n    applications.put(applicationId, application);\n    queue.getMetrics().submitApp(user);\n\n    LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n        + \", in queue: \" + queueName + \", currently num of applications: \"\n        + applications.size());\n    if (isAppRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler()\n        .handle(new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start = getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node = getFSSchedulerNode(nm.getNodeID());\n    \n    List<UpdatedContainerInfo> containerInfoList = nm.pullContainerUpdates();\n    List<ContainerStatus> newlyLaunchedContainers = new ArrayList<ContainerStatus>();\n    List<ContainerStatus> completedContainers = new ArrayList<ContainerStatus>();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() == NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration = getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication": "  private synchronized void removeApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationId);\n    if (application == null){\n      LOG.warn(\"Couldn't find application \" + applicationId);\n      return;\n    }\n    application.stop(finalState);\n    applications.remove(applicationId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.resolveReservationQueueName": "  private synchronized String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID,\n      boolean isRecovering) {\n    FSQueue queue = queueMgr.getQueue(queueName);\n    if ((queue == null) || !allocConf.isReservable(queue.getQueueName())) {\n      return queueName;\n    }\n    // Use fully specified name from now on (including root. prefix)\n    queueName = queue.getQueueName();\n    if (reservationID != null) {\n      String resQName = queueName + \".\" + reservationID.toString();\n      queue = queueMgr.getQueue(resQName);\n      if (queue == null) {\n        // reservation has terminated during failover\n        if (isRecovering && allocConf.getMoveOnExpiry(queueName)) {\n          // move to the default child queue of the plan\n          return getDefaultQueueForPlanQueue(queueName);\n        }\n        String message =\n            \"Application \"\n                + applicationId\n                + \" submitted to a reservation which is not yet currently active: \"\n                + resQName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppEvent(applicationId,\n                RMAppEventType.APP_REJECTED, message));\n        return null;\n      }\n      if (!queue.getParent().getQueueName().equals(queueName)) {\n        String message =\n            \"Application: \" + applicationId + \" submitted to a reservation \"\n                + resQName + \" which does not belong to the specified queue: \"\n                + queueName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppEvent(applicationId,\n                RMAppEventType.APP_REJECTED, message));\n        return null;\n      }\n      // use the reservation queue to run the app\n      queueName = resQName;\n    } else {\n      // use the default child queue of the plan for unreserved apps\n      queueName = getDefaultQueueForPlanQueue(queueName);\n    }\n    return queueName;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateNodeResource": "  public synchronized void updateNodeResource(RMNode nm, \n      ResourceOption resourceOption) {\n    super.updateNodeResource(nm, resourceOption);\n    updateRootQueueMetrics();\n    queueMgr.getRootQueue().setSteadyFairShare(getClusterResource());\n    queueMgr.getRootQueue().recomputeSteadyShares();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplicationAttempt": "  protected synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FSAppAttempt> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    String user = application.getUser();\n    FSLeafQueue queue = (FSLeafQueue) application.getQueue();\n\n    FSAppAttempt attempt =\n        new FSAppAttempt(this, applicationAttemptId, user,\n            queue, new ActiveUsersManager(getRootQueueMetrics()),\n            rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n          .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    boolean runnable = maxRunningEnforcer.canAppBeRunnable(queue, user);\n    queue.addApp(attempt, runnable);\n    if (runnable) {\n      maxRunningEnforcer.trackRunnableApp(attempt);\n    } else {\n      maxRunningEnforcer.trackNonRunnableApp(attempt);\n    }\n    \n    queue.getMetrics().submitAppAttempt(user);\n\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user: \" + user);\n\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeNode": "  private synchronized void removeNode(RMNode rmNode) {\n    NodeId nodeId = rmNode.getNodeID();\n    FSSchedulerNode node = nodeTracker.getNode(nodeId);\n    if (node == null) {\n      LOG.error(\"Attempting to remove non-existent node \" + nodeId);\n      return;\n    }\n\n    // Remove running containers\n    List<RMContainer> runningContainers =\n        node.getCopiedListOfRunningContainers();\n    for (RMContainer container : runningContainers) {\n      super.completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    // Remove reservations, if any\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      super.completedContainer(reservedContainer,\n          SchedulerUtils.createAbnormalContainerStatus(\n              reservedContainer.getContainerId(),\n              SchedulerUtils.LOST_CONTAINER),\n          RMContainerEventType.KILL);\n    }\n\n    nodeTracker.removeNode(nodeId);\n    Resource clusterResource = getClusterResource();\n    queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n    queueMgr.getRootQueue().recomputeSteadyShares();\n    updateRootQueueMetrics();\n    triggerUpdate();\n\n    LOG.info(\"Removed node \" + rmNode.getNodeAddress() +\n        \" cluster capacity: \" + clusterResource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices(true);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getQueue": "  public FSLeafQueue getQueue() {\n    return (FSLeafQueue)super.getQueue();\n  }"
        },
        "bug_report": {
            "Title": "Error in handling event type APP_ATTEMPT_REMOVED to the scheduler",
            "Description": "move app cause rm exit\n{noformat}\n2016-05-24 23:20:47,202 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type APP_ATTEMPT_REMOVED to the scheduler\njava.lang.IllegalStateException: Given app to remove org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt@ea94c3b does not exist in queue [root.bdp_xx.bdp_mart_xx_formal, demand=<memory:28672000, vCores:14000>, running=<memory:28647424, vCores:13422>, share=<memory:28672000, vCores:0>, w=<memory weight=1.0, cpu weight=1.0>]\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.removeApp(FSLeafQueue.java:119)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt(FairScheduler.java:779)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1231)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:114)\n    at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:680)\n    at java.lang.Thread.run(Thread.java:745)\n2016-05-24 23:20:47,202 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_e04_1464073905025_15410_01_001759 Container Transitioned from ACQUIRED to RELEASED\n2016-05-24 23:20:47,202 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Exiting, bbye..\n{noformat}"
        }
    },
    {
        "filename": "YARN-8211.json",
        "creation_time": "2018-04-26T02:13:22.000+0000",
        "stack_trace": "```\njava.nio.BufferUnderflowException\n\n        at java.nio.Buffer.nextGetIndex(Buffer.java:500)\n\n        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:135)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS.getMessgeLength(RegistryDNS.java:820)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS.nioTCPClient(RegistryDNS.java:767)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS$3.call(RegistryDNS.java:846)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS$3.call(RegistryDNS.java:843)\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\n        at java.lang.Thread.run(Thread.java:748)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.server.dns.RegistryDNS.getMessgeLength": "  private int getMessgeLength(ByteBuffer buf) throws EOFException {\n    int ch1 = buf.get();\n    int ch2 = buf.get();\n    if ((ch1 | ch2) < 0) {\n      throw new EOFException();\n    }\n    return (ch1 << 8) + (ch2 & 0xff);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.server.dns.RegistryDNS.nioTCPClient": "  public void nioTCPClient(SocketChannel ch) throws IOException {\n    try {\n      // query sizes are small, so the following two lines should work\n      // in all instances\n      ByteBuffer buf = ByteBuffer.allocate(1024);\n      ch.read(buf);\n      buf.flip();\n      int messageLength = getMessgeLength(buf);\n\n      byte[] in = new byte[messageLength];\n\n      buf.get(in, 0, messageLength);\n\n      Message query;\n      byte[] response;\n      try {\n        query = new Message(in);\n        LOG.info(\"received TCP query {}\", query.getQuestion());\n        response = generateReply(query, ch.socket());\n        if (response == null) {\n          return;\n        }\n      } catch (IOException e) {\n        response = formErrorMessage(in);\n      }\n\n      ByteBuffer out = ByteBuffer.allocate(response.length + 2);\n      out.clear();\n      byte[] data = new byte[2];\n\n      data[1] = (byte)(response.length & 0xFF);\n      data[0] = (byte)((response.length >> 8) & 0xFF);\n      out.put(data);\n      out.put(response);\n      out.flip();\n\n      while(out.hasRemaining()) {\n        ch.write(out);\n      }\n\n    } catch (IOException e) {\n      throw NetUtils.wrapException(ch.socket().getInetAddress().getHostName(),\n          ch.socket().getPort(),\n          ch.socket().getLocalAddress().getHostName(),\n          ch.socket().getLocalPort(), e);\n    } finally {\n      IOUtils.closeStream(ch);\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.server.dns.RegistryDNS.generateReply": "  byte[] generateReply(Message query, Socket s)\n      throws IOException {\n    Header header;\n    boolean badversion;\n    int maxLength;\n    int flags = 0;\n\n    OPTRecord queryOPT = query.getOPT();\n    maxLength = getMaxLength(s, queryOPT);\n\n    header = query.getHeader();\n    if (header.getFlag(Flags.QR)) {\n      LOG.debug(\"returning null\");\n      return null;\n    }\n    if (header.getRcode() != Rcode.NOERROR) {\n      return errorMessage(query, Rcode.FORMERR);\n    }\n    if (header.getOpcode() != Opcode.QUERY) {\n      return errorMessage(query, Rcode.NOTIMP);\n    }\n\n    Record queryRecord = query.getQuestion();\n\n    if (queryOPT != null && (queryOPT.getFlags() & ExtendedFlags.DO) != 0) {\n      flags = FLAG_DNSSECOK;\n    }\n\n    Message response = new Message(query.getHeader().getID());\n    response.getHeader().setFlag(Flags.QR);\n    if (query.getHeader().getFlag(Flags.RD)) {\n      response.getHeader().setFlag(Flags.RD);\n      response.getHeader().setFlag(Flags.RA);\n    }\n    response.addRecord(queryRecord, Section.QUESTION);\n\n    Name name = queryRecord.getName();\n    int type = queryRecord.getType();\n    int dclass = queryRecord.getDClass();\n\n    TSIGRecord queryTSIG = query.getTSIG();\n    if (type == Type.AXFR && s != null) {\n      return doAXFR(name, query, null, queryTSIG, s);\n    }\n    if (!Type.isRR(type) && type != Type.ANY) {\n      return errorMessage(query, Rcode.NOTIMP);\n    }\n\n    LOG.debug(\"calling addAnswer\");\n    byte rcode = addAnswer(response, name, type, dclass, 0, flags);\n    if (rcode != Rcode.NOERROR) {\n      rcode = remoteLookup(response, name, 0);\n      response.getHeader().setRcode(rcode);\n    }\n    addAdditional(response, flags);\n\n    if (queryOPT != null) {\n      int optflags = (flags == FLAG_DNSSECOK) ? ExtendedFlags.DO : 0;\n      OPTRecord opt = new OPTRecord((short) 4096, rcode >>> 16, (byte) 0,\n          optflags);\n      response.addRecord(opt, Section.ADDITIONAL);\n    }\n\n    return response.toWire(maxLength);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.server.dns.RegistryDNS.formErrorMessage": "  public byte[] formErrorMessage(byte[] in) {\n    Header header;\n    try {\n      header = new Header(in);\n    } catch (IOException e) {\n      return null;\n    }\n    return buildErrorMessage(header, Rcode.FORMERR, null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.server.dns.RegistryDNS.call": "      public Boolean call() throws Exception {\n        try {\n          serveNIOUDP(udpChannel, addr, port);\n        } catch (Exception e) {\n          LOG.error(\"Error initializing DNS UDP listener\", e);\n          throw e;\n        }\n        return true;\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.server.dns.RegistryDNS.serveNIOTCP": "  public void serveNIOTCP(ServerSocketChannel serverSocketChannel,\n      InetAddress addr, int port) throws Exception {\n    try {\n\n      while (true) {\n        final SocketChannel socketChannel = serverSocketChannel.accept();\n        if (socketChannel != null) {\n          executor.submit(new Callable<Boolean>() {\n            @Override\n            public Boolean call() throws Exception {\n              nioTCPClient(socketChannel);\n              return true;\n            }\n          });\n\n        } else {\n          Thread.sleep(500);\n        }\n      }\n    } catch (IOException e) {\n      throw NetUtils.wrapException(addr.getHostName(), port,\n          addr.getHostName(), port, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-registry.src.main.java.org.apache.hadoop.registry.server.dns.RegistryDNS.serveNIOUDP": "  private void serveNIOUDP(DatagramChannel channel,\n      InetAddress addr, int port) throws Exception {\n    SocketAddress remoteAddress = null;\n    try {\n\n      ByteBuffer input = ByteBuffer.allocate(4096);\n      ByteBuffer output = ByteBuffer.allocate(4096);\n      byte[] in = null;\n\n      while (true) {\n        input.clear();\n        try {\n          remoteAddress = channel.receive(input);\n        } catch (IOException e) {\n          LOG.debug(\"Error during message receipt\", e);\n          continue;\n        }\n        Message query;\n        byte[] response = null;\n        try {\n          int position = input.position();\n          in = new byte[position];\n          input.flip();\n          input.get(in);\n          query = new Message(in);\n          LOG.info(\"{}: received UDP query {}\", remoteAddress,\n              query.getQuestion());\n          response = generateReply(query, null);\n          if (response == null) {\n            continue;\n          }\n        } catch (IOException e) {\n          response = formErrorMessage(in);\n        }\n        output.clear();\n        output.put(response);\n        output.flip();\n\n        LOG.debug(\"{}:  sending response\", remoteAddress);\n        channel.send(output, remoteAddress);\n      }\n    } catch (Exception e) {\n      if (e instanceof IOException && remoteAddress != null) {\n        throw NetUtils.wrapException(addr.getHostName(),\n            port,\n            ((InetSocketAddress) remoteAddress).getHostName(),\n            ((InetSocketAddress) remoteAddress).getPort(),\n            (IOException) e);\n      } else {\n        throw e;\n      }\n    }\n  }"
        },
        "bug_report": {
            "Title": "Yarn registry dns log finds BufferUnderflowException on port ping",
            "Description": "Yarn registry dns server is constantly getting BufferUnderflowException. \r\n{code:java}\r\n2018-04-25 01:36:56,139 WARN\u00a0 concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(50)) - Execution exception when running task in RegistryDNS 76\r\n\r\n2018-04-25 01:36:56,139 WARN\u00a0 concurrent.ExecutorHelper (ExecutorHelper.java:logThrowableFromAfterExecute(63)) - Caught exception in thread RegistryDNS 76:\r\n\r\njava.nio.BufferUnderflowException\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.nio.Buffer.nextGetIndex(Buffer.java:500)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:135)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.registry.server.dns.RegistryDNS.getMessgeLength(RegistryDNS.java:820)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.registry.server.dns.RegistryDNS.nioTCPClient(RegistryDNS.java:767)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.registry.server.dns.RegistryDNS$3.call(RegistryDNS.java:846)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.registry.server.dns.RegistryDNS$3.call(RegistryDNS.java:843)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(Thread.java:748){code}\r\n\u00a0"
        }
    },
    {
        "filename": "YARN-2124.json",
        "creation_time": "2014-06-05T07:44:27.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.util.resource.Resources.greaterThan(Resources.java:225)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.computeIdealResourceDistribution(ProportionalCapacityPreemptionPolicy.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.recursivelyComputeIdealAssignment(ProportionalCapacityPreemptionPolicy.java:261)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.containerBasedPreemptOrKill(ProportionalCapacityPreemptionPolicy.java:198)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.editSchedule(ProportionalCapacityPreemptionPolicy.java:174)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor.invokePolicy(SchedulingMonitor.java:72)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor$PreemptionChecker.run(SchedulingMonitor.java:82)\n        at java.lang.Thread.run(Thread.java:744)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.resource.Resources.greaterThan": "  public static boolean greaterThan(\n      ResourceCalculator resourceCalculator,\n      Resource clusterResource,\n      Resource lhs, Resource rhs) {\n    return resourceCalculator.compare(clusterResource, lhs, rhs) > 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.computeIdealResourceDistribution": "  private void computeIdealResourceDistribution(ResourceCalculator rc,\n      List<TempQueue> queues, Resource totalPreemptionAllowed, Resource tot_guarant) {\n\n    // qAlloc tracks currently active queues (will decrease progressively as\n    // demand is met)\n    List<TempQueue> qAlloc = new ArrayList<TempQueue>(queues);\n    // unassigned tracks how much resources are still to assign, initialized\n    // with the total capacity for this set of queues\n    Resource unassigned = Resources.clone(tot_guarant);\n\n    // group queues based on whether they have non-zero guaranteed capacity\n    Set<TempQueue> nonZeroGuarQueues = new HashSet<TempQueue>();\n    Set<TempQueue> zeroGuarQueues = new HashSet<TempQueue>();\n\n    for (TempQueue q : qAlloc) {\n      if (Resources\n          .greaterThan(rc, tot_guarant, q.guaranteed, Resources.none())) {\n        nonZeroGuarQueues.add(q);\n      } else {\n        zeroGuarQueues.add(q);\n      }\n    }\n\n    // first compute the allocation as a fixpoint based on guaranteed capacity\n    computeFixpointAllocation(rc, tot_guarant, nonZeroGuarQueues, unassigned,\n        false);\n\n    // if any capacity is left unassigned, distributed among zero-guarantee \n    // queues uniformly (i.e., not based on guaranteed capacity, as this is zero)\n    if (!zeroGuarQueues.isEmpty()\n        && Resources.greaterThan(rc, tot_guarant, unassigned, Resources.none())) {\n      computeFixpointAllocation(rc, tot_guarant, zeroGuarQueues, unassigned,\n          true);\n    }\n    \n    // based on ideal assignment computed above and current assignment we derive\n    // how much preemption is required overall\n    Resource totPreemptionNeeded = Resource.newInstance(0, 0);\n    for (TempQueue t:queues) {\n      if (Resources.greaterThan(rc, tot_guarant, t.current, t.idealAssigned)) {\n        Resources.addTo(totPreemptionNeeded,\n            Resources.subtract(t.current, t.idealAssigned));\n      }\n    }\n\n    // if we need to preempt more than is allowed, compute a factor (0<f<1)\n    // that is used to scale down how much we ask back from each queue\n    float scalingFactor = 1.0F;\n    if (Resources.greaterThan(rc, tot_guarant,\n          totPreemptionNeeded, totalPreemptionAllowed)) {\n       scalingFactor = Resources.divide(rc, tot_guarant,\n           totalPreemptionAllowed, totPreemptionNeeded);\n    }\n\n    // assign to each queue the amount of actual preemption based on local\n    // information of ideal preemption and scaling factor\n    for (TempQueue t : queues) {\n      t.assignPreemption(scalingFactor, rc, tot_guarant);\n    }\n    if (LOG.isDebugEnabled()) {\n      long time = clock.getTime();\n      for (TempQueue t : queues) {\n        LOG.debug(time + \": \" + t);\n      }\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.computeFixpointAllocation": "  private void computeFixpointAllocation(ResourceCalculator rc,\n      Resource tot_guarant, Collection<TempQueue> qAlloc, Resource unassigned, \n      boolean ignoreGuarantee) {\n    //assign all cluster resources until no more demand, or no resources are left\n    while (!qAlloc.isEmpty() && Resources.greaterThan(rc, tot_guarant,\n          unassigned, Resources.none())) {\n      Resource wQassigned = Resource.newInstance(0, 0);\n\n      // we compute normalizedGuarantees capacity based on currently active\n      // queues\n      resetCapacity(rc, unassigned, qAlloc, ignoreGuarantee);\n      \n      // offer for each queue their capacity first and in following invocations\n      // their share of over-capacity\n      for (Iterator<TempQueue> i = qAlloc.iterator(); i.hasNext();) {\n        TempQueue sub = i.next();\n        Resource wQavail =\n          Resources.multiply(unassigned, sub.normalizedGuarantee);\n        Resource wQidle = sub.offer(wQavail, rc, tot_guarant);\n        Resource wQdone = Resources.subtract(wQavail, wQidle);\n        // if the queue returned a value > 0 it means it is fully satisfied\n        // and it is removed from the list of active queues qAlloc\n        if (!Resources.greaterThan(rc, tot_guarant,\n              wQdone, Resources.none())) {\n          i.remove();\n        }\n        Resources.addTo(wQassigned, wQdone);\n      }\n      Resources.subtractFrom(unassigned, wQassigned);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.assignPreemption": "    public void assignPreemption(float scalingFactor,\n        ResourceCalculator rc, Resource clusterResource) {\n      if (Resources.greaterThan(rc, clusterResource, current, idealAssigned)) {\n          toBePreempted = Resources.multiply(\n              Resources.subtract(current, idealAssigned), scalingFactor);\n      } else {\n        toBePreempted = Resource.newInstance(0, 0);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.recursivelyComputeIdealAssignment": "  private List<TempQueue> recursivelyComputeIdealAssignment(\n      TempQueue root, Resource totalPreemptionAllowed) {\n    List<TempQueue> leafs = new ArrayList<TempQueue>();\n    if (root.getChildren() != null &&\n        root.getChildren().size() > 0) {\n      // compute ideal distribution at this level\n      computeIdealResourceDistribution(rc, root.getChildren(),\n          totalPreemptionAllowed, root.idealAssigned);\n      // compute recursively for lower levels and build list of leafs\n      for(TempQueue t : root.getChildren()) {\n        leafs.addAll(recursivelyComputeIdealAssignment(t, totalPreemptionAllowed));\n      }\n    } else {\n      // we are in a leaf nothing to do, just return yourself\n      return Collections.singletonList(root);\n    }\n    return leafs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.getChildren": "    public ArrayList<TempQueue> getChildren(){\n      return children;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.containerBasedPreemptOrKill": "  private void containerBasedPreemptOrKill(CSQueue root,\n      Resource clusterResources) {\n\n    // extract a summary of the queues from scheduler\n    TempQueue tRoot;\n    synchronized (scheduler) {\n      tRoot = cloneQueues(root, clusterResources);\n    }\n\n    // compute the ideal distribution of resources among queues\n    // updates cloned queues state accordingly\n    tRoot.idealAssigned = tRoot.guaranteed;\n    Resource totalPreemptionAllowed = Resources.multiply(clusterResources,\n        percentageClusterPreemptionAllowed);\n    List<TempQueue> queues =\n      recursivelyComputeIdealAssignment(tRoot, totalPreemptionAllowed);\n\n    // based on ideal allocation select containers to be preempted from each\n    // queue and each application\n    Map<ApplicationAttemptId,Set<RMContainer>> toPreempt =\n        getContainersToPreempt(queues, clusterResources);\n\n    logToCSV(queues);\n\n    // if we are in observeOnly mode return before any action is taken\n    if (observeOnly) {\n      return;\n    }\n\n    // preempt (or kill) the selected containers\n    for (Map.Entry<ApplicationAttemptId,Set<RMContainer>> e\n         : toPreempt.entrySet()) {\n      for (RMContainer container : e.getValue()) {\n        // if we tried to preempt this for more than maxWaitTime\n        if (preempted.get(container) != null &&\n            preempted.get(container) + maxWaitTime < clock.getTime()) {\n          // kill it\n          dispatcher.handle(new ContainerPreemptEvent(e.getKey(), container,\n                ContainerPreemptEventType.KILL_CONTAINER));\n          preempted.remove(container);\n        } else {\n          //otherwise just send preemption events\n          dispatcher.handle(new ContainerPreemptEvent(e.getKey(), container,\n                ContainerPreemptEventType.PREEMPT_CONTAINER));\n          if (preempted.get(container) == null) {\n            preempted.put(container, clock.getTime());\n          }\n        }\n      }\n    }\n\n    // Keep the preempted list clean\n    for (Iterator<RMContainer> i = preempted.keySet().iterator(); i.hasNext();){\n      RMContainer id = i.next();\n      // garbage collect containers that are irrelevant for preemption\n      if (preempted.get(id) + 2 * maxWaitTime < clock.getTime()) {\n        i.remove();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.logToCSV": "  private void logToCSV(List<TempQueue> unorderedqueues){\n    List<TempQueue> queues = new ArrayList<TempQueue>(unorderedqueues);\n    Collections.sort(queues, new Comparator<TempQueue>(){\n      @Override\n      public int compare(TempQueue o1, TempQueue o2) {\n        return o1.queueName.compareTo(o2.queueName);\n      }});\n    String queueState = \" QUEUESTATE: \" + clock.getTime();\n    StringBuilder sb = new StringBuilder();\n    sb.append(queueState);\n    for (TempQueue tq : queues) {\n      sb.append(\", \");\n      tq.appendLogString(sb);\n    }\n    LOG.info(sb.toString());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.cloneQueues": "  private TempQueue cloneQueues(CSQueue root, Resource clusterResources) {\n    TempQueue ret;\n    synchronized (root) {\n      String queueName = root.getQueueName();\n      float absUsed = root.getAbsoluteUsedCapacity();\n      float absCap = root.getAbsoluteCapacity();\n      float absMaxCap = root.getAbsoluteMaximumCapacity();\n\n      Resource current = Resources.multiply(clusterResources, absUsed);\n      Resource guaranteed = Resources.multiply(clusterResources, absCap);\n      Resource maxCapacity = Resources.multiply(clusterResources, absMaxCap);\n      if (root instanceof LeafQueue) {\n        LeafQueue l = (LeafQueue) root;\n        Resource pending = l.getTotalResourcePending();\n        ret = new TempQueue(queueName, current, pending, guaranteed,\n            maxCapacity);\n\n        ret.setLeafQueue(l);\n      } else {\n        Resource pending = Resource.newInstance(0, 0);\n        ret = new TempQueue(root.getQueueName(), current, pending, guaranteed,\n            maxCapacity);\n        for (CSQueue c : root.getChildQueues()) {\n          ret.addChild(cloneQueues(c, clusterResources));\n        }\n      }\n    }\n    return ret;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.getContainersToPreempt": "  private Map<ApplicationAttemptId,Set<RMContainer>> getContainersToPreempt(\n      List<TempQueue> queues, Resource clusterResource) {\n\n    Map<ApplicationAttemptId,Set<RMContainer>> list =\n        new HashMap<ApplicationAttemptId,Set<RMContainer>>();\n\n    for (TempQueue qT : queues) {\n      // we act only if we are violating balance by more than\n      // maxIgnoredOverCapacity\n      if (Resources.greaterThan(rc, clusterResource, qT.current,\n          Resources.multiply(qT.guaranteed, 1.0 + maxIgnoredOverCapacity))) {\n        // we introduce a dampening factor naturalTerminationFactor that\n        // accounts for natural termination of containers\n        Resource resToObtain =\n          Resources.multiply(qT.toBePreempted, naturalTerminationFactor);\n\n        // lock the leafqueue while we scan applications and unreserve\n        synchronized(qT.leafQueue) {\n          NavigableSet<FiCaSchedulerApp> ns =\n            (NavigableSet<FiCaSchedulerApp>) qT.leafQueue.getApplications();\n          Iterator<FiCaSchedulerApp> desc = ns.descendingIterator();\n          qT.actuallyPreempted = Resources.clone(resToObtain);\n          while (desc.hasNext()) {\n            FiCaSchedulerApp fc = desc.next();\n            if (Resources.lessThanOrEqual(rc, clusterResource,\n                resToObtain, Resources.none())) {\n              break;\n            }\n            list.put(fc.getApplicationAttemptId(),\n            preemptFrom(fc, clusterResource, resToObtain));\n          }\n        }\n      }\n    }\n    return list;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.editSchedule": "  public void editSchedule(){\n    CSQueue root = scheduler.getRootQueue();\n    Resource clusterResources =\n      Resources.clone(scheduler.getClusterResource());\n    containerBasedPreemptOrKill(root, clusterResources);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor.invokePolicy": "  public void invokePolicy(){\n    scheduleEditPolicy.editSchedule();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor.run": "    public void run() {\n      while (!stopped && !Thread.currentThread().isInterrupted()) {\n        //invoke the preemption policy at a regular pace\n        //the policy will generate preemption or kill events\n        //managed by the dispatcher\n        invokePolicy();\n        try {\n          Thread.sleep(monitorInterval);\n        } catch (InterruptedException e) {\n          LOG.info(getName() + \" thread interrupted\");\n          break;\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.util.resource.resourceCalculator.compare": "  public abstract int \n  compare(Resource clusterResource, Resource lhs, Resource rhs);\n  \n  public static int divideAndCeil(int a, int b) {\n    if (b == 0) {\n      LOG.info(\"divideAndCeil called with a=\" + a + \" b=\" + b);\n      return 0;\n    }\n    return (a + (b - 1)) / b;\n  }"
        },
        "bug_report": {
            "Title": "ProportionalCapacityPreemptionPolicy cannot work because it's initialized before scheduler initialized",
            "Description": "When I play with scheduler with preemption, I found ProportionalCapacityPreemptionPolicy cannot work. NPE will be raised when RM start\n{code}\n2014-06-05 11:01:33,201 ERROR org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[SchedulingMonitor (ProportionalCapacityPreemptionPolicy),5,main] threw an Exception.\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.util.resource.Resources.greaterThan(Resources.java:225)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.computeIdealResourceDistribution(ProportionalCapacityPreemptionPolicy.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.recursivelyComputeIdealAssignment(ProportionalCapacityPreemptionPolicy.java:261)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.containerBasedPreemptOrKill(ProportionalCapacityPreemptionPolicy.java:198)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.editSchedule(ProportionalCapacityPreemptionPolicy.java:174)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor.invokePolicy(SchedulingMonitor.java:72)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor$PreemptionChecker.run(SchedulingMonitor.java:82)\n        at java.lang.Thread.run(Thread.java:744)\n{code}\n\nThis is caused by ProportionalCapacityPreemptionPolicy needs ResourceCalculator from CapacityScheduler. But ProportionalCapacityPreemptionPolicy get initialized before CapacityScheduler initialized. So ResourceCalculator will set to null in ProportionalCapacityPreemptionPolicy. "
        }
    },
    {
        "filename": "YARN-7849.json",
        "creation_time": "2018-01-29T23:49:33.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: Containers Utillization not propagated to RMNode expected:<<pmem:1024, vmem:2048, vCores:11.0>> but was:<null>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:743)\n\tat org.junit.Assert.assertEquals(Assert.java:118)\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.verifySimulatedUtilization(TestMiniYarnClusterNodeUtilization.java:227)\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.testUpdateNodeUtilization(TestMiniYarnClusterNodeUtilization.java:116)\n```",
        "source_code": {},
        "bug_report": {
            "Title": "TestMiniYarnClusterNodeUtilization#testUpdateNodeUtilization fails due to heartbeat sync error",
            "Description": "testUpdateNodeUtilization is failing.  From a branch-2.8 run:\r\n{noformat}\r\nTests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 13.013 sec <<< FAILURE! - in org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization\r\ntestUpdateNodeUtilization(org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization)  Time elapsed: 12.961 sec  <<< FAILURE!\r\njava.lang.AssertionError: Containers Utillization not propagated to RMNode expected:<<pmem:1024, vmem:2048, vCores:11.0>> but was:<null>\r\n\tat org.junit.Assert.fail(Assert.java:88)\r\n\tat org.junit.Assert.failNotEquals(Assert.java:743)\r\n\tat org.junit.Assert.assertEquals(Assert.java:118)\r\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.verifySimulatedUtilization(TestMiniYarnClusterNodeUtilization.java:227)\r\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.testUpdateNodeUtilization(TestMiniYarnClusterNodeUtilization.java:116)\r\n{noformat}\r\n"
        }
    },
    {
        "filename": "YARN-8591.json",
        "creation_time": "2018-07-27T05:56:26.000+0000",
        "stack_trace": "```\njavax.ws.rs.WebApplicationException: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.handleException(TimelineReaderWebServices.java:196)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:624)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:474)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.security.TimelineReaderWhitelistAuthorizationFilter.doFilter(TimelineReaderWhitelistAuthorizationFilter.java:85)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:98)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1604)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n        at org.eclipse.jetty.server.Server.handle(Server.java:534)\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\nCaused by: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccess(TimelineReaderWebServices.java:3536)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccessForGenericEntities(TimelineReaderWebServices.java:3513)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:622)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.handleException": "  private static void handleException(Exception e, String url, long startTime,\n      String invalidNumMsg) throws BadRequestException,\n      WebApplicationException {\n    long endTime = Time.monotonicNow();\n    LOG.info(\"Processed URL \" + url + \" but encountered exception (Took \" +\n        (endTime - startTime) + \" ms.)\");\n    if (e instanceof NumberFormatException) {\n      throw new BadRequestException(invalidNumMsg + \" is not a numeric value.\");\n    } else if (e instanceof IllegalArgumentException) {\n      throw new BadRequestException(e.getMessage() == null ?\n          \"Requested Invalid Field.\" : e.getMessage());\n    } else if (e instanceof NotFoundException) {\n      throw (NotFoundException)e;\n    } else if (e instanceof TimelineParseException) {\n      throw new BadRequestException(e.getMessage() == null ?\n          \"Filter Parsing failed.\" : e.getMessage());\n    } else if (e instanceof BadRequestException) {\n      throw (BadRequestException)e;\n    } else if (e instanceof ForbiddenException) {\n      throw (ForbiddenException) e;\n    } else {\n      LOG.error(\"Error while processing REST request\", e);\n      throw new WebApplicationException(e,\n          Response.Status.INTERNAL_SERVER_ERROR);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities": "  public Set<TimelineEntity> getEntities(\n      @Context HttpServletRequest req,\n      @Context HttpServletResponse res,\n      @PathParam(\"clusterid\") String clusterId,\n      @PathParam(\"appid\") String appId,\n      @PathParam(\"entitytype\") String entityType,\n      @QueryParam(\"userid\") String userId,\n      @QueryParam(\"flowname\") String flowName,\n      @QueryParam(\"flowrunid\") String flowRunId,\n      @QueryParam(\"limit\") String limit,\n      @QueryParam(\"createdtimestart\") String createdTimeStart,\n      @QueryParam(\"createdtimeend\") String createdTimeEnd,\n      @QueryParam(\"relatesto\") String relatesTo,\n      @QueryParam(\"isrelatedto\") String isRelatedTo,\n      @QueryParam(\"infofilters\") String infofilters,\n      @QueryParam(\"conffilters\") String conffilters,\n      @QueryParam(\"metricfilters\") String metricfilters,\n      @QueryParam(\"eventfilters\") String eventfilters,\n      @QueryParam(\"confstoretrieve\") String confsToRetrieve,\n      @QueryParam(\"metricstoretrieve\") String metricsToRetrieve,\n      @QueryParam(\"fields\") String fields,\n      @QueryParam(\"metricslimit\") String metricsLimit,\n      @QueryParam(\"metricstimestart\") String metricsTimeStart,\n      @QueryParam(\"metricstimeend\") String metricsTimeEnd,\n      @QueryParam(\"fromid\") String fromId) {\n    String url = req.getRequestURI() +\n        (req.getQueryString() == null ? \"\" :\n            QUERY_STRING_SEP + req.getQueryString());\n    UserGroupInformation callerUGI =\n        TimelineReaderWebServicesUtils.getUser(req);\n    LOG.info(\"Received URL \" + url + \" from user \" +\n        TimelineReaderWebServicesUtils.getUserName(callerUGI));\n    long startTime = Time.monotonicNow();\n    init(res);\n    TimelineReaderManager timelineReaderManager = getTimelineReaderManager();\n    Set<TimelineEntity> entities = null;\n    try {\n      TimelineReaderContext context = TimelineReaderWebServicesUtils\n          .createTimelineReaderContext(clusterId, userId, flowName, flowRunId,\n              appId, entityType, null, null);\n      entities = timelineReaderManager.getEntities(context,\n          TimelineReaderWebServicesUtils\n              .createTimelineEntityFilters(limit, createdTimeStart,\n                  createdTimeEnd, relatesTo, isRelatedTo, infofilters,\n                  conffilters, metricfilters, eventfilters, fromId),\n          TimelineReaderWebServicesUtils\n              .createTimelineDataToRetrieve(confsToRetrieve, metricsToRetrieve,\n                  fields, metricsLimit, metricsTimeStart, metricsTimeEnd));\n\n      checkAccessForGenericEntities(entities, callerUGI, entityType);\n    } catch (Exception e) {\n      handleException(e, url, startTime,\n          \"createdTime start/end or limit or flowrunid\");\n    }\n    long endTime = Time.monotonicNow();\n    if (entities == null) {\n      entities = Collections.emptySet();\n    }\n    LOG.info(\"Processed URL \" + url +\n        \" (Took \" + (endTime - startTime) + \" ms.)\");\n    return entities;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getTimelineReaderManager": "  private TimelineReaderManager getTimelineReaderManager() {\n    return (TimelineReaderManager)\n        ctxt.getAttribute(TimelineReaderServer.TIMELINE_READER_MANAGER_ATTR);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.init": "  private void init(HttpServletResponse response) {\n    response.setContentType(null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccessForGenericEntities": "  private void checkAccessForGenericEntities(Set<TimelineEntity> entities,\n      UserGroupInformation callerUGI, String entityType) throws Exception {\n    if (entities != null && entities.size() > 0\n        && isDisplayEntityPerUserFilterEnabled(\n        getTimelineReaderManager().getConfig())) {\n      TimelineReaderContext timelineReaderContext = null;\n      TimelineEntity entity = entities.iterator().next();\n      String uid =\n          (String) entity.getInfo().get(TimelineReaderUtils.FROMID_KEY);\n      if (TimelineEntityType.YARN_APPLICATION.matches(entityType)) {\n        timelineReaderContext =\n            TimelineFromIdConverter.APPLICATION_FROMID.decodeUID(uid);\n      } else {\n        timelineReaderContext =\n            TimelineFromIdConverter.GENERIC_ENTITY_FROMID.decodeUID(uid);\n      }\n      checkAccess(getTimelineReaderManager(), callerUGI,\n          timelineReaderContext.getUserId());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.security.TimelineReaderWhitelistAuthorizationFilter.doFilter": "  public void doFilter(ServletRequest request, ServletResponse response,\n      FilterChain chain) throws IOException, ServletException {\n    HttpServletRequest httpRequest = (HttpServletRequest) request;\n    HttpServletResponse httpResponse = (HttpServletResponse) response;\n\n    if (isWhitelistReadAuthEnabled) {\n      UserGroupInformation callerUGI = TimelineReaderWebServicesUtils\n          .getCallerUserGroupInformation(httpRequest, true);\n      if (callerUGI == null) {\n        String msg = \"Unable to obtain user name, user not authenticated\";\n        throw new AuthorizationException(msg);\n      }\n      if (!(adminAclList.isUserAllowed(callerUGI)\n          || allowedUsersAclList.isUserAllowed(callerUGI))) {\n        String userName = callerUGI.getShortUserName();\n        String msg = \"User \" + userName\n            + \" is not allowed to read TimelineService V2 data.\";\n        httpResponse.sendError(HttpServletResponse.SC_FORBIDDEN, msg);\n        return;\n      }\n    }\n    if (chain != null) {\n      chain.doFilter(request, response);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.http.CrossOriginFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n      FilterChain chain)\n      throws IOException, ServletException {\n    doCrossFilter((HttpServletRequest) req, (HttpServletResponse) res);\n    chain.doFilter(req, res);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.http.CrossOriginFilter.doCrossFilter": "  private void doCrossFilter(HttpServletRequest req, HttpServletResponse res) {\n\n    String originsList = encodeHeader(req.getHeader(ORIGIN));\n    if (!isCrossOrigin(originsList)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Header origin is null. Returning\");\n      }\n      return;\n    }\n\n    if (!areOriginsAllowed(originsList)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Header origins '\" + originsList + \"' not allowed. Returning\");\n      }\n      return;\n    }\n\n    String accessControlRequestMethod =\n        req.getHeader(ACCESS_CONTROL_REQUEST_METHOD);\n    if (!isMethodAllowed(accessControlRequestMethod)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Access control method '\" + accessControlRequestMethod +\n            \"' not allowed. Returning\");\n      }\n      return;\n    }\n\n    String accessControlRequestHeaders =\n        req.getHeader(ACCESS_CONTROL_REQUEST_HEADERS);\n    if (!areHeadersAllowed(accessControlRequestHeaders)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Access control headers '\" + accessControlRequestHeaders +\n            \"' not allowed. Returning\");\n      }\n      return;\n    }\n\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\"Completed cross origin filter checks. Populating \" +\n          \"HttpServletResponse\");\n    }\n    res.setHeader(ACCESS_CONTROL_ALLOW_ORIGIN, originsList);\n    res.setHeader(ACCESS_CONTROL_ALLOW_CREDENTIALS, Boolean.TRUE.toString());\n    res.setHeader(ACCESS_CONTROL_ALLOW_METHODS, getAllowedMethodsHeader());\n    res.setHeader(ACCESS_CONTROL_ALLOW_HEADERS, getAllowedHeadersHeader());\n    res.setHeader(ACCESS_CONTROL_MAX_AGE, maxAge);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.doFilter": "    public void doFilter(ServletRequest request,\n                         ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequestWrapper quoted =\n        new RequestQuoter((HttpServletRequest) request);\n      HttpServletResponse httpResponse = (HttpServletResponse) response;\n\n      String mime = inferMimeType(request);\n      if (mime == null) {\n        httpResponse.setContentType(\"text/plain; charset=utf-8\");\n      } else if (mime.startsWith(\"text/html\")) {\n        // HTML with unspecified encoding, we want to\n        // force HTML with utf-8 encoding\n        // This is to avoid the following security issue:\n        // http://openmya.hacker.jp/hasegawa/security/utf7cs.html\n        httpResponse.setContentType(\"text/html; charset=utf-8\");\n      } else if (mime.startsWith(\"application/xml\")) {\n        httpResponse.setContentType(\"text/xml; charset=utf-8\");\n      }\n      headerMap.forEach((k, v) -> httpResponse.addHeader(k, v));\n      chain.doFilter(quoted, httpResponse);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.inferMimeType": "    private String inferMimeType(ServletRequest request) {\n      String path = ((HttpServletRequest)request).getRequestURI();\n      ServletContextHandler.Context sContext =\n          (ServletContextHandler.Context)config.getServletContext();\n      String mime = sContext.getMimeType(path);\n      return (mime == null) ? null : mime;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.NoCacheFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n                       FilterChain chain)\n    throws IOException, ServletException {\n    HttpServletResponse httpRes = (HttpServletResponse) res;\n    httpRes.setHeader(\"Cache-Control\", \"no-cache\");\n    long now = System.currentTimeMillis();\n    httpRes.addDateHeader(\"Expires\", now);\n    httpRes.addDateHeader(\"Date\", now);\n    httpRes.addHeader(\"Pragma\", \"no-cache\");\n    chain.doFilter(req, res);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccess": "  static void checkAccess(TimelineReaderManager readerManager,\n      UserGroupInformation callerUGI, Set<TimelineEntity> entities,\n      String entityUserKey, boolean verifyForAllEntity) {\n    if (entities.size() > 0 && isDisplayEntityPerUserFilterEnabled(\n        readerManager.getConfig())) {\n      Set<TimelineEntity> userEntities = new LinkedHashSet<>();\n      userEntities.addAll(entities);\n      for (TimelineEntity entity : userEntities) {\n        if (entity.getInfo() != null) {\n          String userId = (String) entity.getInfo().get(entityUserKey);\n          if (!validateAuthUserWithEntityUser(readerManager, callerUGI,\n              userId)) {\n            entities.remove(entity);\n            if (!verifyForAllEntity) {\n              break;\n            }\n          }\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.validateAuthUserWithEntityUser": "  static boolean validateAuthUserWithEntityUser(\n      TimelineReaderManager readerManager, UserGroupInformation ugi,\n      String entityUser) {\n    String authUser = TimelineReaderWebServicesUtils.getUserName(ugi);\n    String requestedUser = TimelineReaderWebServicesUtils.parseStr(entityUser);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Authenticated User: \" + authUser + \" Requested User:\" + entityUser);\n    }\n    return (readerManager.checkAccess(ugi) || authUser.equals(requestedUser));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.isDisplayEntityPerUserFilterEnabled": "  static boolean isDisplayEntityPerUserFilterEnabled(Configuration config) {\n    return !config\n        .getBoolean(YarnConfiguration.TIMELINE_SERVICE_READ_AUTH_ENABLED,\n            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_READ_AUTH_ENABLED)\n        && config\n        .getBoolean(YarnConfiguration.FILTER_ENTITY_LIST_BY_USER, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.createTimelineReaderContext": "  static TimelineReaderContext createTimelineReaderContext(String clusterId,\n      String userId, String flowName, String flowRunId, String appId,\n      String entityType, String entityIdPrefix, String entityId,\n      String doAsUser) {\n    return new TimelineReaderContext(parseStr(clusterId), parseStr(userId),\n        parseStr(flowName), parseLongStr(flowRunId), parseStr(appId),\n        parseStr(entityType), parseLongStr(entityIdPrefix), parseStr(entityId),\n        parseStr(doAsUser));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseLongStr": "  static Long parseLongStr(String str) {\n    return str == null ? null : Long.parseLong(str.trim());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseStr": "  static String parseStr(String str) {\n    return StringUtils.trimToNull(str);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.getUserName": "  static String getUserName(UserGroupInformation callerUGI) {\n    return ((callerUGI != null) ? callerUGI.getUserName().trim() : \"\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.createTimelineEntityFilters": "  static TimelineEntityFilters createTimelineEntityFilters(String limit,\n      Long createdTimeStart, Long createdTimeEnd, String relatesTo,\n      String isRelatedTo, String infofilters, String conffilters,\n      String metricfilters, String eventfilters,\n      String fromid) throws TimelineParseException {\n    return new TimelineEntityFilters.Builder()\n        .entityLimit(parseLongStr(limit))\n        .createdTimeBegin(createdTimeStart)\n        .createTimeEnd(createdTimeEnd)\n        .relatesTo(parseRelationFilters(relatesTo))\n        .isRelatedTo(parseRelationFilters(isRelatedTo))\n        .infoFilters(parseKVFilters(infofilters, false))\n        .configFilters(parseKVFilters(conffilters, true))\n        .metricFilters(parseMetricFilters(metricfilters))\n        .eventFilters(parseEventFilters(eventfilters))\n        .fromId(parseStr(fromid)).build();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseMetricFilters": "  static TimelineFilterList parseMetricFilters(String expr)\n      throws TimelineParseException {\n    return parseFilters(new TimelineParserForNumericFilters(expr));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseEventFilters": "  static TimelineFilterList parseEventFilters(String expr)\n      throws TimelineParseException {\n    return parseFilters(new TimelineParserForExistFilters(expr,\n        TimelineParseConstants.COMMA_CHAR));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseKVFilters": "  static TimelineFilterList parseKVFilters(String expr, boolean valueAsString)\n      throws TimelineParseException {\n    return parseFilters(new TimelineParserForKVFilters(expr, valueAsString));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseRelationFilters": "  static TimelineFilterList parseRelationFilters(String expr)\n      throws TimelineParseException {\n    return parseFilters(new TimelineParserForRelationFilters(expr,\n        TimelineParseConstants.COMMA_CHAR,\n        TimelineParseConstants.COLON_DELIMITER));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.createTimelineDataToRetrieve": "  static TimelineDataToRetrieve createTimelineDataToRetrieve(String confs,\n      String metrics, String fields, String metricsLimit,\n      String metricsTimeBegin, String metricsTimeEnd)\n      throws TimelineParseException {\n    return new TimelineDataToRetrieve(parseDataToRetrieve(confs),\n        parseDataToRetrieve(metrics), parseFieldsStr(fields,\n        TimelineParseConstants.COMMA_DELIMITER), parseIntStr(metricsLimit),\n        parseLongStr(metricsTimeBegin), parseLongStr(metricsTimeEnd));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseFieldsStr": "  static EnumSet<Field> parseFieldsStr(String str, String delimiter) {\n    if (str == null) {\n      return null;\n    }\n    String[] strs = str.split(delimiter);\n    EnumSet<Field> fieldList = EnumSet.noneOf(Field.class);\n    for (String s : strs) {\n      fieldList.add(Field.valueOf(s.trim().toUpperCase()));\n    }\n    return fieldList;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseIntStr": "  static Integer parseIntStr(String str) {\n    return str == null ? null : Integer.parseInt(str.trim());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.parseDataToRetrieve": "  static TimelineFilterList parseDataToRetrieve(String expr)\n        throws TimelineParseException {\n    return parseFilters(new TimelineParserForDataToRetrieve(expr));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderContext.setEntityType": "  public void setEntityType(String type) {\n    this.entityType = type;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.getUser": "  public static UserGroupInformation getUser(HttpServletRequest req) {\n    return getCallerUserGroupInformation(req, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-timelineservice.src.main.java.org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServicesUtils.getCallerUserGroupInformation": "  public static UserGroupInformation getCallerUserGroupInformation(\n      HttpServletRequest hsr, boolean usePrincipal) {\n\n    String remoteUser = hsr.getRemoteUser();\n    if (usePrincipal) {\n      Principal princ = hsr.getUserPrincipal();\n      remoteUser = princ == null ? null : princ.getName();\n    }\n\n    UserGroupInformation callerUGI = null;\n    if (remoteUser != null) {\n      callerUGI = UserGroupInformation.createRemoteUser(remoteUser);\n    }\n\n    return callerUGI;\n  }"
        },
        "bug_report": {
            "Title": "[ATSv2] NPE while checking for entity acl in non-secure cluster",
            "Description": "{code:java}\r\nGET http://ctr-e138-1518143905142-417433-01-000004.hwx.site:8198/ws/v2/timeline/apps/application_1532578985272_0002/entities/YARN_CONTAINER?fields=ALL&_=1532670071899{code}\r\n{code:java}\r\n2018-07-27 05:32:03,468 WARN  webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR\r\njavax.ws.rs.WebApplicationException: java.lang.NullPointerException\r\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.handleException(TimelineReaderWebServices.java:196)\r\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:624)\r\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:474)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n        at java.lang.reflect.Method.invoke(Method.java:498)\r\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\r\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\r\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\r\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\r\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\r\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\r\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\r\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\r\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\r\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\r\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\r\n        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\r\n        at org.apache.hadoop.yarn.server.timelineservice.reader.security.TimelineReaderWhitelistAuthorizationFilter.doFilter(TimelineReaderWhitelistAuthorizationFilter.java:85)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)\r\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:98)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1604)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\r\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\r\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\r\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\r\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\r\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\r\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\r\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\r\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\r\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\r\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\r\n        at org.eclipse.jetty.server.Server.handle(Server.java:534)\r\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\r\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\r\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\r\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\r\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\r\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\r\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\r\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\r\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\r\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccess(TimelineReaderWebServices.java:3536)\r\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccessForGenericEntities(TimelineReaderWebServices.java:3513)\r\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:622)\r\n{code}"
        }
    },
    {
        "filename": "YARN-6649.json",
        "creation_time": "2017-05-25T20:36:08.000+0000",
        "stack_trace": "```\njavax.ws.rs.WebApplicationException: java.lang.RuntimeException: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getEntity(TimelineWebServices.java:164)\n\tat sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n\tat com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n\tat com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n\tat com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n\tat com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:636)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:294)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:588)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:95)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1352)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.RuntimeException: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.util.FSTUtil.rethrow(FSTUtil.java:122)\n\tat org.nustaq.serialization.FSTConfiguration.asObject(FSTConfiguration.java:879)\n\tat org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntity(RollingLevelDBTimelineStore.java:478)\n\tat org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntity(RollingLevelDBTimelineStore.java:414)\n\tat org.apache.hadoop.yarn.server.timeline.EntityFileTimelineStore.getEntity(EntityFileTimelineStore.java:911)\n\tat org.apache.hadoop.yarn.server.timeline.TimelineDataManager.doGetEntity(TimelineDataManager.java:215)\n\tat org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getEntity(TimelineDataManager.java:202)\n\tat org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getEntity(TimelineWebServices.java:155)\n\t... 52 more\nCaused by: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:240)\n\tat org.nustaq.serialization.FSTConfiguration.asObject(FSTConfiguration.java:877)\n\t... 58 more\nCaused by: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173)\n\tat org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:431)\n\tat org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:853)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:338)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:323)\n\tat org.nustaq.serialization.serializers.FSTArrayListSerializer.instantiate(FSTArrayListSerializer.java:63)\n\tat org.nustaq.serialization.FSTObjectInput.instantiateAndReadWithSer(FSTObjectInput.java:459)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:354)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:323)\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:304)\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:238)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getEntity": "  public TimelineEntity getEntity(\n      @Context HttpServletRequest req,\n      @Context HttpServletResponse res,\n      @PathParam(\"entityType\") String entityType,\n      @PathParam(\"entityId\") String entityId,\n      @QueryParam(\"fields\") String fields) {\n    init(res);\n    TimelineEntity entity = null;\n    try {\n      entity = timelineDataManager.getEntity(\n          parseStr(entityType),\n          parseStr(entityId),\n          parseFieldsStr(fields, \",\"),\n          getUser(req));\n    } catch (IllegalArgumentException e) {\n      throw new BadRequestException(e);\n    } catch (Exception e) {\n      LOG.error(\"Error getting entity\", e);\n      throw new WebApplicationException(e,\n          Response.Status.INTERNAL_SERVER_ERROR);\n    }\n    if (entity == null) {\n      throw new NotFoundException(\"Timeline entity \"\n          + new EntityIdentifier(parseStr(entityId), parseStr(entityType))\n          + \" is not found\");\n    }\n    return entity;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.parseFieldsStr": "  private static EnumSet<Field> parseFieldsStr(String str, String delimiter) {\n    if (str == null) {\n      return null;\n    }\n    String[] strs = str.split(delimiter);\n    List<Field> fieldList = new ArrayList<Field>();\n    for (String s : strs) {\n      s = StringUtils.toUpperCase(s.trim());\n      if (s.equals(\"EVENTS\")) {\n        fieldList.add(Field.EVENTS);\n      } else if (s.equals(\"LASTEVENTONLY\")) {\n        fieldList.add(Field.LAST_EVENT_ONLY);\n      } else if (s.equals(\"RELATEDENTITIES\")) {\n        fieldList.add(Field.RELATED_ENTITIES);\n      } else if (s.equals(\"PRIMARYFILTERS\")) {\n        fieldList.add(Field.PRIMARY_FILTERS);\n      } else if (s.equals(\"OTHERINFO\")) {\n        fieldList.add(Field.OTHER_INFO);\n      } else {\n        throw new IllegalArgumentException(\"Requested nonexistent field \" + s);\n      }\n    }\n    if (fieldList.size() == 0) {\n      return null;\n    }\n    Field f1 = fieldList.remove(fieldList.size() - 1);\n    if (fieldList.size() == 0) {\n      return EnumSet.of(f1);\n    } else {\n      return EnumSet.of(f1, fieldList.toArray(new Field[fieldList.size()]));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.parseStr": "  private static String parseStr(String str) {\n    return str == null ? null : str.trim();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.init": "  private void init(HttpServletResponse response) {\n    response.setContentType(null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getUser": "  private static UserGroupInformation getUser(HttpServletRequest req) {\n    String remoteUser = req.getRemoteUser();\n    UserGroupInformation callerUGI = null;\n    if (remoteUser != null) {\n      callerUGI = UserGroupInformation.createRemoteUser(remoteUser);\n    }\n    return callerUGI;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter": "  protected void doFilter(FilterChain filterChain, HttpServletRequest request,\n      HttpServletResponse response) throws IOException, ServletException {\n    boolean requestCompleted = false;\n    UserGroupInformation ugi = null;\n    AuthenticationToken authToken = (AuthenticationToken)\n        request.getUserPrincipal();\n    if (authToken != null && authToken != AuthenticationToken.ANONYMOUS) {\n      // if the request was authenticated because of a delegation token,\n      // then we ignore proxyuser (this is the same as the RPC behavior).\n      ugi = (UserGroupInformation) request.getAttribute(\n          DelegationTokenAuthenticationHandler.DELEGATION_TOKEN_UGI_ATTRIBUTE);\n      if (ugi == null) {\n        String realUser = request.getUserPrincipal().getName();\n        ugi = UserGroupInformation.createRemoteUser(realUser,\n            handlerAuthMethod);\n        String doAsUser = getDoAs(request);\n        if (doAsUser != null) {\n          ugi = UserGroupInformation.createProxyUser(doAsUser, ugi);\n          try {\n            ProxyUsers.authorize(ugi, request.getRemoteAddr());\n          } catch (AuthorizationException ex) {\n            HttpExceptionUtils.createServletExceptionResponse(response,\n                HttpServletResponse.SC_FORBIDDEN, ex);\n            requestCompleted = true;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Authentication exception: \" + ex.getMessage(), ex);\n            } else {\n              LOG.warn(\"Authentication exception: \" + ex.getMessage());\n            }\n          }\n        }\n      }\n      UGI_TL.set(ugi);\n    }\n    if (!requestCompleted) {\n      final UserGroupInformation ugiF = ugi;\n      try {\n        request = new HttpServletRequestWrapper(request) {\n\n          @Override\n          public String getAuthType() {\n            return (ugiF != null) ? handlerAuthMethod.toString() : null;\n          }\n\n          @Override\n          public String getRemoteUser() {\n            return (ugiF != null) ? ugiF.getShortUserName() : null;\n          }\n\n          @Override\n          public Principal getUserPrincipal() {\n            return (ugiF != null) ? new Principal() {\n              @Override\n              public String getName() {\n                return ugiF.getUserName();\n              }\n            } : null;\n          }\n        };\n        super.doFilter(filterChain, request, response);\n      } finally {\n        UGI_TL.remove();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.getDoAs": "  static String getDoAs(HttpServletRequest request) {\n    String queryString = request.getQueryString();\n    if (queryString == null) {\n      return null;\n    }\n    List<NameValuePair> list = URLEncodedUtils.parse(queryString, UTF8_CHARSET);\n    if (list != null) {\n      for (NameValuePair nv : list) {\n        if (DelegationTokenAuthenticatedURL.DO_AS.\n            equalsIgnoreCase(nv.getName())) {\n          return nv.getValue();\n        }\n      }\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.getUserPrincipal": "          public Principal getUserPrincipal() {\n            return (ugiF != null) ? new Principal() {\n              @Override\n              public String getName() {\n                return ugiF.getUserName();\n              }\n            } : null;\n          }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.getName": "              public String getName() {\n                return ugiF.getUserName();\n              }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.http.CrossOriginFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n      FilterChain chain)\n      throws IOException, ServletException {\n    doCrossFilter((HttpServletRequest) req, (HttpServletResponse) res);\n    chain.doFilter(req, res);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.http.CrossOriginFilter.doCrossFilter": "  private void doCrossFilter(HttpServletRequest req, HttpServletResponse res) {\n\n    String originsList = encodeHeader(req.getHeader(ORIGIN));\n    if (!isCrossOrigin(originsList)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Header origin is null. Returning\");\n      }\n      return;\n    }\n\n    if (!areOriginsAllowed(originsList)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Header origins '\" + originsList + \"' not allowed. Returning\");\n      }\n      return;\n    }\n\n    String accessControlRequestMethod =\n        req.getHeader(ACCESS_CONTROL_REQUEST_METHOD);\n    if (!isMethodAllowed(accessControlRequestMethod)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Access control method '\" + accessControlRequestMethod +\n            \"' not allowed. Returning\");\n      }\n      return;\n    }\n\n    String accessControlRequestHeaders =\n        req.getHeader(ACCESS_CONTROL_REQUEST_HEADERS);\n    if (!areHeadersAllowed(accessControlRequestHeaders)) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Access control headers '\" + accessControlRequestHeaders +\n            \"' not allowed. Returning\");\n      }\n      return;\n    }\n\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\"Completed cross origin filter checks. Populating \" +\n          \"HttpServletResponse\");\n    }\n    res.setHeader(ACCESS_CONTROL_ALLOW_ORIGIN, originsList);\n    res.setHeader(ACCESS_CONTROL_ALLOW_CREDENTIALS, Boolean.TRUE.toString());\n    res.setHeader(ACCESS_CONTROL_ALLOW_METHODS, getAllowedMethodsHeader());\n    res.setHeader(ACCESS_CONTROL_ALLOW_HEADERS, getAllowedHeadersHeader());\n    res.setHeader(ACCESS_CONTROL_MAX_AGE, maxAge);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.doFilter": "    public void doFilter(ServletRequest request,\n                         ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequestWrapper quoted =\n        new RequestQuoter((HttpServletRequest) request);\n      HttpServletResponse httpResponse = (HttpServletResponse) response;\n\n      String mime = inferMimeType(request);\n      if (mime == null) {\n        httpResponse.setContentType(\"text/plain; charset=utf-8\");\n      } else if (mime.startsWith(\"text/html\")) {\n        // HTML with unspecified encoding, we want to\n        // force HTML with utf-8 encoding\n        // This is to avoid the following security issue:\n        // http://openmya.hacker.jp/hasegawa/security/utf7cs.html\n        httpResponse.setContentType(\"text/html; charset=utf-8\");\n      } else if (mime.startsWith(\"application/xml\")) {\n        httpResponse.setContentType(\"text/xml; charset=utf-8\");\n      }\n\n      if(Boolean.valueOf(this.config.getInitParameter(X_FRAME_ENABLED))) {\n        httpResponse.addHeader(\"X-FRAME-OPTIONS\",\n            this.config.getInitParameter(X_FRAME_VALUE));\n      }\n      chain.doFilter(quoted, httpResponse);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.inferMimeType": "    private String inferMimeType(ServletRequest request) {\n      String path = ((HttpServletRequest)request).getRequestURI();\n      ServletContextHandler.Context sContext =\n          (ServletContextHandler.Context)config.getServletContext();\n      String mime = sContext.getMimeType(path);\n      return (mime == null) ? null : mime;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.NoCacheFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n                       FilterChain chain)\n    throws IOException, ServletException {\n    HttpServletResponse httpRes = (HttpServletResponse) res;\n    httpRes.setHeader(\"Cache-Control\", \"no-cache\");\n    long now = System.currentTimeMillis();\n    httpRes.addDateHeader(\"Expires\", now);\n    httpRes.addDateHeader(\"Date\", now);\n    httpRes.addHeader(\"Pragma\", \"no-cache\");\n    chain.doFilter(req, res);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntity": "  private static TimelineEntity getEntity(String entityId, String entityType,\n      Long startTime, EnumSet<Field> fields, DBIterator iterator,\n      byte[] prefix, int prefixlen) throws IOException {\n    if (fields == null) {\n      fields = EnumSet.allOf(Field.class);\n    }\n\n    TimelineEntity entity = new TimelineEntity();\n    boolean events = false;\n    boolean lastEvent = false;\n    if (fields.contains(Field.EVENTS)) {\n      events = true;\n    } else if (fields.contains(Field.LAST_EVENT_ONLY)) {\n      lastEvent = true;\n    } else {\n      entity.setEvents(null);\n    }\n    boolean relatedEntities = false;\n    if (fields.contains(Field.RELATED_ENTITIES)) {\n      relatedEntities = true;\n    } else {\n      entity.setRelatedEntities(null);\n    }\n    boolean primaryFilters = false;\n    if (fields.contains(Field.PRIMARY_FILTERS)) {\n      primaryFilters = true;\n    } else {\n      entity.setPrimaryFilters(null);\n    }\n    boolean otherInfo = false;\n    if (fields.contains(Field.OTHER_INFO)) {\n      otherInfo = true;\n    } else {\n      entity.setOtherInfo(null);\n    }\n\n    // iterate through the entity's entry, parsing information if it is part\n    // of a requested field\n    for (; iterator.hasNext(); iterator.next()) {\n      byte[] key = iterator.peekNext().getKey();\n      if (!prefixMatches(prefix, prefixlen, key)) {\n        break;\n      }\n      if (key.length == prefixlen) {\n        continue;\n      }\n      if (key[prefixlen] == PRIMARY_FILTERS_COLUMN[0]) {\n        if (primaryFilters) {\n          addPrimaryFilter(entity, key, prefixlen\n              + PRIMARY_FILTERS_COLUMN.length);\n        }\n      } else if (key[prefixlen] == OTHER_INFO_COLUMN[0]) {\n        if (otherInfo) {\n          entity.addOtherInfo(\n              parseRemainingKey(key, prefixlen + OTHER_INFO_COLUMN.length),\n              fstConf.asObject(iterator.peekNext().getValue()));\n        }\n      } else if (key[prefixlen] == RELATED_ENTITIES_COLUMN[0]) {\n        if (relatedEntities) {\n          addRelatedEntity(entity, key, prefixlen\n              + RELATED_ENTITIES_COLUMN.length);\n        }\n      } else if (key[prefixlen] == EVENTS_COLUMN[0]) {\n        if (events || (lastEvent && entity.getEvents().size() == 0)) {\n          TimelineEvent event = getEntityEvent(null, key, prefixlen\n              + EVENTS_COLUMN.length, iterator.peekNext().getValue());\n          if (event != null) {\n            entity.addEvent(event);\n          }\n        }\n      } else if (key[prefixlen] == DOMAIN_ID_COLUMN[0]) {\n        byte[] v = iterator.peekNext().getValue();\n        String domainId = new String(v, UTF_8);\n        entity.setDomainId(domainId);\n      } else {\n        LOG.warn(String.format(\"Found unexpected column for entity %s of \"\n            + \"type %s (0x%02x)\", entityId, entityType, key[prefixlen]));\n      }\n    }\n\n    entity.setEntityId(entityId);\n    entity.setEntityType(entityType);\n    entity.setStartTime(startTime);\n\n    return entity;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.addPrimaryFilter": "  private static void addPrimaryFilter(TimelineEntity entity, byte[] key,\n      int offset) throws IOException {\n    KeyParser kp = new KeyParser(key, offset);\n    String name = kp.getNextString();\n    byte[] bytes = kp.getRemainingBytes();\n    Object value = fstConf.asObject(bytes);\n    entity.addPrimaryFilter(name, value);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.addRelatedEntity": "  private static void addRelatedEntity(TimelineEntity entity, byte[] key,\n      int offset) throws IOException {\n    KeyParser kp = new KeyParser(key, offset);\n    String type = kp.getNextString();\n    String id = kp.getNextString();\n    entity.addRelatedEntity(type, id);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.parseRemainingKey": "  private static String parseRemainingKey(byte[] b, int offset) {\n    return new String(b, offset, b.length - offset, UTF_8);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getStartTimeLong": "  private Long getStartTimeLong(String entityId, String entityType)\n      throws IOException {\n    EntityIdentifier entity = new EntityIdentifier(entityId, entityType);\n    // start time is not provided, so try to look it up\n    if (startTimeReadCache.containsKey(entity)) {\n      // found the start time in the cache\n      return startTimeReadCache.get(entity);\n    } else {\n      // try to look up the start time in the db\n      byte[] b = createStartTimeLookupKey(entity.getId(), entity.getType());\n      byte[] v = starttimedb.get(b);\n      if (v == null) {\n        // did not find the start time in the db\n        return null;\n      } else {\n        // found the start time in the db\n        Long l = readReverseOrderedLong(v, 0);\n        startTimeReadCache.put(entity, l);\n        return l;\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntityEvent": "  private static TimelineEvent getEntityEvent(Set<String> eventTypes,\n      byte[] key, int offset, byte[] value) throws IOException {\n    KeyParser kp = new KeyParser(key, offset);\n    long ts = kp.getNextLong();\n    String tstype = kp.getNextString();\n    if (eventTypes == null || eventTypes.contains(tstype)) {\n      TimelineEvent event = new TimelineEvent();\n      event.setTimestamp(ts);\n      event.setEventType(tstype);\n      Object o = fstConf.asObject(value);\n      if (o == null) {\n        event.setEventInfo(null);\n      } else if (o instanceof Map) {\n        @SuppressWarnings(\"unchecked\")\n        Map<String, Object> m = (Map<String, Object>) o;\n        event.setEventInfo(m);\n      } else {\n        throw new IOException(\"Couldn't deserialize event info map\");\n      }\n      return event;\n    }\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.TimelineDataManager.doGetEntity": "  private TimelineEntity doGetEntity(\n      String entityType,\n      String entityId,\n      EnumSet<Field> fields,\n      UserGroupInformation callerUGI) throws YarnException, IOException {\n    TimelineEntity entity = null;\n    entity =\n        store.getEntity(entityId, entityType, fields);\n    if (entity != null) {\n      addDefaultDomainIdIfAbsent(entity);\n      // check ACLs\n      if (!timelineACLsManager.checkAccess(\n          callerUGI, ApplicationAccessType.VIEW_APP, entity)) {\n        entity = null;\n      }\n    }\n    return entity;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.TimelineDataManager.addDefaultDomainIdIfAbsent": "  private static void addDefaultDomainIdIfAbsent(TimelineEntity entity) {\n    // be compatible with the timeline data created before 2.6\n    if (entity.getDomainId() == null) {\n      entity.setDomainId(DEFAULT_DOMAIN_ID);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-applicationhistoryservice.src.main.java.org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getEntity": "  public TimelineEntity getEntity(\n      String entityType,\n      String entityId,\n      EnumSet<Field> fields,\n      UserGroupInformation callerUGI) throws YarnException, IOException {\n    long startTime = Time.monotonicNow();\n    metrics.incrGetEntityOps();\n    try {\n      return doGetEntity(entityType, entityId, fields, callerUGI);\n    } finally {\n      metrics.addGetEntityTime(Time.monotonicNow() - startTime);\n    }\n  }"
        },
        "bug_report": {
            "Title": "RollingLevelDBTimelineServer throws RuntimeException if object decoding ever fails runtime exception",
            "Description": "When Using tez ui (makes REST api calls to timeline service REST api), some calls were coming back as 500 internal server error. The root cause was YARN-6654. This jira is to handle object decoding to prevent sending back internal server errors to the client and instead respond with a partial message instead.\n\n{code}\n2017-05-30 12:47:10,670 WARN org.apache.hadoop.yarn.webapp.GenericExceptionHandler: INTERNAL_SERVER_ERROR\njavax.ws.rs.WebApplicationException: java.lang.RuntimeException: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getEntity(TimelineWebServices.java:164)\n\tat sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n\tat com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n\tat com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n\tat com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n\tat com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:636)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:294)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:588)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:95)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1352)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.RuntimeException: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.util.FSTUtil.rethrow(FSTUtil.java:122)\n\tat org.nustaq.serialization.FSTConfiguration.asObject(FSTConfiguration.java:879)\n\tat org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntity(RollingLevelDBTimelineStore.java:478)\n\tat org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntity(RollingLevelDBTimelineStore.java:414)\n\tat org.apache.hadoop.yarn.server.timeline.EntityFileTimelineStore.getEntity(EntityFileTimelineStore.java:911)\n\tat org.apache.hadoop.yarn.server.timeline.TimelineDataManager.doGetEntity(TimelineDataManager.java:215)\n\tat org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getEntity(TimelineDataManager.java:202)\n\tat org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getEntity(TimelineWebServices.java:155)\n\t... 52 more\nCaused by: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:240)\n\tat org.nustaq.serialization.FSTConfiguration.asObject(FSTConfiguration.java:877)\n\t... 58 more\nCaused by: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173)\n\tat org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:431)\n\tat org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:853)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:338)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:323)\n\tat org.nustaq.serialization.serializers.FSTArrayListSerializer.instantiate(FSTArrayListSerializer.java:63)\n\tat org.nustaq.serialization.FSTObjectInput.instantiateAndReadWithSer(FSTObjectInput.java:459)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:354)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:323)\n\tat org.nustaq.serialization.serializers.FSTMapSerializer.instantiate(FSTMapSerializer.java:78)\n\tat org.nustaq.serialization.FSTObjectInput.instantiateAndReadWithSer(FSTObjectInput.java:459)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:354)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:323)\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:304)\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:238)\n\t... 59 more\n\n{code}\n"
        }
    },
    {
        "filename": "YARN-3742.json",
        "creation_time": "2015-05-29T06:00:38.000+0000",
        "stack_trace": "```\njava.io.IOException: Wait for ZKClient creation timed out\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1066)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1090)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.existsWithRetries(ZKRMStateStore.java:996)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.updateApplicationStateInternal(ZKRMStateStore.java:643)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$UpdateAppTransition.transition(RMStateStore.java:162)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$UpdateAppTransition.transition(RMStateStore.java:147)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:879)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:874)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.runWithCheck": "    T runWithCheck() throws Exception {\n      long startTime = System.currentTimeMillis();\n      synchronized (ZKRMStateStore.this) {\n        while (zkClient == null) {\n          ZKRMStateStore.this.wait(zkSessionTimeout);\n          if (zkClient != null) {\n            break;\n          }\n          if (System.currentTimeMillis() - startTime > zkSessionTimeout) {\n            throw new IOException(\"Wait for ZKClient creation timed out\");\n          }\n        }\n        return run();\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.run": "    abstract T run() throws KeeperException, InterruptedException;\n\n    T runWithCheck() throws Exception {\n      long startTime = System.currentTimeMillis();\n      synchronized (ZKRMStateStore.this) {\n        while (zkClient == null) {\n          ZKRMStateStore.this.wait(zkSessionTimeout);\n          if (zkClient != null) {\n            break;\n          }\n          if (System.currentTimeMillis() - startTime > zkSessionTimeout) {\n            throw new IOException(\"Wait for ZKClient creation timed out\");\n          }\n        }\n        return run();\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.runWithRetries": "    T runWithRetries() throws Exception {\n      int retry = 0;\n      while (true) {\n        try {\n          return runWithCheck();\n        } catch (KeeperException.NoAuthException nae) {\n          if (HAUtil.isHAEnabled(getConfig())) {\n            // NoAuthException possibly means that this store is fenced due to\n            // another RM becoming active. Even if not,\n            // it is safer to assume we have been fenced\n            throw new StoreFencedException();\n          }\n        } catch (KeeperException ke) {\n          if (ke.code() == Code.NODEEXISTS) {\n            LOG.info(\"znode already exists!\");\n            return null;\n          }\n          if (hasDeleteNodeOp && ke.code() == Code.NONODE) {\n            LOG.info(\"znode has already been deleted!\");\n            return null;\n          }\n\n          LOG.info(\"Exception while executing a ZK operation.\", ke);\n          if (shouldRetry(ke.code()) && ++retry < numRetries) {\n            LOG.info(\"Retrying operation on ZK. Retry no. \" + retry);\n            Thread.sleep(zkRetryInterval);\n            createConnection();\n            continue;\n          }\n          LOG.info(\"Maxed out ZK retries. Giving up!\");\n          throw ke;\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.shouldRetry": "    private boolean shouldRetry(Code code) {\n      switch (code) {\n        case CONNECTIONLOSS:\n        case OPERATIONTIMEOUT:\n        case SESSIONEXPIRED:\n        case SESSIONMOVED:\n          return true;\n        default:\n          break;\n      }\n      return false;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createConnection": "  private synchronized void createConnection()\n      throws IOException, InterruptedException {\n    closeZkClients();\n    for (int retries = 0; retries < numRetries && zkClient == null;\n        retries++) {\n      try {\n        activeZkClient = getNewZooKeeper();\n        zkClient = activeZkClient;\n        for (ZKUtil.ZKAuthInfo zkAuth : zkAuths) {\n          zkClient.addAuthInfo(zkAuth.getScheme(), zkAuth.getAuth());\n        }\n        if (useDefaultFencingScheme) {\n          zkClient.addAuthInfo(zkRootNodeAuthScheme,\n              (zkRootNodeUsername + \":\" + zkRootNodePassword).getBytes(Charset.forName(\"UTF-8\")));\n        }\n      } catch (IOException ioe) {\n        // Retry in case of network failures\n        LOG.info(\"Failed to connect to the ZooKeeper on attempt - \" +\n            (retries + 1));\n        ioe.printStackTrace();\n      }\n    }\n    if (zkClient == null) {\n      LOG.error(\"Unable to connect to Zookeeper\");\n      throw new YarnRuntimeException(\"Unable to connect to Zookeeper\");\n    }\n    ZKRMStateStore.this.notifyAll();\n    LOG.info(\"Created new ZK connection\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.existsWithRetries": "  private Stat existsWithRetries(\n      final String path, final boolean watch) throws Exception {\n    return new ZKAction<Stat>() {\n      @Override\n      Stat run() throws KeeperException, InterruptedException {\n        return zkClient.exists(path, watch);\n      }\n    }.runWithRetries();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.updateApplicationStateInternal": "  public synchronized void updateApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateDataPB) throws Exception {\n    String nodeUpdatePath = getNodePath(rmAppRoot, appId.toString());\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Storing final state info for app: \" + appId + \" at: \"\n          + nodeUpdatePath);\n    }\n    byte[] appStateData = appStateDataPB.getProto().toByteArray();\n\n    if (existsWithRetries(nodeUpdatePath, false) != null) {\n      setDataWithRetries(nodeUpdatePath, appStateData, -1);\n    } else {\n      createWithRetries(nodeUpdatePath, appStateData, zkAcl,\n        CreateMode.PERSISTENT);\n      LOG.debug(appId + \" znode didn't exist. Created a new znode to\"\n          + \" update the application state.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.setDataWithRetries": "  public void setDataWithRetries(final String path, final byte[] data,\n                                 final int version) throws Exception {\n    doStoreMultiWithRetries(Op.setData(path, data, version));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries": "  public void createWithRetries(\n      final String path, final byte[] data, final List<ACL> acl,\n      final CreateMode mode) throws Exception {\n    doStoreMultiWithRetries(Op.create(path, data, acl, mode));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getNodePath": "  String getNodePath(String root, String nodeName) {\n    return (root + \"/\" + nodeName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.transition": "    public void transition(RMStateStore store, RMStateStoreEvent event) {\n      if (!(event instanceof RMStateStoreAMRMTokenEvent)) {\n        // should never happen\n        LOG.error(\"Illegal event type: \" + event.getClass());\n        return;\n      }\n      RMStateStoreAMRMTokenEvent amrmEvent = (RMStateStoreAMRMTokenEvent) event;\n\n      try {\n        LOG.info(\"Updating AMRMToken\");\n        store.storeOrUpdateAMRMTokenSecretManagerState(\n            amrmEvent.getAmrmTokenSecretManagerState(), amrmEvent.isUpdate());\n      } catch (Exception e) {\n        LOG.error(\"Error storing info for AMRMTokenSecretManager\", e);\n        store.notifyStoreOperationFailed(e);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeRMDelegationTokenState": "  protected abstract void storeRMDelegationTokenState(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate)\n      throws Exception;\n\n  /**\n   * RMDTSecretManager call this to remove the state of a delegation token\n   */\n  public void removeRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, null,\n        RMStateStoreEventType.REMOVE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationAttemptStateInternal": "  protected abstract void updateApplicationAttemptStateInternal(\n      ApplicationAttemptId attemptId,\n      ApplicationAttemptStateData attemptStateData) throws Exception;\n\n  /**\n   * RMDTSecretManager call this to store the state of a delegation token\n   * and sequence number\n   */\n  public void storeRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, renewDate,\n        RMStateStoreEventType.STORE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeApplicationStateInternal": "  protected abstract void removeApplicationStateInternal(\n      ApplicationStateData appState) throws Exception;\n\n  // TODO: This should eventually become cluster-Id + \"AM_RM_TOKEN_SERVICE\". See\n  // YARN-1779\n  public static final Text AM_RM_TOKEN_SERVICE = new Text(\n    \"AM_RM_TOKEN_SERVICE\");\n\n  public static final Text AM_CLIENT_TOKEN_MASTER_KEY_NAME =\n      new Text(\"YARN_CLIENT_TOKEN_MASTER_KEY\");\n  \n  public Credentials getCredentialsFromAppAttempt(RMAppAttempt appAttempt) {\n    Credentials credentials = new Credentials();\n\n    SecretKey clientTokenMasterKey =\n        appAttempt.getClientTokenMasterKey();\n    if(clientTokenMasterKey != null){\n      credentials.addSecretKey(AM_CLIENT_TOKEN_MASTER_KEY_NAME,\n          clientTokenMasterKey.getEncoded());\n    }\n    return credentials;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeRMDTMasterKeyState": "  protected abstract void removeRMDTMasterKeyState(DelegationKey delegationKey)\n      throws Exception;\n\n  /**\n   * Blocking API Derived classes must implement this method to store or update\n   * the state of AMRMToken Master Key\n   */\n  protected abstract void storeOrUpdateAMRMTokenSecretManagerState(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate)\n      throws Exception;\n\n  /**\n   * Store or Update state of AMRMToken Master Key\n   */\n  public void storeOrUpdateAMRMTokenSecretManager(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate) {\n    handleStoreEvent(new RMStateStoreAMRMTokenEvent(\n        amrmTokenSecretManagerState, isUpdate,\n        RMStateStoreEventType.UPDATE_AMRM_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.notifyApplication": "  private void notifyApplication(RMAppEvent event) {\n    rmDispatcher.getEventHandler().handle(event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeApplicationStateInternal": "  protected abstract void storeApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateData) throws Exception;\n\n  protected abstract void updateApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateData) throws Exception;\n  \n  @SuppressWarnings(\"unchecked\")\n  /**\n   * Non-blocking API\n   * ResourceManager services call this to store state on an application attempt\n   * This does not block the dispatcher threads\n   * RMAppAttemptStoredEvent will be sent on completion to notify the RMAppAttempt\n   */\n  public synchronized void storeNewApplicationAttempt(RMAppAttempt appAttempt) {\n    Credentials credentials = getCredentialsFromAppAttempt(appAttempt);\n\n    AggregateAppResourceUsage resUsage =\n        appAttempt.getRMAppAttemptMetrics().getAggregateAppResourceUsage();\n    ApplicationAttemptStateData attemptState =\n        ApplicationAttemptStateData.newInstance(\n            appAttempt.getAppAttemptId(),\n            appAttempt.getMasterContainer(),\n            credentials, appAttempt.getStartTime(),\n            resUsage.getMemorySeconds(),\n            resUsage.getVcoreSeconds());\n\n    dispatcher.getEventHandler().handle(\n      new RMStateStoreAppAttemptEvent(attemptState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeApplicationAttemptStateInternal": "  protected abstract void storeApplicationAttemptStateInternal(\n      ApplicationAttemptId attemptId,\n      ApplicationAttemptStateData attemptStateData) throws Exception;\n\n  protected abstract void updateApplicationAttemptStateInternal(\n      ApplicationAttemptId attemptId,\n      ApplicationAttemptStateData attemptStateData) throws Exception;\n\n  /**\n   * RMDTSecretManager call this to store the state of a delegation token\n   * and sequence number\n   */\n  public void storeRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, renewDate,\n        RMStateStoreEventType.STORE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.notifyApplicationAttempt": "  private void notifyApplicationAttempt(RMAppAttemptEvent event) {\n    rmDispatcher.getEventHandler().handle(event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeOrUpdateAMRMTokenSecretManagerState": "  protected abstract void storeOrUpdateAMRMTokenSecretManagerState(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate)\n      throws Exception;\n\n  /**\n   * Store or Update state of AMRMToken Master Key\n   */\n  public void storeOrUpdateAMRMTokenSecretManager(\n      AMRMTokenSecretManagerState amrmTokenSecretManagerState, boolean isUpdate) {\n    handleStoreEvent(new RMStateStoreAMRMTokenEvent(\n        amrmTokenSecretManagerState, isUpdate,\n        RMStateStoreEventType.UPDATE_AMRM_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationStateInternal": "  protected abstract void updateApplicationStateInternal(ApplicationId appId,\n      ApplicationStateData appStateData) throws Exception;\n  \n  @SuppressWarnings(\"unchecked\")\n  /**\n   * Non-blocking API\n   * ResourceManager services call this to store state on an application attempt\n   * This does not block the dispatcher threads\n   * RMAppAttemptStoredEvent will be sent on completion to notify the RMAppAttempt\n   */\n  public synchronized void storeNewApplicationAttempt(RMAppAttempt appAttempt) {\n    Credentials credentials = getCredentialsFromAppAttempt(appAttempt);\n\n    AggregateAppResourceUsage resUsage =\n        appAttempt.getRMAppAttemptMetrics().getAggregateAppResourceUsage();\n    ApplicationAttemptStateData attemptState =\n        ApplicationAttemptStateData.newInstance(\n            appAttempt.getAppAttemptId(),\n            appAttempt.getMasterContainer(),\n            credentials, appAttempt.getStartTime(),\n            resUsage.getMemorySeconds(),\n            resUsage.getVcoreSeconds());\n\n    dispatcher.getEventHandler().handle(\n      new RMStateStoreAppAttemptEvent(attemptState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.storeRMDTMasterKeyState": "  protected abstract void storeRMDTMasterKeyState(DelegationKey delegationKey)\n      throws Exception;\n\n  /**\n   * RMDTSecretManager call this to remove the state of a master key\n   */\n  public void removeRMDTMasterKey(DelegationKey delegationKey) {\n    handleStoreEvent(new RMStateStoreRMDTMasterKeyEvent(delegationKey,\n        RMStateStoreEventType.REMOVE_MASTERKEY));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.notifyStoreOperationFailed": "  protected void notifyStoreOperationFailed(Exception failureCause) {\n    if (failureCause instanceof StoreFencedException) {\n      updateFencedState();\n      Thread standByTransitionThread =\n          new Thread(new StandByTransitionThread());\n      standByTransitionThread.setName(\"StandByTransitionThread Handler\");\n      standByTransitionThread.start();\n    } else {\n      rmDispatcher.getEventHandler().handle(\n        new RMFatalEvent(RMFatalEventType.STATE_STORE_OP_FAILED, failureCause));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.removeRMDelegationTokenState": "  protected abstract void removeRMDelegationTokenState(\n      RMDelegationTokenIdentifier rmDTIdentifier) throws Exception;\n\n  /**\n   * RMDTSecretManager call this to update the state of a delegation token\n   * and sequence number\n   */\n  public void updateRMDelegationToken(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate) {\n    handleStoreEvent(new RMStateStoreRMDTEvent(rmDTIdentifier, renewDate,\n        RMStateStoreEventType.UPDATE_DELEGATION_TOKEN));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateRMDelegationTokenState": "  protected abstract void updateRMDelegationTokenState(\n      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate)\n      throws Exception;\n\n  /**\n   * RMDTSecretManager call this to store the state of a master key\n   */\n  public void storeRMDTMasterKey(DelegationKey delegationKey) {\n    handleStoreEvent(new RMStateStoreRMDTMasterKeyEvent(delegationKey,\n        RMStateStoreEventType.STORE_MASTERKEY));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent": "  protected void handleStoreEvent(RMStateStoreEvent event) {\n    this.writeLock.lock();\n    try {\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing event of type \" + event.getType());\n      }\n\n      final RMStateStoreState oldState = getRMStateStoreState();\n\n      this.stateMachine.doTransition(event.getType(), event);\n\n      if (oldState != getRMStateStoreState()) {\n        LOG.info(\"RMStateStore state change from \" + oldState + \" to \"\n            + getRMStateStoreState());\n      }\n\n    } catch (InvalidStateTransitonException e) {\n      LOG.error(\"Can't handle this event at current state\", e);\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.getRMStateStoreState": "  public RMStateStoreState getRMStateStoreState() {\n    this.readLock.lock();\n    try {\n      return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handle": "    public void handle(RMStateStoreEvent event) {\n      handleStoreEvent(event);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreAMRMTokenEvent.isUpdate": "  public boolean isUpdate() {\n    return isUpdate;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreAMRMTokenEvent.getAmrmTokenSecretManagerState": "  public AMRMTokenSecretManagerState getAmrmTokenSecretManagerState() {\n    return amrmTokenSecretManagerState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreRMDTEvent.getRmDTIdentifier": "  public RMDelegationTokenIdentifier getRmDTIdentifier() {\n    return rmDTIdentifier;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreRMDTEvent.getRenewDate": "  public Long getRenewDate() {\n    return renewDate;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "YARN RM  will shut down if ZKClient creation times out ",
            "Description": "The RM goes down showing the following stacktrace if the ZK client connection fails to be created. We should not exit but transition to StandBy and stop doing things and let the other RM take over.\n\n{code}\n2015-04-19 01:22:20,513  FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Received a org.apache.hadoop.yarn.server.resourcemanager.RMFatalEvent of type STATE_STORE_OP_FAILED. Cause:\njava.io.IOException: Wait for ZKClient creation timed out\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1066)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1090)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.existsWithRetries(ZKRMStateStore.java:996)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.updateApplicationStateInternal(ZKRMStateStore.java:643)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$UpdateAppTransition.transition(RMStateStore.java:162)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$UpdateAppTransition.transition(RMStateStore.java:147)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:879)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:874)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}"
        }
    },
    {
        "filename": "YARN-4984.json",
        "creation_time": "2016-04-21T19:16:03.000+0000",
        "stack_trace": "```\nException is:\norg.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 1380589 for hdfswrite) can't be found in cache\n    at org.apache.hadoop.ipc.Client.call(Client.java:1427)\n    at org.apache.hadoop.ipc.Client.call(Client.java:1358)\n    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n    at com.sun.proxy.$Proxy13.getFileInfo(Unknown Source)\n    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:771)\n    at sun.reflect.GeneratedMethodAccessor76.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:252)\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)\n    at com.sun.proxy.$Proxy14.getFileInfo(Unknown Source)\n    at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2116)\n    at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1315)\n    at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1311)\n    at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n    at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1311)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.checkExists(LogAggregationService.java:248)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.access$100(LogAggregationService.java:67)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$1.run(LogAggregationService.java:276)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at javax.security.auth.Subject.doAs(Subject.java:415)\n    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.createAppDir(LogAggregationService.java:261)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initAppAggregator(LogAggregationService.java:367)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initApp(LogAggregationService.java:320)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:447)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:67)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.call": "  Writable call(RPC.RpcKind rpcKind, Writable rpcRequest,\n      ConnectionId remoteId, int serviceClass,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    final Call call = createCall(rpcKind, rpcRequest);\n    final Connection connection = getConnection(remoteId, call, serviceClass,\n        fallbackToSimpleAuth);\n    try {\n      connection.sendRpcRequest(call);                 // send the rpc request\n    } catch (RejectedExecutionException e) {\n      throw new IOException(\"connection has been closed\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      LOG.warn(\"interrupted waiting to send rpc request to server\", e);\n      throw new IOException(e);\n    }\n\n    if (isAsynchronousMode()) {\n      Future<Writable> returnFuture = new AbstractFuture<Writable>() {\n        @Override\n        public Writable get() throws InterruptedException, ExecutionException {\n          try {\n            set(getRpcResponse(call, connection));\n          } catch (IOException ie) {\n            setException(ie);\n          }\n          return super.get();\n        }\n      };\n\n      returnValue.set(returnFuture);\n      return null;\n    } else {\n      return getRpcResponse(call, connection);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.isAsynchronousMode": "  static boolean isAsynchronousMode() {\n    return asynchronousMode.get();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnection": "  private Connection getConnection(ConnectionId remoteId,\n      Call call, int serviceClass, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    while (true) {\n      // These lines below can be shorten with computeIfAbsent in Java8\n      connection = connections.get(remoteId);\n      if (connection == null) {\n        connection = new Connection(remoteId, serviceClass);\n        Connection existing = connections.putIfAbsent(remoteId, connection);\n        if (existing != null) {\n          connection = existing;\n        }\n      }\n\n      if (connection.addCall(call)) {\n        break;\n      } else {\n        // This connection is closed, should be removed. But other thread could\n        // have already known this closedConnection, and replace it with a new\n        // connection. So we should call conditional remove to make sure we only\n        // remove this closedConnection.\n        connections.remove(remoteId, connection);\n      }\n    }\n\n    // If the server happens to be slow, the method below will take longer to\n    // establish a connection.\n    connection.setupIOstreams(fallbackToSimpleAuth);\n    return connection;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.createCall": "  Call createCall(RPC.RpcKind rpcKind, Writable rpcRequest) {\n    return new Call(rpcKind, rpcRequest);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRpcResponse": "  private Writable getRpcResponse(final Call call, final Connection connection)\n      throws IOException {\n    synchronized (call) {\n      while (!call.done) {\n        try {\n          call.wait();                           // wait for the result\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\"Call interrupted\");\n        }\n      }\n\n      if (call.error != null) {\n        if (call.error instanceof RemoteException) {\n          call.error.fillInStackTrace();\n          throw call.error;\n        } else { // local exception\n          InetSocketAddress address = connection.getRemoteAddress();\n          throw NetUtils.wrapException(address.getHostName(),\n                  address.getPort(),\n                  NetUtils.getHostname(),\n                  0,\n                  call.error);\n        }\n      } else {\n        return call.getRpcResponse();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setException": "    public synchronized void setException(IOException error) {\n      this.error = error;\n      callComplete();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.sendRpcRequest": "    public void sendRpcRequest(final Call call)\n        throws InterruptedException, IOException {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n\n      // Serialize the call to be sent. This is done from the actual\n      // caller thread, rather than the sendParamsExecutor thread,\n      \n      // so that if the serialization throws an error, it is reported\n      // properly. This also parallelizes the serialization.\n      //\n      // Format of a call on the wire:\n      // 0) Length of rest below (1 + 2)\n      // 1) RpcRequestHeader  - is serialized Delimited hence contains length\n      // 2) RpcRequest\n      //\n      // Items '1' and '2' are prepared here. \n      final DataOutputBuffer d = new DataOutputBuffer();\n      RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader(\n          call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry,\n          clientId);\n      header.writeDelimitedTo(d);\n      call.rpcRequest.write(d);\n\n      synchronized (sendRpcRequestLock) {\n        Future<?> senderFuture = sendParamsExecutor.submit(new Runnable() {\n          @Override\n          public void run() {\n            try {\n              synchronized (Connection.this.out) {\n                if (shouldCloseConnection.get()) {\n                  return;\n                }\n                \n                if (LOG.isDebugEnabled())\n                  LOG.debug(getName() + \" sending #\" + call.id);\n         \n                byte[] data = d.getData();\n                int totalLength = d.getLength();\n                out.writeInt(totalLength); // Total Length\n                out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest\n                out.flush();\n              }\n            } catch (IOException e) {\n              // exception at this point would leave the connection in an\n              // unrecoverable state (eg half a call left on the wire).\n              // So, close the connection, killing any outstanding calls\n              markClosed(e);\n            } finally {\n              //the buffer is just an in-memory buffer, but it is still polite to\n              // close early\n              IOUtils.closeStream(d);\n            }\n          }\n        });\n      \n        try {\n          senderFuture.get();\n        } catch (ExecutionException e) {\n          Throwable cause = e.getCause();\n          \n          // cause should only be a RuntimeException as the Runnable above\n          // catches IOException\n          if (cause instanceof RuntimeException) {\n            throw (RuntimeException) cause;\n          } else {\n            throw new RuntimeException(\"unexpected checked exception\", cause);\n          }\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.invoke": "    public Object invoke(Object proxy, Method method, Object[] args)\n        throws ServiceException {\n      long startTime = 0;\n      if (LOG.isDebugEnabled()) {\n        startTime = Time.now();\n      }\n      \n      if (args.length != 2) { // RpcController + Message\n        throw new ServiceException(\"Too many parameters for request. Method: [\"\n            + method.getName() + \"]\" + \", Expected: 2, Actual: \"\n            + args.length);\n      }\n      if (args[1] == null) {\n        throw new ServiceException(\"null param while calling Method: [\"\n            + method.getName() + \"]\");\n      }\n\n      // if Tracing is on then start a new span for this rpc.\n      // guard it in the if statement to make sure there isn't\n      // any extra string manipulation.\n      Tracer tracer = Tracer.curThreadTracer();\n      TraceScope traceScope = null;\n      if (tracer != null) {\n        traceScope = tracer.newScope(RpcClientUtil.methodToTraceString(method));\n      }\n\n      RequestHeaderProto rpcRequestHeader = constructRpcRequestHeader(method);\n      \n      if (LOG.isTraceEnabled()) {\n        LOG.trace(Thread.currentThread().getId() + \": Call -> \" +\n            remoteId + \": \" + method.getName() +\n            \" {\" + TextFormat.shortDebugString((Message) args[1]) + \"}\");\n      }\n\n\n      Message theRequest = (Message) args[1];\n      final RpcResponseWrapper val;\n      try {\n        val = (RpcResponseWrapper) client.call(RPC.RpcKind.RPC_PROTOCOL_BUFFER,\n            new RpcRequestWrapper(rpcRequestHeader, theRequest), remoteId,\n            fallbackToSimpleAuth);\n\n      } catch (Throwable e) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Exception <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + e + \"}\");\n        }\n        if (traceScope != null) {\n          traceScope.addTimelineAnnotation(\"Call got exception: \" +\n              e.toString());\n        }\n        throw new ServiceException(e);\n      } finally {\n        if (traceScope != null) traceScope.close();\n      }\n\n      if (LOG.isDebugEnabled()) {\n        long callTime = Time.now() - startTime;\n        LOG.debug(\"Call: \" + method.getName() + \" took \" + callTime + \"ms\");\n      }\n      \n      Message prototype = null;\n      try {\n        prototype = getReturnProtoType(method);\n      } catch (Exception e) {\n        throw new ServiceException(e);\n      }\n      Message returnMessage;\n      try {\n        returnMessage = prototype.newBuilderForType()\n            .mergeFrom(val.theResponseRead).build();\n\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(Thread.currentThread().getId() + \": Response <- \" +\n              remoteId + \": \" + method.getName() +\n                \" {\" + TextFormat.shortDebugString(returnMessage) + \"}\");\n        }\n\n      } catch (Throwable e) {\n        throw new ServiceException(e);\n      }\n      return returnMessage;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getReturnProtoType": "    private Message getReturnProtoType(Method method) throws Exception {\n      if (returnTypes.containsKey(method.getName())) {\n        return returnTypes.get(method.getName());\n      }\n      \n      Class<?> returnType = method.getReturnType();\n      Method newInstMethod = returnType.getMethod(\"getDefaultInstance\");\n      newInstMethod.setAccessible(true);\n      Message prototype = (Message) newInstMethod.invoke(null, (Object[]) null);\n      returnTypes.put(method.getName(), prototype);\n      return prototype;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcRequestWrapper request = (RpcRequestWrapper) writableRequest;\n        RequestHeaderProto rpcRequest = request.requestHeader;\n        String methodName = rpcRequest.getMethodName();\n        \n        \n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = prototype.newBuilderForType()\n            .mergeFrom(request.theRequestRead).build();\n        \n        Message result;\n        long startTime = Time.now();\n        int qTime = (int) (startTime - receiveTime);\n        Exception exception = null;\n        try {\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n        } catch (ServiceException e) {\n          exception = (Exception) e.getCause();\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          exception = e;\n          throw e;\n        } finally {\n          int processingTime = (int) (Time.now() - startTime);\n          if (LOG.isDebugEnabled()) {\n            String msg = \"Served: \" + methodName + \" queueTime= \" + qTime +\n                \" procesingTime= \" + processingTime;\n            if (exception != null) {\n              msg += \" exception= \" + exception.getClass().getSimpleName();\n            }\n            LOG.debug(msg);\n          }\n          String detailedMetricsName = (exception == null) ?\n              methodName :\n              exception.getClass().getSimpleName();\n          server.updateMetrics(detailedMetricsName, qTime, processingTime);\n        }\n        return new RpcResponseWrapper(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.close": "    public void close() throws IOException {\n      if (!isClosed) {\n        isClosed = true;\n        CLIENTS.stopClient(client);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.toString": "    public String toString() {\n      return requestHeader.getDeclaringClassProtocolName() + \".\" +\n          requestHeader.getMethodName();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.constructRpcRequestHeader": "    private RequestHeaderProto constructRpcRequestHeader(Method method) {\n      RequestHeaderProto.Builder builder = RequestHeaderProto\n          .newBuilder();\n      builder.setMethodName(method.getName());\n     \n\n      // For protobuf, {@code protocol} used when creating client side proxy is\n      // the interface extending BlockingInterface, which has the annotations \n      // such as ProtocolName etc.\n      //\n      // Using Method.getDeclaringClass(), as in WritableEngine to get at\n      // the protocol interface will return BlockingInterface, from where \n      // the annotation ProtocolName and Version cannot be\n      // obtained.\n      //\n      // Hence we simply use the protocol class used to create the proxy.\n      // For PB this may limit the use of mixins on client side.\n      builder.setDeclaringClassProtocolName(protocolName);\n      builder.setClientProtocolVersion(clientProtocolVersion);\n      return builder.build();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod": "  protected Object invokeMethod(Method method, Object[] args) throws Throwable {\n    try {\n      if (!method.isAccessible()) {\n        method.setAccessible(true);\n      }\n      return method.invoke(currentProxy.proxy, args);\n    } catch (InvocationTargetException e) {\n      throw e.getCause();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invoke": "  public Object invoke(Object proxy, Method method, Object[] args)\n    throws Throwable {\n    RetryPolicy policy = methodNameToPolicyMap.get(method.getName());\n    if (policy == null) {\n      policy = defaultPolicy;\n    }\n    \n    // The number of times this method invocation has been failed over.\n    int invocationFailoverCount = 0;\n    final boolean isRpc = isRpcInvocation(currentProxy.proxy);\n    final int callId = isRpc? Client.nextCallId(): RpcConstants.INVALID_CALL_ID;\n    int retries = 0;\n    while (true) {\n      // The number of times this invocation handler has ever been failed over,\n      // before this method invocation attempt. Used to prevent concurrent\n      // failed method invocations from triggering multiple failover attempts.\n      long invocationAttemptFailoverCount;\n      synchronized (proxyProvider) {\n        invocationAttemptFailoverCount = proxyProviderFailoverCount;\n      }\n\n      if (isRpc) {\n        Client.setCallIdAndRetryCount(callId, retries);\n      }\n      try {\n        Object ret = invokeMethod(method, args);\n        hasMadeASuccessfulCall = true;\n        return ret;\n      } catch (Exception ex) {\n        if (Thread.currentThread().isInterrupted()) {\n          // If interrupted, do not retry.\n          throw ex;\n        }\n        boolean isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n            .getMethod(method.getName(), method.getParameterTypes())\n            .isAnnotationPresent(Idempotent.class);\n        if (!isIdempotentOrAtMostOnce) {\n          isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n              .getMethod(method.getName(), method.getParameterTypes())\n              .isAnnotationPresent(AtMostOnce.class);\n        }\n        List<RetryAction> actions = extractActions(policy, ex, retries++,\n                invocationFailoverCount, isIdempotentOrAtMostOnce);\n        RetryAction failAction = getFailAction(actions);\n        if (failAction != null) {\n          // fail.\n          if (failAction.reason != null) {\n            LOG.warn(\"Exception while invoking \" + currentProxy.proxy.getClass()\n                + \".\" + method.getName() + \" over \" + currentProxy.proxyInfo\n                + \". Not retrying because \" + failAction.reason, ex);\n          }\n          throw ex;\n        } else { // retry or failover\n          // avoid logging the failover if this is the first call on this\n          // proxy object, and we successfully achieve the failover without\n          // any flip-flopping\n          boolean worthLogging = \n            !(invocationFailoverCount == 0 && !hasMadeASuccessfulCall);\n          worthLogging |= LOG.isDebugEnabled();\n          RetryAction failOverAction = getFailOverAction(actions);\n          long delay = getDelayMillis(actions);\n\n          if (worthLogging) {\n            String msg = \"Exception while invoking \" + method.getName()\n                + \" of class \" + currentProxy.proxy.getClass().getSimpleName()\n                + \" over \" + currentProxy.proxyInfo;\n\n            if (invocationFailoverCount > 0) {\n              msg += \" after \" + invocationFailoverCount + \" fail over attempts\"; \n            }\n\n            if (failOverAction != null) {\n              // failover\n              msg += \". Trying to fail over \" + formatSleepMessage(delay);\n            } else {\n              // retry\n              msg += \". Retrying \" + formatSleepMessage(delay);\n            }\n            LOG.info(msg, ex);\n          }\n\n          if (delay > 0) {\n            Thread.sleep(delay);\n          }\n\n          if (failOverAction != null) {\n            // Make sure that concurrent failed method invocations only cause a\n            // single actual fail over.\n            synchronized (proxyProvider) {\n              if (invocationAttemptFailoverCount == proxyProviderFailoverCount) {\n                proxyProvider.performFailover(currentProxy.proxy);\n                proxyProviderFailoverCount++;\n              } else {\n                LOG.warn(\"A failover has occurred since the start of this method\"\n                    + \" invocation attempt.\");\n              }\n              currentProxy = proxyProvider.getProxy();\n            }\n            invocationFailoverCount++;\n          }\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystemLinkResolver.resolve": "  public T resolve(final FileSystem filesys, final Path path)\n      throws IOException {\n    int count = 0;\n    T in = null;\n    Path p = path;\n    // Assumes path belongs to this FileSystem.\n    // Callers validate this by passing paths through FileSystem#checkPath\n    FileSystem fs = filesys;\n    for (boolean isLink = true; isLink;) {\n      try {\n        in = doCall(p);\n        isLink = false;\n      } catch (UnresolvedLinkException e) {\n        if (!filesys.resolveSymlinks) {\n          throw new IOException(\"Path \" + path + \" contains a symlink\"\n              + \" and symlink resolution is disabled (\"\n              + CommonConfigurationKeys.FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY\n              + \").\", e);\n        }\n        if (!FileSystem.areSymlinksEnabled()) {\n          throw new IOException(\"Symlink resolution is disabled in\" +\n              \" this version of Hadoop.\");\n        }\n        if (count++ > FsConstants.MAX_PATH_LINKS) {\n          throw new IOException(\"Possible cyclic loop while \" +\n                                \"following symbolic link \" + path);\n        }\n        // Resolve the first unresolved path component\n        p = FSLinkResolver.qualifySymlinkTarget(fs.getUri(), p,\n            filesys.resolveLink(p));\n        fs = FileSystem.getFSofPath(p, filesys.getConf());\n        // Have to call next if it's a new FS\n        if (!fs.equals(filesys)) {\n          return next(fs, p);\n        }\n        // Else, we keep resolving with this filesystem\n      }\n    }\n    // Successful call, path was fully resolved\n    return in;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystemLinkResolver.doCall": "  abstract public T doCall(final Path p) throws IOException,\n      UnresolvedLinkException;\n\n  /**\n   * Calls the abstract FileSystem call equivalent to the specialized subclass\n   * implementation in {@link #doCall(Path)}. This is used when retrying the",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystemLinkResolver.next": "  abstract public T next(final FileSystem fs, final Path p) throws IOException;\n\n  /**\n   * Attempt calling overridden {@link #doCall(Path)} method with",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.checkExists": "  private boolean checkExists(FileSystem fs, Path path, FsPermission fsPerm)\n      throws IOException {\n    boolean exists = true;\n    try {\n      FileStatus appDirStatus = fs.getFileStatus(path);\n      if (!APP_DIR_PERMISSIONS.equals(appDirStatus.getPermission())) {\n        fs.setPermission(path, APP_DIR_PERMISSIONS);\n      }\n    } catch (FileNotFoundException fnfe) {\n      exists = false;\n    }\n    return exists;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.run": "      public void run() {\n        try {\n          appLogAggregator.run();\n        } finally {\n          appLogAggregators.remove(appId);\n          closeFileSystems(userUgi);\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.getFileSystem": "  protected FileSystem getFileSystem(Configuration conf) throws IOException {\n    return this.remoteRootLogDir.getFileSystem(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.getRemoteAppLogDir": "  Path getRemoteAppLogDir(ApplicationId appId, String user) {\n    return LogAggregationUtils.getRemoteAppLogDir(this.remoteRootLogDir, appId,\n        user, this.remoteRootLogDirSuffix);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.closeFileSystems": "  protected void closeFileSystems(final UserGroupInformation userUgi) {\n    try {\n      FileSystem.closeAllForUGI(userUgi);\n    } catch (IOException e) {\n      LOG.warn(\"Failed to close filesystems: \", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.createDir": "  private void createDir(FileSystem fs, Path path, FsPermission fsPerm)\n      throws IOException {\n    FsPermission dirPerm = new FsPermission(fsPerm);\n    fs.mkdirs(path, dirPerm);\n    FsPermission umask = FsPermission.getUMask(fs.getConf());\n    if (!dirPerm.equals(dirPerm.applyUMask(umask))) {\n      fs.setPermission(path, new FsPermission(fsPerm));\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.createAppDir": "  protected void createAppDir(final String user, final ApplicationId appId,\n      UserGroupInformation userUgi) {\n    try {\n      userUgi.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          try {\n            // TODO: Reuse FS for user?\n            FileSystem remoteFS = getFileSystem(getConfig());\n\n            // Only creating directories if they are missing to avoid\n            // unnecessary load on the filesystem from all of the nodes\n            Path appDir = LogAggregationUtils.getRemoteAppLogDir(\n                LogAggregationService.this.remoteRootLogDir, appId, user,\n                LogAggregationService.this.remoteRootLogDirSuffix);\n            appDir = appDir.makeQualified(remoteFS.getUri(),\n                remoteFS.getWorkingDirectory());\n\n            if (!checkExists(remoteFS, appDir, APP_DIR_PERMISSIONS)) {\n              Path suffixDir = LogAggregationUtils.getRemoteLogSuffixedDir(\n                  LogAggregationService.this.remoteRootLogDir, user,\n                  LogAggregationService.this.remoteRootLogDirSuffix);\n              suffixDir = suffixDir.makeQualified(remoteFS.getUri(),\n                  remoteFS.getWorkingDirectory());\n\n              if (!checkExists(remoteFS, suffixDir, APP_DIR_PERMISSIONS)) {\n                Path userDir = LogAggregationUtils.getRemoteLogUserDir(\n                    LogAggregationService.this.remoteRootLogDir, user);\n                userDir = userDir.makeQualified(remoteFS.getUri(),\n                    remoteFS.getWorkingDirectory());\n\n                if (!checkExists(remoteFS, userDir, APP_DIR_PERMISSIONS)) {\n                  createDir(remoteFS, userDir, APP_DIR_PERMISSIONS);\n                }\n\n                createDir(remoteFS, suffixDir, APP_DIR_PERMISSIONS);\n              }\n\n              createDir(remoteFS, appDir, APP_DIR_PERMISSIONS);\n            }\n\n          } catch (IOException e) {\n            LOG.error(\"Failed to setup application log directory for \"\n                + appId, e);\n            throw e;\n          }\n          return null;\n        }\n      });\n    } catch (Exception e) {\n      throw new YarnRuntimeException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initAppAggregator": "  protected void initAppAggregator(final ApplicationId appId, String user,\n      Credentials credentials, Map<ApplicationAccessType, String> appAcls,\n      LogAggregationContext logAggregationContext) {\n\n    // Get user's FileSystem credentials\n    final UserGroupInformation userUgi =\n        UserGroupInformation.createRemoteUser(user);\n    if (credentials != null) {\n      userUgi.addCredentials(credentials);\n    }\n\n    // New application\n    final AppLogAggregator appLogAggregator =\n        new AppLogAggregatorImpl(this.dispatcher, this.deletionService,\n            getConfig(), appId, userUgi, this.nodeId, dirsHandler,\n            getRemoteNodeLogFileForApp(appId, user),\n            appAcls, logAggregationContext, this.context,\n            getLocalFileContext(getConfig()));\n    if (this.appLogAggregators.putIfAbsent(appId, appLogAggregator) != null) {\n      throw new YarnRuntimeException(\"Duplicate initApp for \" + appId);\n    }\n    // wait until check for existing aggregator to create dirs\n    YarnRuntimeException appDirException = null;\n    try {\n      // Create the app dir\n      createAppDir(user, appId, userUgi);\n    } catch (Exception e) {\n      appLogAggregator.disableLogAggregation();\n      if (!(e instanceof YarnRuntimeException)) {\n        appDirException = new YarnRuntimeException(e);\n      } else {\n        appDirException = (YarnRuntimeException)e;\n      }\n    }\n\n    // TODO Get the user configuration for the list of containers that need log\n    // aggregation.\n\n    // Schedule the aggregator.\n    Runnable aggregatorWrapper = new Runnable() {\n      public void run() {\n        try {\n          appLogAggregator.run();\n        } finally {\n          appLogAggregators.remove(appId);\n          closeFileSystems(userUgi);\n        }\n      }\n    };\n    this.threadPool.execute(aggregatorWrapper);\n\n    if (appDirException != null) {\n      throw appDirException;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.getRemoteNodeLogFileForApp": "  Path getRemoteNodeLogFileForApp(ApplicationId appId, String user) {\n    return LogAggregationUtils.getRemoteNodeLogFileForApp(\n        this.remoteRootLogDir, appId, user, this.nodeId,\n        this.remoteRootLogDirSuffix);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.getLocalFileContext": "  FileContext getLocalFileContext(Configuration conf) {\n    try {\n      return FileContext.getLocalFSFileContext(conf);\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Failed to access local fs\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initApp": "  private void initApp(final ApplicationId appId, String user,\n      Credentials credentials, Map<ApplicationAccessType, String> appAcls,\n      LogAggregationContext logAggregationContext) {\n    ApplicationEvent eventResponse;\n    try {\n      verifyAndCreateRemoteLogDir(getConfig());\n      initAppAggregator(appId, user, credentials, appAcls,\n          logAggregationContext);\n      eventResponse = new ApplicationEvent(appId,\n          ApplicationEventType.APPLICATION_LOG_HANDLING_INITED);\n    } catch (YarnRuntimeException e) {\n      LOG.warn(\"Application failed to init aggregation\", e);\n      eventResponse = new ApplicationEvent(appId,\n          ApplicationEventType.APPLICATION_LOG_HANDLING_FAILED);\n    }\n    this.dispatcher.getEventHandler().handle(eventResponse);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.verifyAndCreateRemoteLogDir": "  void verifyAndCreateRemoteLogDir(Configuration conf) {\n    // Checking the existence of the TLD\n    FileSystem remoteFS = null;\n    try {\n      remoteFS = getFileSystem(conf);\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\"Unable to get Remote FileSystem instance\", e);\n    }\n    boolean remoteExists = true;\n    try {\n      FsPermission perms =\n          remoteFS.getFileStatus(this.remoteRootLogDir).getPermission();\n      if (!perms.equals(TLDIR_PERMISSIONS)) {\n        LOG.warn(\"Remote Root Log Dir [\" + this.remoteRootLogDir\n            + \"] already exist, but with incorrect permissions. \"\n            + \"Expected: [\" + TLDIR_PERMISSIONS + \"], Found: [\" + perms\n            + \"].\" + \" The cluster may have problems with multiple users.\");\n      }\n    } catch (FileNotFoundException e) {\n      remoteExists = false;\n    } catch (IOException e) {\n      throw new YarnRuntimeException(\n          \"Failed to check permissions for dir [\"\n              + this.remoteRootLogDir + \"]\", e);\n    }\n    if (!remoteExists) {\n      LOG.warn(\"Remote Root Log Dir [\" + this.remoteRootLogDir\n          + \"] does not exist. Attempting to create it.\");\n      try {\n        Path qualified =\n            this.remoteRootLogDir.makeQualified(remoteFS.getUri(),\n                remoteFS.getWorkingDirectory());\n        remoteFS.mkdirs(qualified, new FsPermission(TLDIR_PERMISSIONS));\n        remoteFS.setPermission(qualified, new FsPermission(TLDIR_PERMISSIONS));\n      } catch (IOException e) {\n        throw new YarnRuntimeException(\"Failed to create remoteLogDir [\"\n            + this.remoteRootLogDir + \"]\", e);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle": "  public void handle(LogHandlerEvent event) {\n    switch (event.getType()) {\n      case APPLICATION_STARTED:\n        LogHandlerAppStartedEvent appStartEvent =\n            (LogHandlerAppStartedEvent) event;\n        initApp(appStartEvent.getApplicationId(), appStartEvent.getUser(),\n            appStartEvent.getCredentials(),\n            appStartEvent.getApplicationAcls(),\n            appStartEvent.getLogAggregationContext());\n        break;\n      case CONTAINER_FINISHED:\n        LogHandlerContainerFinishedEvent containerFinishEvent =\n            (LogHandlerContainerFinishedEvent) event;\n        stopContainer(containerFinishEvent.getContainerId(),\n            containerFinishEvent.getExitCode());\n        break;\n      case APPLICATION_FINISHED:\n        LogHandlerAppFinishedEvent appFinishedEvent =\n            (LogHandlerAppFinishedEvent) event;\n        stopApp(appFinishedEvent.getApplicationId());\n        break;\n      default:\n        ; // Ignore\n    }\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcClientUtil.methodToTraceString": "  public static String methodToTraceString(Method method) {\n    Class<?> clazz = method.getDeclaringClass();\n    while (true) {\n      Class<?> next = clazz.getEnclosingClass();\n      if (next == null || next.getEnclosingClass() == null) break;\n      clazz = next;\n    }\n    return clazz.getSimpleName() + \"#\" + method.getName();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FSLinkResolver.qualifySymlinkTarget": "  public static Path qualifySymlinkTarget(final URI pathURI,\n      Path pathWithLink, Path target) {\n    // NB: makeQualified uses the target's scheme and authority, if\n    // specified, and the scheme and authority of pathURI, if not.\n    final URI targetUri = target.toUri();\n    final String scheme = targetUri.getScheme();\n    final String auth = targetUri.getAuthority();\n    return (scheme == null && auth == null) ? target.makeQualified(pathURI,\n        pathWithLink.getParent()) : target;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.areSymlinksEnabled": "  public static boolean areSymlinksEnabled() {\n    return symlinksEnabled;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getUri": "  public abstract URI getUri();\n  \n  /**\n   * Return a canonicalized form of this FileSystem's URI.\n   * \n   * The default implementation simply calls {@link #canonicalizeUri(URI)}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.equals": "      public boolean equals(Object obj) {\n        if (obj == this) {\n          return true;\n        }\n        if (obj != null && obj instanceof Key) {\n          Key that = (Key)obj;\n          return isEqual(this.scheme, that.scheme)\n                 && isEqual(this.authority, that.authority)\n                 && isEqual(this.ugi, that.ugi)\n                 && (this.unique == that.unique);\n        }\n        return false;        \n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.isEqual": "      static boolean isEqual(Object a, Object b) {\n        return a == b || (a != null && a.equals(b));        \n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getFSofPath": "  protected static FileSystem getFSofPath(final Path absOrFqPath,\n      final Configuration conf)\n      throws UnsupportedFileSystemException, IOException {\n    absOrFqPath.checkNotSchemeWithRelative();\n    absOrFqPath.checkNotRelative();\n\n    // Uses the default file system if not fully qualified\n    return get(absOrFqPath.toUri(), conf);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.get": "    FileSystem get(URI uri, Configuration conf) throws IOException{\n      Key key = new Key(uri, conf);\n      return getInternal(uri, conf, key);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregator.disableLogAggregation": "  void disableLogAggregation();\n}"
        },
        "bug_report": {
            "Title": "LogAggregationService shouldn't swallow exception in handling createAppDir() which cause thread leak.",
            "Description": "Due to YARN-4325, many stale applications still exists in NM state store and get recovered after NM restart. The app initiation will get failed due to token invalid, but exception is swallowed and aggregator thread is still created for invalid app.\n\nException is:\n{noformat}\n158 2016-04-19 23:38:33,039 ERROR logaggregation.LogAggregationService (LogAggregationService.java:run(300)) - Failed to setup application log directory for application_1448        060878692_11842\n    159 org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 1380589 for hdfswrite) can't be fo        und in cache\n    160         at org.apache.hadoop.ipc.Client.call(Client.java:1427)\n    161         at org.apache.hadoop.ipc.Client.call(Client.java:1358)\n    162         at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n    163         at com.sun.proxy.$Proxy13.getFileInfo(Unknown Source)\n    164         at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:771)\n    165         at sun.reflect.GeneratedMethodAccessor76.invoke(Unknown Source)\n    166         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    167         at java.lang.reflect.Method.invoke(Method.java:606)\n    168         at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:252)\n    169         at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)\n    170         at com.sun.proxy.$Proxy14.getFileInfo(Unknown Source)\n    171         at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2116)\n    172         at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1315)\n    173         at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1311)\n    174         at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n    175         at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1311)\n    176         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.checkExists(LogAggregationService.java:248)\n    177         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.access$100(LogAggregationService.java:67)\n    178         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$1.run(LogAggregationService.java:276)\n    179         at java.security.AccessController.doPrivileged(Native Method)\n    180         at javax.security.auth.Subject.doAs(Subject.java:415)\n    181         at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n    182         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.createAppDir(LogAggregationService.java:261)\n    183         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initAppAggregator(LogAggregationService.java:367)\n    184         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initApp(LogAggregationService.java:320)\n    185         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:447)\n    186         at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:67)\n\n{noformat}"
        }
    },
    {
        "filename": "YARN-4584.json",
        "creation_time": "2016-01-12T09:08:31.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.recover(RMAppAttemptImpl.java:887)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recover(RMAppImpl.java:826)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:953)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:946)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:786)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:464)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1232)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:594)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1022)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1062)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1058)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1705)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1058)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:323)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:127)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:877)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.recover": "  public void recover(RMState state) {\n    ApplicationStateData appState =\n        state.getApplicationState().get(getAppAttemptId().getApplicationId());\n    ApplicationAttemptStateData attemptState =\n        appState.getAttempt(getAppAttemptId());\n    assert attemptState != null;\n    LOG.info(\"Recovering attempt: \" + getAppAttemptId() + \" with final state: \"\n        + attemptState.getState());\n    diagnostics.append(\"Attempt recovered after RM restart\");\n    diagnostics.append(attemptState.getDiagnostics());\n    this.amContainerExitStatus = attemptState.getAMContainerExitStatus();\n    if (amContainerExitStatus == ContainerExitStatus.PREEMPTED) {\n      this.attemptMetrics.setIsPreempted();\n    }\n\n    Credentials credentials = attemptState.getAppAttemptTokens();\n    setMasterContainer(attemptState.getMasterContainer());\n    recoverAppAttemptCredentials(credentials, attemptState.getState());\n    this.recoveredFinalState = attemptState.getState();\n    this.originalTrackingUrl = attemptState.getFinalTrackingUrl();\n    this.finalStatus = attemptState.getFinalApplicationStatus();\n    this.startTime = attemptState.getStartTime();\n    this.finishTime = attemptState.getFinishTime();\n    this.attemptMetrics.updateAggregateAppResourceUsage(\n        attemptState.getMemorySeconds(),attemptState.getVcoreSeconds());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getMasterContainer": "  public Container getMasterContainer() {\n    return this.masterContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getStartTime": "  public long getStartTime() {\n    this.readLock.lock();\n    try {\n      return this.startTime;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAMContainerExitStatus": "  public int getAMContainerExitStatus() {\n    this.readLock.lock();\n    try {\n      return this.amContainerExitStatus;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getFinalApplicationStatus": "  public FinalApplicationStatus getFinalApplicationStatus() {\n    this.readLock.lock();\n    try {\n      return this.finalStatus;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getFinishTime": "  public long getFinishTime() {\n    try {\n      this.readLock.lock();\n      return this.finishTime;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getDiagnostics": "  public String getDiagnostics() {\n    this.readLock.lock();\n    try {\n      if (diagnostics.length() == 0 && amLaunchDiagnostics != null) {\n        return amLaunchDiagnostics;\n      }\n      return this.diagnostics.toString();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setMasterContainer": "  public void setMasterContainer(Container container) {\n    masterContainer = container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.recoverAppAttemptCredentials": "  private void recoverAppAttemptCredentials(Credentials appAttemptTokens,\n      RMAppAttemptState state) {\n    if (appAttemptTokens == null || state == RMAppAttemptState.FAILED\n        || state == RMAppAttemptState.FINISHED\n        || state == RMAppAttemptState.KILLED) {\n      return;\n    }\n\n    if (UserGroupInformation.isSecurityEnabled()) {\n      byte[] clientTokenMasterKeyBytes = appAttemptTokens.getSecretKey(\n          RMStateStore.AM_CLIENT_TOKEN_MASTER_KEY_NAME);\n      if (clientTokenMasterKeyBytes != null) {\n        clientTokenMasterKey = rmContext.getClientToAMTokenSecretManager()\n            .registerMasterKey(applicationAttemptId, clientTokenMasterKeyBytes);\n      }\n    }\n\n    setAMRMToken(rmContext.getAMRMTokenSecretManager().createAndGetAMRMToken(\n        applicationAttemptId));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptId": "  public ApplicationAttemptId getAppAttemptId() {\n    return this.applicationAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getState": "  public RMAppAttemptState getState() {\n    this.readLock.lock();\n\n    try {\n      return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recover": "  public void recover(RMState state) {\n    ApplicationStateData appState =\n        state.getApplicationState().get(getApplicationId());\n    this.recoveredFinalState = appState.getState();\n    LOG.info(\"Recovering app: \" + getApplicationId() + \" with \" + \n        + appState.getAttemptCount() + \" attempts and final state = \"\n        + this.recoveredFinalState );\n    this.diagnostics.append(null == appState.getDiagnostics() ? \"\" : appState\n        .getDiagnostics());\n    this.storedFinishTime = appState.getFinishTime();\n    this.startTime = appState.getStartTime();\n    this.callerContext = appState.getCallerContext();\n    // If interval > 0, some attempts might have been deleted.\n    if (submissionContext.getAttemptFailuresValidityInterval() > 0) {\n      this.firstAttemptIdInStateStore = appState.getFirstAttemptId();\n      this.nextAttemptId = firstAttemptIdInStateStore;\n    }\n\n    // send the ATS create Event\n    sendATSCreateEvent(this, this.startTime);\n\n    for(int i=0; i<appState.getAttemptCount(); ++i) {\n      // create attempt\n      createNewAttempt();\n      ((RMAppAttemptImpl)this.currentAttempt).recover(state);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getFinishTime": "  public long getFinishTime() {\n    this.readLock.lock();\n\n    try {\n      return this.finishTime;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getState": "  public RMAppState getState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.sendATSCreateEvent": "  private void sendATSCreateEvent(RMApp app, long startTime) {\n    rmContext.getRMApplicationHistoryWriter().applicationStarted(app);\n    rmContext.getSystemMetricsPublisher().appCreated(app, startTime);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.createNewAttempt": "  private void createNewAttempt() {\n    ApplicationAttemptId appAttemptId =\n        ApplicationAttemptId.newInstance(applicationId, nextAttemptId++);\n\n    BlacklistManager currentAMBlacklist;\n    if (currentAttempt != null) {\n      currentAMBlacklist = currentAttempt.getAMBlacklist();\n    } else {\n      if (amBlacklistingEnabled) {\n        currentAMBlacklist = new SimpleBlacklistManager(\n            scheduler.getNumClusterNodes(), blacklistDisableThreshold);\n      } else {\n        currentAMBlacklist = new DisabledBlacklistManager();\n      }\n    }\n    RMAppAttempt attempt =\n        new RMAppAttemptImpl(appAttemptId, rmContext, scheduler, masterService,\n          submissionContext, conf,\n          // The newly created attempt maybe last attempt if (number of\n          // previously failed attempts(which should not include Preempted,\n          // hardware error and NM resync) + 1) equal to the max-attempt\n          // limit.\n          maxAppAttempts == (getNumFailedAppAttempts() + 1), amReq,\n          currentAMBlacklist);\n    attempts.put(appAttemptId, attempt);\n    currentAttempt = attempt;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getStartTime": "  public long getStartTime() {\n    this.readLock.lock();\n\n    try {\n      return this.startTime;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getCallerContext": "  public CallerContext getCallerContext() {\n    return callerContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getDiagnostics": "  public StringBuilder getDiagnostics() {\n    this.readLock.lock();\n    try {\n      if (diagnostics.length() == 0 && getCurrentAppAttempt() != null) {\n        String appAttemptDiagnostics = getCurrentAppAttempt().getDiagnostics();\n        if (appAttemptDiagnostics != null) {\n          return new StringBuilder(appAttemptDiagnostics);\n        }\n      }\n      return this.diagnostics;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.transition": "    public RMAppState transition(RMAppImpl app, RMAppEvent event) {\n      int numberOfFailure = app.getNumFailedAppAttempts();\n      LOG.info(\"The number of failed attempts\"\n          + (app.attemptFailuresValidityInterval > 0 ? \" in previous \"\n              + app.attemptFailuresValidityInterval + \" milliseconds \" : \" \")\n          + \"is \" + numberOfFailure + \". The max attempts is \"\n          + app.maxAppAttempts);\n\n      removeExcessAttempts(app);\n\n      if (!app.submissionContext.getUnmanagedAM()\n          && numberOfFailure < app.maxAppAttempts) {\n        if (initialState.equals(RMAppState.KILLING)) {\n          // If this is not last attempt, app should be killed instead of\n          // launching a new attempt\n          app.rememberTargetTransitionsAndStoreState(event,\n            new AppKilledTransition(), RMAppState.KILLED, RMAppState.KILLED);\n          return RMAppState.FINAL_SAVING;\n        }\n\n        boolean transferStateFromPreviousAttempt;\n        RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n        transferStateFromPreviousAttempt =\n            failedEvent.getTransferStateFromPreviousAttempt();\n\n        RMAppAttempt oldAttempt = app.currentAttempt;\n        app.createAndStartNewAttempt(transferStateFromPreviousAttempt);\n        // Transfer the state from the previous attempt to the current attempt.\n        // Note that the previous failed attempt may still be collecting the\n        // container events from the scheduler and update its data structures\n        // before the new attempt is created. We always transferState for\n        // finished containers so that they can be acked to NM,\n        // but when pulling finished container we will check this flag again.\n        ((RMAppAttemptImpl) app.currentAttempt)\n          .transferStateFromAttempt(oldAttempt);\n        return initialState;\n      } else {\n        if (numberOfFailure >= app.maxAppAttempts) {\n          app.isNumAttemptsBeyondThreshold = true;\n        }\n        app.rememberTargetTransitionsAndStoreState(event,\n          new AttemptFailedFinalStateSavedTransition(), RMAppState.FAILED,\n          RMAppState.FAILED);\n        return RMAppState.FINAL_SAVING;\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.processNodeUpdate": "  private void processNodeUpdate(RMAppNodeUpdateType type, RMNode node) {\n    NodeState nodeState = node.getState();\n    updatedNodes.add(node);\n    LOG.debug(\"Received node update event:\" + type + \" for node:\" + node\n        + \" with state:\" + nodeState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.rememberTargetTransitionsAndStoreState": "  private void rememberTargetTransitionsAndStoreState(RMAppEvent event,\n      Object transitionToDo, RMAppState targetFinalState,\n      RMAppState stateToBeStored) {\n    rememberTargetTransitions(event, transitionToDo, targetFinalState);\n    this.stateBeforeFinalSaving = getState();\n    this.storedFinishTime = this.systemClock.getTime();\n\n    LOG.info(\"Updating application \" + this.applicationId\n        + \" with final state: \" + this.targetedFinalState);\n    // we lost attempt_finished diagnostics in app, because attempt_finished\n    // diagnostics is sent after app final state is saved. Later on, we will\n    // create GetApplicationAttemptReport specifically for getting per attempt\n    // info.\n    String diags = null;\n    switch (event.getType()) {\n    case APP_REJECTED:\n    case ATTEMPT_FINISHED:\n    case ATTEMPT_KILLED:\n      diags = event.getDiagnosticMsg();\n      break;\n    case ATTEMPT_FAILED:\n      RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n      diags = getAppAttemptFailedDiagnostics(failedEvent);\n      break;\n    default:\n      break;\n    }\n\n    ApplicationStateData appState =\n        ApplicationStateData.newInstance(this.submitTime, this.startTime,\n            this.user, this.submissionContext,\n            stateToBeStored, diags, this.storedFinishTime, this.callerContext);\n    this.rmContext.getStateStore().updateApplicationState(appState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.isAppInFinalState": "  public static boolean isAppInFinalState(RMApp rmApp) {\n    RMAppState appState = ((RMAppImpl) rmApp).getRecoveredFinalState();\n    if (appState == null) {\n      appState = rmApp.getState();\n    }\n    return appState == RMAppState.FAILED || appState == RMAppState.FINISHED\n        || appState == RMAppState.KILLED;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts": "  private void recoverAppAttempts() {\n    for (RMAppAttempt attempt : getAppAttempts().values()) {\n      attempt.handle(new RMAppAttemptEvent(attempt.getAppAttemptId(),\n        RMAppAttemptEventType.RECOVER));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getUser": "  public String getUser() {\n    return this.user;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.parseCredentials": "  protected Credentials parseCredentials() throws IOException {\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = submissionContext.getAMContainerSpec().getTokens();\n    if (tokens != null) {\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n    return credentials;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.createAndStartNewAttempt": "  private void\n      createAndStartNewAttempt(boolean transferStateFromPreviousAttempt) {\n    createNewAttempt();\n    handler.handle(new RMAppStartAttemptEvent(currentAttempt.getAppAttemptId(),\n      transferStateFromPreviousAttempt));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getRanNodes": "  public Set<NodeId> getRanNodes() {\n    return ranNodes;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.rememberTargetTransitions": "  private void rememberTargetTransitions(RMAppEvent event,\n      Object transitionToDo, RMAppState targetFinalState) {\n    transitionTodo = transitionToDo;\n    targetedFinalState = targetFinalState;\n    eventCausingFinalSaving = event;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getAppAttemptFailedDiagnostics": "  private String getAppAttemptFailedDiagnostics(RMAppEvent event) {\n    String msg = null;\n    RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n    if (this.submissionContext.getUnmanagedAM()) {\n      // RM does not manage the AM. Do not retry\n      msg = \"Unmanaged application \" + this.getApplicationId()\n              + \" failed due to \" + failedEvent.getDiagnosticMsg()\n              + \". Failing the application.\";\n    } else if (this.isNumAttemptsBeyondThreshold) {\n      int globalLimit = conf.getInt(YarnConfiguration.RM_AM_MAX_ATTEMPTS,\n          YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS);\n      msg = String.format(\n        \"Application %s failed %d times%s%s due to %s. Failing the application.\",\n          getApplicationId(),\n          maxAppAttempts,\n          (attemptFailuresValidityInterval <= 0 ? \"\"\n               : (\" in previous \" + attemptFailuresValidityInterval\n                  + \" milliseconds\")),\n          (globalLimit == maxAppAttempts) ? \"\"\n              : (\" (global limit =\" + globalLimit\n                 + \"; local limit is =\" + maxAppAttempts + \")\"),\n          failedEvent.getDiagnosticMsg());\n    }\n    return msg;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.removeExcessAttempts": "    private void removeExcessAttempts(RMAppImpl app) {\n      while (app.nextAttemptId - app.firstAttemptIdInStateStore\n          > app.maxAppAttempts) {\n        // attempts' first element is oldest attempt because it is a\n        // LinkedHashMap\n        ApplicationAttemptId attemptId = ApplicationAttemptId.newInstance(\n            app.getApplicationId(), app.firstAttemptIdInStateStore);\n        app.firstAttemptIdInStateStore++;\n        LOG.info(\"Remove attempt from state store : \" + attemptId);\n        app.rmContext.getStateStore().removeApplicationAttempt(attemptId);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getNumFailedAppAttempts": "  private int getNumFailedAppAttempts() {\n    int completedAttempts = 0;\n    long endTime = this.systemClock.getTime();\n    // Do not count AM preemption, hardware failures or NM resync\n    // as attempt failure.\n    for (RMAppAttempt attempt : attempts.values()) {\n      if (attempt.shouldCountTowardsMaxAttemptRetry()) {\n        if (this.attemptFailuresValidityInterval <= 0\n            || (attempt.getFinishTime() > endTime\n                - this.attemptFailuresValidityInterval)) {\n          completedAttempts++;\n        }\n      }\n    }\n    return completedAttempts;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle": "  public void handle(RMAppEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId appID = event.getApplicationId();\n      LOG.debug(\"Processing event for \" + appID + \" of type \"\n          + event.getType());\n      final RMAppState oldState = getState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getState()) {\n        LOG.info(appID + \" State change from \" + oldState + \" to \"\n            + getState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication": "  protected void recoverApplication(ApplicationStateData appState,\n      RMState rmState) throws Exception {\n    ApplicationSubmissionContext appContext =\n        appState.getApplicationSubmissionContext();\n    ApplicationId appId = appContext.getApplicationId();\n\n    // create and recover app.\n    RMAppImpl application =\n        createAndPopulateNewRMApp(appContext, appState.getSubmitTime(),\n            appState.getUser(), true);\n\n    application.handle(new RMAppRecoverEvent(appId, rmState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp": "  private RMAppImpl createAndPopulateNewRMApp(\n      ApplicationSubmissionContext submissionContext, long submitTime,\n      String user, boolean isRecovery)\n      throws YarnException, AccessControlException {\n    // Do queue mapping\n    if (!isRecovery) {\n      if (rmContext.getQueuePlacementManager() != null) {\n        // We only do queue mapping when it's a new application\n        rmContext.getQueuePlacementManager().placeApplication(\n            submissionContext, user);\n      }\n    }\n    \n    ApplicationId applicationId = submissionContext.getApplicationId();\n    ResourceRequest amReq =\n        validateAndCreateResourceRequest(submissionContext, isRecovery);\n\n    // Verify and get the update application priority and set back to\n    // submissionContext\n    Priority appPriority = rmContext.getScheduler()\n        .checkAndGetApplicationPriority(submissionContext.getPriority(), user,\n            submissionContext.getQueue(), applicationId);\n    submissionContext.setPriority(appPriority);\n\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n    // Since FairScheduler queue mapping is done inside scheduler,\n    // if FairScheduler is used and the queue doesn't exist, we should not\n    // fail here because queue will be created inside FS. Ideally, FS queue\n    // mapping should be done outside scheduler too like CS.\n    // For now, exclude FS for the acl check.\n    if (!isRecovery && isAclEnabled && scheduler instanceof CapacityScheduler &&\n        !scheduler.checkAccess(userUgi, QueueACL.SUBMIT_APPLICATIONS,\n            submissionContext.getQueue()) &&\n        !scheduler.checkAccess(userUgi, QueueACL.ADMINISTER_QUEUE,\n            submissionContext.getQueue())) {\n      throw new AccessControlException(\n          \"User \" + user + \" does not have permission to submit \"\n              + applicationId + \" to queue \" + submissionContext.getQueue());\n    }\n\n    // Create RMApp\n    RMAppImpl application = new RMAppImpl(applicationId, rmContext, this.conf,\n        submissionContext.getApplicationName(), user,\n        submissionContext.getQueue(), submissionContext, this.scheduler,\n        this.masterService, submitTime, submissionContext.getApplicationType(),\n        submissionContext.getApplicationTags(), amReq);\n\n    // Concurrent app submissions with same applicationId will fail here\n    // Concurrent app submissions with different applicationIds will not\n    // influence each other\n    if (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw new YarnException(message);\n    }\n    // Inform the ACLs Manager\n    this.applicationACLsManager.addApplication(applicationId,\n        submissionContext.getAMContainerSpec().getApplicationACLs());\n    String appViewACLs = submissionContext.getAMContainerSpec()\n        .getApplicationACLs().get(ApplicationAccessType.VIEW_APP);\n    rmContext.getSystemMetricsPublisher().appACLsUpdated(\n        application, appViewACLs, System.currentTimeMillis());\n    return application;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch(event.getType()) {\n      case APP_COMPLETED: \n      {\n        finishApplication(applicationId);\n        logApplicationSummary(applicationId);\n        checkAppNumCompletedLimit(); \n      } \n      break;\n      default:\n        LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n      }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover": "  public void recover(RMState state) throws Exception {\n    RMStateStore store = rmContext.getStateStore();\n    assert store != null;\n    // recover applications\n    Map<ApplicationId, ApplicationStateData> appStates =\n        state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationStateData appState : appStates.values()) {\n      recoverApplication(appState, state);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover reservations\n    if (reservationSystem != null) {\n      reservationSystem.recover(state);\n    }\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setSchedulerRecoveryStartAndWaitTime": "  private void setSchedulerRecoveryStartAndWaitTime(RMState state,\n      Configuration conf) {\n    if (!state.getApplicationState().isEmpty()) {\n      long waitTime =\n          conf.getLong(YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS,\n            YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS);\n      rmContext.setSchedulerRecoveryStartAndWaitTime(waitTime);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(false);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n\n    // Use the customized yarn filter instead of the standard kerberos filter to\n    // allow users to authenticate using delegation tokens\n    // 4 conditions need to be satisfied -\n    // 1. security is enabled\n    // 2. http auth type is set to kerberos\n    // 3. \"yarn.resourcemanager.webapp.use-yarn-filter\" override is set to true\n    // 4. hadoop.http.filter.initializers container AuthenticationFilterInitializer\n\n    Configuration conf = getConfig();\n    boolean enableCorsFilter =\n        conf.getBoolean(YarnConfiguration.RM_WEBAPP_ENABLE_CORS_FILTER,\n            YarnConfiguration.DEFAULT_RM_WEBAPP_ENABLE_CORS_FILTER);\n    boolean useYarnAuthenticationFilter =\n        conf.getBoolean(\n          YarnConfiguration.RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER);\n    String authPrefix = \"hadoop.http.authentication.\";\n    String authTypeKey = authPrefix + \"type\";\n    String filterInitializerConfKey = \"hadoop.http.filter.initializers\";\n    String actualInitializers = \"\";\n    Class<?>[] initializersClasses =\n        conf.getClasses(filterInitializerConfKey);\n\n    // setup CORS\n    if (enableCorsFilter) {\n      conf.setBoolean(HttpCrossOriginFilterInitializer.PREFIX\n          + HttpCrossOriginFilterInitializer.ENABLED_SUFFIX, true);\n    }\n\n    boolean hasHadoopAuthFilterInitializer = false;\n    boolean hasRMAuthFilterInitializer = false;\n    if (initializersClasses != null) {\n      for (Class<?> initializer : initializersClasses) {\n        if (initializer.getName().equals(\n          AuthenticationFilterInitializer.class.getName())) {\n          hasHadoopAuthFilterInitializer = true;\n        }\n        if (initializer.getName().equals(\n          RMAuthenticationFilterInitializer.class.getName())) {\n          hasRMAuthFilterInitializer = true;\n        }\n      }\n      if (UserGroupInformation.isSecurityEnabled()\n          && useYarnAuthenticationFilter\n          && hasHadoopAuthFilterInitializer\n          && conf.get(authTypeKey, \"\").equals(\n            KerberosAuthenticationHandler.TYPE)) {\n        ArrayList<String> target = new ArrayList<String>();\n        for (Class<?> filterInitializer : initializersClasses) {\n          if (filterInitializer.getName().equals(\n            AuthenticationFilterInitializer.class.getName())) {\n            if (hasRMAuthFilterInitializer == false) {\n              target.add(RMAuthenticationFilterInitializer.class.getName());\n            }\n            continue;\n          }\n          target.add(filterInitializer.getName());\n        }\n        actualInitializers = StringUtils.join(\",\", target);\n\n        LOG.info(\"Using RM authentication filter(kerberos/delegation-token)\"\n            + \" for RM webapp authentication\");\n        RMAuthenticationFilter\n          .setDelegationTokenSecretManager(getClientRMService().rmDTSecretManager);\n        conf.set(filterInitializerConfKey, actualInitializers);\n      }\n    }\n\n    // if security is not enabled and the default filter initializer has not \n    // been set, set the initializer to include the\n    // RMAuthenticationFilterInitializer which in turn will set up the simple\n    // auth filter.\n\n    String initializers = conf.get(filterInitializerConfKey);\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      if (initializersClasses == null || initializersClasses.length == 0) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName());\n        conf.set(authTypeKey, \"simple\");\n      } else if (initializers.equals(StaticUserWebFilter.class.getName())) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName() + \",\"\n              + initializers);\n        conf.set(authTypeKey, \"simple\");\n      }\n    }\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .at(webAppAddress);\n    String proxyHostAndPort = WebAppUtils.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n\n    }\n    webApp = builder.start(new RMWebApp(this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    HAServiceState state = rmContext.getHAServiceState();\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    if (state == HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\", pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive": "  public synchronized void transitionToActive(\n      HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {\n    // call refreshAdminAcls before HA state transition\n    // for the case that adminAcls have been updated in previous active RM\n    try {\n      refreshAdminAcls(false);\n    } catch (YarnException ex) {\n      throw new ServiceFailedException(\"Can not execute refreshAdminAcls\", ex);\n    }\n\n    UserGroupInformation user = checkAccess(\"transitionToActive\");\n    checkHaStateChange(reqInfo);\n    try {\n      rm.transitionToActive();\n    } catch (Exception e) {\n      RMAuditLogger.logFailure(user.getShortUserName(), \"transitionToActive\",\n          \"\", \"RM\",\n          \"Exception transitioning to active\");\n      throw new ServiceFailedException(\n          \"Error when transitioning to Active mode\", e);\n    }\n    try {\n      // call all refresh*s for active RM to get the updated configurations.\n      refreshAll();\n    } catch (Exception e) {\n      LOG.error(\"RefreshAll failed so firing fatal event\", e);\n      rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n          new RMFatalEvent(RMFatalEventType.TRANSITION_TO_ACTIVE_FAILED, e));\n      throw new ServiceFailedException(\n          \"Error on refreshAll during transistion to Active\", e);\n    }\n    RMAuditLogger.logSuccess(user.getShortUserName(), \"transitionToActive\",\n        \"RM\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkHaStateChange": "  private void checkHaStateChange(StateChangeRequestInfo req)\n      throws AccessControlException {\n    switch (req.getSource()) {\n      case REQUEST_BY_USER:\n        if (autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Manual failover for this ResourceManager is disallowed, \" +\n                  \"because automatic failover is enabled.\");\n        }\n        break;\n      case REQUEST_BY_USER_FORCED:\n        if (autoFailoverEnabled) {\n          LOG.warn(\"Allowing manual failover from \" +\n              org.apache.hadoop.ipc.Server.getRemoteAddress() +\n              \" even though automatic failover is enabled, because the user \" +\n              \"specified the force flag\");\n        }\n        break;\n      case REQUEST_BY_ZKFC:\n        if (!autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Request from ZK failover controller at \" +\n                  org.apache.hadoop.ipc.Server.getRemoteAddress() + \" denied \" +\n                  \"since automatic failover is not enabled\");\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess": "  private UserGroupInformation checkAccess(String method) throws IOException {\n    return RMServerUtils.verifyAdminAccess(authorizer, method, LOG);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll": "  private void refreshAll() throws ServiceFailedException {\n    try {\n      refreshQueues(RefreshQueuesRequest.newInstance());\n      refreshNodes(RefreshNodesRequest.newInstance(DecommissionType.NORMAL));\n      refreshSuperUserGroupsConfiguration(\n          RefreshSuperUserGroupsConfigurationRequest.newInstance());\n      refreshUserToGroupsMappings(\n          RefreshUserToGroupsMappingsRequest.newInstance());\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls(RefreshServiceAclsRequest.newInstance());\n      }\n      refreshClusterMaxPriority(RefreshClusterMaxPriorityRequest.newInstance());\n    } catch (Exception ex) {\n      throw new ServiceFailedException(ex.getMessage());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls": "  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    String argName = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), argName, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    authorizer.setAdmins(getAdminAclList(conf), UserGroupInformation\n        .getCurrentUser());\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive": "  public void becomeActive() throws ServiceFailedException {\n    try {\n      rmContext.getRMAdminService().transitionToActive(req);\n    } catch (Exception e) {\n      throw new ServiceFailedException(\"RM could not transition to Active\", e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeActive": "  private boolean becomeActive() {\n    assert wantToBeInElection;\n    if (state == State.ACTIVE) {\n      // already active\n      return true;\n    }\n    try {\n      Stat oldBreadcrumbStat = fenceOldActive();\n      writeBreadCrumbNode(oldBreadcrumbStat);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming active for \" + this);\n      }\n      appClient.becomeActive();\n      state = State.ACTIVE;\n      return true;\n    } catch (Exception e) {\n      LOG.warn(\"Exception handling the winning of election\", e);\n      // Caller will handle quitting and rejoining the election.\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.writeBreadCrumbNode": "  private void writeBreadCrumbNode(Stat oldBreadcrumbStat)\n      throws KeeperException, InterruptedException {\n    Preconditions.checkState(appData != null, \"no appdata\");\n    \n    LOG.info(\"Writing znode \" + zkBreadCrumbPath +\n        \" to indicate that the local node is the most recent active...\");\n    if (oldBreadcrumbStat == null) {\n      // No previous active, just create the node\n      createWithRetries(zkBreadCrumbPath, appData, zkAcl,\n        CreateMode.PERSISTENT);\n    } else {\n      // There was a previous active, update the node\n      setDataWithRetries(zkBreadCrumbPath, appData, oldBreadcrumbStat.getVersion());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fenceOldActive": "  private Stat fenceOldActive() throws InterruptedException, KeeperException {\n    final Stat stat = new Stat();\n    byte[] data;\n    LOG.info(\"Checking for any old active which needs to be fenced...\");\n    try {\n      data = zkDoWithRetries(new ZKAction<byte[]>() {\n        @Override\n        public byte[] run() throws KeeperException, InterruptedException {\n          return zkClient.getData(zkBreadCrumbPath, false, stat);\n        }\n      });\n    } catch (KeeperException ke) {\n      if (isNodeDoesNotExist(ke.code())) {\n        LOG.info(\"No old node to fence\");\n        return null;\n      }\n      \n      // If we failed to read for any other reason, then likely we lost\n      // our session, or we don't have permissions, etc. In any case,\n      // we probably shouldn't become active, and failing the whole\n      // thing is the best bet.\n      throw ke;\n    }\n\n    LOG.info(\"Old node exists: \" + StringUtils.byteToHexString(data));\n    if (Arrays.equals(data, appData)) {\n      LOG.info(\"But old node has our own data, so don't need to fence it.\");\n    } else {\n      appClient.fenceOldActive(data);\n    }\n    return stat;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.processResult": "  public synchronized void processResult(int rc, String path, Object ctx,\n      Stat stat) {\n    if (isStaleClient(ctx)) return;\n    monitorLockNodePending = false;\n\n    assert wantToBeInElection :\n        \"Got a StatNode result after quitting election\";\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"StatNode result: \" + rc + \" for path: \" + path\n          + \" connectionState: \" + zkConnectionState + \" for \" + this);\n    }\n\n    Code code = Code.get(rc);\n    if (isSuccess(code)) {\n      // the following owner check completes verification in case the lock znode\n      // creation was retried\n      if (stat.getEphemeralOwner() == zkClient.getSessionId()) {\n        // we own the lock znode. so we are the leader\n        if (!becomeActive()) {\n          reJoinElectionAfterFailureToBecomeActive();\n        }\n      } else {\n        // we dont own the lock znode. so we are a standby.\n        becomeStandby();\n      }\n      // the watch set by us will notify about changes\n      return;\n    }\n\n    if (isNodeDoesNotExist(code)) {\n      // the lock znode disappeared before we started monitoring it\n      enterNeutralMode();\n      joinElectionInternal();\n      return;\n    }\n\n    String errorMessage = \"Received stat error from Zookeeper. code:\"\n        + code.toString();\n    LOG.debug(errorMessage);\n\n    if (shouldRetry(code)) {\n      if (statRetryCount < maxRetryNum) {\n        ++statRetryCount;\n        monitorLockNodeAsync();\n        return;\n      }\n      errorMessage = errorMessage\n          + \". Not retrying further znode monitoring connection errors.\";\n    } else if (isSessionExpired(code)) {\n      // This isn't fatal - the client Watcher will re-join the election\n      LOG.warn(\"Lock monitoring failed because session was lost\");\n      return;\n    }\n\n    fatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code) {\n    return code == Code.CONNECTIONLOSS || code == Code.OPERATIONTIMEOUT;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.joinElectionInternal": "  private void joinElectionInternal() {\n    Preconditions.checkState(appData != null,\n        \"trying to join election without any app data\");\n    if (zkClient == null) {\n      if (!reEstablishSession()) {\n        fatalError(\"Failed to reEstablish connection with ZooKeeper\");\n        return;\n      }\n    }\n\n    createRetryCount = 0;\n    wantToBeInElection = true;\n    createLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createLockNodeAsync": "  private void createLockNodeAsync() {\n    zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,\n        this, zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSuccess": "  private static boolean isSuccess(Code code) {\n    return (code == Code.OK);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorActiveStatus": "  private void monitorActiveStatus() {\n    assert wantToBeInElection;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Monitoring active leader for \" + this);\n    }\n    statRetryCount = 0;\n    monitorLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeDoesNotExist": "  private static boolean isNodeDoesNotExist(Code code) {\n    return (code == Code.NONODE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.reJoinElectionAfterFailureToBecomeActive": "  private void reJoinElectionAfterFailureToBecomeActive() {\n    reJoinElection(SLEEP_AFTER_FAILURE_TO_BECOME_ACTIVE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.enterNeutralMode": "  private void enterNeutralMode() {\n    if (state != State.NEUTRAL) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Entering neutral mode for \" + this);\n      }\n      state = State.NEUTRAL;\n      appClient.enterNeutralMode();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorLockNodeAsync": "  private void monitorLockNodeAsync() {\n    if (monitorLockNodePending && monitorLockNodeClient == zkClient) {\n      LOG.info(\"Ignore duplicate monitor lock-node request.\");\n      return;\n    }\n    monitorLockNodePending = true;\n    monitorLockNodeClient = zkClient;\n    zkClient.exists(zkLockFilePath,\n        watcher, this,\n        zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSessionExpired": "  private static boolean isSessionExpired(Code code) {\n    return (code == Code.SESSIONEXPIRED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeStandby": "  private void becomeStandby() {\n    if (state != State.STANDBY) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming standby for \" + this);\n      }\n      state = State.STANDBY;\n      appClient.becomeStandby();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fatalError": "  private void fatalError(String errorMessage) {\n    LOG.fatal(errorMessage);\n    reset();\n    appClient.notifyFatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isStaleClient": "  private synchronized boolean isStaleClient(Object ctx) {\n    Preconditions.checkNotNull(ctx);\n    if (zkClient != (ZooKeeper)ctx) {\n      LOG.warn(\"Ignoring stale result from old client with sessionId \" +\n          String.format(\"0x%08x\", ((ZooKeeper)ctx).getSessionId()));\n      return true;\n    }\n    return false;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppMoveEvent.getResult": "  public SettableFuture<Object> getResult() {\n    return result;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppNodeUpdateEvent.getNode": "  public RMNode getNode() {\n    return node;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppNodeUpdateEvent.getUpdateType": "  public RMAppNodeUpdateType getUpdateType() {\n    return updateType;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppRunningOnNodeEvent.getNodeId": "  public NodeId getNodeId() {\n    return node;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppRecoverEvent.getRMState": "  public RMState getRMState() {\n    return state;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppFailedAttemptEvent.getTransferStateFromPreviousAttempt": "  public boolean getTransferStateFromPreviousAttempt() {\n    return transferStateFromPreviousAttempt;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppMoveEvent.getTargetQueue": "  public String getTargetQueue() {\n    return targetQueue;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getAMRMTokenSecretManager": "  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMDelegationTokenSecretManager": "  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ApplicationId appId,\n      ApplicationAttemptId attemptId, ContainerId containerId) {\n    return createFailureLog(user, operation, perm, target, description, appId,\n        attemptId, containerId, null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      ApplicationId appId, ApplicationAttemptId attemptId,\n      ContainerId containerId, CallerContext callerContext) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.SUCCESS, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    appendCallerContext(b, callerContext);\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getDispatcher": "  Dispatcher getDispatcher();\n\n  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMAdminService": "  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}"
        },
        "bug_report": {
            "Title": "RM startup failure when AM attempts greater than max-attempts",
            "Description": "Configure 3 queue in cluster with 8 GB\n# queue 40%\n# queue 50% \n# default 10%\n\n* Submit applications to all 3 queue with container size as 1024MB (sleep job with 50 containers on all queues)\n* AM that gets assigned to default queue and gets preempted immediately after 20 preemption kill all application\n\nDue resource limit in default queue AM got prempted about 20 times \nOn RM restart RM fails to restart\n\n{noformat}\n2016-01-12 10:49:04,081 DEBUG org.apache.hadoop.service.AbstractService: noteFailure java.lang.NullPointerException\n2016-01-12 10:49:04,081 INFO org.apache.hadoop.service.AbstractService: Service RMActiveServices failed in state STARTED; cause: java.lang.NullPointerException\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.recover(RMAppAttemptImpl.java:887)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recover(RMAppImpl.java:826)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:953)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:946)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:786)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:464)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1232)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:594)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1022)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1062)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1058)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1705)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1058)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:323)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:127)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:877)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n2016-01-12 10:49:04,082 DEBUG org.apache.hadoop.service.AbstractService: Service: RMActiveServices entered state STOPPED\n2016-01-12 10:49:04,082 DEBUG org.apache.hadoop.service.CompositeService: RMActiveServices: stopping services, size=16\n\n{noformat}"
        }
    },
    {
        "filename": "YARN-2846.json",
        "creation_time": "2014-11-11T15:30:08.000+0000",
        "stack_trace": "```\njava.io.IOException: Interrupted while waiting for process 20001 to exit\n        at org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.reacquireContainer(ContainerExecutor.java:180)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.call(RecoveredContainerLaunch.java:82)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.call(RecoveredContainerLaunch.java:46)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.InterruptedException: sleep interrupted\n        at java.lang.Thread.sleep(Native Method)\n        at org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.reacquireContainer(ContainerExecutor.java:177)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.reacquireContainer": "  public int reacquireContainer(String user, ContainerId containerId)\n      throws IOException {\n    Path pidPath = getPidFilePath(containerId);\n    if (pidPath == null) {\n      LOG.warn(containerId + \" is not active, returning terminated error\");\n      return ExitCode.TERMINATED.getExitCode();\n    }\n\n    String pid = null;\n    pid = ProcessIdFileReader.getProcessId(pidPath);\n    if (pid == null) {\n      throw new IOException(\"Unable to determine pid for \" + containerId);\n    }\n\n    LOG.info(\"Reacquiring \" + containerId + \" with pid \" + pid);\n    try {\n      while(isContainerProcessAlive(user, pid)) {\n        Thread.sleep(1000);\n      }\n    } catch (InterruptedException e) {\n      throw new IOException(\"Interrupted while waiting for process \" + pid\n          + \" to exit\", e);\n    }\n\n    // wait for exit code file to appear\n    String exitCodeFile = ContainerLaunch.getExitCodeFile(pidPath.toString());\n    File file = new File(exitCodeFile);\n    final int sleepMsec = 100;\n    int msecLeft = 2000;\n    while (!file.exists() && msecLeft >= 0) {\n      if (!isContainerActive(containerId)) {\n        LOG.info(containerId + \" was deactivated\");\n        return ExitCode.TERMINATED.getExitCode();\n      }\n      try {\n        Thread.sleep(sleepMsec);\n      } catch (InterruptedException e) {\n        throw new IOException(\n            \"Interrupted while waiting for exit code from \" + containerId, e);\n      }\n      msecLeft -= sleepMsec;\n    }\n    if (msecLeft < 0) {\n      throw new IOException(\"Timeout while waiting for exit code from \"\n          + containerId);\n    }\n\n    try {\n      return Integer.parseInt(FileUtils.readFileToString(file).trim());\n    } catch (NumberFormatException e) {\n      throw new IOException(\"Error parsing exit code from pid \" + pid, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.getProcessId": "  public String getProcessId(ContainerId containerID) {\n    String pid = null;\n    Path pidFile = pidFiles.get(containerID);\n    if (pidFile == null) {\n      // This container isn't even launched yet.\n      return pid;\n    }\n    try {\n      pid = ProcessIdFileReader.getProcessId(pidFile);\n    } catch (IOException e) {\n      LOG.error(\"Got exception reading pid from pid-file \" + pidFile, e);\n    }\n    return pid;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.getPidFilePath": "  protected Path getPidFilePath(ContainerId containerId) {\n    try {\n      readLock.lock();\n      return (this.pidFiles.get(containerId));\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.isContainerProcessAlive": "  public abstract boolean isContainerProcessAlive(String user, String pid)\n      throws IOException;\n\n  /**\n   * Recover an already existing container. This is a blocking call and returns\n   * only when the container exits.  Note that the container must have been\n   * activated prior to this call.\n   * @param user the user of the container\n   * @param containerId The ID of the container to reacquire\n   * @return The exit code of the pre-existing container\n   * @throws IOException\n   */\n  public int reacquireContainer(String user, ContainerId containerId)\n      throws IOException {\n    Path pidPath = getPidFilePath(containerId);\n    if (pidPath == null) {\n      LOG.warn(containerId + \" is not active, returning terminated error\");\n      return ExitCode.TERMINATED.getExitCode();\n    }\n\n    String pid = null;\n    pid = ProcessIdFileReader.getProcessId(pidPath);\n    if (pid == null) {\n      throw new IOException(\"Unable to determine pid for \" + containerId);\n    }\n\n    LOG.info(\"Reacquiring \" + containerId + \" with pid \" + pid);\n    try {\n      while(isContainerProcessAlive(user, pid)) {\n        Thread.sleep(1000);\n      }\n    } catch (InterruptedException e) {\n      throw new IOException(\"Interrupted while waiting for process \" + pid\n          + \" to exit\", e);\n    }\n\n    // wait for exit code file to appear\n    String exitCodeFile = ContainerLaunch.getExitCodeFile(pidPath.toString());\n    File file = new File(exitCodeFile);\n    final int sleepMsec = 100;\n    int msecLeft = 2000;\n    while (!file.exists() && msecLeft >= 0) {\n      if (!isContainerActive(containerId)) {\n        LOG.info(containerId + \" was deactivated\");\n        return ExitCode.TERMINATED.getExitCode();\n      }\n      try {\n        Thread.sleep(sleepMsec);\n      } catch (InterruptedException e) {\n        throw new IOException(\n            \"Interrupted while waiting for exit code from \" + containerId, e);\n      }\n      msecLeft -= sleepMsec;\n    }\n    if (msecLeft < 0) {\n      throw new IOException(\"Timeout while waiting for exit code from \"\n          + containerId);\n    }\n\n    try {\n      return Integer.parseInt(FileUtils.readFileToString(file).trim());\n    } catch (NumberFormatException e) {\n      throw new IOException(\"Error parsing exit code from pid \" + pid, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.isContainerActive": "  protected boolean isContainerActive(ContainerId containerId) {\n    try {\n      readLock.lock();\n      return (this.pidFiles.containsKey(containerId));\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.toString": "    public String toString() {\n      return str;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.call": "  public Integer call() {\n    int retCode = ExitCode.LOST.getExitCode();\n    ContainerId containerId = container.getContainerId();\n    String appIdStr = ConverterUtils.toString(\n        containerId.getApplicationAttemptId().getApplicationId());\n    String containerIdStr = ConverterUtils.toString(containerId);\n\n    dispatcher.getEventHandler().handle(new ContainerEvent(containerId,\n        ContainerEventType.CONTAINER_LAUNCHED));\n\n    try {\n      File pidFile = locatePidFile(appIdStr, containerIdStr);\n      if (pidFile != null) {\n        String pidPathStr = pidFile.getPath();\n        pidFilePath = new Path(pidPathStr);\n        exec.activateContainer(containerId, pidFilePath);\n        retCode = exec.reacquireContainer(container.getUser(), containerId);\n      } else {\n        LOG.warn(\"Unable to locate pid file for container \" + containerIdStr);\n      }\n    } catch (IOException e) {\n        LOG.error(\"Unable to recover container \" + containerIdStr, e);\n    } finally {\n      this.completed.set(true);\n      exec.deactivateContainer(containerId);\n      try {\n        getContext().getNMStateStore().storeContainerCompleted(containerId,\n            retCode);\n      } catch (IOException e) {\n        LOG.error(\"Unable to set exit code for container \" + containerId);\n      }\n    }\n\n    if (retCode != 0) {\n      LOG.warn(\"Recovered container exited with a non-zero exit code \"\n          + retCode);\n      this.dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerId,\n          ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, retCode,\n          \"Container exited with a non-zero exit code \" + retCode));\n      return retCode;\n    }\n\n    LOG.info(\"Recovered container \" + containerId + \" succeeded\");\n    dispatcher.getEventHandler().handle(\n        new ContainerEvent(containerId,\n            ContainerEventType.CONTAINER_EXITED_WITH_SUCCESS));\n    return 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.locatePidFile": "  private File locatePidFile(String appIdStr, String containerIdStr) {\n    String pidSubpath= getPidFileSubpath(appIdStr, containerIdStr);\n    for (String dir : getContext().getLocalDirsHandler().getLocalDirs()) {\n      File pidFile = new File(dir, pidSubpath);\n      if (pidFile.exists()) {\n        return pidFile;\n      }\n    }\n    return null;\n  }"
        },
        "bug_report": {
            "Title": "Incorrect persist exit code for running containers in reacquireContainer() that interrupted by NodeManager restart.",
            "Description": "The NM restart work preserving feature could make running AM container get LOST and killed during stop NM daemon. The exception is like below:\n{code}\n2014-11-11 00:48:35,214 INFO  monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:run(408)) - Memory usage of ProcessTree 22140 for container-id container_1415666714233_0001_01_000084: 53.8 MB of 512 MB physical memory used; 931.3 MB of 1.0 GB virtual memory used\n2014-11-11 00:48:35,223 ERROR nodemanager.NodeManager (SignalLogger.java:handle(60)) - RECEIVED SIGNAL 15: SIGTERM\n2014-11-11 00:48:35,299 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50060\n2014-11-11 00:48:35,337 INFO  containermanager.ContainerManagerImpl (ContainerManagerImpl.java:cleanUpApplicationsOnNMShutDown(512)) - Applications still running : [application_1415666714233_0001]\n2014-11-11 00:48:35,338 INFO  ipc.Server (Server.java:stop(2437)) - Stopping server on 45454\n2014-11-11 00:48:35,344 INFO  ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 45454\n2014-11-11 00:48:35,346 INFO  logaggregation.LogAggregationService (LogAggregationService.java:serviceStop(141)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService waiting for pending aggregation during exit\n2014-11-11 00:48:35,347 INFO  ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder\n2014-11-11 00:48:35,347 INFO  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:abortLogAggregation(502)) - Aborting log aggregation for application_1415666714233_0001\n2014-11-11 00:48:35,348 WARN  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:run(382)) - Aggregation did not complete for application application_1415666714233_0001\n2014-11-11 00:48:35,358 WARN  monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:run(476)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.\n2014-11-11 00:48:35,406 ERROR launcher.RecoveredContainerLaunch (RecoveredContainerLaunch.java:call(87)) - Unable to recover container container_1415666714233_0001_01_000001\njava.io.IOException: Interrupted while waiting for process 20001 to exit\n        at org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.reacquireContainer(ContainerExecutor.java:180)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.call(RecoveredContainerLaunch.java:82)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.call(RecoveredContainerLaunch.java:46)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.InterruptedException: sleep interrupted\n        at java.lang.Thread.sleep(Native Method)\n        at org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.reacquireContainer(ContainerExecutor.java:177)\n        ... 6 more\n{code}\nIn reacquireContainer() of ContainerExecutor.java, the while loop of checking container process (AM container) will be interrupted by NM stop. The IOException get thrown and failed to generate an ExitCodeFile for the running container. Later, the IOException will be caught in upper call (RecoveredContainerLaunch.call()) and the ExitCode (by default to be LOST without any setting) get persistent in NMStateStore. \nAfter NM restart again, this container is recovered as COMPLETE state but exit code is LOST (154) - cause this (AM) container get killed later.\nWe should get rid of recording the exit code of running containers if detecting process is interrupted. "
        }
    },
    {
        "filename": "YARN-7890.json",
        "creation_time": "2018-02-03T21:10:43.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at java.util.Collections$UnmodifiableCollection.<init>(Collections.java:1026)\n        at java.util.Collections$UnmodifiableList.<init>(Collections.java:1302)\n        at java.util.Collections.unmodifiableList(Collections.java:1287)\n        at org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext.getFilecacheDirs(ContainerStartContext.java:200)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.buildContainerRuntimeContext(LinuxContainerExecutor.java:651)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:546)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:465)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.call(ContainerRelaunch.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.call(ContainerRelaunch.java:49)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext.getFilecacheDirs": "  public List<String> getFilecacheDirs() {\n    return Collections.unmodifiableList(this.filecacheDirs);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.buildContainerRuntimeContext": "  private ContainerRuntimeContext buildContainerRuntimeContext(\n      ContainerStartContext ctx, Path pidFilePath,\n      String resourcesOptions, String tcCommandFile) {\n\n    List<String> prefixCommands = new ArrayList<>();\n    addSchedPriorityCommand(prefixCommands);\n\n    Container container = ctx.getContainer();\n\n    ContainerRuntimeContext.Builder builder = new ContainerRuntimeContext\n            .Builder(container);\n    if (prefixCommands.size() > 0) {\n      builder.setExecutionAttribute(CONTAINER_LAUNCH_PREFIX_COMMANDS,\n              prefixCommands);\n    }\n\n    builder.setExecutionAttribute(LOCALIZED_RESOURCES,\n        ctx.getLocalizedResources())\n      .setExecutionAttribute(RUN_AS_USER, getRunAsUser(ctx.getUser()))\n      .setExecutionAttribute(USER, ctx.getUser())\n      .setExecutionAttribute(APPID, ctx.getAppId())\n      .setExecutionAttribute(CONTAINER_ID_STR,\n        container.getContainerId().toString())\n      .setExecutionAttribute(CONTAINER_WORK_DIR, ctx.getContainerWorkDir())\n      .setExecutionAttribute(NM_PRIVATE_CONTAINER_SCRIPT_PATH,\n        ctx.getNmPrivateContainerScriptPath())\n      .setExecutionAttribute(NM_PRIVATE_TOKENS_PATH,\n        ctx.getNmPrivateTokensPath())\n      .setExecutionAttribute(PID_FILE_PATH, pidFilePath)\n      .setExecutionAttribute(LOCAL_DIRS, ctx.getLocalDirs())\n      .setExecutionAttribute(LOG_DIRS, ctx.getLogDirs())\n      .setExecutionAttribute(FILECACHE_DIRS, ctx.getFilecacheDirs())\n      .setExecutionAttribute(USER_LOCAL_DIRS, ctx.getUserLocalDirs())\n      .setExecutionAttribute(CONTAINER_LOCAL_DIRS, ctx.getContainerLocalDirs())\n      .setExecutionAttribute(CONTAINER_LOG_DIRS, ctx.getContainerLogDirs())\n      .setExecutionAttribute(RESOURCES_OPTIONS, resourcesOptions);\n\n    if (tcCommandFile != null) {\n      builder.setExecutionAttribute(TC_COMMAND_FILE, tcCommandFile);\n    }\n\n    return builder.build();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getRunAsUser": "  String getRunAsUser(String user) {\n    if (UserGroupInformation.isSecurityEnabled() ||\n        !containerLimitUsers) {\n      return user;\n    } else {\n      return nonsecureLocalUser;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.addSchedPriorityCommand": "  protected void addSchedPriorityCommand(List<String> command) {\n    if (containerSchedPriorityIsSet) {\n      command.addAll(Arrays.asList(\"nice\", \"-n\",\n          Integer.toString(containerSchedPriorityAdjustment)));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.toString": "    public String toString() {\n      return String.valueOf(code);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer": "  public int launchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    Container container = ctx.getContainer();\n    String user = ctx.getUser();\n\n    verifyUsernamePattern(user);\n\n    ContainerId containerId = container.getContainerId();\n\n    resourcesHandler.preExecute(containerId,\n            container.getResource());\n    String resourcesOptions = resourcesHandler.getResourcesOption(containerId);\n    String tcCommandFile = null;\n\n    try {\n      if (resourceHandlerChain != null) {\n        List<PrivilegedOperation> ops = resourceHandlerChain\n            .preStart(container);\n\n        if (ops != null) {\n          List<PrivilegedOperation> resourceOps = new ArrayList<>();\n\n          resourceOps.add(new PrivilegedOperation(\n              PrivilegedOperation.OperationType.ADD_PID_TO_CGROUP,\n                  resourcesOptions));\n\n          for (PrivilegedOperation op : ops) {\n            switch (op.getOperationType()) {\n            case ADD_PID_TO_CGROUP:\n              resourceOps.add(op);\n              break;\n            case TC_MODIFY_STATE:\n              tcCommandFile = op.getArguments().get(0);\n              break;\n            default:\n              LOG.warn(\"PrivilegedOperation type unsupported in launch: \"\n                  + op.getOperationType());\n            }\n          }\n\n          if (resourceOps.size() > 1) {\n            //squash resource operations\n            try {\n              PrivilegedOperation operation = PrivilegedOperationExecutor\n                  .squashCGroupOperations(resourceOps);\n              resourcesOptions = operation.getArguments().get(0);\n            } catch (PrivilegedOperationException e) {\n              LOG.error(\"Failed to squash cgroup operations!\", e);\n              throw new ResourceHandlerException(\n                  \"Failed to squash cgroup operations!\");\n            }\n          }\n        }\n      }\n    } catch (ResourceHandlerException e) {\n      LOG.error(\"ResourceHandlerChain.preStart() failed!\", e);\n      throw new IOException(\"ResourceHandlerChain.preStart() failed!\", e);\n    }\n\n    try {\n      Path pidFilePath = getPidFilePath(containerId);\n      if (pidFilePath != null) {\n\n        ContainerRuntimeContext runtimeContext = buildContainerRuntimeContext(\n            ctx, pidFilePath, resourcesOptions, tcCommandFile);\n\n        linuxContainerRuntime.launchContainer(runtimeContext);\n      } else {\n        LOG.info(\n            \"Container was marked as inactive. Returning terminated error\");\n        return ContainerExecutor.ExitCode.TERMINATED.getExitCode();\n      }\n    } catch (ContainerExecutionException e) {\n      int exitCode = e.getExitCode();\n      LOG.warn(\"Exit code from container \" + containerId + \" is : \" + exitCode);\n      // 143 (SIGTERM) and 137 (SIGKILL) exit codes means the container was\n      // terminated/killed forcefully. In all other cases, log the\n      // output\n      if (exitCode != ContainerExecutor.ExitCode.FORCE_KILLED.getExitCode()\n          && exitCode != ContainerExecutor.ExitCode.TERMINATED.getExitCode()) {\n        LOG.warn(\"Exception from container-launch with container ID: \"\n            + containerId + \" and exit code: \" + exitCode, e);\n\n        StringBuilder builder = new StringBuilder();\n        builder.append(\"Exception from container-launch.\\n\");\n        builder.append(\"Container id: \" + containerId + \"\\n\");\n        builder.append(\"Exit code: \" + exitCode + \"\\n\");\n        if (!Optional.fromNullable(e.getErrorOutput()).or(\"\").isEmpty()) {\n          builder.append(\"Exception message: \" + e.getErrorOutput() + \"\\n\");\n        }\n        //Skip stack trace\n        String output = e.getOutput();\n        if (output != null && !e.getOutput().isEmpty()) {\n          builder.append(\"Shell output: \" + output + \"\\n\");\n        }\n        String diagnostics = builder.toString();\n        logOutput(diagnostics);\n        container.handle(new ContainerDiagnosticsUpdateEvent(containerId,\n            diagnostics));\n        if (exitCode ==\n                ExitCode.INVALID_CONTAINER_EXEC_PERMISSIONS.getExitCode() ||\n            exitCode ==\n                ExitCode.INVALID_CONFIG_FILE.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_SCRIPT_COPY.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_CREDENTIALS_FILE.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_WORK_DIRECTORIES.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_APP_LOG_DIRECTORIES.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_TMP_DIRECTORIES.getExitCode()) {\n          throw new ConfigurationException(\n              \"Linux Container Executor reached unrecoverable exception\", e);\n        }\n      } else {\n        container.handle(new ContainerDiagnosticsUpdateEvent(containerId,\n            \"Container killed on request. Exit code is \" + exitCode));\n      }\n      return exitCode;\n    } finally {\n      resourcesHandler.postExecute(containerId);\n\n      try {\n        if (resourceHandlerChain != null) {\n          resourceHandlerChain.postComplete(containerId);\n        }\n      } catch (ResourceHandlerException e) {\n        LOG.warn(\"ResourceHandlerChain.postComplete failed for \" +\n            \"containerId: \" + containerId + \". Exception: \" + e);\n      }\n    }\n\n    return 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getExitCode": "    public int getExitCode() {\n      return code;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.verifyUsernamePattern": "  void verifyUsernamePattern(String user) {\n    if (!UserGroupInformation.isSecurityEnabled() &&\n        !nonsecureLocalUserPattern.matcher(user).matches()) {\n      throw new IllegalArgumentException(\"Invalid user name '\" + user + \"',\" +\n          \" it must match '\" + nonsecureLocalUserPattern.pattern() + \"'\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer": "  protected int launchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    ContainerId containerId = container.getContainerId();\n    if (container.isMarkedForKilling()) {\n      LOG.info(\"Container \" + containerId + \" not launched as it has already \"\n          + \"been marked for Killing\");\n      this.killedBeforeStart = true;\n      return ExitCode.TERMINATED.getExitCode();\n    }\n    // LaunchContainer is a blocking call. We are here almost means the\n    // container is launched, so send out the event.\n    dispatcher.getEventHandler().handle(new ContainerEvent(\n        containerId,\n        ContainerEventType.CONTAINER_LAUNCHED));\n    context.getNMStateStore().storeContainerLaunched(containerId);\n\n    // Check if the container is signalled to be killed.\n    if (!containerAlreadyLaunched.compareAndSet(false, true)) {\n      LOG.info(\"Container \" + containerId + \" not launched as \"\n          + \"cleanup already called\");\n      return ExitCode.TERMINATED.getExitCode();\n    } else {\n      exec.activateContainer(containerId, pidFilePath);\n      return exec.launchContainer(ctx);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.call": "  public Integer call() {\n    if (!validateContainerState()) {\n      return 0;\n    }\n\n    ContainerId containerId = container.getContainerId();\n    String containerIdStr = containerId.toString();\n    int ret = -1;\n    Path containerLogDir;\n    try {\n      Path containerWorkDir = getContainerWorkDir();\n      cleanupPreviousContainerFiles(containerWorkDir);\n\n      containerLogDir = getContainerLogDir();\n\n      Map<Path, List<String>> localResources = getLocalizedResources();\n\n      String appIdStr = app.getAppId().toString();\n      Path nmPrivateContainerScriptPath =\n          getNmPrivateContainerScriptPath(appIdStr, containerIdStr);\n      Path nmPrivateTokensPath =\n          getNmPrivateTokensPath(appIdStr, containerIdStr);\n      pidFilePath = getPidFilePath(appIdStr, containerIdStr);\n\n      LOG.info(\"Relaunch container with \"\n          + \"workDir = \" + containerWorkDir.toString()\n          + \", logDir = \" + containerLogDir.toString()\n          + \", nmPrivateContainerScriptPath = \"\n          + nmPrivateContainerScriptPath.toString()\n          + \", nmPrivateTokensPath = \" + nmPrivateTokensPath.toString()\n          + \", pidFilePath = \" + pidFilePath.toString());\n\n      List<String> localDirs = dirsHandler.getLocalDirs();\n      List<String> logDirs = dirsHandler.getLogDirs();\n      List<String> containerLocalDirs = getContainerLocalDirs(localDirs);\n      List<String> containerLogDirs = getContainerLogDirs(logDirs);\n\n      if (!dirsHandler.areDisksHealthy()) {\n        ret = ContainerExitStatus.DISKS_FAILED;\n        throw new IOException(\"Most of the disks failed. \"\n            + dirsHandler.getDisksHealthReport(false));\n      }\n\n      ret = launchContainer(new ContainerStartContext.Builder()\n          .setContainer(container)\n          .setLocalizedResources(localResources)\n          .setNmPrivateContainerScriptPath(nmPrivateContainerScriptPath)\n          .setNmPrivateTokensPath(nmPrivateTokensPath)\n          .setUser(container.getUser())\n          .setAppId(appIdStr)\n          .setContainerWorkDir(containerWorkDir)\n          .setLocalDirs(localDirs)\n          .setLogDirs(logDirs)\n          .setContainerLocalDirs(containerLocalDirs)\n          .setContainerLogDirs(containerLogDirs)\n          .build());\n    } catch (ConfigurationException e) {\n      LOG.error(\"Failed to launch container due to configuration error.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerId, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      // Mark the node as unhealthy\n      getContext().getNodeStatusUpdater().reportException(e);\n      return ret;\n    } catch (Throwable e) {\n      LOG.warn(\"Failed to relaunch container.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerId, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      return ret;\n    } finally {\n      setContainerCompletedStatus(ret);\n    }\n\n    handleContainerExitCode(ret, containerLogDir);\n\n    return ret;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.getNmPrivateContainerScriptPath": "  private Path getNmPrivateContainerScriptPath(String appIdStr,\n      String containerIdStr) throws IOException {\n    return dirsHandler.getLocalPathForRead(\n        getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n            + CONTAINER_SCRIPT);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.getNmPrivateTokensPath": "  private Path getNmPrivateTokensPath(String appIdStr,\n       String containerIdStr) throws IOException {\n    return dirsHandler.getLocalPathForRead(\n        getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n            + String.format(ContainerLocalizer.TOKEN_FILE_NAME_FMT,\n            containerIdStr));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.getContainerWorkDir": "  private Path getContainerWorkDir() throws IOException {\n    String containerWorkDir = container.getWorkDir();\n    if (containerWorkDir == null\n        || !dirsHandler.isGoodLocalDir(containerWorkDir)) {\n      throw new IOException(\n          \"Could not find a good work dir \" + containerWorkDir\n          + \" for container \" + container);\n    }\n\n    return new Path(containerWorkDir);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.getContainerLogDir": "  private Path getContainerLogDir() throws IOException {\n    String containerLogDir = container.getLogDir();\n    if (containerLogDir == null || !dirsHandler.isGoodLogDir(containerLogDir)) {\n      throw new IOException(\"Could not find a good log dir \" + containerLogDir\n          + \" for container \" + container);\n    }\n\n    return new Path(containerLogDir);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.getPidFilePath": "  private Path getPidFilePath(String appIdStr,\n      String containerIdStr) throws IOException {\n    return dirsHandler.getLocalPathForRead(\n        getPidFileSubpath(appIdStr, containerIdStr));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.cleanupPreviousContainerFiles": "  private void cleanupPreviousContainerFiles(Path containerWorkDir) {\n    // delete ContainerScriptPath\n    deleteAsUser(new Path(containerWorkDir, CONTAINER_SCRIPT));\n    // delete TokensPath\n    deleteAsUser(new Path(containerWorkDir, FINAL_CONTAINER_TOKENS_FILE));\n  }"
        },
        "bug_report": {
            "Title": "NPE during container relaunch",
            "Description": "While running a recent build of trunk, I saw the following:\r\n{noformat}\r\n2018-02-02 21:02:40,026 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_e02_1517604848419_0002_01_000004 transitioned from RELAUNCHING to RUNNING\r\n2018-02-02 21:02:40,026 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch: Failed to relaunch container.\r\njava.lang.NullPointerException\r\n        at java.util.Collections$UnmodifiableCollection.<init>(Collections.java:1026)\r\n        at java.util.Collections$UnmodifiableList.<init>(Collections.java:1302)\r\n        at java.util.Collections.unmodifiableList(Collections.java:1287)\r\n        at org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext.getFilecacheDirs(ContainerStartContext.java:200)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.buildContainerRuntimeContext(LinuxContainerExecutor.java:651)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:546)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:465)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.call(ContainerRelaunch.java:107)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.call(ContainerRelaunch.java:49)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n{noformat}"
        }
    },
    {
        "filename": "YARN-139.json",
        "creation_time": "2012-10-01T19:51:20.000+0000",
        "stack_trace": "```\njava.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Thread.join(Thread.java:1143)\n\tat java.lang.Thread.join(Thread.java:1196)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.stop(AsyncDispatcher.java:105)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:437)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:402)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:619)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.stop": "  public void stop() {\n    stopped = true;\n    if (eventHandlingThread != null) {\n      eventHandlingThread.interrupt();\n      try {\n        eventHandlingThread.join();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted Exception while stopping\", ie);\n      }\n    }\n\n    // stop all the components\n    super.stop();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.service.CompositeService.stop": "  private synchronized void stop(int numOfServicesStarted) {\n    // stop in reserve order of start\n    for (int i = numOfServicesStarted; i >= 0; i--) {\n      Service service = serviceList.get(i);\n      try {\n        service.stop();\n      } catch (Throwable t) {\n        LOG.info(\"Error stopping \" + service.getName(), t);\n      }\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.handle": "    public void handle(SpeculatorEvent event) {\n      if (disabled) {\n        return;\n      }\n\n      TaskId tId = event.getTaskID();\n      TaskType tType = null;\n      /* event's TaskId will be null if the event type is JOB_CREATE or\n       * ATTEMPT_STATUS_UPDATE\n       */\n      if (tId != null) {\n        tType = tId.getTaskType(); \n      }\n      boolean shouldMapSpec =\n              conf.getBoolean(MRJobConfig.MAP_SPECULATIVE, false);\n      boolean shouldReduceSpec =\n              conf.getBoolean(MRJobConfig.REDUCE_SPECULATIVE, false);\n\n      /* The point of the following is to allow the MAP and REDUCE speculative\n       * config values to be independent:\n       * IF spec-exec is turned on for maps AND the task is a map task\n       * OR IF spec-exec is turned on for reduces AND the task is a reduce task\n       * THEN call the speculator to handle the event.\n       */\n      if ( (shouldMapSpec && (tType == null || tType == TaskType.MAP))\n        || (shouldReduceSpec && (tType == null || tType == TaskType.REDUCE))) {\n        // Speculator IS enabled, direct the event to there.\n        speculator.handle(event);\n      }\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.getJobId": "  public JobId getJobId() {\n    return jobId;\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.sysexit": "  protected void sysexit() {\n    System.exit(0);\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.getJob": "    public Job getJob(JobId jobID) {\n      return jobs.get(jobID);\n    }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop": "    public synchronized void stop() {\n      try {\n        if(isLastAMRetry) {\n          cleanupStagingDir();\n        } else {\n          LOG.info(\"Skipping cleaning up the staging dir. \"\n              + \"assuming AM will be retried.\");\n        }\n      } catch (IOException io) {\n        LOG.error(\"Failed to cleanup staging dir: \", io);\n      }\n      super.stop();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      eventDispatchers.get(type).handle(event);\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.service.Service.getName": "  String getName();\n\n  /**\n   * Get the configuration of this service.\n   * This is normally not a clone and may be manipulated, though there are no\n   * guarantees as to what the consequences of such actions may be\n   * @return the current configuration, unless a specific implentation chooses\n   * otherwise.\n   */\n  Configuration getConfig();\n\n  /**\n   * Get the current service state\n   * @return the state of the service\n   */\n  STATE getServiceState();\n\n  /**\n   * Get the service start time\n   * @return the start time of the service. This will be zero if the service\n   * has not yet been started.\n   */\n  long getStartTime();\n}",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.setConf": "  public void setConf(Configuration conf) {\n    this.conf = conf;\n    \n    numTries = Math.min(\n      conf.getInt(MRJobConfig.MR_JOB_END_RETRY_ATTEMPTS, 0) + 1\n      , conf.getInt(MRJobConfig.MR_JOB_END_NOTIFICATION_MAX_ATTEMPTS, 1)\n    );\n    waitInterval = Math.min(\n    conf.getInt(MRJobConfig.MR_JOB_END_RETRY_INTERVAL, 5)\n    , conf.getInt(MRJobConfig.MR_JOB_END_NOTIFICATION_MAX_RETRY_INTERVAL, 5)\n    );\n    waitInterval = (waitInterval < 0) ? 5 : waitInterval;\n\n    userUrl = conf.get(MRJobConfig.MR_JOB_END_NOTIFICATION_URL);\n\n    proxyConf = conf.get(MRJobConfig.MR_JOB_END_NOTIFICATION_PROXY);\n\n    //Configure the proxy to use if its set. It should be set like\n    //proxyType@proxyHostname:port\n    if(proxyConf != null && !proxyConf.equals(\"\") &&\n         proxyConf.lastIndexOf(\":\") != -1) {\n      int typeIndex = proxyConf.indexOf(\"@\");\n      Proxy.Type proxyType = Proxy.Type.HTTP;\n      if(typeIndex != -1 &&\n        proxyConf.substring(0, typeIndex).compareToIgnoreCase(\"socks\") == 0) {\n        proxyType = Proxy.Type.SOCKS;\n      }\n      String hostname = proxyConf.substring(typeIndex + 1,\n        proxyConf.lastIndexOf(\":\"));\n      String portConf = proxyConf.substring(proxyConf.lastIndexOf(\":\") + 1);\n      try {\n        int port = Integer.parseInt(portConf);\n        proxyToUse = new Proxy(proxyType,\n          new InetSocketAddress(hostname, port));\n        Log.info(\"Job end notification using proxy type \\\"\" + proxyType + \n        \"\\\" hostname \\\"\" + hostname + \"\\\" and port \\\"\" + port + \"\\\"\");\n      } catch(NumberFormatException nfe) {\n        Log.warn(\"Job end notification couldn't parse configured proxy's port \"\n          + portConf + \". Not going to use a proxy\");\n      }\n    }\n\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notify": "  public void notify(JobReport jobReport)\n    throws InterruptedException {\n    // Do we need job-end notification?\n    if (userUrl == null) {\n      Log.info(\"Job end notification URL not set, skipping.\");\n      return;\n    }\n\n    //Do string replacements for jobId and jobStatus\n    if (userUrl.contains(JOB_ID)) {\n      userUrl = userUrl.replace(JOB_ID, jobReport.getJobId().toString());\n    }\n    if (userUrl.contains(JOB_STATUS)) {\n      userUrl = userUrl.replace(JOB_STATUS, jobReport.getJobState().toString());\n    }\n\n    // Create the URL, ensure sanity\n    try {\n      urlToNotify = new URL(userUrl);\n    } catch (MalformedURLException mue) {\n      Log.warn(\"Job end notification couldn't parse \" + userUrl, mue);\n      return;\n    }\n\n    // Send notification\n    boolean success = false;\n    while (numTries-- > 0 && !success) {\n      Log.info(\"Job end notification attempts left \" + numTries);\n      success = notifyURLOnce();\n      if (!success) {\n        Thread.sleep(waitInterval);\n      }\n    }\n    if (!success) {\n      Log.warn(\"Job end notification failed to notify : \" + urlToNotify);\n    } else {\n      Log.info(\"Job end notification succeeded for \" + jobReport.getJobId());\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notifyURLOnce": "  protected boolean notifyURLOnce() {\n    boolean success = false;\n    try {\n      Log.info(\"Job end notification trying \" + urlToNotify);\n      HttpURLConnection conn =\n        (HttpURLConnection) urlToNotify.openConnection(proxyToUse);\n      conn.setConnectTimeout(5*1000);\n      conn.setReadTimeout(5*1000);\n      conn.setAllowUserInteraction(false);\n      if(conn.getResponseCode() != HttpURLConnection.HTTP_OK) {\n        Log.warn(\"Job end notification to \" + urlToNotify +\" failed with code: \"\n        + conn.getResponseCode() + \" and message \\\"\" + conn.getResponseMessage()\n        +\"\\\"\");\n      }\n      else {\n        success = true;\n        Log.info(\"Job end notification to \" + urlToNotify + \" succeeded\");\n      }\n    } catch(IOException ioe) {\n      Log.warn(\"Job end notification to \" + urlToNotify + \" failed\", ioe);\n    }\n    return success;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Interrupted Exception within AsyncDispatcher leads to user confusion",
            "Description": "Successful applications tend to get InterruptedExceptions during shutdown. The exception is harmless but it leads to lots of user confusion and therefore could be cleaned up.\n\n\n2012-09-28 14:50:12,477 WARN [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Interrupted Exception while stopping\njava.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Thread.join(Thread.java:1143)\n\tat java.lang.Thread.join(Thread.java:1196)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.stop(AsyncDispatcher.java:105)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:437)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:402)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:619)\n2012-09-28 14:50:12,477 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.service.AbstractService: Service:Dispatcher is stopped.\n2012-09-28 14:50:12,477 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.app.MRAppMaster is stopped.\n2012-09-28 14:50:12,477 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Exiting MR AppMaster..GoodBye"
        }
    },
    {
        "filename": "YARN-42.json",
        "creation_time": "2012-05-14T11:38:55.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.YarnException: Failed to initialize LocalizationService\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.init(ResourceLocalizationService.java:202)\n\tat org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.init(ContainerManagerImpl.java:183)\n\tat org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.init(NodeManager.java:166)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:268)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:284)\nCaused by: java.io.IOException: mkdir of /mrv2/tmp/nm-local-dir/usercache failed\n\tat org.apache.hadoop.fs.FileSystem.primitiveMkdir(FileSystem.java:907)\n\tat org.apache.hadoop.fs.DelegateToFileSystem.mkdir(DelegateToFileSystem.java:143)\n\tat org.apache.hadoop.fs.FilterFs.mkdir(FilterFs.java:189)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:706)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:703)\n\tat org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(FileContext.java:2325)\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:703)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.init(ResourceLocalizationService.java:188)\n\t... 6 more\n\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.stop(NonAggregatingLogHandler.java:82)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stop(ContainerManagerImpl.java:266)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:182)\n\tat org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:122)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.primitiveMkdir": "  protected void primitiveMkdir(Path f, FsPermission absolutePermission, \n                    boolean createParent)\n    throws IOException {\n    \n    if (!createParent) { // parent must exist.\n      // since the this.mkdirs makes parent dirs automatically\n      // we must throw exception if parent does not exist.\n      final FileStatus stat = getFileStatus(f.getParent());\n      if (stat == null) {\n        throw new FileNotFoundException(\"Missing parent:\" + f);\n      }\n      if (!stat.isDirectory()) {\n        throw new ParentNotDirectoryException(\"parent is not a dir\");\n      }\n      // parent does exist - go ahead with mkdir of leaf\n    }\n    // Default impl is to assume that permissions do not matter and hence\n    // calling the regular mkdirs is good enough.\n    // FSs that implement permissions should override this.\n    if (!this.mkdirs(f, absolutePermission)) {\n      throw new IOException(\"mkdir of \"+ f + \" failed\");\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.mkdirs": "  public abstract boolean mkdirs(Path f, FsPermission permission\n      ) throws IOException;\n\n  /**\n   * The src file is on the local disk.  Add it to FS at\n   * the given dst name and the source is kept intact afterwards\n   * @param src path\n   * @param dst path\n   */\n  public void copyFromLocalFile(Path src, Path dst)\n    throws IOException {\n    copyFromLocalFile(false, src, dst);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.getFileStatus": "  private FileStatus[] getFileStatus(Path[] paths) throws IOException {\n    if (paths == null) {\n      return null;\n    }\n    ArrayList<FileStatus> results = new ArrayList<FileStatus>(paths.length);\n    for (int i = 0; i < paths.length; i++) {\n      try {\n        results.add(getFileStatus(paths[i]));\n      } catch (FileNotFoundException e) { // do nothing\n      }\n    }\n    return results.toArray(new FileStatus[results.size()]);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FileSystem.isDirectory": "  public boolean isDirectory(Path f) throws IOException {\n    try {\n      return getFileStatus(f).isDirectory();\n    } catch (FileNotFoundException e) {\n      return false;               // f does not exist\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.DelegateToFileSystem.mkdir": "  public void mkdir(Path dir, FsPermission permission, boolean createParent)\n      throws IOException {\n    checkPath(dir);\n    fsImpl.primitiveMkdir(dir, permission, createParent);\n    \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FilterFs.mkdir": "  public void mkdir(Path dir, FsPermission permission, boolean createParent)\n    throws IOException, UnresolvedLinkException {\n    checkPath(dir);\n    myFs.mkdir(dir, permission, createParent);\n    \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.FilterFs.checkPath": "  public void checkPath(Path path) {\n    myFs.checkPath(path);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ShutdownHookManager.run": "        public void run() {\n          MGR.shutdownInProgress.set(true);\n          for (Runnable hook: MGR.getShutdownHooksInOrder()) {\n            try {\n              hook.run();\n            } catch (Throwable ex) {\n              LOG.warn(\"ShutdownHook '\" + hook.getClass().getSimpleName() +\n                       \"' failed, \" + ex.toString(), ex);\n            }\n          }\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ShutdownHookManager.getShutdownHooksInOrder": "  List<Runnable> getShutdownHooksInOrder() {\n    List<HookEntry> list;\n    synchronized (MGR.hooks) {\n      list = new ArrayList<HookEntry>(MGR.hooks);\n    }\n    Collections.sort(list, new Comparator<HookEntry>() {\n\n      //reversing comparison so highest priority hooks are first\n      @Override\n      public int compare(HookEntry o1, HookEntry o2) {\n        return o2.priority - o1.priority;\n      }\n    });\n    List<Runnable> ordered = new ArrayList<Runnable>();\n    for (HookEntry entry: list) {\n      ordered.add(entry.hook);\n    }\n    return ordered;\n  }"
        },
        "bug_report": {
            "Title": "Node Manager throws NPE on startup",
            "Description": "NM throws NPE on startup if it doesn't have persmission's on nm local dir's\n\n\n{code:xml}\n2012-05-14 16:32:13,468 FATAL org.apache.hadoop.yarn.server.nodemanager.NodeManager: Error starting NodeManager\norg.apache.hadoop.yarn.YarnException: Failed to initialize LocalizationService\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.init(ResourceLocalizationService.java:202)\n\tat org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.init(ContainerManagerImpl.java:183)\n\tat org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.init(NodeManager.java:166)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:268)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:284)\nCaused by: java.io.IOException: mkdir of /mrv2/tmp/nm-local-dir/usercache failed\n\tat org.apache.hadoop.fs.FileSystem.primitiveMkdir(FileSystem.java:907)\n\tat org.apache.hadoop.fs.DelegateToFileSystem.mkdir(DelegateToFileSystem.java:143)\n\tat org.apache.hadoop.fs.FilterFs.mkdir(FilterFs.java:189)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:706)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:703)\n\tat org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(FileContext.java:2325)\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:703)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.init(ResourceLocalizationService.java:188)\n\t... 6 more\n2012-05-14 16:32:13,472 INFO org.apache.hadoop.yarn.service.CompositeService: Error stopping org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.stop(NonAggregatingLogHandler.java:82)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stop(ContainerManagerImpl.java:266)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:182)\n\tat org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:122)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\n{code}\n"
        }
    },
    {
        "filename": "YARN-7453.json",
        "creation_time": "2017-11-07T09:46:28.000+0000",
        "stack_trace": "```\norg.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:113)\n\tat org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:1006)\n\tat org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:910)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.doOperation(CuratorTransactionImpl.java:159)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.access$200(CuratorTransactionImpl.java:44)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl$2.call(CuratorTransactionImpl.java:129)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl$2.call(CuratorTransactionImpl.java:125)\n\tat org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:109)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.commit(CuratorTransactionImpl.java:122)\n\tat org.apache.hadoop.util.curator.ZKCuratorManager$SafeTransaction.commit(ZKCuratorManager.java:403)\n\tat org.apache.hadoop.util.curator.ZKCuratorManager.safeSetData(ZKCuratorManager.java:372)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getAndIncrementEpoch(ZKRMStateStore.java:493)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:771)\n\tat org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1162)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1202)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1198)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1198)\n\tat org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:320)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\n\tat org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:894)\n\tat org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:473)\n\tat org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:607)\n\tat org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:505)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.curator.ZKCuratorManager.commit": "    public void commit() throws Exception {\n      transactionFinal = transactionFinal.delete()\n          .forPath(fencingNodePath).and();\n      transactionFinal.commit();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.curator.ZKCuratorManager.delete": "    public void delete(String path) throws Exception {\n      transactionFinal = transactionFinal.delete().forPath(path).and();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.curator.ZKCuratorManager.safeSetData": "  public void safeSetData(String path, byte[] data, int version,\n      List<ACL> fencingACL, String fencingNodePath)\n      throws Exception {\n    SafeTransaction transaction = createTransaction(fencingACL,\n        fencingNodePath);\n    transaction.setData(path, data, version);\n    transaction.commit();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.curator.ZKCuratorManager.setData": "    public void setData(String path, byte[] data, int version)\n        throws Exception {\n      transactionFinal = transactionFinal.setData()\n          .withVersion(version).forPath(path, data).and();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.curator.ZKCuratorManager.createTransaction": "  public SafeTransaction createTransaction(List<ACL> fencingACL,\n      String fencingNodePath) throws Exception {\n    return new SafeTransaction(fencingACL, fencingNodePath);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getAndIncrementEpoch": "  public synchronized long getAndIncrementEpoch() throws Exception {\n    String epochNodePath = getNodePath(zkRootNodePath, EPOCH_NODE);\n    long currentEpoch = baseEpoch;\n\n    if (exists(epochNodePath)) {\n      // load current epoch\n      byte[] data = getData(epochNodePath);\n      Epoch epoch = new EpochPBImpl(EpochProto.parseFrom(data));\n      currentEpoch = epoch.getEpoch();\n      // increment epoch and store it\n      byte[] storeData = Epoch.newInstance(currentEpoch + 1).getProto()\n          .toByteArray();\n      zkManager.safeSetData(epochNodePath, storeData, -1, zkAcl,\n          fencingNodePath);\n    } else {\n      // initialize epoch node with 1 for the next time.\n      byte[] storeData = Epoch.newInstance(currentEpoch + 1).getProto()\n          .toByteArray();\n      zkManager.safeCreate(epochNodePath, storeData, zkAcl,\n          CreateMode.PERSISTENT, zkAcl, fencingNodePath);\n    }\n\n    return currentEpoch;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.exists": "  boolean exists(final String path) throws Exception {\n    return zkManager.exists(path);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getData": "  byte[] getData(final String path) throws Exception {\n    return zkManager.getData(path);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getNodePath": "  String getNodePath(String root, String nodeName) {\n    return (root + \"/\" + nodeName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(false);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover reservations\n    if (reservationSystem != null) {\n      reservationSystem.recover(state);\n    }\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n\n    Configuration conf = getConfig();\n\n    RMWebAppUtil.setupSecurityAndFilters(conf,\n        getClientRMService().rmDTSecretManager);\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .withCSRFProtection(YarnConfiguration.RM_CSRF_PREFIX)\n            .withXFSProtection(YarnConfiguration.RM_XFS_PREFIX)\n            .at(webAppAddress);\n    String proxyHostAndPort = rmContext.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n    }\n\n    WebAppContext uiWebAppContext = null;\n    if (getConfig().getBoolean(YarnConfiguration.YARN_WEBAPP_UI2_ENABLE,\n        YarnConfiguration.DEFAULT_YARN_WEBAPP_UI2_ENABLE)) {\n      String onDiskPath = getConfig()\n          .get(YarnConfiguration.YARN_WEBAPP_UI2_WARFILE_PATH);\n\n      uiWebAppContext = new WebAppContext();\n      uiWebAppContext.setContextPath(UI2_WEBAPP_NAME);\n\n      if (null == onDiskPath) {\n        String war = \"hadoop-yarn-ui-\" + VersionInfo.getVersion() + \".war\";\n        URLClassLoader cl = (URLClassLoader) ClassLoader.getSystemClassLoader();\n        URL url = cl.findResource(war);\n\n        if (null == url) {\n          onDiskPath = getWebAppsPath(\"ui2\");\n        } else {\n          onDiskPath = url.getFile();\n        }\n      }\n      if (onDiskPath == null || onDiskPath.isEmpty()) {\n          LOG.error(\"No war file or webapps found for ui2 !\");\n      } else {\n        if (onDiskPath.endsWith(\".war\")) {\n          uiWebAppContext.setWar(onDiskPath);\n          LOG.info(\"Using war file at: \" + onDiskPath);\n        } else {\n          uiWebAppContext.setResourceBase(onDiskPath);\n          LOG.info(\"Using webapps at: \" + onDiskPath);\n        }\n      }\n    }\n\n    webApp = builder.start(new RMWebApp(this), uiWebAppContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    HAServiceState state = rmContext.getHAServiceState();\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    if (state == HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, (Throwable) null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetRMContext();\n      createAndInitActiveServices(true);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive": "  public synchronized void transitionToActive(\n      HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {\n    if (isRMActive()) {\n      return;\n    }\n    // call refreshAdminAcls before HA state transition\n    // for the case that adminAcls have been updated in previous active RM\n    try {\n      refreshAdminAcls(false);\n    } catch (YarnException ex) {\n      throw new ServiceFailedException(\"Can not execute refreshAdminAcls\", ex);\n    }\n\n    UserGroupInformation user = checkAccess(\"transitionToActive\");\n    checkHaStateChange(reqInfo);\n\n    try {\n      // call all refresh*s for active RM to get the updated configurations.\n      refreshAll();\n    } catch (Exception e) {\n      rm.getRMContext()\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMFatalEvent(RMFatalEventType.TRANSITION_TO_ACTIVE_FAILED,\n                  e, \"failure to refresh configuration settings\"));\n      throw new ServiceFailedException(\n          \"Error on refreshAll during transition to Active\", e);\n    }\n\n    try {\n      rm.transitionToActive();\n    } catch (Exception e) {\n      RMAuditLogger.logFailure(user.getShortUserName(), \"transitionToActive\",\n          \"\", \"RM\",\n          \"Exception transitioning to active\");\n      throw new ServiceFailedException(\n          \"Error when transitioning to Active mode\", e);\n    }\n\n    RMAuditLogger.logSuccess(user.getShortUserName(), \"transitionToActive\",\n        \"RM\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.isRMActive": "  private synchronized boolean isRMActive() {\n    return HAServiceState.ACTIVE == rm.getRMContext().getHAServiceState();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkHaStateChange": "  private void checkHaStateChange(StateChangeRequestInfo req)\n      throws AccessControlException {\n    switch (req.getSource()) {\n      case REQUEST_BY_USER:\n        if (autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Manual failover for this ResourceManager is disallowed, \" +\n                  \"because automatic failover is enabled.\");\n        }\n        break;\n      case REQUEST_BY_USER_FORCED:\n        if (autoFailoverEnabled) {\n          LOG.warn(\"Allowing manual failover from \" +\n              org.apache.hadoop.ipc.Server.getRemoteAddress() +\n              \" even though automatic failover is enabled, because the user \" +\n              \"specified the force flag\");\n        }\n        break;\n      case REQUEST_BY_ZKFC:\n        if (!autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Request from ZK failover controller at \" +\n                  org.apache.hadoop.ipc.Server.getRemoteAddress() + \" denied \" +\n                  \"since automatic failover is not enabled\");\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess": "  private UserGroupInformation checkAccess(String method) throws IOException {\n    return RMServerUtils.verifyAdminAccess(authorizer, method, LOG);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll": "  void refreshAll() throws ServiceFailedException {\n    try {\n      checkAcls(\"refreshAll\");\n      if (isSchedulerMutable()) {\n        try {\n          ((MutableConfScheduler) rm.getRMContext().getScheduler())\n              .getMutableConfProvider().reloadConfigurationFromStore();\n        } catch (Exception e) {\n          throw new IOException(\"Failed to refresh configuration:\", e);\n        }\n      }\n      refreshQueues();\n      refreshNodes();\n      refreshSuperUserGroupsConfiguration();\n      refreshUserToGroupsMappings();\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls();\n      }\n      refreshClusterMaxPriority();\n    } catch (Exception ex) {\n      throw new ServiceFailedException(\"RefreshAll operation failed\", ex);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls": "  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    final String operation = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(operation);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), operation, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    authorizer.setAdmins(getAdminAclList(conf), daemonUser);\n    RMAuditLogger.logSuccess(user.getShortUserName(), operation,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive": "  public void becomeActive() throws ServiceFailedException {\n    cancelDisconnectTimer();\n\n    try {\n      rm.getRMContext().getRMAdminService().transitionToActive(req);\n    } catch (Exception e) {\n      throw new ServiceFailedException(\"RM could not transition to Active\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.cancelDisconnectTimer": "  private void cancelDisconnectTimer() {\n    synchronized (zkDisconnectLock) {\n      if (zkDisconnectTimer != null) {\n        zkDisconnectTimer.cancel();\n        zkDisconnectTimer = null;\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeActive": "  private boolean becomeActive() {\n    assert wantToBeInElection;\n    if (state == State.ACTIVE) {\n      // already active\n      return true;\n    }\n    try {\n      Stat oldBreadcrumbStat = fenceOldActive();\n      writeBreadCrumbNode(oldBreadcrumbStat);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming active for \" + this);\n      }\n      appClient.becomeActive();\n      state = State.ACTIVE;\n      return true;\n    } catch (Exception e) {\n      LOG.warn(\"Exception handling the winning of election\", e);\n      // Caller will handle quitting and rejoining the election.\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.writeBreadCrumbNode": "  private void writeBreadCrumbNode(Stat oldBreadcrumbStat)\n      throws KeeperException, InterruptedException {\n    Preconditions.checkState(appData != null, \"no appdata\");\n    \n    LOG.info(\"Writing znode \" + zkBreadCrumbPath +\n        \" to indicate that the local node is the most recent active...\");\n    if (oldBreadcrumbStat == null) {\n      // No previous active, just create the node\n      createWithRetries(zkBreadCrumbPath, appData, zkAcl,\n        CreateMode.PERSISTENT);\n    } else {\n      // There was a previous active, update the node\n      setDataWithRetries(zkBreadCrumbPath, appData, oldBreadcrumbStat.getVersion());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fenceOldActive": "  private Stat fenceOldActive() throws InterruptedException, KeeperException {\n    final Stat stat = new Stat();\n    byte[] data;\n    LOG.info(\"Checking for any old active which needs to be fenced...\");\n    try {\n      data = zkDoWithRetries(new ZKAction<byte[]>() {\n        @Override\n        public byte[] run() throws KeeperException, InterruptedException {\n          return zkClient.getData(zkBreadCrumbPath, false, stat);\n        }\n      });\n    } catch (KeeperException ke) {\n      if (isNodeDoesNotExist(ke.code())) {\n        LOG.info(\"No old node to fence\");\n        return null;\n      }\n      \n      // If we failed to read for any other reason, then likely we lost\n      // our session, or we don't have permissions, etc. In any case,\n      // we probably shouldn't become active, and failing the whole\n      // thing is the best bet.\n      throw ke;\n    }\n\n    LOG.info(\"Old node exists: \" + StringUtils.byteToHexString(data));\n    if (Arrays.equals(data, appData)) {\n      LOG.info(\"But old node has our own data, so don't need to fence it.\");\n    } else {\n      appClient.fenceOldActive(data);\n    }\n    return stat;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.processResult": "  public synchronized void processResult(int rc, String path, Object ctx,\n      Stat stat) {\n    if (isStaleClient(ctx)) return;\n    monitorLockNodePending = false;\n\n    assert wantToBeInElection :\n        \"Got a StatNode result after quitting election\";\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"StatNode result: \" + rc + \" for path: \" + path\n          + \" connectionState: \" + zkConnectionState + \" for \" + this);\n    }\n\n    Code code = Code.get(rc);\n    if (isSuccess(code)) {\n      // the following owner check completes verification in case the lock znode\n      // creation was retried\n      if (stat.getEphemeralOwner() == zkClient.getSessionId()) {\n        // we own the lock znode. so we are the leader\n        if (!becomeActive()) {\n          reJoinElectionAfterFailureToBecomeActive();\n        }\n      } else {\n        // we dont own the lock znode. so we are a standby.\n        becomeStandby();\n      }\n      // the watch set by us will notify about changes\n      return;\n    }\n\n    if (isNodeDoesNotExist(code)) {\n      // the lock znode disappeared before we started monitoring it\n      enterNeutralMode();\n      joinElectionInternal();\n      return;\n    }\n\n    String errorMessage = \"Received stat error from Zookeeper. code:\"\n        + code.toString();\n    LOG.debug(errorMessage);\n\n    if (shouldRetry(code)) {\n      if (statRetryCount < maxRetryNum) {\n        ++statRetryCount;\n        monitorLockNodeAsync();\n        return;\n      }\n      errorMessage = errorMessage\n          + \". Not retrying further znode monitoring connection errors.\";\n    } else if (isSessionExpired(code)) {\n      // This isn't fatal - the client Watcher will re-join the election\n      LOG.warn(\"Lock monitoring failed because session was lost\");\n      return;\n    }\n\n    fatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code, Code retryIfCode) {\n    return (retryIfCode == null ? false : retryIfCode == code);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.joinElectionInternal": "  private void joinElectionInternal() {\n    Preconditions.checkState(appData != null,\n        \"trying to join election without any app data\");\n    if (zkClient == null) {\n      if (!reEstablishSession()) {\n        fatalError(\"Failed to reEstablish connection with ZooKeeper\");\n        return;\n      }\n    }\n\n    createRetryCount = 0;\n    wantToBeInElection = true;\n    createLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createLockNodeAsync": "  private void createLockNodeAsync() {\n    zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,\n        this, zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSuccess": "  private static boolean isSuccess(Code code) {\n    return (code == Code.OK);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorActiveStatus": "  private void monitorActiveStatus() {\n    assert wantToBeInElection;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Monitoring active leader for \" + this);\n    }\n    statRetryCount = 0;\n    monitorLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeDoesNotExist": "  private static boolean isNodeDoesNotExist(Code code) {\n    return (code == Code.NONODE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.reJoinElectionAfterFailureToBecomeActive": "  private void reJoinElectionAfterFailureToBecomeActive() {\n    reJoinElection(SLEEP_AFTER_FAILURE_TO_BECOME_ACTIVE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.enterNeutralMode": "  private void enterNeutralMode() {\n    if (state != State.NEUTRAL) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Entering neutral mode for \" + this);\n      }\n      state = State.NEUTRAL;\n      appClient.enterNeutralMode();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorLockNodeAsync": "  private void monitorLockNodeAsync() {\n    if (monitorLockNodePending && monitorLockNodeClient == zkClient) {\n      LOG.info(\"Ignore duplicate monitor lock-node request.\");\n      return;\n    }\n    monitorLockNodePending = true;\n    monitorLockNodeClient = zkClient;\n    zkClient.exists(zkLockFilePath,\n        watcher, this,\n        zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSessionExpired": "  private static boolean isSessionExpired(Code code) {\n    return (code == Code.SESSIONEXPIRED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeStandby": "  private void becomeStandby() {\n    if (state != State.STANDBY) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming standby for \" + this);\n      }\n      state = State.STANDBY;\n      appClient.becomeStandby();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fatalError": "  private void fatalError(String errorMessage) {\n    LOG.error(errorMessage);\n    reset();\n    appClient.notifyFatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isStaleClient": "  private synchronized boolean isStaleClient(Object ctx) {\n    Preconditions.checkNotNull(ctx);\n    if (zkClient != (ZooKeeper)ctx) {\n      LOG.warn(\"Ignoring stale result from old client with sessionId \" +\n          String.format(\"0x%08x\", ((ZooKeeper)ctx).getSessionId()));\n      return true;\n    }\n    return false;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Logger log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service {} : {}\", service.getName(), e, e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getLeaderElectorService": "  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n\n  String getAppProxyUrl(Configuration conf, ApplicationId applicationId);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElector.rejoinElection": "  void rejoinElection();\n\n  /**\n   * Get information about the elector's connection to Zookeeper.\n   *\n   * @return zookeeper connection state\n   */\n  String getZookeeperConnectionState();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description, ArgsBuilder args) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          args));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ArgsBuilder args) {\n    StringBuilder b = createStringBuilderForFailureLog(user,\n        operation, target, description, perm);\n    if(args != null) {\n      add(args, b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      InetAddress ip, ArgsBuilder args) {\n    StringBuilder b =\n        createStringBuilderForSuccessEvent(user, operation, target, ip);\n    if(args != null) {\n      add(args, b);\n    }\n    return b.toString();\n  }"
        },
        "bug_report": {
            "Title": "Fix issue where RM fails to switch to active after first successful start",
            "Description": "It is observed that RM fail to switch to ACTIVE after first successful start! The below exception throws when RM is switching from ACTIVE->STANDBY->ACTIVE. This continues in loop!\r\n{noformat}\r\n2017-11-07 15:08:11,664 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state\r\n2017-11-07 15:08:11,669 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Recovery started\r\n2017-11-07 15:08:11,669 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Loaded RM state version info 1.5\r\n2017-11-07 15:08:11,670 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Failed to load/recover state\r\norg.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth\r\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:113)\r\n\tat org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:1006)\r\n\tat org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:910)\r\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.doOperation(CuratorTransactionImpl.java:159)\r\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.access$200(CuratorTransactionImpl.java:44)\r\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl$2.call(CuratorTransactionImpl.java:129)\r\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl$2.call(CuratorTransactionImpl.java:125)\r\n\tat org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:109)\r\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.commit(CuratorTransactionImpl.java:122)\r\n\tat org.apache.hadoop.util.curator.ZKCuratorManager$SafeTransaction.commit(ZKCuratorManager.java:403)\r\n\tat org.apache.hadoop.util.curator.ZKCuratorManager.safeSetData(ZKCuratorManager.java:372)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getAndIncrementEpoch(ZKRMStateStore.java:493)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:771)\r\n\tat org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1162)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1202)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1198)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1198)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:320)\r\n\tat org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\r\n\tat org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:894)\r\n\tat org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:473)\r\n\tat org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:607)\r\n\tat org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:505)\r\n{noformat}"
        }
    },
    {
        "filename": "YARN-3369.json",
        "creation_time": "2015-03-18T23:29:06.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.checkForDeactivation(AppSchedulingInfo.java:383)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.decrementOutstanding(AppSchedulingInfo.java:375)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateOffSwitch(AppSchedulingInfo.java:360)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:270)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate(FiCaSchedulerApp.java:142)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1559)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignOffSwitchContainers(LeafQueue.java:1384)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:1263)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:816)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:588)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:449)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1017)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1059)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:114)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:739)\n        at java.lang.Thread.run(Thread.java:722)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.checkForDeactivation": "  synchronized private void checkForDeactivation() {\n    boolean deactivate = true;\n    for (Priority priority : getPriorities()) {\n      ResourceRequest request = getResourceRequest(priority, ResourceRequest.ANY);\n      if (request.getNumContainers() > 0) {\n        deactivate = false;\n        break;\n      }\n    }\n    if (deactivate) {\n      activeUsersManager.deactivateApplication(user, applicationId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.getPriorities": "  synchronized public Collection<Priority> getPriorities() {\n    return priorities;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.getResourceRequest": "  synchronized public ResourceRequest getResourceRequest(Priority priority,\n      String resourceName) {\n    Map<String, ResourceRequest> nodeRequests = requests.get(priority);\n    return (nodeRequests == null) ? null : nodeRequests.get(resourceName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.decrementOutstanding": "  synchronized private void decrementOutstanding(\n      ResourceRequest offSwitchRequest) {\n    int numOffSwitchContainers = offSwitchRequest.getNumContainers() - 1;\n\n    // Do not remove ANY\n    offSwitchRequest.setNumContainers(numOffSwitchContainers);\n    \n    // Do we have any outstanding requests?\n    // If there is nothing, we need to deactivate this application\n    if (numOffSwitchContainers == 0) {\n      checkForDeactivation();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateOffSwitch": "  synchronized private void allocateOffSwitch(SchedulerNode node,\n      Priority priority, ResourceRequest offSwitchRequest, Container container,\n      List<ResourceRequest> resourceRequests) {\n    // Update future requirements\n    decrementOutstanding(offSwitchRequest);\n    // Update cloned OffRack requests for recovery\n    resourceRequests.add(cloneResourceRequest(offSwitchRequest));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.cloneResourceRequest": "  public ResourceRequest cloneResourceRequest(ResourceRequest request) {\n    ResourceRequest newRequest = ResourceRequest.newInstance(\n        request.getPriority(), request.getResourceName(),\n        request.getCapability(), 1, request.getRelaxLocality());\n    return newRequest;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate": "  synchronized public List<ResourceRequest> allocate(NodeType type,\n      SchedulerNode node, Priority priority, ResourceRequest request,\n      Container container) {\n    List<ResourceRequest> resourceRequests = new ArrayList<ResourceRequest>();\n    if (type == NodeType.NODE_LOCAL) {\n      allocateNodeLocal(node, priority, request, container, resourceRequests);\n    } else if (type == NodeType.RACK_LOCAL) {\n      allocateRackLocal(node, priority, request, container, resourceRequests);\n    } else {\n      allocateOffSwitch(node, priority, request, container, resourceRequests);\n    }\n    QueueMetrics metrics = queue.getMetrics();\n    if (pending) {\n      // once an allocation is done we assume the application is\n      // running from scheduler's POV.\n      pending = false;\n      metrics.runAppAttempt(applicationId, user);\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationId=\" + applicationId\n          + \" container=\" + container.getId()\n          + \" host=\" + container.getNodeId().toString()\n          + \" user=\" + user\n          + \" resource=\" + request.getCapability());\n    }\n    metrics.allocateResources(user, 1, request.getCapability(), true);\n    return resourceRequests;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateNodeLocal": "  synchronized private void allocateNodeLocal(SchedulerNode node,\n      Priority priority, ResourceRequest nodeLocalRequest, Container container,\n      List<ResourceRequest> resourceRequests) {\n    // Update future requirements\n    decResourceRequest(node.getNodeName(), priority, nodeLocalRequest);\n\n    ResourceRequest rackLocalRequest = requests.get(priority).get(\n        node.getRackName());\n    decResourceRequest(node.getRackName(), priority, rackLocalRequest);\n\n    ResourceRequest offRackRequest = requests.get(priority).get(\n        ResourceRequest.ANY);\n    decrementOutstanding(offRackRequest);\n\n    // Update cloned NodeLocal, RackLocal and OffRack requests for recovery\n    resourceRequests.add(cloneResourceRequest(nodeLocalRequest));\n    resourceRequests.add(cloneResourceRequest(rackLocalRequest));\n    resourceRequests.add(cloneResourceRequest(offRackRequest));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateRackLocal": "  synchronized private void allocateRackLocal(SchedulerNode node,\n      Priority priority, ResourceRequest rackLocalRequest, Container container,\n      List<ResourceRequest> resourceRequests) {\n    // Update future requirements\n    decResourceRequest(node.getRackName(), priority, rackLocalRequest);\n    \n    ResourceRequest offRackRequest = requests.get(priority).get(\n        ResourceRequest.ANY);\n    decrementOutstanding(offRackRequest);\n\n    // Update cloned RackLocal and OffRack requests for recovery\n    resourceRequests.add(cloneResourceRequest(rackLocalRequest));\n    resourceRequests.add(cloneResourceRequest(offRackRequest));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate": "  synchronized public RMContainer allocate(NodeType type, FiCaSchedulerNode node,\n      Priority priority, ResourceRequest request, \n      Container container) {\n\n    if (isStopped) {\n      return null;\n    }\n    \n    // Required sanity check - AM can call 'allocate' to update resource \n    // request without locking the scheduler, hence we need to check\n    if (getTotalRequiredResources(priority) <= 0) {\n      return null;\n    }\n    \n    // Create RMContainer\n    RMContainer rmContainer = new RMContainerImpl(container, this\n        .getApplicationAttemptId(), node.getNodeID(),\n        appSchedulingInfo.getUser(), this.rmContext);\n\n    // Add it to allContainers list.\n    newlyAllocatedContainers.add(rmContainer);\n    liveContainers.put(container.getId(), rmContainer);    \n\n    // Update consumption and track allocations\n    List<ResourceRequest> resourceRequestList = appSchedulingInfo.allocate(\n        type, node, priority, request, container);\n    Resources.addTo(currentConsumption, container.getResource());\n    \n    // Update resource requests related to \"request\" and store in RMContainer \n    ((RMContainerImpl)rmContainer).setResourceRequests(resourceRequestList);\n\n    // Inform the container\n    rmContainer.handle(\n        new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"allocate: applicationAttemptId=\" \n          + container.getId().getApplicationAttemptId() \n          + \" container=\" + container.getId() + \" host=\"\n          + container.getNodeId().getHost() + \" type=\" + type);\n    }\n    RMAuditLogger.logSuccess(getUser(), \n        AuditConstants.ALLOC_CONTAINER, \"SchedulerApp\", \n        getApplicationId(), container.getId());\n    \n    return rmContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer": "    public void assignContainer(Resource resource,\n        Set<String> nodeLabels) {\n      if (nodeLabels == null || nodeLabels.isEmpty()) {\n        userResourceUsage.incUsed(resource);\n      } else {\n        for (String label : nodeLabels) {\n          userResourceUsage.incUsed(label, resource);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.checkLimitsToReserve": "  protected boolean checkLimitsToReserve(Resource clusterResource,\n      FiCaSchedulerApp application, Resource capability) {\n    // we can't reserve if we got here based on the limit\n    // checks assuming we could unreserve!!!\n    Resource userLimit = computeUserLimitAndSetHeadroom(application,\n        clusterResource, capability, null);\n\n    // Check queue max-capacity limit,\n    // TODO: Consider reservation on labels\n    if (!canAssignToThisQueue(clusterResource, null,\n        this.currentResourceLimits, capability, Resources.none())) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"was going to reserve but hit queue limit\");\n      }\n      return false;\n    }\n\n    // Check user limit\n    if (!assignToUser(clusterResource, application.getUser(), userLimit,\n        application, false, null)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"was going to reserve but hit user limit\");\n      }\n      return false;\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.shouldAllocOrReserveNewContainer": "  boolean shouldAllocOrReserveNewContainer(FiCaSchedulerApp application,\n      Priority priority, Resource required) {\n    int requiredContainers = application.getTotalRequiredResources(priority);\n    int reservedContainers = application.getNumReservedContainers(priority);\n    int starvation = 0;\n    if (reservedContainers > 0) {\n      float nodeFactor = \n          Resources.ratio(\n              resourceCalculator, required, getMaximumAllocation()\n              );\n      \n      // Use percentage of node required to bias against large containers...\n      // Protect against corner case where you need the whole node with\n      // Math.min(nodeFactor, minimumAllocationFactor)\n      starvation = \n          (int)((application.getReReservations(priority) / (float)reservedContainers) * \n                (1.0f - (Math.min(nodeFactor, getMinimumAllocationFactor())))\n               );\n      \n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"needsContainers:\" +\n            \" app.#re-reserve=\" + application.getReReservations(priority) + \n            \" reserved=\" + reservedContainers + \n            \" nodeFactor=\" + nodeFactor + \n            \" minAllocFactor=\" + getMinimumAllocationFactor() +\n            \" starvation=\" + starvation);\n      }\n    }\n    return (((starvation + requiredContainers) - reservedContainers) > 0);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.reserve": "  private void reserve(FiCaSchedulerApp application, Priority priority, \n      FiCaSchedulerNode node, RMContainer rmContainer, Container container) {\n    // Update reserved metrics if this is the first reservation\n    if (rmContainer == null) {\n      getMetrics().reserveResource(\n          application.getUser(), container.getResource());\n    }\n\n    // Inform the application \n    rmContainer = application.reserve(node, priority, rmContainer, container);\n    \n    // Update the node\n    node.reserveResource(application, priority, rmContainer);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getContainer": "  private Container getContainer(RMContainer rmContainer, \n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      Resource capability, Priority priority) {\n    return (rmContainer != null) ? rmContainer.getContainer() :\n      createContainer(application, node, capability, priority);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.findNodeToUnreserve": "  protected boolean findNodeToUnreserve(Resource clusterResource,\n      FiCaSchedulerNode node, FiCaSchedulerApp application, Priority priority,\n      Resource askedResource, Resource minimumUnreservedResource) {\n    // need to unreserve some other container first\n    NodeId idToUnreserve =\n        application.getNodeIdToUnreserve(priority, minimumUnreservedResource,\n            resourceCalculator, clusterResource);\n    if (idToUnreserve == null) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"checked to see if could unreserve for app but nothing \"\n            + \"reserved that matches for this app\");\n      }\n      return false;\n    }\n    FiCaSchedulerNode nodeToUnreserve = scheduler.getNode(idToUnreserve);\n    if (nodeToUnreserve == null) {\n      LOG.error(\"node to unreserve doesn't exist, nodeid: \" + idToUnreserve);\n      return false;\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"unreserving for app: \" + application.getApplicationId()\n        + \" on nodeId: \" + idToUnreserve\n        + \" in order to replace reserved application and place it on node: \"\n        + node.getNodeID() + \" needing: \" + askedResource);\n    }\n\n    // headroom\n    Resources.addTo(application.getHeadroom(), nodeToUnreserve\n        .getReservedContainer().getReservedResource());\n\n    // Make sure to not have completedContainers sort the queues here since\n    // we are already inside an iterator loop for the queues and this would\n    // cause an concurrent modification exception.\n    completedContainer(clusterResource, application, nodeToUnreserve,\n        nodeToUnreserve.getReservedContainer(),\n        SchedulerUtils.createAbnormalContainerStatus(nodeToUnreserve\n            .getReservedContainer().getContainerId(),\n            SchedulerUtils.UNRESERVED_CONTAINER),\n        RMContainerEventType.RELEASED, null, false);\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.toString": "  public String toString() {\n    return queueName + \": \" + \n        \"capacity=\" + queueCapacities.getCapacity() + \", \" + \n        \"absoluteCapacity=\" + queueCapacities.getAbsoluteCapacity() + \", \" + \n        \"usedResources=\" + queueUsage.getUsed() +  \", \" +\n        \"usedCapacity=\" + getUsedCapacity() + \", \" + \n        \"absoluteUsedCapacity=\" + getAbsoluteUsedCapacity() + \", \" +\n        \"numApps=\" + getNumApplications() + \", \" + \n        \"numContainers=\" + getNumContainers();  \n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.unreserve": "  private boolean unreserve(FiCaSchedulerApp application, Priority priority,\n      FiCaSchedulerNode node, RMContainer rmContainer) {\n    // Done with the reservation?\n    if (application.unreserve(node, priority)) {\n      node.unreserveResource(application);\n\n      // Update reserved metrics\n      getMetrics().unreserveResource(application.getUser(),\n          rmContainer.getContainer().getResource());\n      return true;\n    }\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getUsed": "    public Resource getUsed(String label) {\n      return userResourceUsage.getUsed(label);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getMinimumResourceNeedUnreserved": "  private Resource getMinimumResourceNeedUnreserved(Resource askedResource) {\n    // First we need to get minimum resource we need unreserve\n    // minimum-resource-need-unreserve = used + asked - limit\n    Resource minimumUnreservedResource =\n        Resources.subtract(Resources.add(queueUsage.getUsed(), askedResource),\n            currentResourceLimits.getLimit());\n    return minimumUnreservedResource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignOffSwitchContainers": "  private Resource assignOffSwitchContainers(Resource clusterResource,\n      ResourceRequest offSwitchResourceRequest, FiCaSchedulerNode node,\n      FiCaSchedulerApp application, Priority priority,\n      RMContainer reservedContainer, MutableObject allocatedContainer) {\n    if (canAssign(application, priority, node, NodeType.OFF_SWITCH,\n        reservedContainer)) {\n      return assignContainer(clusterResource, node, application, priority,\n          offSwitchResourceRequest, NodeType.OFF_SWITCH, reservedContainer,\n          allocatedContainer);\n    }\n    \n    return Resources.none();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.canAssign": "  boolean canAssign(FiCaSchedulerApp application, Priority priority, \n      FiCaSchedulerNode node, NodeType type, RMContainer reservedContainer) {\n\n    // Clearly we need containers for this application...\n    if (type == NodeType.OFF_SWITCH) {\n      if (reservedContainer != null) {\n        return true;\n      }\n\n      // 'Delay' off-switch\n      ResourceRequest offSwitchRequest = \n          application.getResourceRequest(priority, ResourceRequest.ANY);\n      long missedOpportunities = application.getSchedulingOpportunities(priority);\n      long requiredContainers = offSwitchRequest.getNumContainers(); \n      \n      float localityWaitFactor = \n        application.getLocalityWaitFactor(priority, \n            scheduler.getNumClusterNodes());\n      \n      return ((requiredContainers * localityWaitFactor) < missedOpportunities);\n    }\n\n    // Check if we need containers on this rack \n    ResourceRequest rackLocalRequest = \n      application.getResourceRequest(priority, node.getRackName());\n    if (rackLocalRequest == null || rackLocalRequest.getNumContainers() <= 0) {\n      return false;\n    }\n      \n    // If we are here, we do need containers on this rack for RACK_LOCAL req\n    if (type == NodeType.RACK_LOCAL) {\n      // 'Delay' rack-local just a little bit...\n      long missedOpportunities = application.getSchedulingOpportunities(priority);\n      return (\n          Math.min(scheduler.getNumClusterNodes(), getNodeLocalityDelay()) < \n          missedOpportunities\n          );\n    }\n\n    // Check if we need containers on this host\n    if (type == NodeType.NODE_LOCAL) {\n      // Now check if we need containers on this host...\n      ResourceRequest nodeLocalRequest = \n        application.getResourceRequest(priority, node.getNodeName());\n      if (nodeLocalRequest != null) {\n        return nodeLocalRequest.getNumContainers() > 0;\n      }\n    }\n\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode": "  private CSAssignment assignContainersOnNode(Resource clusterResource,\n      FiCaSchedulerNode node, FiCaSchedulerApp application, Priority priority,\n      RMContainer reservedContainer) {\n    Resource assigned = Resources.none();\n\n    NodeType requestType = null;\n    MutableObject allocatedContainer = new MutableObject();\n    // Data-local\n    ResourceRequest nodeLocalResourceRequest =\n        application.getResourceRequest(priority, node.getNodeName());\n    if (nodeLocalResourceRequest != null) {\n      requestType = NodeType.NODE_LOCAL;\n      assigned =\n          assignNodeLocalContainers(clusterResource, nodeLocalResourceRequest, \n            node, application, priority, reservedContainer,\n            allocatedContainer);\n      if (Resources.greaterThan(resourceCalculator, clusterResource,\n          assigned, Resources.none())) {\n\n        //update locality statistics\n        if (allocatedContainer.getValue() != null) {\n          application.incNumAllocatedContainers(NodeType.NODE_LOCAL,\n            requestType);\n        }\n        return new CSAssignment(assigned, NodeType.NODE_LOCAL);\n      }\n    }\n\n    // Rack-local\n    ResourceRequest rackLocalResourceRequest =\n        application.getResourceRequest(priority, node.getRackName());\n    if (rackLocalResourceRequest != null) {\n      if (!rackLocalResourceRequest.getRelaxLocality()) {\n        return SKIP_ASSIGNMENT;\n      }\n\n      if (requestType != NodeType.NODE_LOCAL) {\n        requestType = NodeType.RACK_LOCAL;\n      }\n\n      assigned = \n          assignRackLocalContainers(clusterResource, rackLocalResourceRequest, \n            node, application, priority, reservedContainer,\n            allocatedContainer);\n      if (Resources.greaterThan(resourceCalculator, clusterResource,\n          assigned, Resources.none())) {\n\n        //update locality statistics\n        if (allocatedContainer.getValue() != null) {\n          application.incNumAllocatedContainers(NodeType.RACK_LOCAL,\n            requestType);\n        }\n        return new CSAssignment(assigned, NodeType.RACK_LOCAL);\n      }\n    }\n    \n    // Off-switch\n    ResourceRequest offSwitchResourceRequest =\n        application.getResourceRequest(priority, ResourceRequest.ANY);\n    if (offSwitchResourceRequest != null) {\n      if (!offSwitchResourceRequest.getRelaxLocality()) {\n        return SKIP_ASSIGNMENT;\n      }\n      if (requestType != NodeType.NODE_LOCAL\n          && requestType != NodeType.RACK_LOCAL) {\n        requestType = NodeType.OFF_SWITCH;\n      }\n\n      assigned =\n          assignOffSwitchContainers(clusterResource, offSwitchResourceRequest,\n            node, application, priority, reservedContainer,\n            allocatedContainer);\n\n      // update locality statistics\n      if (allocatedContainer.getValue() != null) {\n        application.incNumAllocatedContainers(NodeType.OFF_SWITCH, requestType);\n      }\n      return new CSAssignment(assigned, NodeType.OFF_SWITCH);\n    }\n    \n    return SKIP_ASSIGNMENT;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers": "  private Resource assignNodeLocalContainers(Resource clusterResource,\n      ResourceRequest nodeLocalResourceRequest, FiCaSchedulerNode node,\n      FiCaSchedulerApp application, Priority priority,\n      RMContainer reservedContainer, MutableObject allocatedContainer) {\n    if (canAssign(application, priority, node, NodeType.NODE_LOCAL, \n        reservedContainer)) {\n      return assignContainer(clusterResource, node, application, priority,\n          nodeLocalResourceRequest, NodeType.NODE_LOCAL, reservedContainer,\n          allocatedContainer);\n    }\n    \n    return Resources.none();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignRackLocalContainers": "  private Resource assignRackLocalContainers(Resource clusterResource,\n      ResourceRequest rackLocalResourceRequest, FiCaSchedulerNode node,\n      FiCaSchedulerApp application, Priority priority,\n      RMContainer reservedContainer, MutableObject allocatedContainer) {\n    if (canAssign(application, priority, node, NodeType.RACK_LOCAL,\n        reservedContainer)) {\n      return assignContainer(clusterResource, node, application, priority,\n          rackLocalResourceRequest, NodeType.RACK_LOCAL, reservedContainer,\n          allocatedContainer);\n    }\n    \n    return Resources.none();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers": "  public synchronized CSAssignment assignContainers(Resource clusterResource,\n      FiCaSchedulerNode node, ResourceLimits currentResourceLimits) {\n    updateCurrentResourceLimits(currentResourceLimits, clusterResource);\n    \n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\"assignContainers: node=\" + node.getNodeName()\n        + \" #applications=\" + activeApplications.size());\n    }\n    \n    // if our queue cannot access this node, just return\n    if (!SchedulerUtils.checkQueueAccessToNode(accessibleLabels,\n        node.getLabels())) {\n      return NULL_ASSIGNMENT;\n    }\n    \n    // Check for reserved resources\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      FiCaSchedulerApp application = \n          getApplication(reservedContainer.getApplicationAttemptId());\n      synchronized (application) {\n        return assignReservedContainer(application, node, reservedContainer,\n            clusterResource);\n      }\n    }\n    \n    // Try to assign containers to applications in order\n    for (FiCaSchedulerApp application : activeApplications) {\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"pre-assignContainers for application \"\n        + application.getApplicationId());\n        application.showRequests();\n      }\n\n      synchronized (application) {\n        // Check if this resource is on the blacklist\n        if (SchedulerAppUtils.isBlacklisted(application, node, LOG)) {\n          continue;\n        }\n        \n        // Schedule in priority order\n        for (Priority priority : application.getPriorities()) {\n          ResourceRequest anyRequest =\n              application.getResourceRequest(priority, ResourceRequest.ANY);\n          if (null == anyRequest) {\n            continue;\n          }\n          \n          // Required resource\n          Resource required = anyRequest.getCapability();\n\n          // Do we need containers at this 'priority'?\n          if (application.getTotalRequiredResources(priority) <= 0) {\n            continue;\n          }\n          if (!this.reservationsContinueLooking) {\n            if (!shouldAllocOrReserveNewContainer(application, priority, required)) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"doesn't need containers based on reservation algo!\");\n              }\n              continue;\n            }\n          }\n          \n          Set<String> requestedNodeLabels =\n              getRequestLabelSetByExpression(anyRequest\n                  .getNodeLabelExpression());\n\n          // Compute user-limit & set headroom\n          // Note: We compute both user-limit & headroom with the highest \n          //       priority request as the target. \n          //       This works since we never assign lower priority requests\n          //       before all higher priority ones are serviced.\n          Resource userLimit = \n              computeUserLimitAndSetHeadroom(application, clusterResource, \n                  required, requestedNodeLabels);          \n          \n          // Check queue max-capacity limit\n          if (!super.canAssignToThisQueue(clusterResource, node.getLabels(),\n              this.currentResourceLimits, required, application.getCurrentReservation())) {\n            return NULL_ASSIGNMENT;\n          }\n\n          // Check user limit\n          if (!assignToUser(clusterResource, application.getUser(), userLimit,\n              application, true, requestedNodeLabels)) {\n            break;\n          }\n\n          // Inform the application it is about to get a scheduling opportunity\n          application.addSchedulingOpportunity(priority);\n          \n          // Try to schedule\n          CSAssignment assignment =  \n            assignContainersOnNode(clusterResource, node, application, priority, \n                null);\n\n          // Did the application skip this node?\n          if (assignment.getSkipped()) {\n            // Don't count 'skipped nodes' as a scheduling opportunity!\n            application.subtractSchedulingOpportunity(priority);\n            continue;\n          }\n          \n          // Did we schedule or reserve a container?\n          Resource assigned = assignment.getResource();\n          if (Resources.greaterThan(\n              resourceCalculator, clusterResource, assigned, Resources.none())) {\n\n            // Book-keeping \n            // Note: Update headroom to account for current allocation too...\n            allocateResource(clusterResource, application, assigned,\n                node.getLabels());\n            \n            // Don't reset scheduling opportunities for non-local assignments\n            // otherwise the app will be delayed for each non-local assignment.\n            // This helps apps with many off-cluster requests schedule faster.\n            if (assignment.getType() != NodeType.OFF_SWITCH) {\n              if (LOG.isDebugEnabled()) {\n                LOG.debug(\"Resetting scheduling opportunities\");\n              }\n              application.resetSchedulingOpportunities(priority);\n            }\n            \n            // Done\n            return assignment;\n          } else {\n            // Do not assign out of order w.r.t priorities\n            break;\n          }\n        }\n      }\n\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"post-assignContainers for application \"\n          + application.getApplicationId());\n      }\n      application.showRequests();\n    }\n  \n    return NULL_ASSIGNMENT;\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.allocateResource": "  synchronized void allocateResource(Resource clusterResource,\n      SchedulerApplicationAttempt application, Resource resource,\n      Set<String> nodeLabels) {\n    super.allocateResource(clusterResource, resource, nodeLabels);\n    \n    // Update user metrics\n    String userName = application.getUser();\n    User user = getUser(userName);\n    user.assignContainer(resource, nodeLabels);\n    // Note this is a bit unconventional since it gets the object and modifies\n    // it here, rather then using set routine\n    Resources.subtractFrom(application.getHeadroom(), resource); // headroom\n    metrics.setAvailableResourcesToUser(userName, application.getHeadroom());\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.info(getQueueName() + \n          \" user=\" + userName + \n          \" used=\" + queueUsage.getUsed() + \" numContainers=\" + numContainers +\n          \" headroom = \" + application.getHeadroom() +\n          \" user-resources=\" + user.getUsed()\n          );\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignToUser": "  protected synchronized boolean assignToUser(Resource clusterResource,\n      String userName, Resource limit, FiCaSchedulerApp application,\n      boolean checkReservations, Set<String> requestLabels) {\n    User user = getUser(userName);\n    \n    String label = CommonNodeLabelsManager.NO_LABEL;\n    if (requestLabels != null && !requestLabels.isEmpty()) {\n      label = requestLabels.iterator().next();\n    }\n\n    // Note: We aren't considering the current request since there is a fixed\n    // overhead of the AM, but it's a > check, not a >= check, so...\n    if (Resources\n        .greaterThan(resourceCalculator, clusterResource,\n            user.getUsed(label),\n            limit)) {\n      // if enabled, check to see if could we potentially use this node instead\n      // of a reserved node if the application has reserved containers\n      if (this.reservationsContinueLooking && checkReservations) {\n        if (Resources.lessThanOrEqual(\n            resourceCalculator,\n            clusterResource,\n            Resources.subtract(user.getUsed(),\n                application.getCurrentReservation()), limit)) {\n\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"User \" + userName + \" in queue \" + getQueueName()\n                + \" will exceed limit based on reservations - \" + \" consumed: \"\n                + user.getUsed() + \" reserved: \"\n                + application.getCurrentReservation() + \" limit: \" + limit);\n          }\n          return true;\n        }\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"User \" + userName + \" in queue \" + getQueueName()\n            + \" will exceed limit - \" + \" consumed: \"\n            + user.getUsed() + \" limit: \" + limit);\n      }\n      return false;\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.computeUserLimitAndSetHeadroom": "  Resource computeUserLimitAndSetHeadroom(FiCaSchedulerApp application,\n      Resource clusterResource, Resource required, Set<String> requestedLabels) {\n    String user = application.getUser();\n    User queueUser = getUser(user);\n\n    // Compute user limit respect requested labels,\n    // TODO, need consider headroom respect labels also\n    Resource userLimit =\n        computeUserLimit(application, clusterResource, required,\n            queueUser, requestedLabels);\n\n    setQueueResourceLimitsInfo(clusterResource);\n    \n    Resource headroom =\n        getHeadroom(queueUser, currentResourceLimits.getLimit(),\n            clusterResource, userLimit);\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Headroom calculation for user \" + user + \": \" + \n          \" userLimit=\" + userLimit + \n          \" queueMaxAvailRes=\" + currentResourceLimits.getLimit() + \n          \" consumed=\" + queueUser.getUsed() + \n          \" headroom=\" + headroom);\n    }\n    \n    CapacityHeadroomProvider headroomProvider = new CapacityHeadroomProvider(\n      queueUser, this, application, required, queueResourceLimitsInfo);\n    \n    application.setHeadroomProvider(headroomProvider);\n\n    metrics.setAvailableResourcesToUser(user, headroom);\n    \n    return userLimit;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getUser": "  public synchronized User getUser(String userName) {\n    User user = users.get(userName);\n    if (user == null) {\n      user = new User();\n      users.put(userName, user);\n    }\n    return user;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getApplication": "  private synchronized FiCaSchedulerApp getApplication(\n      ApplicationAttemptId applicationAttemptId) {\n    return applicationAttemptMap.get(applicationAttemptId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.updateCurrentResourceLimits": "  private void updateCurrentResourceLimits(\n      ResourceLimits currentResourceLimits, Resource clusterResource) {\n    // TODO: need consider non-empty node labels when resource limits supports\n    // node labels\n    // Even if ParentQueue will set limits respect child's max queue capacity,\n    // but when allocating reserved container, CapacityScheduler doesn't do\n    // this. So need cap limits by queue's max capacity here.\n    this.currentResourceLimits = currentResourceLimits;\n    Resource queueMaxResource =\n        Resources.multiplyAndNormalizeDown(resourceCalculator, labelManager\n            .getResourceByLabel(RMNodeLabelsManager.NO_LABEL, clusterResource),\n            queueCapacities\n                .getAbsoluteMaximumCapacity(RMNodeLabelsManager.NO_LABEL),\n            minimumAllocation);\n    this.currentResourceLimits.setLimit(Resources.min(resourceCalculator,\n        clusterResource, queueMaxResource, currentResourceLimits.getLimit()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getRequestLabelSetByExpression": "  private static Set<String> getRequestLabelSetByExpression(\n      String labelExpression) {\n    Set<String> labels = new HashSet<String>();\n    if (null == labelExpression) {\n      return labels;\n    }\n    for (String l : labelExpression.split(\"&&\")) {\n      if (l.trim().isEmpty()) {\n        continue;\n      }\n      labels.add(l.trim());\n    }\n    return labels;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignReservedContainer": "  private synchronized CSAssignment assignReservedContainer(\n      FiCaSchedulerApp application, FiCaSchedulerNode node,\n      RMContainer rmContainer, Resource clusterResource) {\n    // Do we still need this reservation?\n    Priority priority = rmContainer.getReservedPriority();\n    if (application.getTotalRequiredResources(priority) == 0) {\n      // Release\n      return new CSAssignment(application, rmContainer);\n    }\n\n    // Try to assign if we have sufficient resources\n    assignContainersOnNode(clusterResource, node, application, priority, \n        rmContainer);\n    \n    // Doesn't matter... since it's already charged for at time of reservation\n    // \"re-reservation\" is *free*\n    return new CSAssignment(Resources.none(), NodeType.NODE_LOCAL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues": "  private synchronized CSAssignment assignContainersToChildQueues(\n      Resource cluster, FiCaSchedulerNode node, ResourceLimits limits) {\n    CSAssignment assignment = \n        new CSAssignment(Resources.createResource(0, 0), NodeType.NODE_LOCAL);\n    \n    printChildQueues();\n\n    // Try to assign to most 'under-served' sub-queue\n    for (Iterator<CSQueue> iter = childQueues.iterator(); iter.hasNext();) {\n      CSQueue childQueue = iter.next();\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Trying to assign to queue: \" + childQueue.getQueuePath()\n          + \" stats: \" + childQueue);\n      }\n      \n      // Get ResourceLimits of child queue before assign containers\n      ResourceLimits childLimits =\n          getResourceLimitsOfChild(childQueue, cluster, limits);\n      \n      assignment = childQueue.assignContainers(cluster, node, childLimits);\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Assigned to queue: \" + childQueue.getQueuePath() +\n          \" stats: \" + childQueue + \" --> \" + \n          assignment.getResource() + \", \" + assignment.getType());\n      }\n\n      // If we do assign, remove the queue and re-insert in-order to re-sort\n      if (Resources.greaterThan(\n              resourceCalculator, cluster, \n              assignment.getResource(), Resources.none())) {\n        // Remove and re-insert to sort\n        iter.remove();\n        LOG.info(\"Re-sorting assigned queue: \" + childQueue.getQueuePath() + \n            \" stats: \" + childQueue);\n        childQueues.add(childQueue);\n        if (LOG.isDebugEnabled()) {\n          printChildQueues();\n        }\n        break;\n      }\n    }\n    \n    return assignment;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers": "  public synchronized CSAssignment assignContainers(Resource clusterResource,\n      FiCaSchedulerNode node, ResourceLimits resourceLimits) {\n    CSAssignment assignment = \n        new CSAssignment(Resources.createResource(0, 0), NodeType.NODE_LOCAL);\n    Set<String> nodeLabels = node.getLabels();\n    \n    // if our queue cannot access this node, just return\n    if (!SchedulerUtils.checkQueueAccessToNode(accessibleLabels, nodeLabels)) {\n      return assignment;\n    }\n    \n    while (canAssign(clusterResource, node)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Trying to assign containers to child-queue of \"\n          + getQueueName());\n      }\n      \n      // Are we over maximum-capacity for this queue?\n      // This will also consider parent's limits and also continuous reservation\n      // looking\n      if (!super.canAssignToThisQueue(clusterResource, nodeLabels, resourceLimits,\n          minimumAllocation, Resources.createResource(getMetrics()\n              .getReservedMB(), getMetrics().getReservedVirtualCores()))) {\n        break;\n      }\n      \n      // Schedule\n      CSAssignment assignedToChild = \n          assignContainersToChildQueues(clusterResource, node, resourceLimits);\n      assignment.setType(assignedToChild.getType());\n      \n      // Done if no child-queue assigned anything\n      if (Resources.greaterThan(\n              resourceCalculator, clusterResource, \n              assignedToChild.getResource(), Resources.none())) {\n        // Track resource utilization for the parent-queue\n        super.allocateResource(clusterResource, assignedToChild.getResource(),\n            nodeLabels);\n        \n        // Track resource utilization in this pass of the scheduler\n        Resources.addTo(assignment.getResource(), assignedToChild.getResource());\n        \n        LOG.info(\"assignedContainer\" +\n            \" queue=\" + getQueueName() + \n            \" usedCapacity=\" + getUsedCapacity() +\n            \" absoluteUsedCapacity=\" + getAbsoluteUsedCapacity() +\n            \" used=\" + queueUsage.getUsed() + \n            \" cluster=\" + clusterResource);\n\n      } else {\n        break;\n      }\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"ParentQ=\" + getQueueName()\n          + \" assignedSoFarInThisIteration=\" + assignment.getResource()\n          + \" usedCapacity=\" + getUsedCapacity()\n          + \" absoluteUsedCapacity=\" + getAbsoluteUsedCapacity());\n      }\n\n      // Do not assign more than one container if this isn't the root queue\n      // or if we've already assigned an off-switch container\n      if (!rootQueue || assignment.getType() == NodeType.OFF_SWITCH) {\n        if (LOG.isDebugEnabled()) {\n          if (rootQueue && assignment.getType() == NodeType.OFF_SWITCH) {\n            LOG.debug(\"Not assigning more than one off-switch container,\" +\n                \" assignments so far: \" + assignment);\n          }\n        }\n        break;\n      }\n    } \n    \n    return assignment;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getQueuePath": "  public String getQueuePath() {\n    String parentPath = ((parent == null) ? \"\" : (parent.getQueuePath() + \".\"));\n    return parentPath + getQueueName();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getResourceLimitsOfChild": "  private ResourceLimits getResourceLimitsOfChild(CSQueue child,\n      Resource clusterResource, ResourceLimits parentLimits) {\n    // Set resource-limit of a given child, child.limit =\n    // min(my.limit - my.used + child.used, child.max)\n\n    // Parent available resource = parent-limit - parent-used-resource\n    Resource parentMaxAvailableResource =\n        Resources.subtract(parentLimits.getLimit(), getUsedResources());\n\n    // Child's limit = parent-available-resource + child-used\n    Resource childLimit =\n        Resources.add(parentMaxAvailableResource, child.getUsedResources());\n\n    // Get child's max resource\n    Resource childConfiguredMaxResource =\n        Resources.multiplyAndNormalizeDown(resourceCalculator, labelManager\n            .getResourceByLabel(RMNodeLabelsManager.NO_LABEL, clusterResource),\n            child.getAbsoluteMaximumCapacity(), minimumAllocation);\n\n    // Child's limit should be capped by child configured max resource\n    childLimit =\n        Resources.min(resourceCalculator, clusterResource, childLimit,\n            childConfiguredMaxResource);\n\n    // Normalize before return\n    childLimit =\n        Resources.roundDown(resourceCalculator, childLimit, minimumAllocation);\n\n    return new ResourceLimits(childLimit);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.printChildQueues": "  private void printChildQueues() {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"printChildQueues - queue: \" + getQueuePath()\n        + \" child-queues: \" + getChildQueuesToPrint());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode": "  private synchronized void allocateContainersToNode(FiCaSchedulerNode node) {\n    if (rmContext.isWorkPreservingRecoveryEnabled()\n        && !rmContext.isSchedulerReadyForAllocatingContainers()) {\n      return;\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      FiCaSchedulerApp reservedApplication =\n          getCurrentAttemptForContainer(reservedContainer.getContainerId());\n      \n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" + \n          reservedApplication.getApplicationId() + \" on node: \" + \n          node.getNodeID());\n      \n      LeafQueue queue = ((LeafQueue)reservedApplication.getQueue());\n      CSAssignment assignment =\n          queue.assignContainers(\n              clusterResource,\n              node,\n              // TODO, now we only consider limits for parent for non-labeled\n              // resources, should consider labeled resources as well.\n              new ResourceLimits(labelManager.getResourceByLabel(\n                  RMNodeLabelsManager.NO_LABEL, clusterResource)));\n      \n      RMContainer excessReservation = assignment.getExcessReservation();\n      if (excessReservation != null) {\n      Container container = excessReservation.getContainer();\n      queue.completedContainer(\n          clusterResource, assignment.getApplication(), node, \n          excessReservation, \n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getId(), \n              SchedulerUtils.UNRESERVED_CONTAINER), \n          RMContainerEventType.RELEASED, null, true);\n      }\n\n    }\n\n    // Try to schedule more if there are no reservations to fulfill\n    if (node.getReservedContainer() == null) {\n      if (calculator.computeAvailableContainers(node.getAvailableResource(),\n        minimumAllocation) > 0) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Trying to schedule on node: \" + node.getNodeName() +\n              \", available: \" + node.getAvailableResource());\n        }\n        root.assignContainers(\n            clusterResource,\n            node,\n            // TODO, now we only consider limits for parent for non-labeled\n            // resources, should consider labeled resources as well.\n            new ResourceLimits(labelManager.getResourceByLabel(\n                RMNodeLabelsManager.NO_LABEL, clusterResource)));\n      }\n    } else {\n      LOG.info(\"Skipping scheduling since node \" + node.getNodeID() + \n          \" is reserved by application \" + \n          node.getReservedContainer().getContainerId().getApplicationAttemptId()\n          );\n    }\n  \n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainer": "  protected synchronized void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n    if (rmContainer == null) {\n      LOG.info(\"Container \" + containerStatus.getContainerId() +\n          \" completed with event \" + event);\n      return;\n    }\n    \n    Container container = rmContainer.getContainer();\n    \n    // Get the application for the finished container\n    FiCaSchedulerApp application =\n        getCurrentAttemptForContainer(container.getId());\n    ApplicationId appId =\n        container.getId().getApplicationAttemptId().getApplicationId();\n    if (application == null) {\n      LOG.info(\"Container \" + container + \" of\" + \" finished application \"\n          + appId + \" completed with event \" + event);\n      return;\n    }\n    \n    // Get the node on which the container was allocated\n    FiCaSchedulerNode node = getNode(container.getNodeId());\n    \n    // Inform the queue\n    LeafQueue queue = (LeafQueue)application.getQueue();\n    queue.completedContainer(clusterResource, application, node, \n        rmContainer, containerStatus, event, null, true);\n\n    LOG.info(\"Application attempt \" + application.getApplicationAttemptId()\n        + \" released container \" + container.getId() + \" on node: \" + node\n        + \" with event: \" + event);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public synchronized CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return queues.get(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_LABELS_UPDATE:\n    {\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent =\n          (NodeLabelsUpdateSchedulerEvent) event;\n      \n      for (Entry<NodeId, Set<String>> entry : labelUpdateEvent\n          .getUpdatedNodeToLabels().entrySet()) {\n        NodeId id = entry.getKey();\n        Set<String> labels = entry.getValue();\n        updateLabelsOnNode(id, labels);\n      }\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      RMNode node = nodeUpdatedEvent.getRMNode();\n      nodeUpdate(node);\n      if (!scheduleAsynchronously) {\n        allocateContainersToNode(getNode(node.getNodeID()));\n      }\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName,\n            appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent = \n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId), \n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId, \n              SchedulerUtils.EXPIRED_CONTAINER), \n          RMContainerEventType.EXPIRE);\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addNode": "  private synchronized void addNode(RMNode nodeManager) {\n    FiCaSchedulerNode schedulerNode = new FiCaSchedulerNode(nodeManager,\n        usePortForNodeName, nodeManager.getNodeLabels());\n    this.nodes.put(nodeManager.getNodeID(), schedulerNode);\n    Resources.addTo(clusterResource, nodeManager.getTotalCapability());\n\n    // update this node to node label manager\n    if (labelManager != null) {\n      labelManager.activateNode(nodeManager.getNodeID(),\n          nodeManager.getTotalCapability());\n    }\n    \n    root.updateClusterResource(clusterResource, new ResourceLimits(\n        clusterResource));\n    int numNodes = numNodeManagers.incrementAndGet();\n    updateMaximumAllocation(schedulerNode, true);\n    \n    LOG.info(\"Added node \" + nodeManager.getNodeAddress() + \n        \" clusterResource: \" + clusterResource);\n\n    if (scheduleAsynchronously && numNodes == 1) {\n      asyncSchedulerThread.beginSchedule();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateLabelsOnNode": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set<String> newLabels) {\n    FiCaSchedulerNode node = nodes.get(nodeId);\n    if (null == node) {\n      return;\n    }\n    \n    // labels is same, we don't need do update\n    if (node.getLabels().size() == newLabels.size()\n        && node.getLabels().containsAll(newLabels)) {\n      return;\n    }\n    \n    // Kill running containers since label is changed\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      ContainerId containerId = rmContainer.getContainerId();\n      completedContainer(rmContainer, \n          ContainerStatus.newInstance(containerId,\n              ContainerState.COMPLETE, \n              String.format(\n                  \"Container=%s killed since labels on the node=%s changed\",\n                  containerId.toString(), nodeId.toString()),\n              ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),\n          RMContainerEventType.KILL);\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (null != reservedContainer) {\n      dropContainerReservation(reservedContainer);\n    }\n    \n    // Update node labels after we've done this\n    node.updateLabels(newLabels);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplication": "  private synchronized void addApplication(ApplicationId applicationId,\n    String queueName, String user, boolean isAppRecovering) {\n\n    if (mappings != null && mappings.size() > 0) {\n      try {\n        String mappedQueue = getMappedQueue(user);\n        if (mappedQueue != null) {\n          // We have a mapping, should we use it?\n          if (queueName.equals(YarnConfiguration.DEFAULT_QUEUE_NAME)\n              || overrideWithQueueMappings) {\n            LOG.info(\"Application \" + applicationId + \" user \" + user\n                + \" mapping [\" + queueName + \"] to [\" + mappedQueue\n                + \"] override \" + overrideWithQueueMappings);\n            queueName = mappedQueue;\n            RMApp rmApp = rmContext.getRMApps().get(applicationId);\n            rmApp.setQueue(queueName);\n          }\n        }\n      } catch (IOException ioex) {\n        String message = \"Failed to submit application \" + applicationId +\n            \" submitted by user \" + user + \" reason: \" + ioex.getMessage();\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, message));\n        return;\n      }\n    }\n\n    // sanity checks.\n    CSQueue queue = getQueue(queueName);\n    if (queue == null) {\n      //During a restart, this indicates a queue was removed, which is\n      //not presently supported\n      if (isAppRecovering) {\n        String queueErrorMsg = \"Queue named \" + queueName\n           + \" missing during application recovery.\"\n           + \" Queue removal during recovery is not presently supported by the\"\n           + \" capacity scheduler, please restart with all queues configured\"\n           + \" which were present before shutdown/restart.\";\n        LOG.fatal(queueErrorMsg);\n        throw new QueueNotFoundException(queueErrorMsg);\n      }\n      String message = \"Application \" + applicationId + \n      \" submitted by user \" + user + \" to unknown queue: \" + queueName;\n      this.rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n    if (!(queue instanceof LeafQueue)) {\n      String message = \"Application \" + applicationId + \n          \" submitted by user \" + user + \" to non-leaf queue: \" + queueName;\n      this.rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n    // Submit to the queue\n    try {\n      queue.submitApplication(applicationId, user, queueName);\n    } catch (AccessControlException ace) {\n      // Ignore the exception for recovered app as the app was previously accepted\n      if (!isAppRecovering) {\n        LOG.info(\"Failed to submit application \" + applicationId + \" to queue \"\n            + queueName + \" from user \" + user, ace);\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, ace.toString()));\n        return;\n      }\n    }\n    // update the metrics\n    queue.getMetrics().submitApp(user);\n    SchedulerApplication<FiCaSchedulerApp> application =\n        new SchedulerApplication<FiCaSchedulerApp>(queue, user);\n    applications.put(applicationId, application);\n    LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n        + \", in queue: \" + queueName);\n    if (isAppRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler()\n        .handle(new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getNode": "  public FiCaSchedulerNode getNode(NodeId nodeId) {\n    return nodes.get(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplication": "  private synchronized void doneApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationId);\n    if (application == null){\n      // The AppRemovedSchedulerEvent maybe sent on recovery for completed apps,\n      // ignore it.\n      LOG.warn(\"Couldn't find application \" + applicationId);\n      return;\n    }\n    CSQueue queue = (CSQueue) application.getQueue();\n    if (!(queue instanceof LeafQueue)) {\n      LOG.error(\"Cannot finish application \" + \"from non-leaf queue: \"\n          + queue.getQueueName());\n    } else {\n      queue.finishApplication(applicationId, application.getUser());\n    }\n    application.stop(finalState);\n    applications.remove(applicationId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" clusterResources: \" + clusterResource);\n    }\n\n    FiCaSchedulerNode node = getNode(nm.getNodeID());\n    \n    List<UpdatedContainerInfo> containerInfoList = nm.pullContainerUpdates();\n    List<ContainerStatus> newlyLaunchedContainers = new ArrayList<ContainerStatus>();\n    List<ContainerStatus> completedContainers = new ArrayList<ContainerStatus>();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    }\n    \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId = completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId), \n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Now node data structures are upto date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\"Node being looked for scheduling \" + nm\n        + \" availableResource: \" + node.getAvailableResource());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.resolveReservationQueueName": "  private synchronized String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID) {\n    CSQueue queue = getQueue(queueName);\n    // Check if the queue is a plan queue\n    if ((queue == null) || !(queue instanceof PlanQueue)) {\n      return queueName;\n    }\n    if (reservationID != null) {\n      String resQName = reservationID.toString();\n      queue = getQueue(resQName);\n      if (queue == null) {\n        String message =\n            \"Application \"\n                + applicationId\n                + \" submitted to a reservation which is not yet currently active: \"\n                + resQName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, message));\n        return null;\n      }\n      if (!queue.getParent().getQueueName().equals(queueName)) {\n        String message =\n            \"Application: \" + applicationId + \" submitted to a reservation \"\n                + resQName + \" which does not belong to the specified queue: \"\n                + queueName;\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppRejectedEvent(applicationId, message));\n        return null;\n      }\n      // use the reservation queue to run the app\n      queueName = resQName;\n    } else {\n      // use the default child queue of the plan for unreserved apps\n      queueName = queueName + ReservationConstants.DEFAULT_QUEUE_SUFFIX;\n    }\n    return queueName;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt": "  private synchronized void doneApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    LOG.info(\"Application Attempt \" + applicationAttemptId + \" is done.\" +\n        \" finalState=\" + rmAppAttemptFinalState);\n    \n    FiCaSchedulerApp attempt = getApplicationAttempt(applicationAttemptId);\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationAttemptId.getApplicationId());\n\n    if (application == null || attempt == null) {\n      LOG.info(\"Unknown application \" + applicationAttemptId + \" has completed!\");\n      return;\n    }\n\n    // Release all the allocated, acquired, running containers\n    for (RMContainer rmContainer : attempt.getLiveContainers()) {\n      if (keepContainers\n          && rmContainer.getState().equals(RMContainerState.RUNNING)) {\n        // do not kill the running container in the case of work-preserving AM\n        // restart.\n        LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n        continue;\n      }\n      completedContainer(\n        rmContainer,\n        SchedulerUtils.createAbnormalContainerStatus(\n          rmContainer.getContainerId(), SchedulerUtils.COMPLETED_APPLICATION),\n        RMContainerEventType.KILL);\n    }\n\n    // Release all reserved containers\n    for (RMContainer rmContainer : attempt.getReservedContainers()) {\n      completedContainer(\n        rmContainer,\n        SchedulerUtils.createAbnormalContainerStatus(\n          rmContainer.getContainerId(), \"Application Complete\"),\n        RMContainerEventType.KILL);\n    }\n\n    // Clean up pending requests, metrics etc.\n    attempt.stop(rmAppAttemptFinalState);\n\n    // Inform the queue\n    String queueName = attempt.getQueue().getQueueName();\n    CSQueue queue = queues.get(queueName);\n    if (!(queue instanceof LeafQueue)) {\n      LOG.error(\"Cannot finish application \" + \"from non-leaf queue: \"\n          + queueName);\n    } else {\n      queue.finishApplicationAttempt(attempt, queue.getQueueName());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeAndQueueResource": "  private synchronized void updateNodeAndQueueResource(RMNode nm, \n      ResourceOption resourceOption) {\n    updateNodeResource(nm, resourceOption);\n    root.updateClusterResource(clusterResource, new ResourceLimits(\n        clusterResource));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    CSQueue queue = (CSQueue) application.getQueue();\n\n    FiCaSchedulerApp attempt =\n        new FiCaSchedulerApp(applicationAttemptId, application.getUser(),\n          queue, queue.getActiveUsersManager(), rmContext);\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(application\n        .getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    queue.submitApplicationAttempt(attempt, application.getUser());\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user \" + application.getUser() + \" in queue \"\n        + queue.getQueueName());\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.removeNode": "  private synchronized void removeNode(RMNode nodeInfo) {\n    // update this node to node label manager\n    if (labelManager != null) {\n      labelManager.deactivateNode(nodeInfo.getNodeID());\n    }\n    \n    FiCaSchedulerNode node = nodes.get(nodeInfo.getNodeID());\n    if (node == null) {\n      return;\n    }\n    Resources.subtractFrom(clusterResource, node.getRMNode().getTotalCapability());\n    root.updateClusterResource(clusterResource, new ResourceLimits(\n        clusterResource));\n    int numNodes = numNodeManagers.decrementAndGet();\n\n    if (scheduleAsynchronously && numNodes == 0) {\n      asyncSchedulerThread.suspendSchedule();\n    }\n    \n    // Remove running containers\n    List<RMContainer> runningContainers = node.getRunningContainers();\n    for (RMContainer container : runningContainers) {\n      completedContainer(container, \n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(), \n              SchedulerUtils.LOST_CONTAINER), \n          RMContainerEventType.KILL);\n    }\n    \n    // Remove reservations, if any\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      completedContainer(reservedContainer, \n          SchedulerUtils.createAbnormalContainerStatus(\n              reservedContainer.getContainerId(), \n              SchedulerUtils.LOST_CONTAINER), \n          RMContainerEventType.KILL);\n    }\n\n    this.nodes.remove(nodeInfo.getNodeID());\n    updateMaximumAllocation(node, false);\n\n    LOG.info(\"Removed node \" + nodeInfo.getNodeAddress() + \n        \" clusterResource: \" + clusterResource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) throws Exception {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.activeUsersManager.deactivateApplication": "  synchronized public void deactivateApplication(\n      String user, ApplicationId applicationId) {\n    Set<ApplicationId> userApps = usersApplications.get(user);\n    if (userApps != null) {\n      if (userApps.remove(applicationId)) {\n        metrics.deactivateApp(user);\n      }\n      if (userApps.isEmpty()) {\n        usersApplications.remove(user);\n        --activeUsers;\n        metrics.decrActiveUsers();\n        LOG.debug(\"User \" + user + \" removed from activeUsers, currently: \" + \n            activeUsers);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.allocateResources": "  public void allocateResources(String user, int containers, Resource res,\n      boolean decrPending) {\n    allocatedContainers.incr(containers);\n    aggregateContainersAllocated.incr(containers);\n    allocatedMB.incr(res.getMemory() * containers);\n    allocatedVCores.incr(res.getVirtualCores() * containers);\n    if (decrPending) {\n      _decrPendingResources(containers, res);\n    }\n    QueueMetrics userMetrics = getUserMetrics(user);\n    if (userMetrics != null) {\n      userMetrics.allocateResources(user, containers, res, decrPending);\n    }\n    if (parent != null) {\n      parent.allocateResources(user, containers, res, decrPending);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics._decrPendingResources": "  private void _decrPendingResources(int containers, Resource res) {\n    pendingContainers.decr(containers);\n    pendingMB.decr(res.getMemory() * containers);\n    pendingVCores.decr(res.getVirtualCores() * containers);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.getUserMetrics": "  public synchronized QueueMetrics getUserMetrics(String userName) {\n    if (users == null) {\n      return null;\n    }\n    QueueMetrics metrics = users.get(userName);\n    if (metrics == null) {\n      metrics = new QueueMetrics(metricsSystem, queueName, null, false, conf);\n      users.put(userName, metrics);\n      metricsSystem.register(\n          sourceName(queueName).append(\",user=\").append(userName).toString(),\n          \"Metrics for user '\"+ userName +\"' in queue '\"+ queueName +\"'\",\n          metrics.tag(QUEUE_INFO, queueName).tag(USER_INFO, userName));\n    }\n    return metrics;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.queue.getMetrics": "  QueueMetrics getMetrics();\n\n  /**\n   * Get queue information\n   * @param includeChildQueues include child queues?\n   * @param recursive recursively get child queue information?\n   * @return queue information\n   */\n  QueueInfo getQueueInfo(boolean includeChildQueues, boolean recursive);\n  \n  /**\n   * Get queue ACLs for given <code>user</code>.\n   * @param user username\n   * @return queue ACLs for user\n   */\n  List<QueueUserACLInfo> getQueueUserAclInfo(UserGroupInformation user);\n\n  boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  public ActiveUsersManager getActiveUsersManager();\n\n  /**\n   * Recover the state of the queue for a given container.\n   * @param clusterResource the resource of the cluster\n   * @param schedulerAttempt the application for which the container was allocated\n   * @param rmContainer the container that was recovered.\n   */\n  public void recoverContainer(Resource clusterResource,\n      SchedulerApplicationAttempt schedulerAttempt, RMContainer rmContainer);\n  \n  /**\n   * Get labels can be accessed of this queue\n   * labels={*}, means this queue can access any label",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.runAppAttempt": "  public void runAppAttempt(ApplicationId appId, String user) {\n    runBuckets.add(appId, System.currentTimeMillis());\n    appsRunning.incr();\n    appsPending.decr();\n    QueueMetrics userMetrics = getUserMetrics(user);\n    if (userMetrics != null) {\n      userMetrics.runAppAttempt(appId, user);\n    }\n    if (parent != null) {\n      parent.runAppAttempt(appId, user);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getType": "  public NodeType getType() {\n    return type;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getSkipped": "  public boolean getSkipped() {\n    return skipped;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getResource": "  public Resource getResource() {\n    return resource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getExcessReservation": "  public RMContainer getExcessReservation() {\n    return excessReservation;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.assignContainers": "  public CSAssignment assignContainers(Resource clusterResource,\n      FiCaSchedulerNode node, ResourceLimits resourceLimits);\n  \n  /**\n   * A container assigned to the queue has completed.\n   * @param clusterResource the resource of the cluster\n   * @param application application to which the container was assigned\n   * @param node node on which the container completed\n   * @param container completed container, \n   *                  <code>null</code> if it was just a reservation\n   * @param containerStatus <code>ContainerStatus</code> for the completed \n   *                        container\n   * @param childQueue <code>CSQueue</code> to reinsert in childQueues \n   * @param event event to be sent to the container\n   * @param sortQueues indicates whether it should re-sort the queues\n   */\n  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   * @param resourceLimits the current ResourceLimits\n   */\n  public void updateClusterResource(Resource clusterResource,\n      ResourceLimits resourceLimits);\n  \n  /**\n   * Get the {@link ActiveUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getApplication": "  public FiCaSchedulerApp getApplication() {\n    return application;\n  }"
        },
        "bug_report": {
            "Title": "Missing NullPointer check in AppSchedulingInfo causes RM to die ",
            "Description": "In AppSchedulingInfo.java the method checkForDeactivation() has these 2 consecutive lines:\n{code}\nResourceRequest request = getResourceRequest(priority, ResourceRequest.ANY);\nif (request.getNumContainers() > 0) {\n{code}\nthe first line calls getResourceRequest and it can return null.\n{code}\nsynchronized public ResourceRequest getResourceRequest(\nPriority priority, String resourceName) {\n    Map<String, ResourceRequest> nodeRequests = requests.get(priority);\n    return  (nodeRequests == null) ? {color:red} null : nodeRequests.get(resourceName);\n}\n{code}\nThe second line dereferences the pointer directly without a check.\nIf the pointer is null, the RM dies. \n\n{quote}2015-03-17 14:14:04,757 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.checkForDeactivation(AppSchedulingInfo.java:383)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.decrementOutstanding(AppSchedulingInfo.java:375)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateOffSwitch(AppSchedulingInfo.java:360)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:270)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate(FiCaSchedulerApp.java:142)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1559)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignOffSwitchContainers(LeafQueue.java:1384)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:1263)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:816)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:588)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:449)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1017)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1059)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:114)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:739)\n        at java.lang.Thread.run(Thread.java:722)\n{color:red} *2015-03-17 14:14:04,758 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Exiting, bbye..*{color} {quote}"
        }
    },
    {
        "filename": "YARN-945.json",
        "creation_time": "2013-07-19T22:59:06.000+0000",
        "stack_trace": "```\norg.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN]\n   at org.apache.hadoop.ipc.Server$Connection.initializeAuthContext(Server.java:1531)\n   at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1482)\n   at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:788)\n   at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:587)\n   at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:562)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.initializeAuthContext": "    private AuthProtocol initializeAuthContext(int authType)\n        throws IOException, InterruptedException {\n      AuthProtocol authProtocol = AuthProtocol.valueOf(authType);\n      if (authProtocol == null) {\n        IOException ioe = new IpcException(\"Unknown auth protocol:\" + authType);\n        doSaslReply(ioe);\n        throw ioe;        \n      }\n      boolean isSimpleEnabled = enabledAuthMethods.contains(AuthMethod.SIMPLE);\n      switch (authProtocol) {\n        case NONE: {\n          // don't reply if client is simple and server is insecure\n          if (!isSimpleEnabled) {\n            IOException ioe = new AccessControlException(\n                \"SIMPLE authentication is not enabled.\"\n                    + \"  Available:\" + enabledAuthMethods);\n            doSaslReply(ioe);\n            throw ioe;\n          }\n          break;\n        }\n        case SASL: {\n          // switch to simple hack, but don't switch if other auths are\n          // supported, ex. tokens\n          if (isSimpleEnabled && enabledAuthMethods.size() == 1) {\n            authProtocol = AuthProtocol.NONE;\n            skipInitialSaslHandshake = true;\n            doSaslReply(buildSaslResponse(SaslState.SUCCESS, null));\n          }\n          // else wait for a negotiate or initiate\n          break;\n        }\n      }\n      return authProtocol;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doSaslReply": "    private void doSaslReply(Exception ioe) throws IOException {\n      setupResponse(authFailedResponse, authFailedCall,\n          RpcStatusProto.FATAL, RpcErrorCodeProto.FATAL_UNAUTHORIZED,\n          null, ioe.getClass().getName(), ioe.getLocalizedMessage());\n      responder.doRespond(authFailedCall);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.valueOf": "    static AuthProtocol valueOf(int callId) {\n      for (AuthProtocol authType : AuthProtocol.values()) {\n        if (authType.callId == callId) {\n          return authType;\n        }\n      }\n      return null;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.buildSaslResponse": "    private RpcSaslProto buildSaslResponse(SaslState state, byte[] replyToken) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Will send \" + state + \" token of size \"\n            + ((replyToken != null) ? replyToken.length : null)\n            + \" from saslServer.\");\n      }\n      RpcSaslProto.Builder response = RpcSaslProto.newBuilder();\n      response.setState(state);\n      if (replyToken != null) {\n        response.setToken(ByteString.copyFrom(replyToken));\n      }\n      return response.build();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.readAndProcess": "    public int readAndProcess() throws IOException, InterruptedException {\n      while (true) {\n        /* Read at most one RPC. If the header is not read completely yet\n         * then iterate until we read first RPC or until there is no data left.\n         */    \n        int count = -1;\n        if (dataLengthBuffer.remaining() > 0) {\n          count = channelRead(channel, dataLengthBuffer);       \n          if (count < 0 || dataLengthBuffer.remaining() > 0) \n            return count;\n        }\n        \n        if (!connectionHeaderRead) {\n          //Every connection is expected to send the header.\n          if (connectionHeaderBuf == null) {\n            connectionHeaderBuf = ByteBuffer.allocate(3);\n          }\n          count = channelRead(channel, connectionHeaderBuf);\n          if (count < 0 || connectionHeaderBuf.remaining() > 0) {\n            return count;\n          }\n          int version = connectionHeaderBuf.get(0);\n          // TODO we should add handler for service class later\n          this.setServiceClass(connectionHeaderBuf.get(1));\n          dataLengthBuffer.flip();\n          \n          // Check if it looks like the user is hitting an IPC port\n          // with an HTTP GET - this is a common error, so we can\n          // send back a simple string indicating as much.\n          if (HTTP_GET_BYTES.equals(dataLengthBuffer)) {\n            setupHttpRequestOnIpcPortResponse();\n            return -1;\n          }\n          \n          if (!RpcConstants.HEADER.equals(dataLengthBuffer)\n              || version != CURRENT_VERSION) {\n            //Warning is ok since this is not supposed to happen.\n            LOG.warn(\"Incorrect header or version mismatch from \" + \n                     hostAddress + \":\" + remotePort +\n                     \" got version \" + version + \n                     \" expected version \" + CURRENT_VERSION);\n            setupBadVersionResponse(version);\n            return -1;\n          }\n          \n          // this may switch us into SIMPLE\n          authProtocol = initializeAuthContext(connectionHeaderBuf.get(2));          \n          \n          dataLengthBuffer.clear();\n          connectionHeaderBuf = null;\n          connectionHeaderRead = true;\n          continue;\n        }\n        \n        if (data == null) {\n          dataLengthBuffer.flip();\n          dataLength = dataLengthBuffer.getInt();\n          if ((dataLength == RpcConstants.PING_CALL_ID) && (!useWrap)) {\n            // covers the !useSasl too\n            dataLengthBuffer.clear();\n            return 0; // ping message\n          }\n          checkDataLength(dataLength);\n          data = ByteBuffer.allocate(dataLength);\n        }\n        \n        count = channelRead(channel, data);\n        \n        if (data.remaining() == 0) {\n          dataLengthBuffer.clear();\n          data.flip();\n          boolean isHeaderRead = connectionContextRead;\n          processRpcRequestPacket(data.array());\n          data = null;\n          if (!isHeaderRead) {\n            continue;\n          }\n        } \n        return count;\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.channelRead": "  private int channelRead(ReadableByteChannel channel, \n                          ByteBuffer buffer) throws IOException {\n    \n    int count = (buffer.remaining() <= NIO_BUFFER_LIMIT) ?\n                channel.read(buffer) : channelIO(channel, null, buffer);\n    if (count > 0) {\n      rpcMetrics.incrReceivedBytes(count);\n    }\n    return count;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupHttpRequestOnIpcPortResponse": "    private void setupHttpRequestOnIpcPortResponse() throws IOException {\n      Call fakeCall = new Call(0, RpcConstants.INVALID_RETRY_COUNT, null, this);\n      fakeCall.setResponse(ByteBuffer.wrap(\n          RECEIVED_HTTP_REQ_RESPONSE.getBytes()));\n      responder.doRespond(fakeCall);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.get": "  public static Server get() {\n    return SERVER.get();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.checkDataLength": "    private void checkDataLength(int dataLength) throws IOException {\n      if (dataLength < 0) {\n        String error = \"Unexpected data length \" + dataLength +\n                       \"!! from \" + getHostAddress();\n        LOG.warn(error);\n        throw new IOException(error);\n      } else if (dataLength > maxDataLength) {\n        String error = \"Requested data length \" + dataLength +\n              \" is longer than maximum configured RPC length \" + \n            maxDataLength + \".  RPC came from \" + getHostAddress();\n        LOG.warn(error);\n        throw new IOException(error);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.processRpcRequestPacket": "    private void processRpcRequestPacket(byte[] buf) throws IOException,\n        InterruptedException {\n      if (saslContextEstablished && useWrap) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(\"Have read input token of size \" + buf.length\n              + \" for processing by saslServer.unwrap()\");        \n        final byte[] plaintextData = saslServer.unwrap(buf, 0, buf.length);\n        // loops over decoded data and calls processOneRpc\n        unwrapPacketAndProcessRpcs(plaintextData);\n      } else {\n        processOneRpc(buf);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupBadVersionResponse": "    private void setupBadVersionResponse(int clientVersion) throws IOException {\n      String errMsg = \"Server IPC version \" + CURRENT_VERSION +\n      \" cannot communicate with client version \" + clientVersion;\n      ByteArrayOutputStream buffer = new ByteArrayOutputStream();\n      \n      if (clientVersion >= 9) {\n        // Versions >>9  understand the normal response\n        Call fakeCall = new Call(-1, RpcConstants.INVALID_RETRY_COUNT, null,\n            this);\n        setupResponse(buffer, fakeCall, \n            RpcStatusProto.FATAL, RpcErrorCodeProto.FATAL_VERSION_MISMATCH,\n            null, VersionMismatch.class.getName(), errMsg);\n        responder.doRespond(fakeCall);\n      } else if (clientVersion >= 3) {\n        Call fakeCall = new Call(-1, RpcConstants.INVALID_RETRY_COUNT, null,\n            this);\n        // Versions 3 to 8 use older response\n        setupResponseOldVersionFatal(buffer, fakeCall,\n            null, VersionMismatch.class.getName(), errMsg);\n\n        responder.doRespond(fakeCall);\n      } else if (clientVersion == 2) { // Hadoop 0.18.3\n        Call fakeCall = new Call(0, RpcConstants.INVALID_RETRY_COUNT, null,\n            this);\n        DataOutputStream out = new DataOutputStream(buffer);\n        out.writeInt(0); // call ID\n        out.writeBoolean(true); // error\n        WritableUtils.writeString(out, VersionMismatch.class.getName());\n        WritableUtils.writeString(out, errMsg);\n        fakeCall.setResponse(ByteBuffer.wrap(buffer.toByteArray()));\n        \n        responder.doRespond(fakeCall);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setServiceClass": "    public void setServiceClass(int serviceClass) {\n      this.serviceClass = serviceClass;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRead": "    void doRead(SelectionKey key) throws InterruptedException {\n      int count = 0;\n      Connection c = (Connection)key.attachment();\n      if (c == null) {\n        return;  \n      }\n      c.setLastContact(Time.now());\n      \n      try {\n        count = c.readAndProcess();\n      } catch (InterruptedException ieo) {\n        LOG.info(getName() + \": readAndProcess caught InterruptedException\", ieo);\n        throw ieo;\n      } catch (Exception e) {\n        // log stack trace for \"interesting\" exceptions not sent to client\n        LOG.info(getName() + \": readAndProcess from client \" +\n            c.getHostAddress() + \" threw exception [\" + e + \"]\",\n            (e instanceof WrappedRpcServerException) ? null : e);\n        count = -1; //so that the (count < 0) block is executed\n      }\n      if (count < 0) {\n        if (LOG.isDebugEnabled())\n          LOG.debug(getName() + \": disconnecting client \" + \n                    c + \". Number of active connections: \"+\n                    numConnections);\n        closeConnection(c);\n        c = null;\n      }\n      else {\n        c.setLastContact(Time.now());\n      }\n    }   ",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getHostAddress": "    public String getHostAddress() {\n      return hostAddress;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setLastContact": "    public void setLastContact(long lastContact) {\n      this.lastContact = lastContact;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeConnection": "  private void closeConnection(Connection connection) {\n    synchronized (connectionList) {\n      if (connectionList.remove(connection))\n        numConnections--;\n    }\n    try {\n      connection.close();\n    } catch (IOException e) {\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRunLoop": "    private void doRunLoop() {\n      long lastPurgeTime = 0;   // last check for old calls.\n\n      while (running) {\n        try {\n          waitPending();     // If a channel is being registered, wait.\n          writeSelector.select(PURGE_INTERVAL);\n          Iterator<SelectionKey> iter = writeSelector.selectedKeys().iterator();\n          while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            iter.remove();\n            try {\n              if (key.isValid() && key.isWritable()) {\n                  doAsyncWrite(key);\n              }\n            } catch (IOException e) {\n              LOG.info(getName() + \": doAsyncWrite threw exception \" + e);\n            }\n          }\n          long now = Time.now();\n          if (now < lastPurgeTime + PURGE_INTERVAL) {\n            continue;\n          }\n          lastPurgeTime = now;\n          //\n          // If there were some calls that have not been sent out for a\n          // long time, discard them.\n          //\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"Checking for old call responses.\");\n          }\n          ArrayList<Call> calls;\n          \n          // get the list of channels from list of keys.\n          synchronized (writeSelector.keys()) {\n            calls = new ArrayList<Call>(writeSelector.keys().size());\n            iter = writeSelector.keys().iterator();\n            while (iter.hasNext()) {\n              SelectionKey key = iter.next();\n              Call call = (Call)key.attachment();\n              if (call != null && key.channel() == call.connection.channel) { \n                calls.add(call);\n              }\n            }\n          }\n          \n          for(Call call : calls) {\n            try {\n              doPurge(call, now);\n            } catch (IOException e) {\n              LOG.warn(\"Error in purging old calls \" + e);\n            }\n          }\n        } catch (OutOfMemoryError e) {\n          //\n          // we can run out of memory if we have too many threads\n          // log the event and sleep for a minute and give\n          // some thread(s) a chance to finish\n          //\n          LOG.warn(\"Out of Memory in server select\", e);\n          try { Thread.sleep(60000); } catch (Exception ie) {}\n        } catch (Exception e) {\n          LOG.warn(\"Exception in Responder\", e);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.waitPending": "    private synchronized void waitPending() throws InterruptedException {\n      while (pending > 0) {\n        wait();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doPurge": "    private void doPurge(Call call, long now) throws IOException {\n      LinkedList<Call> responseQueue = call.connection.responseQueue;\n      synchronized (responseQueue) {\n        Iterator<Call> iter = responseQueue.listIterator(0);\n        while (iter.hasNext()) {\n          call = iter.next();\n          if (now > call.timestamp + PURGE_INTERVAL) {\n            closeConnection(call.connection);\n            break;\n          }\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doAsyncWrite": "    private void doAsyncWrite(SelectionKey key) throws IOException {\n      Call call = (Call)key.attachment();\n      if (call == null) {\n        return;\n      }\n      if (key.channel() != call.connection.channel) {\n        throw new IOException(\"doAsyncWrite: bad channel\");\n      }\n\n      synchronized(call.connection.responseQueue) {\n        if (processResponse(call.connection.responseQueue, false)) {\n          try {\n            key.interestOps(0);\n          } catch (CancelledKeyException e) {\n            /* The Listener/reader might have closed the socket.\n             * We don't explicitly cancel the key, so not sure if this will\n             * ever fire.\n             * This warning could be removed.\n             */\n            LOG.warn(\"Exception while changing ops : \" + e);\n          }\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.run": "                     public Writable run() throws Exception {\n                       // make the call\n                       return call(call.rpcKind, call.connection.protocolName, \n                                   call.rpcRequest, call.timestamp);\n\n                     }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupResponse": "  private void setupResponse(ByteArrayOutputStream responseBuf,\n                             Call call, RpcStatusProto status, RpcErrorCodeProto erCode,\n                             Writable rv, String errorClass, String error) \n  throws IOException {\n    responseBuf.reset();\n    DataOutputStream out = new DataOutputStream(responseBuf);\n    RpcResponseHeaderProto.Builder headerBuilder =  \n        RpcResponseHeaderProto.newBuilder();\n    headerBuilder.setClientId(ByteString.copyFrom(call.clientId));\n    headerBuilder.setCallId(call.callId);\n    headerBuilder.setRetryCount(call.retryCount);\n    headerBuilder.setStatus(status);\n    headerBuilder.setServerIpcVersionNum(CURRENT_VERSION);\n\n    if (status == RpcStatusProto.SUCCESS) {\n      RpcResponseHeaderProto header = headerBuilder.build();\n      final int headerLen = header.getSerializedSize();\n      int fullLength  = CodedOutputStream.computeRawVarint32Size(headerLen) +\n          headerLen;\n      try {\n        if (rv instanceof ProtobufRpcEngine.RpcWrapper) {\n          ProtobufRpcEngine.RpcWrapper resWrapper = \n              (ProtobufRpcEngine.RpcWrapper) rv;\n          fullLength += resWrapper.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          rv.write(out);\n        } else { // Have to serialize to buffer to get len\n          final DataOutputBuffer buf = new DataOutputBuffer();\n          rv.write(buf);\n          byte[] data = buf.getData();\n          fullLength += buf.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          out.write(data, 0, buf.getLength());\n        }\n      } catch (Throwable t) {\n        LOG.warn(\"Error serializing call response for call \" + call, t);\n        // Call back to same function - this is OK since the\n        // buffer is reset at the top, and since status is changed\n        // to ERROR it won't infinite loop.\n        setupResponse(responseBuf, call, RpcStatusProto.ERROR,\n            RpcErrorCodeProto.ERROR_SERIALIZING_RESPONSE,\n            null, t.getClass().getName(),\n            StringUtils.stringifyException(t));\n        return;\n      }\n    } else { // Rpc Failure\n      headerBuilder.setExceptionClassName(errorClass);\n      headerBuilder.setErrorMsg(error);\n      headerBuilder.setErrorDetail(erCode);\n      RpcResponseHeaderProto header = headerBuilder.build();\n      int headerLen = header.getSerializedSize();\n      final int fullLength  = \n          CodedOutputStream.computeRawVarint32Size(headerLen) + headerLen;\n      out.writeInt(fullLength);\n      header.writeDelimitedTo(out);\n    }\n    if (call.connection.useWrap) {\n      wrapWithSasl(responseBuf, call);\n    }\n    call.setResponse(ByteBuffer.wrap(responseBuf.toByteArray()));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.close": "    private synchronized void close() throws IOException {\n      disposeSasl();\n      data = null;\n      dataLengthBuffer = null;\n      if (!channel.isOpen())\n        return;\n      try {socket.shutdownOutput();} catch(Exception e) {\n        LOG.debug(\"Ignoring socket shutdown exception\", e);\n      }\n      if (channel.isOpen()) {\n        try {channel.close();} catch(Exception e) {}\n      }\n      try {socket.close();} catch(Exception e) {}\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRespond": "    void doRespond(Call call) throws IOException {\n      synchronized (call.connection.responseQueue) {\n        call.connection.responseQueue.addLast(call);\n        if (call.connection.responseQueue.size() == 1) {\n          processResponse(call.connection.responseQueue, true);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.cleanupConnections": "    private void cleanupConnections(boolean force) {\n      if (force || numConnections > thresholdIdleConnections) {\n        long currentTime = Time.now();\n        if (!force && (currentTime - lastCleanupRunTime) < cleanupInterval) {\n          return;\n        }\n        int start = 0;\n        int end = numConnections - 1;\n        if (!force) {\n          start = rand.nextInt() % numConnections;\n          end = rand.nextInt() % numConnections;\n          int temp;\n          if (end < start) {\n            temp = start;\n            start = end;\n            end = temp;\n          }\n        }\n        int i = start;\n        int numNuked = 0;\n        while (i <= end) {\n          Connection c;\n          synchronized (connectionList) {\n            try {\n              c = connectionList.get(i);\n            } catch (Exception e) {return;}\n          }\n          if (c.timedOut(currentTime)) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(getName() + \": disconnecting client \" + c.getHostAddress());\n            closeConnection(c);\n            numNuked++;\n            end--;\n            c = null;\n            if (!force && numNuked == maxConnectionsToNuke) break;\n          }\n          else i++;\n        }\n        lastCleanupRunTime = Time.now();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeCurrentConnection": "    private void closeCurrentConnection(SelectionKey key, Throwable e) {\n      if (key != null) {\n        Connection c = (Connection)key.attachment();\n        if (c != null) {\n          if (LOG.isDebugEnabled())\n            LOG.debug(getName() + \": disconnecting client \" + c.getHostAddress());\n          closeConnection(c);\n          c = null;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doAccept": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c = null;\n      ServerSocketChannel server = (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel = server.accept()) != null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        \n        Reader reader = getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey = reader.registerChannel(channel);\n          c = new Connection(readKey, channel, Time.now());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getRpcErrorCodeProto": "    public RpcErrorCodeProto getRpcErrorCodeProto() {\n      return errCode;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.call": "  public abstract Writable call(RPC.RpcKind rpcKind, String protocol,\n      Writable param, long receiveTime) throws Exception;\n  \n  /**\n   * Authorize the incoming client connection.\n   * \n   * @param user client user\n   * @param protocolName - the protocol\n   * @param addr InetAddress of incoming connection\n   * @throws AuthorizationException when the client isn't authorized to talk the protocol\n   */\n  private void authorize(UserGroupInformation user, String protocolName,\n      InetAddress addr) throws AuthorizationException {\n    if (authorize) {\n      if (protocolName == null) {\n        throw new AuthorizationException(\"Null protocol not authorized\");\n      }\n      Class<?> protocol = null;\n      try {\n        protocol = getProtocolClass(protocolName, getConf());\n      } catch (ClassNotFoundException cfne) {\n        throw new AuthorizationException(\"Unknown protocol: \" + \n                                         protocolName);\n      }\n      serviceAuthorizationManager.authorize(user, protocol, getConf(), addr);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getSelector": "    synchronized Selector getSelector() { return selector; }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.isTerse": "    boolean isTerse(Class<?> t) {\n      return terseExceptions.contains(t.toString());\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.toString": "    public String toString() {\n      return getHostAddress() + \":\" + remotePort; \n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcServerException.getRpcStatusProto": "  public RpcStatusProto getRpcStatusProto() {\n    return RpcStatusProto.ERROR;\n  }"
        },
        "bug_report": {
            "Title": "AM register failing after AMRMToken",
            "Description": "509 2013-07-19 15:53:55,569 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54313: readAndProcess from client 127.0.0.1       threw exception [org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN]]\n510 org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN]\n511   at org.apache.hadoop.ipc.Server$Connection.initializeAuthContext(Server.java:1531)\n512   at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1482)\n513   at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:788)\n514   at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:587)\n515   at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:562)\n"
        }
    },
    {
        "filename": "YARN-6072.json",
        "creation_time": "2017-01-08T09:21:12.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls(AdminService.java:569)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls(AdminService.java:552)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:707)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n\norg.apache.hadoop.ha.ServiceFailedException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:712)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Error on refreshAll during transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:311)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        ... 4 more\n\nCaused by: org.apache.hadoop.ha.ServiceFailedException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:712)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        ... 5 more\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls": "  private synchronized void refreshServiceAcls(Configuration configuration,\n      PolicyProvider policyProvider) {\n    this.server.refreshServiceAclWithLoadedConfiguration(configuration,\n        policyProvider);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls": "  private UserGroupInformation checkAcls(String method) throws YarnException {\n    try {\n      return checkAccess(method);\n    } catch (IOException ioe) {\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshActiveServicesAcls": "  private void refreshActiveServicesAcls() throws IOException, YarnException  {\n    PolicyProvider policyProvider = RMPolicyProvider.getInstance();\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.HADOOP_POLICY_CONFIGURATION_FILE);\n    rmContext.getClientRMService().refreshServiceAcls(conf, policyProvider);\n    rmContext.getApplicationMasterService().refreshServiceAcls(\n        conf, policyProvider);\n    rmContext.getResourceTrackerService().refreshServiceAcls(\n        conf, policyProvider);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.getConfiguration": "  private synchronized Configuration getConfiguration(Configuration conf,\n      String... confFileNames) throws YarnException, IOException {\n    for (String confFileName : confFileNames) {\n      InputStream confFileInputStream = this.rmContext.getConfigurationProvider()\n          .getConfigurationInputStream(conf, confFileName);\n      if (confFileInputStream != null) {\n        conf.addResource(confFileInputStream);\n      }\n    }\n    return conf;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkRMStatus": "  private void checkRMStatus(String user, String operation, String msg)\n      throws StandbyException {\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user, operation, \"\",\n          \"AdminService\", \"ResourceManager is not active. Can not \" + msg);\n      throwStandbyException();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll": "  void refreshAll() throws ServiceFailedException {\n    try {\n      checkAcls(\"refreshAll\");\n      refreshQueues();\n      refreshNodes();\n      refreshSuperUserGroupsConfiguration();\n      refreshUserToGroupsMappings();\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls();\n      }\n      refreshClusterMaxPriority();\n    } catch (Exception ex) {\n      throw new ServiceFailedException(ex.getMessage());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshSuperUserGroupsConfiguration": "  private void refreshSuperUserGroupsConfiguration()\n      throws IOException, YarnException {\n    // Accept hadoop common configs in core-site.xml as well as RM specific\n    // configurations in yarn-site.xml\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE,\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    RMServerUtils.processRMProxyUsersConf(conf);\n    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshUserToGroupsMappings": "  private void refreshUserToGroupsMappings() throws IOException, YarnException {\n    Groups.getUserToGroupsMappingService(\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE)).refresh();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshClusterMaxPriority": "  private void refreshClusterMaxPriority() throws IOException, YarnException {\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n\n    rmContext.getScheduler().setClusterMaxPriority(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshQueues": "  private void refreshQueues() throws IOException, YarnException {\n    rmContext.getScheduler().reinitialize(getConfig(), this.rmContext);\n    // refresh the reservation system\n    ReservationSystem rSystem = rmContext.getReservationSystem();\n    if (rSystem != null) {\n      rSystem.reinitialize(getConfig(), rmContext);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshNodes": "  private void refreshNodes() throws IOException, YarnException {\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    rmContext.getNodesListManager().refreshNodes(conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive": "  public synchronized void transitionToActive(\n      HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {\n    // call refreshAdminAcls before HA state transition\n    // for the case that adminAcls have been updated in previous active RM\n    try {\n      refreshAdminAcls(false);\n    } catch (YarnException ex) {\n      throw new ServiceFailedException(\"Can not execute refreshAdminAcls\", ex);\n    }\n\n    UserGroupInformation user = checkAccess(\"transitionToActive\");\n    checkHaStateChange(reqInfo);\n\n    try {\n      // call all refresh*s for active RM to get the updated configurations.\n      refreshAll();\n    } catch (Exception e) {\n      LOG.error(\"RefreshAll failed so firing fatal event\", e);\n      rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMFatalEvent(RMFatalEventType.TRANSITION_TO_ACTIVE_FAILED,\n                  e));\n      throw new ServiceFailedException(\n          \"Error on refreshAll during transition to Active\", e);\n    }\n\n    try {\n      rm.transitionToActive();\n    } catch (Exception e) {\n      RMAuditLogger.logFailure(user.getShortUserName(), \"transitionToActive\",\n          \"\", \"RM\",\n          \"Exception transitioning to active\");\n      throw new ServiceFailedException(\n          \"Error when transitioning to Active mode\", e);\n    }\n\n    RMAuditLogger.logSuccess(user.getShortUserName(), \"transitionToActive\",\n        \"RM\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkHaStateChange": "  private void checkHaStateChange(StateChangeRequestInfo req)\n      throws AccessControlException {\n    switch (req.getSource()) {\n      case REQUEST_BY_USER:\n        if (autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Manual failover for this ResourceManager is disallowed, \" +\n                  \"because automatic failover is enabled.\");\n        }\n        break;\n      case REQUEST_BY_USER_FORCED:\n        if (autoFailoverEnabled) {\n          LOG.warn(\"Allowing manual failover from \" +\n              org.apache.hadoop.ipc.Server.getRemoteAddress() +\n              \" even though automatic failover is enabled, because the user \" +\n              \"specified the force flag\");\n        }\n        break;\n      case REQUEST_BY_ZKFC:\n        if (!autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Request from ZK failover controller at \" +\n                  org.apache.hadoop.ipc.Server.getRemoteAddress() + \" denied \" +\n                  \"since automatic failover is not enabled\");\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess": "  private UserGroupInformation checkAccess(String method) throws IOException {\n    return RMServerUtils.verifyAdminAccess(authorizer, method, LOG);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls": "  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    final String operation = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(operation);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), operation, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    authorizer.setAdmins(getAdminAclList(conf), daemonUser);\n    RMAuditLogger.logSuccess(user.getShortUserName(), operation,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive": "  public void becomeActive() throws ServiceFailedException {\n    cancelDisconnectTimer();\n\n    try {\n      rmContext.getRMAdminService().transitionToActive(req);\n    } catch (Exception e) {\n      throw new ServiceFailedException(\"RM could not transition to Active\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.cancelDisconnectTimer": "  private void cancelDisconnectTimer() {\n    synchronized (zkDisconnectLock) {\n      if (zkDisconnectTimer != null) {\n        zkDisconnectTimer.cancel();\n        zkDisconnectTimer = null;\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeActive": "  private boolean becomeActive() {\n    assert wantToBeInElection;\n    if (state == State.ACTIVE) {\n      // already active\n      return true;\n    }\n    try {\n      Stat oldBreadcrumbStat = fenceOldActive();\n      writeBreadCrumbNode(oldBreadcrumbStat);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming active for \" + this);\n      }\n      appClient.becomeActive();\n      state = State.ACTIVE;\n      return true;\n    } catch (Exception e) {\n      LOG.warn(\"Exception handling the winning of election\", e);\n      // Caller will handle quitting and rejoining the election.\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.writeBreadCrumbNode": "  private void writeBreadCrumbNode(Stat oldBreadcrumbStat)\n      throws KeeperException, InterruptedException {\n    Preconditions.checkState(appData != null, \"no appdata\");\n    \n    LOG.info(\"Writing znode \" + zkBreadCrumbPath +\n        \" to indicate that the local node is the most recent active...\");\n    if (oldBreadcrumbStat == null) {\n      // No previous active, just create the node\n      createWithRetries(zkBreadCrumbPath, appData, zkAcl,\n        CreateMode.PERSISTENT);\n    } else {\n      // There was a previous active, update the node\n      setDataWithRetries(zkBreadCrumbPath, appData, oldBreadcrumbStat.getVersion());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fenceOldActive": "  private Stat fenceOldActive() throws InterruptedException, KeeperException {\n    final Stat stat = new Stat();\n    byte[] data;\n    LOG.info(\"Checking for any old active which needs to be fenced...\");\n    try {\n      data = zkDoWithRetries(new ZKAction<byte[]>() {\n        @Override\n        public byte[] run() throws KeeperException, InterruptedException {\n          return zkClient.getData(zkBreadCrumbPath, false, stat);\n        }\n      });\n    } catch (KeeperException ke) {\n      if (isNodeDoesNotExist(ke.code())) {\n        LOG.info(\"No old node to fence\");\n        return null;\n      }\n      \n      // If we failed to read for any other reason, then likely we lost\n      // our session, or we don't have permissions, etc. In any case,\n      // we probably shouldn't become active, and failing the whole\n      // thing is the best bet.\n      throw ke;\n    }\n\n    LOG.info(\"Old node exists: \" + StringUtils.byteToHexString(data));\n    if (Arrays.equals(data, appData)) {\n      LOG.info(\"But old node has our own data, so don't need to fence it.\");\n    } else {\n      appClient.fenceOldActive(data);\n    }\n    return stat;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.processResult": "  public synchronized void processResult(int rc, String path, Object ctx,\n      Stat stat) {\n    if (isStaleClient(ctx)) return;\n    monitorLockNodePending = false;\n\n    assert wantToBeInElection :\n        \"Got a StatNode result after quitting election\";\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"StatNode result: \" + rc + \" for path: \" + path\n          + \" connectionState: \" + zkConnectionState + \" for \" + this);\n    }\n\n    Code code = Code.get(rc);\n    if (isSuccess(code)) {\n      // the following owner check completes verification in case the lock znode\n      // creation was retried\n      if (stat.getEphemeralOwner() == zkClient.getSessionId()) {\n        // we own the lock znode. so we are the leader\n        if (!becomeActive()) {\n          reJoinElectionAfterFailureToBecomeActive();\n        }\n      } else {\n        // we dont own the lock znode. so we are a standby.\n        becomeStandby();\n      }\n      // the watch set by us will notify about changes\n      return;\n    }\n\n    if (isNodeDoesNotExist(code)) {\n      // the lock znode disappeared before we started monitoring it\n      enterNeutralMode();\n      joinElectionInternal();\n      return;\n    }\n\n    String errorMessage = \"Received stat error from Zookeeper. code:\"\n        + code.toString();\n    LOG.debug(errorMessage);\n\n    if (shouldRetry(code)) {\n      if (statRetryCount < maxRetryNum) {\n        ++statRetryCount;\n        monitorLockNodeAsync();\n        return;\n      }\n      errorMessage = errorMessage\n          + \". Not retrying further znode monitoring connection errors.\";\n    } else if (isSessionExpired(code)) {\n      // This isn't fatal - the client Watcher will re-join the election\n      LOG.warn(\"Lock monitoring failed because session was lost\");\n      return;\n    }\n\n    fatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code) {\n    return code == Code.CONNECTIONLOSS || code == Code.OPERATIONTIMEOUT;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.joinElectionInternal": "  private void joinElectionInternal() {\n    Preconditions.checkState(appData != null,\n        \"trying to join election without any app data\");\n    if (zkClient == null) {\n      if (!reEstablishSession()) {\n        fatalError(\"Failed to reEstablish connection with ZooKeeper\");\n        return;\n      }\n    }\n\n    createRetryCount = 0;\n    wantToBeInElection = true;\n    createLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createLockNodeAsync": "  private void createLockNodeAsync() {\n    zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,\n        this, zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSuccess": "  private static boolean isSuccess(Code code) {\n    return (code == Code.OK);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorActiveStatus": "  private void monitorActiveStatus() {\n    assert wantToBeInElection;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Monitoring active leader for \" + this);\n    }\n    statRetryCount = 0;\n    monitorLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeDoesNotExist": "  private static boolean isNodeDoesNotExist(Code code) {\n    return (code == Code.NONODE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.reJoinElectionAfterFailureToBecomeActive": "  private void reJoinElectionAfterFailureToBecomeActive() {\n    reJoinElection(SLEEP_AFTER_FAILURE_TO_BECOME_ACTIVE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.enterNeutralMode": "  private void enterNeutralMode() {\n    if (state != State.NEUTRAL) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Entering neutral mode for \" + this);\n      }\n      state = State.NEUTRAL;\n      appClient.enterNeutralMode();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorLockNodeAsync": "  private void monitorLockNodeAsync() {\n    if (monitorLockNodePending && monitorLockNodeClient == zkClient) {\n      LOG.info(\"Ignore duplicate monitor lock-node request.\");\n      return;\n    }\n    monitorLockNodePending = true;\n    monitorLockNodeClient = zkClient;\n    zkClient.exists(zkLockFilePath,\n        watcher, this,\n        zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSessionExpired": "  private static boolean isSessionExpired(Code code) {\n    return (code == Code.SESSIONEXPIRED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeStandby": "  private void becomeStandby() {\n    if (state != State.STANDBY) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming standby for \" + this);\n      }\n      state = State.STANDBY;\n      appClient.becomeStandby();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fatalError": "  private void fatalError(String errorMessage) {\n    LOG.fatal(errorMessage);\n    reset();\n    appClient.notifyFatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isStaleClient": "  private synchronized boolean isStaleClient(Object ctx) {\n    Preconditions.checkNotNull(ctx);\n    if (zkClient != (ZooKeeper)ctx) {\n      LOG.warn(\"Ignoring stale result from old client with sessionId \" +\n          String.format(\"0x%08x\", ((ZooKeeper)ctx).getSessionId()));\n      return true;\n    }\n    return false;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      ApplicationId appId, ApplicationAttemptId attemptId,\n      ContainerId containerId, Resource resource, CallerContext callerContext,\n      InetAddress ip) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    if (ip != null) {\n      add(Keys.IP, ip.getHostAddress(), b);\n    }\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.SUCCESS, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    if (resource != null) {\n      add(Keys.RESOURCE, resource.toString(), b);\n    }\n    appendCallerContext(b, callerContext);\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          null, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ApplicationId appId,\n      ApplicationAttemptId attemptId, ContainerId containerId, Resource resource) {\n    return createFailureLog(user, operation, perm, target, description, appId,\n        attemptId, containerId, resource, null);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getDispatcher": "  Dispatcher getDispatcher();\n\n  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMAdminService": "  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n}"
        },
        "bug_report": {
            "Title": "RM unable to start in secure mode",
            "Description": "Resource manager is unable to start in secure mode\n\n{code}\n2017-01-08 14:27:29,917 INFO org.apache.hadoop.conf.Configuration: found resource hadoop-policy.xml at file:/opt/hadoop/release/hadoop-3.0.0-alpha2-SNAPSHOT/etc/hadoop/hadoop-policy.xml\n2017-01-08 14:27:29,918 INFO org.apache.hadoop.yarn.server.resourcemanager.AdminService: Refresh All\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls(AdminService.java:569)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls(AdminService.java:552)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:707)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n2017-01-08 14:27:29,919 ERROR org.apache.hadoop.yarn.server.resourcemanager.AdminService: RefreshAll failed so firing fatal event\norg.apache.hadoop.ha.ServiceFailedException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:712)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n2017-01-08 14:27:29,920 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033\n2017-01-08 14:27:29,948 WARN org.apache.hadoop.ha.ActiveStandbyElector: Exception handling the winning of election\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Error on refreshAll during transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:311)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        ... 4 more\nCaused by: org.apache.hadoop.ha.ServiceFailedException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:712)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        ... 5 more\n\n{code}\n\nResourceManager services are added in following order\n# EmbeddedElector\n# AdminService\n\nDuring resource manager service start() .EmbeddedElector starts first and invokes  {{AdminService#refreshAll()}} but {{AdminService#serviceStart()}} happens after {{ActiveStandbyElectorBasedElectorService}} service start is complete. So {{AdminService#server}} will be *null* which causes  {{AdminService#refreshAll()}}  to fail\n{code}\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls();\n      }\n{code}"
        }
    },
    {
        "filename": "YARN-7663.json",
        "creation_time": "2017-12-15T01:52:46.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: START at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:805)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:116)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:901)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:885)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      listener.preTransition(operand, currentState, event);\n      STATE oldState = currentState;\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      listener.postTransition(operand, oldState, currentState, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.postTransition": "    public void postTransition(Object op, Enum beforeState, Enum afterState,\n        Object processedEvent) { }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.preTransition": "    public void preTransition(Object op, Enum beforeState,\n        Object eventToBeProcessed) { }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle": "  public void handle(RMAppEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId appID = event.getApplicationId();\n      LOG.debug(\"Processing event for \" + appID + \" of type \"\n          + event.getType());\n      final RMAppState oldState = getState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.error(\"App: \" + appID\n            + \" can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      // Log at INFO if we're not recovering or not in a terminal state.\n      // Log at DEBUG otherwise.\n      if ((oldState != getState()) &&\n          (((recoveredFinalState == null)) ||\n            (event.getType() != RMAppEventType.RECOVER))) {\n        LOG.info(String.format(STATE_CHANGE_MESSAGE, appID, oldState,\n            getState(), event.getType()));\n      } else if ((oldState != getState()) && LOG.isDebugEnabled()) {\n        LOG.debug(String.format(STATE_CHANGE_MESSAGE, appID, oldState,\n            getState(), event.getType()));\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getState": "  public RMAppState getState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handleTransitionToStandByInNewThread": "  private void handleTransitionToStandByInNewThread() {\n    Thread standByTransitionThread =\n        new Thread(activeServices.standByTransitionRunnable);\n    standByTransitionThread.setName(\"StandByTransitionThread\");\n    standByTransitionThread.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "RMAppImpl:Invalid event: START at KILLED",
            "Description": "Send kill to application, the RM log shows:\r\n\r\n{code:java}\r\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: START at KILLED\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:805)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:116)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:901)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:885)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\n{code}\r\n\r\n\r\nif insert sleep before where the START event was created, this bug will deterministically reproduce. "
        }
    },
    {
        "filename": "YARN-5873.json",
        "creation_time": "2016-11-12T09:54:20.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerStartEvent.hashCode(WritingContainerStartEvent.java:38)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$MultiThreadedDispatcher$CompositEventHandler.handle(RMApplicationHistoryWriter.java:354)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.containerStarted(RMApplicationHistoryWriter.java:278)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:251)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:217)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:210)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate(FiCaSchedulerApp.java:227)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.handleNewContainerAllocation(RegularContainerAllocator.java:704)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.doAllocation(RegularContainerAllocator.java:746)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.allocate(RegularContainerAllocator.java:832)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.assignContainers(RegularContainerAllocator.java:865)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.assignContainers(FiCaSchedulerApp.java:931)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:1044)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:690)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:508)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers(CapacityScheduler.java:1475)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode(CapacityScheduler.java:1470)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1559)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1346)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:1221)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1601)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:149)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerStartEvent.hashCode": "  public int hashCode() {\n    return containerId.getApplicationAttemptId().getApplicationId().hashCode();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handle": "      public void handle(Event event) {\n        // Use hashCode (of ApplicationId) to dispatch the event to the child\n        // dispatcher, such that all the writing events of one application will\n        // be handled by one thread, the scheduled order of the these events\n        // will be preserved\n        int index = (event.hashCode() & Integer.MAX_VALUE) % dispatchers.size();\n        dispatchers.get(index).getEventHandler().handle(event);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent": "  protected void handleWritingApplicationHistoryEvent(\n      WritingApplicationHistoryEvent event) {\n    switch (event.getType()) {\n      case APP_START:\n        WritingApplicationStartEvent wasEvent =\n            (WritingApplicationStartEvent) event;\n        try {\n          writer.applicationStarted(wasEvent.getApplicationStartData());\n          LOG.info(\"Stored the start data of application \"\n              + wasEvent.getApplicationId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the start data of application \"\n              + wasEvent.getApplicationId());\n        }\n        break;\n      case APP_FINISH:\n        WritingApplicationFinishEvent wafEvent =\n            (WritingApplicationFinishEvent) event;\n        try {\n          writer.applicationFinished(wafEvent.getApplicationFinishData());\n          LOG.info(\"Stored the finish data of application \"\n              + wafEvent.getApplicationId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the finish data of application \"\n              + wafEvent.getApplicationId());\n        }\n        break;\n      case APP_ATTEMPT_START:\n        WritingApplicationAttemptStartEvent waasEvent =\n            (WritingApplicationAttemptStartEvent) event;\n        try {\n          writer.applicationAttemptStarted(waasEvent\n            .getApplicationAttemptStartData());\n          LOG.info(\"Stored the start data of application attempt \"\n              + waasEvent.getApplicationAttemptId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the start data of application attempt \"\n              + waasEvent.getApplicationAttemptId());\n        }\n        break;\n      case APP_ATTEMPT_FINISH:\n        WritingApplicationAttemptFinishEvent waafEvent =\n            (WritingApplicationAttemptFinishEvent) event;\n        try {\n          writer.applicationAttemptFinished(waafEvent\n            .getApplicationAttemptFinishData());\n          LOG.info(\"Stored the finish data of application attempt \"\n              + waafEvent.getApplicationAttemptId());\n        } catch (IOException e) {\n          LOG\n            .error(\"Error when storing the finish data of application attempt \"\n                + waafEvent.getApplicationAttemptId());\n        }\n        break;\n      case CONTAINER_START:\n        WritingContainerStartEvent wcsEvent =\n            (WritingContainerStartEvent) event;\n        try {\n          writer.containerStarted(wcsEvent.getContainerStartData());\n          LOG.info(\"Stored the start data of container \"\n              + wcsEvent.getContainerId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the start data of container \"\n              + wcsEvent.getContainerId());\n        }\n        break;\n      case CONTAINER_FINISH:\n        WritingContainerFinishEvent wcfEvent =\n            (WritingContainerFinishEvent) event;\n        try {\n          writer.containerFinished(wcfEvent.getContainerFinishData());\n          LOG.info(\"Stored the finish data of container \"\n              + wcfEvent.getContainerId());\n        } catch (IOException e) {\n          LOG.error(\"Error when storing the finish data of container \"\n              + wcfEvent.getContainerId());\n        }\n        break;\n      default:\n        LOG.error(\"Unknown WritingApplicationHistoryEvent type: \"\n            + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.getEventHandler": "    public EventHandler getEventHandler() {\n      return new CompositEventHandler();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.containerStarted": "  public void containerStarted(RMContainer container) {\n    if (historyServiceEnabled) {\n      dispatcher.getEventHandler().handle(\n        new WritingContainerStartEvent(container.getContainerId(),\n          ContainerStartData.newInstance(container.getContainerId(),\n            container.getAllocatedResource(), container.getAllocatedNode(),\n            container.getAllocatedPriority(), container.getCreationTime())));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate": "  public RMContainer allocate(FiCaSchedulerNode node,\n      SchedulerRequestKey schedulerKey, ResourceRequest request,\n      Container container) {\n    try {\n      readLock.lock();\n\n      if (isStopped) {\n        return null;\n      }\n\n      // Required sanity check - AM can call 'allocate' to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getTotalRequiredResources(schedulerKey) <= 0) {\n        return null;\n      }\n\n      // Create RMContainer\n      RMContainer rmContainer = new RMContainerImpl(container,\n          this.getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), this.rmContext,\n          request.getNodeLabelExpression());\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // FIXME, should set when confirmed\n      updateAMContainerDiagnostics(AMState.ASSIGNED, null);\n\n      return rmContainer;\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.handleNewContainerAllocation": "  private ContainerAllocation handleNewContainerAllocation(\n      ContainerAllocation allocationResult, FiCaSchedulerNode node,\n      SchedulerRequestKey schedulerKey, Container container) {\n    // Inform the application\n    RMContainer allocatedContainer = application.allocate(node, schedulerKey,\n        lastResourceRequest, container);\n\n    allocationResult.updatedContainer = allocatedContainer;\n\n    // Does the application need this resource?\n    if (allocatedContainer == null) {\n      // Skip this app if we failed to allocate.\n      ContainerAllocation ret =\n          new ContainerAllocation(allocationResult.containerToBeUnreserved,\n              null, AllocationState.APP_SKIPPED);\n      ActivitiesLogger.APP.recordAppActivityWithoutAllocation(activitiesManager,\n          node, application, schedulerKey.getPriority(),\n          ActivityDiagnosticConstant.FAIL_TO_ALLOCATE, ActivityState.REJECTED);\n      return ret;\n    }\n    \n    return allocationResult;    \n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.allocate": "  private ContainerAllocation allocate(Resource clusterResource,\n      PlacementSet<FiCaSchedulerNode> ps, SchedulingMode schedulingMode,\n      ResourceLimits resourceLimits, SchedulerRequestKey schedulerKey,\n      RMContainer reservedContainer) {\n    // Do checks before determining which node to allocate\n    // Directly return if this check fails.\n    ContainerAllocation result;\n    if (reservedContainer == null) {\n      result = preCheckForPlacementSet(clusterResource, ps, schedulingMode,\n          resourceLimits, schedulerKey);\n      if (null != result) {\n        return result;\n      }\n    } else {\n      // pre-check when allocating reserved container\n      if (application.getTotalRequiredResources(schedulerKey) == 0) {\n        // Release\n        return new ContainerAllocation(reservedContainer, null,\n            AllocationState.QUEUE_SKIPPED);\n      }\n    }\n\n    SchedulingPlacementSet<FiCaSchedulerNode> schedulingPS =\n        application.getAppSchedulingInfo().getSchedulingPlacementSet(\n            schedulerKey);\n\n    result = ContainerAllocation.PRIORITY_SKIPPED;\n\n    Iterator<FiCaSchedulerNode> iter = schedulingPS.getPreferredNodeIterator(\n        ps);\n    while (iter.hasNext()) {\n      FiCaSchedulerNode node = iter.next();\n\n      result = tryAllocateOnNode(clusterResource, node, schedulingMode,\n          resourceLimits, schedulerKey, reservedContainer);\n\n      if (AllocationState.ALLOCATED == result.state\n          || AllocationState.RESERVED == result.state) {\n        result = doAllocation(result, node, schedulerKey, reservedContainer);\n        break;\n      }\n    }\n\n    return result;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.doAllocation": "  ContainerAllocation doAllocation(ContainerAllocation allocationResult,\n      FiCaSchedulerNode node, SchedulerRequestKey schedulerKey,\n      RMContainer reservedContainer) {\n    // Create the container if necessary\n    Container container =\n        getContainer(reservedContainer, node,\n            allocationResult.getResourceToBeAllocated(), schedulerKey);\n\n    // something went wrong getting/creating the container\n    if (container == null) {\n      application\n          .updateAppSkipNodeDiagnostics(\"Scheduling of container failed. \");\n      LOG.warn(\"Couldn't get container for allocation!\");\n      ActivitiesLogger.APP.recordAppActivityWithoutAllocation(activitiesManager,\n          node, application, schedulerKey.getPriority(),\n          ActivityDiagnosticConstant.COULD_NOT_GET_CONTAINER,\n          ActivityState.REJECTED);\n      return ContainerAllocation.APP_SKIPPED;\n    }\n\n    if (allocationResult.getAllocationState() == AllocationState.ALLOCATED) {\n      // When allocating container\n      allocationResult = handleNewContainerAllocation(allocationResult, node,\n          schedulerKey, container);\n    } else {\n      // When reserving container\n      RMContainer updatedContainer = reservedContainer;\n      if (updatedContainer == null) {\n        updatedContainer = new RMContainerImpl(container,\n            application.getApplicationAttemptId(), node.getNodeID(),\n            application.getAppSchedulingInfo().getUser(), rmContext);\n      }\n      allocationResult.updatedContainer = updatedContainer;\n    }\n\n    // Only reset opportunities when we FIRST allocate the container. (IAW, When\n    // reservedContainer != null, it's not the first time)\n    if (reservedContainer == null) {\n      // Don't reset scheduling opportunities for off-switch assignments\n      // otherwise the app will be delayed for each non-local assignment.\n      // This helps apps with many off-cluster requests schedule faster.\n      if (allocationResult.containerNodeType != NodeType.OFF_SWITCH) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Resetting scheduling opportunities\");\n        }\n        // Only reset scheduling opportunities for RACK_LOCAL if configured\n        // to do so. Not resetting means we will continue to schedule\n        // RACK_LOCAL without delay.\n        if (allocationResult.containerNodeType == NodeType.NODE_LOCAL\n            || application.getCSLeafQueue().getRackLocalityFullReset()) {\n          application.resetSchedulingOpportunities(schedulerKey);\n        }\n      }\n\n      // Non-exclusive scheduling opportunity is different: we need reset\n      // it when:\n      // - It allocated on the default partition\n      //\n      // This is to make sure non-labeled resource request will be\n      // most likely allocated on non-labeled nodes first.\n      if (StringUtils.equals(node.getPartition(),\n          RMNodeLabelsManager.NO_LABEL)) {\n        application\n            .resetMissedNonPartitionedRequestSchedulingOpportunity(schedulerKey);\n      }\n    }\n\n    return allocationResult;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.getContainer": "  private Container getContainer(RMContainer rmContainer,\n      FiCaSchedulerNode node, Resource capability,\n      SchedulerRequestKey schedulerKey) {\n    return (rmContainer != null) ? rmContainer.getContainer()\n        : createContainer(node, capability, schedulerKey);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.assignContainers": "  public CSAssignment assignContainers(Resource clusterResource,\n      PlacementSet<FiCaSchedulerNode> ps, SchedulingMode schedulingMode,\n      ResourceLimits resourceLimits,\n      RMContainer reservedContainer) {\n    FiCaSchedulerNode node = PlacementSetUtils.getSingleNode(ps);\n\n    if (reservedContainer == null) {\n      // Check if application needs more resource, skip if it doesn't need more.\n      if (!application.hasPendingResourceRequest(rc,\n          ps.getPartition(), clusterResource, schedulingMode)) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Skip app_attempt=\" + application.getApplicationAttemptId()\n              + \", because it doesn't need more resource, schedulingMode=\"\n              + schedulingMode.name() + \" node-label=\" + ps.getPartition());\n        }\n        ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(\n            activitiesManager, node, application, application.getPriority(),\n            ActivityDiagnosticConstant.APPLICATION_DO_NOT_NEED_RESOURCE);\n        return CSAssignment.SKIP_ASSIGNMENT;\n      }\n      \n      // Schedule in priority order\n      for (SchedulerRequestKey schedulerKey : application.getSchedulerKeys()) {\n        ContainerAllocation result =\n            allocate(clusterResource, ps, schedulingMode, resourceLimits,\n                schedulerKey, null);\n\n        AllocationState allocationState = result.getAllocationState();\n        if (allocationState == AllocationState.PRIORITY_SKIPPED) {\n          continue;\n        }\n        return getCSAssignmentFromAllocateResult(clusterResource, result,\n            null, node);\n      }\n\n      // We will reach here if we skipped all priorities of the app, so we will\n      // skip the app.\n      ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(\n          activitiesManager, node, application, application.getPriority(),\n          ActivityDiagnosticConstant.SKIPPED_ALL_PRIORITIES);\n      return CSAssignment.SKIP_ASSIGNMENT;\n    } else {\n      ContainerAllocation result =\n          allocate(clusterResource, ps, schedulingMode, resourceLimits,\n              reservedContainer.getReservedSchedulerKey(), reservedContainer);\n      return getCSAssignmentFromAllocateResult(clusterResource, result,\n          reservedContainer, node);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.assignContainers": "  public CSAssignment assignContainers(Resource clusterResource,\n      PlacementSet<FiCaSchedulerNode> ps, ResourceLimits currentResourceLimits,\n      SchedulingMode schedulingMode, RMContainer reservedContainer) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"pre-assignContainers for application \"\n          + getApplicationId());\n      showRequests();\n    }\n\n    return containerAllocator.assignContainers(clusterResource, ps,\n        schedulingMode, currentResourceLimits, reservedContainer);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers": "  public CSAssignment assignContainers(Resource clusterResource,\n      PlacementSet<FiCaSchedulerNode> ps, ResourceLimits currentResourceLimits,\n    SchedulingMode schedulingMode) {\n    updateCurrentResourceLimits(currentResourceLimits, clusterResource);\n    FiCaSchedulerNode node = PlacementSetUtils.getSingleNode(ps);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"assignContainers: partition=\" + ps.getPartition()\n          + \" #applications=\" + orderingPolicy.getNumSchedulableEntities());\n    }\n\n    setPreemptionAllowed(currentResourceLimits, ps.getPartition());\n\n    // Check for reserved resources, try to allocate reserved container first.\n    CSAssignment assignment = allocateFromReservedContainer(clusterResource,\n        ps, currentResourceLimits, schedulingMode);\n    if (null != assignment) {\n      return assignment;\n    }\n\n    // if our queue cannot access this node, just return\n    if (schedulingMode == SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY\n        && !accessibleToPartition(ps.getPartition())) {\n      ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n          getParent().getQueueName(), getQueueName(), ActivityState.REJECTED,\n          ActivityDiagnosticConstant.NOT_ABLE_TO_ACCESS_PARTITION + ps\n              .getPartition());\n      return CSAssignment.NULL_ASSIGNMENT;\n    }\n\n    // Check if this queue need more resource, simply skip allocation if this\n    // queue doesn't need more resources.\n    if (!hasPendingResourceRequest(ps.getPartition(), clusterResource,\n        schedulingMode)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Skip this queue=\" + getQueuePath()\n            + \", because it doesn't need more resource, schedulingMode=\"\n            + schedulingMode.name() + \" node-partition=\" + ps.getPartition());\n      }\n      ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n          getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,\n          ActivityDiagnosticConstant.QUEUE_DO_NOT_NEED_MORE_RESOURCE);\n      return CSAssignment.NULL_ASSIGNMENT;\n    }\n\n    for (Iterator<FiCaSchedulerApp> assignmentIterator =\n         orderingPolicy.getAssignmentIterator();\n         assignmentIterator.hasNext(); ) {\n      FiCaSchedulerApp application = assignmentIterator.next();\n\n      ActivitiesLogger.APP.startAppAllocationRecording(activitiesManager,\n          node.getNodeID(), SystemClock.getInstance().getTime(), application);\n\n      // Check queue max-capacity limit\n      if (!super.canAssignToThisQueue(clusterResource, ps.getPartition(),\n          currentResourceLimits, application.getCurrentReservation(),\n          schedulingMode)) {\n        ActivitiesLogger.APP.recordRejectedAppActivityFromLeafQueue(\n            activitiesManager, node, application, application.getPriority(),\n            ActivityDiagnosticConstant.QUEUE_MAX_CAPACITY_LIMIT);\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,\n            ActivityDiagnosticConstant.EMPTY);\n        return CSAssignment.NULL_ASSIGNMENT;\n      }\n\n      Resource userLimit = computeUserLimitAndSetHeadroom(application,\n          clusterResource, ps.getPartition(), schedulingMode);\n\n      // Check user limit\n      if (!canAssignToUser(clusterResource, application.getUser(), userLimit,\n          application, ps.getPartition(), currentResourceLimits)) {\n        application.updateAMContainerDiagnostics(AMState.ACTIVATED,\n            \"User capacity has reached its maximum limit.\");\n        ActivitiesLogger.APP.recordRejectedAppActivityFromLeafQueue(\n            activitiesManager, node, application, application.getPriority(),\n            ActivityDiagnosticConstant.USER_CAPACITY_MAXIMUM_LIMIT);\n        continue;\n      }\n\n      // Try to schedule\n      assignment = application.assignContainers(clusterResource,\n          ps, currentResourceLimits, schedulingMode, null);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"post-assignContainers for application \" + application\n            .getApplicationId());\n        application.showRequests();\n      }\n\n      // Did we schedule or reserve a container?\n      Resource assigned = assignment.getResource();\n\n      if (Resources.greaterThan(resourceCalculator, clusterResource, assigned,\n          Resources.none())) {\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            getParent().getQueueName(), getQueueName(),\n            ActivityState.ACCEPTED, ActivityDiagnosticConstant.EMPTY);\n        return assignment;\n      } else if (assignment.getSkippedType()\n          == CSAssignment.SkippedType.OTHER) {\n        ActivitiesLogger.APP.finishSkippedAppAllocationRecording(\n            activitiesManager, application.getApplicationId(),\n            ActivityState.SKIPPED, ActivityDiagnosticConstant.EMPTY);\n        application.updateNodeInfoForAMDiagnostics(node);\n      } else if (assignment.getSkippedType()\n          == CSAssignment.SkippedType.QUEUE_LIMIT) {\n        return assignment;\n      } else{\n        // If we don't allocate anything, and it is not skipped by application,\n        // we will return to respect FIFO of applications\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,\n            ActivityDiagnosticConstant.RESPECT_FIFO);\n        ActivitiesLogger.APP.finishSkippedAppAllocationRecording(\n            activitiesManager, application.getApplicationId(),\n            ActivityState.SKIPPED, ActivityDiagnosticConstant.EMPTY);\n        return CSAssignment.NULL_ASSIGNMENT;\n      }\n    }\n    ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n        getParent().getQueueName(), getQueueName(), ActivityState.SKIPPED,\n        ActivityDiagnosticConstant.EMPTY);\n\n    return CSAssignment.NULL_ASSIGNMENT;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.allocateFromReservedContainer": "  private CSAssignment allocateFromReservedContainer(\n      Resource clusterResource, PlacementSet<FiCaSchedulerNode> ps,\n      ResourceLimits currentResourceLimits, SchedulingMode schedulingMode) {\n    FiCaSchedulerNode node = PlacementSetUtils.getSingleNode(ps);\n    if (null == node) {\n      return null;\n    }\n\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      FiCaSchedulerApp application = getApplication(\n          reservedContainer.getApplicationAttemptId());\n\n      if (null != application) {\n        ActivitiesLogger.APP.startAppAllocationRecording(activitiesManager,\n            node.getNodeID(), SystemClock.getInstance().getTime(), application);\n        CSAssignment assignment = application.assignContainers(clusterResource,\n            ps, currentResourceLimits, schedulingMode, reservedContainer);\n        return assignment;\n      }\n    }\n\n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.computeUserLimitAndSetHeadroom": "  Resource computeUserLimitAndSetHeadroom(FiCaSchedulerApp application,\n      Resource clusterResource, String nodePartition,\n      SchedulingMode schedulingMode) {\n    String user = application.getUser();\n    User queueUser = getUser(user);\n\n    // Compute user limit respect requested labels,\n    // TODO, need consider headroom respect labels also\n    Resource userLimit =\n        computeUserLimit(application.getUser(), clusterResource, queueUser,\n            nodePartition, schedulingMode);\n\n    setQueueResourceLimitsInfo(clusterResource);\n\n    Resource headroom =\n        getHeadroom(queueUser, cachedResourceLimitsForHeadroom.getLimit(),\n            clusterResource, userLimit, nodePartition);\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Headroom calculation for user \" + user + \": \" + \n          \" userLimit=\" + userLimit + \n          \" queueMaxAvailRes=\" + cachedResourceLimitsForHeadroom.getLimit() +\n          \" consumed=\" + queueUser.getUsed() + \n          \" headroom=\" + headroom);\n    }\n    \n    CapacityHeadroomProvider headroomProvider = new CapacityHeadroomProvider(\n      queueUser, this, application, queueResourceLimitsInfo);\n    \n    application.setHeadroomProvider(headroomProvider);\n\n    metrics.setAvailableResourcesToUser(user, headroom);\n    \n    return userLimit;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getUser": "  public User getUser(String userName) {\n    return users.get(userName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.updateCurrentResourceLimits": "  private void updateCurrentResourceLimits(\n      ResourceLimits currentResourceLimits, Resource clusterResource) {\n    // TODO: need consider non-empty node labels when resource limits supports\n    // node labels\n    // Even if ParentQueue will set limits respect child's max queue capacity,\n    // but when allocating reserved container, CapacityScheduler doesn't do\n    // this. So need cap limits by queue's max capacity here.\n    this.cachedResourceLimitsForHeadroom =\n        new ResourceLimits(currentResourceLimits.getLimit());\n    Resource queueMaxResource =\n        Resources.multiplyAndNormalizeDown(resourceCalculator, labelManager\n            .getResourceByLabel(RMNodeLabelsManager.NO_LABEL, clusterResource),\n            queueCapacities\n                .getAbsoluteMaximumCapacity(RMNodeLabelsManager.NO_LABEL),\n            minimumAllocation);\n    this.cachedResourceLimitsForHeadroom.setLimit(Resources.min(\n        resourceCalculator, clusterResource, queueMaxResource,\n        currentResourceLimits.getLimit()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.canAssignToUser": "  protected boolean canAssignToUser(Resource clusterResource,\n      String userName, Resource limit, FiCaSchedulerApp application,\n      String nodePartition, ResourceLimits currentResourceLimits) {\n    try {\n      readLock.lock();\n      User user = getUser(userName);\n\n      currentResourceLimits.setAmountNeededUnreserve(Resources.none());\n\n      // Note: We aren't considering the current request since there is a fixed\n      // overhead of the AM, but it's a > check, not a >= check, so...\n      if (Resources.greaterThan(resourceCalculator, clusterResource,\n          user.getUsed(nodePartition), limit)) {\n        // if enabled, check to see if could we potentially use this node instead\n        // of a reserved node if the application has reserved containers\n        if (this.reservationsContinueLooking && nodePartition.equals(\n            CommonNodeLabelsManager.NO_LABEL)) {\n          if (Resources.lessThanOrEqual(resourceCalculator, clusterResource,\n              Resources.subtract(user.getUsed(),\n                  application.getCurrentReservation()), limit)) {\n\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"User \" + userName + \" in queue \" + getQueueName()\n                  + \" will exceed limit based on reservations - \"\n                  + \" consumed: \" + user.getUsed() + \" reserved: \" + application\n                  .getCurrentReservation() + \" limit: \" + limit);\n            }\n            Resource amountNeededToUnreserve = Resources.subtract(\n                user.getUsed(nodePartition), limit);\n            // we can only acquire a new container if we unreserve first to\n            // respect user-limit\n            currentResourceLimits.setAmountNeededUnreserve(\n                amountNeededToUnreserve);\n            return true;\n          }\n        }\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"User \" + userName + \" in queue \" + getQueueName()\n              + \" will exceed limit - \" + \" consumed: \" + user\n              .getUsed(nodePartition) + \" limit: \" + limit);\n        }\n        return false;\n      }\n      return true;\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getQueuePath": "  public String getQueuePath() {\n    return getParent().getQueuePath() + \".\" + getQueueName();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.setPreemptionAllowed": "  private void setPreemptionAllowed(ResourceLimits limits, String nodePartition) {\n    // Set preemption-allowed:\n    // For leaf queue, only under-utilized queue is allowed to preempt resources from other queues\n    float usedCapacity = queueCapacities.getAbsoluteUsedCapacity(nodePartition);\n    float guaranteedCapacity = queueCapacities.getAbsoluteCapacity(nodePartition);\n    limits.setIsAllowPreemption(usedCapacity < guaranteedCapacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues": "  private CSAssignment assignContainersToChildQueues(Resource cluster,\n      PlacementSet<FiCaSchedulerNode> ps, ResourceLimits limits,\n      SchedulingMode schedulingMode) {\n    CSAssignment assignment = CSAssignment.NULL_ASSIGNMENT;\n\n    Resource parentLimits = limits.getLimit();\n    printChildQueues();\n\n    // Try to assign to most 'under-served' sub-queue\n    for (Iterator<CSQueue> iter = sortAndGetChildrenAllocationIterator(\n        ps.getPartition()); iter.hasNext(); ) {\n      CSQueue childQueue = iter.next();\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Trying to assign to queue: \" + childQueue.getQueuePath()\n          + \" stats: \" + childQueue);\n      }\n\n      // Get ResourceLimits of child queue before assign containers\n      ResourceLimits childLimits =\n          getResourceLimitsOfChild(childQueue, cluster, parentLimits,\n              ps.getPartition());\n      \n      CSAssignment childAssignment = childQueue.assignContainers(cluster, ps,\n          childLimits, schedulingMode);\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Assigned to queue: \" + childQueue.getQueuePath() +\n            \" stats: \" + childQueue + \" --> \" +\n            childAssignment.getResource() + \", \" + childAssignment.getType());\n      }\n\n      if (Resources.greaterThan(\n              resourceCalculator, cluster, \n              childAssignment.getResource(), Resources.none())) {\n        assignment = childAssignment;\n        break;\n      } else if (childAssignment.getSkippedType() ==\n          CSAssignment.SkippedType.QUEUE_LIMIT) {\n        if (assignment.getSkippedType() !=\n            CSAssignment.SkippedType.QUEUE_LIMIT) {\n          assignment = childAssignment;\n        }\n        Resource resourceToSubtract = Resources.max(resourceCalculator,\n            cluster, childLimits.getHeadroom(), Resources.none());\n        if(LOG.isDebugEnabled()) {\n          LOG.debug(\"Decrease parentLimits \" + parentLimits +\n              \" for \" + this.getQueueName() + \" by \" +\n              resourceToSubtract + \" as childQueue=\" +\n              childQueue.getQueueName() + \" is blocked\");\n        }\n        parentLimits = Resources.subtract(parentLimits,\n            resourceToSubtract);\n      }\n    }\n\n    return assignment;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.sortAndGetChildrenAllocationIterator": "  private Iterator<CSQueue> sortAndGetChildrenAllocationIterator(\n      String partition) {\n    // Previously we keep a sorted list for default partition, it is not good\n    // when multi-threading scheduler is enabled, so to make a simpler code\n    // now re-sort queue every time irrespective to node partition.\n    partitionQueueComparator.setPartitionToLookAt(partition);\n    List<CSQueue> childrenList = new ArrayList<>(childQueues);\n    Collections.sort(childrenList, partitionQueueComparator);\n    return childrenList.iterator();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getQueuePath": "  public String getQueuePath() {\n    String parentPath = ((parent == null) ? \"\" : (parent.getQueuePath() + \".\"));\n    return parentPath + getQueueName();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers": "  public CSAssignment assignContainers(Resource clusterResource,\n      PlacementSet<FiCaSchedulerNode> ps, ResourceLimits resourceLimits,\n    SchedulingMode schedulingMode) {\n    FiCaSchedulerNode node = PlacementSetUtils.getSingleNode(ps);\n\n    // if our queue cannot access this node, just return\n    if (schedulingMode == SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY\n        && !accessibleToPartition(ps.getPartition())) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Skip this queue=\" + getQueuePath()\n            + \", because it is not able to access partition=\" + ps\n            .getPartition());\n      }\n\n      ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n          getParentName(), getQueueName(), ActivityState.REJECTED,\n          ActivityDiagnosticConstant.NOT_ABLE_TO_ACCESS_PARTITION + node\n              .getPartition());\n      if (rootQueue) {\n        ActivitiesLogger.NODE.finishSkippedNodeAllocation(activitiesManager,\n            node);\n      }\n\n      return CSAssignment.NULL_ASSIGNMENT;\n    }\n\n    // Check if this queue need more resource, simply skip allocation if this\n    // queue doesn't need more resources.\n    if (!super.hasPendingResourceRequest(ps.getPartition(), clusterResource,\n        schedulingMode)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Skip this queue=\" + getQueuePath()\n            + \", because it doesn't need more resource, schedulingMode=\"\n            + schedulingMode.name() + \" node-partition=\" + ps\n            .getPartition());\n      }\n\n      ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n          getParentName(), getQueueName(), ActivityState.SKIPPED,\n          ActivityDiagnosticConstant.QUEUE_DO_NOT_NEED_MORE_RESOURCE);\n      if (rootQueue) {\n        ActivitiesLogger.NODE.finishSkippedNodeAllocation(activitiesManager,\n            node);\n      }\n\n      return CSAssignment.NULL_ASSIGNMENT;\n    }\n\n    CSAssignment assignment = new CSAssignment(Resources.createResource(0, 0),\n        NodeType.NODE_LOCAL);\n\n    while (canAssign(clusterResource, node)) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Trying to assign containers to child-queue of \"\n            + getQueueName());\n      }\n\n      // Are we over maximum-capacity for this queue?\n      // This will also consider parent's limits and also continuous reservation\n      // looking\n      if (!super.canAssignToThisQueue(clusterResource, ps.getPartition(),\n          resourceLimits, Resources\n              .createResource(getMetrics().getReservedMB(),\n                  getMetrics().getReservedVirtualCores()), schedulingMode)) {\n\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            getParentName(), getQueueName(), ActivityState.SKIPPED,\n            ActivityDiagnosticConstant.QUEUE_MAX_CAPACITY_LIMIT);\n        if (rootQueue) {\n          ActivitiesLogger.NODE.finishSkippedNodeAllocation(activitiesManager,\n              node);\n        }\n\n        break;\n      }\n\n      // Schedule\n      CSAssignment assignedToChild = assignContainersToChildQueues(\n          clusterResource, ps, resourceLimits, schedulingMode);\n      assignment.setType(assignedToChild.getType());\n      assignment.setRequestLocalityType(\n          assignedToChild.getRequestLocalityType());\n      assignment.setExcessReservation(assignedToChild.getExcessReservation());\n      assignment.setContainersToKill(assignedToChild.getContainersToKill());\n\n      // Done if no child-queue assigned anything\n      if (Resources.greaterThan(resourceCalculator, clusterResource,\n          assignedToChild.getResource(), Resources.none())) {\n\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            getParentName(), getQueueName(), ActivityState.ACCEPTED,\n            ActivityDiagnosticConstant.EMPTY);\n\n        boolean isReserved =\n            assignedToChild.getAssignmentInformation().getReservationDetails()\n                != null && !assignedToChild.getAssignmentInformation()\n                .getReservationDetails().isEmpty();\n        if (node != null && !isReserved) {\n          if (rootQueue) {\n            ActivitiesLogger.NODE.finishAllocatedNodeAllocation(\n                activitiesManager, node,\n                assignedToChild.getAssignmentInformation()\n                    .getFirstAllocatedOrReservedContainerId(),\n                AllocationState.ALLOCATED);\n          }\n        } else{\n          if (rootQueue) {\n            ActivitiesLogger.NODE.finishAllocatedNodeAllocation(\n                activitiesManager, node,\n                assignedToChild.getAssignmentInformation()\n                    .getFirstAllocatedOrReservedContainerId(),\n                AllocationState.RESERVED);\n          }\n        }\n\n        // Track resource utilization in this pass of the scheduler\n        Resources.addTo(assignment.getResource(),\n            assignedToChild.getResource());\n        Resources.addTo(assignment.getAssignmentInformation().getAllocated(),\n            assignedToChild.getAssignmentInformation().getAllocated());\n        Resources.addTo(assignment.getAssignmentInformation().getReserved(),\n            assignedToChild.getAssignmentInformation().getReserved());\n        assignment.getAssignmentInformation().incrAllocations(\n            assignedToChild.getAssignmentInformation().getNumAllocations());\n        assignment.getAssignmentInformation().incrReservations(\n            assignedToChild.getAssignmentInformation().getNumReservations());\n        assignment.getAssignmentInformation().getAllocationDetails().addAll(\n            assignedToChild.getAssignmentInformation()\n                .getAllocationDetails());\n        assignment.getAssignmentInformation().getReservationDetails().addAll(\n            assignedToChild.getAssignmentInformation()\n                .getReservationDetails());\n        assignment.setIncreasedAllocation(\n            assignedToChild.isIncreasedAllocation());\n\n        LOG.info(\"assignedContainer\" + \" queue=\" + getQueueName()\n            + \" usedCapacity=\" + getUsedCapacity() + \" absoluteUsedCapacity=\"\n            + getAbsoluteUsedCapacity() + \" used=\" + queueUsage.getUsed()\n            + \" cluster=\" + clusterResource);\n\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\n              \"ParentQ=\" + getQueueName() + \" assignedSoFarInThisIteration=\"\n                  + assignment.getResource() + \" usedCapacity=\"\n                  + getUsedCapacity() + \" absoluteUsedCapacity=\"\n                  + getAbsoluteUsedCapacity());\n        }\n      } else{\n        assignment.setSkippedType(assignedToChild.getSkippedType());\n\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            getParentName(), getQueueName(), ActivityState.SKIPPED,\n            ActivityDiagnosticConstant.EMPTY);\n        if (rootQueue) {\n          ActivitiesLogger.NODE.finishSkippedNodeAllocation(activitiesManager,\n              node);\n        }\n\n        break;\n      }\n\n      /*\n       * Previously here, we can allocate more than one container for each\n       * allocation under rootQ. Now this logic is not proper any more\n       * in global scheduling world.\n       *\n       * So here do not try to allocate more than one container for each\n       * allocation, let top scheduler make the decision.\n       */\n      break;\n    }\n\n    return assignment;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getResourceLimitsOfChild": "  private ResourceLimits getResourceLimitsOfChild(CSQueue child,\n      Resource clusterResource, Resource parentLimits,\n      String nodePartition) {\n    // Set resource-limit of a given child, child.limit =\n    // min(my.limit - my.used + child.used, child.max)\n\n    // Parent available resource = parent-limit - parent-used-resource\n    Resource parentMaxAvailableResource = Resources.subtract(\n        parentLimits, queueUsage.getUsed(nodePartition));\n    // Deduct killable from used\n    Resources.addTo(parentMaxAvailableResource,\n        getTotalKillableResource(nodePartition));\n\n    // Child's limit = parent-available-resource + child-used\n    Resource childLimit = Resources.add(parentMaxAvailableResource,\n        child.getQueueResourceUsage().getUsed(nodePartition));\n\n    // Get child's max resource\n    Resource childConfiguredMaxResource = Resources.multiplyAndNormalizeDown(\n        resourceCalculator,\n        labelManager.getResourceByLabel(nodePartition, clusterResource),\n        child.getQueueCapacities().getAbsoluteMaximumCapacity(nodePartition),\n        minimumAllocation);\n\n    // Child's limit should be capped by child configured max resource\n    childLimit =\n        Resources.min(resourceCalculator, clusterResource, childLimit,\n            childConfiguredMaxResource);\n\n    // Normalize before return\n    childLimit =\n        Resources.roundDown(resourceCalculator, childLimit, minimumAllocation);\n\n    return new ResourceLimits(childLimit);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.printChildQueues": "  private void printChildQueues() {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"printChildQueues - queue: \" + getQueuePath()\n        + \" child-queues: \" + getChildQueuesToPrint());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers": "  private CSAssignment allocateOrReserveNewContainers(\n      PlacementSet<FiCaSchedulerNode> ps, boolean withNodeHeartbeat) {\n    CSAssignment assignment = root.assignContainers(getClusterResource(), ps,\n        new ResourceLimits(labelManager\n            .getResourceByLabel(ps.getPartition(), getClusterResource())),\n        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n\n    assignment.setSchedulingMode(SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n    submitResourceCommitRequest(getClusterResource(), assignment);\n\n    if (Resources.greaterThan(calculator, getClusterResource(),\n        assignment.getResource(), Resources.none())) {\n      if (withNodeHeartbeat) {\n        updateSchedulerHealth(lastNodeUpdateTime,\n            PlacementSetUtils.getSingleNode(ps).getNodeID(), assignment);\n      }\n      return assignment;\n    }\n\n    // Only do non-exclusive allocation when node has node-labels.\n    if (StringUtils.equals(ps.getPartition(), RMNodeLabelsManager.NO_LABEL)) {\n      return null;\n    }\n\n    // Only do non-exclusive allocation when the node-label supports that\n    try {\n      if (rmContext.getNodeLabelManager().isExclusiveNodeLabel(\n          ps.getPartition())) {\n        return null;\n      }\n    } catch (IOException e) {\n      LOG.warn(\"Exception when trying to get exclusivity of node label=\" + ps\n          .getPartition(), e);\n      return null;\n    }\n\n    // Try to use NON_EXCLUSIVE\n    assignment = root.assignContainers(getClusterResource(), ps,\n        // TODO, now we only consider limits for parent for non-labeled\n        // resources, should consider labeled resources as well.\n        new ResourceLimits(labelManager\n            .getResourceByLabel(RMNodeLabelsManager.NO_LABEL,\n                getClusterResource())),\n        SchedulingMode.IGNORE_PARTITION_EXCLUSIVITY);\n    assignment.setSchedulingMode(SchedulingMode.IGNORE_PARTITION_EXCLUSIVITY);\n    submitResourceCommitRequest(getClusterResource(), assignment);\n\n    return assignment;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateSchedulerHealth": "  private void updateSchedulerHealth(long now, NodeId nodeId,\n      CSAssignment assignment) {\n    List<AssignmentInformation.AssignmentDetails> allocations =\n        assignment.getAssignmentInformation().getAllocationDetails();\n    List<AssignmentInformation.AssignmentDetails> reservations =\n        assignment.getAssignmentInformation().getReservationDetails();\n    if (!allocations.isEmpty()) {\n      ContainerId allocatedContainerId =\n          allocations.get(allocations.size() - 1).containerId;\n      String allocatedQueue = allocations.get(allocations.size() - 1).queue;\n      schedulerHealth.updateAllocation(now, nodeId, allocatedContainerId,\n        allocatedQueue);\n    }\n    if (!reservations.isEmpty()) {\n      ContainerId reservedContainerId =\n          reservations.get(reservations.size() - 1).containerId;\n      String reservedQueue = reservations.get(reservations.size() - 1).queue;\n      schedulerHealth.updateReservation(now, nodeId, reservedContainerId,\n        reservedQueue);\n    }\n    schedulerHealth.updateSchedulerReservationCounts(assignment\n      .getAssignmentInformation().getNumReservations());\n    schedulerHealth.updateSchedulerAllocationCounts(assignment\n      .getAssignmentInformation().getNumAllocations());\n    schedulerHealth.updateSchedulerRunDetails(now, assignment\n      .getAssignmentInformation().getAllocated(), assignment\n      .getAssignmentInformation().getReserved());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.submitResourceCommitRequest": "  public void submitResourceCommitRequest(Resource cluster,\n      CSAssignment csAssignment) {\n    ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request =\n        createResourceCommitRequest(csAssignment);\n\n    if (null == request) {\n      return;\n    }\n\n    if (scheduleAsynchronously) {\n      // Submit to a commit thread and commit it async-ly\n      resourceCommitterService.addNewCommitRequest(request);\n    } else{\n      // Otherwise do it sync-ly.\n      tryCommit(cluster, request);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode": "  private CSAssignment allocateContainerOnSingleNode(PlacementSet<FiCaSchedulerNode> ps,\n      FiCaSchedulerNode node, boolean withNodeHeartbeat) {\n    // Backward compatible way to make sure previous behavior which allocation\n    // driven by node heartbeat works.\n    if (getNode(node.getNodeID()) != node) {\n      LOG.error(\"Trying to schedule on a removed node, please double check.\");\n      return null;\n    }\n\n    CSAssignment assignment;\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n    RMContainer reservedContainer = node.getReservedContainer();\n    if (reservedContainer != null) {\n      FiCaSchedulerApp reservedApplication = getCurrentAttemptForContainer(\n          reservedContainer.getContainerId());\n\n      // Try to fulfill the reservation\n      LOG.info(\n          \"Trying to fulfill reservation for application \" + reservedApplication\n              .getApplicationId() + \" on node: \" + node.getNodeID());\n\n      LeafQueue queue = ((LeafQueue) reservedApplication.getQueue());\n      assignment = queue.assignContainers(getClusterResource(), ps,\n          // TODO, now we only consider limits for parent for non-labeled\n          // resources, should consider labeled resources as well.\n          new ResourceLimits(labelManager\n              .getResourceByLabel(RMNodeLabelsManager.NO_LABEL,\n                  getClusterResource())),\n          SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n\n      if (assignment.isFulfilledReservation()) {\n        if (withNodeHeartbeat) {\n          // Only update SchedulerHealth in sync scheduling, existing\n          // Data structure of SchedulerHealth need to be updated for\n          // Async mode\n          updateSchedulerHealth(lastNodeUpdateTime, node.getNodeID(),\n              assignment);\n        }\n\n        schedulerHealth.updateSchedulerFulfilledReservationCounts(1);\n\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            queue.getParent().getQueueName(), queue.getQueueName(),\n            ActivityState.ACCEPTED, ActivityDiagnosticConstant.EMPTY);\n        ActivitiesLogger.NODE.finishAllocatedNodeAllocation(activitiesManager,\n            node, reservedContainer.getContainerId(),\n            AllocationState.ALLOCATED_FROM_RESERVED);\n      } else{\n        ActivitiesLogger.QUEUE.recordQueueActivity(activitiesManager, node,\n            queue.getParent().getQueueName(), queue.getQueueName(),\n            ActivityState.ACCEPTED, ActivityDiagnosticConstant.EMPTY);\n        ActivitiesLogger.NODE.finishAllocatedNodeAllocation(activitiesManager,\n            node, reservedContainer.getContainerId(), AllocationState.SKIPPED);\n      }\n\n      assignment.setSchedulingMode(\n          SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);\n      submitResourceCommitRequest(getClusterResource(), assignment);\n    }\n\n    // Do not schedule if there are any reservations to fulfill on the node\n    if (node.getReservedContainer() != null) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Skipping scheduling since node \" + node.getNodeID()\n            + \" is reserved by application \" + node.getReservedContainer()\n            .getContainerId().getApplicationAttemptId());\n      }\n      return null;\n    }\n\n    // First check if we can schedule\n    // When this time look at one node only, try schedule if the node\n    // has any available or killable resource\n    if (calculator.computeAvailableContainers(Resources\n            .add(node.getUnallocatedResource(), node.getTotalKillableResources()),\n        minimumAllocation) <= 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"This node or this node partition doesn't have available or\"\n            + \"killable resource\");\n      }\n      return null;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Trying to schedule on node: \" + node.getNodeName() + \", available: \"\n              + node.getUnallocatedResource());\n    }\n\n    return allocateOrReserveNewContainers(ps, withNodeHeartbeat);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return queues.get(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getNode": "  public FiCaSchedulerNode getNode(NodeId nodeId) {\n    return nodeTracker.getNode(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode": "  CSAssignment allocateContainersToNode(PlacementSet<FiCaSchedulerNode> ps,\n      boolean withNodeHeartbeat) {\n    if (rmContext.isWorkPreservingRecoveryEnabled() && !rmContext\n        .isSchedulerReadyForAllocatingContainers()) {\n      return null;\n    }\n\n    // Backward compatible way to make sure previous behavior which allocation\n    // driven by node heartbeat works.\n    FiCaSchedulerNode node = PlacementSetUtils.getSingleNode(ps);\n\n    // We have two different logics to handle allocation on single node / multi\n    // nodes.\n    if (null != node) {\n      return allocateContainerOnSingleNode(ps, node, withNodeHeartbeat);\n    } else {\n      return allocateContainersOnMultiNodes(ps);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersOnMultiNodes": "  private CSAssignment allocateContainersOnMultiNodes(\n      PlacementSet<FiCaSchedulerNode> ps) {\n    // When this time look at multiple nodes, try schedule if the\n    // partition has any available resource or killable resource\n    if (root.getQueueCapacities().getUsedCapacity(ps.getPartition()) >= 1.0f\n        && preemptionManager.getKillableResource(\n        CapacitySchedulerConfiguration.ROOT, ps.getPartition()) == Resources\n        .none()) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"This node or this node partition doesn't have available or\"\n            + \"killable resource\");\n      }\n      return null;\n    }\n\n    return allocateOrReserveNewContainers(ps, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.canAllocateMore": "  private boolean canAllocateMore(CSAssignment assignment, int offswitchCount) {\n    if (null != assignment && Resources.greaterThan(getResourceCalculator(),\n        getClusterResource(), assignment.getResource(), Resources.none())\n        && offswitchCount < offswitchPerHeartbeatLimit) {\n      // And it should not be a reserved container\n      if (assignment.getAssignmentInformation().getNumReservations() == 0) {\n        return true;\n      }\n    }\n\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate": "  protected synchronized void nodeUpdate(RMNode rmNode) {\n    try {\n      readLock.lock();\n      setLastNodeUpdateTime(Time.now());\n      super.nodeUpdate(rmNode);\n    } finally {\n      readLock.unlock();\n    }\n\n    // Try to do scheduling\n    if (!scheduleAsynchronously) {\n      try {\n        writeLock.lock();\n        ActivitiesLogger.NODE.startNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n\n        // reset allocation and reservation stats before we start doing any\n        // work\n        updateSchedulerHealth(lastNodeUpdateTime, rmNode.getNodeID(),\n            CSAssignment.NULL_ASSIGNMENT);\n\n        allocateContainersToNode(rmNode.getNodeID(), true);\n        ActivitiesLogger.NODE.finishNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n      } finally {\n        writeLock.unlock();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent =\n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_LABELS_UPDATE:\n    {\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent =\n          (NodeLabelsUpdateSchedulerEvent) event;\n      \n      updateNodeLabelsAndQueueResource(labelUpdateEvent);\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName = resolveReservationQueueName(appAddedEvent.getQueue(),\n          appAddedEvent.getApplicationId(), appAddedEvent.getReservationID(),\n          appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        if (!appAddedEvent.getIsAppRecovering()) {\n          addApplication(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        } else {\n          addApplicationOnRecovery(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        }\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      if (containerExpiredEvent.isIncrease()) {\n        rollbackContainerResource(containerId);\n      } else {\n        completedContainer(getRMContainer(containerId),\n            SchedulerUtils.createAbnormalContainerStatus(\n                containerId,\n                SchedulerUtils.EXPIRED_CONTAINER),\n            RMContainerEventType.EXPIRE);\n      }\n    }\n    break;\n    case KILL_RESERVED_CONTAINER:\n    {\n      ContainerPreemptEvent killReservedContainerEvent =\n          (ContainerPreemptEvent) event;\n      RMContainer container = killReservedContainerEvent.getContainer();\n      killReservedContainer(container);\n    }\n    break;\n    case MARK_CONTAINER_FOR_PREEMPTION:\n    {\n      ContainerPreemptEvent preemptContainerEvent =\n          (ContainerPreemptEvent)event;\n      ApplicationAttemptId aid = preemptContainerEvent.getAppId();\n      RMContainer containerToBePreempted = preemptContainerEvent.getContainer();\n      markContainerForPreemption(aid, containerToBePreempted);\n    }\n    break;\n    case MARK_CONTAINER_FOR_KILLABLE:\n    {\n      ContainerPreemptEvent containerKillableEvent = (ContainerPreemptEvent)event;\n      RMContainer killableContainer = containerKillableEvent.getContainer();\n      markContainerForKillable(killableContainer);\n    }\n    break;\n    case MARK_CONTAINER_FOR_NONKILLABLE:\n    {\n      if (isLazyPreemptionEnabled) {\n        ContainerPreemptEvent cancelKillContainerEvent =\n            (ContainerPreemptEvent) event;\n        markContainerForNonKillable(cancelKillContainerEvent.getContainer());\n      }\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addNode": "  private void addNode(RMNode nodeManager) {\n    try {\n      writeLock.lock();\n      FiCaSchedulerNode schedulerNode = new FiCaSchedulerNode(nodeManager,\n          usePortForNodeName, nodeManager.getNodeLabels());\n      nodeTracker.addNode(schedulerNode);\n\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.activateNode(nodeManager.getNodeID(),\n            schedulerNode.getTotalResource());\n      }\n\n      Resource clusterResource = getClusterResource();\n      root.updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n\n      LOG.info(\n          \"Added node \" + nodeManager.getNodeAddress() + \" clusterResource: \"\n              + clusterResource);\n\n      if (scheduleAsynchronously && getNumClusterNodes() == 1) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.beginSchedule();\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplication": "  private void addApplication(ApplicationId applicationId,\n      String queueName, String user, Priority priority) {\n    try {\n      writeLock.lock();\n      if (isSystemAppsLimitReached()) {\n        String message = \"Maximum system application limit reached,\"\n            + \"cannot accept submission of application: \" + applicationId;\n        this.rmContext.getDispatcher().getEventHandler().handle(new RMAppEvent(\n            applicationId, RMAppEventType.APP_REJECTED, message));\n        return;\n      }\n      // Sanity checks.\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to unknown queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      if (!(queue instanceof LeafQueue)) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to non-leaf queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        LOG.info(\"Failed to submit application \" + applicationId + \" to queue \"\n            + queueName + \" from user \" + user, ace);\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                ace.toString()));\n        return;\n      }\n      // update the metrics\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeLabelsAndQueueResource": "  private void updateNodeLabelsAndQueueResource(\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent) {\n    try {\n      writeLock.lock();\n      for (Entry<NodeId, Set<String>> entry : labelUpdateEvent\n          .getUpdatedNodeToLabels().entrySet()) {\n        NodeId id = entry.getKey();\n        Set<String> labels = entry.getValue();\n        updateLabelsOnNode(id, labels);\n      }\n      Resource clusterResource = getClusterResource();\n      root.updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplication": "  private void doneApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationId);\n      if (application == null) {\n        // The AppRemovedSchedulerEvent maybe sent on recovery for completed\n        // apps, ignore it.\n        LOG.warn(\"Couldn't find application \" + applicationId);\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\"Cannot finish application \" + \"from non-leaf queue: \" + queue\n            .getQueueName());\n      } else{\n        queue.finishApplication(applicationId, application.getUser());\n      }\n      application.stop(finalState);\n      applications.remove(applicationId);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.resolveReservationQueueName": "  private String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID,\n      boolean isRecovering) {\n    try {\n      readLock.lock();\n      CSQueue queue = getQueue(queueName);\n      // Check if the queue is a plan queue\n      if ((queue == null) || !(queue instanceof PlanQueue)) {\n        return queueName;\n      }\n      if (reservationID != null) {\n        String resQName = reservationID.toString();\n        queue = getQueue(resQName);\n        if (queue == null) {\n          // reservation has terminated during failover\n          if (isRecovering && conf.getMoveOnExpiry(\n              getQueue(queueName).getQueuePath())) {\n            // move to the default child queue of the plan\n            return getDefaultReservationQueueName(queueName);\n          }\n          String message = \"Application \" + applicationId\n              + \" submitted to a reservation which is not currently active: \"\n              + resQName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        if (!queue.getParent().getQueueName().equals(queueName)) {\n          String message =\n              \"Application: \" + applicationId + \" submitted to a reservation \"\n                  + resQName + \" which does not belong to the specified queue: \"\n                  + queueName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        // use the reservation queue to run the app\n        queueName = resQName;\n      } else{\n        // use the default child queue of the plan for unreserved apps\n        queueName = getDefaultReservationQueueName(queueName);\n      }\n      return queueName;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt": "  private void doneApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    try {\n      writeLock.lock();\n      LOG.info(\"Application Attempt \" + applicationAttemptId + \" is done.\"\n          + \" finalState=\" + rmAppAttemptFinalState);\n\n      FiCaSchedulerApp attempt = getApplicationAttempt(applicationAttemptId);\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n\n      if (application == null || attempt == null) {\n        LOG.info(\n            \"Unknown application \" + applicationAttemptId + \" has completed!\");\n        return;\n      }\n\n      // Release all the allocated, acquired, running containers\n      for (RMContainer rmContainer : attempt.getLiveContainers()) {\n        if (keepContainers && rmContainer.getState().equals(\n            RMContainerState.RUNNING)) {\n          // do not kill the running container in the case of work-preserving AM\n          // restart.\n          LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n          continue;\n        }\n        super.completedContainer(rmContainer, SchedulerUtils\n                .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                    SchedulerUtils.COMPLETED_APPLICATION),\n            RMContainerEventType.KILL);\n      }\n\n      // Release all reserved containers\n      for (RMContainer rmContainer : attempt.getReservedContainers()) {\n        super.completedContainer(rmContainer, SchedulerUtils\n            .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                \"Application Complete\"), RMContainerEventType.KILL);\n      }\n\n      // Clean up pending requests, metrics etc.\n      attempt.stop(rmAppAttemptFinalState);\n\n      // Inform the queue\n      String queueName = attempt.getQueue().getQueueName();\n      CSQueue queue = queues.get(queueName);\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\n            \"Cannot finish application \" + \"from non-leaf queue: \" + queueName);\n      } else{\n        queue.finishApplicationAttempt(attempt, queue.getQueueName());\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationOnRecovery": "  private void addApplicationOnRecovery(\n      ApplicationId applicationId, String queueName, String user,\n      Priority priority) {\n    try {\n      writeLock.lock();\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        //During a restart, this indicates a queue was removed, which is\n        //not presently supported\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName + \" which no longer exists after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" missing during application recovery.\"\n              + \" Queue removal during recovery is not presently \"\n              + \"supported by the capacity scheduler, please \"\n              + \"restart with all queues configured\"\n              + \" which were present before shutdown/restart.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      if (!(queue instanceof LeafQueue)) {\n        // During RM restart, this means leaf queue was converted to a parent\n        // queue, which is not supported for running apps.\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName\n                      + \" which is no longer a leaf queue after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" is no longer a leaf queue during application recovery.\"\n              + \" Changing a leaf queue to a parent queue during recovery is\"\n              + \" not presently supported by the capacity scheduler. Please\"\n              + \" restart with leaf queues before shutdown/restart continuing\"\n              + \" as leaf queues.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        // Ignore the exception for recovered app as the app was previously\n        // accepted.\n      }\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForKillable": "  public void markContainerForKillable(\n      RMContainer killableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE + \": container\"\n            + killableContainer.toString());\n      }\n\n      if (!isLazyPreemptionEnabled) {\n        super.completedContainer(killableContainer, SchedulerUtils\n            .createPreemptedContainerStatus(killableContainer.getContainerId(),\n                SchedulerUtils.PREEMPTED_CONTAINER), RMContainerEventType.KILL);\n      } else{\n        FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n            killableContainer.getAllocatedNode());\n\n        FiCaSchedulerApp application = getCurrentAttemptForContainer(\n            killableContainer.getContainerId());\n\n        node.markContainerToKillable(killableContainer.getContainerId());\n\n        // notify PreemptionManager\n        // Get the application for the finished container\n        if (null != application) {\n          String leafQueueName = application.getCSLeafQueue().getQueueName();\n          getPreemptionManager().addKillableContainer(\n              new KillableContainer(killableContainer, node.getPartition(),\n                  leafQueueName));\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForNonKillable": "  private void markContainerForNonKillable(\n      RMContainer nonKillableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            SchedulerEventType.MARK_CONTAINER_FOR_NONKILLABLE + \": container\"\n                + nonKillableContainer.toString());\n      }\n\n      FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n          nonKillableContainer.getAllocatedNode());\n\n      FiCaSchedulerApp application = getCurrentAttemptForContainer(\n          nonKillableContainer.getContainerId());\n\n      node.markContainerToNonKillable(nonKillableContainer.getContainerId());\n\n      // notify PreemptionManager\n      // Get the application for the finished container\n      if (null != application) {\n        String leafQueueName = application.getCSLeafQueue().getQueueName();\n        getPreemptionManager().removeKillableContainer(\n            new KillableContainer(nonKillableContainer, node.getPartition(),\n                leafQueueName));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForPreemption": "  public void markContainerForPreemption(ApplicationAttemptId aid,\n      RMContainer cont) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION\n            + \": appAttempt:\" + aid.toString() + \" container: \"\n            + cont.toString());\n    }\n    FiCaSchedulerApp app = getApplicationAttempt(aid);\n    if (app != null) {\n      app.markContainerForPreemption(cont.getContainerId());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeAndQueueResource": "  private void updateNodeAndQueueResource(RMNode nm,\n      ResourceOption resourceOption) {\n    try {\n      writeLock.lock();\n      updateNodeResource(nm, resourceOption);\n      Resource clusterResource = getClusterResource();\n      root.updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.killReservedContainer": "  public void killReservedContainer(RMContainer container) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.KILL_RESERVED_CONTAINER + \":\"\n          + container.toString());\n    }\n    // To think: What happens if this is no longer a reserved container, for\n    // e.g if the reservation became an allocation.\n    super.completedContainer(container,\n        SchedulerUtils.createAbnormalContainerStatus(\n            container.getContainerId(),\n            SchedulerUtils.UNRESERVED_CONTAINER),\n        RMContainerEventType.KILL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n      if (application == null) {\n        LOG.warn(\"Application \" + applicationAttemptId.getApplicationId()\n            + \" cannot be found in scheduler.\");\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n\n      FiCaSchedulerApp attempt = new FiCaSchedulerApp(applicationAttemptId,\n          application.getUser(), queue, queue.getActiveUsersManager(),\n          rmContext, application.getPriority(), isAttemptRecovering,\n          activitiesManager);\n      if (transferStateFromPreviousAttempt) {\n        attempt.transferStateFromPreviousAttempt(\n            application.getCurrentAppAttempt());\n      }\n      application.setCurrentAppAttempt(attempt);\n\n      // Update attempt priority to the latest to avoid race condition i.e\n      // SchedulerApplicationAttempt is created with old priority but it is not\n      // set to SchedulerApplication#setCurrentAppAttempt.\n      // Scenario would occur is\n      // 1. SchdulerApplicationAttempt is created with old priority.\n      // 2. updateApplicationPriority() updates SchedulerApplication. Since\n      // currentAttempt is null, it just return.\n      // 3. ScheduelerApplcationAttempt is set in\n      // SchedulerApplication#setCurrentAppAttempt.\n      attempt.setPriority(application.getPriority());\n\n      queue.submitApplicationAttempt(attempt, application.getUser());\n      LOG.info(\"Added Application Attempt \" + applicationAttemptId\n          + \" to scheduler from user \" + application.getUser() + \" in queue \"\n          + queue.getQueueName());\n      if (isAttemptRecovering) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(applicationAttemptId\n              + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n        }\n      } else{\n        rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppAttemptEvent(applicationAttemptId,\n                RMAppAttemptEventType.ATTEMPT_ADDED));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.removeNode": "  private void removeNode(RMNode nodeInfo) {\n    try {\n      writeLock.lock();\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.deactivateNode(nodeInfo.getNodeID());\n      }\n\n      NodeId nodeId = nodeInfo.getNodeID();\n      FiCaSchedulerNode node = nodeTracker.getNode(nodeId);\n      if (node == null) {\n        LOG.error(\"Attempting to remove non-existent node \" + nodeId);\n        return;\n      }\n\n      // Remove running containers\n      List<RMContainer> runningContainers =\n          node.getCopiedListOfRunningContainers();\n      for (RMContainer container : runningContainers) {\n        super.completedContainer(container, SchedulerUtils\n            .createAbnormalContainerStatus(container.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      // Remove reservations, if any\n      RMContainer reservedContainer = node.getReservedContainer();\n      if (reservedContainer != null) {\n        super.completedContainer(reservedContainer, SchedulerUtils\n            .createAbnormalContainerStatus(reservedContainer.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      nodeTracker.removeNode(nodeId);\n      Resource clusterResource = getClusterResource();\n      root.updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n      int numNodes = nodeTracker.nodeCount();\n\n      if (scheduleAsynchronously && numNodes == 0) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.suspendSchedule();\n        }\n      }\n\n      LOG.info(\n          \"Removed node \" + nodeInfo.getNodeAddress() + \" clusterResource: \"\n              + getClusterResource());\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.rollbackContainerResource": "  private void rollbackContainerResource(\n      ContainerId containerId) {\n    RMContainer rmContainer = getRMContainer(containerId);\n    if (rmContainer == null) {\n      LOG.info(\"Cannot rollback resource for container \" + containerId\n          + \". The container does not exist.\");\n      return;\n    }\n    FiCaSchedulerApp application = getCurrentAttemptForContainer(containerId);\n    if (application == null) {\n      LOG.info(\"Cannot rollback resource for container \" + containerId\n          + \". The application that the container \"\n          + \"belongs to does not exist.\");\n      return;\n    }\n    LOG.info(\"Roll back resource for container \" + containerId);\n\n    SchedulerNode schedulerNode = getSchedulerNode(\n        rmContainer.getAllocatedNode());\n    SchedContainerChangeRequest decreaseRequest =\n        new SchedContainerChangeRequest(this.rmContext, schedulerNode,\n            rmContainer, rmContainer.getLastConfirmedResource());\n    decreaseContainer(decreaseRequest, application);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.EventDispatcher.run": "    public void run() {\n\n      T event;\n\n      while (!stopped && !Thread.currentThread().isInterrupted()) {\n        try {\n          event = eventQueue.take();\n        } catch (InterruptedException e) {\n          LOG.error(\"Returning, interrupted : \" + e);\n          return; // TODO: Kill RM.\n        }\n\n        try {\n          handler.handle(event);\n        } catch (Throwable t) {\n          // An error occurred, but we are shutting down anyway.\n          // If it was an InterruptedException, the very act of\n          // shutdown could have caused it and is probably harmless.\n          if (stopped) {\n            LOG.warn(\"Exception during shutdown: \", t);\n            break;\n          }\n          LOG.fatal(\"Error in handling event type \" + event.getType()\n              + \" to the Event Dispatcher\", t);\n          if (shouldExitOnError\n              && !ShutdownHookManager.get().isShutdownInProgress()) {\n            LOG.info(\"Exiting, bbye..\");\n            System.exit(-1);\n          }\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.EventDispatcher.handle": "  public void handle(T event) {\n    try {\n      int qSize = eventQueue.size();\n      if (qSize !=0 && qSize %1000 == 0) {\n        LOG.info(\"Size of \" + getName() + \" event-queue is \" + qSize);\n      }\n      int remCapacity = eventQueue.remainingCapacity();\n      if (remCapacity < 1000) {\n        LOG.info(\"Very low remaining capacity on \" + getName() + \"\" +\n            \"event queue: \" + remCapacity);\n      }\n      this.eventQueue.put(event);\n    } catch (InterruptedException e) {\n      LOG.info(\"Interrupted. Trying to exit gracefully.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.ContainerAllocation.getAllocationState": "  public AllocationState getAllocationState() {\n    return state;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getSkippedType": "  public SkippedType getSkippedType() {\n    return skipped;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getResource": "  public Resource getResource() {\n    return resource;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.getType": "  public NodeType getType() {\n    return type;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n\n  public PrivilegedEntity getPrivilegedEntity();\n\n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Set used capacity of the queue.\n   * @param usedCapacity\n   *          used capacity of the queue\n   */\n  public void setUsedCapacity(float usedCapacity);\n\n  /**\n   * Set absolute used capacity of the queue.\n   * @param absUsedCapacity\n   *          absolute used capacity of the queue\n   */\n  public void setAbsoluteUsedCapacity(float absUsedCapacity);\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param ps {@link PlacementSet} of nodes which resources are available",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.setSchedulingMode": "  public void setSchedulingMode(SchedulingMode schedulingMode) {\n    this.schedulingMode = schedulingMode;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getParent": "  public CSQueue getParent();\n\n  /**\n   * Set the parent <code>Queue</code>.\n   * @param newParentQueue new parent queue\n   */\n  public void setParent(CSQueue newParentQueue);\n\n  /**\n   * Get the queue name.\n   * @return the queue name\n   */\n  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n\n  public PrivilegedEntity getPrivilegedEntity();\n\n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Set used capacity of the queue.\n   * @param usedCapacity\n   *          used capacity of the queue\n   */\n  public void setUsedCapacity(float usedCapacity);\n\n  /**\n   * Set absolute used capacity of the queue.\n   * @param absUsedCapacity\n   *          absolute used capacity of the queue\n   */\n  public void setAbsoluteUsedCapacity(float absUsedCapacity);\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param ps {@link PlacementSet} of nodes which resources are available",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.assignContainers": "  CSAssignment assignContainers(Resource clusterResource,\n      FiCaSchedulerNode node, ResourceLimits resourceLimits,\n      SchedulingMode schedulingMode);\n\n  boolean accept(Resource cluster,\n      ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request);\n\n  void apply(Resource cluster,\n      ResourceCommitRequest<FiCaSchedulerApp, FiCaSchedulerNode> request);\n\n  /**\n   * Get readLock associated with the Queue.\n   * @return readLock of corresponding queue.\n   */\n  public ReentrantReadWriteLock.ReadLock getReadLock();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSAssignment.isFulfilledReservation": "  public boolean isFulfilledReservation() {\n    return this.fulfilledReservation;\n  }"
        },
        "bug_report": {
            "Title": "RM crashes with NPE if generic application history is enabled",
            "Description": "{noformat}\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerStartEvent.hashCode(WritingContainerStartEvent.java:38)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$MultiThreadedDispatcher$CompositEventHandler.handle(RMApplicationHistoryWriter.java:354)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.containerStarted(RMApplicationHistoryWriter.java:278)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:251)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:217)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:210)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate(FiCaSchedulerApp.java:227)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.handleNewContainerAllocation(RegularContainerAllocator.java:704)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.doAllocation(RegularContainerAllocator.java:746)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.allocate(RegularContainerAllocator.java:832)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.assignContainers(RegularContainerAllocator.java:865)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.ContainerAllocator.assignContainers(ContainerAllocator.java:81)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.assignContainers(FiCaSchedulerApp.java:931)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:1044)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:690)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:508)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers(CapacityScheduler.java:1475)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode(CapacityScheduler.java:1470)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1559)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1346)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:1221)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1601)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:149)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:745)\n2016-11-12 14:22:07,153 INFO SchedulerEventDispatcher:Event Processor org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:79) org.apache.hadoop.yarn.event.EventDispatcher: Exiting, bbye..\n{noformat}"
        }
    },
    {
        "filename": "YARN-3227.json",
        "creation_time": "2015-02-19T16:58:01.000+0000",
        "stack_trace": "```\njava.io.IOException: Failed to renew token: Kind: TIMELINE_DELEGATION_TOKEN,\nService: timelineserver.example.com:4080, Ident: (owner=user,\nrenewer=rmuser, realUser=oozie, issueDate=1423248845528,\nmaxDate=1423853645528, sequenceNumber=9716, masterKeyId=9)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.handleAppSubmitEvent(DelegationTokenRenewer.java:443)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.access$800(DelegationTokenRenewer.java:77)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.handleDTRenewerAppSubmitEvent(DelegationTokenRenewer.java:808)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.run(DelegationTokenRenewer.java:789)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\nCaused by: java.io.IOException: HTTP status [401], message [Unauthorized]\n        at org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:169)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.doDelegationTokenOperation(DelegationTokenAuthenticator.java:286)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.renewDelegationToken(DelegationTokenAuthenticator.java:211)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.renewDelegationToken(DelegationTokenAuthenticatedURL.java:414)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$2.run(TimelineClientImpl.java:374)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$2.run(TimelineClientImpl.java:360)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$4.run(TimelineClientImpl.java:429)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$TimelineClientConnectionRetry.retryOn(TimelineClientImpl.java:161)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.operateDelegationToken(TimelineClientImpl.java:444)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.renewDelegationToken(TimelineClientImpl.java:378)\n        at org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier$Renewer.renew(TimelineDelegationTokenIdentifier.java:81)\n        at org.apache.hadoop.security.token.Token.renew(Token.java:377)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:532)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:529)\n```",
        "source_code": {
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.DelegationTokenRenewer.run": "  public void run() {\n    for(;;) {\n      RenewAction<?> action = null;\n      try {\n        action = queue.take();\n        if (action.renew()) {\n          queue.add(action);\n        }\n      } catch (InterruptedException ie) {\n        return;\n      } catch (Exception ie) {\n        action.weakFs.get().LOG.warn(\"Failed to renew token, action=\" + action,\n            ie);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.fs.DelegationTokenRenewer.renew": "    private boolean renew() throws IOException, InterruptedException {\n      final T fs = weakFs.get();\n      final boolean b = fs != null;\n      if (b) {\n        synchronized(fs) {\n          try {\n            long expires = token.renew(fs.getConf());\n            updateRenewalTime(expires - Time.now());\n          } catch (IOException ie) {\n            try {\n              Token<?>[] tokens = fs.addDelegationTokens(null, null);\n              if (tokens.length == 0) {\n                throw new IOException(\"addDelegationTokens returned no tokens\");\n              }\n              token = tokens[0];\n              updateRenewalTime(renewCycle);\n              fs.setDelegationToken(token);\n            } catch (IOException ie2) {\n              isValid = false;\n              throw new IOException(\"Can't renew or get new delegation token \", ie);\n            }\n          }\n        }\n      }\n      return b;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.HttpExceptionUtils.validateResponse": "  public static void validateResponse(HttpURLConnection conn,\n      int expectedStatus) throws IOException {\n    if (conn.getResponseCode() != expectedStatus) {\n      Exception toThrow;\n      InputStream es = null;\n      try {\n        es = conn.getErrorStream();\n        ObjectMapper mapper = new ObjectMapper();\n        Map json = mapper.readValue(es, Map.class);\n        json = (Map) json.get(ERROR_JSON);\n        String exClass = (String) json.get(ERROR_CLASSNAME_JSON);\n        String exMsg = (String) json.get(ERROR_MESSAGE_JSON);\n        if (exClass != null) {\n          try {\n            ClassLoader cl = HttpExceptionUtils.class.getClassLoader();\n            Class klass = cl.loadClass(exClass);\n            Constructor constr = klass.getConstructor(String.class);\n            toThrow = (Exception) constr.newInstance(exMsg);\n          } catch (Exception ex) {\n            toThrow = new IOException(String.format(\n                \"HTTP status [%d], exception [%s], message [%s] \",\n                conn.getResponseCode(), exClass, exMsg));\n          }\n        } else {\n          String msg = (exMsg != null) ? exMsg : conn.getResponseMessage();\n          toThrow = new IOException(String.format(\n              \"HTTP status [%d], message [%s]\", conn.getResponseCode(), msg));\n        }\n      } catch (Exception ex) {\n        toThrow = new IOException(String.format(\n            \"HTTP status [%d], message [%s]\", conn.getResponseCode(),\n            conn.getResponseMessage()));\n      } finally {\n        if (es != null) {\n          try {\n            es.close();\n          } catch (IOException ex) {\n            //ignore\n          }\n        }\n      }\n      throwEx(toThrow);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.HttpExceptionUtils.throwEx": "  private static void throwEx(Throwable ex) {\n    HttpExceptionUtils.<RuntimeException>throwException(ex);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.doDelegationTokenOperation": "  private Map doDelegationTokenOperation(URL url,\n      AuthenticatedURL.Token token, DelegationTokenOperation operation,\n      String renewer, Token<?> dToken, boolean hasResponse, String doAsUser)\n      throws IOException, AuthenticationException {\n    Map ret = null;\n    Map<String, String> params = new HashMap<String, String>();\n    params.put(OP_PARAM, operation.toString());\n    if (renewer != null) {\n      params.put(RENEWER_PARAM, renewer);\n    }\n    if (dToken != null) {\n      params.put(TOKEN_PARAM, dToken.encodeToUrlString());\n    }\n    // proxyuser\n    if (doAsUser != null) {\n      params.put(DelegationTokenAuthenticatedURL.DO_AS,\n          URLEncoder.encode(doAsUser, \"UTF-8\"));\n    }\n    String urlStr = url.toExternalForm();\n    StringBuilder sb = new StringBuilder(urlStr);\n    String separator = (urlStr.contains(\"?\")) ? \"&\" : \"?\";\n    for (Map.Entry<String, String> entry : params.entrySet()) {\n      sb.append(separator).append(entry.getKey()).append(\"=\").\n          append(URLEncoder.encode(entry.getValue(), \"UTF8\"));\n      separator = \"&\";\n    }\n    url = new URL(sb.toString());\n    AuthenticatedURL aUrl = new AuthenticatedURL(this, connConfigurator);\n    HttpURLConnection conn = aUrl.openConnection(url, token);\n    conn.setRequestMethod(operation.getHttpMethod());\n    HttpExceptionUtils.validateResponse(conn, HttpURLConnection.HTTP_OK);\n    if (hasResponse) {\n      String contentType = conn.getHeaderField(CONTENT_TYPE);\n      contentType = (contentType != null) ?\n          contentType.toLowerCase(Locale.ENGLISH) : null;\n      if (contentType != null &&\n          contentType.contains(APPLICATION_JSON_MIME)) {\n        try {\n          ObjectMapper mapper = new ObjectMapper();\n          ret = mapper.readValue(conn.getInputStream(), Map.class);\n        } catch (Exception ex) {\n          throw new AuthenticationException(String.format(\n              \"'%s' did not handle the '%s' delegation token operation: %s\",\n              url.getAuthority(), operation, ex.getMessage()), ex);\n        }\n      } else {\n        throw new AuthenticationException(String.format(\"'%s' did not \" +\n                \"respond with JSON to the '%s' delegation token operation\",\n            url.getAuthority(), operation));\n      }\n    }\n    return ret;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.getHttpMethod": "    public String getHttpMethod() {\n      return httpMethod;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.renewDelegationToken": "  public long renewDelegationToken(URL url,\n      AuthenticatedURL.Token token,\n      Token<AbstractDelegationTokenIdentifier> dToken, String doAsUser)\n      throws IOException, AuthenticationException {\n    Map json = doDelegationTokenOperation(url, token,\n        DelegationTokenOperation.RENEWDELEGATIONTOKEN, null, dToken, true,\n        doAsUser);\n    return (Long) json.get(RENEW_DELEGATION_TOKEN_JSON);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.renewDelegationToken": "  public long renewDelegationToken(URL url, Token token, String doAsUser)\n      throws IOException, AuthenticationException {\n    Preconditions.checkNotNull(url, \"url\");\n    Preconditions.checkNotNull(token, \"token\");\n    Preconditions.checkNotNull(token.delegationToken,\n        \"No delegation token available\");\n    try {\n      return ((KerberosDelegationTokenAuthenticator) getAuthenticator()).\n          renewDelegationToken(url, token, token.delegationToken, doAsUser);\n    } catch (IOException ex) {\n      token.delegationToken = null;\n      throw ex;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.run": "          public HttpURLConnection run() throws Exception {\n            return new DelegationTokenAuthenticatedURL(\n                authenticator, connConfigurator).openConnection(url, token,\n                doAsUser);\n          }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.getDelegationToken": "  public Token<TimelineDelegationTokenIdentifier> getDelegationToken(\n      final String renewer) throws IOException, YarnException {\n    boolean isProxyAccess =\n        UserGroupInformation.getCurrentUser().getAuthenticationMethod()\n        == UserGroupInformation.AuthenticationMethod.PROXY;\n    final String doAsUser = isProxyAccess ?\n        UserGroupInformation.getCurrentUser().getShortUserName() : null;\n    PrivilegedExceptionAction<Token<TimelineDelegationTokenIdentifier>> getDTAction =\n        new PrivilegedExceptionAction<Token<TimelineDelegationTokenIdentifier>>() {\n\n          @Override\n          public Token<TimelineDelegationTokenIdentifier> run()\n              throws Exception {\n            DelegationTokenAuthenticatedURL authUrl =\n                new DelegationTokenAuthenticatedURL(authenticator,\n                    connConfigurator);\n            return (Token) authUrl.getDelegationToken(\n                resURI.toURL(), token, renewer, doAsUser);\n          }\n        };\n    return (Token<TimelineDelegationTokenIdentifier>) operateDelegationToken(getDTAction);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.cancelDelegationToken": "  public void cancelDelegationToken(\n      final Token<TimelineDelegationTokenIdentifier> timelineDT)\n          throws IOException, YarnException {\n    boolean isProxyAccess =\n        UserGroupInformation.getCurrentUser().getAuthenticationMethod()\n        == UserGroupInformation.AuthenticationMethod.PROXY;\n    final String doAsUser = isProxyAccess ?\n        UserGroupInformation.getCurrentUser().getShortUserName() : null;\n    boolean useHttps = YarnConfiguration.useHttps(this.getConfig());\n    final String scheme = useHttps ? \"https\" : \"http\";\n    final InetSocketAddress address = SecurityUtil.getTokenServiceAddr(timelineDT);\n    PrivilegedExceptionAction<Void> cancelDTAction =\n        new PrivilegedExceptionAction<Void>() {\n\n          @Override\n          public Void run() throws Exception {\n            // If the timeline DT to cancel is different than cached, replace it.\n            // Token to set every time for retry, because when exception happens,\n            // DelegationTokenAuthenticatedURL will reset it to null;\n            if (!timelineDT.equals(token.getDelegationToken())) {\n              token.setDelegationToken((Token) timelineDT);\n            }\n            DelegationTokenAuthenticatedURL authUrl =\n                new DelegationTokenAuthenticatedURL(authenticator,\n                    connConfigurator);\n            final URI serviceURI = new URI(scheme, null, address.getHostName(),\n                address.getPort(), RESOURCE_URI_STR, null, null);\n            authUrl.cancelDelegationToken(serviceURI.toURL(), token, doAsUser);\n            return null;\n          }\n        };\n    operateDelegationToken(cancelDTAction);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.handle": "    public ClientResponse handle(final ClientRequest cr)\n        throws ClientHandlerException {\n      // Set up the retry operation\n      TimelineClientRetryOp jerseyRetryOp = new TimelineClientRetryOp() {\n        @Override\n        public Object run() {\n          // Try pass the request, if fail, keep retrying\n          return getNext().handle(cr);\n        }\n\n        @Override\n        public boolean shouldRetryOn(Exception e) {\n          // Only retry on connection exceptions\n          return (e instanceof ClientHandlerException)\n              && (e.getCause() instanceof ConnectException);\n        }\n      };\n      try {\n        return (ClientResponse) connectionRetry.retryOn(jerseyRetryOp);\n      } catch (IOException e) {\n        throw new ClientHandlerException(\"Jersey retry failed!\\nMessage: \"\n              + e.getMessage());\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.renewDelegationToken": "  public long renewDelegationToken(\n      final Token<TimelineDelegationTokenIdentifier> timelineDT)\n          throws IOException, YarnException {\n    boolean isProxyAccess =\n        UserGroupInformation.getCurrentUser().getAuthenticationMethod()\n        == UserGroupInformation.AuthenticationMethod.PROXY;\n    final String doAsUser = isProxyAccess ?\n        UserGroupInformation.getCurrentUser().getShortUserName() : null;\n    boolean useHttps = YarnConfiguration.useHttps(this.getConfig());\n    final String scheme = useHttps ? \"https\" : \"http\";\n    final InetSocketAddress address = SecurityUtil.getTokenServiceAddr(timelineDT);\n    PrivilegedExceptionAction<Long> renewDTAction =\n        new PrivilegedExceptionAction<Long>() {\n\n          @Override\n          public Long run() throws Exception {\n            // If the timeline DT to renew is different than cached, replace it.\n            // Token to set every time for retry, because when exception happens,\n            // DelegationTokenAuthenticatedURL will reset it to null;\n            if (!timelineDT.equals(token.getDelegationToken())) {\n              token.setDelegationToken((Token) timelineDT);\n            }\n            DelegationTokenAuthenticatedURL authUrl =\n                new DelegationTokenAuthenticatedURL(authenticator,\n                    connConfigurator);\n            final URI serviceURI = new URI(scheme, null, address.getHostName(),\n                address.getPort(), RESOURCE_URI_STR, null, null);\n            return authUrl\n                .renewDelegationToken(serviceURI.toURL(), token, doAsUser);\n          }\n        };\n    return (Long) operateDelegationToken(renewDTAction);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.retryOn": "    public Object retryOn(TimelineClientRetryOp op)\n        throws RuntimeException, IOException {\n      int leftRetries = maxRetries;\n      retried = false;\n\n      // keep trying\n      while (true) {\n        try {\n          // try perform the op, if fail, keep retrying\n          return op.run();\n        } catch (IOException | RuntimeException e) {\n          // break if there's no retries left\n          if (leftRetries == 0) {\n            break;\n          }\n          if (op.shouldRetryOn(e)) {\n            logException(e, leftRetries);\n          } else {\n            throw e;\n          }\n        }\n        if (leftRetries > 0) {\n          leftRetries--;\n        }\n        retried = true;\n        try {\n          // sleep for the given time interval\n          Thread.sleep(retryInterval);\n        } catch (InterruptedException ie) {\n          LOG.warn(\"Client retry sleep interrupted! \");\n        }\n      }\n      throw new RuntimeException(\"Failed to connect to timeline server. \"\n          + \"Connection retries limit exceeded. \"\n          + \"The posted timeline event may be missing\");\n    };",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.shouldRetryOn": "      public boolean shouldRetryOn(Exception e) {\n        // Only retry on connection exceptions\n        return (e instanceof ConnectException);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.logException": "    private void logException(Exception e, int leftRetries) {\n      if (leftRetries > 0) {\n        LOG.info(\"Exception caught by TimelineClientConnectionRetry,\"\n              + \" will try \" + leftRetries + \" more time(s).\\nMessage: \"\n              + e.getMessage());\n      } else {\n        // note that maxRetries may be -1 at the very beginning\n        LOG.info(\"ConnectionException caught by TimelineClientConnectionRetry,\"\n            + \" will keep retrying.\\nMessage: \"\n            + e.getMessage());\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.operateDelegationToken": "  private Object operateDelegationToken(\n      final PrivilegedExceptionAction<?> action)\n      throws IOException, YarnException {\n    // Set up the retry operation\n    TimelineClientRetryOp tokenRetryOp = new TimelineClientRetryOp() {\n\n      @Override\n      public Object run() throws IOException {\n        // Try pass the request, if fail, keep retrying\n        boolean isProxyAccess =\n            UserGroupInformation.getCurrentUser().getAuthenticationMethod()\n            == UserGroupInformation.AuthenticationMethod.PROXY;\n        UserGroupInformation callerUGI = isProxyAccess ?\n            UserGroupInformation.getCurrentUser().getRealUser()\n            : UserGroupInformation.getCurrentUser();\n        try {\n          return callerUGI.doAs(action);\n        } catch (UndeclaredThrowableException e) {\n          throw new IOException(e.getCause());\n        } catch (InterruptedException e) {\n          throw new IOException(e);\n        }\n      }\n\n      @Override\n      public boolean shouldRetryOn(Exception e) {\n        // Only retry on connection exceptions\n        return (e instanceof ConnectException);\n      }\n    };\n\n    return connectionRetry.retryOn(tokenRetryOp);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier.renew": "    public long renew(Token<?> token, Configuration conf) throws IOException,\n        InterruptedException {\n      TimelineClient client = TimelineClient.createTimelineClient();\n      try {\n        client.init(conf);\n        client.start();\n        return client.renewDelegationToken(\n            (Token<TimelineDelegationTokenIdentifier>) token);\n      } catch (YarnException e) {\n        throw new IOException(e);\n      } finally {\n        client.stop();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.Token.renew": "    public long renew(Token<?> token, Configuration conf) {\n      throw new UnsupportedOperationException(\"Token renewal is not supported \"+\n                                              \" for \" + token.kind + \" tokens\");\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.token.Token.getRenewer": "  private synchronized TokenRenewer getRenewer() throws IOException {\n    if (renewer != null) {\n      return renewer;\n    }\n    renewer = TRIVIAL_RENEWER;\n    synchronized (renewers) {\n      for (TokenRenewer canidate : renewers) {\n        if (canidate.handleKind(this.kind)) {\n          renewer = canidate;\n          return renewer;\n        }\n      }\n    }\n    LOG.warn(\"No TokenRenewer defined for token kind \" + this.kind);\n    return renewer;\n  }"
        },
        "bug_report": {
            "Title": "Timeline renew delegation token fails when RM user's TGT is expired",
            "Description": "When the RM user's kerberos TGT is expired, the RM renew delegation token operation fails as part of job submission. Expected behavior is that RM will relogin to get a new TGT.\n\n{quote}\n2015-02-06 18:54:05,617 [DelegationTokenRenewer #25954] WARN\nsecurity.DelegationTokenRenewer: Unable to add the application to the\ndelegation token renewer.\njava.io.IOException: Failed to renew token: Kind: TIMELINE_DELEGATION_TOKEN,\nService: timelineserver.example.com:4080, Ident: (owner=user,\nrenewer=rmuser, realUser=oozie, issueDate=1423248845528,\nmaxDate=1423853645528, sequenceNumber=9716, masterKeyId=9)\n        at\norg.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.handleAppSubmitEvent(DelegationTokenRenewer.java:443)\n        at\norg.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.access$800(DelegationTokenRenewer.java:77)\n        at\norg.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.handleDTRenewerAppSubmitEvent(DelegationTokenRenewer.java:808)\n        at\norg.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.run(DelegationTokenRenewer.java:789)\n        at\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\nCaused by: java.io.IOException: HTTP status [401], message [Unauthorized]\n        at\norg.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:169)\n        at\norg.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.doDelegationTokenOperation(DelegationTokenAuthenticator.java:286)\n        at\norg.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.renewDelegationToken(DelegationTokenAuthenticator.java:211)\n        at\norg.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.renewDelegationToken(DelegationTokenAuthenticatedURL.java:414)\n        at\norg.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$2.run(TimelineClientImpl.java:374)\n        at\norg.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$2.run(TimelineClientImpl.java:360)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at\norg.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)\n        at\norg.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$4.run(TimelineClientImpl.java:429)\n        at\norg.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$TimelineClientConnectionRetry.retryOn(TimelineClientImpl.java:161)\n        at\norg.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.operateDelegationToken(TimelineClientImpl.java:444)\n        at\norg.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.renewDelegationToken(TimelineClientImpl.java:378)\n        at\norg.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier$Renewer.renew(TimelineDelegationTokenIdentifier.java:81)\n        at org.apache.hadoop.security.token.Token.renew(Token.java:377)\n        at\norg.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:532)\n        at\norg.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:529)\n{quote}"
        }
    },
    {
        "filename": "YARN-4235.json",
        "creation_time": "2015-10-07T19:26:24.000+0000",
        "stack_trace": "```\njava.lang.IndexOutOfBoundsException: Index: 0\n\tat java.util.Collections$EmptyList.get(Collections.java:3212)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule$PrimaryGroup.getQueueForApp(QueuePlacementRule.java:149)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule.assignAppToQueue(QueuePlacementRule.java:74)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementPolicy.assignAppToQueue(QueuePlacementPolicy.java:167)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.assignToQueue(FairScheduler.java:689)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication(FairScheduler.java:595)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1180)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:111)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule.getQueueForApp": "    protected String getQueueForApp(String requestedQueue, String user,\n        Groups groups, Map<FSQueueType, Set<String>> configuredQueues) {\n      throw new UnsupportedOperationException();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule.assignAppToQueue": "    public String assignAppToQueue(String requestedQueue, String user,\n        Groups groups, Map<FSQueueType, Set<String>> configuredQueues) {\n      return null;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule.cleanName": "  protected String cleanName(String name) {\n    name = name.trim();\n    if (name.contains(\".\")) {\n      String converted = name.replaceAll(\"\\\\.\", \"_dot_\");\n      LOG.warn(\"Name \" + name + \" is converted to \" + converted\n          + \" when it is used as a queue name.\");\n      return converted;\n    } else {\n      return name;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementPolicy.assignAppToQueue": "  public String assignAppToQueue(String requestedQueue, String user)\n      throws IOException {\n    for (QueuePlacementRule rule : rules) {\n      String queue = rule.assignAppToQueue(requestedQueue, user, groups,\n          configuredQueues);\n      if (queue == null || !queue.isEmpty()) {\n        return queue;\n      }\n    }\n    throw new IllegalStateException(\"Should have applied a rule before \" +\n    \t\t\"reaching here\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.assignToQueue": "  FSLeafQueue assignToQueue(RMApp rmApp, String queueName, String user) {\n    FSLeafQueue queue = null;\n    String appRejectMsg = null;\n\n    try {\n      QueuePlacementPolicy placementPolicy = allocConf.getPlacementPolicy();\n      queueName = placementPolicy.assignAppToQueue(queueName, user);\n      if (queueName == null) {\n        appRejectMsg = \"Application rejected by queue placement policy\";\n      } else {\n        queue = queueMgr.getLeafQueue(queueName, true);\n        if (queue == null) {\n          appRejectMsg = queueName + \" is not a leaf queue\";\n        }\n      }\n    } catch (InvalidQueueNameException qne) {\n      appRejectMsg = qne.getMessage();\n    } catch (IOException ioe) {\n      appRejectMsg = \"Error assigning app to queue \" + queueName;\n    }\n\n    if (appRejectMsg != null && rmApp != null) {\n      LOG.error(appRejectMsg);\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppRejectedEvent(rmApp.getApplicationId(), appRejectMsg));\n      return null;\n    }\n\n    if (rmApp != null) {\n      rmApp.setQueue(queue.getName());\n    } else {\n      LOG.error(\"Couldn't find RM app to set queue name on\");\n    }\n    return queue;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getContainerReports(),\n          nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName, appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n      break;\n    case NODE_RESOURCE_UPDATE:\n      if (!(event instanceof NodeResourceUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeResource(nodeResourceUpdatedEvent.getRMNode(),\n            nodeResourceUpdatedEvent.getResourceOption());\n      break;\n    case APP_ATTEMPT_ADDED:\n      if (!(event instanceof AppAttemptAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n      break;\n    case APP_ATTEMPT_REMOVED:\n      if (!(event instanceof AppAttemptRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      removeApplicationAttempt(\n          appAttemptRemovedEvent.getApplicationAttemptID(),\n          appAttemptRemovedEvent.getFinalAttemptState(),\n          appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    case CONTAINER_RESCHEDULED:\n      if (!(event instanceof ContainerRescheduledEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerRescheduledEvent containerRescheduledEvent =\n          (ContainerRescheduledEvent) event;\n      RMContainer container = containerRescheduledEvent.getContainer();\n      recoverResourceRequestForContainer(container);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected synchronized void addApplication(ApplicationId applicationId,\n      String queueName, String user, boolean isAppRecovering) {\n    if (queueName == null || queueName.isEmpty()) {\n      String message = \"Reject application \" + applicationId +\n              \" submitted by user \" + user + \" with an empty queue name.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n\n    if (queueName.startsWith(\".\") || queueName.endsWith(\".\")) {\n      String message = \"Reject application \" + applicationId\n          + \" submitted by user \" + user + \" with an illegal queue name \"\n          + queueName + \". \"\n          + \"The queue name cannot start/end with period.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, message));\n      return;\n    }\n\n    RMApp rmApp = rmContext.getRMApps().get(applicationId);\n    FSLeafQueue queue = assignToQueue(rmApp, queueName, user);\n    if (queue == null) {\n      return;\n    }\n\n    // Enforce ACLs\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n\n    if (!queue.hasAccess(QueueACL.SUBMIT_APPLICATIONS, userUgi)\n        && !queue.hasAccess(QueueACL.ADMINISTER_QUEUE, userUgi)) {\n      String msg = \"User \" + userUgi.getUserName() +\n              \" cannot submit applications to queue \" + queue.getName();\n      LOG.info(msg);\n      rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppRejectedEvent(applicationId, msg));\n      return;\n    }\n  \n    SchedulerApplication<FSAppAttempt> application =\n        new SchedulerApplication<FSAppAttempt>(queue, user);\n    applications.put(applicationId, application);\n    queue.getMetrics().submitApp(user);\n\n    LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n        + \", in queue: \" + queueName + \", currently num of applications: \"\n        + applications.size());\n    if (isAppRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler()\n        .handle(new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) throws Exception {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }"
        },
        "bug_report": {
            "Title": "FairScheduler PrimaryGroup does not handle empty groups returned for a user ",
            "Description": "We see NPE if empty groups are returned for a user. This causes a NPE and cause RM to crash as below\n\n{noformat}\n2015-09-22 16:51:52,780  FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type APP_ADDED to the scheduler\njava.lang.IndexOutOfBoundsException: Index: 0\n\tat java.util.Collections$EmptyList.get(Collections.java:3212)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule$PrimaryGroup.getQueueForApp(QueuePlacementRule.java:149)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule.assignAppToQueue(QueuePlacementRule.java:74)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementPolicy.assignAppToQueue(QueuePlacementPolicy.java:167)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.assignToQueue(FairScheduler.java:689)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication(FairScheduler.java:595)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1180)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:111)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n\tat java.lang.Thread.run(Thread.java:745)\n2015-09-22 16:51:52,797  INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Exiting, bbye..\n{noformat}"
        }
    },
    {
        "filename": "YARN-4833.json",
        "creation_time": "2016-03-17T13:22:23.000+0000",
        "stack_trace": "```\norg.apache.hadoop.security.AccessControlException: User hdfs does not have permission to submit application_1458273884145_0001 to queue default\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:380)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.submitApplication:618)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:252)\n        at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:483)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2360)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2356)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2356)\n\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateIOException(RPCUtil.java:80)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:119)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:272)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:257)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy23.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:261)\n        at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:295)\n        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)\n        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:244)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:222)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): User hdfs does not have permission to submit application_1458273884145_0001 to queue default\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:380)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.submitApplication:618)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:252)\n        at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:483)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2360)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2356)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2356)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1449)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine$Invoker.java:230)\n        at com.sun.proxy.$Proxy22.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:269)\n        ... 35 more\n\njava.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.connect:206)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\n        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:634)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:733)\n        at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:378)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1510)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1425)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine$Invoker.java:230)\n        at com.sun.proxy.$Proxy22.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:269)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:257)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy23.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.submitApplication:261)\n        at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.submitApplication:295)\n        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.submitJob:301)\n        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.submitJobInternal:244)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.main:74)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.RunJar.run(RunJar.run:222)\n        at org.apache.hadoop.util.RunJar.main(RunJar.main:136)\nCaused by: java.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.connect:206)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\n        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:634)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:733)\n        at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:378)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1510)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp": "  private RMAppImpl createAndPopulateNewRMApp(\n      ApplicationSubmissionContext submissionContext, long submitTime,\n      String user, boolean isRecovery)\n      throws YarnException, AccessControlException {\n    // Do queue mapping\n    if (!isRecovery) {\n      if (rmContext.getQueuePlacementManager() != null) {\n        // We only do queue mapping when it's a new application\n        rmContext.getQueuePlacementManager().placeApplication(\n            submissionContext, user);\n      }\n    }\n    \n    ApplicationId applicationId = submissionContext.getApplicationId();\n    ResourceRequest amReq =\n        validateAndCreateResourceRequest(submissionContext, isRecovery);\n\n    // Verify and get the update application priority and set back to\n    // submissionContext\n    Priority appPriority = rmContext.getScheduler()\n        .checkAndGetApplicationPriority(submissionContext.getPriority(), user,\n            submissionContext.getQueue(), applicationId);\n    submissionContext.setPriority(appPriority);\n\n    UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(user);\n    // Since FairScheduler queue mapping is done inside scheduler,\n    // if FairScheduler is used and the queue doesn't exist, we should not\n    // fail here because queue will be created inside FS. Ideally, FS queue\n    // mapping should be done outside scheduler too like CS.\n    // For now, exclude FS for the acl check.\n    if (!isRecovery && YarnConfiguration.isAclEnabled(conf)\n        && scheduler instanceof CapacityScheduler) {\n      String queueName = submissionContext.getQueue();\n      String appName = submissionContext.getApplicationName();\n      CSQueue csqueue = ((CapacityScheduler) scheduler).getQueue(queueName);\n      if (null != csqueue\n          && !authorizer.checkPermission(\n              new AccessRequest(csqueue.getPrivilegedEntity(), userUgi,\n                  SchedulerUtils.toAccessType(QueueACL.SUBMIT_APPLICATIONS),\n                  applicationId.toString(), appName))\n          && !authorizer.checkPermission(\n              new AccessRequest(csqueue.getPrivilegedEntity(), userUgi,\n                  SchedulerUtils.toAccessType(QueueACL.ADMINISTER_QUEUE),\n                  applicationId.toString(), appName))) {\n        throw new AccessControlException(\n            \"User \" + user + \" does not have permission to submit \"\n                + applicationId + \" to queue \" + submissionContext.getQueue());\n      }\n    }\n\n    // Create RMApp\n    RMAppImpl application = new RMAppImpl(applicationId, rmContext, this.conf,\n        submissionContext.getApplicationName(), user,\n        submissionContext.getQueue(), submissionContext, this.scheduler,\n        this.masterService, submitTime, submissionContext.getApplicationType(),\n        submissionContext.getApplicationTags(), amReq);\n\n    // Concurrent app submissions with same applicationId will fail here\n    // Concurrent app submissions with different applicationIds will not\n    // influence each other\n    if (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw new YarnException(message);\n    }\n    // Inform the ACLs Manager\n    this.applicationACLsManager.addApplication(applicationId,\n        submissionContext.getAMContainerSpec().getApplicationACLs());\n    String appViewACLs = submissionContext.getAMContainerSpec()\n        .getApplicationACLs().get(ApplicationAccessType.VIEW_APP);\n    rmContext.getSystemMetricsPublisher().appACLsUpdated(\n        application, appViewACLs, System.currentTimeMillis());\n    return application;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest": "  private ResourceRequest validateAndCreateResourceRequest(\n      ApplicationSubmissionContext submissionContext, boolean isRecovery)\n      throws InvalidResourceRequestException {\n    // Validation of the ApplicationSubmissionContext needs to be completed\n    // here. Only those fields that are dependent on RM's configuration are\n    // checked here as they have to be validated whether they are part of new\n    // submission or just being recovered.\n\n    // Check whether AM resource requirements are within required limits\n    if (!submissionContext.getUnmanagedAM()) {\n      ResourceRequest amReq = submissionContext.getAMContainerResourceRequest();\n      if (amReq == null) {\n        amReq = BuilderUtils\n            .newResourceRequest(RMAppAttemptImpl.AM_CONTAINER_PRIORITY,\n                ResourceRequest.ANY, submissionContext.getResource(), 1);\n      }\n\n      // set label expression for AM container\n      if (null == amReq.getNodeLabelExpression()) {\n        amReq.setNodeLabelExpression(submissionContext\n            .getNodeLabelExpression());\n      }\n\n      try {\n        SchedulerUtils.normalizeAndValidateRequest(amReq,\n            scheduler.getMaximumResourceCapability(),\n            submissionContext.getQueue(), scheduler, isRecovery, rmContext);\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"RM app submission failed in validating AM resource request\"\n            + \" for application \" + submissionContext.getApplicationId(), e);\n        throw e;\n      }\n\n      SchedulerUtils.normalizeRequest(amReq, scheduler.getResourceCalculator(),\n          scheduler.getClusterResource(),\n          scheduler.getMinimumResourceCapability(),\n          scheduler.getMaximumResourceCapability(),\n          scheduler.getMinimumResourceCapability());\n      return amReq;\n    }\n    \n    return null;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.toString": "      @Override public String toString() {\n        return buffer.toString();\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication": "  protected void submitApplication(\n      ApplicationSubmissionContext submissionContext, long submitTime,\n      String user) throws YarnException, AccessControlException {\n    ApplicationId applicationId = submissionContext.getApplicationId();\n\n    RMAppImpl application =\n        createAndPopulateNewRMApp(submissionContext, submitTime, user, false);\n    Credentials credentials = null;\n    try {\n      credentials = parseCredentials(submissionContext);\n      if (UserGroupInformation.isSecurityEnabled()) {\n        this.rmContext.getDelegationTokenRenewer()\n            .addApplicationAsync(applicationId, credentials,\n                submissionContext.getCancelTokensWhenComplete(),\n                application.getUser());\n      } else {\n        // Dispatcher is not yet started at this time, so these START events\n        // enqueued should be guaranteed to be first processed when dispatcher\n        // gets started.\n        this.rmContext.getDispatcher().getEventHandler()\n            .handle(new RMAppEvent(applicationId, RMAppEventType.START));\n      }\n    } catch (Exception e) {\n      LOG.warn(\"Unable to parse credentials.\", e);\n      // Sending APP_REJECTED is fine, since we assume that the\n      // RMApp is in NEW state and thus we haven't yet informed the\n      // scheduler about the existence of the application\n      assert application.getState() == RMAppState.NEW;\n      this.rmContext.getDispatcher().getEventHandler()\n          .handle(new RMAppEvent(applicationId,\n              RMAppEventType.APP_REJECTED, e.getMessage()));\n      throw RPCUtil.getRemoteException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch(event.getType()) {\n      case APP_COMPLETED: \n      {\n        finishApplication(applicationId);\n        logApplicationSummary(applicationId);\n        checkAppNumCompletedLimit(); \n      } \n      break;\n      default:\n        LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n      }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.parseCredentials": "  protected Credentials parseCredentials(\n      ApplicationSubmissionContext application) throws IOException {\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = application.getAMContainerSpec().getTokens();\n    if (tokens != null) {\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n    return credentials;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication": "  public SubmitApplicationResponseProto submitApplication(RpcController arg0,\n      SubmitApplicationRequestProto proto) throws ServiceException {\n    SubmitApplicationRequestPBImpl request = new SubmitApplicationRequestPBImpl(proto);\n    try {\n      SubmitApplicationResponse response = real.submitApplication(request);\n      return ((SubmitApplicationResponsePBImpl)response).getProto();\n    } catch (YarnException e) {\n      throw new ServiceException(e);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcRequestWrapper request = (RpcRequestWrapper) writableRequest;\n        RequestHeaderProto rpcRequest = request.requestHeader;\n        String methodName = rpcRequest.getMethodName();\n        \n        \n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = prototype.newBuilderForType()\n            .mergeFrom(request.theRequestRead).build();\n        \n        Message result;\n        long startTime = Time.now();\n        int qTime = (int) (startTime - receiveTime);\n        Exception exception = null;\n        try {\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n        } catch (ServiceException e) {\n          exception = (Exception) e.getCause();\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          exception = e;\n          throw e;\n        } finally {\n          int processingTime = (int) (Time.now() - startTime);\n          if (LOG.isDebugEnabled()) {\n            String msg = \"Served: \" + methodName + \" queueTime= \" + qTime +\n                \" procesingTime= \" + processingTime;\n            if (exception != null) {\n              msg += \" exception= \" + exception.getClass().getSimpleName();\n            }\n            LOG.debug(msg);\n          }\n          String detailedMetricsName = (exception == null) ?\n              methodName :\n              exception.getClass().getSimpleName();\n          server.rpcMetrics.addRpcQueueTime(qTime);\n          server.rpcMetrics.addRpcProcessingTime(processingTime);\n          server.rpcDetailedMetrics.addProcessingTime(detailedMetricsName,\n              processingTime);\n          if (server.isLogSlowRPC()) {\n            server.logSlowRpcCalls(methodName, processingTime);\n          }\n        }\n        return new RpcResponseWrapper(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getProtocolImpl": "      private static ProtoClassProtoImpl getProtocolImpl(RPC.Server server,\n          String protoName, long clientVersion) throws RpcServerException {\n        ProtoNameVer pv = new ProtoNameVer(protoName, clientVersion);\n        ProtoClassProtoImpl impl = \n            server.getProtocolImplMap(RPC.RpcKind.RPC_PROTOCOL_BUFFER).get(pv);\n        if (impl == null) { // no match for Protocol AND Version\n          VerProtocolImpl highest = \n              server.getHighestSupportedProtocol(RPC.RpcKind.RPC_PROTOCOL_BUFFER, \n                  protoName);\n          if (highest == null) {\n            throw new RpcNoSuchProtocolException(\n                \"Unknown protocol: \" + protoName);\n          }\n          // protocol supported but not the version that client wants\n          throw new RPC.VersionMismatch(protoName, clientVersion,\n              highest.version);\n        }\n        return impl;\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RPC.call": "    public Writable call(RPC.RpcKind rpcKind, String protocol,\n        Writable rpcRequest, long receiveTime) throws Exception {\n      return getRpcInvoker(rpcKind).call(this, protocol, rpcRequest,\n          receiveTime);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.run": "        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.sendResponse": "    private void sendResponse(Call call) throws IOException {\n      responder.doRespond(call);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupResponse": "  private static void setupResponse(ByteArrayOutputStream responseBuf,\n                             Call call, RpcStatusProto status, RpcErrorCodeProto erCode,\n                             Writable rv, String errorClass, String error) \n  throws IOException {\n    responseBuf.reset();\n    DataOutputStream out = new DataOutputStream(responseBuf);\n    RpcResponseHeaderProto.Builder headerBuilder =  \n        RpcResponseHeaderProto.newBuilder();\n    headerBuilder.setClientId(ByteString.copyFrom(call.clientId));\n    headerBuilder.setCallId(call.callId);\n    headerBuilder.setRetryCount(call.retryCount);\n    headerBuilder.setStatus(status);\n    headerBuilder.setServerIpcVersionNum(CURRENT_VERSION);\n\n    if (status == RpcStatusProto.SUCCESS) {\n      RpcResponseHeaderProto header = headerBuilder.build();\n      final int headerLen = header.getSerializedSize();\n      int fullLength  = CodedOutputStream.computeRawVarint32Size(headerLen) +\n          headerLen;\n      try {\n        if (rv instanceof ProtobufRpcEngine.RpcWrapper) {\n          ProtobufRpcEngine.RpcWrapper resWrapper = \n              (ProtobufRpcEngine.RpcWrapper) rv;\n          fullLength += resWrapper.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          rv.write(out);\n        } else { // Have to serialize to buffer to get len\n          final DataOutputBuffer buf = new DataOutputBuffer();\n          rv.write(buf);\n          byte[] data = buf.getData();\n          fullLength += buf.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          out.write(data, 0, buf.getLength());\n        }\n      } catch (Throwable t) {\n        LOG.warn(\"Error serializing call response for call \" + call, t);\n        // Call back to same function - this is OK since the\n        // buffer is reset at the top, and since status is changed\n        // to ERROR it won't infinite loop.\n        setupResponse(responseBuf, call, RpcStatusProto.ERROR,\n            RpcErrorCodeProto.ERROR_SERIALIZING_RESPONSE,\n            null, t.getClass().getName(),\n            StringUtils.stringifyException(t));\n        return;\n      }\n    } else { // Rpc Failure\n      headerBuilder.setExceptionClassName(errorClass);\n      headerBuilder.setErrorMsg(error);\n      headerBuilder.setErrorDetail(erCode);\n      RpcResponseHeaderProto header = headerBuilder.build();\n      int headerLen = header.getSerializedSize();\n      final int fullLength  = \n          CodedOutputStream.computeRawVarint32Size(headerLen) + headerLen;\n      out.writeInt(fullLength);\n      header.writeDelimitedTo(out);\n    }\n    call.setResponse(ByteBuffer.wrap(responseBuf.toByteArray()));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.size": "    int size() {\n      return count.get();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeIdle": "    synchronized void closeIdle(boolean scanAll) {\n      long minLastContact = Time.now() - maxIdleTime;\n      // concurrent iterator might miss new connections added\n      // during the iteration, but that's ok because they won't\n      // be idle yet anyway and will be caught on next scan\n      int closed = 0;\n      for (Connection connection : connections) {\n        // stop if connections dropped below threshold unless scanning all\n        if (!scanAll && size() < idleScanThreshold) {\n          break;\n        }\n        // stop if not scanning all and max connections are closed\n        if (connection.isIdle() &&\n            connection.getLastContact() < minLastContact &&\n            close(connection) &&\n            !scanAll && (++closed == maxIdleToClose)) {\n          break;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.close": "    boolean close(Connection connection) {\n      boolean exists = remove(connection);\n      if (exists) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(Thread.currentThread().getName() +\n              \": disconnecting client \" + connection +\n              \". Number of active connections: \"+ size());\n        }\n        // only close if actually removed to avoid double-closing due\n        // to possible races\n        connection.close();\n      }\n      return exists;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRunLoop": "    private void doRunLoop() {\n      long lastPurgeTime = 0;   // last check for old calls.\n\n      while (running) {\n        try {\n          waitPending();     // If a channel is being registered, wait.\n          writeSelector.select(PURGE_INTERVAL);\n          Iterator<SelectionKey> iter = writeSelector.selectedKeys().iterator();\n          while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            iter.remove();\n            try {\n              if (key.isValid() && key.isWritable()) {\n                  doAsyncWrite(key);\n              }\n            } catch (IOException e) {\n              LOG.info(Thread.currentThread().getName() + \": doAsyncWrite threw exception \" + e);\n            }\n          }\n          long now = Time.now();\n          if (now < lastPurgeTime + PURGE_INTERVAL) {\n            continue;\n          }\n          lastPurgeTime = now;\n          //\n          // If there were some calls that have not been sent out for a\n          // long time, discard them.\n          //\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"Checking for old call responses.\");\n          }\n          ArrayList<Call> calls;\n          \n          // get the list of channels from list of keys.\n          synchronized (writeSelector.keys()) {\n            calls = new ArrayList<Call>(writeSelector.keys().size());\n            iter = writeSelector.keys().iterator();\n            while (iter.hasNext()) {\n              SelectionKey key = iter.next();\n              Call call = (Call)key.attachment();\n              if (call != null && key.channel() == call.connection.channel) { \n                calls.add(call);\n              }\n            }\n          }\n          \n          for(Call call : calls) {\n            doPurge(call, now);\n          }\n        } catch (OutOfMemoryError e) {\n          //\n          // we can run out of memory if we have too many threads\n          // log the event and sleep for a minute and give\n          // some thread(s) a chance to finish\n          //\n          LOG.warn(\"Out of Memory in server select\", e);\n          try { Thread.sleep(60000); } catch (Exception ie) {}\n        } catch (Exception e) {\n          LOG.warn(\"Exception in Responder\", e);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.stopIdleScan": "    void stopIdleScan() {\n      idleScanTimer.cancel();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeCurrentConnection": "    private void closeCurrentConnection(SelectionKey key, Throwable e) {\n      if (key != null) {\n        Connection c = (Connection)key.attachment();\n        if (c != null) {\n          closeConnection(c);\n          c = null;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doAccept": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server = (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel = server.accept()) != null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader = getReader();\n        Connection c = connectionManager.register(channel);\n        // If the connectionManager can't take it, close the connection.\n        if (c == null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanup(null, channel);\n          }\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeAll": "    void closeAll() {\n      // use a copy of the connections to be absolutely sure the concurrent\n      // iterator doesn't miss a connection\n      for (Connection connection : toArray()) {\n        close(connection);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.scheduleIdleScanTask": "    private void scheduleIdleScanTask() {\n      if (!running) {\n        return;\n      }\n      TimerTask idleScanTask = new TimerTask(){\n        @Override\n        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }\n      };\n      idleScanTimer.schedule(idleScanTask, idleScanInterval);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getRpcErrorCodeProto": "    public RpcErrorCodeProto getRpcErrorCodeProto() {\n      return errCode;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.call": "  public abstract Writable call(RPC.RpcKind rpcKind, String protocol,\n      Writable param, long receiveTime) throws Exception;\n  \n  /**\n   * Authorize the incoming client connection.\n   * \n   * @param user client user\n   * @param protocolName - the protocol\n   * @param addr InetAddress of incoming connection\n   * @throws AuthorizationException when the client isn't authorized to talk the protocol\n   */\n  private void authorize(UserGroupInformation user, String protocolName,\n      InetAddress addr) throws AuthorizationException {\n    if (authorize) {\n      if (protocolName == null) {\n        throw new AuthorizationException(\"Null protocol not authorized\");\n      }\n      Class<?> protocol = null;\n      try {\n        protocol = getProtocolClass(protocolName, getConf());\n      } catch (ClassNotFoundException cfne) {\n        throw new AuthorizationException(\"Unknown protocol: \" + \n                                         protocolName);\n      }\n      serviceAuthorizationManager.authorize(user, protocol, getConf(), addr);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getSelector": "    synchronized Selector getSelector() { return selector; }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.startIdleScan": "    void startIdleScan() {\n      scheduleIdleScanTask();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.toString": "    public String toString() {\n      return getHostAddress() + \":\" + remotePort; \n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.logException": "  void logException(Log logger, Throwable e, Call call) {\n    if (exceptionsHandler.isSuppressedLog(e.getClass())) {\n      return; // Log nothing.\n    }\n\n    final String logMsg = Thread.currentThread().getName() + \", call \" + call;\n    if (exceptionsHandler.isTerseLog(e.getClass())) {\n      // Don't log the whole stack trace. Way too noisy!\n      logger.info(logMsg + \": \" + e);\n    } else if (e instanceof RuntimeException || e instanceof Error) {\n      // These exception types indicate something is probably wrong\n      // on the server side, as opposed to just a normal exceptional\n      // result.\n      logger.warn(logMsg, e);\n    } else {\n      logger.info(logMsg, e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.remove": "    private boolean remove(Connection connection) {\n      boolean removed = connections.remove(connection);\n      if (removed) {\n        count.getAndDecrement();\n      }\n      return removed;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException": "  private static <T extends Throwable> T instantiateException(\n      Class<? extends T> cls, RemoteException re) throws RemoteException {\n    try {\n      Constructor<? extends T> cn = cls.getConstructor(String.class);\n      cn.setAccessible(true);\n      T ex = cn.newInstance(re.getMessage());\n      ex.initCause(re);\n      return ex;\n      // RemoteException contains useful information as against the\n      // java.lang.reflect exceptions.\n    } catch (NoSuchMethodException e) {\n      throw re;\n    } catch (IllegalArgumentException e) {\n      throw re;\n    } catch (SecurityException e) {\n      throw re;\n    } catch (InstantiationException e) {\n      throw re;\n    } catch (IllegalAccessException e) {\n      throw re;\n    } catch (InvocationTargetException e) {\n      throw re;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.RPCUtil.instantiateIOException": "  private static <T extends IOException> T instantiateIOException(\n      Class<? extends T> cls, RemoteException re) throws RemoteException {\n    return instantiateException(cls, re);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException": "  public static Void unwrapAndThrowException(ServiceException se)\n      throws IOException, YarnException {\n    Throwable cause = se.getCause();\n    if (cause == null) {\n      // SE generated by the RPC layer itself.\n      throw new IOException(se);\n    } else {\n      if (cause instanceof RemoteException) {\n        RemoteException re = (RemoteException) cause;\n        Class<?> realClass = null;\n        try {\n          realClass = Class.forName(re.getClassName());\n        } catch (ClassNotFoundException cnf) {\n          // Assume this to be a new exception type added to YARN. This isn't\n          // absolutely correct since the RPC layer could add an exception as\n          // well.\n          throw instantiateYarnException(YarnException.class, re);\n        }\n\n        if (YarnException.class.isAssignableFrom(realClass)) {\n          throw instantiateYarnException(\n              realClass.asSubclass(YarnException.class), re);\n        } else if (IOException.class.isAssignableFrom(realClass)) {\n          throw instantiateIOException(realClass.asSubclass(IOException.class),\n              re);\n        } else if (RuntimeException.class.isAssignableFrom(realClass)) {\n          throw instantiateRuntimeException(\n              realClass.asSubclass(RuntimeException.class), re);\n        } else {\n          throw re;\n        }\n        // RemoteException contains useful information as against the\n        // java.lang.reflect exceptions.\n\n      } else if (cause instanceof IOException) {\n        // RPC Client exception.\n        throw (IOException) cause;\n      } else if (cause instanceof RuntimeException) {\n        // RPC RuntimeException\n        throw (RuntimeException) cause;\n      } else {\n        // Should not be generated.\n        throw new IOException(se);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.RPCUtil.instantiateRuntimeException": "  private static <T extends RuntimeException> T instantiateRuntimeException(\n      Class<? extends T> cls, RemoteException re) throws RemoteException {\n    return instantiateException(cls, re);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.RPCUtil.instantiateYarnException": "  private static <T extends YarnException> T instantiateYarnException(\n      Class<? extends T> cls, RemoteException re) throws RemoteException {\n    return instantiateException(cls, re);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication": "  public SubmitApplicationResponse submitApplication(\n      SubmitApplicationRequest request) throws YarnException,\n      IOException {\n    SubmitApplicationRequestProto requestProto =\n        ((SubmitApplicationRequestPBImpl) request).getProto();\n    try {\n      return new SubmitApplicationResponsePBImpl(proxy.submitApplication(null,\n        requestProto));\n    } catch (ServiceException e) {\n      RPCUtil.unwrapAndThrowException(e);\n      return null;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod": "  protected Object invokeMethod(Method method, Object[] args) throws Throwable {\n    try {\n      if (!method.isAccessible()) {\n        method.setAccessible(true);\n      }\n      return method.invoke(currentProxy.proxy, args);\n    } catch (InvocationTargetException e) {\n      throw e.getCause();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.io.retry.RetryInvocationHandler.invoke": "  public Object invoke(Object proxy, Method method, Object[] args)\n    throws Throwable {\n    RetryPolicy policy = methodNameToPolicyMap.get(method.getName());\n    if (policy == null) {\n      policy = defaultPolicy;\n    }\n    \n    // The number of times this method invocation has been failed over.\n    int invocationFailoverCount = 0;\n    final boolean isRpc = isRpcInvocation(currentProxy.proxy);\n    final int callId = isRpc? Client.nextCallId(): RpcConstants.INVALID_CALL_ID;\n    int retries = 0;\n    while (true) {\n      // The number of times this invocation handler has ever been failed over,\n      // before this method invocation attempt. Used to prevent concurrent\n      // failed method invocations from triggering multiple failover attempts.\n      long invocationAttemptFailoverCount;\n      synchronized (proxyProvider) {\n        invocationAttemptFailoverCount = proxyProviderFailoverCount;\n      }\n\n      if (isRpc) {\n        Client.setCallIdAndRetryCount(callId, retries);\n      }\n      try {\n        Object ret = invokeMethod(method, args);\n        hasMadeASuccessfulCall = true;\n        return ret;\n      } catch (Exception ex) {\n        if (Thread.currentThread().isInterrupted()) {\n          // If interrupted, do not retry.\n          throw ex;\n        }\n        boolean isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n            .getMethod(method.getName(), method.getParameterTypes())\n            .isAnnotationPresent(Idempotent.class);\n        if (!isIdempotentOrAtMostOnce) {\n          isIdempotentOrAtMostOnce = proxyProvider.getInterface()\n              .getMethod(method.getName(), method.getParameterTypes())\n              .isAnnotationPresent(AtMostOnce.class);\n        }\n        List<RetryAction> actions = extractActions(policy, ex, retries++,\n                invocationFailoverCount, isIdempotentOrAtMostOnce);\n        RetryAction failAction = getFailAction(actions);\n        if (failAction != null) {\n          // fail.\n          if (failAction.reason != null) {\n            LOG.warn(\"Exception while invoking \" + currentProxy.proxy.getClass()\n                + \".\" + method.getName() + \" over \" + currentProxy.proxyInfo\n                + \". Not retrying because \" + failAction.reason, ex);\n          }\n          throw ex;\n        } else { // retry or failover\n          // avoid logging the failover if this is the first call on this\n          // proxy object, and we successfully achieve the failover without\n          // any flip-flopping\n          boolean worthLogging = \n            !(invocationFailoverCount == 0 && !hasMadeASuccessfulCall);\n          worthLogging |= LOG.isDebugEnabled();\n          RetryAction failOverAction = getFailOverAction(actions);\n          long delay = getDelayMillis(actions);\n\n          if (worthLogging) {\n            String msg = \"Exception while invoking \" + method.getName()\n                + \" of class \" + currentProxy.proxy.getClass().getSimpleName()\n                + \" over \" + currentProxy.proxyInfo;\n\n            if (invocationFailoverCount > 0) {\n              msg += \" after \" + invocationFailoverCount + \" fail over attempts\"; \n            }\n\n            if (failOverAction != null) {\n              // failover\n              msg += \". Trying to fail over \" + formatSleepMessage(delay);\n            } else {\n              // retry\n              msg += \". Retrying \" + formatSleepMessage(delay);\n            }\n            LOG.info(msg, ex);\n          }\n\n          if (delay > 0) {\n            Thread.sleep(delay);\n          }\n\n          if (failOverAction != null) {\n            // Make sure that concurrent failed method invocations only cause a\n            // single actual fail over.\n            synchronized (proxyProvider) {\n              if (invocationAttemptFailoverCount == proxyProviderFailoverCount) {\n                proxyProvider.performFailover(currentProxy.proxy);\n                proxyProviderFailoverCount++;\n              } else {\n                LOG.warn(\"A failover has occurred since the start of this method\"\n                    + \" invocation attempt.\");\n              }\n              currentProxy = proxyProvider.getProxy();\n            }\n            invocationFailoverCount++;\n          }\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication": "  public ApplicationId\n      submitApplication(ApplicationSubmissionContext appContext)\n          throws YarnException, IOException {\n    ApplicationId applicationId = appContext.getApplicationId();\n    if (applicationId == null) {\n      throw new ApplicationIdNotProvidedException(\n          \"ApplicationId is not provided in ApplicationSubmissionContext\");\n    }\n    SubmitApplicationRequest request =\n        Records.newRecord(SubmitApplicationRequest.class);\n    request.setApplicationSubmissionContext(appContext);\n\n    // Automatically add the timeline DT into the CLC\n    // Only when the security and the timeline service are both enabled\n    if (isSecurityEnabled() && timelineServiceEnabled) {\n      addTimelineDelegationToken(appContext.getAMContainerSpec());\n    }\n\n    //TODO: YARN-1763:Handle RM failovers during the submitApplication call.\n    rmClient.submitApplication(request);\n\n    int pollCount = 0;\n    long startTime = System.currentTimeMillis();\n    EnumSet<YarnApplicationState> waitingStates = \n                                 EnumSet.of(YarnApplicationState.NEW,\n                                 YarnApplicationState.NEW_SAVING,\n                                 YarnApplicationState.SUBMITTED);\n    EnumSet<YarnApplicationState> failToSubmitStates = \n                                  EnumSet.of(YarnApplicationState.FAILED,\n                                  YarnApplicationState.KILLED);\t\t\n    while (true) {\n      try {\n        ApplicationReport appReport = getApplicationReport(applicationId);\n        YarnApplicationState state = appReport.getYarnApplicationState();\n        if (!waitingStates.contains(state)) {\n          if(failToSubmitStates.contains(state)) {\n            throw new YarnException(\"Failed to submit \" + applicationId + \n                \" to YARN : \" + appReport.getDiagnostics());\n          }\n          LOG.info(\"Submitted application \" + applicationId);\n          break;\n        }\n\n        long elapsedMillis = System.currentTimeMillis() - startTime;\n        if (enforceAsyncAPITimeout() &&\n            elapsedMillis >= asyncApiPollTimeoutMillis) {\n          throw new YarnException(\"Timed out while waiting for application \" +\n              applicationId + \" to be submitted successfully\");\n        }\n\n        // Notify the client through the log every 10 poll, in case the client\n        // is blocked here too long.\n        if (++pollCount % 10 == 0) {\n          LOG.info(\"Application submission is not finished, \" +\n              \"submitted application \" + applicationId +\n              \" is still in \" + state);\n        }\n        try {\n          Thread.sleep(submitPollIntervalMillis);\n        } catch (InterruptedException ie) {\n          LOG.error(\"Interrupted while waiting for application \"\n              + applicationId\n              + \" to be successfully submitted.\");\n        }\n      } catch (ApplicationNotFoundException ex) {\n        // FailOver or RM restart happens before RMStateStore saves\n        // ApplicationState\n        LOG.info(\"Re-submit application \" + applicationId + \"with the \" +\n            \"same ApplicationSubmissionContext\");\n        rmClient.submitApplication(request);\n      }\n    }\n\n    return applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.isSecurityEnabled": "  protected boolean isSecurityEnabled() {\n    return UserGroupInformation.isSecurityEnabled();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.addTimelineDelegationToken": "  private void addTimelineDelegationToken(\n      ContainerLaunchContext clc) throws YarnException, IOException {\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = clc.getTokens();\n    if (tokens != null) {\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n    // If the timeline delegation token is already in the CLC, no need to add\n    // one more\n    for (org.apache.hadoop.security.token.Token<? extends TokenIdentifier> token : credentials\n        .getAllTokens()) {\n      if (token.getKind().equals(TimelineDelegationTokenIdentifier.KIND_NAME)) {\n        return;\n      }\n    }\n    org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier>\n        timelineDelegationToken = getTimelineDelegationToken();\n    if (timelineDelegationToken == null) {\n      return;\n    }\n    credentials.addToken(timelineService, timelineDelegationToken);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Add timline delegation token into credentials: \"\n          + timelineDelegationToken);\n    }\n    DataOutputBuffer dob = new DataOutputBuffer();\n    credentials.writeTokenStorageToStream(dob);\n    tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    clc.setTokens(tokens);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.enforceAsyncAPITimeout": "  boolean enforceAsyncAPITimeout() {\n    return asyncApiPollTimeoutMillis >= 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplicationReport": "  public ApplicationReport getApplicationReport(ApplicationId appId)\n      throws YarnException, IOException {\n    GetApplicationReportResponse response = null;\n    try {\n      GetApplicationReportRequest request = Records\n          .newRecord(GetApplicationReportRequest.class);\n      request.setApplicationId(appId);\n      response = rmClient.getApplicationReport(request);\n    } catch (ApplicationNotFoundException e) {\n      if (!historyServiceEnabled) {\n        // Just throw it as usual if historyService is not enabled.\n        throw e;\n      }\n      return historyClient.getApplicationReport(appId);\n    }\n    return response.getApplicationReport();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ToolRunner.run": "  public static int run(Tool tool, String[] args) \n    throws Exception{\n    return run(tool.getConf(), tool, args);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ProgramDriver.invoke": "    public void invoke(String[] args)\n      throws Throwable {\n      try {\n        main.invoke(null, new Object[]{args});\n      } catch (InvocationTargetException except) {\n        throw except.getCause();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ProgramDriver.run": "  public int run(String[] args)\n    throws Throwable \n  {\n    // Make sure they gave us a program name.\n    if (args.length == 0) {\n      System.out.println(\"An example program must be given as the\" + \n                         \" first argument.\");\n      printUsage(programs);\n      return -1;\n    }\n\t\n    // And that it is good.\n    ProgramDescription pgm = programs.get(args[0]);\n    if (pgm == null) {\n      System.out.println(\"Unknown program '\" + args[0] + \"' chosen.\");\n      printUsage(programs);\n      return -1;\n    }\n\t\n    // Remove the leading argument and call main\n    String[] new_args = new String[args.length - 1];\n    for(int i=1; i < args.length; ++i) {\n      new_args[i-1] = args[i];\n    }\n    pgm.invoke(new_args);\n    return 0;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ProgramDriver.printUsage": "  private static void printUsage(Map<String, ProgramDescription> programs) {\n    System.out.println(\"Valid program names are:\");\n    for(Map.Entry<String, ProgramDescription> item : programs.entrySet()) {\n      System.out.println(\"  \" + item.getKey() + \": \" +\n                         item.getValue().getDescription());         \n    } \n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.RunJar.run": "        public void run() {\n          FileUtil.fullyDelete(workDir);\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.RunJar.unJar": "  public static void unJar(File jarFile, File toDir, Pattern unpackRegex)\n    throws IOException {\n    JarFile jar = new JarFile(jarFile);\n    try {\n      Enumeration<JarEntry> entries = jar.entries();\n      while (entries.hasMoreElements()) {\n        final JarEntry entry = entries.nextElement();\n        if (!entry.isDirectory() &&\n            unpackRegex.matcher(entry.getName()).matches()) {\n          InputStream in = jar.getInputStream(entry);\n          try {\n            File file = new File(toDir, entry.getName());\n            ensureDirectory(file.getParentFile());\n            OutputStream out = new FileOutputStream(file);\n            try {\n              IOUtils.copyBytes(in, out, 8192);\n            } finally {\n              out.close();\n            }\n          } finally {\n            in.close();\n          }\n        }\n      }\n    } finally {\n      jar.close();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.RunJar.createClassLoader": "  private ClassLoader createClassLoader(File file, final File workDir)\n      throws MalformedURLException {\n    ClassLoader loader;\n    // see if the client classloader is enabled\n    if (useClientClassLoader()) {\n      StringBuilder sb = new StringBuilder();\n      sb.append(workDir+\"/\").\n          append(File.pathSeparator).append(file).\n          append(File.pathSeparator).append(workDir+\"/classes/\").\n          append(File.pathSeparator).append(workDir+\"/lib/*\");\n      // HADOOP_CLASSPATH is added to the client classpath\n      String hadoopClasspath = getHadoopClasspath();\n      if (hadoopClasspath != null && !hadoopClasspath.isEmpty()) {\n        sb.append(File.pathSeparator).append(hadoopClasspath);\n      }\n      String clientClasspath = sb.toString();\n      // get the system classes\n      String systemClasses = getSystemClasses();\n      List<String> systemClassesList = systemClasses == null ?\n          null :\n          Arrays.asList(StringUtils.getTrimmedStrings(systemClasses));\n      // create an application classloader that isolates the user classes\n      loader = new ApplicationClassLoader(clientClasspath,\n          getClass().getClassLoader(), systemClassesList);\n    } else {\n      List<URL> classPath = new ArrayList<URL>();\n      classPath.add(new File(workDir+\"/\").toURI().toURL());\n      classPath.add(file.toURI().toURL());\n      classPath.add(new File(workDir, \"classes/\").toURI().toURL());\n      File[] libs = new File(workDir, \"lib\").listFiles();\n      if (libs != null) {\n        for (int i = 0; i < libs.length; i++) {\n          classPath.add(libs[i].toURI().toURL());\n        }\n      }\n      // create a normal parent-delegating classloader\n      loader = new URLClassLoader(classPath.toArray(new URL[0]));\n    }\n    return loader;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.RunJar.ensureDirectory": "  private static void ensureDirectory(File dir) throws IOException {\n    if (!dir.mkdirs() && !dir.isDirectory()) {\n      throw new IOException(\"Mkdirs failed to create \" +\n                            dir.toString());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.RunJar.main": "  public static void main(String[] args) throws Throwable {\n    new RunJar().run(args);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.call": "  Writable call(RPC.RpcKind rpcKind, Writable rpcRequest,\n      ConnectionId remoteId, int serviceClass,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    final Call call = createCall(rpcKind, rpcRequest);\n    Connection connection = getConnection(remoteId, call, serviceClass,\n      fallbackToSimpleAuth);\n    try {\n      connection.sendRpcRequest(call);                 // send the rpc request\n    } catch (RejectedExecutionException e) {\n      throw new IOException(\"connection has been closed\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      LOG.warn(\"interrupted waiting to send rpc request to server\", e);\n      throw new IOException(e);\n    }\n\n    synchronized (call) {\n      while (!call.done) {\n        try {\n          call.wait();                           // wait for the result\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          throw new InterruptedIOException(\"Call interrupted\");\n        }\n      }\n\n      if (call.error != null) {\n        if (call.error instanceof RemoteException) {\n          call.error.fillInStackTrace();\n          throw call.error;\n        } else { // local exception\n          InetSocketAddress address = connection.getRemoteAddress();\n          throw NetUtils.wrapException(address.getHostName(),\n                  address.getPort(),\n                  NetUtils.getHostname(),\n                  0,\n                  call.error);\n        }\n      } else {\n        return call.getRpcResponse();\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRemoteAddress": "    public InetSocketAddress getRemoteAddress() {\n      return server;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getConnection": "  private Connection getConnection(ConnectionId remoteId,\n      Call call, int serviceClass, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    while (true) {\n      // These lines below can be shorten with computeIfAbsent in Java8\n      connection = connections.get(remoteId);\n      if (connection == null) {\n        connection = new Connection(remoteId, serviceClass);\n        Connection existing = connections.putIfAbsent(remoteId, connection);\n        if (existing != null) {\n          connection = existing;\n        }\n      }\n\n      if (connection.addCall(call)) {\n        break;\n      } else {\n        // This connection is closed, should be removed. But other thread could\n        // have already known this closedConnection, and replace it with a new\n        // connection. So we should call conditional remove to make sure we only\n        // remove this closedConnection.\n        connections.remove(remoteId, connection);\n      }\n    }\n\n    // If the server happens to be slow, the method below will take longer to\n    // establish a connection.\n    connection.setupIOstreams(fallbackToSimpleAuth);\n    return connection;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.createCall": "  Call createCall(RPC.RpcKind rpcKind, Writable rpcRequest) {\n    return new Call(rpcKind, rpcRequest);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.sendRpcRequest": "    public void sendRpcRequest(final Call call)\n        throws InterruptedException, IOException {\n      if (shouldCloseConnection.get()) {\n        return;\n      }\n\n      // Serialize the call to be sent. This is done from the actual\n      // caller thread, rather than the sendParamsExecutor thread,\n      \n      // so that if the serialization throws an error, it is reported\n      // properly. This also parallelizes the serialization.\n      //\n      // Format of a call on the wire:\n      // 0) Length of rest below (1 + 2)\n      // 1) RpcRequestHeader  - is serialized Delimited hence contains length\n      // 2) RpcRequest\n      //\n      // Items '1' and '2' are prepared here. \n      final DataOutputBuffer d = new DataOutputBuffer();\n      RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader(\n          call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry,\n          clientId);\n      header.writeDelimitedTo(d);\n      call.rpcRequest.write(d);\n\n      synchronized (sendRpcRequestLock) {\n        Future<?> senderFuture = sendParamsExecutor.submit(new Runnable() {\n          @Override\n          public void run() {\n            try {\n              synchronized (Connection.this.out) {\n                if (shouldCloseConnection.get()) {\n                  return;\n                }\n                \n                if (LOG.isDebugEnabled())\n                  LOG.debug(getName() + \" sending #\" + call.id);\n         \n                byte[] data = d.getData();\n                int totalLength = d.getLength();\n                out.writeInt(totalLength); // Total Length\n                out.write(data, 0, totalLength);// RpcRequestHeader + RpcRequest\n                out.flush();\n              }\n            } catch (IOException e) {\n              // exception at this point would leave the connection in an\n              // unrecoverable state (eg half a call left on the wire).\n              // So, close the connection, killing any outstanding calls\n              markClosed(e);\n            } finally {\n              //the buffer is just an in-memory buffer, but it is still polite to\n              // close early\n              IOUtils.closeStream(d);\n            }\n          }\n        });\n      \n        try {\n          senderFuture.get();\n        } catch (ExecutionException e) {\n          Throwable cause = e.getCause();\n          \n          // cause should only be a RuntimeException as the Runnable above\n          // catches IOException\n          if (cause instanceof RuntimeException) {\n            throw (RuntimeException) cause;\n          } else {\n            throw new RuntimeException(\"unexpected checked exception\", cause);\n          }\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getRpcResponse": "    public synchronized Writable getRpcResponse() {\n      return rpcResponse;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.net.NetUtils.connect": "  public static void connect(Socket socket, \n                             SocketAddress endpoint,\n                             SocketAddress localAddr,\n                             int timeout) throws IOException {\n    if (socket == null || endpoint == null || timeout < 0) {\n      throw new IllegalArgumentException(\"Illegal argument for connect()\");\n    }\n    \n    SocketChannel ch = socket.getChannel();\n    \n    if (localAddr != null) {\n      Class localClass = localAddr.getClass();\n      Class remoteClass = endpoint.getClass();\n      Preconditions.checkArgument(localClass.equals(remoteClass),\n          \"Local address %s must be of same family as remote address %s.\",\n          localAddr, endpoint);\n      socket.bind(localAddr);\n    }\n\n    try {\n      if (ch == null) {\n        // let the default implementation handle it.\n        socket.connect(endpoint, timeout);\n      } else {\n        SocketIOWithTimeout.connect(ch, endpoint, timeout);\n      }\n    } catch (SocketTimeoutException ste) {\n      throw new ConnectTimeoutException(ste.getMessage());\n    }\n\n    // There is a very rare case allowed by the TCP specification, such that\n    // if we are trying to connect to an endpoint on the local machine,\n    // and we end up choosing an ephemeral port equal to the destination port,\n    // we will actually end up getting connected to ourself (ie any data we\n    // send just comes right back). This is only possible if the target\n    // daemon is down, so we'll treat it like connection refused.\n    if (socket.getLocalPort() == socket.getPort() &&\n        socket.getLocalAddress().equals(socket.getInetAddress())) {\n      LOG.info(\"Detected a loopback TCP socket, disconnecting it\");\n      socket.close();\n      throw new ConnectException(\n        \"Localhost targeted connection resulted in a loopback. \" +\n        \"No daemon is listening on the target port.\");\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupConnection": "    private synchronized void setupConnection() throws IOException {\n      short ioFailures = 0;\n      short timeoutFailures = 0;\n      while (true) {\n        try {\n          this.socket = socketFactory.createSocket();\n          this.socket.setTcpNoDelay(tcpNoDelay);\n          this.socket.setKeepAlive(true);\n          \n          if (tcpLowLatency) {\n            /*\n             * This allows intermediate switches to shape IPC traffic\n             * differently from Shuffle/HDFS DataStreamer traffic.\n             *\n             * IPTOS_RELIABILITY (0x04) | IPTOS_LOWDELAY (0x10)\n             *\n             * Prefer to optimize connect() speed & response latency over net\n             * throughput.\n             */\n            this.socket.setTrafficClass(0x04 | 0x10);\n            this.socket.setPerformancePreferences(1, 2, 0);\n          }\n\n          /*\n           * Bind the socket to the host specified in the principal name of the\n           * client, to ensure Server matching address of the client connection\n           * to host name in principal passed.\n           */\n          UserGroupInformation ticket = remoteId.getTicket();\n          if (ticket != null && ticket.hasKerberosCredentials()) {\n            KerberosInfo krbInfo = \n              remoteId.getProtocol().getAnnotation(KerberosInfo.class);\n            if (krbInfo != null && krbInfo.clientPrincipal() != null) {\n              String host = \n                SecurityUtil.getHostFromPrincipal(remoteId.getTicket().getUserName());\n              \n              // If host name is a valid local address then bind socket to it\n              InetAddress localAddr = NetUtils.getLocalInetAddress(host);\n              if (localAddr != null) {\n                this.socket.setReuseAddress(true);\n                this.socket.bind(new InetSocketAddress(localAddr, 0));\n              }\n            }\n          }\n          \n          NetUtils.connect(this.socket, server, connectionTimeout);\n          if (rpcTimeout > 0) {\n            pingInterval = rpcTimeout;  // rpcTimeout overwrites pingInterval\n          }\n          this.socket.setSoTimeout(pingInterval);\n          return;\n        } catch (ConnectTimeoutException toe) {\n          /* Check for an address change and update the local reference.\n           * Reset the failure counter if the address was changed\n           */\n          if (updateAddress()) {\n            timeoutFailures = ioFailures = 0;\n          }\n          handleConnectionTimeout(timeoutFailures++,\n              maxRetriesOnSocketTimeouts, toe);\n        } catch (IOException ie) {\n          if (updateAddress()) {\n            timeoutFailures = ioFailures = 0;\n          }\n          handleConnectionFailure(ioFailures++, ie);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getProtocol": "    Class<?> getProtocol() {\n      return protocol;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.updateAddress": "    private synchronized boolean updateAddress() throws IOException {\n      // Do a fresh lookup with the old host name.\n      InetSocketAddress currentAddr = NetUtils.createSocketAddrForHost(\n                               server.getHostName(), server.getPort());\n\n      if (!server.equals(currentAddr)) {\n        LOG.warn(\"Address change detected. Old: \" + server.toString() +\n                                 \" New: \" + currentAddr.toString());\n        server = currentAddr;\n        return true;\n      }\n      return false;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.getTicket": "    UserGroupInformation getTicket() {\n      return ticket;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.handleConnectionTimeout": "    private void handleConnectionTimeout(\n        int curRetries, int maxRetries, IOException ioe) throws IOException {\n\n      closeConnection();\n\n      // throw the exception if the maximum number of retries is reached\n      if (curRetries >= maxRetries) {\n        throw ioe;\n      }\n      LOG.info(\"Retrying connect to server: \" + server + \". Already tried \"\n          + curRetries + \" time(s); maxRetries=\" + maxRetries);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.handleConnectionFailure": "    private void handleConnectionFailure(int curRetries, IOException ioe\n        ) throws IOException {\n      closeConnection();\n\n      final RetryAction action;\n      try {\n        action = connectionRetryPolicy.shouldRetry(ioe, curRetries, 0, true);\n      } catch(Exception e) {\n        throw e instanceof IOException? (IOException)e: new IOException(e);\n      }\n      if (action.action == RetryAction.RetryDecision.FAIL) {\n        if (action.reason != null) {\n          LOG.warn(\"Failed to connect to server: \" + server + \": \"\n              + action.reason, ioe);\n        }\n        throw ioe;\n      }\n\n      // Throw the exception if the thread is interrupted\n      if (Thread.currentThread().isInterrupted()) {\n        LOG.warn(\"Interrupted while trying for connection\");\n        throw ioe;\n      }\n\n      try {\n        Thread.sleep(action.delayMillis);\n      } catch (InterruptedException e) {\n        throw (IOException)new InterruptedIOException(\"Interrupted: action=\"\n            + action + \", retry policy=\" + connectionRetryPolicy).initCause(e);\n      }\n      LOG.info(\"Retrying connect to server: \" + server + \". Already tried \"\n          + curRetries + \" time(s); retry policy is \" + connectionRetryPolicy);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupIOstreams": "    private synchronized void setupIOstreams(\n        AtomicBoolean fallbackToSimpleAuth) {\n      if (socket != null || shouldCloseConnection.get()) {\n        return;\n      } \n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to \"+server);\n        }\n        Span span = Tracer.getCurrentSpan();\n        if (span != null) {\n          span.addTimelineAnnotation(\"IPC client connecting to \" + server);\n        }\n        short numRetries = 0;\n        Random rand = null;\n        while (true) {\n          setupConnection();\n          InputStream inStream = NetUtils.getInputStream(socket);\n          OutputStream outStream = NetUtils.getOutputStream(socket);\n          writeConnectionHeader(outStream);\n          if (authProtocol == AuthProtocol.SASL) {\n            final InputStream in2 = inStream;\n            final OutputStream out2 = outStream;\n            UserGroupInformation ticket = remoteId.getTicket();\n            if (ticket.getRealUser() != null) {\n              ticket = ticket.getRealUser();\n            }\n            try {\n              authMethod = ticket\n                  .doAs(new PrivilegedExceptionAction<AuthMethod>() {\n                    @Override\n                    public AuthMethod run()\n                        throws IOException, InterruptedException {\n                      return setupSaslConnection(in2, out2);\n                    }\n                  });\n            } catch (IOException ex) {\n              if (saslRpcClient == null) {\n                // whatever happened -it can't be handled, so rethrow\n                throw ex;\n              }\n              // otherwise, assume a connection problem\n              authMethod = saslRpcClient.getAuthMethod();\n              if (rand == null) {\n                rand = new Random();\n              }\n              handleSaslConnectionFailure(numRetries++, maxRetriesOnSasl, ex,\n                  rand, ticket);\n              continue;\n            }\n            if (authMethod != AuthMethod.SIMPLE) {\n              // Sasl connect is successful. Let's set up Sasl i/o streams.\n              inStream = saslRpcClient.getInputStream(inStream);\n              outStream = saslRpcClient.getOutputStream(outStream);\n              // for testing\n              remoteId.saslQop =\n                  (String)saslRpcClient.getNegotiatedProperty(Sasl.QOP);\n              LOG.debug(\"Negotiated QOP is :\" + remoteId.saslQop);\n              if (fallbackToSimpleAuth != null) {\n                fallbackToSimpleAuth.set(false);\n              }\n            } else if (UserGroupInformation.isSecurityEnabled()) {\n              if (!fallbackAllowed) {\n                throw new IOException(\"Server asks us to fall back to SIMPLE \" +\n                    \"auth, but this client is configured to only allow secure \" +\n                    \"connections.\");\n              }\n              if (fallbackToSimpleAuth != null) {\n                fallbackToSimpleAuth.set(true);\n              }\n            }\n          }\n        \n          if (doPing) {\n            inStream = new PingInputStream(inStream);\n          }\n          this.in = new DataInputStream(new BufferedInputStream(inStream));\n\n          // SASL may have already buffered the stream\n          if (!(outStream instanceof BufferedOutputStream)) {\n            outStream = new BufferedOutputStream(outStream);\n          }\n          this.out = new DataOutputStream(outStream);\n          \n          writeConnectionContext(remoteId, authMethod);\n\n          // update last activity time\n          touch();\n\n          span = Tracer.getCurrentSpan();\n          if (span != null) {\n            span.addTimelineAnnotation(\"IPC client connected to \" + server);\n          }\n\n          // start the receiver thread after the socket connection has been set\n          // up\n          start();\n          return;\n        }\n      } catch (Throwable t) {\n        if (t instanceof IOException) {\n          markClosed((IOException)t);\n        } else {\n          markClosed(new IOException(\"Couldn't set up IO streams: \" + t, t));\n        }\n        close();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.close": "    private synchronized void close() {\n      if (!shouldCloseConnection.get()) {\n        LOG.error(\"The connection is not in the closed state\");\n        return;\n      }\n\n      // We have marked this connection as closed. Other thread could have\n      // already known it and replace this closedConnection with a new one.\n      // We should only remove this closedConnection.\n      connections.remove(remoteId, this);\n\n      // close the streams and therefore the socket\n      IOUtils.closeStream(out);\n      IOUtils.closeStream(in);\n      disposeSasl();\n\n      // clean up all calls\n      if (closeException == null) {\n        if (!calls.isEmpty()) {\n          LOG.warn(\n              \"A connection is closed for no cause and calls are not empty\");\n\n          // clean up calls anyway\n          closeException = new IOException(\"Unexpected closed connection\");\n          cleanupCalls();\n        }\n      } else {\n        // log the info\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"closing ipc connection to \" + server + \": \" +\n              closeException.getMessage(),closeException);\n        }\n\n        // cleanup calls\n        cleanupCalls();\n      }\n      closeConnection();\n      if (LOG.isDebugEnabled())\n        LOG.debug(getName() + \": closed\");\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.handleSaslConnectionFailure": "    private synchronized void handleSaslConnectionFailure(\n        final int currRetries, final int maxRetries, final Exception ex,\n        final Random rand, final UserGroupInformation ugi) throws IOException,\n        InterruptedException {\n      ugi.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws IOException, InterruptedException {\n          final short MAX_BACKOFF = 5000;\n          closeConnection();\n          disposeSasl();\n          if (shouldAuthenticateOverKrb()) {\n            if (currRetries < maxRetries) {\n              if(LOG.isDebugEnabled()) {\n                LOG.debug(\"Exception encountered while connecting to \"\n                    + \"the server : \" + ex);\n              }\n              // try re-login\n              if (UserGroupInformation.isLoginKeytabBased()) {\n                UserGroupInformation.getLoginUser().reloginFromKeytab();\n              } else if (UserGroupInformation.isLoginTicketBased()) {\n                UserGroupInformation.getLoginUser().reloginFromTicketCache();\n              }\n              // have granularity of milliseconds\n              //we are sleeping with the Connection lock held but since this\n              //connection instance is being used for connecting to the server\n              //in question, it is okay\n              Thread.sleep((rand.nextInt(MAX_BACKOFF) + 1));\n              return null;\n            } else {\n              String msg = \"Couldn't setup connection for \"\n                  + UserGroupInformation.getLoginUser().getUserName() + \" to \"\n                  + remoteId;\n              LOG.warn(msg, ex);\n              throw (IOException) new IOException(msg).initCause(ex);\n            }\n          } else {\n            LOG.warn(\"Exception encountered while connecting to \"\n                + \"the server : \" + ex);\n          }\n          if (ex instanceof RemoteException)\n            throw (RemoteException) ex;\n          throw new IOException(ex);\n        }\n      });\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.writeConnectionContext": "    private void writeConnectionContext(ConnectionId remoteId,\n                                        AuthMethod authMethod)\n                                            throws IOException {\n      // Write out the ConnectionHeader\n      IpcConnectionContextProto message = ProtoUtil.makeIpcConnectionContext(\n          RPC.getProtocolName(remoteId.getProtocol()),\n          remoteId.getTicket(),\n          authMethod);\n      RpcRequestHeaderProto connectionContextHeader = ProtoUtil\n          .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n              OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,\n              RpcConstants.INVALID_RETRY_COUNT, clientId);\n      RpcRequestMessageWrapper request =\n          new RpcRequestMessageWrapper(connectionContextHeader, message);\n      \n      // Write out the packet length\n      out.writeInt(request.getLength());\n      request.write(out);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.markClosed": "    private synchronized void markClosed(IOException e) {\n      if (shouldCloseConnection.compareAndSet(false, true)) {\n        closeException = e;\n        notifyAll();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.setupSaslConnection": "    private synchronized AuthMethod setupSaslConnection(final InputStream in2, \n        final OutputStream out2) throws IOException {\n      // Do not use Client.conf here! We must use ConnectionId.conf, since the\n      // Client object is cached and shared between all RPC clients, even those\n      // for separate services.\n      saslRpcClient = new SaslRpcClient(remoteId.getTicket(),\n          remoteId.getProtocol(), remoteId.getAddress(), remoteId.conf);\n      return saslRpcClient.saslConnect(in2, out2);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.touch": "    private void touch() {\n      lastActivity.set(Time.now());\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Client.writeConnectionHeader": "    private void writeConnectionHeader(OutputStream outStream)\n        throws IOException {\n      DataOutputStream out = new DataOutputStream(new BufferedOutputStream(outStream));\n      // Write out the header, version and authentication method\n      out.write(RpcConstants.HEADER.array());\n      out.write(RpcConstants.CURRENT_VERSION);\n      out.write(serviceClass);\n      out.write(authProtocol.callId);\n      out.flush();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getSystemMetricsPublisher": "  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMApps": "  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getScheduler": "  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getQueuePlacementManager": "  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.logSlowRpcCalls": "  void logSlowRpcCalls(String methodName, int processingTime) {\n    final int deviation = 3;\n\n    // 1024 for minSampleSize just a guess -- not a number computed based on\n    // sample size analysis. It is chosen with the hope that this\n    // number is high enough to avoid spurious logging, yet useful\n    // in practice.\n    final int minSampleSize = 1024;\n    final double threeSigma = rpcMetrics.getProcessingMean() +\n        (rpcMetrics.getProcessingStdDev() * deviation);\n\n    if ((rpcMetrics.getProcessingSampleCount() > minSampleSize) &&\n        (processingTime > threeSigma)) {\n      if(LOG.isWarnEnabled()) {\n        String client = CurCall.get().connection.toString();\n        LOG.warn(\n            \"Slow RPC : \" + methodName + \" took \" + processingTime +\n                \" milliseconds to process from client \" + client);\n      }\n      rpcMetrics.incrSlowRpc();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.toString": "    public String toString() {\n      return getHostAddress() + \":\" + remotePort; \n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.get": "  public static Server get() {\n    return SERVER.get();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.server.isLogSlowRPC": "  protected boolean isLogSlowRPC() {\n    return logSlowRPC;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.CallerContext.setCurrent": "  public static void setCurrent(CallerContext callerContext) {\n    CurrentCallerContextHolder.CALLER_CONTEXT.set(callerContext);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcServerException.getRpcStatusProto": "  public RpcStatusProto getRpcStatusProto() {\n    return RpcStatusProto.ERROR;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.GenericOptionsParser.getRemainingArgs": "  public String[] getRemainingArgs() {\n    return (commandLine == null) ? new String[]{} : commandLine.getArgs();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.ShutdownHookManager.get": "  public static ShutdownHookManager get() {\n    return MGR;\n  }"
        },
        "bug_report": {
            "Title": "For Queue AccessControlException client retries multiple times on both RM",
            "Description": "Submit application to queue where ACL is enabled and submitted user is not  having access. Client retries till failMaxattempt 10 times.\n\n{noformat}\n16/03/18 10:01:06 INFO retry.RetryInvocationHandler: Exception while invoking submitApplication of class ApplicationClientProtocolPBClientImpl over rm1. Trying to fail over immediately.\norg.apache.hadoop.security.AccessControlException: User hdfs does not have permission to submit application_1458273884145_0001 to queue default\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:380)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:618)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:252)\n        at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:483)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2360)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2356)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2356)\n\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateIOException(RPCUtil.java:80)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:119)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:272)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:257)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy23.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:261)\n        at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:295)\n        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)\n        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:244)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:222)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): User hdfs does not have permission to submit application_1458273884145_0001 to queue default\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:380)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:618)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:252)\n        at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:483)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2360)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2356)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2356)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1449)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n        at com.sun.proxy.$Proxy22.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:269)\n        ... 35 more\n16/03/18 10:01:06 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm2\n16/03/18 10:01:06 WARN ipc.Client: Failed to connect to server: host-10-19-92-187/10.19.91.146:45022: retries get failed due to exceeded maximum allowed retries number: 0\njava.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\n        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:634)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:733)\n        at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:378)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1510)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1425)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n        at com.sun.proxy.$Proxy22.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:269)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:257)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy23.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:261)\n        at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:295)\n        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)\n        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:244)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:222)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n16/03/18 10:01:06 INFO retry.RetryInvocationHandler: Exception while invoking submitApplication of class ApplicationClientProtocolPBClientImpl over rm2 after 1 fail over attempts. Trying to fail over after sleeping for 22450ms.\njava.net.ConnectException: Call From host-10-19-92-199/10.19.91.157 to host-10-19-92-187:45022 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1453)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n        at com.sun.proxy.$Proxy22.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:269)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:257)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy23.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:261)\n        at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:295)\n        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)\n        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:244)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:222)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: java.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\n        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:634)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:733)\n        at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:378)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1510)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1425)\n        ... 39 more\n\n{noformat}\n\n*Solution*\n# As per discussion with [~jianhe] should handle the AccessControlException in RetryPolicy and should go to fallbackPolicy \n# Wrap AccessControl exception to YarnException in {{RMAppManager#submitApplication}}\nThoughts?"
        }
    },
    {
        "filename": "YARN-1689.json",
        "creation_time": "2014-02-05T19:16:00.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getTransferredContainers(AbstractYarnScheduler.java:48)\n        at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.registerApplicationMaster(ApplicationMasterService.java:278)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.registerApplicationMaster(ApplicationMasterProtocolPBServiceImpl.java:90)\n        at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:95)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1958)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1956)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: ATTEMPT_REGISTERED at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:624)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:81)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:656)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:640)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:662)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getTransferredContainers": "  public synchronized List<Container> getTransferredContainers(\n      ApplicationAttemptId currentAttempt) {\n    ApplicationId appId = currentAttempt.getApplicationId();\n    SchedulerApplication app = applications.get(appId);\n    List<Container> containerList = new ArrayList<Container>();\n    RMApp appImpl = this.rmContext.getRMApps().get(appId);\n    if (appImpl.getApplicationSubmissionContext().getUnmanagedAM()) {\n      return containerList;\n    }\n    Collection<RMContainer> liveContainers =\n        app.getCurrentAppAttempt().getLiveContainers();\n    ContainerId amContainerId =\n        rmContext.getRMApps().get(appId).getCurrentAppAttempt()\n          .getMasterContainer().getId();\n    for (RMContainer rmContainer : liveContainers) {\n      if (!rmContainer.getContainerId().equals(amContainerId)) {\n        containerList.add(rmContainer.getContainer());\n      }\n    }\n    return containerList;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.registerApplicationMaster": "  public RegisterApplicationMasterResponse registerApplicationMaster(\n      RegisterApplicationMasterRequest request) throws YarnException,\n      IOException {\n\n    ApplicationAttemptId applicationAttemptId = authorizeRequest();\n\n    ApplicationId appID = applicationAttemptId.getApplicationId();\n    AllocateResponseLock lock = responseMap.get(applicationAttemptId);\n    if (lock == null) {\n      RMAuditLogger.logFailure(this.rmContext.getRMApps().get(appID).getUser(),\n          AuditConstants.REGISTER_AM, \"Application doesn't exist in cache \"\n              + applicationAttemptId, \"ApplicationMasterService\",\n          \"Error in registering application master\", appID,\n          applicationAttemptId);\n      throwApplicationDoesNotExistInCacheException(applicationAttemptId);\n    }\n\n    // Allow only one thread in AM to do registerApp at a time.\n    synchronized (lock) {\n      AllocateResponse lastResponse = lock.getAllocateResponse();\n      if (hasApplicationMasterRegistered(applicationAttemptId)) {\n        String message =\n            \"Application Master is already registered : \"\n                + applicationAttemptId.getApplicationId();\n        LOG.warn(message);\n        RMAuditLogger.logFailure(\n          this.rmContext.getRMApps()\n            .get(applicationAttemptId.getApplicationId()).getUser(),\n          AuditConstants.REGISTER_AM, \"\", \"ApplicationMasterService\", message,\n          applicationAttemptId.getApplicationId(), applicationAttemptId);\n        throw new InvalidApplicationMasterRequestException(message);\n      }\n      \n      this.amLivelinessMonitor.receivedPing(applicationAttemptId);\n      RMApp app = this.rmContext.getRMApps().get(appID);\n      \n      // Setting the response id to 0 to identify if the\n      // application master is register for the respective attemptid\n      lastResponse.setResponseId(0);\n      lock.setAllocateResponse(lastResponse);\n      LOG.info(\"AM registration \" + applicationAttemptId);\n      this.rmContext\n        .getDispatcher()\n        .getEventHandler()\n        .handle(\n          new RMAppAttemptRegistrationEvent(applicationAttemptId, request\n            .getHost(), request.getRpcPort(), request.getTrackingUrl()));\n      RMAuditLogger.logSuccess(app.getUser(), AuditConstants.REGISTER_AM,\n        \"ApplicationMasterService\", appID, applicationAttemptId);\n\n      // Pick up min/max resource from scheduler...\n      RegisterApplicationMasterResponse response = recordFactory\n          .newRecordInstance(RegisterApplicationMasterResponse.class);\n      response.setMaximumResourceCapability(rScheduler\n          .getMaximumResourceCapability());\n      response.setApplicationACLs(app.getRMAppAttempt(applicationAttemptId)\n          .getSubmissionContext().getAMContainerSpec().getApplicationACLs());\n      response.setQueue(app.getQueue());\n      if (UserGroupInformation.isSecurityEnabled()) {\n        LOG.info(\"Setting client token master key\");\n        response.setClientToAMTokenMasterKey(java.nio.ByteBuffer.wrap(rmContext\n            .getClientToAMTokenSecretManager()\n            .getMasterKey(applicationAttemptId).getEncoded()));        \n      }\n\n      List<Container> containerList =\n          ((AbstractYarnScheduler) rScheduler)\n            .getTransferredContainers(applicationAttemptId);\n      response.setContainersFromPreviousAttempt(containerList);\n      return response;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.getAllocateResponse": "    public synchronized AllocateResponse getAllocateResponse() {\n      return response;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.throwApplicationDoesNotExistInCacheException": "  private void throwApplicationDoesNotExistInCacheException(\n      ApplicationAttemptId appAttemptId)\n      throws InvalidApplicationMasterRequestException {\n    String message = \"Application doesn't exist in cache \"\n        + appAttemptId;\n    LOG.error(message);\n    throw new InvalidApplicationMasterRequestException(message);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.hasApplicationMasterRegistered": "  public boolean hasApplicationMasterRegistered(\n      ApplicationAttemptId appAttemptId) {\n    boolean hasApplicationMasterRegistered = false;\n    AllocateResponseLock lastResponse = responseMap.get(appAttemptId);\n    if (lastResponse != null) {\n      synchronized (lastResponse) {\n        if (lastResponse.getAllocateResponse() != null\n            && lastResponse.getAllocateResponse().getResponseId() >= 0) {\n          hasApplicationMasterRegistered = true;\n        }\n      }\n    }\n    return hasApplicationMasterRegistered;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.authorizeRequest": "  private ApplicationAttemptId authorizeRequest()\n      throws YarnException {\n\n    UserGroupInformation remoteUgi;\n    try {\n      remoteUgi = UserGroupInformation.getCurrentUser();\n    } catch (IOException e) {\n      String msg =\n          \"Cannot obtain the user-name for authorizing ApplicationMaster. \"\n              + \"Got exception: \" + StringUtils.stringifyException(e);\n      LOG.warn(msg);\n      throw RPCUtil.getRemoteException(msg);\n    }\n\n    boolean tokenFound = false;\n    String message = \"\";\n    AMRMTokenIdentifier appTokenIdentifier = null;\n    try {\n      appTokenIdentifier = selectAMRMTokenIdentifier(remoteUgi);\n      if (appTokenIdentifier == null) {\n        tokenFound = false;\n        message = \"No AMRMToken found for user \" + remoteUgi.getUserName();\n      } else {\n        tokenFound = true;\n      }\n    } catch (IOException e) {\n      tokenFound = false;\n      message =\n          \"Got exception while looking for AMRMToken for user \"\n              + remoteUgi.getUserName();\n    }\n\n    if (!tokenFound) {\n      LOG.warn(message);\n      throw RPCUtil.getRemoteException(message);\n    }\n\n    return appTokenIdentifier.getApplicationAttemptId();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.setAllocateResponse": "    public synchronized void setAllocateResponse(AllocateResponse response) {\n      this.response = response;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.registerApplicationMaster": "  public RegisterApplicationMasterResponseProto registerApplicationMaster(\n      RpcController arg0, RegisterApplicationMasterRequestProto proto)\n      throws ServiceException {\n    RegisterApplicationMasterRequestPBImpl request = new RegisterApplicationMasterRequestPBImpl(proto);\n    try {\n      RegisterApplicationMasterResponse response = real.registerApplicationMaster(request);\n      return ((RegisterApplicationMasterResponsePBImpl)response).getProto();\n    } catch (YarnException e) {\n      throw new ServiceException(e);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcRequestWrapper request = (RpcRequestWrapper) writableRequest;\n        RequestHeaderProto rpcRequest = request.requestHeader;\n        String methodName = rpcRequest.getMethodName();\n        \n        \n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = prototype.newBuilderForType()\n            .mergeFrom(request.theRequestRead).build();\n        \n        Message result;\n        try {\n          long startTime = Time.now();\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n          int processingTime = (int) (Time.now() - startTime);\n          int qTime = (int) (startTime - receiveTime);\n          if (LOG.isDebugEnabled()) {\n            LOG.info(\"Served: \" + methodName + \" queueTime= \" + qTime +\n                      \" procesingTime= \" + processingTime);\n          }\n          server.rpcMetrics.addRpcQueueTime(qTime);\n          server.rpcMetrics.addRpcProcessingTime(processingTime);\n          server.rpcDetailedMetrics.addProcessingTime(methodName,\n              processingTime);\n        } catch (ServiceException e) {\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          throw e;\n        }\n        return new RpcResponseWrapper(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getProtocolImpl": "      private static ProtoClassProtoImpl getProtocolImpl(RPC.Server server,\n          String protoName, long clientVersion) throws RpcServerException {\n        ProtoNameVer pv = new ProtoNameVer(protoName, clientVersion);\n        ProtoClassProtoImpl impl = \n            server.getProtocolImplMap(RPC.RpcKind.RPC_PROTOCOL_BUFFER).get(pv);\n        if (impl == null) { // no match for Protocol AND Version\n          VerProtocolImpl highest = \n              server.getHighestSupportedProtocol(RPC.RpcKind.RPC_PROTOCOL_BUFFER, \n                  protoName);\n          if (highest == null) {\n            throw new RpcNoSuchProtocolException(\n                \"Unknown protocol: \" + protoName);\n          }\n          // protocol supported but not the version that client wants\n          throw new RPC.VersionMismatch(protoName, clientVersion,\n              highest.version);\n        }\n        return impl;\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RPC.call": "    public Writable call(RPC.RpcKind rpcKind, String protocol,\n        Writable rpcRequest, long receiveTime) throws Exception {\n      return getRpcInvoker(rpcKind).call(this, protocol, rpcRequest,\n          receiveTime);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.run": "        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupResponse": "  private void setupResponse(ByteArrayOutputStream responseBuf,\n                             Call call, RpcStatusProto status, RpcErrorCodeProto erCode,\n                             Writable rv, String errorClass, String error) \n  throws IOException {\n    responseBuf.reset();\n    DataOutputStream out = new DataOutputStream(responseBuf);\n    RpcResponseHeaderProto.Builder headerBuilder =  \n        RpcResponseHeaderProto.newBuilder();\n    headerBuilder.setClientId(ByteString.copyFrom(call.clientId));\n    headerBuilder.setCallId(call.callId);\n    headerBuilder.setRetryCount(call.retryCount);\n    headerBuilder.setStatus(status);\n    headerBuilder.setServerIpcVersionNum(CURRENT_VERSION);\n\n    if (status == RpcStatusProto.SUCCESS) {\n      RpcResponseHeaderProto header = headerBuilder.build();\n      final int headerLen = header.getSerializedSize();\n      int fullLength  = CodedOutputStream.computeRawVarint32Size(headerLen) +\n          headerLen;\n      try {\n        if (rv instanceof ProtobufRpcEngine.RpcWrapper) {\n          ProtobufRpcEngine.RpcWrapper resWrapper = \n              (ProtobufRpcEngine.RpcWrapper) rv;\n          fullLength += resWrapper.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          rv.write(out);\n        } else { // Have to serialize to buffer to get len\n          final DataOutputBuffer buf = new DataOutputBuffer();\n          rv.write(buf);\n          byte[] data = buf.getData();\n          fullLength += buf.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          out.write(data, 0, buf.getLength());\n        }\n      } catch (Throwable t) {\n        LOG.warn(\"Error serializing call response for call \" + call, t);\n        // Call back to same function - this is OK since the\n        // buffer is reset at the top, and since status is changed\n        // to ERROR it won't infinite loop.\n        setupResponse(responseBuf, call, RpcStatusProto.ERROR,\n            RpcErrorCodeProto.ERROR_SERIALIZING_RESPONSE,\n            null, t.getClass().getName(),\n            StringUtils.stringifyException(t));\n        return;\n      }\n    } else { // Rpc Failure\n      headerBuilder.setExceptionClassName(errorClass);\n      headerBuilder.setErrorMsg(error);\n      headerBuilder.setErrorDetail(erCode);\n      RpcResponseHeaderProto header = headerBuilder.build();\n      int headerLen = header.getSerializedSize();\n      final int fullLength  = \n          CodedOutputStream.computeRawVarint32Size(headerLen) + headerLen;\n      out.writeInt(fullLength);\n      header.writeDelimitedTo(out);\n    }\n    if (call.connection.useWrap) {\n      wrapWithSasl(responseBuf, call);\n    }\n    call.setResponse(ByteBuffer.wrap(responseBuf.toByteArray()));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.size": "    int size() {\n      return count.get();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeIdle": "    synchronized void closeIdle(boolean scanAll) {\n      long minLastContact = Time.now() - maxIdleTime;\n      // concurrent iterator might miss new connections added\n      // during the iteration, but that's ok because they won't\n      // be idle yet anyway and will be caught on next scan\n      int closed = 0;\n      for (Connection connection : connections) {\n        // stop if connections dropped below threshold unless scanning all\n        if (!scanAll && size() < idleScanThreshold) {\n          break;\n        }\n        // stop if not scanning all and max connections are closed\n        if (connection.isIdle() &&\n            connection.getLastContact() < minLastContact &&\n            close(connection) &&\n            !scanAll && (++closed == maxIdleToClose)) {\n          break;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.close": "    boolean close(Connection connection) {\n      boolean exists = remove(connection);\n      if (exists) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(Thread.currentThread().getName() +\n              \": disconnecting client \" + connection +\n              \". Number of active connections: \"+ size());\n        }\n        // only close if actually removed to avoid double-closing due\n        // to possible races\n        connection.close();\n      }\n      return exists;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRespond": "    void doRespond(Call call) throws IOException {\n      synchronized (call.connection.responseQueue) {\n        call.connection.responseQueue.addLast(call);\n        if (call.connection.responseQueue.size() == 1) {\n          processResponse(call.connection.responseQueue, true);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRunLoop": "    private void doRunLoop() {\n      long lastPurgeTime = 0;   // last check for old calls.\n\n      while (running) {\n        try {\n          waitPending();     // If a channel is being registered, wait.\n          writeSelector.select(PURGE_INTERVAL);\n          Iterator<SelectionKey> iter = writeSelector.selectedKeys().iterator();\n          while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            iter.remove();\n            try {\n              if (key.isValid() && key.isWritable()) {\n                  doAsyncWrite(key);\n              }\n            } catch (IOException e) {\n              LOG.info(Thread.currentThread().getName() + \": doAsyncWrite threw exception \" + e);\n            }\n          }\n          long now = Time.now();\n          if (now < lastPurgeTime + PURGE_INTERVAL) {\n            continue;\n          }\n          lastPurgeTime = now;\n          //\n          // If there were some calls that have not been sent out for a\n          // long time, discard them.\n          //\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"Checking for old call responses.\");\n          }\n          ArrayList<Call> calls;\n          \n          // get the list of channels from list of keys.\n          synchronized (writeSelector.keys()) {\n            calls = new ArrayList<Call>(writeSelector.keys().size());\n            iter = writeSelector.keys().iterator();\n            while (iter.hasNext()) {\n              SelectionKey key = iter.next();\n              Call call = (Call)key.attachment();\n              if (call != null && key.channel() == call.connection.channel) { \n                calls.add(call);\n              }\n            }\n          }\n          \n          for(Call call : calls) {\n            doPurge(call, now);\n          }\n        } catch (OutOfMemoryError e) {\n          //\n          // we can run out of memory if we have too many threads\n          // log the event and sleep for a minute and give\n          // some thread(s) a chance to finish\n          //\n          LOG.warn(\"Out of Memory in server select\", e);\n          try { Thread.sleep(60000); } catch (Exception ie) {}\n        } catch (Exception e) {\n          LOG.warn(\"Exception in Responder\", e);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.stopIdleScan": "    void stopIdleScan() {\n      idleScanTimer.cancel();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeCurrentConnection": "    private void closeCurrentConnection(SelectionKey key, Throwable e) {\n      if (key != null) {\n        Connection c = (Connection)key.attachment();\n        if (c != null) {\n          closeConnection(c);\n          c = null;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doAccept": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server = (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel = server.accept()) != null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader = getReader();\n        Connection c = connectionManager.register(channel);\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeAll": "    void closeAll() {\n      // use a copy of the connections to be absolutely sure the concurrent\n      // iterator doesn't miss a connection\n      for (Connection connection : toArray()) {\n        close(connection);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.scheduleIdleScanTask": "    private void scheduleIdleScanTask() {\n      if (!running) {\n        return;\n      }\n      TimerTask idleScanTask = new TimerTask(){\n        @Override\n        public void run() {\n          if (!running) {\n            return;\n          }\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(Thread.currentThread().getName()+\": task running\");\n          }\n          try {\n            closeIdle(false);\n          } finally {\n            // explicitly reschedule so next execution occurs relative\n            // to the end of this scan, not the beginning\n            scheduleIdleScanTask();\n          }\n        }\n      };\n      idleScanTimer.schedule(idleScanTask, idleScanInterval);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getRpcErrorCodeProto": "    public RpcErrorCodeProto getRpcErrorCodeProto() {\n      return errCode;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.call": "  public abstract Writable call(RPC.RpcKind rpcKind, String protocol,\n      Writable param, long receiveTime) throws Exception;\n  \n  /**\n   * Authorize the incoming client connection.\n   * \n   * @param user client user\n   * @param protocolName - the protocol\n   * @param addr InetAddress of incoming connection\n   * @throws AuthorizationException when the client isn't authorized to talk the protocol\n   */\n  private void authorize(UserGroupInformation user, String protocolName,\n      InetAddress addr) throws AuthorizationException {\n    if (authorize) {\n      if (protocolName == null) {\n        throw new AuthorizationException(\"Null protocol not authorized\");\n      }\n      Class<?> protocol = null;\n      try {\n        protocol = getProtocolClass(protocolName, getConf());\n      } catch (ClassNotFoundException cfne) {\n        throw new AuthorizationException(\"Unknown protocol: \" + \n                                         protocolName);\n      }\n      serviceAuthorizationManager.authorize(user, protocol, getConf(), addr);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getSelector": "    synchronized Selector getSelector() { return selector; }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.isTerse": "    boolean isTerse(Class<?> t) {\n      return terseExceptions.contains(t.toString());\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.startIdleScan": "    void startIdleScan() {\n      scheduleIdleScanTask();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.toString": "    public String toString() {\n      return getHostAddress() + \":\" + remotePort; \n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.remove": "    private boolean remove(Connection connection) {\n      boolean removed = connections.remove(connection);\n      if (removed) {\n        count.getAndDecrement();\n      }\n      return removed;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      LOG.warn(\"PriviledgedActionException as:\"+this+\" cause:\"+cause);\n      if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle": "  public void handle(RMAppEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId appID = event.getApplicationId();\n      LOG.debug(\"Processing event for \" + appID + \" of type \"\n          + event.getType());\n      final RMAppState oldState = getState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getState()) {\n        LOG.info(appID + \" State change from \" + oldState + \" to \"\n            + getState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getState": "  public RMAppState getState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      if (initialize) {\n        resetDispatcher();\n        createAndInitActiveServices();\n      }\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          drained = eventQueue.isEmpty();\n          // blockNewEvents is only set when dispatcher is draining to stop,\n          // adding this check is to avoid the overhead of acquiring the lock\n          // and calling notify every time in the normal run of the loop.\n          if (blockNewEvents) {\n            synchronized (waitForDrained) {\n              if (drained) {\n                waitForDrained.notify();\n              }\n            }\n          }\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplication.getCurrentAppAttempt": "  public SchedulerApplicationAttempt getCurrentAppAttempt() {\n    return currentAttempt;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      ApplicationId appId, ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.SUCCESS, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getClientToAMTokenSecretManager": "  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ApplicationId appId,\n      ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.FAILURE, b);\n    add(Keys.DESCRIPTION, description, b);\n    add(Keys.PERMISSIONS, perm, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcServerException.getRpcStatusProto": "  public RpcStatusProto getRpcStatusProto() {\n    return RpcStatusProto.ERROR;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<String, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "RMAppAttempt is not killed when RMApp is at ACCEPTED",
            "Description": "When running some Hive on Tez jobs, the RM after a while gets into an unusable state where no jobs run. In the RM log I see the following exception:\n{code}\n2014-02-04 20:28:08,553 WARN  ipc.Server (Server.java:run(1978)) - IPC Server handler 0 on 8030, call org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.registerApplicationMaster from 172.18.145.156:40474 Call#0 Retry#0: error: java.lang.NullPointerException\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getTransferredContainers(AbstractYarnScheduler.java:48)\n        at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.registerApplicationMaster(ApplicationMasterService.java:278)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.registerApplicationMaster(ApplicationMasterProtocolPBServiceImpl.java:90)\n        at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:95)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1958)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1956)\n......\n2014-02-04 20:28:08,544 ERROR rmapp.RMAppImpl (RMAppImpl.java:handle(626)) - Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: ATTEMPT_REGISTERED at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:624)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:81)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:656)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:640)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:662)\n2014-02-04 20:28:08,549 INFO  resourcemanager.RMAuditLogger (RMAuditLogger.java:logSuccess(140)) - USER=hrt_qa  IP=172.18.145.156       OPERATION=Kill Application Request      TARGET=ClientRMService  RESULT=SUCCESS  APPID=application_1391543307203_0001\n2014-02-04 20:28:08,553 WARN  ipc.Server (Server.java:run(1978)) - IPC Server handler 0 on 8030, call org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB.registerApplicationMaster from 172.18.145.156:40474 Call#0 Retry#0: error: java.lang.NullPointerException\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getTransferredContainers(AbstractYarnScheduler.java:48)\n        at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.registerApplicationMaster(ApplicationMasterService.java:278)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.registerApplicationMaster(ApplicationMasterProtocolPBServiceImpl.java:90)\n        at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:95)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1958)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1956)\n{code}"
        }
    },
    {
        "filename": "YARN-5594.json",
        "creation_time": "2016-08-30T15:14:19.000+0000",
        "stack_trace": "```\ncom.google.protobuf.InvalidProtocolBufferException: Protocol message contained\nan invalid tag (zero).\nat com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:89)\nat com.google.protobuf.CodedInputStream.readTag(CodedInputStream.java:108)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto.<init>(YarnServerResourceManagerRecoveryProtos.java:4680)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto.<init>(YarnServerResourceManagerRecoveryProtos.java:4644)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$1.parsePartialFrom(YarnServerResourceManagerRecoveryProtos.java:4740)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$1.parsePartialFrom(YarnServerResourceManagerRecoveryProtos.java:4735)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder.mergeFrom(YarnServerResourceManagerRecoveryProtos.java:5075)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder.mergeFrom(YarnServerResourceManagerRecoveryProtos.java:4955)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:337)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:267)\nat com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:210)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:904)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.records.RMDelegationTokenIdentifierData.readFields(RMDelegationTokenIdentifierData.java:43)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadRMDTSecretManagerState(FileSystemRMStateStore.java:355)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadState(FileSystemRMStateStore.java:199)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:587)\nat org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1007)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1048)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1044)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.records.RMDelegationTokenIdentifierData.readFields": "  public void readFields(DataInput in) throws IOException {\n    builder.mergeFrom((DataInputStream) in);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadRMDTSecretManagerState": "  private void loadRMDTSecretManagerState(RMState rmState) throws Exception {\n    checkAndResumeUpdateOperation(rmDTSecretManagerRoot);\n    FileStatus[] childNodes = listStatusWithRetries(rmDTSecretManagerRoot);\n\n    for(FileStatus childNodeStatus : childNodes) {\n      assert childNodeStatus.isFile();\n      String childNodeName = childNodeStatus.getPath().getName();\n      if (checkAndRemovePartialRecordWithRetries(childNodeStatus.getPath())) {\n        continue;\n      }\n      if(childNodeName.startsWith(DELEGATION_TOKEN_SEQUENCE_NUMBER_PREFIX)) {\n        rmState.rmSecretManagerState.dtSequenceNumber =\n            Integer.parseInt(childNodeName.split(\"_\")[1]);\n        continue;\n      }\n\n      Path childNodePath = getNodePath(rmDTSecretManagerRoot, childNodeName);\n      byte[] childData = readFileWithRetries(childNodePath,\n          childNodeStatus.getLen());\n      ByteArrayInputStream is = new ByteArrayInputStream(childData);\n      try (DataInputStream fsIn = new DataInputStream(is)) {\n        if (childNodeName.startsWith(DELEGATION_KEY_PREFIX)) {\n          DelegationKey key = new DelegationKey();\n          key.readFields(fsIn);\n          rmState.rmSecretManagerState.masterKeyState.add(key);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Loaded delegation key: keyId=\" + key.getKeyId()\n                + \", expirationDate=\" + key.getExpiryDate());\n          }\n        } else if (childNodeName.startsWith(DELEGATION_TOKEN_PREFIX)) {\n          RMDelegationTokenIdentifierData identifierData =\n              new RMDelegationTokenIdentifierData();\n          identifierData.readFields(fsIn);\n          RMDelegationTokenIdentifier identifier =\n              identifierData.getTokenIdentifier();\n          long renewDate = identifierData.getRenewDate();\n\n          rmState.rmSecretManagerState.delegationTokenState.put(identifier,\n            renewDate);\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Loaded RMDelegationTokenIdentifier: \" + identifier\n                + \" renewDate=\" + renewDate);\n          }\n        } else {\n          LOG.warn(\"Unknown file for recovering RMDelegationTokenSecretManager\");\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.listStatusWithRetries": "  private FileStatus[] listStatusWithRetries(final Path path,\n      final PathFilter filter) throws Exception {\n    return new FSAction<FileStatus[]>() {\n      @Override\n      public FileStatus[] run() throws Exception {\n        return fs.listStatus(path, filter);\n      }\n    }.runWithRetries();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.checkAndResumeUpdateOperation": "  private void checkAndResumeUpdateOperation(Path path) throws Exception {\n    // Before loading the state information, check whether .new file exists.\n    // If it does, the prior updateFile is failed on half way. We need to\n    // complete replacing the old file first.\n    FileStatus[] newChildNodes =\n        listStatusWithRetries(path, new PathFilter() {\n      @Override\n      public boolean accept(Path path) {\n        return path.getName().endsWith(\".new\");\n      }\n    });\n    for(FileStatus newChildNodeStatus : newChildNodes) {\n      assert newChildNodeStatus.isFile();\n      String newChildNodeName = newChildNodeStatus.getPath().getName();\n      String childNodeName = newChildNodeName.substring(\n              0, newChildNodeName.length() - \".new\".length());\n      Path childNodePath =\n          new Path(newChildNodeStatus.getPath().getParent(), childNodeName);\n      replaceFile(newChildNodeStatus.getPath(), childNodePath);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.checkAndRemovePartialRecordWithRetries": "  private boolean checkAndRemovePartialRecordWithRetries(final Path record)\n      throws Exception {\n    return new FSAction<Boolean>() {\n      @Override\n      public Boolean run() throws Exception {\n        return checkAndRemovePartialRecord(record);\n      }\n    }.runWithRetries();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.readFileWithRetries": "  private byte[] readFileWithRetries(final Path inputPath, final long len)\n      throws Exception {\n    return new FSAction<byte[]>() {\n      @Override\n      public byte[] run() throws Exception {\n        return readFile(inputPath, len);\n      }\n    }.runWithRetries();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.getNodePath": "  Path getNodePath(Path root, String nodeName) {\n    return new Path(root, nodeName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadState": "  public synchronized RMState loadState() throws Exception {\n    RMState rmState = new RMState();\n    // recover DelegationTokenSecretManager\n    loadRMDTSecretManagerState(rmState);\n    // recover RM applications\n    loadRMAppState(rmState);\n    // recover AMRMTokenSecretManager\n    loadAMRMTokenSecretManagerState(rmState);\n    // recover reservation state\n    loadReservationSystemState(rmState);\n    return rmState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadReservationSystemState": "  private void loadReservationSystemState(RMState rmState) throws Exception {\n    try {\n      final ReservationStateFileProcessor fileProcessor = new\n          ReservationStateFileProcessor(rmState);\n      final Path rootDirectory = this.reservationRoot;\n\n      processDirectoriesOfFiles(fileProcessor, rootDirectory);\n    } catch (Exception e) {\n      LOG.error(\"Failed to load state.\", e);\n      throw e;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadRMAppState": "  private void loadRMAppState(RMState rmState) throws Exception {\n    try {\n      List<ApplicationAttemptStateData> attempts = new ArrayList<>();\n      final RMAppStateFileProcessor rmAppStateFileProcessor =\n          new RMAppStateFileProcessor(rmState, attempts);\n      final Path rootDirectory = this.rmAppRoot;\n\n      processDirectoriesOfFiles(rmAppStateFileProcessor, rootDirectory);\n\n      // go through all attempts and add them to their apps, Ideally, each\n      // attempt node must have a corresponding app node, because remove\n      // directory operation remove both at the same time\n      for (ApplicationAttemptStateData attemptState : attempts) {\n        ApplicationId appId = attemptState.getAttemptId().getApplicationId();\n        ApplicationStateData appState = rmState.appState.get(appId);\n        assert appState != null;\n        appState.attempts.put(attemptState.getAttemptId(), attemptState);\n      }\n      LOG.info(\"Done loading applications from FS state store\");\n    } catch (Exception e) {\n      LOG.error(\"Failed to load state.\", e);\n      throw e;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadAMRMTokenSecretManagerState": "  private void loadAMRMTokenSecretManagerState(RMState rmState)\n      throws Exception {\n    checkAndResumeUpdateOperation(amrmTokenSecretManagerRoot);\n    Path amrmTokenSecretManagerStateDataDir =\n        new Path(amrmTokenSecretManagerRoot, AMRMTOKEN_SECRET_MANAGER_NODE);\n    FileStatus status = getFileStatusWithRetries(\n        amrmTokenSecretManagerStateDataDir);\n    if (status == null) {\n      return;\n    }\n    assert status.isFile();\n    byte[] data = readFileWithRetries(amrmTokenSecretManagerStateDataDir,\n            status.getLen());\n    AMRMTokenSecretManagerStatePBImpl stateData =\n        new AMRMTokenSecretManagerStatePBImpl(\n          AMRMTokenSecretManagerStateProto.parseFrom(data));\n    rmState.amrmTokenSecretManagerState =\n        AMRMTokenSecretManagerState.newInstance(\n          stateData.getCurrentMasterKey(), stateData.getNextMasterKey());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(false);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover reservations\n    if (reservationSystem != null) {\n      reservationSystem.recover(state);\n    }\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n\n    // Use the customized yarn filter instead of the standard kerberos filter to\n    // allow users to authenticate using delegation tokens\n    // 4 conditions need to be satisfied -\n    // 1. security is enabled\n    // 2. http auth type is set to kerberos\n    // 3. \"yarn.resourcemanager.webapp.use-yarn-filter\" override is set to true\n    // 4. hadoop.http.filter.initializers container AuthenticationFilterInitializer\n\n    Configuration conf = getConfig();\n    boolean enableCorsFilter =\n        conf.getBoolean(YarnConfiguration.RM_WEBAPP_ENABLE_CORS_FILTER,\n            YarnConfiguration.DEFAULT_RM_WEBAPP_ENABLE_CORS_FILTER);\n    boolean useYarnAuthenticationFilter =\n        conf.getBoolean(\n          YarnConfiguration.RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER);\n    String authPrefix = \"hadoop.http.authentication.\";\n    String authTypeKey = authPrefix + \"type\";\n    String filterInitializerConfKey = \"hadoop.http.filter.initializers\";\n    String actualInitializers = \"\";\n    Class<?>[] initializersClasses =\n        conf.getClasses(filterInitializerConfKey);\n\n    // setup CORS\n    if (enableCorsFilter) {\n      conf.setBoolean(HttpCrossOriginFilterInitializer.PREFIX\n          + HttpCrossOriginFilterInitializer.ENABLED_SUFFIX, true);\n    }\n\n    boolean hasHadoopAuthFilterInitializer = false;\n    boolean hasRMAuthFilterInitializer = false;\n    if (initializersClasses != null) {\n      for (Class<?> initializer : initializersClasses) {\n        if (initializer.getName().equals(\n          AuthenticationFilterInitializer.class.getName())) {\n          hasHadoopAuthFilterInitializer = true;\n        }\n        if (initializer.getName().equals(\n          RMAuthenticationFilterInitializer.class.getName())) {\n          hasRMAuthFilterInitializer = true;\n        }\n      }\n      if (UserGroupInformation.isSecurityEnabled()\n          && useYarnAuthenticationFilter\n          && hasHadoopAuthFilterInitializer\n          && conf.get(authTypeKey, \"\").equals(\n            KerberosAuthenticationHandler.TYPE)) {\n        ArrayList<String> target = new ArrayList<String>();\n        for (Class<?> filterInitializer : initializersClasses) {\n          if (filterInitializer.getName().equals(\n            AuthenticationFilterInitializer.class.getName())) {\n            if (hasRMAuthFilterInitializer == false) {\n              target.add(RMAuthenticationFilterInitializer.class.getName());\n            }\n            continue;\n          }\n          target.add(filterInitializer.getName());\n        }\n        actualInitializers = StringUtils.join(\",\", target);\n\n        LOG.info(\"Using RM authentication filter(kerberos/delegation-token)\"\n            + \" for RM webapp authentication\");\n        RMAuthenticationFilter\n          .setDelegationTokenSecretManager(getClientRMService().rmDTSecretManager);\n        conf.set(filterInitializerConfKey, actualInitializers);\n      }\n    }\n\n    // if security is not enabled and the default filter initializer has not \n    // been set, set the initializer to include the\n    // RMAuthenticationFilterInitializer which in turn will set up the simple\n    // auth filter.\n\n    String initializers = conf.get(filterInitializerConfKey);\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      if (initializersClasses == null || initializersClasses.length == 0) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName());\n        conf.set(authTypeKey, \"simple\");\n      } else if (initializers.equals(StaticUserWebFilter.class.getName())) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName() + \",\"\n              + initializers);\n        conf.set(authTypeKey, \"simple\");\n      }\n    }\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .withCSRFProtection(YarnConfiguration.RM_CSRF_PREFIX)\n            .withXFSProtection(YarnConfiguration.RM_XFS_PREFIX)\n            .at(webAppAddress);\n    String proxyHostAndPort = WebAppUtils.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n\n    }\n    webApp = builder.start(new RMWebApp(this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    HAServiceState state = rmContext.getHAServiceState();\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    if (state == HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices(true);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(LeaderElectorService elector);\n\n  LeaderElectorService getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "Handle old RMDelegationToken format when recovering RM",
            "Description": "We've got that error after upgrade cluster from v.2.5.1 to 2.7.0.\n{noformat}\n2016-08-25 17:20:33,293 ERROR\norg.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Failed to\nload/recover state\ncom.google.protobuf.InvalidProtocolBufferException: Protocol message contained\nan invalid tag (zero).\nat com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:89)\nat com.google.protobuf.CodedInputStream.readTag(CodedInputStream.java:108)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto.<init>(YarnServerResourceManagerRecoveryProtos.java:4680)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto.<init>(YarnServerResourceManagerRecoveryProtos.java:4644)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$1.parsePartialFrom(YarnServerResourceManagerRecoveryProtos.java:4740)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$1.parsePartialFrom(YarnServerResourceManagerRecoveryProtos.java:4735)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder.mergeFrom(YarnServerResourceManagerRecoveryProtos.java:5075)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder.mergeFrom(YarnServerResourceManagerRecoveryProtos.java:4955)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:337)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:267)\nat com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:210)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:904)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.records.RMDelegationTokenIdentifierData.readFields(RMDelegationTokenIdentifierData.java:43)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadRMDTSecretManagerState(FileSystemRMStateStore.java:355)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadState(FileSystemRMStateStore.java:199)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:587)\nat org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1007)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1048)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1044\n{noformat}\nThe reason of this problem is that we use different formats of files /var/mapr/cluster/yarn/rm/system/FSRMStateRoot/RMDTSecretManagerRoot/RMDelegationToken* in these hadoop versions.\n\nThis fix handle old data format during RM recover if InvalidProtocolBufferException occures."
        }
    },
    {
        "filename": "YARN-7511.json",
        "creation_time": "2017-11-16T11:41:43.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at java.util.concurrent.ConcurrentHashMap.replaceNode(ConcurrentHashMap.java:1106)\n        at java.util.concurrent.ConcurrentHashMap.remove(ConcurrentHashMap.java:1097)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.resourceLocalizationFailed(ResourceSet.java:151)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$ResourceLocalizationFailedWhileRunningTransition.transition(ContainerImpl.java:821)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$ResourceLocalizationFailedWhileRunningTransition.transition(ContainerImpl.java:813)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1335)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:95)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1372)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1365)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:834)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.resourceLocalizationFailed": "  public void resourceLocalizationFailed(LocalResourceRequest request) {\n    pendingResources.remove(request);\n    resourcesFailedToBeLocalized.add(request);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.transition": "    public void transition(ContainerImpl container, ContainerEvent event) {\n      // Pause the process/process-grp if it is supported by the container\n      container.dispatcher.getEventHandler().handle(\n          new ContainersLauncherEvent(container,\n              ContainersLauncherEventType.RESUME_CONTAINER));\n      ContainerResumeEvent resumeEvent = (ContainerResumeEvent) event;\n      container.addDiagnostics(resumeEvent.getDiagnostic(), \"\\n\");\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.doRelaunch": "    private void doRelaunch(final ContainerImpl container,\n        int remainingRetryAttempts, final int retryInterval) {\n      LOG.info(\"Relaunching Container \" + container.getContainerId()\n          + \". Remaining retry attempts(after relaunch) : \"\n          + remainingRetryAttempts + \". Interval between retries is \"\n          + retryInterval + \"ms\");\n      container.wasLaunched  = false;\n      container.metrics.endRunningContainer();\n      if (retryInterval == 0) {\n        container.sendRelaunchEvent();\n      } else {\n        // wait for some time, then send launch event\n        new Thread() {\n          @Override\n          public void run() {\n            try {\n              Thread.sleep(retryInterval);\n              container.sendRelaunchEvent();\n            } catch (InterruptedException e) {\n              return;\n            }\n          }\n        }.start();\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.configureRetryContext": "  private static ContainerRetryContext configureRetryContext(\n      Configuration conf, ContainerLaunchContext launchContext,\n      ContainerId containerId) {\n    ContainerRetryContext context;\n    if (launchContext != null\n        && launchContext.getContainerRetryContext() != null) {\n      context = launchContext.getContainerRetryContext();\n    } else {\n      context = ContainerRetryContext.NEVER_RETRY_CONTEXT;\n    }\n    int minimumRestartInterval = conf.getInt(\n        YarnConfiguration.NM_CONTAINER_RETRY_MINIMUM_INTERVAL_MS,\n        YarnConfiguration.DEFAULT_NM_CONTAINER_RETRY_MINIMUM_INTERVAL_MS);\n    if (context.getRetryPolicy() != ContainerRetryPolicy.NEVER_RETRY\n        && context.getRetryInterval() < minimumRestartInterval) {\n      LOG.info(\"Set restart interval to minimum value \" + minimumRestartInterval\n          + \"ms for container \" + containerId);\n      context.setRetryInterval(minimumRestartInterval);\n    }\n    return context;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.createReInitContext": "    protected ReInitializationContext createReInitContext(ContainerImpl\n        container, ContainerEvent event) {\n      container.addDiagnostics(\"Container upgrade will be Rolled-back.\\n\");\n      LOG.warn(\"Container [\" + container.getContainerId() + \"]\" +\n          \" about to be explicitly Rolledback !!\");\n      return container.reInitContext.createContextForRollback();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.canRollback": "  public boolean canRollback() {\n    return (this.reInitContext != null)\n        && (this.reInitContext.canRollback());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.sendScheduleEvent": "  private void sendScheduleEvent() {\n    if (recoveredStatus == RecoveredContainerStatus.PAUSED) {\n      ContainersLauncherEventType launcherEvent;\n      launcherEvent = ContainersLauncherEventType.RECOVER_PAUSED_CONTAINER;\n      dispatcher.getEventHandler()\n          .handle(new ContainersLauncherEvent(this, launcherEvent));\n    } else {\n      dispatcher.getEventHandler().handle(new ContainerSchedulerEvent(this,\n          ContainerSchedulerEventType.SCHEDULE_CONTAINER));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getResource": "  public Resource getResource() {\n    return Resources.clone(\n        this.containerTokenIdentifier.getResource());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.shouldBeUploadedToSharedCache": "  private static boolean shouldBeUploadedToSharedCache(ContainerImpl container,\n      LocalResourceRequest resource) {\n    return container.resourceSet.getResourcesUploadPolicies().get(resource);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.toString": "  public String toString() {\n    this.readLock.lock();\n    try {\n      return this.containerId.toString();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.addDiagnostics": "  private void addDiagnostics(String... diags) {\n    for (String s : diags) {\n      this.diagnostics.append(\"[\" + dateFormat.format(new Date()) + \"]\" + s);\n    }\n    if (diagnostics.length() > diagnosticsMaxSize) {\n      diagnostics.delete(0, diagnostics.length() - diagnosticsMaxSize);\n    }\n    try {\n      stateStore.storeContainerDiagnostics(containerId, diagnostics);\n    } catch (IOException e) {\n      LOG.warn(\"Unable to update diagnostics in state store for \"\n          + containerId, e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.sendContainerMonitorStartEvent": "  private void sendContainerMonitorStartEvent() {\n    long launchDuration = clock.getTime() - containerLaunchStartTime;\n    metrics.addContainerLaunchDuration(launchDuration);\n\n    long pmemBytes = getResource().getMemorySize() * 1024 * 1024L;\n    float pmemRatio = daemonConf.getFloat(\n        YarnConfiguration.NM_VMEM_PMEM_RATIO,\n        YarnConfiguration.DEFAULT_NM_VMEM_PMEM_RATIO);\n    long vmemBytes = (long) (pmemRatio * pmemBytes);\n    int cpuVcores = getResource().getVirtualCores();\n    long localizationDuration = containerLaunchStartTime -\n        containerLocalizationStartTime;\n    dispatcher.getEventHandler().handle(\n        new ContainerStartMonitoringEvent(containerId,\n        vmemBytes, pmemBytes, cpuVcores, launchDuration,\n        localizationDuration));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.isReInitializing": "  public boolean isReInitializing() {\n    return this.isReInitializing;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getLaunchContext": "  public ContainerLaunchContext getLaunchContext() {\n    this.readLock.lock();\n    try {\n      return launchContext;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getContainerId": "  public ContainerId getContainerId() {\n    return this.containerId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.hasDefaultExitCode": "  private boolean hasDefaultExitCode() {\n    return (this.exitCode == ContainerExitStatus.INVALID);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle": "  public void handle(ContainerEvent event) {\n    try {\n      this.writeLock.lock();\n\n      ContainerId containerID = event.getContainerID();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Processing \" + containerID + \" of type \" + event.getType());\n      }\n      ContainerState oldState = stateMachine.getCurrentState();\n      ContainerState newState = null;\n      try {\n        newState =\n            stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.warn(\"Can't handle this event at current state: Current: [\"\n            + oldState + \"], eventType: [\" + event.getType() + \"],\" +\n            \" container: [\" + containerID + \"]\", e);\n      }\n      if (newState != null && oldState != newState) {\n        LOG.info(\"Container \" + containerID + \" transitioned from \"\n            + oldState\n            + \" to \" + newState);\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.setContainerTokenIdentifier": "  public void setContainerTokenIdentifier(ContainerTokenIdentifier token) {\n    this.writeLock.lock();\n    try {\n      this.containerTokenIdentifier = token;\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getContainerState": "  public ContainerState getContainerState() {\n    this.readLock.lock();\n    try {\n      return stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.setIsReInitializing": "  public void setIsReInitializing(boolean isReInitializing) {\n    if (this.isReInitializing && !isReInitializing) {\n      metrics.endReInitingContainer();\n    }\n    this.isReInitializing = isReInitializing;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.cleanup": "  public void cleanup() {\n    Map<LocalResourceVisibility, Collection<LocalResourceRequest>> rsrc =\n        resourceSet.getAllResourcesByVisibility();\n    dispatcher.getEventHandler().handle(\n        new ContainerLocalizationCleanupEvent(this, rsrc));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.sendFinishedEvents": "  private void sendFinishedEvents() {\n    // Inform the application\n    @SuppressWarnings(\"rawtypes\")\n    EventHandler eventHandler = dispatcher.getEventHandler();\n\n    ContainerStatus containerStatus = cloneAndGetContainerStatus();\n    eventHandler.handle(\n        new ApplicationContainerFinishedEvent(containerStatus, startTime));\n\n    // Tell the scheduler the container is Done\n    eventHandler.handle(new ContainerSchedulerEvent(this,\n        ContainerSchedulerEventType.CONTAINER_COMPLETED));\n    // Remove the container from the resource-monitor\n    eventHandler.handle(new ContainerStopMonitoringEvent(containerId));\n    // Tell the logService too\n    eventHandler.handle(new LogHandlerContainerFinishedEvent(\n        containerId, containerTokenIdentifier.getContainerType(), exitCode));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getUser": "  public String getUser() {\n    this.readLock.lock();\n    try {\n      return this.user;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.shouldRetry": "  public static boolean shouldRetry(int errorCode,\n      ContainerRetryContext retryContext, int remainingRetryAttempts) {\n    if (errorCode == ExitCode.SUCCESS.getExitCode()\n        || errorCode == ExitCode.FORCE_KILLED.getExitCode()\n        || errorCode == ExitCode.TERMINATED.getExitCode()) {\n      return false;\n    }\n\n    ContainerRetryPolicy retryPolicy = retryContext.getRetryPolicy();\n    if (retryPolicy == ContainerRetryPolicy.RETRY_ON_ALL_ERRORS\n        || (retryPolicy == ContainerRetryPolicy.RETRY_ON_SPECIFIC_ERROR_CODES\n        && retryContext.getErrorCodes() != null\n        && retryContext.getErrorCodes().contains(errorCode))) {\n      return remainingRetryAttempts > 0\n          || remainingRetryAttempts == ContainerRetryContext.RETRY_FOREVER;\n    }\n\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getCurrentState": "  public org.apache.hadoop.yarn.api.records.ContainerState getCurrentState() {\n    switch (stateMachine.getCurrentState()) {\n    case NEW:\n    case LOCALIZING:\n    case LOCALIZATION_FAILED:\n    case SCHEDULED:\n    case PAUSED:\n    case RESUMING:\n    case RUNNING:\n    case RELAUNCHING:\n    case REINITIALIZING:\n    case REINITIALIZING_AWAITING_KILL:\n    case EXITED_WITH_SUCCESS:\n    case EXITED_WITH_FAILURE:\n    case KILLING:\n    case CONTAINER_CLEANEDUP_AFTER_KILL:\n    case CONTAINER_RESOURCES_CLEANINGUP:\n    case PAUSING:\n      return org.apache.hadoop.yarn.api.records.ContainerState.RUNNING;\n    case DONE:\n    default:\n      return org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getContainerTokenIdentifier": "  public ContainerTokenIdentifier getContainerTokenIdentifier() {\n    this.readLock.lock();\n    try {\n      return this.containerTokenIdentifier;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      listener.preTransition(operand, currentState, event);\n      STATE oldState = currentState;\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      listener.postTransition(operand, oldState, currentState, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.postTransition": "    public void postTransition(Object op, Enum beforeState, Enum afterState,\n        Object processedEvent) { }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.preTransition": "    public void preTransition(Object op, Enum beforeState,\n        Object eventToBeProcessed) { }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        Application app = this.context.getApplications().get(appID);\n        if (app == null) {\n          LOG.info(\"couldn't find application \" + appID + \" while processing\"\n              + \" FINISH_APPS event. The ResourceManager allocated resources\"\n              + \" for this application to the NodeManager but no active\"\n              + \" containers were found to process.\");\n          continue;\n        }\n\n        boolean shouldDropEvent = false;\n        for (Container container : app.getContainers().values()) {\n          if (container.isRecovering()) {\n            LOG.info(\"drop FINISH_APPS event to \" + appID + \" because \"\n                + \"container \" + container.getContainerId()\n                + \" is recovering\");\n            shouldDropEvent = true;\n            break;\n          }\n        }\n        if (shouldDropEvent) {\n          continue;\n        }\n\n        String diagnostic = \"\";\n        if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Application killed on shutdown\";\n        } else if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Application killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                diagnostic));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId containerId : containersFinishedEvent\n          .getContainersToCleanup()) {\n        ApplicationId appId =\n            containerId.getApplicationAttemptId().getApplicationId();\n        Application app = this.context.getApplications().get(appId);\n        if (app == null) {\n          LOG.warn(\"couldn't find app \" + appId + \" while processing\"\n              + \" FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        Container container = app.getContainers().get(containerId);\n        if (container == null) {\n          LOG.warn(\"couldn't find container \" + containerId\n              + \" while processing FINISH_CONTAINERS event\");\n          continue;\n        }\n\n        if (container.isRecovering()) {\n          LOG.info(\"drop FINISH_CONTAINERS event to \" + containerId\n              + \" because container is recovering\");\n          continue;\n        }\n\n        this.dispatcher.getEventHandler().handle(\n              new ContainerKillEvent(containerId,\n                  ContainerExitStatus.KILLED_BY_RESOURCEMANAGER,\n                  \"Container Killed by ResourceManager\"));\n      }\n      break;\n    case UPDATE_CONTAINERS:\n      CMgrUpdateContainersEvent containersDecreasedEvent =\n          (CMgrUpdateContainersEvent) event;\n      for (org.apache.hadoop.yarn.api.records.Container container\n          : containersDecreasedEvent.getContainersToUpdate()) {\n        try {\n          ContainerTokenIdentifier containerTokenIdentifier =\n              BuilderUtils.newContainerTokenIdentifier(\n                  container.getContainerToken());\n          updateContainerInternal(container.getId(),\n              containerTokenIdentifier);\n        } catch (YarnException e) {\n          LOG.error(\"Unable to decrease container resource\", e);\n        } catch (IOException e) {\n          LOG.error(\"Unable to update container resource in store\", e);\n        }\n      }\n      break;\n    case SIGNAL_CONTAINERS:\n      CMgrSignalContainersEvent containersSignalEvent =\n          (CMgrSignalContainersEvent) event;\n      for (SignalContainerRequest request : containersSignalEvent\n          .getContainersToSignal()) {\n        internalSignalToContainer(request, \"ResourceManager\");\n      }\n      break;\n    default:\n        throw new YarnRuntimeException(\n            \"Got an unknown ContainerManagerEvent type: \" + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.updateContainerInternal": "  private void updateContainerInternal(ContainerId containerId,\n      ContainerTokenIdentifier containerTokenIdentifier)\n      throws YarnException, IOException {\n    Container container = context.getContainers().get(containerId);\n    // Check container existence\n    if (container == null) {\n      if (nodeStatusUpdater.isContainerRecentlyStopped(containerId)) {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" was recently stopped on node manager.\");\n      } else {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" is not handled by this NodeManager\");\n      }\n    }\n    // Check container version.\n    int currentVersion = container.getContainerTokenIdentifier().getVersion();\n    if (containerTokenIdentifier.getVersion() <= currentVersion) {\n      throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n          + \" has update version [\" + currentVersion + \"] >= requested version\"\n          + \" [\" + containerTokenIdentifier.getVersion() + \"]\");\n    }\n\n    // Check validity of the target resource.\n    Resource currentResource = container.getResource();\n    ExecutionType currentExecType =\n        container.getContainerTokenIdentifier().getExecutionType();\n    boolean isResourceChange = false;\n    boolean isExecTypeUpdate = false;\n    Resource targetResource = containerTokenIdentifier.getResource();\n    ExecutionType targetExecType = containerTokenIdentifier.getExecutionType();\n\n    // Is true if either the resources has increased or execution type\n    // updated from opportunistic to guaranteed\n    boolean isIncrease = false;\n    if (!currentResource.equals(targetResource)) {\n      isResourceChange = true;\n      isIncrease = Resources.fitsIn(currentResource, targetResource)\n          && !Resources.fitsIn(targetResource, currentResource);\n    } else if (!currentExecType.equals(targetExecType)) {\n      isExecTypeUpdate = true;\n      isIncrease = currentExecType == ExecutionType.OPPORTUNISTIC &&\n          targetExecType == ExecutionType.GUARANTEED;\n    }\n    if (isIncrease) {\n      org.apache.hadoop.yarn.api.records.Container increasedContainer = null;\n      if (isResourceChange) {\n        increasedContainer =\n            org.apache.hadoop.yarn.api.records.Container.newInstance(\n                containerId, null, null, targetResource, null, null,\n                currentExecType);\n        if (context.getIncreasedContainers().putIfAbsent(containerId,\n            increasedContainer) != null){\n          throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n              + \" resource is being increased -or- \" +\n              \"is undergoing ExecutionType promoted.\");\n        }\n      }\n    }\n    this.readLock.lock();\n    try {\n      if (!serviceStopped) {\n        // Dispatch message to Container to actually\n        // make the change.\n        dispatcher.getEventHandler().handle(new UpdateContainerTokenEvent(\n            container.getContainerId(), containerTokenIdentifier,\n            isResourceChange, isExecTypeUpdate, isIncrease));\n      } else {\n        throw new YarnException(\n            \"Unable to change container resource as the NodeManager is \"\n                + \"in the process of shutting down\");\n      }\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.internalSignalToContainer": "  private void internalSignalToContainer(SignalContainerRequest request,\n      String sentBy) {\n    ContainerId containerId = request.getContainerId();\n    Container container = this.context.getContainers().get(containerId);\n    if (container != null) {\n      LOG.info(containerId + \" signal request \" + request.getCommand()\n            + \" by \" + sentBy);\n      this.dispatcher.getEventHandler().handle(\n          new SignalContainersLauncherEvent(container,\n              request.getCommand()));\n    } else {\n      LOG.info(\"Container \" + containerId + \" no longer exists\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerResourceFailedEvent.getDiagnosticMessage": "  public String getDiagnosticMessage() {\n    return diagnosticMesage;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerKillEvent.getDiagnostic": "  public String getDiagnostic() {\n    return this.diagnostic;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.UpdateContainerTokenEvent.getUpdatedToken": "  public ContainerTokenIdentifier getUpdatedToken() {\n    return updatedToken;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerExitEvent.getExitCode": "  public int getExitCode() {\n    return this.exitCode;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerExitEvent.getDiagnosticInfo": "  public String getDiagnosticInfo() {\n    return diagnosticInfo;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerResourceLocalizedEvent.getLocation": "  public Path getLocation() {\n    return loc;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerResumeEvent.getDiagnostic": "  public String getDiagnostic() {\n    return this.diagnostic;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerPauseEvent.getDiagnostic": "  public String getDiagnostic() {\n    return this.diagnostic;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerKillEvent.getContainerExitStatus": "  public int getContainerExitStatus() {\n    return this.exitStatus;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "NPE in ContainerLocalizer when localization failed for running container",
            "Description": "Error log:\r\n{noformat}\r\n2017-09-30 20:14:32,839 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\r\njava.lang.NullPointerException\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ConcurrentHashMap.replaceNode(ConcurrentHashMap.java:1106)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ConcurrentHashMap.remove(ConcurrentHashMap.java:1097)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.resourceLocalizationFailed(ResourceSet.java:151)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$ResourceLocalizationFailedWhileRunningTransition.transition(ContainerImpl.java:821)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$ResourceLocalizationFailedWhileRunningTransition.transition(ContainerImpl.java:813)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1335)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:95)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1372)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1365)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(Thread.java:834)\r\n2017-09-30 20:14:32,842 INFO [AsyncDispatcher ShutDown handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..\r\n{noformat}\r\n\r\nReproduce this problem:\r\n1. Container was running and ContainerManagerImpl#localize was called for this container\r\n2. Localization failed in ResourceLocalizationService$LocalizerRunner#run and sent out ContainerResourceFailedEvent with null LocalResourceRequest.\r\n3. NPE when ResourceLocalizationFailedWhileRunningTransition#transition --> container.resourceSet.resourceLocalizationFailed(null)\r\n\r\nI think we can fix this problem through ensuring that request is not null before remove it."
        }
    },
    {
        "filename": "YARN-3790.json",
        "creation_time": "2015-06-10T04:53:40.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: expected:<6144> but was:<8192>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:743)\n\tat org.junit.Assert.assertEquals(Assert.java:118)\n\tat org.junit.Assert.assertEquals(Assert.java:555)\n\tat org.junit.Assert.assertEquals(Assert.java:542)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.assertMetrics(TestWorkPreservingRMRestart.java:853)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.checkFSQueue(TestWorkPreservingRMRestart.java:342)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testSchedulerRecovery(TestWorkPreservingRMRestart.java:241)\n```",
        "source_code": {},
        "bug_report": {
            "Title": "usedResource from rootQueue metrics may get stale data for FS scheduler after recovering the container",
            "Description": "Failure trace is as follows\n\n{noformat}\nTests run: 28, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 284.078 sec <<< FAILURE! - in org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart\ntestSchedulerRecovery[1](org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart)  Time elapsed: 6.502 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<6144> but was:<8192>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:743)\n\tat org.junit.Assert.assertEquals(Assert.java:118)\n\tat org.junit.Assert.assertEquals(Assert.java:555)\n\tat org.junit.Assert.assertEquals(Assert.java:542)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.assertMetrics(TestWorkPreservingRMRestart.java:853)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.checkFSQueue(TestWorkPreservingRMRestart.java:342)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testSchedulerRecovery(TestWorkPreservingRMRestart.java:241)\n{noformat}"
        }
    },
    {
        "filename": "YARN-6068.json",
        "creation_time": "2017-01-07T03:16:07.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FAILED at RUNNING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:459)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:64)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:1084)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:1076)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle": "  public void handle(ApplicationEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId applicationID = event.getApplicationID();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            \"Processing \" + applicationID + \" of type \" + event.getType());\n      }\n      ApplicationState oldState = stateMachine.getCurrentState();\n      ApplicationState newState = null;\n      try {\n        // queue event requesting init of the same app\n        newState = stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.warn(\"Can't handle this event at current state\", e);\n      }\n      if (newState != null && oldState != newState) {\n        LOG.info(\"Application \" + applicationID + \" transitioned from \"\n            + oldState + \" to \" + newState);\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        Application app = this.context.getApplications().get(appID);\n        if (app == null) {\n          LOG.warn(\"couldn't find application \" + appID + \" while processing\"\n              + \" FINISH_APPS event\");\n          continue;\n        }\n        String diagnostic = \"\";\n        if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Application killed on shutdown\";\n        } else if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Application killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                diagnostic));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId container : containersFinishedEvent\n          .getContainersToCleanup()) {\n          this.dispatcher.getEventHandler().handle(\n              new ContainerKillEvent(container,\n                  ContainerExitStatus.KILLED_BY_RESOURCEMANAGER,\n                  \"Container Killed by ResourceManager\"));\n      }\n      break;\n    case DECREASE_CONTAINERS_RESOURCE:\n      CMgrDecreaseContainersResourceEvent containersDecreasedEvent =\n          (CMgrDecreaseContainersResourceEvent) event;\n      for (org.apache.hadoop.yarn.api.records.Container container\n          : containersDecreasedEvent.getContainersToDecrease()) {\n        try {\n          changeContainerResourceInternal(container.getId(),\n              container.getVersion(), container.getResource(), false);\n        } catch (YarnException e) {\n          LOG.error(\"Unable to decrease container resource\", e);\n        } catch (IOException e) {\n          LOG.error(\"Unable to update container resource in store\", e);\n        }\n      }\n      break;\n    case SIGNAL_CONTAINERS:\n      CMgrSignalContainersEvent containersSignalEvent =\n          (CMgrSignalContainersEvent) event;\n      for (SignalContainerRequest request : containersSignalEvent\n          .getContainersToSignal()) {\n        internalSignalToContainer(request, \"ResourceManager\");\n      }\n      break;\n    default:\n        throw new YarnRuntimeException(\n            \"Got an unknown ContainerManagerEvent type: \" + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.changeContainerResourceInternal": "  private void changeContainerResourceInternal(ContainerId containerId,\n      int containerVersion, Resource targetResource, boolean increase)\n          throws YarnException, IOException {\n    Container container = context.getContainers().get(containerId);\n    // Check container existence\n    if (container == null) {\n      if (nodeStatusUpdater.isContainerRecentlyStopped(containerId)) {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" was recently stopped on node manager.\");\n      } else {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" is not handled by this NodeManager\");\n      }\n    }\n    // Check container state\n    org.apache.hadoop.yarn.server.nodemanager.\n        containermanager.container.ContainerState currentState =\n        container.getContainerState();\n    if (currentState != org.apache.hadoop.yarn.server.\n        nodemanager.containermanager.container.ContainerState.RUNNING) {\n      throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n          + \" is in \" + currentState.name() + \" state.\"\n          + \" Resource can only be changed when a container is in\"\n          + \" RUNNING state\");\n    }\n    // Check validity of the target resource.\n    Resource currentResource = container.getResource();\n    if (currentResource.equals(targetResource)) {\n      LOG.warn(\"Unable to change resource for container \"\n          + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is the same as the current resource\");\n      return;\n    }\n    if (increase && !Resources.fitsIn(currentResource, targetResource)) {\n      throw RPCUtil.getRemoteException(\"Unable to increase resource for \"\n          + \"container \" + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is smaller than the current resource \"\n          + currentResource.toString());\n    }\n    if (!increase &&\n        (!Resources.fitsIn(Resources.none(), targetResource)\n            || !Resources.fitsIn(targetResource, currentResource))) {\n      throw RPCUtil.getRemoteException(\"Unable to decrease resource for \"\n          + \"container \" + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is not smaller than the current resource \"\n          + currentResource.toString());\n    }\n    if (increase) {\n      org.apache.hadoop.yarn.api.records.Container increasedContainer =\n          org.apache.hadoop.yarn.api.records.Container.newInstance(\n              containerId, null, null, targetResource, null, null);\n      if (context.getIncreasedContainers().putIfAbsent(containerId,\n          increasedContainer) != null){\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" resource is being increased.\");\n      }\n    }\n    this.readLock.lock();\n    try {\n      if (!serviceStopped) {\n        // Persist container resource change for recovery\n        this.context.getNMStateStore().storeContainerResourceChanged(\n            containerId, containerVersion, targetResource);\n        getContainersMonitor().handle(\n            new ChangeMonitoringContainerResourceEvent(\n                containerId, targetResource));\n      } else {\n        throw new YarnException(\n            \"Unable to change container resource as the NodeManager is \"\n                + \"in the process of shutting down\");\n      }\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.internalSignalToContainer": "  private void internalSignalToContainer(SignalContainerRequest request,\n      String sentBy) {\n    ContainerId containerId = request.getContainerId();\n    Container container = this.context.getContainers().get(containerId);\n    if (container != null) {\n      LOG.info(containerId + \" signal request \" + request.getCommand()\n            + \" by \" + sentBy);\n      this.dispatcher.getEventHandler().handle(\n          new SignalContainersLauncherEvent(container,\n              request.getCommand()));\n    } else {\n      LOG.info(\"Container \" + containerId + \" no longer exists\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        stopped = true;\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Log aggregation get failed when NM restart even with recovery",
            "Description": "The exception log is as following:\n{noformat}\n2017-01-05 19:16:36,352 INFO  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:abortLogAggregation(527)) - Aborting log aggregation for application_1483640789847_0001\n2017-01-05 19:16:36,352 WARN  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:run(399)) - Aggregation did not complete for application application_1483640789847_0001\n2017-01-05 19:16:36,353 WARN  application.ApplicationImpl (ApplicationImpl.java:handle(461)) - Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FAILED at RUNNING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:459)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:64)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:1084)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:1076)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\n2017-01-05 19:16:36,355 INFO  application.ApplicationImpl (ApplicationImpl.java:handle(464)) - Application application_1483640789847_0001 transitioned from RUNNING to null\n{noformat}"
        }
    },
    {
        "filename": "YARN-903.json",
        "creation_time": "2013-07-07T08:35:30.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000002 is not handled by this NodeManager\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:45)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeGetAndStopContainerRequest(ContainerManagerImpl.java:614)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stopContainer(ContainerManagerImpl.java:538)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagementProtocolPBServiceImpl.stopContainer(ContainerManagementProtocolPBServiceImpl.java:88)\n\tat org.apache.hadoop.yarn.proto.ContainerManagementProtocol$ContainerManagementProtocolService$2.callBlockingMethod(ContainerManagementProtocol.java:85)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:605)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1033)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1868)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1864)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1862)\n\norg.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000001 is not handled by this NodeManager\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:45)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeGetAndStopContainerRequest(ContainerManagerImpl.java:614)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stopContainer(ContainerManagerImpl.java:538)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagementProtocolPBServiceImpl.stopContainer(ContainerManagementProtocolPBServiceImpl.java:88)\n\tat org.apache.hadoop.yarn.proto.ContainerManagementProtocol$ContainerManagementProtocolService$2.callBlockingMethod(ContainerManagementProtocol.java:85)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:605)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1033)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1868)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1864)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1862)\n\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1934)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)\n\tat org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$CallbackHandlerThread.run(AMRMClientAsyncImpl.java:281)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException": "  public static YarnException getRemoteException(String message) {\n    return new YarnException(message);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeGetAndStopContainerRequest": "  protected void authorizeGetAndStopContainerRequest(ContainerId containerId,\n      Container container, boolean stopRequest) throws YarnException {\n\n    UserGroupInformation remoteUgi = getRemoteUgi();\n    NMTokenIdentifier identifier = selectNMTokenIdentifier(remoteUgi);\n\n    /*\n     * For get/stop container status; we need to verify that 1) User (NMToken)\n     * application attempt only has started container. 2) Requested containerId\n     * belongs to the same application attempt (NMToken) which was used. (Note:-\n     * This will prevent user in knowing another application's containers).\n     */\n\n    if ((!identifier.getApplicationAttemptId().equals(\n      containerId.getApplicationAttemptId()))\n        || (container != null && !identifier.getApplicationAttemptId().equals(\n          container.getContainerId().getApplicationAttemptId()))) {\n      if (stopRequest) {\n        LOG.warn(identifier.getApplicationAttemptId()\n            + \" attempted to stop non-application container : \"\n            + container.getContainerId().toString());\n        NMAuditLogger.logFailure(\"UnknownUser\", AuditConstants.STOP_CONTAINER,\n          \"ContainerManagerImpl\", \"Trying to stop unknown container!\",\n          identifier.getApplicationAttemptId().getApplicationId(),\n          container.getContainerId());\n      } else {\n        LOG.warn(identifier.getApplicationAttemptId()\n            + \" attempted to get get status for non-application container : \"\n            + container.getContainerId().toString());\n      }\n      throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n          + \" is not started by this application attempt.\");\n    }\n\n    if (container == null) {\n      throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n          + \" is not handled by this NodeManager\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.selectNMTokenIdentifier": "  protected NMTokenIdentifier selectNMTokenIdentifier(\n      UserGroupInformation remoteUgi) {\n    Set<TokenIdentifier> tokenIdentifiers = remoteUgi.getTokenIdentifiers();\n    NMTokenIdentifier resultId = null;\n    for (TokenIdentifier id : tokenIdentifiers) {\n      if (id instanceof NMTokenIdentifier) {\n        resultId = (NMTokenIdentifier) id;\n        break;\n      }\n    }\n    return resultId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.getRemoteUgi": "  protected UserGroupInformation getRemoteUgi()\n      throws YarnException {\n    UserGroupInformation remoteUgi;\n    try {\n      remoteUgi = UserGroupInformation.getCurrentUser();\n    } catch (IOException e) {\n      String msg = \"Cannot obtain the user-name. Got exception: \"\n          + StringUtils.stringifyException(e);\n      LOG.warn(msg);\n      throw RPCUtil.getRemoteException(msg);\n    }\n    return remoteUgi;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stopContainer": "  public StopContainerResponse stopContainer(StopContainerRequest request)\n      throws YarnException, IOException {\n\n    ContainerId containerID = request.getContainerId();\n    String containerIDStr = containerID.toString();\n    Container container = this.context.getContainers().get(containerID);\n    LOG.info(\"Getting container-status for \" + containerIDStr);\n    authorizeGetAndStopContainerRequest(containerID, container, true);\n\n    StopContainerResponse response =\n        recordFactory.newRecordInstance(StopContainerResponse.class);\n\n    dispatcher.getEventHandler().handle(\n      new ContainerKillEvent(containerID,\n        \"Container killed by the ApplicationMaster.\"));\n\n    NMAuditLogger.logSuccess(container.getUser(),\n      AuditConstants.STOP_CONTAINER, \"ContainerManageImpl\", containerID\n        .getApplicationAttemptId().getApplicationId(), containerID);\n\n    // TODO: Move this code to appropriate place once kill_container is\n    // implemented.\n    nodeStatusUpdater.sendOutofBandHeartBeat();\n\n    return response;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                \"Application Killed by ResourceManager\"));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId container : containersFinishedEvent\n          .getContainersToCleanup()) {\n        String diagnostic = \"\";\n        if (containersFinishedEvent.getReason() == \n            CMgrCompletedContainersEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Container Killed on Shutdown\";\n        } else if (containersFinishedEvent.getReason() == \n            CMgrCompletedContainersEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Container Killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ContainerKillEvent(container, diagnostic));\n      }\n      break;\n    default:\n      LOG.warn(\"Invalid event \" + event.getType() + \". Ignoring.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagementProtocolPBServiceImpl.stopContainer": "  public StopContainerResponseProto stopContainer(RpcController arg0,\n      StopContainerRequestProto proto) throws ServiceException {\n    StopContainerRequestPBImpl request = new StopContainerRequestPBImpl(proto);\n    try {\n      StopContainerResponse response = real.stopContainer(request);\n      return ((StopContainerResponsePBImpl)response).getProto();\n    } catch (YarnException e) {\n      throw new ServiceException(e);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.call": "      public Writable call(RPC.Server server, String connectionProtocolName,\n          Writable writableRequest, long receiveTime) throws Exception {\n        RpcRequestWrapper request = (RpcRequestWrapper) writableRequest;\n        RequestHeaderProto rpcRequest = request.requestHeader;\n        String methodName = rpcRequest.getMethodName();\n        \n        \n        /** \n         * RPCs for a particular interface (ie protocol) are done using a\n         * IPC connection that is setup using rpcProxy.\n         * The rpcProxy's has a declared protocol name that is \n         * sent form client to server at connection time. \n         * \n         * Each Rpc call also sends a protocol name \n         * (called declaringClassprotocolName). This name is usually the same\n         * as the connection protocol name except in some cases. \n         * For example metaProtocols such ProtocolInfoProto which get info\n         * about the protocol reuse the connection but need to indicate that\n         * the actual protocol is different (i.e. the protocol is\n         * ProtocolInfoProto) since they reuse the connection; in this case\n         * the declaringClassProtocolName field is set to the ProtocolInfoProto.\n         */\n\n        String declaringClassProtoName = \n            rpcRequest.getDeclaringClassProtocolName();\n        long clientVersion = rpcRequest.getClientProtocolVersion();\n        if (server.verbose)\n          LOG.info(\"Call: connectionProtocolName=\" + connectionProtocolName + \n              \", method=\" + methodName);\n        \n        ProtoClassProtoImpl protocolImpl = getProtocolImpl(server, \n                              declaringClassProtoName, clientVersion);\n        BlockingService service = (BlockingService) protocolImpl.protocolImpl;\n        MethodDescriptor methodDescriptor = service.getDescriptorForType()\n            .findMethodByName(methodName);\n        if (methodDescriptor == null) {\n          String msg = \"Unknown method \" + methodName + \" called on \" \n                                + connectionProtocolName + \" protocol.\";\n          LOG.warn(msg);\n          throw new RpcNoSuchMethodException(msg);\n        }\n        Message prototype = service.getRequestPrototype(methodDescriptor);\n        Message param = prototype.newBuilderForType()\n            .mergeFrom(request.theRequestRead).build();\n        \n        Message result;\n        try {\n          long startTime = Time.now();\n          server.rpcDetailedMetrics.init(protocolImpl.protocolClass);\n          result = service.callBlockingMethod(methodDescriptor, null, param);\n          int processingTime = (int) (Time.now() - startTime);\n          int qTime = (int) (startTime - receiveTime);\n          if (LOG.isDebugEnabled()) {\n            LOG.info(\"Served: \" + methodName + \" queueTime= \" + qTime +\n                      \" procesingTime= \" + processingTime);\n          }\n          server.rpcMetrics.addRpcQueueTime(qTime);\n          server.rpcMetrics.addRpcProcessingTime(processingTime);\n          server.rpcDetailedMetrics.addProcessingTime(methodName,\n              processingTime);\n        } catch (ServiceException e) {\n          throw (Exception) e.getCause();\n        } catch (Exception e) {\n          throw e;\n        }\n        return new RpcResponseWrapper(result);\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.ProtobufRpcEngine.getProtocolImpl": "      private static ProtoClassProtoImpl getProtocolImpl(RPC.Server server,\n          String protoName, long clientVersion) throws RpcServerException {\n        ProtoNameVer pv = new ProtoNameVer(protoName, clientVersion);\n        ProtoClassProtoImpl impl = \n            server.getProtocolImplMap(RPC.RpcKind.RPC_PROTOCOL_BUFFER).get(pv);\n        if (impl == null) { // no match for Protocol AND Version\n          VerProtocolImpl highest = \n              server.getHighestSupportedProtocol(RPC.RpcKind.RPC_PROTOCOL_BUFFER, \n                  protoName);\n          if (highest == null) {\n            throw new RpcNoSuchProtocolException(\n                \"Unknown protocol: \" + protoName);\n          }\n          // protocol supported but not the version that client wants\n          throw new RPC.VersionMismatch(protoName, clientVersion,\n              highest.version);\n        }\n        return impl;\n      }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RPC.call": "    public Writable call(RPC.RpcKind rpcKind, String protocol,\n        Writable rpcRequest, long receiveTime) throws Exception {\n      return getRpcInvoker(rpcKind).call(this, protocol, rpcRequest,\n          receiveTime);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.run": "                     public Writable run() throws Exception {\n                       // make the call\n                       return call(call.rpcKind, call.connection.protocolName, \n                                   call.rpcRequest, call.timestamp);\n\n                     }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.setupResponse": "  private void setupResponse(ByteArrayOutputStream responseBuf,\n                             Call call, RpcStatusProto status, RpcErrorCodeProto erCode,\n                             Writable rv, String errorClass, String error) \n  throws IOException {\n    responseBuf.reset();\n    DataOutputStream out = new DataOutputStream(responseBuf);\n    RpcResponseHeaderProto.Builder headerBuilder =  \n        RpcResponseHeaderProto.newBuilder();\n    headerBuilder.setCallId(call.callId);\n    headerBuilder.setStatus(status);\n    headerBuilder.setServerIpcVersionNum(Server.CURRENT_VERSION);\n\n    if (status == RpcStatusProto.SUCCESS) {\n      RpcResponseHeaderProto header = headerBuilder.build();\n      final int headerLen = header.getSerializedSize();\n      int fullLength  = CodedOutputStream.computeRawVarint32Size(headerLen) +\n          headerLen;\n      try {\n        if (rv instanceof ProtobufRpcEngine.RpcWrapper) {\n          ProtobufRpcEngine.RpcWrapper resWrapper = \n              (ProtobufRpcEngine.RpcWrapper) rv;\n          fullLength += resWrapper.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          rv.write(out);\n        } else { // Have to serialize to buffer to get len\n          final DataOutputBuffer buf = new DataOutputBuffer();\n          rv.write(buf);\n          byte[] data = buf.getData();\n          fullLength += buf.getLength();\n          out.writeInt(fullLength);\n          header.writeDelimitedTo(out);\n          out.write(data, 0, buf.getLength());\n        }\n      } catch (Throwable t) {\n        LOG.warn(\"Error serializing call response for call \" + call, t);\n        // Call back to same function - this is OK since the\n        // buffer is reset at the top, and since status is changed\n        // to ERROR it won't infinite loop.\n        setupResponse(responseBuf, call, RpcStatusProto.ERROR,\n            RpcErrorCodeProto.ERROR_SERIALIZING_RESPONSE,\n            null, t.getClass().getName(),\n            StringUtils.stringifyException(t));\n        return;\n      }\n    } else { // Rpc Failure\n      headerBuilder.setExceptionClassName(errorClass);\n      headerBuilder.setErrorMsg(error);\n      headerBuilder.setErrorDetail(erCode);\n      RpcResponseHeaderProto header = headerBuilder.build();\n      int headerLen = header.getSerializedSize();\n      final int fullLength  = \n          CodedOutputStream.computeRawVarint32Size(headerLen) + headerLen;\n      out.writeInt(fullLength);\n      header.writeDelimitedTo(out);\n    }\n    if (call.connection.useWrap) {\n      wrapWithSasl(responseBuf, call);\n    }\n    call.setResponse(ByteBuffer.wrap(responseBuf.toByteArray()));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.close": "    private synchronized void close() throws IOException {\n      disposeSasl();\n      data = null;\n      dataLengthBuffer = null;\n      if (!channel.isOpen())\n        return;\n      try {socket.shutdownOutput();} catch(Exception e) {\n        LOG.debug(\"Ignoring socket shutdown exception\", e);\n      }\n      if (channel.isOpen()) {\n        try {channel.close();} catch(Exception e) {}\n      }\n      try {socket.close();} catch(Exception e) {}\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRespond": "    void doRespond(Call call) throws IOException {\n      synchronized (call.connection.responseQueue) {\n        call.connection.responseQueue.addLast(call);\n        if (call.connection.responseQueue.size() == 1) {\n          processResponse(call.connection.responseQueue, true);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doRunLoop": "    private void doRunLoop() {\n      long lastPurgeTime = 0;   // last check for old calls.\n\n      while (running) {\n        try {\n          waitPending();     // If a channel is being registered, wait.\n          writeSelector.select(PURGE_INTERVAL);\n          Iterator<SelectionKey> iter = writeSelector.selectedKeys().iterator();\n          while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            iter.remove();\n            try {\n              if (key.isValid() && key.isWritable()) {\n                  doAsyncWrite(key);\n              }\n            } catch (IOException e) {\n              LOG.info(getName() + \": doAsyncWrite threw exception \" + e);\n            }\n          }\n          long now = Time.now();\n          if (now < lastPurgeTime + PURGE_INTERVAL) {\n            continue;\n          }\n          lastPurgeTime = now;\n          //\n          // If there were some calls that have not been sent out for a\n          // long time, discard them.\n          //\n          if(LOG.isDebugEnabled()) {\n            LOG.debug(\"Checking for old call responses.\");\n          }\n          ArrayList<Call> calls;\n          \n          // get the list of channels from list of keys.\n          synchronized (writeSelector.keys()) {\n            calls = new ArrayList<Call>(writeSelector.keys().size());\n            iter = writeSelector.keys().iterator();\n            while (iter.hasNext()) {\n              SelectionKey key = iter.next();\n              Call call = (Call)key.attachment();\n              if (call != null && key.channel() == call.connection.channel) { \n                calls.add(call);\n              }\n            }\n          }\n          \n          for(Call call : calls) {\n            try {\n              doPurge(call, now);\n            } catch (IOException e) {\n              LOG.warn(\"Error in purging old calls \" + e);\n            }\n          }\n        } catch (OutOfMemoryError e) {\n          //\n          // we can run out of memory if we have too many threads\n          // log the event and sleep for a minute and give\n          // some thread(s) a chance to finish\n          //\n          LOG.warn(\"Out of Memory in server select\", e);\n          try { Thread.sleep(60000); } catch (Exception ie) {}\n        } catch (Exception e) {\n          LOG.warn(\"Exception in Responder\", e);\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.cleanupConnections": "    private void cleanupConnections(boolean force) {\n      if (force || numConnections > thresholdIdleConnections) {\n        long currentTime = Time.now();\n        if (!force && (currentTime - lastCleanupRunTime) < cleanupInterval) {\n          return;\n        }\n        int start = 0;\n        int end = numConnections - 1;\n        if (!force) {\n          start = rand.nextInt() % numConnections;\n          end = rand.nextInt() % numConnections;\n          int temp;\n          if (end < start) {\n            temp = start;\n            start = end;\n            end = temp;\n          }\n        }\n        int i = start;\n        int numNuked = 0;\n        while (i <= end) {\n          Connection c;\n          synchronized (connectionList) {\n            try {\n              c = connectionList.get(i);\n            } catch (Exception e) {return;}\n          }\n          if (c.timedOut(currentTime)) {\n            if (LOG.isDebugEnabled())\n              LOG.debug(getName() + \": disconnecting client \" + c.getHostAddress());\n            closeConnection(c);\n            numNuked++;\n            end--;\n            c = null;\n            if (!force && numNuked == maxConnectionsToNuke) break;\n          }\n          else i++;\n        }\n        lastCleanupRunTime = Time.now();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeCurrentConnection": "    private void closeCurrentConnection(SelectionKey key, Throwable e) {\n      if (key != null) {\n        Connection c = (Connection)key.attachment();\n        if (c != null) {\n          if (LOG.isDebugEnabled())\n            LOG.debug(getName() + \": disconnecting client \" + c.getHostAddress());\n          closeConnection(c);\n          c = null;\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.doAccept": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c = null;\n      ServerSocketChannel server = (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel = server.accept()) != null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        \n        Reader reader = getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey = reader.registerChannel(channel);\n          c = new Connection(readKey, channel, Time.now());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.closeConnection": "  private void closeConnection(Connection connection) {\n    synchronized (connectionList) {\n      if (connectionList.remove(connection))\n        numConnections--;\n    }\n    try {\n      connection.close();\n    } catch (IOException e) {\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.call": "  public abstract Writable call(RPC.RpcKind rpcKind, String protocol,\n      Writable param, long receiveTime) throws Exception;\n  \n  /**\n   * Authorize the incoming client connection.\n   * \n   * @param user client user\n   * @param protocolName - the protocol\n   * @param addr InetAddress of incoming connection\n   * @throws AuthorizationException when the client isn't authorized to talk the protocol\n   */\n  private void authorize(UserGroupInformation user, String protocolName,\n      InetAddress addr) throws AuthorizationException {\n    if (authorize) {\n      if (protocolName == null) {\n        throw new AuthorizationException(\"Null protocol not authorized\");\n      }\n      Class<?> protocol = null;\n      try {\n        protocol = getProtocolClass(protocolName, getConf());\n      } catch (ClassNotFoundException cfne) {\n        throw new AuthorizationException(\"Unknown protocol: \" + \n                                         protocolName);\n      }\n      serviceAuthorizationManager.authorize(user, protocol, getConf(), addr);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.getSelector": "    synchronized Selector getSelector() { return selector; }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.isTerse": "    boolean isTerse(Class<?> t) {\n      return terseExceptions.contains(t.toString());\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.Server.toString": "    public String toString() {\n      return getHostAddress() + \":\" + remotePort; \n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      LOG.error(\"PriviledgedActionException as:\"+this+\" cause:\"+cause);\n      if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-client.src.main.java.org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl.run": "    public void run() {\n      while (keepRunning) {\n        AllocateResponse response;\n        try {\n          if(savedException != null) {\n            LOG.error(\"Stopping callback due to: \", savedException);\n            handler.onError(savedException);\n            break;\n          }\n          response = responseQueue.take();\n        } catch (InterruptedException ex) {\n          LOG.info(\"Interrupted while waiting for queue\", ex);\n          continue;\n        }\n\n        if (response.getAMCommand() != null) {\n          boolean stop = false;\n          switch(response.getAMCommand()) {\n          case AM_RESYNC:\n          case AM_SHUTDOWN:\n            handler.onShutdownRequest();\n            LOG.info(\"Shutdown requested. Stopping callback.\");\n            stop = true;\n            break;\n          default:\n            String msg =\n                  \"Unhandled value of AMCommand: \" + response.getAMCommand();\n            LOG.error(msg);\n            throw new YarnRuntimeException(msg);\n          }\n          if(stop) {\n            // should probably stop heartbeating also YARN-763\n            break;\n          }\n        }\n        List<NodeReport> updatedNodes = response.getUpdatedNodes();\n        if (!updatedNodes.isEmpty()) {\n          handler.onNodesUpdated(updatedNodes);\n        }\n        \n        List<ContainerStatus> completed =\n            response.getCompletedContainersStatuses();\n        if (!completed.isEmpty()) {\n          handler.onContainersCompleted(completed);\n        }\n\n        List<Container> allocated = response.getAllocatedContainers();\n        if (!allocated.isEmpty()) {\n          handler.onContainersAllocated(allocated);\n        }\n        \n        progress = handler.getProgress();\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcServerException.getRpcErrorCodeProto": "  public RpcErrorCodeProto getRpcErrorCodeProto() {\n    return RpcErrorCodeProto.ERROR_RPC_SERVER;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ipc.RpcServerException.getRpcStatusProto": "  public RpcStatusProto getRpcStatusProto() {\n    return RpcStatusProto.ERROR;\n  }"
        },
        "bug_report": {
            "Title": "DistributedShell throwing Errors in logs after successfull completion",
            "Description": "I have tried running DistributedShell and also used ApplicationMaster of the same for my test.\nThe application is successfully running through logging some errors which would be useful to fix.\nBelow are the logs from NodeManager and ApplicationMasterode\n\nLog Snippet for NodeManager\n=============================\n2013-07-07 13:39:18,787 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Connecting to ResourceManager at localhost/127.0.0.1:9990. current no. of attempts is 1\n2013-07-07 13:39:19,050 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -325382586\n2013-07-07 13:39:19,052 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :1005046570\n2013-07-07 13:39:19,053 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as sunny-Inspiron:9993 with total resource of <memory:10240, vCores:8>\n2013-07-07 13:39:19,053 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests\n2013-07-07 13:39:35,256 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1373184544832_0001_000001 (auth:SIMPLE)\n2013-07-07 13:39:35,492 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1373184544832_0001_01_000001 by user sunny\n2013-07-07 13:39:35,507 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1373184544832_0001\n2013-07-07 13:39:35,511 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=sunny\tIP=127.0.0.1\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1373184544832_0001\tCONTAINERID=container_1373184544832_0001_01_000001\n2013-07-07 13:39:35,511 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1373184544832_0001 transitioned from NEW to INITING\n2013-07-07 13:39:35,512 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1373184544832_0001_01_000001 to application application_1373184544832_0001\n2013-07-07 13:39:35,518 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1373184544832_0001 transitioned from INITING to RUNNING\n2013-07-07 13:39:35,528 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000001 transitioned from NEW to LOCALIZING\n2013-07-07 13:39:35,540 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://localhost:9000/application/test.jar transitioned from INIT to DOWNLOADING\n2013-07-07 13:39:35,540 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1373184544832_0001_01_000001\n2013-07-07 13:39:35,675 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/sunny/Hadoop2/hadoopdata/nodemanagerdata/nmPrivate/container_1373184544832_0001_01_000001.tokens. Credentials list: \n2013-07-07 13:39:35,694 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user sunny\n2013-07-07 13:39:35,803 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/sunny/Hadoop2/hadoopdata/nodemanagerdata/nmPrivate/container_1373184544832_0001_01_000001.tokens to /home/sunny/Hadoop2/hadoopdata/nodemanagerdata/usercache/sunny/appcache/application_1373184544832_0001/container_1373184544832_0001_01_000001.tokens\n2013-07-07 13:39:35,803 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/sunny/Hadoop2/hadoopdata/nodemanagerdata/usercache/sunny/appcache/application_1373184544832_0001 = file:/home/sunny/Hadoop2/hadoopdata/nodemanagerdata/usercache/sunny/appcache/application_1373184544832_0001\n2013-07-07 13:39:36,136 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: \"\", exit_status: -1000, \n2013-07-07 13:39:36,406 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://localhost:9000/application/test.jar transitioned from DOWNLOADING to LOCALIZED\n2013-07-07 13:39:36,409 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000001 transitioned from LOCALIZING to LOCALIZED\n2013-07-07 13:39:36,524 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000001 transitioned from LOCALIZED to RUNNING\n2013-07-07 13:39:36,692 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, -c, /home/sunny/Hadoop2/hadoopdata/nodemanagerdata/usercache/sunny/appcache/application_1373184544832_0001/container_1373184544832_0001_01_000001/default_container_executor.sh]\n2013-07-07 13:39:37,144 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: \"\", exit_status: -1000, \n2013-07-07 13:39:38,147 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: \"\", exit_status: -1000, \n2013-07-07 13:39:39,151 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: \"\", exit_status: -1000, \n2013-07-07 13:39:39,209 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1373184544832_0001_01_000001\n2013-07-07 13:39:39,259 WARN org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Unexpected: procfs stat file is not in the expected format for process with pid 11552\n2013-07-07 13:39:39,264 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 29524 for container-id container_1373184544832_0001_01_000001: 79.9 MB of 1 GB physical memory used; 2.2 GB of 2.1 GB virtual memory used\n2013-07-07 13:39:39,645 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1373184544832_0001_000001 (auth:SIMPLE)\n2013-07-07 13:39:39,651 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1373184544832_0001_01_000002 by user sunny\n2013-07-07 13:39:39,651 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=sunny\tIP=127.0.0.1\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1373184544832_0001\tCONTAINERID=container_1373184544832_0001_01_000002\n2013-07-07 13:39:39,651 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1373184544832_0001_01_000002 to application application_1373184544832_0001\n2013-07-07 13:39:39,652 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000002 transitioned from NEW to LOCALIZED\n2013-07-07 13:39:39,660 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Getting container-status for container_1373184544832_0001_01_000002\n2013-07-07 13:39:39,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Returning container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 2, }, state: C_RUNNING, diagnostics: \"\", exit_status: -1000, \n2013-07-07 13:39:39,728 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000002 transitioned from LOCALIZED to RUNNING\n2013-07-07 13:39:39,873 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, -c, /home/sunny/Hadoop2/hadoopdata/nodemanagerdata/usercache/sunny/appcache/application_1373184544832_0001/container_1373184544832_0001_01_000002/default_container_executor.sh]\n2013-07-07 13:39:39,898 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1373184544832_0001_01_000002 succeeded \n2013-07-07 13:39:39,899 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000002 transitioned from RUNNING to EXITED_WITH_SUCCESS\n2013-07-07 13:39:39,900 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1373184544832_0001_01_000002\n2013-07-07 13:39:39,942 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=sunny\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1373184544832_0001\tCONTAINERID=container_1373184544832_0001_01_000002\n2013-07-07 13:39:39,943 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000002 transitioned from EXITED_WITH_SUCCESS to DONE\n2013-07-07 13:39:39,944 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1373184544832_0001_01_000002 from application application_1373184544832_0001\n2013-07-07 13:39:40,155 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: \"\", exit_status: -1000, \n2013-07-07 13:39:40,157 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 2, }, state: C_COMPLETE, diagnostics: \"\", exit_status: 0, \n2013-07-07 13:39:40,158 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1373184544832_0001_01_000002\n2013-07-07 13:39:40,683 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Getting container-status for container_1373184544832_0001_01_000002\n2013-07-07 13:39:40,686 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:appattempt_1373184544832_0001_000001 (auth:TOKEN) cause:org.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000002 is not handled by this NodeManager\n2013-07-07 13:39:40,687 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9993, call org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.stopContainer from 127.0.0.1:51085: error: org.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000002 is not handled by this NodeManager\norg.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000002 is not handled by this NodeManager\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:45)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeGetAndStopContainerRequest(ContainerManagerImpl.java:614)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stopContainer(ContainerManagerImpl.java:538)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagementProtocolPBServiceImpl.stopContainer(ContainerManagementProtocolPBServiceImpl.java:88)\n\tat org.apache.hadoop.yarn.proto.ContainerManagementProtocol$ContainerManagementProtocolService$2.callBlockingMethod(ContainerManagementProtocol.java:85)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:605)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1033)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1868)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1864)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1862)\n2013-07-07 13:39:41,162 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: \"\", exit_status: -1000, \n2013-07-07 13:39:41,691 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1373184544832_0001_01_000001 succeeded \n2013-07-07 13:39:41,692 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS\n2013-07-07 13:39:41,692 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1373184544832_0001_01_000001\n2013-07-07 13:39:41,714 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=sunny\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1373184544832_0001\tCONTAINERID=container_1373184544832_0001_01_000001\n2013-07-07 13:39:41,714 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1373184544832_0001_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE\n2013-07-07 13:39:41,714 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1373184544832_0001_01_000001 from application application_1373184544832_0001\n2013-07-07 13:39:42,166 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1373184544832, }, attemptId: 1, }, id: 1, }, state: C_COMPLETE, diagnostics: \"\", exit_status: 0, \n2013-07-07 13:39:42,166 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1373184544832_0001_01_000001\n2013-07-07 13:39:42,191 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1373184544832_0001_000001 (auth:SIMPLE)\n2013-07-07 13:39:42,195 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Getting container-status for container_1373184544832_0001_01_000001\n2013-07-07 13:39:42,196 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:appattempt_1373184544832_0001_000001 (auth:TOKEN) cause:org.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000001 is not handled by this NodeManager\n2013-07-07 13:39:42,196 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9993, call org.apache.hadoop.yarn.api.ContainerManagementProtocolPB.stopContainer from 127.0.0.1:51086: error: org.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000001 is not handled by this NodeManager\norg.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000001 is not handled by this NodeManager\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:45)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeGetAndStopContainerRequest(ContainerManagerImpl.java:614)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stopContainer(ContainerManagerImpl.java:538)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagementProtocolPBServiceImpl.stopContainer(ContainerManagementProtocolPBServiceImpl.java:88)\n\tat org.apache.hadoop.yarn.proto.ContainerManagementProtocol$ContainerManagementProtocolService$2.callBlockingMethod(ContainerManagementProtocol.java:85)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:605)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1033)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1868)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1864)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1862)\n2013-07-07 13:39:42,264 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1373184544832_0001_01_000002\n2013-07-07 13:39:42,265 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1373184544832_0001_01_000002\n2013-07-07 13:39:42,265 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1373184544832_0001_01_000001\n2013-07-07 13:39:43,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1373184544832_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n2013-07-07 13:39:43,174 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1373184544832_0001\n2013-07-07 13:39:43,180 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1373184544832_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n2013-07-07 13:39:43,180 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1373184544832_0001, with delay of 10800 seconds\n\n\nLog Snippet for Application Manager\n==================================\n13/07/07 13:39:36 INFO client.SimpleApplicationMaster: Initializing ApplicationMaster\n13/07/07 13:39:37 INFO client.SimpleApplicationMaster: Application master for app, appId=1, clustertimestamp=1373184544832, attemptId=1\n13/07/07 13:39:37 INFO client.SimpleApplicationMaster: Starting ApplicationMaster\n13/07/07 13:39:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n13/07/07 13:39:37 INFO impl.NMClientAsyncImpl: Upper bound of the thread pool size is 500\n13/07/07 13:39:37 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-nodemanagers-proxies : 500\n13/07/07 13:39:37 INFO client.SimpleApplicationMaster: Max mem capabililty of resources in this cluster 8192\n13/07/07 13:39:37 INFO client.SimpleApplicationMaster: Requested container ask: Capability[<memory:100, vCores:0>]Priority[0]ContainerCount[1]\n13/07/07 13:39:39 INFO client.SimpleApplicationMaster: Got response from RM for container ask, allocatedCnt=1\n13/07/07 13:39:39 INFO client.SimpleApplicationMaster: Launching shell command on a new container., containerId=container_1373184544832_0001_01_000002, containerNode=sunny-Inspiron:9993, containerNodeURI=sunny-Inspiron:8042, containerResourceMemory1024\n13/07/07 13:39:39 INFO client.SimpleApplicationMaster: Setting up container launch container for containerid=container_1373184544832_0001_01_000002\n13/07/07 13:39:39 INFO impl.NMClientAsyncImpl: Processing Event EventType: START_CONTAINER for Container container_1373184544832_0001_01_000002\n13/07/07 13:39:39 INFO impl.ContainerManagementProtocolProxy: Opening proxy : sunny-Inspiron:9993\n13/07/07 13:39:39 INFO client.SimpleApplicationMaster: Succeeded to start Container container_1373184544832_0001_01_000002\n13/07/07 13:39:39 INFO impl.NMClientAsyncImpl: Processing Event EventType: QUERY_CONTAINER for Container container_1373184544832_0001_01_000002\n13/07/07 13:39:40 INFO client.SimpleApplicationMaster: Got response from RM for container ask, completedCnt=1\n13/07/07 13:39:40 INFO client.SimpleApplicationMaster: Got container status for containerID=container_1373184544832_0001_01_000002, state=COMPLETE, exitStatus=0, diagnostics=\n13/07/07 13:39:40 INFO client.SimpleApplicationMaster: Container completed successfully., containerId=container_1373184544832_0001_01_000002\n13/07/07 13:39:40 INFO client.SimpleApplicationMaster: Application completed. Stopping running containers\n13/07/07 13:39:40 ERROR impl.NMClientImpl: Failed to stop Container container_1373184544832_0001_01_000002when stopping NMClientImpl\n13/07/07 13:39:40 INFO impl.ContainerManagementProtocolProxy: Closing proxy : sunny-Inspiron:9993\n13/07/07 13:39:40 INFO client.SimpleApplicationMaster: Application completed. Signalling finish to RM\n13/07/07 13:39:41 INFO impl.AMRMClientAsyncImpl: Interrupted while waiting for queue\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1934)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)\n\tat org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$CallbackHandlerThread.run(AMRMClientAsyncImpl.java:281)\n13/07/07 13:39:41 INFO client.SimpleApplicationMaster: Application Master completed successfully. exiting\n\n\n"
        }
    },
    {
        "filename": "YARN-8236.json",
        "creation_time": "2018-04-29T16:28:11.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\nat org.apache.hadoop.yarn.service.client.ServiceClient.addKeytabResourceIfSecure(ServiceClient.java:994)\nat org.apache.hadoop.yarn.service.client.ServiceClient.submitApp(ServiceClient.java:685)\nat org.apache.hadoop.yarn.service.client.ServiceClient.actionCreate(ServiceClient.java:269)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.addKeytabResourceIfSecure": "  private void addKeytabResourceIfSecure(SliderFileSystem fileSystem,\n      Map<String, LocalResource> localResource, Service service)\n      throws IOException, YarnException {\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      return;\n    }\n    String principalName = service.getKerberosPrincipal().getPrincipalName();\n    if (StringUtils.isEmpty(principalName)) {\n      LOG.warn(\"No Kerberos principal name specified for \" + service.getName());\n      return;\n    }\n    if(StringUtils.isEmpty(service.getKerberosPrincipal().getKeytab())) {\n      LOG.warn(\"No Kerberos keytab specified for \" + service.getName());\n      return;\n    }\n\n    URI keytabURI;\n    try {\n      keytabURI = new URI(service.getKerberosPrincipal().getKeytab());\n    } catch (URISyntaxException e) {\n      throw new YarnException(e);\n    }\n\n    switch (keytabURI.getScheme()) {\n    case \"hdfs\":\n      Path keytabOnhdfs = new Path(keytabURI);\n      if (!fileSystem.getFileSystem().exists(keytabOnhdfs)) {\n        LOG.warn(service.getName() + \"'s keytab (principalName = \" +\n            principalName + \") doesn't exist at: \" + keytabOnhdfs);\n        return;\n      }\n      LocalResource keytabRes =\n          fileSystem.createAmResource(keytabOnhdfs, LocalResourceType.FILE);\n      localResource.put(String.format(YarnServiceConstants.KEYTAB_LOCATION,\n          service.getName()), keytabRes);\n      LOG.debug(\"Adding \" + service.getName() + \"'s keytab for \" +\n          \"localization, uri = \" + keytabOnhdfs);\n      break;\n    case \"file\":\n      LOG.debug(\"Using a keytab from localhost: \" + keytabURI);\n      break;\n    default:\n      LOG.warn(\"Unsupported URI scheme \" + keytabURI);\n      break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.submitApp": "  ApplicationId submitApp(Service app) throws IOException, YarnException {\n    String serviceName = app.getName();\n    Configuration conf = getConfig();\n    Path appRootDir = fs.buildClusterDirPath(app.getName());\n\n    YarnClientApplication yarnApp = yarnClient.createApplication();\n    ApplicationSubmissionContext submissionContext =\n        yarnApp.getApplicationSubmissionContext();\n    ServiceApiUtil.validateCompResourceSize(\n        yarnApp.getNewApplicationResponse().getMaximumResourceCapability(),\n        app);\n\n    submissionContext.setKeepContainersAcrossApplicationAttempts(true);\n    if (app.getLifetime() > 0) {\n      Map<ApplicationTimeoutType, Long> appTimeout = new HashMap<>();\n      appTimeout.put(ApplicationTimeoutType.LIFETIME, app.getLifetime());\n      submissionContext.setApplicationTimeouts(appTimeout);\n    }\n    submissionContext.setMaxAppAttempts(YarnServiceConf\n        .getInt(YarnServiceConf.AM_RESTART_MAX, DEFAULT_AM_RESTART_MAX, app\n            .getConfiguration(), conf));\n\n    setLogAggregationContext(app, conf, submissionContext);\n\n    Map<String, LocalResource> localResources = new HashMap<>();\n\n    // copy local slideram-log4j.properties to hdfs and add to localResources\n    boolean hasAMLog4j =\n        addAMLog4jResource(serviceName, conf, localResources);\n    // copy jars to hdfs and add to localResources\n    addJarResource(serviceName, localResources);\n    // add keytab if in secure env\n    addKeytabResourceIfSecure(fs, localResources, app);\n    if (LOG.isDebugEnabled()) {\n      printLocalResources(localResources);\n    }\n    Map<String, String> env = addAMEnv();\n\n    // create AM CLI\n    String cmdStr = buildCommandLine(app, conf, appRootDir, hasAMLog4j);\n    submissionContext.setResource(Resource.newInstance(YarnServiceConf\n        .getLong(YarnServiceConf.AM_RESOURCE_MEM,\n            YarnServiceConf.DEFAULT_KEY_AM_RESOURCE_MEM, app.getConfiguration(),\n            conf), 1));\n    String queue = app.getQueue();\n    if (StringUtils.isEmpty(queue)) {\n      queue = conf.get(YARN_QUEUE, DEFAULT_YARN_QUEUE);\n    }\n    submissionContext.setQueue(queue);\n    submissionContext.setApplicationName(serviceName);\n    submissionContext.setApplicationType(YarnServiceConstants.APP_TYPE);\n    Set<String> appTags =\n        AbstractClientProvider.createApplicationTags(serviceName, null, null);\n    if (!appTags.isEmpty()) {\n      submissionContext.setApplicationTags(appTags);\n    }\n    ContainerLaunchContext amLaunchContext =\n        Records.newRecord(ContainerLaunchContext.class);\n    amLaunchContext.setCommands(Collections.singletonList(cmdStr));\n    amLaunchContext.setEnvironment(env);\n    amLaunchContext.setLocalResources(localResources);\n    addCredentials(amLaunchContext, app);\n    submissionContext.setAMContainerSpec(amLaunchContext);\n    yarnClient.submitApplication(submissionContext);\n    return submissionContext.getApplicationId();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.addCredentials": "  private void addCredentials(ContainerLaunchContext amContext, Service app)\n      throws IOException {\n    Credentials allCreds = new Credentials();\n    // HDFS DT\n    if (UserGroupInformation.isSecurityEnabled()) {\n      String tokenRenewer = YarnClientUtils.getRmPrincipal(getConfig());\n      if (StringUtils.isEmpty(tokenRenewer)) {\n        throw new IOException(\n            \"Can't get Master Kerberos principal for the RM to use as renewer\");\n      }\n      final org.apache.hadoop.security.token.Token<?>[] tokens =\n          fs.getFileSystem().addDelegationTokens(tokenRenewer, allCreds);\n      if (LOG.isDebugEnabled()) {\n        if (tokens != null && tokens.length != 0) {\n          for (Token<?> token : tokens) {\n            LOG.debug(\"Got DT: \" + token);\n          }\n        }\n      }\n    }\n\n    if (!StringUtils.isEmpty(app.getDockerClientConfig())) {\n      allCreds.addAll(DockerClientConfigHandler.readCredentialsFromConfigFile(\n          new Path(app.getDockerClientConfig()), getConfig(), app.getName()));\n    }\n\n    if (allCreds.numberOfTokens() > 0) {\n      DataOutputBuffer dob = new DataOutputBuffer();\n      allCreds.writeTokenStorageToStream(dob);\n      ByteBuffer tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContext.setTokens(tokens);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.printLocalResources": "  private void printLocalResources(Map<String, LocalResource> map) {\n    LOG.debug(\"Added LocalResource for localization: \");\n    StringBuilder builder = new StringBuilder();\n    for (Map.Entry<String, LocalResource> entry : map.entrySet()) {\n      builder.append(entry.getKey()).append(\" -> \")\n          .append(entry.getValue().getResource().getFile())\n          .append(System.lineSeparator());\n    }\n    LOG.debug(builder.toString());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.addAMEnv": "  private Map<String, String> addAMEnv() throws IOException {\n    Map<String, String> env = new HashMap<>();\n    ClasspathConstructor classpath =\n        buildClasspath(YarnServiceConstants.SUBMITTED_CONF_DIR, \"lib\", fs, getConfig()\n            .getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false));\n    env.put(\"CLASSPATH\", classpath.buildClasspath());\n    env.put(\"LANG\", \"en_US.UTF-8\");\n    env.put(\"LC_ALL\", \"en_US.UTF-8\");\n    env.put(\"LANGUAGE\", \"en_US.UTF-8\");\n    String jaas = System.getenv(\"HADOOP_JAAS_DEBUG\");\n    if (jaas != null) {\n      env.put(\"HADOOP_JAAS_DEBUG\", jaas);\n    }\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      String userName = UserGroupInformation.getCurrentUser().getUserName();\n      LOG.debug(\"Run as user \" + userName);\n      // HADOOP_USER_NAME env is used by UserGroupInformation when log in\n      // This env makes AM run as this user\n      env.put(\"HADOOP_USER_NAME\", userName);\n    }\n    LOG.debug(\"AM env: \\n{}\", stringifyMap(env));\n    return env;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.buildCommandLine": "  private String buildCommandLine(Service app, Configuration conf,\n      Path appRootDir, boolean hasSliderAMLog4j) throws BadConfigException {\n    JavaCommandLineBuilder CLI = new JavaCommandLineBuilder();\n    CLI.forceIPv4().headless();\n    String jvmOpts = YarnServiceConf\n        .get(YarnServiceConf.JVM_OPTS, \"\", app.getConfiguration(), conf);\n    if (!jvmOpts.contains(\"-Xmx\")) {\n      jvmOpts += DEFAULT_AM_JVM_XMX;\n    }\n\n    CLI.setJVMOpts(jvmOpts);\n    if (hasSliderAMLog4j) {\n      CLI.sysprop(SYSPROP_LOG4J_CONFIGURATION, YARN_SERVICE_LOG4J_FILENAME);\n      CLI.sysprop(SYSPROP_LOG_DIR, ApplicationConstants.LOG_DIR_EXPANSION_VAR);\n    }\n    CLI.add(ServiceMaster.class.getCanonicalName());\n    //TODO debugAM CLI.add(Arguments.ARG_DEBUG)\n    CLI.add(\"-\" + ServiceMaster.YARNFILE_OPTION, new Path(appRootDir,\n        app.getName() + \".json\"));\n    // pass the registry binding\n    CLI.addConfOptionToCLI(conf, RegistryConstants.KEY_REGISTRY_ZK_ROOT,\n        RegistryConstants.DEFAULT_ZK_REGISTRY_ROOT);\n    CLI.addMandatoryConfOption(conf, RegistryConstants.KEY_REGISTRY_ZK_QUORUM);\n\n    // write out the path output\n    CLI.addOutAndErrFiles(STDOUT_AM, STDERR_AM);\n    String cmdStr = CLI.build();\n    LOG.debug(\"AM launch command: {}\", cmdStr);\n    return cmdStr;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.addJarResource": "  protected Path addJarResource(String serviceName,\n      Map<String, LocalResource> localResources)\n      throws IOException, SliderException {\n    Path libPath = fs.buildClusterDirPath(serviceName);\n    ProviderUtils\n        .addProviderJar(localResources, ServiceMaster.class, SERVICE_CORE_JAR, fs,\n            libPath, \"lib\", false);\n    Path dependencyLibTarGzip = fs.getDependencyTarGzip();\n    if (fs.isFile(dependencyLibTarGzip)) {\n      LOG.info(\"Loading lib tar from \" + dependencyLibTarGzip);\n      fs.submitTarGzipAndUpdate(localResources);\n    } else {\n      if (dependencyLibTarGzip != null) {\n        LOG.warn(\"Property {} has a value {}, but is not a valid file\",\n            YarnServiceConf.DEPENDENCY_TARBALL_PATH, dependencyLibTarGzip);\n      }\n      String[] libs = ServiceUtils.getLibDirs();\n      LOG.info(\"Uploading all dependency jars to HDFS. For faster submission of\"\n          + \" apps, set config property {} to the dependency tarball location.\"\n          + \" Dependency tarball can be uploaded to any HDFS path directly\"\n          + \" or by using command: yarn app -{} [<Destination Folder>]\",\n          YarnServiceConf.DEPENDENCY_TARBALL_PATH,\n          ApplicationCLI.ENABLE_FAST_LAUNCH);\n      for (String libDirProp : libs) {\n        ProviderUtils.addAllDependencyJars(localResources, fs, libPath, \"lib\",\n            libDirProp);\n      }\n    }\n    return libPath;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.setLogAggregationContext": "  private void setLogAggregationContext(Service app, Configuration conf,\n      ApplicationSubmissionContext submissionContext) {\n    LogAggregationContext context = Records.newRecord(LogAggregationContext\n        .class);\n    String finalLogInclude = YarnServiceConf.get\n        (FINAL_LOG_INCLUSION_PATTERN, null, app.getConfiguration(), conf);\n    if (!StringUtils.isEmpty(finalLogInclude)) {\n      context.setIncludePattern(finalLogInclude);\n    }\n    String finalLogExclude = YarnServiceConf.get\n        (FINAL_LOG_EXCLUSION_PATTERN, null, app.getConfiguration(), conf);\n    if (!StringUtils.isEmpty(finalLogExclude)) {\n      context.setExcludePattern(finalLogExclude);\n    }\n    String rollingLogInclude = YarnServiceConf.get\n        (ROLLING_LOG_INCLUSION_PATTERN, null, app.getConfiguration(), conf);\n    if (!StringUtils.isEmpty(rollingLogInclude)) {\n      context.setRolledLogsIncludePattern(rollingLogInclude);\n    }\n    String rollingLogExclude = YarnServiceConf.get\n        (ROLLING_LOG_EXCLUSION_PATTERN, null, app.getConfiguration(), conf);\n    if (!StringUtils.isEmpty(rollingLogExclude)) {\n      context.setRolledLogsExcludePattern(rollingLogExclude);\n    }\n    submissionContext.setLogAggregationContext(context);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.addAMLog4jResource": "  private boolean addAMLog4jResource(String serviceName, Configuration conf,\n      Map<String, LocalResource> localResources)\n      throws IOException, BadClusterStateException {\n    boolean hasAMLog4j = false;\n    String hadoopConfDir =\n        System.getenv(ApplicationConstants.Environment.HADOOP_CONF_DIR.name());\n    if (hadoopConfDir != null) {\n      File localFile =\n          new File(hadoopConfDir, YarnServiceConstants.YARN_SERVICE_LOG4J_FILENAME);\n      if (localFile.exists()) {\n        Path localFilePath = createLocalPath(localFile);\n        Path appDirPath = fs.buildClusterDirPath(serviceName);\n        Path remoteConfPath =\n            new Path(appDirPath, YarnServiceConstants.SUBMITTED_CONF_DIR);\n        Path remoteFilePath =\n            new Path(remoteConfPath, YarnServiceConstants.YARN_SERVICE_LOG4J_FILENAME);\n        copy(conf, localFilePath, remoteFilePath);\n        LocalResource localResource =\n            fs.createAmResource(remoteConfPath, LocalResourceType.FILE);\n        localResources.put(localFilePath.getName(), localResource);\n        hasAMLog4j = true;\n      } else {\n        LOG.warn(\"AM log4j property file doesn't exist: \" + localFile);\n      }\n    }\n    return hasAMLog4j;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.actionCreate": "  public ApplicationId actionCreate(Service service)\n      throws IOException, YarnException {\n    String serviceName = service.getName();\n    ServiceApiUtil.validateAndResolveService(service, fs, getConfig());\n    verifyNoLiveAppInRM(serviceName, \"create\");\n    Path appDir = checkAppNotExistOnHdfs(service, false);\n\n    // Write the definition first and then submit - AM will read the definition\n    ServiceApiUtil.createDirAndPersistApp(fs, appDir, service);\n    ApplicationId appId = submitApp(service);\n    cachedAppInfo.put(serviceName, new AppInfo(appId, service\n        .getKerberosPrincipal().getPrincipalName()));\n    service.setId(appId.toString());\n    // update app definition with appId\n    ServiceApiUtil.writeAppDefinition(fs, appDir, service);\n    return appId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.checkAppNotExistOnHdfs": "  private Path checkAppNotExistOnHdfs(Service service, boolean isUpgrade)\n      throws IOException, SliderException {\n    Path appDir = !isUpgrade ? fs.buildClusterDirPath(service.getName()) :\n        fs.buildClusterUpgradeDirPath(service.getName(), service.getVersion());\n    fs.verifyDirectoryNonexistent(\n        new Path(appDir, service.getName() + \".json\"));\n    return appDir;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-applications.hadoop-yarn-services.hadoop-yarn-services-core.src.main.java.org.apache.hadoop.yarn.service.client.ServiceClient.verifyNoLiveAppInRM": "  private void verifyNoLiveAppInRM(String serviceName, String action)\n      throws IOException, YarnException {\n    Set<String> types = new HashSet<>(1);\n    types.add(YarnServiceConstants.APP_TYPE);\n    Set<String> tags = null;\n    if (serviceName != null) {\n      tags = Collections.singleton(ServiceUtils.createNameTag(serviceName));\n    }\n    GetApplicationsRequest request = GetApplicationsRequest.newInstance();\n    request.setApplicationTypes(types);\n    request.setApplicationTags(tags);\n    request.setApplicationStates(liveStates);\n    String user = UserGroupInformation.getCurrentUser().getUserName();\n    if (user != null) {\n      request.setUsers(Collections.singleton(user));\n    }\n    List<ApplicationReport> reports = yarnClient.getApplications(request);\n    if (!reports.isEmpty()) {\n      String message = \"\";\n      if (action.equals(\"destroy\")) {\n        message = \"Failed to destroy service \" + serviceName\n            + \", because it is still running.\";\n      } else {\n        message = \"Failed to \" + action + \" service \" + serviceName\n            + \", because it already exists.\";\n      }\n      throw new YarnException(message);\n    }\n  }"
        },
        "bug_report": {
            "Title": "Invalid kerberos principal file name cause NPE in native service",
            "Description": "Stack trace\r\n\r\n\u00a0\r\n{code:java}\r\n2018-04-29 16:22:54,266 WARN webapp.GenericExceptionHandler (GenericExceptionHandler.java:toResponse(98)) - INTERNAL_SERVER_ERROR\r\njava.lang.NullPointerException\r\nat org.apache.hadoop.yarn.service.client.ServiceClient.addKeytabResourceIfSecure(ServiceClient.java:994)\r\nat org.apache.hadoop.yarn.service.client.ServiceClient.submitApp(ServiceClient.java:685)\r\nat org.apache.hadoop.yarn.service.client.ServiceClient.actionCreate(ServiceClient.java:269){code}\r\n\r\ncc [~gsaha] [~csingh]"
        }
    },
    {
        "filename": "YARN-2857.json",
        "creation_time": "2014-10-24T20:47:51.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n\tat java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:966)\n\tat java.util.LinkedList$ListItr.next(LinkedList.java:888)\n\tat org.apache.hadoop.yarn.ContainerLogAppender.close(ContainerLogAppender.java:94)\n\tat org.apache.log4j.helpers.AppenderAttachableImpl.removeAllAppenders(AppenderAttachableImpl.java:141)\n\tat org.apache.log4j.Category.removeAllAppenders(Category.java:891)\n\tat org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:759)\n\tat org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648)\n\tat org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514)\n\tat org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440)\n\tat org.apache.pig.Main.configureLog4J(Main.java:740)\n\tat org.apache.pig.Main.run(Main.java:384)\n\tat org.apache.pig.PigRunner.run(PigRunner.java:49)\n\tat org.apache.oozie.action.hadoop.PigMain.runPigJob(PigMain.java:283)\n\tat org.apache.oozie.action.hadoop.PigMain.run(PigMain.java:223)\n\tat org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:37)\n\tat org.apache.oozie.action.hadoop.PigMain.main(PigMain.java:76)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:226)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.ContainerLogAppender.close": "  public synchronized void close() {\n    if (tail != null) {\n      for(LoggingEvent event: tail) {\n        super.append(event);\n      }\n    }\n    super.close();\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.YarnChild.run": "              public Object run() throws Exception {\n                taskFinal.taskCleanup(umbilical);\n                return null;\n              }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.YarnChild.main": "  public static void main(String[] args) throws Throwable {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    LOG.debug(\"Child starting\");\n\n    final JobConf job = new JobConf(MRJobConfig.JOB_CONF_FILE);\n    // Initing with our JobConf allows us to avoid loading confs twice\n    Limits.init(job);\n    UserGroupInformation.setConfiguration(job);\n\n    String host = args[0];\n    int port = Integer.parseInt(args[1]);\n    final InetSocketAddress address =\n        NetUtils.createSocketAddrForHost(host, port);\n    final TaskAttemptID firstTaskid = TaskAttemptID.forName(args[2]);\n    long jvmIdLong = Long.parseLong(args[3]);\n    JVMId jvmId = new JVMId(firstTaskid.getJobID(),\n        firstTaskid.getTaskType() == TaskType.MAP, jvmIdLong);\n\n    // initialize metrics\n    DefaultMetricsSystem.initialize(\n        StringUtils.camelize(firstTaskid.getTaskType().name()) +\"Task\");\n\n    // Security framework already loaded the tokens into current ugi\n    Credentials credentials =\n        UserGroupInformation.getCurrentUser().getCredentials();\n    LOG.info(\"Executing with tokens:\");\n    for (Token<?> token: credentials.getAllTokens()) {\n      LOG.info(token);\n    }\n\n    // Create TaskUmbilicalProtocol as actual task owner.\n    UserGroupInformation taskOwner =\n      UserGroupInformation.createRemoteUser(firstTaskid.getJobID().toString());\n    Token<JobTokenIdentifier> jt = TokenCache.getJobToken(credentials);\n    SecurityUtil.setTokenService(jt, address);\n    taskOwner.addToken(jt);\n    final TaskUmbilicalProtocol umbilical =\n      taskOwner.doAs(new PrivilegedExceptionAction<TaskUmbilicalProtocol>() {\n      @Override\n      public TaskUmbilicalProtocol run() throws Exception {\n        return (TaskUmbilicalProtocol)RPC.getProxy(TaskUmbilicalProtocol.class,\n            TaskUmbilicalProtocol.versionID, address, job);\n      }\n    });\n\n    // report non-pid to application master\n    JvmContext context = new JvmContext(jvmId, \"-1000\");\n    LOG.debug(\"PID: \" + System.getenv().get(\"JVM_PID\"));\n    Task task = null;\n    UserGroupInformation childUGI = null;\n    ScheduledExecutorService logSyncer = null;\n\n    try {\n      int idleLoopCount = 0;\n      JvmTask myTask = null;;\n      // poll for new task\n      for (int idle = 0; null == myTask; ++idle) {\n        long sleepTimeMilliSecs = Math.min(idle * 500, 1500);\n        LOG.info(\"Sleeping for \" + sleepTimeMilliSecs\n            + \"ms before retrying again. Got null now.\");\n        MILLISECONDS.sleep(sleepTimeMilliSecs);\n        myTask = umbilical.getTask(context);\n      }\n      if (myTask.shouldDie()) {\n        return;\n      }\n\n      task = myTask.getTask();\n      YarnChild.taskid = task.getTaskID();\n\n      // Create the job-conf and set credentials\n      configureTask(job, task, credentials, jt);\n\n      // log the system properties\n      String systemPropsToLog = MRApps.getSystemPropertiesToLog(job);\n      if (systemPropsToLog != null) {\n        LOG.info(systemPropsToLog);\n      }\n\n      // Initiate Java VM metrics\n      JvmMetrics.initSingleton(jvmId.toString(), job.getSessionId());\n      childUGI = UserGroupInformation.createRemoteUser(System\n          .getenv(ApplicationConstants.Environment.USER.toString()));\n      // Add tokens to new user so that it may execute its task correctly.\n      childUGI.addCredentials(credentials);\n\n      // set job classloader if configured before invoking the task\n      MRApps.setJobClassLoader(job);\n\n      logSyncer = TaskLog.createLogSyncer();\n\n      // Create a final reference to the task for the doAs block\n      final Task taskFinal = task;\n      childUGI.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          // use job-specified working directory\n          FileSystem.get(job).setWorkingDirectory(job.getWorkingDirectory());\n          taskFinal.run(job, umbilical); // run the task\n          return null;\n        }\n      });\n    } catch (FSError e) {\n      LOG.fatal(\"FSError from child\", e);\n      if (!ShutdownHookManager.get().isShutdownInProgress()) {\n        umbilical.fsError(taskid, e.getMessage());\n      }\n    } catch (Exception exception) {\n      LOG.warn(\"Exception running child : \"\n          + StringUtils.stringifyException(exception));\n      try {\n        if (task != null) {\n          // do cleanup for the task\n          if (childUGI == null) { // no need to job into doAs block\n            task.taskCleanup(umbilical);\n          } else {\n            final Task taskFinal = task;\n            childUGI.doAs(new PrivilegedExceptionAction<Object>() {\n              @Override\n              public Object run() throws Exception {\n                taskFinal.taskCleanup(umbilical);\n                return null;\n              }\n            });\n          }\n        }\n      } catch (Exception e) {\n        LOG.info(\"Exception cleaning up: \" + StringUtils.stringifyException(e));\n      }\n      // Report back any failures, for diagnostic purposes\n      if (taskid != null) {\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          umbilical.fatalError(taskid,\n              StringUtils.stringifyException(exception));\n        }\n      }\n    } catch (Throwable throwable) {\n      LOG.fatal(\"Error running child : \"\n    \t        + StringUtils.stringifyException(throwable));\n      if (taskid != null) {\n        if (!ShutdownHookManager.get().isShutdownInProgress()) {\n          Throwable tCause = throwable.getCause();\n          String cause =\n              tCause == null ? throwable.getMessage() : StringUtils\n                  .stringifyException(tCause);\n          umbilical.fatalError(taskid, cause);\n        }\n      }\n    } finally {\n      RPC.stopProxy(umbilical);\n      DefaultMetricsSystem.shutdown();\n      TaskLog.syncLogsShutdown(logSyncer);\n    }\n  }",
            "hadoop-mapreduce-project.hadoop-mapreduce-client.hadoop-mapreduce-client-app.src.main.java.org.apache.hadoop.mapred.YarnChild.configureTask": "  private static void configureTask(JobConf job, Task task,\n      Credentials credentials, Token<JobTokenIdentifier> jt) throws IOException {\n    job.setCredentials(credentials);\n    \n    ApplicationAttemptId appAttemptId =\n        ConverterUtils.toContainerId(\n            System.getenv(Environment.CONTAINER_ID.name()))\n            .getApplicationAttemptId();\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n        appAttemptId.getAttemptId());\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret = TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret == null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret = jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child's MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child's attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    MRApps.setupDistributedCacheLocal(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile = new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n  }"
        },
        "bug_report": {
            "Title": "ConcurrentModificationException in ContainerLogAppender",
            "Description": "Context:\n\n* Hadoop-2.3.0\n* Using Oozie 4.0.1\n* Pig version 0.11.x\n\nThe job is submitted by Oozie to launch Pig script.\n\n\nThe following exception traces were found on MR task log:\n\nIn syslog:\n{noformat}\n2014-10-24 20:37:29,317 WARN [Thread-5] org.apache.hadoop.util.ShutdownHookManager: ShutdownHook '' failed, java.util.ConcurrentModificationException\njava.util.ConcurrentModificationException\n\tat java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:966)\n\tat java.util.LinkedList$ListItr.next(LinkedList.java:888)\n\tat org.apache.hadoop.yarn.ContainerLogAppender.close(ContainerLogAppender.java:94)\n\tat org.apache.log4j.helpers.AppenderAttachableImpl.removeAllAppenders(AppenderAttachableImpl.java:141)\n\tat org.apache.log4j.Category.removeAllAppenders(Category.java:891)\n\tat org.apache.log4j.Hierarchy.shutdown(Hierarchy.java:471)\n\tat org.apache.log4j.LogManager.shutdown(LogManager.java:267)\n\tat org.apache.hadoop.mapred.TaskLog.syncLogsShutdown(TaskLog.java:286)\n\tat org.apache.hadoop.mapred.TaskLog$2.run(TaskLog.java:339)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\n2014-10-24 20:37:29,395 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...\n{noformat}\n\nin stderr:\n{noformat}\njava.util.ConcurrentModificationException\n\tat java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:966)\n\tat java.util.LinkedList$ListItr.next(LinkedList.java:888)\n\tat org.apache.hadoop.yarn.ContainerLogAppender.close(ContainerLogAppender.java:94)\n\tat org.apache.log4j.helpers.AppenderAttachableImpl.removeAllAppenders(AppenderAttachableImpl.java:141)\n\tat org.apache.log4j.Category.removeAllAppenders(Category.java:891)\n\tat org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:759)\n\tat org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648)\n\tat org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514)\n\tat org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440)\n\tat org.apache.pig.Main.configureLog4J(Main.java:740)\n\tat org.apache.pig.Main.run(Main.java:384)\n\tat org.apache.pig.PigRunner.run(PigRunner.java:49)\n\tat org.apache.oozie.action.hadoop.PigMain.runPigJob(PigMain.java:283)\n\tat org.apache.oozie.action.hadoop.PigMain.run(PigMain.java:223)\n\tat org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:37)\n\tat org.apache.oozie.action.hadoop.PigMain.main(PigMain.java:76)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:226)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)\n{noformat}\n"
        }
    },
    {
        "filename": "YARN-2416.json",
        "creation_time": "2014-08-13T22:36:31.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: REGISTERED at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: STATUS_UPDATE at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_ALLOCATED at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getAppAttemptState()) {\n        LOG.info(appAttemptID + \" State change from \" + oldState + \" to \"\n            + getAppAttemptState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      if (initialize) {\n        resetDispatcher();\n        createAndInitActiveServices();\n      }\n    }\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          drained = eventQueue.isEmpty();\n          // blockNewEvents is only set when dispatcher is draining to stop,\n          // adding this check is to avoid the overhead of acquiring the lock\n          // and calling notify every time in the normal run of the loop.\n          if (blockNewEvents) {\n            synchronized (waitForDrained) {\n              if (drained) {\n                waitForDrained.notify();\n              }\n            }\n          }\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<String, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  int getEpoch();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "InvalidStateTransitonException in ResourceManager if AMLauncher does not receive response for startContainers() call in time",
            "Description": "AMLauncher calls startContainers(allRequests) to launch a container for application master. Normally, the call comes back immediately so that the RMAppAttempt changes its state from ALLOCATED to LAUNCHED. \n\nHowever, we do observed that in some cases, the RPC call came back very late but the AM container was already started. Because the RMAppAttempt stuck in ALLOCATED state, once resource manager received the REGISTERED event from the application master, it threw InvalidStateTransitonException as follows.\n\n2014-07-05 08:59:05,021 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: REGISTERED at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n\nFor subsequent STATUS_UPDATE and CONTAINER_ALLOCATED events for this job, resource manager kept throwing InvalidStateTransitonException.\n\n2014-07-05 08:59:06,152 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: STATUS_UPDATE at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n2014-07-05 08:59:07,779 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1404549222428_0001_02_000002 Container Transitioned from NEW to\n ALLOCATED\n2014-07-05 08:59:07,779 ERROR org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_ALLOCATED at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)"
        }
    },
    {
        "filename": "YARN-345.json",
        "creation_time": "2013-01-17T12:57:46.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at APPLICATION_RESOURCES_CLEANINGUP\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at FINISHING_CONTAINERS_WAIT\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_CONTAINER_FINISHED at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: INIT_CONTAINER at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle": "  public void handle(ApplicationEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId applicationID = event.getApplicationID();\n      LOG.debug(\"Processing \" + applicationID + \" of type \" + event.getType());\n\n      ApplicationState oldState = stateMachine.getCurrentState();\n      ApplicationState newState = null;\n      try {\n        // queue event requesting init of the same app\n        newState = stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.warn(\"Can't handle this event at current state\", e);\n      }\n      if (oldState != newState) {\n        LOG.info(\"Application \" + applicationID + \" transitioned from \"\n            + oldState + \" to \" + newState);\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                \"Application Killed by ResourceManager\"));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId container : containersFinishedEvent\n          .getContainersToCleanup()) {\n        String diagnostic = \"\";\n        if (containersFinishedEvent.getReason() == \n            CMgrCompletedContainersEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Container Killed on Shutdown\";\n        } else if (containersFinishedEvent.getReason() == \n            CMgrCompletedContainersEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Container Killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ContainerKillEvent(container, diagnostic));\n      }\n      break;\n    default:\n      LOG.warn(\"Invalid event \" + event.getType() + \". Ignoring.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Many InvalidStateTransitonException errors for ApplicationImpl in Node Manager",
            "Description": "{code:xml}\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}\n{code:xml}\n2013-01-17 04:03:46,726 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at APPLICATION_RESOURCES_CLEANINGUP\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}\n{code:xml}\n2013-01-17 00:01:11,006 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at FINISHING_CONTAINERS_WAIT\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}\n{code:xml}\n\n2013-01-17 10:56:36,975 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1358385982671_1304_01_000001 transitioned from NEW to DONE\n2013-01-17 10:56:36,975 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_CONTAINER_FINISHED at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n2013-01-17 10:56:36,975 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1358385982671_1304 transitioned from FINISHED to null\n{code}\n{code:xml}\n\n2013-01-17 10:56:36,026 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: INIT_CONTAINER at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n2013-01-17 10:56:36,026 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1358385982671_1304 transitioned from FINISHED to null\n{code}\n"
        }
    },
    {
        "filename": "YARN-3894.json",
        "creation_time": "2015-07-08T07:00:51.000+0000",
        "stack_trace": "```\njava.io.IOException: Failed to re-init queues\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:383)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshQueues(AdminService.java:376)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:605)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:314)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\nCaused by: java.lang.IllegalArgumentException: Illegal capacity of 0.5 for children of queue root for label=node2\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.setChildQueues(ParentQueue.java:159)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue(CapacityScheduler.java:639)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitializeQueues(CapacityScheduler.java:503)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:379)\n        ... 8 more\n\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:128)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Error when transitioning to Active mode\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:321)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        ... 4 more\nCaused by: org.apache.hadoop.ha.ServiceFailedException: java.io.IOException: Failed to re-init queues\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:617)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:314)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize": "  public synchronized void\n  reinitialize(Configuration conf, RMContext rmContext) throws IOException {\n    Configuration configuration = new Configuration(conf);\n    CapacitySchedulerConfiguration oldConf = this.conf;\n    this.conf = loadCapacitySchedulerConfiguration(configuration);\n    validateConf(this.conf);\n    try {\n      LOG.info(\"Re-initializing queues...\");\n      refreshMaximumAllocation(this.conf.getMaximumAllocation());\n      reinitializeQueues(this.conf);\n    } catch (Throwable t) {\n      this.conf = oldConf;\n      refreshMaximumAllocation(this.conf.getMaximumAllocation());\n      throw new IOException(\"Failed to re-init queues\", t);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitializeQueues": "  private void reinitializeQueues(CapacitySchedulerConfiguration conf) \n  throws IOException {\n    // Parse new queues\n    Map<String, CSQueue> newQueues = new HashMap<String, CSQueue>();\n    CSQueue newRoot = \n        parseQueue(this, conf, null, CapacitySchedulerConfiguration.ROOT, \n            newQueues, queues, noop); \n    \n    // Ensure all existing queues are still present\n    validateExistingQueues(queues, newQueues);\n\n    // Add new queues\n    addNewQueues(queues, newQueues);\n    \n    // Re-configure queues\n    root.reinitialize(newRoot, clusterResource);\n    initializeQueueMappings();\n\n    // Re-calculate headroom for active applications\n    root.updateClusterResource(clusterResource, new ResourceLimits(\n        clusterResource));\n\n    labelManager.reinitializeQueueLabels(getQueueToLabels());\n    setQueueAcls(authorizer, queues);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.loadCapacitySchedulerConfiguration": "  private CapacitySchedulerConfiguration loadCapacitySchedulerConfiguration(\n      Configuration configuration) throws IOException {\n    try {\n      InputStream CSInputStream =\n          this.rmContext.getConfigurationProvider()\n              .getConfigurationInputStream(configuration,\n                  YarnConfiguration.CS_CONFIGURATION_FILE);\n      if (CSInputStream != null) {\n        configuration.addResource(CSInputStream);\n        return new CapacitySchedulerConfiguration(configuration, false);\n      }\n      return new CapacitySchedulerConfiguration(configuration, true);\n    } catch (Exception e) {\n      throw new IOException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.validateConf": "  private void validateConf(Configuration conf) {\n    // validate scheduler memory allocation setting\n    int minMem = conf.getInt(\n      YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB,\n      YarnConfiguration.DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB);\n    int maxMem = conf.getInt(\n      YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_MB,\n      YarnConfiguration.DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_MB);\n\n    if (minMem <= 0 || minMem > maxMem) {\n      throw new YarnRuntimeException(\"Invalid resource scheduler memory\"\n        + \" allocation configuration\"\n        + \", \" + YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB\n        + \"=\" + minMem\n        + \", \" + YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_MB\n        + \"=\" + maxMem + \", min and max should be greater than 0\"\n        + \", max should be no smaller than min.\");\n    }\n\n    // validate scheduler vcores allocation setting\n    int minVcores = conf.getInt(\n      YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES,\n      YarnConfiguration.DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES);\n    int maxVcores = conf.getInt(\n      YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES,\n      YarnConfiguration.DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES);\n\n    if (minVcores <= 0 || minVcores > maxVcores) {\n      throw new YarnRuntimeException(\"Invalid resource scheduler vcores\"\n        + \" allocation configuration\"\n        + \", \" + YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES\n        + \"=\" + minVcores\n        + \", \" + YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES\n        + \"=\" + maxVcores + \", min and max should be greater than 0\"\n        + \", max should be no smaller than min.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshQueues": "  public RefreshQueuesResponse refreshQueues(RefreshQueuesRequest request)\n      throws YarnException, StandbyException {\n    String argName = \"refreshQueues\";\n    final String msg = \"refresh queues.\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, msg);\n\n    RefreshQueuesResponse response =\n        recordFactory.newRecordInstance(RefreshQueuesResponse.class);\n    try {\n      rmContext.getScheduler().reinitialize(getConfig(), this.rmContext);\n      // refresh the reservation system\n      ReservationSystem rSystem = rmContext.getReservationSystem();\n      if (rSystem != null) {\n        rSystem.reinitialize(getConfig(), rmContext);\n      }\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n      return response;\n    } catch (IOException ioe) {\n      throw logAndWrapException(ioe, user.getShortUserName(), argName, msg);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls": "  private UserGroupInformation checkAcls(String method) throws YarnException {\n    try {\n      return checkAccess(method);\n    } catch (IOException ioe) {\n      throw RPCUtil.getRemoteException(ioe);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.logAndWrapException": "  private YarnException logAndWrapException(Exception exception, String user,\n      String operation, String msg) throws YarnException {\n    LOG.warn(\"Exception \" + msg, exception);\n    RMAuditLogger.logFailure(user, operation, \"\",\n        \"AdminService\", \"Exception \" + msg);\n    return RPCUtil.getRemoteException(exception);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkRMStatus": "  private void checkRMStatus(String user, String operation, String msg)\n      throws StandbyException {\n    if (!isRMActive()) {\n      RMAuditLogger.logFailure(user, operation, \"\",\n          \"AdminService\", \"ResourceManager is not active. Can not \" + msg);\n      throwStandbyException();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll": "  private void refreshAll() throws ServiceFailedException {\n    try {\n      refreshQueues(RefreshQueuesRequest.newInstance());\n      refreshNodes(RefreshNodesRequest.newInstance(DecommissionType.NORMAL));\n      refreshSuperUserGroupsConfiguration(\n          RefreshSuperUserGroupsConfigurationRequest.newInstance());\n      refreshUserToGroupsMappings(\n          RefreshUserToGroupsMappingsRequest.newInstance());\n      if (getConfig().getBoolean(\n          CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          false)) {\n        refreshServiceAcls(RefreshServiceAclsRequest.newInstance());\n      }\n    } catch (Exception ex) {\n      throw new ServiceFailedException(ex.getMessage());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshSuperUserGroupsConfiguration": "  public RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(\n      RefreshSuperUserGroupsConfigurationRequest request)\n      throws YarnException, IOException {\n    String argName = \"refreshSuperUserGroupsConfiguration\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, \"refresh super-user-groups.\");\n\n    // Accept hadoop common configs in core-site.xml as well as RM specific\n    // configurations in yarn-site.xml\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE,\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    RMServerUtils.processRMProxyUsersConf(conf);\n    ProxyUsers.refreshSuperUserGroupsConfiguration(conf);\n    RMAuditLogger.logSuccess(user.getShortUserName(),\n        argName, \"AdminService\");\n    \n    return recordFactory.newRecordInstance(\n        RefreshSuperUserGroupsConfigurationResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshNodes": "  public RefreshNodesResponse refreshNodes(RefreshNodesRequest request)\n      throws YarnException, StandbyException {\n    String argName = \"refreshNodes\";\n    final String msg = \"refresh nodes.\";\n    UserGroupInformation user = checkAcls(\"refreshNodes\");\n\n    checkRMStatus(user.getShortUserName(), argName, msg);\n\n    try {\n      Configuration conf =\n          getConfiguration(new Configuration(false),\n              YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n      switch (request.getDecommissionType()) {\n      case NORMAL:\n        rmContext.getNodesListManager().refreshNodes(conf);\n        break;\n      case GRACEFUL:\n        rmContext.getNodesListManager().refreshNodesGracefully(conf);\n        break;\n      case FORCEFUL:\n        rmContext.getNodesListManager().refreshNodesForcefully();\n        break;\n      }\n      RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n          \"AdminService\");\n      return recordFactory.newRecordInstance(RefreshNodesResponse.class);\n    } catch (IOException ioe) {\n      throw logAndWrapException(ioe, user.getShortUserName(), argName, msg);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshUserToGroupsMappings": "  public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(\n      RefreshUserToGroupsMappingsRequest request)\n      throws YarnException, IOException {\n    String argName = \"refreshUserToGroupsMappings\";\n    UserGroupInformation user = checkAcls(argName);\n\n    checkRMStatus(user.getShortUserName(), argName, \"refresh user-groups.\");\n\n    Groups.getUserToGroupsMappingService(\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.CORE_SITE_CONFIGURATION_FILE)).refresh();\n\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName, \"AdminService\");\n\n    return recordFactory.newRecordInstance(\n        RefreshUserToGroupsMappingsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls": "  private synchronized void refreshServiceAcls(Configuration configuration,\n      PolicyProvider policyProvider) {\n    this.server.refreshServiceAclWithLoadedConfiguration(configuration,\n        policyProvider);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive": "  public synchronized void transitionToActive(\n      HAServiceProtocol.StateChangeRequestInfo reqInfo) throws IOException {\n    // call refreshAdminAcls before HA state transition\n    // for the case that adminAcls have been updated in previous active RM\n    try {\n      refreshAdminAcls(false);\n    } catch (YarnException ex) {\n      throw new ServiceFailedException(\"Can not execute refreshAdminAcls\", ex);\n    }\n\n    UserGroupInformation user = checkAccess(\"transitionToActive\");\n    checkHaStateChange(reqInfo);\n    try {\n      rm.transitionToActive();\n      // call all refresh*s for active RM to get the updated configurations.\n      refreshAll();\n      RMAuditLogger.logSuccess(user.getShortUserName(),\n          \"transitionToActive\", \"RMHAProtocolService\");\n    } catch (Exception e) {\n      RMAuditLogger.logFailure(user.getShortUserName(), \"transitionToActive\",\n          \"\", \"RMHAProtocolService\",\n          \"Exception transitioning to active\");\n      throw new ServiceFailedException(\n          \"Error when transitioning to Active mode\", e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkHaStateChange": "  private void checkHaStateChange(StateChangeRequestInfo req)\n      throws AccessControlException {\n    switch (req.getSource()) {\n      case REQUEST_BY_USER:\n        if (autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Manual failover for this ResourceManager is disallowed, \" +\n                  \"because automatic failover is enabled.\");\n        }\n        break;\n      case REQUEST_BY_USER_FORCED:\n        if (autoFailoverEnabled) {\n          LOG.warn(\"Allowing manual failover from \" +\n              org.apache.hadoop.ipc.Server.getRemoteAddress() +\n              \" even though automatic failover is enabled, because the user \" +\n              \"specified the force flag\");\n        }\n        break;\n      case REQUEST_BY_ZKFC:\n        if (!autoFailoverEnabled) {\n          throw new AccessControlException(\n              \"Request from ZK failover controller at \" +\n                  org.apache.hadoop.ipc.Server.getRemoteAddress() + \" denied \" +\n                  \"since automatic failover is not enabled\");\n        }\n        break;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess": "  private UserGroupInformation checkAccess(String method) throws IOException {\n    return RMServerUtils.verifyAdminAccess(authorizer, method, LOG);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls": "  private RefreshAdminAclsResponse refreshAdminAcls(boolean checkRMHAState)\n      throws YarnException, IOException {\n    String argName = \"refreshAdminAcls\";\n    UserGroupInformation user = checkAcls(argName);\n\n    if (checkRMHAState) {\n      checkRMStatus(user.getShortUserName(), argName, \"refresh Admin ACLs.\");\n    }\n    Configuration conf =\n        getConfiguration(new Configuration(false),\n            YarnConfiguration.YARN_SITE_CONFIGURATION_FILE);\n    authorizer.setAdmins(getAdminAclList(conf), UserGroupInformation\n        .getCurrentUser());\n    RMAuditLogger.logSuccess(user.getShortUserName(), argName,\n        \"AdminService\");\n\n    return recordFactory.newRecordInstance(RefreshAdminAclsResponse.class);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive": "  public void becomeActive() throws ServiceFailedException {\n    try {\n      rmContext.getRMAdminService().transitionToActive(req);\n    } catch (Exception e) {\n      throw new ServiceFailedException(\"RM could not transition to Active\", e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeActive": "  private boolean becomeActive() {\n    assert wantToBeInElection;\n    if (state == State.ACTIVE) {\n      // already active\n      return true;\n    }\n    try {\n      Stat oldBreadcrumbStat = fenceOldActive();\n      writeBreadCrumbNode(oldBreadcrumbStat);\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming active for \" + this);\n      }\n      appClient.becomeActive();\n      state = State.ACTIVE;\n      return true;\n    } catch (Exception e) {\n      LOG.warn(\"Exception handling the winning of election\", e);\n      // Caller will handle quitting and rejoining the election.\n      return false;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.writeBreadCrumbNode": "  private void writeBreadCrumbNode(Stat oldBreadcrumbStat)\n      throws KeeperException, InterruptedException {\n    Preconditions.checkState(appData != null, \"no appdata\");\n    \n    LOG.info(\"Writing znode \" + zkBreadCrumbPath +\n        \" to indicate that the local node is the most recent active...\");\n    if (oldBreadcrumbStat == null) {\n      // No previous active, just create the node\n      createWithRetries(zkBreadCrumbPath, appData, zkAcl,\n        CreateMode.PERSISTENT);\n    } else {\n      // There was a previous active, update the node\n      setDataWithRetries(zkBreadCrumbPath, appData, oldBreadcrumbStat.getVersion());\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fenceOldActive": "  private Stat fenceOldActive() throws InterruptedException, KeeperException {\n    final Stat stat = new Stat();\n    byte[] data;\n    LOG.info(\"Checking for any old active which needs to be fenced...\");\n    try {\n      data = zkDoWithRetries(new ZKAction<byte[]>() {\n        @Override\n        public byte[] run() throws KeeperException, InterruptedException {\n          return zkClient.getData(zkBreadCrumbPath, false, stat);\n        }\n      });\n    } catch (KeeperException ke) {\n      if (isNodeDoesNotExist(ke.code())) {\n        LOG.info(\"No old node to fence\");\n        return null;\n      }\n      \n      // If we failed to read for any other reason, then likely we lost\n      // our session, or we don't have permissions, etc. In any case,\n      // we probably shouldn't become active, and failing the whole\n      // thing is the best bet.\n      throw ke;\n    }\n\n    LOG.info(\"Old node exists: \" + StringUtils.byteToHexString(data));\n    if (Arrays.equals(data, appData)) {\n      LOG.info(\"But old node has our own data, so don't need to fence it.\");\n    } else {\n      appClient.fenceOldActive(data);\n    }\n    return stat;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.processResult": "  public synchronized void processResult(int rc, String path, Object ctx,\n      Stat stat) {\n    if (isStaleClient(ctx)) return;\n    monitorLockNodePending = false;\n\n    assert wantToBeInElection :\n        \"Got a StatNode result after quitting election\";\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"StatNode result: \" + rc + \" for path: \" + path\n          + \" connectionState: \" + zkConnectionState + \" for \" + this);\n    }\n\n    Code code = Code.get(rc);\n    if (isSuccess(code)) {\n      // the following owner check completes verification in case the lock znode\n      // creation was retried\n      if (stat.getEphemeralOwner() == zkClient.getSessionId()) {\n        // we own the lock znode. so we are the leader\n        if (!becomeActive()) {\n          reJoinElectionAfterFailureToBecomeActive();\n        }\n      } else {\n        // we dont own the lock znode. so we are a standby.\n        becomeStandby();\n      }\n      // the watch set by us will notify about changes\n      return;\n    }\n\n    if (isNodeDoesNotExist(code)) {\n      // the lock znode disappeared before we started monitoring it\n      enterNeutralMode();\n      joinElectionInternal();\n      return;\n    }\n\n    String errorMessage = \"Received stat error from Zookeeper. code:\"\n        + code.toString();\n    LOG.debug(errorMessage);\n\n    if (shouldRetry(code)) {\n      if (statRetryCount < maxRetryNum) {\n        ++statRetryCount;\n        monitorLockNodeAsync();\n        return;\n      }\n      errorMessage = errorMessage\n          + \". Not retrying further znode monitoring connection errors.\";\n    } else if (isSessionExpired(code)) {\n      // This isn't fatal - the client Watcher will re-join the election\n      LOG.warn(\"Lock monitoring failed because session was lost\");\n      return;\n    }\n\n    fatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.shouldRetry": "  private static boolean shouldRetry(Code code) {\n    return code == Code.CONNECTIONLOSS || code == Code.OPERATIONTIMEOUT;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.joinElectionInternal": "  private void joinElectionInternal() {\n    Preconditions.checkState(appData != null,\n        \"trying to join election without any app data\");\n    if (zkClient == null) {\n      if (!reEstablishSession()) {\n        fatalError(\"Failed to reEstablish connection with ZooKeeper\");\n        return;\n      }\n    }\n\n    createRetryCount = 0;\n    wantToBeInElection = true;\n    createLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.toString": "  public String toString() {\n    return \"elector id=\" + System.identityHashCode(this) +\n      \" appData=\" +\n      ((appData == null) ? \"null\" : StringUtils.byteToHexString(appData)) + \n      \" cb=\" + appClient;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.createLockNodeAsync": "  private void createLockNodeAsync() {\n    zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,\n        this, zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSuccess": "  private static boolean isSuccess(Code code) {\n    return (code == Code.OK);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorActiveStatus": "  private void monitorActiveStatus() {\n    assert wantToBeInElection;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Monitoring active leader for \" + this);\n    }\n    statRetryCount = 0;\n    monitorLockNodeAsync();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeDoesNotExist": "  private static boolean isNodeDoesNotExist(Code code) {\n    return (code == Code.NONODE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.reJoinElectionAfterFailureToBecomeActive": "  private void reJoinElectionAfterFailureToBecomeActive() {\n    reJoinElection(SLEEP_AFTER_FAILURE_TO_BECOME_ACTIVE);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.enterNeutralMode": "  private void enterNeutralMode() {\n    if (state != State.NEUTRAL) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Entering neutral mode for \" + this);\n      }\n      state = State.NEUTRAL;\n      appClient.enterNeutralMode();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.monitorLockNodeAsync": "  private void monitorLockNodeAsync() {\n    if (monitorLockNodePending && monitorLockNodeClient == zkClient) {\n      LOG.info(\"Ignore duplicate monitor lock-node request.\");\n      return;\n    }\n    monitorLockNodePending = true;\n    monitorLockNodeClient = zkClient;\n    zkClient.exists(zkLockFilePath,\n        watcher, this,\n        zkClient);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isSessionExpired": "  private static boolean isSessionExpired(Code code) {\n    return (code == Code.SESSIONEXPIRED);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.becomeStandby": "  private void becomeStandby() {\n    if (state != State.STANDBY) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Becoming standby for \" + this);\n      }\n      state = State.STANDBY;\n      appClient.becomeStandby();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.fatalError": "  private void fatalError(String errorMessage) {\n    LOG.fatal(errorMessage);\n    reset();\n    appClient.notifyFatalError(errorMessage);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isStaleClient": "  private synchronized boolean isStaleClient(Object ctx) {\n    Preconditions.checkNotNull(ctx);\n    if (zkClient != (ZooKeeper)ctx) {\n      LOG.warn(\"Ignoring stale result from old client with sessionId \" +\n          String.format(\"0x%08x\", ((ZooKeeper)ctx).getSessionId()));\n      return true;\n    }\n    return false;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.ha.ActiveStandbyElector.isNodeExists": "  private static boolean isNodeExists(Code code) {\n    return (code == Code.NODEEXISTS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.setChildQueues": "  synchronized void setChildQueues(Collection<CSQueue> childQueues) {\n    // Validate\n    float childCapacities = 0;\n    for (CSQueue queue : childQueues) {\n      childCapacities += queue.getCapacity();\n    }\n    float delta = Math.abs(1.0f - childCapacities);  // crude way to check\n    // allow capacities being set to 0, and enforce child 0 if parent is 0\n    if (((queueCapacities.getCapacity() > 0) && (delta > PRECISION)) || \n        ((queueCapacities.getCapacity() == 0) && (childCapacities > 0))) {\n      throw new IllegalArgumentException(\"Illegal\" +\n      \t\t\" capacity of \" + childCapacities + \n      \t\t\" for children of queue \" + queueName);\n    }\n    // check label capacities\n    for (String nodeLabel : labelManager.getClusterNodeLabelNames()) {\n      float capacityByLabel = queueCapacities.getCapacity(nodeLabel);\n      // check children's labels\n      float sum = 0;\n      for (CSQueue queue : childQueues) {\n        sum += queue.getQueueCapacities().getCapacity(nodeLabel);\n      }\n      if ((capacityByLabel > 0 && Math.abs(1.0f - sum) > PRECISION)\n          || (capacityByLabel == 0) && (sum > 0)) {\n        throw new IllegalArgumentException(\"Illegal\" + \" capacity of \"\n            + sum + \" for children of queue \" + queueName\n            + \" for label=\" + nodeLabel);\n      }\n    }\n    \n    this.childQueues.clear();\n    this.childQueues.addAll(childQueues);\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"setChildQueues: \" + getChildQueuesToPrint());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getChildQueuesToPrint": "  String getChildQueuesToPrint() {\n    StringBuilder sb = new StringBuilder();\n    for (CSQueue q : childQueues) {\n      sb.append(q.getQueuePath() + \n          \"usedCapacity=(\" + q.getUsedCapacity() + \"), \" + \n          \" label=(\"\n          + StringUtils.join(q.getAccessibleNodeLabels().iterator(), \",\") \n          + \")\");\n    }\n    return sb.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue": "  static CSQueue parseQueue(\n      CapacitySchedulerContext csContext,\n      CapacitySchedulerConfiguration conf, \n      CSQueue parent, String queueName, Map<String, CSQueue> queues,\n      Map<String, CSQueue> oldQueues, \n      QueueHook hook) throws IOException {\n    CSQueue queue;\n    String fullQueueName =\n        (parent == null) ? queueName\n            : (parent.getQueuePath() + \".\" + queueName);\n    String[] childQueueNames = \n      conf.getQueues(fullQueueName);\n    boolean isReservableQueue = conf.isReservable(fullQueueName);\n    if (childQueueNames == null || childQueueNames.length == 0) {\n      if (null == parent) {\n        throw new IllegalStateException(\n            \"Queue configuration missing child queue names for \" + queueName);\n      }\n      // Check if the queue will be dynamically managed by the Reservation\n      // system\n      if (isReservableQueue) {\n        queue =\n            new PlanQueue(csContext, queueName, parent,\n                oldQueues.get(queueName));\n      } else {\n        queue =\n            new LeafQueue(csContext, queueName, parent,\n                oldQueues.get(queueName));\n\n        // Used only for unit tests\n        queue = hook.hook(queue);\n      }\n    } else {\n      if (isReservableQueue) {\n        throw new IllegalStateException(\n            \"Only Leaf Queues can be reservable for \" + queueName);\n      }\n      ParentQueue parentQueue = \n        new ParentQueue(csContext, queueName, parent, oldQueues.get(queueName));\n\n      // Used only for unit tests\n      queue = hook.hook(parentQueue);\n\n      List<CSQueue> childQueues = new ArrayList<CSQueue>();\n      for (String childQueueName : childQueueNames) {\n        CSQueue childQueue = \n          parseQueue(csContext, conf, queue, childQueueName, \n              queues, oldQueues, hook);\n        childQueues.add(childQueue);\n      }\n      parentQueue.setChildQueues(childQueues);\n    }\n\n    if(queue instanceof LeafQueue == true && queues.containsKey(queueName)\n      && queues.get(queueName) instanceof LeafQueue == true) {\n      throw new IOException(\"Two leaf queues were named \" + queueName\n        + \". Leaf queue names must be distinct\");\n    }\n    queues.put(queueName, queue);\n\n    LOG.info(\"Initialized queue: \" + queue);\n    return queue;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.hook": "    public CSQueue hook(CSQueue queue) {\n      return queue;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getReservationSystem": "  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getScheduler": "  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logSuccess": "  public static void logSuccess(String user, String operation, String target) {\n    if (LOG.isInfoEnabled()) {\n      LOG.info(createSuccessLog(user, operation, target, null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createSuccessLog": "  static String createSuccessLog(String user, String operation, String target,\n      ApplicationId appId, ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.SUCCESS, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.logFailure": "  public static void logFailure(String user, String operation, String perm,\n      String target, String description) {\n    if (LOG.isWarnEnabled()) {\n      LOG.warn(createFailureLog(user, operation, perm, target, description,\n          null, null, null));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger.createFailureLog": "  static String createFailureLog(String user, String operation, String perm,\n      String target, String description, ApplicationId appId,\n      ApplicationAttemptId attemptId, ContainerId containerId) {\n    StringBuilder b = new StringBuilder();\n    start(Keys.USER, user, b);\n    addRemoteIP(b);\n    add(Keys.OPERATION, operation, b);\n    add(Keys.TARGET, target ,b);\n    add(Keys.RESULT, AuditConstants.FAILURE, b);\n    add(Keys.DESCRIPTION, description, b);\n    add(Keys.PERMISSIONS, perm, b);\n    if (appId != null) {\n      add(Keys.APPID, appId.toString(), b);\n    }\n    if (attemptId != null) {\n      add(Keys.APPATTEMPTID, attemptId.toString(), b);\n    }\n    if (containerId != null) {\n      add(Keys.CONTAINERID, containerId.toString(), b);\n    }\n    return b.toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMAdminService": "  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.queueCapacities.getCapacity": "  public float getCapacity(String label) {\n    if (StringUtils.equals(label, RMNodeLabelsManager.NO_LABEL) && isRoot) {\n      return 1f;\n    }\n    \n    return _get(label, CapacityType.CAP);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.queueCapacities._get": "  private float _get(String label, CapacityType type) {\n    try {\n      readLock.lock();\n      Capacities cap = capacitiesMap.get(label);\n      if (null == cap) {\n        return LABEL_DOESNT_EXIST_CAP;\n      }\n      return cap.capacitiesArr[type.idx];\n    } finally {\n      readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getQueuePath": "  public String getQueuePath() {\n    String parentPath = ((parent == null) ? \"\" : (parent.getQueuePath() + \".\"));\n    return parentPath + getQueueName();\n  }"
        },
        "bug_report": {
            "Title": "RM startup should fail for wrong CS xml NodeLabel capacity configuration ",
            "Description": "Currently in capacity Scheduler when capacity configuration is wrong\nRM will shutdown, but not incase of NodeLabels capacity mismatch\n\n\nIn {{CapacityScheduler#initializeQueues}}\n\n{code}\n  private void initializeQueues(CapacitySchedulerConfiguration conf)\n    throws IOException {   \n    root = \n        parseQueue(this, conf, null, CapacitySchedulerConfiguration.ROOT, \n            queues, queues, noop);\n    labelManager.reinitializeQueueLabels(getQueueToLabels());\n    root = \n        parseQueue(this, conf, null, CapacitySchedulerConfiguration.ROOT, \n            queues, queues, noop);\n    LOG.info(\"Initialized root queue \" + root);\n    initializeQueueMappings();\n    setQueueAcls(authorizer, queues);\n  }\n{code}\n\n{{labelManager}} is initialized from queues and calculation for Label level capacity mismatch happens in {{parseQueue}} . So during initialization {{parseQueue}} the labels will be empty . \n\n*Steps to reproduce*\n# Configure RM with capacity scheduler\n# Add one or two node label from rmadmin\n# Configure capacity xml with nodelabel but issue with capacity configuration for already added label\n# Restart both RM\n# Check on service init of capacity scheduler node label list is populated \n\n*Expected*\n\nRM should not start \n\n\n*Current exception on reintialize check*\n\n{code}\n2015-07-07 19:18:25,655 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=0.5, absoluteCapacity=0.5, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0\n2015-07-07 19:18:25,656 WARN org.apache.hadoop.yarn.server.resourcemanager.AdminService: Exception refresh queues.\njava.io.IOException: Failed to re-init queues\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:383)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshQueues(AdminService.java:376)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:605)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:314)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\nCaused by: java.lang.IllegalArgumentException: Illegal capacity of 0.5 for children of queue root for label=node2\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.setChildQueues(ParentQueue.java:159)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue(CapacityScheduler.java:639)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitializeQueues(CapacityScheduler.java:503)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:379)\n        ... 8 more\n2015-07-07 19:18:25,656 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=dsperf   OPERATION=refreshQueues TARGET=AdminService     RESULT=FAILURE  DESCRIPTION=Exception refresh queues.   PERMISSIONS=\n2015-07-07 19:18:25,656 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=dsperf   OPERATION=transitionToActive    TARGET=RMHAProtocolService      RESULT=FAILURE  DESCRIPTION=Exception transitioning to active   PERMISSIONS=\n2015-07-07 19:18:25,656 WARN org.apache.hadoop.ha.ActiveStandbyElector: Exception handling the winning of election\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:128)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Error when transitioning to Active mode\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:321)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        ... 4 more\nCaused by: org.apache.hadoop.ha.ServiceFailedException: java.io.IOException: Failed to re-init queues\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:617)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:314)\n        ... 5 more\n\n{code}\n\n"
        }
    },
    {
        "filename": "YARN-1903.json",
        "creation_time": "2014-04-04T20:51:24.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: 4: \n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testGetContainerStatus(TestNMClient.java:382)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testContainerManagement(TestNMClient.java:346)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testNMClient(TestNMClient.java:226)\n```",
        "source_code": {},
        "bug_report": {
            "Title": "Killing Container on NEW and LOCALIZING will result in exitCode and diagnostics not set",
            "Description": "The container status after stopping container is not expected.\n{code}\njava.lang.AssertionError: 4: \n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testGetContainerStatus(TestNMClient.java:382)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testContainerManagement(TestNMClient.java:346)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testNMClient(TestNMClient.java:226)\n{code}"
        }
    },
    {
        "filename": "YARN-4347.json",
        "creation_time": "2015-11-11T22:32:59.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:746)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1155)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:116)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1037)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1001)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:755)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts(RMAppImpl.java:839)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.access$1900(RMAppImpl.java:102)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:854)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:844)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:719)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:313)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:411)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1219)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:593)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1026)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1067)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1063)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private synchronized void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    SchedulerApplication<FiCaSchedulerApp> application =\n        applications.get(applicationAttemptId.getApplicationId());\n    if (application == null) {\n      LOG.warn(\"Application \" + applicationAttemptId.getApplicationId() +\n          \" cannot be found in scheduler.\");\n      return;\n    }\n    CSQueue queue = (CSQueue) application.getQueue();\n\n    FiCaSchedulerApp attempt = new FiCaSchedulerApp(applicationAttemptId,\n        application.getUser(), queue, queue.getActiveUsersManager(), rmContext,\n        application.getPriority());\n    if (transferStateFromPreviousAttempt) {\n      attempt.transferStateFromPreviousAttempt(\n          application.getCurrentAppAttempt());\n    }\n    application.setCurrentAppAttempt(attempt);\n\n    // Update attempt priority to the latest to avoid race condition i.e\n    // SchedulerApplicationAttempt is created with old priority but it is not\n    // set to SchedulerApplication#setCurrentAppAttempt.\n    // Scenario would occur is\n    // 1. SchdulerApplicationAttempt is created with old priority.\n    // 2. updateApplicationPriority() updates SchedulerApplication. Since\n    // currentAttempt is null, it just return.\n    // 3. ScheduelerApplcationAttempt is set in\n    // SchedulerApplication#setCurrentAppAttempt.\n    attempt.setPriority(application.getPriority());\n\n    queue.submitApplicationAttempt(attempt, application.getUser());\n    LOG.info(\"Added Application Attempt \" + applicationAttemptId\n        + \" to scheduler from user \" + application.getUser() + \" in queue \"\n        + queue.getQueueName());\n    if (isAttemptRecovering) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(applicationAttemptId\n            + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n      }\n    } else {\n      rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppAttemptEvent(applicationAttemptId,\n            RMAppAttemptEventType.ATTEMPT_ADDED));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return queues.get(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_LABELS_UPDATE:\n    {\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent =\n          (NodeLabelsUpdateSchedulerEvent) event;\n      \n      for (Entry<NodeId, Set<String>> entry : labelUpdateEvent\n          .getUpdatedNodeToLabels().entrySet()) {\n        NodeId id = entry.getKey();\n        Set<String> labels = entry.getValue();\n        updateLabelsOnNode(id, labels);\n      }\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      RMNode node = nodeUpdatedEvent.getRMNode();\n      setLastNodeUpdateTime(Time.now());\n      nodeUpdate(node);\n      if (!scheduleAsynchronously) {\n        allocateContainersToNode(getNode(node.getNodeID()));\n      }\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName = resolveReservationQueueName(appAddedEvent.getQueue(),\n          appAddedEvent.getApplicationId(), appAddedEvent.getReservationID(),\n          appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        if (!appAddedEvent.getIsAppRecovering()) {\n          addApplication(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        } else {\n          addApplicationOnRecovery(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        }\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent = \n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      completedContainer(getRMContainer(containerId), \n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId, \n              SchedulerUtils.EXPIRED_CONTAINER), \n          RMContainerEventType.EXPIRE);\n    }\n    break;\n    case DROP_RESERVATION:\n    {\n      ContainerPreemptEvent dropReservationEvent = (ContainerPreemptEvent)event;\n      RMContainer container = dropReservationEvent.getContainer();\n      dropContainerReservation(container);\n    }\n    break;\n    case PREEMPT_CONTAINER:\n    {\n      ContainerPreemptEvent preemptContainerEvent =\n          (ContainerPreemptEvent)event;\n      ApplicationAttemptId aid = preemptContainerEvent.getAppId();\n      RMContainer containerToBePreempted = preemptContainerEvent.getContainer();\n      preemptContainer(aid, containerToBePreempted);\n    }\n    break;\n    case KILL_CONTAINER:\n    {\n      ContainerPreemptEvent killContainerEvent = (ContainerPreemptEvent)event;\n      RMContainer containerToBeKilled = killContainerEvent.getContainer();\n      killContainer(containerToBeKilled);\n    }\n    break;\n    case CONTAINER_RESCHEDULED:\n    {\n      ContainerRescheduledEvent containerRescheduledEvent =\n          (ContainerRescheduledEvent) event;\n      RMContainer container = containerRescheduledEvent.getContainer();\n      recoverResourceRequestForContainer(container);\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.transition": "    public void\n        transition(RMAppAttemptImpl appAttempt, RMAppAttemptEvent event) {\n      if (appAttempt.targetedFinalState.equals(RMAppAttemptState.FAILED)\n          || appAttempt.targetedFinalState.equals(RMAppAttemptState.KILLED)) {\n        // ignore Container_Finished Event if we were supposed to reach\n        // FAILED/KILLED state.\n        return;\n      }\n\n      // pass in the earlier AMUnregistered Event also, as this is needed for\n      // AMFinishedAfterFinalSavingTransition later on\n      appAttempt.rememberTargetTransitions(event,\n        new AMFinishedAfterFinalSavingTransition(\n        appAttempt.eventCausingFinalSaving), RMAppAttemptState.FINISHED);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.updateInfoOnAMUnregister": "  private void updateInfoOnAMUnregister(RMAppAttemptEvent event) {\n    progress = 1.0f;\n    RMAppAttemptUnregistrationEvent unregisterEvent =\n        (RMAppAttemptUnregistrationEvent) event;\n    diagnostics.append(unregisterEvent.getDiagnosticMsg());\n    originalTrackingUrl = sanitizeTrackingUrl(unregisterEvent.getFinalTrackingUrl());\n    finalStatus = unregisterEvent.getFinalApplicationStatus();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.sanitizeTrackingUrl": "  private static String sanitizeTrackingUrl(String url) {\n    return (url == null || url.trim().isEmpty()) ? \"N/A\" : url;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getSubmissionContext": "  public ApplicationSubmissionContext getSubmissionContext() {\n    return this.submissionContext;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.launchAttempt": "  private void launchAttempt(){\n    launchAMStartTime = System.currentTimeMillis();\n    // Send event to launch the AM Container\n    eventHandler.handle(new AMLauncherEvent(AMLauncherEventType.LAUNCH, this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.sendAMContainerToNM": "  private void sendAMContainerToNM(RMAppAttemptImpl appAttempt,\n      RMAppAttemptContainerFinishedEvent containerFinishedEvent) {\n    NodeId nodeId = containerFinishedEvent.getNodeId();\n    if (containerFinishedEvent.getContainerStatus() != null) {\n      if (shouldCountTowardsNodeBlacklisting(containerFinishedEvent\n          .getContainerStatus().getExitStatus())) {\n        appAttempt.addAMNodeToBlackList(containerFinishedEvent.getNodeId());\n      }\n    } else {\n      LOG.warn(\"No ContainerStatus in containerFinishedEvent\");\n    }\n    finishedContainersSentToAM.putIfAbsent(nodeId,\n      new ArrayList<ContainerStatus>());\n    appAttempt.finishedContainersSentToAM.get(nodeId).add(\n      containerFinishedEvent.getContainerStatus());\n\n    if (!appAttempt.getSubmissionContext()\n      .getKeepContainersAcrossApplicationAttempts()) {\n      appAttempt.sendFinishedContainersToNM();\n    } else {\n      appAttempt.sendFinishedAMContainerToNM(nodeId,\n          containerFinishedEvent.getContainerStatus().getContainerId());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.invalidateAMHostAndPort": "  private void invalidateAMHostAndPort() {\n    this.host = \"N/A\";\n    this.rpcPort = -1;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setMasterContainer": "  public void setMasterContainer(Container container) {\n    masterContainer = container;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.attemptLaunched": "  private void attemptLaunched() {\n    // Register with AMLivelinessMonitor\n    rmContext.getAMLivelinessMonitor().register(getAppAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getHost": "  public String getHost() {\n    this.readLock.lock();\n\n    try {\n      return this.host;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getProgress": "  public float getProgress() {\n    this.readLock.lock();\n\n    try {\n      return this.progress;\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.storeAttempt": "  private void storeAttempt() {\n    // store attempt data in a non-blocking manner to prevent dispatcher\n    // thread starvation and wait for state to be saved\n    LOG.info(\"Storing attempt: AppId: \" + \n              getAppAttemptId().getApplicationId() \n              + \" AttemptId: \" + \n              getAppAttemptId()\n              + \" MasterContainer: \" + masterContainer);\n    rmContext.getStateStore().storeNewApplicationAttempt(this);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.setAMContainerCrashedDiagnosticsAndExitStatus": "  private void setAMContainerCrashedDiagnosticsAndExitStatus(\n      RMAppAttemptContainerFinishedEvent finishEvent) {\n    ContainerStatus status = finishEvent.getContainerStatus();\n    String diagnostics = getAMContainerCrashedDiagnostics(finishEvent);\n    this.diagnostics.append(diagnostics);\n    this.amContainerExitStatus = status.getExitStatus();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAMBlacklist": "  public BlacklistManager getAMBlacklist() {\n    return blacklistedNodesForAM;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.retryFetchingAMContainer": "  private void retryFetchingAMContainer(final RMAppAttemptImpl appAttempt) {\n    // start a new thread so that we are not blocking main dispatcher thread.\n    new Thread() {\n      @Override\n      public void run() {\n        try {\n          Thread.sleep(500);\n        } catch (InterruptedException e) {\n          LOG.warn(\"Interrupted while waiting to resend the\"\n              + \" ContainerAllocated Event.\");\n        }\n        appAttempt.eventHandler.handle(\n            new RMAppAttemptEvent(appAttempt.applicationAttemptId,\n                RMAppAttemptEventType.CONTAINER_ALLOCATED));\n      }\n    }.start();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAMExpiredDiagnostics": "  private static String getAMExpiredDiagnostics(RMAppAttemptEvent event) {\n    String diag =\n        \"ApplicationMaster for attempt \" + event.getApplicationAttemptId()\n            + \" timed out\";\n    return diag;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.shouldCountTowardsMaxAttemptRetry": "  public boolean shouldCountTowardsMaxAttemptRetry() {\n    try {\n      this.readLock.lock();\n      int exitStatus = getAMContainerExitStatus();\n      return !(exitStatus == ContainerExitStatus.PREEMPTED\n          || exitStatus == ContainerExitStatus.ABORTED\n          || exitStatus == ContainerExitStatus.DISKS_FAILED\n          || exitStatus == ContainerExitStatus.KILLED_BY_RESOURCEMANAGER);\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.addJustFinishedContainer": "  private static void addJustFinishedContainer(RMAppAttemptImpl appAttempt,\n      RMAppAttemptContainerFinishedEvent containerFinishedEvent) {\n    appAttempt.justFinishedContainers.putIfAbsent(containerFinishedEvent\n        .getNodeId(), new ArrayList<ContainerStatus>());\n    appAttempt.justFinishedContainers.get(containerFinishedEvent\n            .getNodeId()).add(containerFinishedEvent.getContainerStatus());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getClientTokenMasterKey": "  public SecretKey getClientTokenMasterKey() {\n    return this.clientTokenMasterKey;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitionsAndStoreState": "  private void rememberTargetTransitionsAndStoreState(RMAppAttemptEvent event,\n      Object transitionToDo, RMAppAttemptState targetFinalState,\n      RMAppAttemptState stateToBeStored) {\n\n    rememberTargetTransitions(event, transitionToDo, targetFinalState);\n    stateBeforeFinalSaving = getState();\n\n    // As of today, finalState, diagnostics, final-tracking-url and\n    // finalAppStatus are the only things that we store into the StateStore\n    // AFTER the initial saving on app-attempt-start\n    // These fields can be visible from outside only after they are saved in\n    // StateStore\n    String diags = null;\n\n    // don't leave the tracking URL pointing to a non-existent AM\n    setTrackingUrlToRMAppPage(stateToBeStored);\n    String finalTrackingUrl = getOriginalTrackingUrl();\n    FinalApplicationStatus finalStatus = null;\n    int exitStatus = ContainerExitStatus.INVALID;\n    switch (event.getType()) {\n    case LAUNCH_FAILED:\n      diags = event.getDiagnosticMsg();\n      break;\n    case REGISTERED:\n      diags = getUnexpectedAMRegisteredDiagnostics();\n      break;\n    case UNREGISTERED:\n      RMAppAttemptUnregistrationEvent unregisterEvent =\n          (RMAppAttemptUnregistrationEvent) event;\n      diags = unregisterEvent.getDiagnosticMsg();\n      // reset finalTrackingUrl to url sent by am\n      finalTrackingUrl = sanitizeTrackingUrl(unregisterEvent.getFinalTrackingUrl());\n      finalStatus = unregisterEvent.getFinalApplicationStatus();\n      break;\n    case CONTAINER_FINISHED:\n      RMAppAttemptContainerFinishedEvent finishEvent =\n          (RMAppAttemptContainerFinishedEvent) event;\n      diags = getAMContainerCrashedDiagnostics(finishEvent);\n      exitStatus = finishEvent.getContainerStatus().getExitStatus();\n      break;\n    case KILL:\n      break;\n    case FAIL:\n      diags = event.getDiagnosticMsg();\n      break;\n    case EXPIRE:\n      diags = getAMExpiredDiagnostics(event);\n      break;\n    default:\n      break;\n    }\n    AggregateAppResourceUsage resUsage =\n        this.attemptMetrics.getAggregateAppResourceUsage();\n    RMStateStore rmStore = rmContext.getStateStore();\n    setFinishTime(System.currentTimeMillis());\n\n    ApplicationAttemptStateData attemptState =\n        ApplicationAttemptStateData.newInstance(\n            applicationAttemptId,  getMasterContainer(),\n            rmStore.getCredentialsFromAppAttempt(this),\n            startTime, stateToBeStored, finalTrackingUrl, diags,\n            finalStatus, exitStatus,\n          getFinishTime(), resUsage.getMemorySeconds(),\n          resUsage.getVcoreSeconds());\n    LOG.info(\"Updating application attempt \" + applicationAttemptId\n        + \" with final state: \" + targetedFinalState + \", and exit status: \"\n        + exitStatus);\n    rmStore.updateApplicationAttemptState(attemptState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.transferStateFromAttempt": "  public void transferStateFromAttempt(RMAppAttempt attempt) {\n    this.justFinishedContainers = attempt.getJustFinishedContainersReference();\n    this.finishedContainersSentToAM =\n        attempt.getFinishedContainersSentToAMReference();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getDiagnostics": "  public String getDiagnostics() {\n    this.readLock.lock();\n\n    try {\n      return this.diagnostics.toString();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.removeCredentials": "  private void removeCredentials(RMAppAttemptImpl appAttempt) {\n    // Unregister from the ClientToAMTokenSecretManager\n    if (UserGroupInformation.isSecurityEnabled()) {\n      appAttempt.rmContext.getClientToAMTokenSecretManager()\n        .unRegisterApplication(appAttempt.getAppAttemptId());\n    }\n\n    // Remove the AppAttempt from the AMRMTokenSecretManager\n    appAttempt.rmContext.getAMRMTokenSecretManager()\n      .applicationMasterFinished(appAttempt.getAppAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getMasterContainer": "  public Container getMasterContainer() {\n    return this.masterContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptId": "  public ApplicationAttemptId getAppAttemptId() {\n    return this.applicationAttemptId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitions": "  private void rememberTargetTransitions(RMAppAttemptEvent event,\n      Object transitionToDo, RMAppAttemptState targetFinalState) {\n    transitionTodo = transitionToDo;\n    targetedFinalState = targetFinalState;\n    eventCausingFinalSaving = event;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getUnexpectedAMRegisteredDiagnostics": "  private static String getUnexpectedAMRegisteredDiagnostics() {\n    return \"Unmanaged AM must register after AM attempt reaches LAUNCHED state.\";\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle": "  public void handle(RMAppAttemptEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();\n      LOG.debug(\"Processing event for \" + appAttemptID + \" of type \"\n          + event.getType());\n      final RMAppAttemptState oldState = getAppAttemptState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getAppAttemptState()) {\n        LOG.info(appAttemptID + \" State change from \" + oldState + \" to \"\n            + getAppAttemptState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getAppAttemptState": "  public RMAppAttemptState getAppAttemptState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts": "  private void recoverAppAttempts() {\n    for (RMAppAttempt attempt : getAppAttempts().values()) {\n      attempt.handle(new RMAppAttemptEvent(attempt.getAppAttemptId(),\n        RMAppAttemptEventType.RECOVER));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getAppAttempts": "  public Map<ApplicationAttemptId, RMAppAttempt> getAppAttempts() {\n    this.readLock.lock();\n\n    try {\n      return Collections.unmodifiableMap(this.attempts);\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle": "  public void handle(RMAppEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId appID = event.getApplicationId();\n      LOG.debug(\"Processing event for \" + appID + \" of type \"\n          + event.getType());\n      final RMAppState oldState = getState();\n      try {\n        /* keep the master in sync with the state machine */\n        this.stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.error(\"Can't handle this event at current state\", e);\n        /* TODO fail the application on the failed transition */\n      }\n\n      if (oldState != getState()) {\n        LOG.info(appID + \" State change from \" + oldState + \" to \"\n            + getState());\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.transition": "    public RMAppState transition(RMAppImpl app, RMAppEvent event) {\n      int numberOfFailure = app.getNumFailedAppAttempts();\n      LOG.info(\"The number of failed attempts\"\n          + (app.attemptFailuresValidityInterval > 0 ? \" in previous \"\n              + app.attemptFailuresValidityInterval + \" milliseconds \" : \" \")\n          + \"is \" + numberOfFailure + \". The max attempts is \"\n          + app.maxAppAttempts);\n      if (!app.submissionContext.getUnmanagedAM()\n          && numberOfFailure < app.maxAppAttempts) {\n        if (initialState.equals(RMAppState.KILLING)) {\n          // If this is not last attempt, app should be killed instead of\n          // launching a new attempt\n          app.rememberTargetTransitionsAndStoreState(event,\n            new AppKilledTransition(), RMAppState.KILLED, RMAppState.KILLED);\n          return RMAppState.FINAL_SAVING;\n        }\n\n        boolean transferStateFromPreviousAttempt;\n        RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n        transferStateFromPreviousAttempt =\n            failedEvent.getTransferStateFromPreviousAttempt();\n\n        RMAppAttempt oldAttempt = app.currentAttempt;\n        app.createAndStartNewAttempt(transferStateFromPreviousAttempt);\n        // Transfer the state from the previous attempt to the current attempt.\n        // Note that the previous failed attempt may still be collecting the\n        // container events from the scheduler and update its data structures\n        // before the new attempt is created. We always transferState for\n        // finished containers so that they can be acked to NM,\n        // but when pulling finished container we will check this flag again.\n        ((RMAppAttemptImpl) app.currentAttempt)\n          .transferStateFromAttempt(oldAttempt);\n        return initialState;\n      } else {\n        if (numberOfFailure >= app.maxAppAttempts) {\n          app.isNumAttemptsBeyondThreshold = true;\n        }\n        app.rememberTargetTransitionsAndStoreState(event,\n          new AttemptFailedFinalStateSavedTransition(), RMAppState.FAILED,\n          RMAppState.FAILED);\n        return RMAppState.FINAL_SAVING;\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.processNodeUpdate": "  private void processNodeUpdate(RMAppNodeUpdateType type, RMNode node) {\n    NodeState nodeState = node.getState();\n    updatedNodes.add(node);\n    LOG.debug(\"Received node update event:\" + type + \" for node:\" + node\n        + \" with state:\" + nodeState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.rememberTargetTransitionsAndStoreState": "  private void rememberTargetTransitionsAndStoreState(RMAppEvent event,\n      Object transitionToDo, RMAppState targetFinalState,\n      RMAppState stateToBeStored) {\n    rememberTargetTransitions(event, transitionToDo, targetFinalState);\n    this.stateBeforeFinalSaving = getState();\n    this.storedFinishTime = this.systemClock.getTime();\n\n    LOG.info(\"Updating application \" + this.applicationId\n        + \" with final state: \" + this.targetedFinalState);\n    // we lost attempt_finished diagnostics in app, because attempt_finished\n    // diagnostics is sent after app final state is saved. Later on, we will\n    // create GetApplicationAttemptReport specifically for getting per attempt\n    // info.\n    String diags = null;\n    switch (event.getType()) {\n    case APP_REJECTED:\n    case ATTEMPT_FINISHED:\n    case ATTEMPT_KILLED:\n      diags = event.getDiagnosticMsg();\n      break;\n    case ATTEMPT_FAILED:\n      RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n      diags = getAppAttemptFailedDiagnostics(failedEvent);\n      break;\n    default:\n      break;\n    }\n    ApplicationStateData appState =\n        ApplicationStateData.newInstance(this.submitTime, this.startTime,\n            this.user, this.submissionContext,\n            stateToBeStored, diags, this.storedFinishTime);\n    this.rmContext.getStateStore().updateApplicationState(appState);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.isAppInFinalState": "  public static boolean isAppInFinalState(RMApp rmApp) {\n    RMAppState appState = ((RMAppImpl) rmApp).getRecoveredFinalState();\n    if (appState == null) {\n      appState = rmApp.getState();\n    }\n    return appState == RMAppState.FAILED || appState == RMAppState.FINISHED\n        || appState == RMAppState.KILLED;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getState": "  public RMAppState getState() {\n    this.readLock.lock();\n    try {\n        return this.stateMachine.getCurrentState();\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getApplicationId": "  public ApplicationId getApplicationId() {\n    return this.applicationId;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getUser": "  public String getUser() {\n    return this.user;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.parseCredentials": "  protected Credentials parseCredentials() throws IOException {\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = submissionContext.getAMContainerSpec().getTokens();\n    if (tokens != null) {\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n    return credentials;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.createAndStartNewAttempt": "  private void\n      createAndStartNewAttempt(boolean transferStateFromPreviousAttempt) {\n    createNewAttempt();\n    handler.handle(new RMAppStartAttemptEvent(currentAttempt.getAppAttemptId(),\n      transferStateFromPreviousAttempt));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getRanNodes": "  public Set<NodeId> getRanNodes() {\n    return ranNodes;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.rememberTargetTransitions": "  private void rememberTargetTransitions(RMAppEvent event,\n      Object transitionToDo, RMAppState targetFinalState) {\n    transitionTodo = transitionToDo;\n    targetedFinalState = targetFinalState;\n    eventCausingFinalSaving = event;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recover": "  public void recover(RMState state) {\n    ApplicationStateData appState =\n        state.getApplicationState().get(getApplicationId());\n    this.recoveredFinalState = appState.getState();\n    LOG.info(\"Recovering app: \" + getApplicationId() + \" with \" + \n        + appState.getAttemptCount() + \" attempts and final state = \"\n        + this.recoveredFinalState );\n    this.diagnostics.append(null == appState.getDiagnostics() ? \"\" : appState\n        .getDiagnostics());\n    this.storedFinishTime = appState.getFinishTime();\n    this.startTime = appState.getStartTime();\n\n    for(int i=0; i<appState.getAttemptCount(); ++i) {\n      // create attempt\n      createNewAttempt();\n      ((RMAppAttemptImpl)this.currentAttempt).recover(state);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getAppAttemptFailedDiagnostics": "  private String getAppAttemptFailedDiagnostics(RMAppEvent event) {\n    String msg = null;\n    RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;\n    if (this.submissionContext.getUnmanagedAM()) {\n      // RM does not manage the AM. Do not retry\n      msg = \"Unmanaged application \" + this.getApplicationId()\n              + \" failed due to \" + failedEvent.getDiagnosticMsg()\n              + \". Failing the application.\";\n    } else if (this.isNumAttemptsBeyondThreshold) {\n      int globalLimit = conf.getInt(YarnConfiguration.RM_AM_MAX_ATTEMPTS,\n          YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS);\n      msg = String.format(\n        \"Application %s failed %d times%s%s due to %s. Failing the application.\",\n          getApplicationId(),\n          maxAppAttempts,\n          (attemptFailuresValidityInterval <= 0 ? \"\"\n               : (\" in previous \" + attemptFailuresValidityInterval\n                  + \" milliseconds\")),\n          (globalLimit == maxAppAttempts) ? \"\"\n              : (\" (global limit =\" + globalLimit\n                 + \"; local limit is =\" + maxAppAttempts + \")\"),\n          failedEvent.getDiagnosticMsg());\n    }\n    return msg;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.getNumFailedAppAttempts": "  private int getNumFailedAppAttempts() {\n    int completedAttempts = 0;\n    long endTime = this.systemClock.getTime();\n    // Do not count AM preemption, hardware failures or NM resync\n    // as attempt failure.\n    for (RMAppAttempt attempt : attempts.values()) {\n      if (attempt.shouldCountTowardsMaxAttemptRetry()) {\n        if (this.attemptFailuresValidityInterval <= 0\n            || (attempt.getFinishTime() > endTime\n                - this.attemptFailuresValidityInterval)) {\n          completedAttempts++;\n        }\n      }\n    }\n    return completedAttempts;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication": "  protected void recoverApplication(ApplicationStateData appState,\n      RMState rmState) throws Exception {\n    ApplicationSubmissionContext appContext =\n        appState.getApplicationSubmissionContext();\n    ApplicationId appId = appContext.getApplicationId();\n\n    // create and recover app.\n    RMAppImpl application =\n        createAndPopulateNewRMApp(appContext, appState.getSubmitTime(),\n            appState.getUser(), true);\n\n    application.handle(new RMAppRecoverEvent(appId, rmState));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp": "  private RMAppImpl createAndPopulateNewRMApp(\n      ApplicationSubmissionContext submissionContext, long submitTime,\n      String user, boolean isRecovery) throws YarnException {\n    // Do queue mapping\n    if (!isRecovery) {\n      if (rmContext.getQueuePlacementManager() != null) {\n        // We only do queue mapping when it's a new application\n        rmContext.getQueuePlacementManager().placeApplication(\n            submissionContext, user);\n      }\n    }\n    \n    ApplicationId applicationId = submissionContext.getApplicationId();\n    ResourceRequest amReq =\n        validateAndCreateResourceRequest(submissionContext, isRecovery);\n\n    // Verify and get the update application priority and set back to\n    // submissionContext\n    Priority appPriority = rmContext.getScheduler()\n        .checkAndGetApplicationPriority(submissionContext.getPriority(), user,\n            submissionContext.getQueue(), applicationId);\n    submissionContext.setPriority(appPriority);\n\n    // Create RMApp\n    RMAppImpl application = new RMAppImpl(applicationId, rmContext, this.conf,\n        submissionContext.getApplicationName(), user,\n        submissionContext.getQueue(), submissionContext, this.scheduler,\n        this.masterService, submitTime, submissionContext.getApplicationType(),\n        submissionContext.getApplicationTags(), amReq);\n\n    // Concurrent app submissions with same applicationId will fail here\n    // Concurrent app submissions with different applicationIds will not\n    // influence each other\n    if (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw new YarnException(message);\n    }\n    // Inform the ACLs Manager\n    this.applicationACLsManager.addApplication(applicationId,\n        submissionContext.getAMContainerSpec().getApplicationACLs());\n    String appViewACLs = submissionContext.getAMContainerSpec()\n        .getApplicationACLs().get(ApplicationAccessType.VIEW_APP);\n    rmContext.getSystemMetricsPublisher().appACLsUpdated(\n        application, appViewACLs, System.currentTimeMillis());\n    return application;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch(event.getType()) {\n      case APP_COMPLETED: \n      {\n        finishApplication(applicationId);\n        logApplicationSummary(applicationId);\n        checkAppNumCompletedLimit(); \n      } \n      break;\n      default:\n        LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n      }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover": "  public void recover(RMState state) throws Exception {\n    RMStateStore store = rmContext.getStateStore();\n    assert store != null;\n    // recover applications\n    Map<ApplicationId, ApplicationStateData> appStates =\n        state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for (ApplicationStateData appState : appStates.values()) {\n      recoverApplication(appState, state);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmContext.getRMDelegationTokenSecretManager().recover(state);\n\n    // recover AMRMTokenSecretManager\n    rmContext.getAMRMTokenSecretManager().recover(state);\n\n    // recover reservations\n    if (reservationSystem != null) {\n      reservationSystem.recover(state);\n    }\n    // recover applications\n    rmAppManager.recover(state);\n\n    setSchedulerRecoveryStartAndWaitTime(state, conf);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.setSchedulerRecoveryStartAndWaitTime": "  private void setSchedulerRecoveryStartAndWaitTime(RMState state,\n      Configuration conf) {\n    if (!state.getApplicationState().isEmpty()) {\n      long waitTime =\n          conf.getLong(YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS,\n            YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS);\n      rmContext.setSchedulerRecoveryStartAndWaitTime(waitTime);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    if (this.rmContext.isHAEnabled()) {\n      transitionToStandby(true);\n    } else {\n      transitionToActive();\n    }\n\n    startWepApp();\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER,\n        false)) {\n      int port = webApp.port();\n      WebAppUtils.setRMWebAppPort(conf, port);\n    }\n    super.serviceStart();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive": "  synchronized void transitionToActive() throws Exception {\n    if (rmContext.getHAServiceState() == HAServiceProtocol.HAServiceState.ACTIVE) {\n      LOG.info(\"Already in active state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to active state\");\n\n    this.rmLoginUGI.doAs(new PrivilegedExceptionAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }\n    });\n\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.ACTIVE);\n    LOG.info(\"Transitioned to active state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n\n    // Use the customized yarn filter instead of the standard kerberos filter to\n    // allow users to authenticate using delegation tokens\n    // 4 conditions need to be satisfied -\n    // 1. security is enabled\n    // 2. http auth type is set to kerberos\n    // 3. \"yarn.resourcemanager.webapp.use-yarn-filter\" override is set to true\n    // 4. hadoop.http.filter.initializers container AuthenticationFilterInitializer\n\n    Configuration conf = getConfig();\n    boolean enableCorsFilter =\n        conf.getBoolean(YarnConfiguration.RM_WEBAPP_ENABLE_CORS_FILTER,\n            YarnConfiguration.DEFAULT_RM_WEBAPP_ENABLE_CORS_FILTER);\n    boolean useYarnAuthenticationFilter =\n        conf.getBoolean(\n          YarnConfiguration.RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER);\n    String authPrefix = \"hadoop.http.authentication.\";\n    String authTypeKey = authPrefix + \"type\";\n    String filterInitializerConfKey = \"hadoop.http.filter.initializers\";\n    String actualInitializers = \"\";\n    Class<?>[] initializersClasses =\n        conf.getClasses(filterInitializerConfKey);\n\n    // setup CORS\n    if (enableCorsFilter) {\n      conf.setBoolean(HttpCrossOriginFilterInitializer.PREFIX\n          + HttpCrossOriginFilterInitializer.ENABLED_SUFFIX, true);\n    }\n\n    boolean hasHadoopAuthFilterInitializer = false;\n    boolean hasRMAuthFilterInitializer = false;\n    if (initializersClasses != null) {\n      for (Class<?> initializer : initializersClasses) {\n        if (initializer.getName().equals(\n          AuthenticationFilterInitializer.class.getName())) {\n          hasHadoopAuthFilterInitializer = true;\n        }\n        if (initializer.getName().equals(\n          RMAuthenticationFilterInitializer.class.getName())) {\n          hasRMAuthFilterInitializer = true;\n        }\n      }\n      if (UserGroupInformation.isSecurityEnabled()\n          && useYarnAuthenticationFilter\n          && hasHadoopAuthFilterInitializer\n          && conf.get(authTypeKey, \"\").equals(\n            KerberosAuthenticationHandler.TYPE)) {\n        ArrayList<String> target = new ArrayList<String>();\n        for (Class<?> filterInitializer : initializersClasses) {\n          if (filterInitializer.getName().equals(\n            AuthenticationFilterInitializer.class.getName())) {\n            if (hasRMAuthFilterInitializer == false) {\n              target.add(RMAuthenticationFilterInitializer.class.getName());\n            }\n            continue;\n          }\n          target.add(filterInitializer.getName());\n        }\n        actualInitializers = StringUtils.join(\",\", target);\n\n        LOG.info(\"Using RM authentication filter(kerberos/delegation-token)\"\n            + \" for RM webapp authentication\");\n        RMAuthenticationFilter\n          .setDelegationTokenSecretManager(getClientRMService().rmDTSecretManager);\n        conf.set(filterInitializerConfKey, actualInitializers);\n      }\n    }\n\n    // if security is not enabled and the default filter initializer has not \n    // been set, set the initializer to include the\n    // RMAuthenticationFilterInitializer which in turn will set up the simple\n    // auth filter.\n\n    String initializers = conf.get(filterInitializerConfKey);\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      if (initializersClasses == null || initializersClasses.length == 0) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName());\n        conf.set(authTypeKey, \"simple\");\n      } else if (initializers.equals(StaticUserWebFilter.class.getName())) {\n        conf.set(filterInitializerConfKey,\n          RMAuthenticationFilterInitializer.class.getName() + \",\"\n              + initializers);\n        conf.set(authTypeKey, \"simple\");\n      }\n    }\n\n    Builder<ApplicationMasterService> builder = \n        WebApps\n            .$for(\"cluster\", ApplicationMasterService.class, masterService,\n                \"ws\")\n            .with(conf)\n            .withHttpSpnegoPrincipalKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY)\n            .withHttpSpnegoKeytabKey(\n                YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)\n            .at(webAppAddress);\n    String proxyHostAndPort = WebAppUtils.getProxyHostAndPort(conf);\n    if(WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf).\n        equals(proxyHostAndPort)) {\n      if (HAUtil.isHAEnabled(conf)) {\n        fetcher = new AppReportFetcher(conf);\n      } else {\n        fetcher = new AppReportFetcher(conf, getClientRMService());\n      }\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME,\n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n\n    }\n    webApp = builder.start(new RMWebApp(this));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    HAServiceState state = rmContext.getHAServiceState();\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    if (state == HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) throws Exception {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetDispatcher();\n      createAndInitActiveServices();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.handle": "    public void handle(RMNodeEvent event) {\n      NodeId nodeId = event.getNodeId();\n      RMNode node = this.rmContext.getRMNodes().get(nodeId);\n      if (node != null) {\n        try {\n          ((EventHandler<RMNodeEvent>) node).handle(event);\n        } catch (Throwable t) {\n          LOG.error(\"Error in handling event type \" + event.getType()\n              + \" for node \" + nodeId, t);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.submitApplicationAttempt": "  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @param resourceLimits how much overall resource of this queue can use. \n   * @param schedulingMode Type of exclusive check when assign container on a \n   * NodeManager, see {@link SchedulingMode}.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getQueueName": "  public String getQueueName();\n\n  /**\n   * Get the full name of the queue, including the heirarchy.\n   * @return the full name of the queue\n   */\n  public String getQueuePath();\n  \n  /**\n   * Get the configured <em>capacity</em> of the queue.\n   * @return configured queue capacity\n   */\n  public float getCapacity();\n\n  /**\n   * Get capacity of the parent of the queue as a function of the \n   * cumulative capacity in the cluster.\n   * @return capacity of the parent of the queue as a function of the \n   *         cumulative capacity in the cluster\n   */\n  public float getAbsoluteCapacity();\n  \n  /**\n   * Get the configured maximum-capacity of the queue. \n   * @return the configured maximum-capacity of the queue\n   */\n  public float getMaximumCapacity();\n  \n  /**\n   * Get maximum-capacity of the queue as a funciton of the cumulative capacity\n   * of the cluster.\n   * @return maximum-capacity of the queue as a funciton of the cumulative capacity\n   *         of the cluster\n   */\n  public float getAbsoluteMaximumCapacity();\n  \n  /**\n   * Get the current absolute used capacity of the queue\n   * relative to the entire cluster.\n   * @return queue absolute used capacity\n   */\n  public float getAbsoluteUsedCapacity();\n\n  /**\n   * Set used capacity of the queue.\n   * @param usedCapacity\n   *          used capacity of the queue\n   */\n  public void setUsedCapacity(float usedCapacity);\n\n  /**\n   * Set absolute used capacity of the queue.\n   * @param absUsedCapacity\n   *          absolute used capacity of the queue\n   */\n  public void setAbsoluteUsedCapacity(float absUsedCapacity);\n\n  /**\n   * Get the current used capacity of nodes without label(s) of the queue\n   * and it's children (if any).\n   * @return queue used capacity\n   */\n  public float getUsedCapacity();\n\n  /**\n   * Get the currently utilized resources which allocated at nodes without any\n   * labels in the cluster by the queue and children (if any).\n   * \n   * @return used resources by the queue and it's children\n   */\n  public Resource getUsedResources();\n  \n  /**\n   * Get the current run-state of the queue\n   * @return current run-state\n   */\n  public QueueState getState();\n  \n  /**\n   * Get child queues\n   * @return child queues\n   */\n  public List<CSQueue> getChildQueues();\n  \n  /**\n   * Check if the <code>user</code> has permission to perform the operation\n   * @param acl ACL\n   * @param user user\n   * @return <code>true</code> if the user has the permission, \n   *         <code>false</code> otherwise\n   */\n  public boolean hasAccess(QueueACL acl, UserGroupInformation user);\n  \n  /**\n   * Submit a new application to the queue.\n   * @param applicationId the applicationId of the application being submitted\n   * @param user user who submitted the application\n   * @param queue queue to which the application is submitted\n   */\n  public void submitApplication(ApplicationId applicationId, String user,\n      String queue) throws AccessControlException;\n\n  /**\n   * Submit an application attempt to the queue.\n   */\n  public void submitApplicationAttempt(FiCaSchedulerApp application,\n      String userName);\n\n  /**\n   * An application submitted to this queue has finished.\n   * @param applicationId\n   * @param user user who submitted the application\n   */\n  public void finishApplication(ApplicationId applicationId, String user);\n\n  /**\n   * An application attempt submitted to this queue has finished.\n   */\n  public void finishApplicationAttempt(FiCaSchedulerApp application,\n      String queue);\n\n  /**\n   * Assign containers to applications in the queue or it's children (if any).\n   * @param clusterResource the resource of the cluster.\n   * @param node node on which resources are available\n   * @param resourceLimits how much overall resource of this queue can use. \n   * @param schedulingMode Type of exclusive check when assign container on a \n   * NodeManager, see {@link SchedulingMode}.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.getActiveUsersManager": "  public ActiveUsersManager getActiveUsersManager();\n  \n  /**\n   * Adds all applications in the queue and its subqueues to the given collection.\n   * @param apps the collection to add the applications to\n   */\n  public void collectSchedulerApplications(Collection<ApplicationAttemptId> apps);\n\n  /**\n  * Detach a container from this queue\n  * @param clusterResource the current cluster resource\n  * @param application application to which the container was assigned\n  * @param container the container to detach\n  */\n  public void detachContainer(Resource clusterResource,\n               FiCaSchedulerApp application, RMContainer container);\n\n  /**\n   * Attach a container to this queue\n   * @param clusterResource the current cluster resource\n   * @param application application to which the container was assigned\n   * @param container the container to attach\n   */\n  public void attachContainer(Resource clusterResource,\n               FiCaSchedulerApp application, RMContainer container);\n\n  /**\n   * Check whether <em>disable_preemption</em> property is set for this queue\n   * @return true if <em>disable_preemption</em> is set, false if not\n   */\n  public boolean getPreemptionDisabled();\n  \n  /**\n   * Get QueueCapacities of this queue\n   * @return queueCapacities\n   */\n  public QueueCapacities getQueueCapacities();\n  \n  /**\n   * Get ResourceUsage of this queue\n   * @return resourceUsage\n   */\n  public ResourceUsage getQueueResourceUsage();\n\n  /**\n   * When partition of node updated, we will update queue's resource usage if it\n   * has container(s) running on that.\n   */\n  public void incUsedResource(String nodePartition, Resource resourceToInc,\n      SchedulerApplicationAttempt application);\n\n  /**\n   * When partition of node updated, we will update queue's resource usage if it\n   * has container(s) running on that.\n   */\n  public void decUsedResource(String nodePartition, Resource resourceToDec,\n      SchedulerApplicationAttempt application);\n\n  /**\n   * When an outstanding resource is fulfilled or canceled, calling this will\n   * decrease pending resource in a queue.\n   *\n   * @param nodeLabel\n   *          asked by application\n   * @param resourceToDec\n   *          new resource asked\n   */\n  public void decPendingResource(String nodeLabel, Resource resourceToDec);\n  \n  /**\n   * Decrease container resource in the queue\n   */\n  public void decreaseContainer(Resource clusterResource,\n      SchedContainerChangeRequest decreaseRequest,\n      FiCaSchedulerApp app);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppMoveEvent.getResult": "  public SettableFuture<Object> getResult() {\n    return result;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppNodeUpdateEvent.getNode": "  public RMNode getNode() {\n    return node;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppNodeUpdateEvent.getUpdateType": "  public RMAppNodeUpdateType getUpdateType() {\n    return updateType;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppRunningOnNodeEvent.getNodeId": "  public NodeId getNodeId() {\n    return node;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppRecoverEvent.getRMState": "  public RMState getRMState() {\n    return state;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppFailedAttemptEvent.getTransferStateFromPreviousAttempt": "  public boolean getTransferStateFromPreviousAttempt() {\n    return transferStateFromPreviousAttempt;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppMoveEvent.getTargetQueue": "  public String getTargetQueue() {\n    return targetQueue;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getAMRMTokenSecretManager": "  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMDelegationTokenSecretManager": "  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isWorkPreservingRecoveryEnabled": "  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "Resource manager fails with Null pointer exception",
            "Description": "Resource manager fails with NPE while trying to load or recover a finished application. \n{code}\n2015-11-11 17:53:22,351 ERROR resourcemanager.ResourceManager (ResourceManager.java:serviceStart(597)) - Failed to load/recover state\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:746)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1155)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:116)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1037)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1001)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:755)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts(RMAppImpl.java:839)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.access$1900(RMAppImpl.java:102)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:854)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:844)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:719)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:313)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:411)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1219)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:593)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1026)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1067)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1063)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n{code}"
        }
    },
    {
        "filename": "YARN-1692.json",
        "creation_time": "2014-02-07T02:01:17.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:926)\n        at java.util.HashMap$ValueIterator.next(HashMap.java:954)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.updateDemand(AppSchedulable.java:85)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.updateDemand(FSLeafQueue.java:125)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.updateDemand(FSParentQueue.java:82)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update(FairScheduler.java:217)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$UpdateThread.run(FairScheduler.java:195)\n        at java.lang.Thread.run(Thread.java:724)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.updateDemand": "  public void updateDemand() {\n    demand = Resources.createResource(0);\n    // Demand is current consumption plus outstanding requests\n    Resources.addTo(demand, app.getCurrentConsumption());\n\n    // Add up outstanding resource requests\n    for (Priority p : app.getPriorities()) {\n      for (ResourceRequest r : app.getResourceRequests(p).values()) {\n        Resource total = Resources.multiply(r.getCapability(), r.getNumContainers());\n        Resources.addTo(demand, total);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.updateDemand": "  public void updateDemand() {\n    // Compute demand by iterating through apps in the queue\n    // Limit demand to maxResources\n    Resource maxRes = scheduler.getAllocationConfiguration()\n        .getMaxResources(getName());\n    demand = Resources.createResource(0);\n    for (AppSchedulable sched : runnableAppScheds) {\n      if (Resources.equals(demand, maxRes)) {\n        break;\n      }\n      updateDemandForApp(sched, maxRes);\n    }\n    for (AppSchedulable sched : nonRunnableAppScheds) {\n      if (Resources.equals(demand, maxRes)) {\n        break;\n      }\n      updateDemandForApp(sched, maxRes);\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"The updated demand for \" + getName() + \" is \" + demand\n          + \"; the max is \" + maxRes);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.updateDemandForApp": "  private void updateDemandForApp(AppSchedulable sched, Resource maxRes) {\n    sched.updateDemand();\n    Resource toAdd = sched.getDemand();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Counting resource from \" + sched.getName() + \" \" + toAdd\n          + \"; Total resource consumption for \" + getName() + \" now \"\n          + demand);\n    }\n    demand = Resources.add(demand, toAdd);\n    demand = Resources.componentwiseMin(demand, maxRes);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.updateDemand": "  public void updateDemand() {\n    // Compute demand by iterating through apps in the queue\n    // Limit demand to maxResources\n    Resource maxRes = scheduler.getAllocationConfiguration()\n        .getMaxResources(getName());\n    demand = Resources.createResource(0);\n    for (FSQueue childQueue : childQueues) {\n      childQueue.updateDemand();\n      Resource toAdd = childQueue.getDemand();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Counting resource from \" + childQueue.getName() + \" \" + \n            toAdd + \"; Total resource consumption for \" + getName() +\n            \" now \" + demand);\n      }\n      demand = Resources.add(demand, toAdd);\n      demand = Resources.componentwiseMin(demand, maxRes);\n      if (Resources.equals(demand, maxRes)) {\n        break;\n      }\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"The updated demand for \" + getName() + \" is \" + demand +\n          \"; the max is \" + maxRes);\n    }    \n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.getDemand": "  public Resource getDemand() {\n    return demand;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update": "  protected synchronized void update() {\n    updatePreemptionVariables(); // Determine if any queues merit preemption\n\n    FSQueue rootQueue = queueMgr.getRootQueue();\n\n    // Recursively update demands for all queues\n    rootQueue.updateDemand();\n\n    rootQueue.setFairShare(clusterCapacity);\n    // Recursively compute fair shares for all queues\n    // and update metrics\n    rootQueue.recomputeShares();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updatePreemptionVariables": "  private void updatePreemptionVariables() {\n    long now = clock.getTime();\n    lastPreemptionUpdateTime = now;\n    for (FSLeafQueue sched : queueMgr.getLeafQueues()) {\n      if (!isStarvedForMinShare(sched)) {\n        sched.setLastTimeAtMinShare(now);\n      }\n      if (!isStarvedForFairShare(sched)) {\n        sched.setLastTimeAtHalfFairShare(now);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.run": "            public void run() {\n              continuousScheduling();\n            }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousScheduling": "  private void continuousScheduling() {\n    while (true) {\n      List<NodeId> nodeIdList = new ArrayList<NodeId>(nodes.keySet());\n      Collections.sort(nodeIdList, nodeAvailableResourceComparator);\n\n      // iterate all nodes\n      for (NodeId nodeId : nodeIdList) {\n        if (nodes.containsKey(nodeId)) {\n          FSSchedulerNode node = nodes.get(nodeId);\n          try {\n            if (Resources.fitsIn(minimumAllocation,\n                    node.getAvailableResource())) {\n              attemptScheduling(node);\n            }\n          } catch (Throwable ex) {\n            LOG.warn(\"Error while attempting scheduling for node \" + node +\n                    \": \" + ex.toString(), ex);\n          }\n        }\n      }\n      try {\n        Thread.sleep(getContinuousSchedulingSleepMs());\n      } catch (InterruptedException e) {\n        LOG.warn(\"Error while doing sleep in continuous scheduling: \" +\n                e.toString(), e);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.preemptTasksIfNecessary": "  protected synchronized void preemptTasksIfNecessary() {\n    if (!preemptionEnabled) {\n      return;\n    }\n\n    long curTime = clock.getTime();\n    if (curTime - lastPreemptCheckTime < preemptionInterval) {\n      return;\n    }\n    lastPreemptCheckTime = curTime;\n\n    Resource resToPreempt = Resources.none();\n\n    for (FSLeafQueue sched : queueMgr.getLeafQueues()) {\n      resToPreempt = Resources.add(resToPreempt, resToPreempt(sched, curTime));\n    }\n    if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity, resToPreempt,\n        Resources.none())) {\n      preemptResources(queueMgr.getLeafQueues(), resToPreempt);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue.recomputeShares": "  public abstract void recomputeShares();\n  \n  /**\n   * Gets the children of this queue, if any.\n   */\n  public abstract List<FSQueue> getChildQueues();\n  \n  /**\n   * Adds all applications in the queue and its subqueues to the given collection.\n   * @param apps the collection to add the applications to\n   */\n  public abstract void collectSchedulerApplications(\n      Collection<ApplicationAttemptId> apps);\n  \n  /**\n   * Return the number of apps for which containers can be allocated.\n   * Includes apps in subqueues.\n   */\n  public abstract int getNumRunnableApps();\n  \n  /**\n   * Helper method to check if the queue should attempt assigning resources\n   * \n   * @return true if check passes (can assign) or false otherwise\n   */\n  protected boolean assignContainerPreCheck(FSSchedulerNode node) {\n    if (!Resources.fitsIn(getResourceUsage(),\n        scheduler.getAllocationConfiguration().getMaxResources(getName()))\n        || node.getReservedContainer() != null) {\n      return false;\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueue.setFairShare": "  public void setFairShare(Resource fairShare) {\n    super.setFairShare(fairShare);\n    metrics.setFairShare(fairShare);\n  }"
        },
        "bug_report": {
            "Title": "ConcurrentModificationException in fair scheduler AppSchedulable",
            "Description": "We saw a ConcurrentModificationException thrown in the fair scheduler:\n\n{noformat}\n2014-02-07 01:40:01,978 ERROR org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler: Exception in fair scheduler UpdateThread\njava.util.ConcurrentModificationException\n        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:926)\n        at java.util.HashMap$ValueIterator.next(HashMap.java:954)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.updateDemand(AppSchedulable.java:85)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.updateDemand(FSLeafQueue.java:125)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.updateDemand(FSParentQueue.java:82)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update(FairScheduler.java:217)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$UpdateThread.run(FairScheduler.java:195)\n        at java.lang.Thread.run(Thread.java:724)\n{noformat}\n\nThe map that  gets returned by FSSchedulerApp.getResourceRequests() are iterated on without proper synchronization."
        }
    },
    {
        "filename": "YARN-7697.json",
        "creation_time": "2018-01-03T19:28:50.000+0000",
        "stack_trace": "```\njava.lang.OutOfMemoryError: Java heap space\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadIndexedLogsMeta(LogAggregationIndexedFileController.java:823)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadIndexedLogsMeta(LogAggregationIndexedFileController.java:840)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriterInRolling(LogAggregationIndexedFileController.java:293)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.access$600(LogAggregationIndexedFileController.java:98)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$1.run(LogAggregationIndexedFileController.java:216)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriter(LogAggregationIndexedFileController.java:197)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.uploadLogsForContainers(AppLogAggregatorImpl.java:205)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregation(AppLogAggregatorImpl.java:312)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.run(AppLogAggregatorImpl.java:284)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$1.run(LogAggregationService.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadIndexedLogsMeta": "  private IndexedLogsMeta loadIndexedLogsMeta(Path remoteLogPath)\n      throws IOException {\n    return loadIndexedLogsMeta(remoteLogPath, -1);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriterInRolling": "  private Path initializeWriterInRolling(final Path remoteLogFile,\n      final ApplicationId appId, final String nodeId) throws Exception {\n    Path aggregatedLogFile = null;\n    // check uuid\n    // if we can not find uuid, we would load the uuid\n    // from previous aggregated log files, and at the same\n    // time, we would delete any aggregated log files which\n    // has invalid uuid.\n    if (uuid == null) {\n      uuid = loadUUIDFromLogFile(fc, remoteLogFile.getParent(),\n            appId, nodeId);\n    }\n    Path currentRemoteLogFile = getCurrentRemoteLogFile(\n        fc, remoteLogFile.getParent(), nodeId);\n    // check checksum file\n    boolean overwriteCheckSum = true;\n    remoteLogCheckSumFile = new Path(remoteLogFile.getParent(),\n        (remoteLogFile.getName() + CHECK_SUM_FILE_SUFFIX));\n    if(fc.util().exists(remoteLogCheckSumFile)) {\n      // if the checksum file exists, we should reset cached\n      // indexedLogsMeta.\n      indexedLogsMeta.getLogMetas().clear();\n      if (currentRemoteLogFile != null) {\n        FSDataInputStream checksumFileInputStream = null;\n        try {\n          checksumFileInputStream = fc.open(remoteLogCheckSumFile);\n          int nameLength = checksumFileInputStream.readInt();\n          byte[] b = new byte[nameLength];\n          int actualLength = checksumFileInputStream.read(b);\n          if (actualLength == nameLength) {\n            String recoveredLogFile = new String(\n                b, Charset.forName(\"UTF-8\"));\n            if (recoveredLogFile.equals(\n                currentRemoteLogFile.getName())) {\n              overwriteCheckSum = false;\n              long endIndex = checksumFileInputStream.readLong();\n              IndexedLogsMeta recoveredLogsMeta = null;\n              try {\n                truncateFileWithRetries(fc, currentRemoteLogFile,\n                    endIndex);\n                recoveredLogsMeta = loadIndexedLogsMeta(\n                    currentRemoteLogFile);\n              } catch (Exception ex) {\n                recoveredLogsMeta = loadIndexedLogsMeta(\n                    currentRemoteLogFile, endIndex);\n              }\n              if (recoveredLogsMeta != null) {\n                indexedLogsMeta = recoveredLogsMeta;\n              }\n            }\n          }\n        } finally {\n          IOUtils.cleanupWithLogger(LOG, checksumFileInputStream);\n        }\n      }\n    }\n    // check whether we need roll over old logs\n    if (currentRemoteLogFile == null || isRollover(\n        fc, currentRemoteLogFile)) {\n      indexedLogsMeta.getLogMetas().clear();\n      overwriteCheckSum = true;\n      aggregatedLogFile = new Path(remoteLogFile.getParent(),\n          remoteLogFile.getName() + \"_\" + sysClock.getTime());\n      fsDataOStream = fc.create(aggregatedLogFile,\n          EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n          new Options.CreateOpts[] {});\n      // writes the uuid\n      fsDataOStream.write(uuid);\n      fsDataOStream.flush();\n    } else {\n      aggregatedLogFile = currentRemoteLogFile;\n      fsDataOStream = fc.create(currentRemoteLogFile,\n          EnumSet.of(CreateFlag.CREATE, CreateFlag.APPEND),\n          new Options.CreateOpts[] {});\n    }\n    // recreate checksum file if needed before aggregate the logs\n    if (overwriteCheckSum) {\n      final long currentAggregatedLogFileLength = fc\n          .getFileStatus(aggregatedLogFile).getLen();\n      FSDataOutputStream checksumFileOutputStream = null;\n      try {\n        checksumFileOutputStream = fc.create(remoteLogCheckSumFile,\n            EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n            new Options.CreateOpts[] {});\n        String fileName = aggregatedLogFile.getName();\n        checksumFileOutputStream.writeInt(fileName.length());\n        checksumFileOutputStream.write(fileName.getBytes(\n            Charset.forName(\"UTF-8\")));\n        checksumFileOutputStream.writeLong(\n            currentAggregatedLogFileLength);\n        checksumFileOutputStream.flush();\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, checksumFileOutputStream);\n      }\n    }\n    return aggregatedLogFile;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.isRollover": "  public boolean isRollover(final FileContext fc,\n      final Path candidate) throws IOException {\n    FileStatus fs = fc.getFileStatus(candidate);\n    return fs.getLen() >= this.logRollOverMaxFileSize;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.write": "  public void write(LogKey logKey, LogValue logValue) throws IOException {\n    String containerId = logKey.toString();\n    Set<File> pendingUploadFiles = logValue\n        .getPendingLogFilesToUploadForThisContainer();\n    List<IndexedFileLogMeta> metas = new ArrayList<>();\n    for (File logFile : pendingUploadFiles) {\n      FileInputStream in = null;\n      try {\n        in = SecureIOUtils.openForRead(logFile, logValue.getUser(), null);\n      } catch (IOException e) {\n        logErrorMessage(logFile, e);\n        IOUtils.cleanupWithLogger(LOG, in);\n        continue;\n      }\n      final long fileLength = logFile.length();\n      IndexedFileOutputStreamState outputStreamState = null;\n      try {\n        outputStreamState = new IndexedFileOutputStreamState(\n            this.compressAlgo, this.fsDataOStream, conf, this.currentOffSet);\n        byte[] buf = new byte[65535];\n        int len = 0;\n        long bytesLeft = fileLength;\n        while ((len = in.read(buf)) != -1) {\n          //If buffer contents within fileLength, write\n          if (len < bytesLeft) {\n            outputStreamState.getOutputStream().write(buf, 0, len);\n            bytesLeft-=len;\n          } else {\n            //else only write contents within fileLength, then exit early\n            outputStreamState.getOutputStream().write(buf, 0,\n                (int)bytesLeft);\n            break;\n          }\n        }\n        long newLength = logFile.length();\n        if(fileLength < newLength) {\n          LOG.warn(\"Aggregated logs truncated by approximately \"+\n              (newLength-fileLength) +\" bytes.\");\n        }\n        logAggregationSuccessfullyInThisCyCle = true;\n      } catch (IOException e) {\n        String message = logErrorMessage(logFile, e);\n        if (outputStreamState != null &&\n            outputStreamState.getOutputStream() != null) {\n          outputStreamState.getOutputStream().write(\n              message.getBytes(Charset.forName(\"UTF-8\")));\n        }\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, in);\n      }\n\n      IndexedFileLogMeta meta = new IndexedFileLogMeta();\n      meta.setContainerId(containerId.toString());\n      meta.setFileName(logFile.getName());\n      if (outputStreamState != null) {\n        outputStreamState.finish();\n        meta.setFileCompressedSize(outputStreamState.getCompressedSize());\n        meta.setStartIndex(outputStreamState.getStartPos());\n        meta.setFileSize(fileLength);\n      }\n      meta.setLastModificatedTime(logFile.lastModified());\n      metas.add(meta);\n    }\n    logsMetaInThisCycle.addContainerLogMeta(containerId, metas);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadUUIDFromLogFile": "  private byte[] loadUUIDFromLogFile(final FileContext fc,\n      final Path parent, final ApplicationId appId, final String nodeId)\n      throws Exception {\n    byte[] id = null;\n    RemoteIterator<FileStatus> files = fc.listStatus(parent);\n    FSDataInputStream fsDataInputStream = null;\n    byte[] uuid = createUUID(appId);\n    while(files.hasNext()) {\n      try {\n        Path checkPath = files.next().getPath();\n        if (checkPath.getName().contains(LogAggregationUtils\n            .getNodeString(nodeId)) && !checkPath.getName()\n                .endsWith(CHECK_SUM_FILE_SUFFIX)) {\n          fsDataInputStream = fc.open(checkPath);\n          byte[] b = new byte[uuid.length];\n          int actual = fsDataInputStream.read(b);\n          if (actual != uuid.length || Arrays.equals(b, uuid)) {\n            deleteFileWithRetries(fc, checkPath);\n          } else if (id == null){\n            id = uuid;\n          }\n        }\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, fsDataInputStream);\n      }\n    }\n    return id == null ? uuid : id;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.getCurrentRemoteLogFile": "  private Path getCurrentRemoteLogFile(final FileContext fc,\n      final Path parent, final String nodeId) throws IOException {\n    RemoteIterator<FileStatus> files = fc.listStatus(parent);\n    long maxTime = 0L;\n    Path returnPath = null;\n    while(files.hasNext()) {\n      FileStatus candidate = files.next();\n      String fileName = candidate.getPath().getName();\n      if (fileName.contains(LogAggregationUtils.getNodeString(nodeId))\n          && !fileName.endsWith(LogAggregationUtils.TMP_FILE_SUFFIX) &&\n          !fileName.endsWith(CHECK_SUM_FILE_SUFFIX)) {\n        if (candidate.getModificationTime() > maxTime) {\n          maxTime = candidate.getModificationTime();\n          returnPath = candidate.getPath();\n        }\n      }\n    }\n    return returnPath;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.getLogMetas": "    public Map<String, List<IndexedFileLogMeta>> getLogMetas() {\n      return logMetas;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.truncateFileWithRetries": "  private void truncateFileWithRetries(final FileContext fileContext,\n      final Path truncatePath, final long newLength) throws Exception {\n    new FSAction<Void>() {\n      @Override\n      public Void run() throws Exception {\n        fileContext.truncate(truncatePath, newLength);\n        return null;\n      }\n    }.runWithRetries();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.run": "    abstract T run() throws Exception;\n\n    T runWithRetries() throws Exception {\n      int retry = 0;\n      while (true) {\n        try {\n          return run();\n        } catch (IOException e) {\n          LOG.info(\"Exception while executing an FS operation.\", e);\n          if (++retry > fsNumRetries) {\n            LOG.info(\"Maxed out FS retries. Giving up!\");\n            throw e;\n          }\n          LOG.info(\"Retrying operation on FS. Retry no. \" + retry);\n          Thread.sleep(fsRetryInterval);\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.setNodeId": "    public void setNodeId(String nodeId) {\n      this.nodeId = nodeId;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.setAcls": "    public void setAcls(Map<ApplicationAccessType, String> acls) {\n      this.acls = acls;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.setVersion": "    public void setVersion(int version) {\n      this.version = version;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.createUUID": "  private byte[] createUUID(ApplicationId appId) throws IOException {\n    try {\n      MessageDigest digest = MessageDigest.getInstance(\"SHA-256\");\n      return digest.digest(appId.toString().getBytes(\n          Charset.forName(\"UTF-8\")));\n    } catch (NoSuchAlgorithmException ex) {\n      throw new IOException(ex);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.deleteFileWithPrivilege": "  private Object deleteFileWithPrivilege(final FileContext fileContext,\n      final UserGroupInformation userUgi, final Path fileToDelete)\n      throws Exception {\n    return userUgi.doAs(new PrivilegedExceptionAction<Object>() {\n      @Override\n      public Object run() throws Exception {\n        if (fileContext.util().exists(fileToDelete)) {\n          fileContext.delete(fileToDelete, false);\n        }\n        return null;\n      }\n    });\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.setUser": "    public void setUser(String user) {\n      this.user = user;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.setCompressName": "    public void setCompressName(String compressName) {\n      this.compressName = compressName;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.doAs": "  public <T> T doAs(PrivilegedExceptionAction<T> action\n                    ) throws IOException, InterruptedException {\n    try {\n      logPrivilegedAction(subject, action);\n      return Subject.doAs(subject, action);\n    } catch (PrivilegedActionException pae) {\n      Throwable cause = pae.getCause();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"PrivilegedActionException as:\" + this + \" cause:\" + cause);\n      }\n      if (cause == null) {\n        throw new RuntimeException(\"PrivilegedActionException with no \" +\n                \"underlying cause. UGI [\" + this + \"]\" +\": \" + pae, pae);\n      } else if (cause instanceof IOException) {\n        throw (IOException) cause;\n      } else if (cause instanceof Error) {\n        throw (Error) cause;\n      } else if (cause instanceof RuntimeException) {\n        throw (RuntimeException) cause;\n      } else if (cause instanceof InterruptedException) {\n        throw (InterruptedException) cause;\n      } else {\n        throw new UndeclaredThrowableException(cause);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.security.UserGroupInformation.logPrivilegedAction": "  private void logPrivilegedAction(Subject subject, Object action) {\n    if (LOG.isDebugEnabled()) {\n      // would be nice if action included a descriptive toString()\n      String where = new Throwable().getStackTrace()[2].toString();\n      LOG.debug(\"PrivilegedAction as:\"+this+\" from:\"+where);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriter": "  public void initializeWriter(\n      final LogAggregationFileControllerContext context)\n      throws IOException {\n    final UserGroupInformation userUgi = context.getUserUgi();\n    final Map<ApplicationAccessType, String> appAcls = context.getAppAcls();\n    final String nodeId = context.getNodeId().toString();\n    final ApplicationId appId = context.getAppId();\n    final Path remoteLogFile = context.getRemoteNodeLogFileForApp();\n    this.ugi = userUgi;\n    logAggregationSuccessfullyInThisCyCle = false;\n    logsMetaInThisCycle = new IndexedPerAggregationLogMeta();\n    logAggregationTimeInThisCycle = this.sysClock.getTime();\n    logsMetaInThisCycle.setUploadTimeStamp(logAggregationTimeInThisCycle);\n    logsMetaInThisCycle.setRemoteNodeFile(remoteLogFile.getName());\n    try {\n      userUgi.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          fc = FileContext.getFileContext(\n              remoteRootLogDir.toUri(), conf);\n          fc.setUMask(APP_LOG_FILE_UMASK);\n          if (indexedLogsMeta == null) {\n            indexedLogsMeta = new IndexedLogsMeta();\n            indexedLogsMeta.setVersion(VERSION);\n            indexedLogsMeta.setUser(userUgi.getShortUserName());\n            indexedLogsMeta.setAcls(appAcls);\n            indexedLogsMeta.setNodeId(nodeId);\n            String compressName = conf.get(\n                YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE,\n                YarnConfiguration.DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE);\n            indexedLogsMeta.setCompressName(compressName);\n          }\n          Path aggregatedLogFile = null;\n          if (context.isLogAggregationInRolling()) {\n            aggregatedLogFile = initializeWriterInRolling(\n                remoteLogFile, appId, nodeId);\n          } else {\n            aggregatedLogFile = remoteLogFile;\n            fsDataOStream = fc.create(remoteLogFile,\n                EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE),\n                new Options.CreateOpts[] {});\n            if (uuid == null) {\n              uuid = createUUID(appId);\n            }\n            fsDataOStream.write(uuid);\n            fsDataOStream.flush();\n          }\n\n          long aggregatedLogFileLength = fc.getFileStatus(\n              aggregatedLogFile).getLen();\n          // append a simple character(\"\\n\") to move the writer cursor, so\n          // we could get the correct position when we call\n          // fsOutputStream.getStartPos()\n          final byte[] dummyBytes = \"\\n\".getBytes(Charset.forName(\"UTF-8\"));\n          fsDataOStream.write(dummyBytes);\n          fsDataOStream.flush();\n\n          if (fsDataOStream.getPos() >= (aggregatedLogFileLength\n              + dummyBytes.length)) {\n            currentOffSet = 0;\n          } else {\n            currentOffSet = aggregatedLogFileLength;\n          }\n          return null;\n        }\n      });\n    } catch (Exception e) {\n      throw new IOException(e);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.setRemoteNodeFile": "    public void setRemoteNodeFile(String remoteNodeLogFileName) {\n      this.remoteNodeLogFileName = remoteNodeLogFileName;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.getNodeId": "    public String getNodeId() {\n      return nodeId;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.setUploadTimeStamp": "    public void setUploadTimeStamp(long uploadTimeStamp) {\n      this.uploadTimeStamp = uploadTimeStamp;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.uploadLogsForContainers": "  private void uploadLogsForContainers(boolean appFinished) {\n    if (this.logAggregationDisabled) {\n      return;\n    }\n\n    addCredentials();\n\n    // Create a set of Containers whose logs will be uploaded in this cycle.\n    // It includes:\n    // a) all containers in pendingContainers: those containers are finished\n    //    and satisfy the ContainerLogAggregationPolicy.\n    // b) some set of running containers: For all the Running containers,\n    //    we use exitCode of 0 to find those which satisfy the\n    //    ContainerLogAggregationPolicy.\n    Set<ContainerId> pendingContainerInThisCycle = new HashSet<ContainerId>();\n    this.pendingContainers.drainTo(pendingContainerInThisCycle);\n    Set<ContainerId> finishedContainers =\n        new HashSet<ContainerId>(pendingContainerInThisCycle);\n    if (this.context.getApplications().get(this.appId) != null) {\n      for (Container container : this.context.getApplications()\n        .get(this.appId).getContainers().values()) {\n        ContainerType containerType =\n            container.getContainerTokenIdentifier().getContainerType();\n        if (shouldUploadLogs(new ContainerLogContext(\n            container.getContainerId(), containerType, 0))) {\n          pendingContainerInThisCycle.add(container.getContainerId());\n        }\n      }\n    }\n\n    if (pendingContainerInThisCycle.isEmpty()) {\n      sendLogAggregationReport(true, \"\", appFinished);\n      return;\n    }\n\n    logAggregationTimes++;\n    String diagnosticMessage = \"\";\n    boolean logAggregationSucceedInThisCycle = true;\n    try {\n      try {\n        logAggregationFileController.initializeWriter(logControllerContext);\n      } catch (IOException e1) {\n        logAggregationSucceedInThisCycle = false;\n        LOG.error(\"Cannot create writer for app \" + this.applicationId\n            + \". Skip log upload this time. \", e1);\n        return;\n      }\n\n      boolean uploadedLogsInThisCycle = false;\n      for (ContainerId container : pendingContainerInThisCycle) {\n        ContainerLogAggregator aggregator = null;\n        if (containerLogAggregators.containsKey(container)) {\n          aggregator = containerLogAggregators.get(container);\n        } else {\n          aggregator = new ContainerLogAggregator(container);\n          containerLogAggregators.put(container, aggregator);\n        }\n        Set<Path> uploadedFilePathsInThisCycle =\n            aggregator.doContainerLogAggregation(logAggregationFileController,\n            appFinished, finishedContainers.contains(container));\n        if (uploadedFilePathsInThisCycle.size() > 0) {\n          uploadedLogsInThisCycle = true;\n          List<Path> uploadedFilePathsInThisCycleList = new ArrayList<>();\n          uploadedFilePathsInThisCycleList.addAll(uploadedFilePathsInThisCycle);\n          DeletionTask deletionTask = new FileDeletionTask(delService,\n              this.userUgi.getShortUserName(), null,\n              uploadedFilePathsInThisCycleList);\n          delService.delete(deletionTask);\n        }\n\n        // This container is finished, and all its logs have been uploaded,\n        // remove it from containerLogAggregators.\n        if (finishedContainers.contains(container)) {\n          containerLogAggregators.remove(container);\n        }\n      }\n\n      logControllerContext.setUploadedLogsInThisCycle(uploadedLogsInThisCycle);\n      logControllerContext.setLogUploadTimeStamp(System.currentTimeMillis());\n      logControllerContext.increLogAggregationTimes();\n      try {\n        this.logAggregationFileController.postWrite(logControllerContext);\n        diagnosticMessage = \"Log uploaded successfully for Application: \"\n            + appId + \" in NodeManager: \"\n            + LogAggregationUtils.getNodeString(nodeId) + \" at \"\n            + Times.format(logControllerContext.getLogUploadTimeStamp())\n            + \"\\n\";\n      } catch (Exception e) {\n        diagnosticMessage = e.getMessage();\n        renameTemporaryLogFileFailed = true;\n        logAggregationSucceedInThisCycle = false;\n      }\n    } finally {\n      sendLogAggregationReport(logAggregationSucceedInThisCycle,\n          diagnosticMessage, appFinished);\n      logAggregationFileController.closeWriter();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.shouldUploadLogs": "  private boolean shouldUploadLogs(ContainerLogContext logContext) {\n    return logAggPolicy.shouldDoLogAggregation(logContext);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doContainerLogAggregation": "    public Set<Path> doContainerLogAggregation(\n        LogAggregationFileController logAggregationFileController,\n        boolean appFinished, boolean containerFinished) {\n      LOG.info(\"Uploading logs for container \" + containerId\n          + \". Current good log dirs are \"\n          + StringUtils.join(\",\", dirsHandler.getLogDirsForRead()));\n      final LogKey logKey = new LogKey(containerId);\n      final LogValue logValue =\n          new LogValue(dirsHandler.getLogDirsForRead(), containerId,\n            userUgi.getShortUserName(), logAggregationContext,\n            this.uploadedFileMeta,  retentionContext, appFinished,\n            containerFinished);\n      try {\n        logAggregationFileController.write(logKey, logValue);\n      } catch (Exception e) {\n        LOG.error(\"Couldn't upload logs for \" + containerId\n            + \". Skipping this container.\", e);\n        return new HashSet<Path>();\n      }\n      this.uploadedFileMeta.addAll(logValue\n        .getCurrentUpLoadedFileMeta());\n      // if any of the previous uploaded logs have been deleted,\n      // we need to remove them from alreadyUploadedLogs\n      Iterable<String> mask =\n          Iterables.filter(uploadedFileMeta, new Predicate<String>() {\n            @Override\n            public boolean apply(String next) {\n              return logValue.getAllExistingFilesMeta().contains(next);\n            }\n          });\n\n      this.uploadedFileMeta = Sets.newHashSet(mask);\n\n      // need to return files uploaded or older-than-retention clean up.\n      return Sets.union(logValue.getCurrentUpLoadedFilesPath(),\n          logValue.getObseleteRetentionLogFiles());\n\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.addCredentials": "  private void addCredentials() {\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials systemCredentials =\n          context.getSystemCredentialsForApps().get(appId);\n      if (systemCredentials != null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Adding new framework-token for \" + appId\n              + \" for log-aggregation: \" + systemCredentials.getAllTokens()\n              + \"; userUgi=\" + userUgi);\n        }\n        // this will replace old token\n        userUgi.addCredentials(systemCredentials);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.sendLogAggregationReport": "  private void sendLogAggregationReport(\n      boolean logAggregationSucceedInThisCycle, String diagnosticMessage,\n      boolean appFinished) {\n    LogAggregationStatus logAggregationStatus =\n        logAggregationSucceedInThisCycle\n            ? LogAggregationStatus.RUNNING\n            : LogAggregationStatus.RUNNING_WITH_FAILURE;\n    sendLogAggregationReportInternal(logAggregationStatus, diagnosticMessage);\n    if (appFinished) {\n      // If the app is finished, one extra final report with log aggregation\n      // status SUCCEEDED/FAILED will be sent to RM to inform the RM\n      // that the log aggregation in this NM is completed.\n      LogAggregationStatus finalLogAggregationStatus =\n          renameTemporaryLogFileFailed || !logAggregationSucceedInThisCycle\n              ? LogAggregationStatus.FAILED\n              : LogAggregationStatus.SUCCEEDED;\n      sendLogAggregationReportInternal(finalLogAggregationStatus, \"\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregation": "  private void doAppLogAggregation() {\n    while (!this.appFinishing.get() && !this.aborted.get()) {\n      synchronized(this) {\n        try {\n          waiting.set(true);\n          if (logControllerContext.isLogAggregationInRolling()) {\n            wait(logControllerContext.getRollingMonitorInterval() * 1000);\n            if (this.appFinishing.get() || this.aborted.get()) {\n              break;\n            }\n            uploadLogsForContainers(false);\n          } else {\n            wait(THREAD_SLEEP_TIME);\n          }\n        } catch (InterruptedException e) {\n          LOG.warn(\"PendingContainers queue is interrupted\");\n          this.appFinishing.set(true);\n        }\n      }\n    }\n\n    if (this.aborted.get()) {\n      return;\n    }\n\n    // App is finished, upload the container logs.\n    uploadLogsForContainers(true);\n\n    doAppLogAggregationPostCleanUp();\n\n    this.dispatcher.getEventHandler().handle(\n        new ApplicationEvent(this.appId,\n            ApplicationEventType.APPLICATION_LOG_HANDLING_FINISHED));\n    this.appAggregationFinished.set(true);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregationPostCleanUp": "  private void doAppLogAggregationPostCleanUp() {\n    // Remove the local app-log-dirs\n    List<Path> localAppLogDirs = new ArrayList<Path>();\n    for (String rootLogDir : dirsHandler.getLogDirsForCleanup()) {\n      Path logPath = new Path(rootLogDir, applicationId);\n      try {\n        // check if log dir exists\n        lfs.getFileStatus(logPath);\n        localAppLogDirs.add(logPath);\n      } catch (UnsupportedFileSystemException ue) {\n        LOG.warn(\"Log dir \" + rootLogDir + \"is an unsupported file system\", ue);\n        continue;\n      } catch (IOException fe) {\n        continue;\n      }\n    }\n\n    if (localAppLogDirs.size() > 0) {\n      List<Path> localAppLogDirsList = new ArrayList<>();\n      localAppLogDirsList.addAll(localAppLogDirs);\n      DeletionTask deletionTask = new FileDeletionTask(delService,\n          this.userUgi.getShortUserName(), null, localAppLogDirsList);\n      this.delService.delete(deletionTask);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.run": "  public void run() {\n    try {\n      doAppLogAggregation();\n    } catch (Exception e) {\n      // do post clean up of log directories on any exception\n      LOG.error(\"Error occurred while aggregating the log for the application \"\n          + appId, e);\n      doAppLogAggregationPostCleanUp();\n    } finally {\n      if (!this.appAggregationFinished.get() && !this.aborted.get()) {\n        LOG.warn(\"Log aggregation did not complete for application \" + appId);\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationEvent(this.appId,\n                ApplicationEventType.APPLICATION_LOG_HANDLING_FAILED));\n      }\n      this.appAggregationFinished.set(true);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.run": "      public void run() {\n        try {\n          appLogAggregator.run();\n        } finally {\n          appLogAggregators.remove(appId);\n          closeFileSystems(userUgi);\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.closeFileSystems": "  protected void closeFileSystems(final UserGroupInformation userUgi) {\n    try {\n      FileSystem.closeAllForUGI(userUgi);\n    } catch (IOException e) {\n      LOG.warn(\"Failed to close filesystems: \", e);\n    }\n  }"
        },
        "bug_report": {
            "Title": "NM goes down with OOM due to leak in log-aggregation",
            "Description": "2017-12-29 01:43:50,601 FATAL yarn.YarnUncaughtExceptionHandler (YarnUncaughtExceptionHandler.java:uncaughtException(51)) - Thread Thread[LogAggregationService #0,5,main] threw an Error.  Shutting down now...\r\njava.lang.OutOfMemoryError: Java heap space\r\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadIndexedLogsMeta(LogAggregationIndexedFileController.java:823)\r\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadIndexedLogsMeta(LogAggregationIndexedFileController.java:840)\r\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriterInRolling(LogAggregationIndexedFileController.java:293)\r\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.access$600(LogAggregationIndexedFileController.java:98)\r\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$1.run(LogAggregationIndexedFileController.java:216)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at javax.security.auth.Subject.doAs(Subject.java:422)\r\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)\r\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriter(LogAggregationIndexedFileController.java:197)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.uploadLogsForContainers(AppLogAggregatorImpl.java:205)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregation(AppLogAggregatorImpl.java:312)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.run(AppLogAggregatorImpl.java:284)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$1.run(LogAggregationService.java:262)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n2017-12-29 01:43:50,601 INFO  application.ApplicationImpl (ApplicationImpl.java:handle(464)) - Application ap"
        }
    },
    {
        "filename": "YARN-7382.json",
        "creation_time": "2017-10-23T23:36:59.000+0000",
        "stack_trace": "```\njava.util.NoSuchElementException\n        at java.util.concurrent.ConcurrentSkipListMap.firstKey(ConcurrentSkipListMap.java:2036)\n        at java.util.concurrent.ConcurrentSkipListSet.first(ConcurrentSkipListSet.java:396)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.getNextPendingAsk(AppSchedulingInfo.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.isOverAMShareLimit(FSAppAttempt.java:901)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:1326)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:221)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:221)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1019)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:887)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1104)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:128)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:748)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.getNextPendingAsk": "  public PendingAsk getNextPendingAsk() {\n    try {\n      readLock.lock();\n      SchedulerRequestKey firstRequestKey = schedulerKeys.first();\n      return getPendingAsk(firstRequestKey, ResourceRequest.ANY);\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.getPendingAsk": "  public PendingAsk getPendingAsk(SchedulerRequestKey schedulerKey,\n      String resourceName) {\n    try {\n      this.readLock.lock();\n      SchedulingPlacementSet ps = schedulerKeyToPlacementSets.get(schedulerKey);\n      return (ps == null) ? PendingAsk.ZERO : ps.getPendingAsk(resourceName);\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.isOverAMShareLimit": "  private boolean isOverAMShareLimit() {\n    // Check the AM resource usage for the leaf queue\n    if (!isAmRunning() && !getUnmanagedAM()) {\n      // Return true if we have not ask, or queue is not be able to run app's AM\n      PendingAsk ask = appSchedulingInfo.getNextPendingAsk();\n      if (ask.getCount() == 0 || !getQueue().canRunAppAM(\n          ask.getPerAllocationResource())) {\n        return true;\n      }\n    }\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getQueue": "  public FSLeafQueue getQueue() {\n    return (FSLeafQueue) queue;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    if (isOverAMShareLimit()) {\n      PendingAsk amAsk = appSchedulingInfo.getNextPendingAsk();\n      updateAMDiagnosticMsg(amAsk.getPerAllocationResource(),\n          \" exceeds maximum AM resource allowed).\");\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"AM resource request: \" + amAsk.getPerAllocationResource()\n            + \" exceeds maximum AM resource allowed, \"\n            + getQueue().dumpState());\n      }\n      return Resources.none();\n    }\n    return assignContainer(node, false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.equals": "  public boolean equals(Object o) {\n    return super.equals(o);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getAllowedLocalityLevelByTime": "  NodeType getAllowedLocalityLevelByTime(\n      SchedulerRequestKey schedulerKey, long nodeLocalityDelayMs,\n      long rackLocalityDelayMs, long currentTimeMs) {\n    // if not being used, can schedule anywhere\n    if (nodeLocalityDelayMs < 0 || rackLocalityDelayMs < 0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    try {\n      writeLock.lock();\n\n      // default level is NODE_LOCAL\n      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n        // add the initial time of priority to prevent comparing with FsApp\n        // startTime and allowedLocalityLevel degrade\n        lastScheduledContainer.put(schedulerKey, currentTimeMs);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\n              \"Init the lastScheduledContainer time, priority: \" + schedulerKey\n                  .getPriority() + \", time: \" + currentTimeMs);\n        }\n        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n        return NodeType.NODE_LOCAL;\n      }\n\n      NodeType allowed = allowedLocalityLevel.get(schedulerKey);\n\n      // if level is already most liberal, we're done\n      if (allowed.equals(NodeType.OFF_SWITCH)) {\n        return NodeType.OFF_SWITCH;\n      }\n\n      // check waiting time\n      long waitTime = currentTimeMs;\n      if (lastScheduledContainer.containsKey(schedulerKey)) {\n        waitTime -= lastScheduledContainer.get(schedulerKey);\n      } else{\n        waitTime -= getStartTime();\n      }\n\n      long thresholdTime = allowed.equals(NodeType.NODE_LOCAL) ?\n          nodeLocalityDelayMs :\n          rackLocalityDelayMs;\n\n      if (waitTime > thresholdTime) {\n        if (allowed.equals(NodeType.NODE_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"Waiting time: \" + waitTime\n                + \" ms, nodeLocalityDelay time: \" + nodeLocalityDelayMs + \" ms\"\n                + \", change allowedLocality from NODE_LOCAL to RACK_LOCAL\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n          resetSchedulingOpportunities(schedulerKey, currentTimeMs);\n        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"Waiting time: \" + waitTime\n                + \" ms, nodeLocalityDelay time: \" + nodeLocalityDelayMs + \" ms\"\n                + \", change allowedLocality from RACK_LOCAL to OFF_SWITCH\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n          resetSchedulingOpportunities(schedulerKey, currentTimeMs);\n        }\n      }\n      return allowedLocalityLevel.get(schedulerKey);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.hasContainerForNode": "  private boolean hasContainerForNode(SchedulerRequestKey key,\n      FSSchedulerNode node) {\n    PendingAsk offswitchAsk = getPendingAsk(key, ResourceRequest.ANY);\n    Resource resource = offswitchAsk.getPerAllocationResource();\n    boolean hasRequestForOffswitch =\n        offswitchAsk.getCount() > 0;\n    boolean hasRequestForRack = getOutstandingAsksCount(key,\n        node.getRackName()) > 0;\n    boolean hasRequestForNode = getOutstandingAsksCount(key,\n        node.getNodeName()) > 0;\n\n    boolean ret = true;\n    if (!(// There must be outstanding requests at the given priority:\n        hasRequestForOffswitch &&\n            // If locality relaxation is turned off at *-level, there must be a\n            // non-zero request for the node's rack:\n            (appSchedulingInfo.canDelayTo(key, ResourceRequest.ANY) ||\n                (hasRequestForRack)) &&\n            // If locality relaxation is turned off at rack-level,\n            // there must be a non-zero request at the node:\n            (!hasRequestForRack || appSchedulingInfo.canDelayTo(key,\n                node.getRackName()) || (hasRequestForNode)) &&\n            // The requested container must be able to fit on the node:\n            Resources.lessThanOrEqual(RESOURCE_CALCULATOR, null,\n                resource,\n                node.getRMNode().getTotalCapability()))) {\n      ret = false;\n    } else if (!getQueue().fitsInMaxShare(resource)) {\n      // The requested container must fit in queue maximum share\n      updateAMDiagnosticMsg(resource,\n          \" exceeds current queue or its parents maximum resource allowed).\");\n\n      ret = false;\n    }\n\n    return ret;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.reserve": "  private boolean reserve(Resource perAllocationResource, FSSchedulerNode node,\n      Container reservedContainer, NodeType type,\n      SchedulerRequestKey schedulerKey) {\n\n    RMContainer nodeReservedContainer = node.getReservedContainer();\n    boolean reservableForThisApp = nodeReservedContainer == null ||\n        nodeReservedContainer.getApplicationAttemptId()\n            .equals(getApplicationAttemptId());\n    if (reservableForThisApp &&!reservationExceedsThreshold(node, type)) {\n      LOG.info(\"Making reservation: node=\" + node.getNodeName() +\n              \" app_id=\" + getApplicationId());\n      if (reservedContainer == null) {\n        reservedContainer =\n            createContainer(node, perAllocationResource,\n              schedulerKey);\n        getMetrics().reserveResource(node.getPartition(), getUser(),\n            reservedContainer.getResource());\n        RMContainer rmContainer =\n                super.reserve(node, schedulerKey, null, reservedContainer);\n        node.reserveResource(this, schedulerKey, rmContainer);\n        setReservation(node);\n      } else {\n        RMContainer rmContainer = node.getReservedContainer();\n        super.reserve(node, schedulerKey, rmContainer, reservedContainer);\n        node.reserveResource(this, schedulerKey, rmContainer);\n        setReservation(node);\n      }\n      return true;\n    }\n    return false;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getName": "  public String getName() {\n    return getApplicationId().toString();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.updateAMDiagnosticMsg": "  private void updateAMDiagnosticMsg(Resource resource, String reason) {\n    if (!isWaitingForAMContainer()) {\n      return;\n    }\n\n    StringBuilder diagnosticMessageBldr = new StringBuilder();\n    diagnosticMessageBldr.append(\" (Resource request: \");\n    diagnosticMessageBldr.append(resource);\n    diagnosticMessageBldr.append(reason);\n    updateAMContainerDiagnostics(AMState.INACTIVATED,\n        diagnosticMessageBldr.toString());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserve": "  public void unreserve(SchedulerRequestKey schedulerKey,\n      FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    unreserveInternal(schedulerKey, node);\n    node.unreserveResource(this);\n    clearReservation(node);\n    getMetrics().unreserveResource(node.getPartition(),\n        getUser(), rmContainer.getContainer().getResource());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate": "  public RMContainer allocate(NodeType type, FSSchedulerNode node,\n      SchedulerRequestKey schedulerKey, PendingAsk pendingAsk,\n      Container reservedContainer) {\n    RMContainer rmContainer;\n    Container container;\n\n    try {\n      writeLock.lock();\n      // Update allowed locality level\n      NodeType allowed = allowedLocalityLevel.get(schedulerKey);\n      if (allowed != null) {\n        if (allowed.equals(NodeType.OFF_SWITCH) && (type.equals(\n            NodeType.NODE_LOCAL) || type.equals(NodeType.RACK_LOCAL))) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        } else if (allowed.equals(NodeType.RACK_LOCAL) && type.equals(\n            NodeType.NODE_LOCAL)) {\n          this.resetAllowedLocalityLevel(schedulerKey, type);\n        }\n      }\n\n      // Required sanity check - AM can call 'allocate' to update resource\n      // request without locking the scheduler, hence we need to check\n      if (getOutstandingAsksCount(schedulerKey) <= 0) {\n        return null;\n      }\n\n      container = reservedContainer;\n      if (container == null) {\n        container = createContainer(node, pendingAsk.getPerAllocationResource(),\n            schedulerKey);\n      }\n\n      // Create RMContainer\n      rmContainer = new RMContainerImpl(container, schedulerKey,\n          getApplicationAttemptId(), node.getNodeID(),\n          appSchedulingInfo.getUser(), rmContext);\n      ((RMContainerImpl) rmContainer).setQueueName(this.getQueueName());\n\n      // Add it to allContainers list.\n      addToNewlyAllocatedContainers(node, rmContainer);\n      liveContainers.put(container.getId(), rmContainer);\n\n      // Update consumption and track allocations\n      List<ResourceRequest> resourceRequestList = appSchedulingInfo.allocate(\n          type, node, schedulerKey, container);\n      this.attemptResourceUsage.incUsed(container.getResource());\n      getQueue().incUsedResource(container.getResource());\n\n      // Update resource requests related to \"request\" and store in RMContainer\n      ((RMContainerImpl) rmContainer).setResourceRequests(resourceRequestList);\n\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerEvent(container.getId(), RMContainerEventType.START));\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"allocate: applicationAttemptId=\" + container.getId()\n            .getApplicationAttemptId() + \" container=\" + container.getId()\n            + \" host=\" + container.getNodeId().getHost() + \" type=\" + type);\n      }\n      RMAuditLogger.logSuccess(getUser(), AuditConstants.ALLOC_CONTAINER,\n          \"SchedulerApp\", getApplicationId(), container.getId(),\n          container.getResource());\n    } finally {\n      writeLock.unlock();\n    }\n\n    return rmContainer;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getAllowedLocalityLevel": "  NodeType getAllowedLocalityLevel(\n      SchedulerRequestKey schedulerKey, int numNodes,\n      double nodeLocalityThreshold, double rackLocalityThreshold) {\n    // upper limit on threshold\n    if (nodeLocalityThreshold > 1.0) {\n      nodeLocalityThreshold = 1.0;\n    }\n    if (rackLocalityThreshold > 1.0) {\n      rackLocalityThreshold = 1.0;\n    }\n\n    // If delay scheduling is not being used, can schedule anywhere\n    if (nodeLocalityThreshold < 0.0 || rackLocalityThreshold < 0.0) {\n      return NodeType.OFF_SWITCH;\n    }\n\n    try {\n      writeLock.lock();\n\n      // Default level is NODE_LOCAL\n      if (!allowedLocalityLevel.containsKey(schedulerKey)) {\n        allowedLocalityLevel.put(schedulerKey, NodeType.NODE_LOCAL);\n        return NodeType.NODE_LOCAL;\n      }\n\n      NodeType allowed = allowedLocalityLevel.get(schedulerKey);\n\n      // If level is already most liberal, we're done\n      if (allowed.equals(NodeType.OFF_SWITCH)) {\n        return NodeType.OFF_SWITCH;\n      }\n\n      double threshold = allowed.equals(NodeType.NODE_LOCAL) ?\n          nodeLocalityThreshold :\n          rackLocalityThreshold;\n\n      // Relax locality constraints once we've surpassed threshold.\n      int schedulingOpportunities = getSchedulingOpportunities(schedulerKey);\n      double thresholdNum = numNodes * threshold;\n      if (schedulingOpportunities > thresholdNum) {\n        if (allowed.equals(NodeType.NODE_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                + \", nodeLocalityThreshold: \" + thresholdNum\n                + \", change allowedLocality from NODE_LOCAL to RACK_LOCAL\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.RACK_LOCAL);\n          resetSchedulingOpportunities(schedulerKey);\n        } else if (allowed.equals(NodeType.RACK_LOCAL)) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"SchedulingOpportunities: \" + schedulingOpportunities\n                + \", rackLocalityThreshold: \" + thresholdNum\n                + \", change allowedLocality from RACK_LOCAL to OFF_SWITCH\"\n                + \", priority: \" + schedulerKey.getPriority()\n                + \", app attempt id: \" + this.attemptId);\n          }\n          allowedLocalityLevel.put(schedulerKey, NodeType.OFF_SWITCH);\n          resetSchedulingOpportunities(schedulerKey);\n        }\n      }\n      return allowedLocalityLevel.get(schedulerKey);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getPriority": "  public Priority getPriority() {\n    // Right now per-app priorities are not passed to scheduler,\n    // so everyone has the same priority.\n    return appPriority;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.isReservable": "  private boolean isReservable(Resource capacity) {\n    // Reserve only when the app is starved and the requested container size\n    // is larger than the configured threshold\n    return isStarved() &&\n        scheduler.isAtLeastReservationThreshold(\n            getQueue().getPolicy().getResourceCalculator(), capacity);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    Resource assigned = none();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Node \" + node.getNodeName() + \" offered to queue: \" +\n          getName() + \" fairShare: \" + getFairShare());\n    }\n\n    if (!assignContainerPreCheck(node)) {\n      return assigned;\n    }\n\n    for (FSAppAttempt sched : fetchAppsWithDemand(true)) {\n      if (SchedulerAppUtils.isPlaceBlacklisted(sched, node, LOG)) {\n        continue;\n      }\n      assigned = sched.assignContainer(node);\n      if (!assigned.equals(none())) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Assigned container in queue:\" + getName() + \" \" +\n              \"container:\" + assigned);\n        }\n        break;\n      }\n    }\n    return assigned;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.fetchAppsWithDemand": "  private TreeSet<FSAppAttempt> fetchAppsWithDemand(boolean assignment) {\n    TreeSet<FSAppAttempt> pendingForResourceApps =\n        new TreeSet<>(policy.getComparator());\n    readLock.lock();\n    try {\n      for (FSAppAttempt app : runnableApps) {\n        if (!Resources.isNone(app.getPendingDemand()) &&\n            (assignment || app.shouldCheckForStarvation())) {\n          pendingForResourceApps.add(app);\n        }\n      }\n    } finally {\n      readLock.unlock();\n    }\n    return pendingForResourceApps;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer": "  public Resource assignContainer(FSSchedulerNode node) {\n    Resource assigned = Resources.none();\n\n    // If this queue is over its limit, reject\n    if (!assignContainerPreCheck(node)) {\n      return assigned;\n    }\n\n    // Hold the write lock when sorting childQueues\n    writeLock.lock();\n    try {\n      Collections.sort(childQueues, policy.getComparator());\n    } finally {\n      writeLock.unlock();\n    }\n\n    /*\n     * We are releasing the lock between the sort and iteration of the\n     * \"sorted\" list. There could be changes to the list here:\n     * 1. Add a child queue to the end of the list, this doesn't affect\n     * container assignment.\n     * 2. Remove a child queue, this is probably good to take care of so we\n     * don't assign to a queue that is going to be removed shortly.\n     */\n    readLock.lock();\n    try {\n      for (FSQueue child : childQueues) {\n        assigned = child.assignContainer(node);\n        if (!Resources.equals(assigned, Resources.none())) {\n          break;\n        }\n      }\n    } finally {\n      readLock.unlock();\n    }\n    return assigned;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling": "  void attemptScheduling(FSSchedulerNode node) {\n    try {\n      writeLock.lock();\n      if (rmContext.isWorkPreservingRecoveryEnabled() && !rmContext\n          .isSchedulerReadyForAllocatingContainers()) {\n        return;\n      }\n\n      final NodeId nodeID = node.getNodeID();\n      if (!nodeTracker.exists(nodeID)) {\n        // The node might have just been removed while this thread was waiting\n        // on the synchronized lock before it entered this synchronized method\n        LOG.info(\n            \"Skipping scheduling as the node \" + nodeID + \" has been removed\");\n        return;\n      }\n\n      // Assign new containers...\n      // 1. Ensure containers are assigned to the apps that preempted\n      // 2. Check for reserved applications\n      // 3. Schedule if there are no reservations\n\n      // Apps may wait for preempted containers\n      // We have to satisfy these first to avoid cases, when we preempt\n      // a container for A from B and C gets the preempted containers,\n      // when C does not qualify for preemption itself.\n      assignPreemptedContainers(node);\n      FSAppAttempt reservedAppSchedulable = node.getReservedAppSchedulable();\n      boolean validReservation = false;\n      if (reservedAppSchedulable != null) {\n        validReservation = reservedAppSchedulable.assignReservedContainer(node);\n      }\n      if (!validReservation) {\n        // No reservation, schedule at queue which is farthest below fair share\n        int assignedContainers = 0;\n        Resource assignedResource = Resources.clone(Resources.none());\n        Resource maxResourcesToAssign = Resources.multiply(\n            node.getUnallocatedResource(), 0.5f);\n        while (node.getReservedContainer() == null) {\n          Resource assignment = queueMgr.getRootQueue().assignContainer(node);\n          if (assignment.equals(Resources.none())) {\n            break;\n          }\n\n          assignedContainers++;\n          Resources.addTo(assignedResource, assignment);\n          if (!shouldContinueAssigning(assignedContainers, maxResourcesToAssign,\n              assignedResource)) {\n            break;\n          }\n        }\n      }\n      updateRootQueueMetrics();\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateRootQueueMetrics": "  private void updateRootQueueMetrics() {\n    rootMetrics.setAvailableResourcesToQueue(\n        Resources.subtract(\n            getClusterResource(), rootMetrics.getAllocatedResources()));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.shouldContinueAssigning": "  private boolean shouldContinueAssigning(int containers,\n      Resource maxResourcesToAssign, Resource assignedResource) {\n    if (!assignMultiple) {\n      return false; // assignMultiple is not enabled. Allocate one at a time.\n    }\n\n    if (maxAssignDynamic) {\n      // Using fitsIn to check if the resources assigned so far are less than\n      // or equal to max resources to assign (half of remaining resources).\n      // The \"equal to\" part can lead to allocating one extra container.\n      return Resources.fitsIn(assignedResource, maxResourcesToAssign);\n    } else {\n      return maxAssign <= 0 || containers < maxAssign;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.assignPreemptedContainers": "  static void assignPreemptedContainers(FSSchedulerNode node) {\n    for (Entry<FSAppAttempt, Resource> entry :\n        node.getPreemptionList().entrySet()) {\n      FSAppAttempt app = entry.getKey();\n      Resource preemptionPending = Resources.clone(entry.getValue());\n      while (!app.isStopped() && !Resources.isNone(preemptionPending)) {\n        Resource assigned = app.assignContainer(node);\n        if (Resources.isNone(assigned) ||\n            assigned.equals(FairScheduler.CONTAINER_RESERVED)) {\n          // Fail to assign, let's not try further\n          break;\n        }\n        Resources.subtractFromNonNegative(preemptionPending, assigned);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate": "  protected void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start = getClock().getTime();\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode = getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration = getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getFSSchedulerNode": "  private FSSchedulerNode getFSSchedulerNode(NodeId nodeId) {\n    return nodeTracker.getNode(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch (event.getType()) {\n    case NODE_ADDED:\n      if (!(event instanceof NodeAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getContainerReports(),\n          nodeAddedEvent.getAddedRMNode());\n      break;\n    case NODE_REMOVED:\n      if (!(event instanceof NodeRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n      break;\n    case NODE_UPDATE:\n      if (!(event instanceof NodeUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n      break;\n    case APP_ADDED:\n      if (!(event instanceof AppAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName =\n          resolveReservationQueueName(appAddedEvent.getQueue(),\n              appAddedEvent.getApplicationId(),\n              appAddedEvent.getReservationID(),\n              appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        addApplication(appAddedEvent.getApplicationId(),\n            queueName, appAddedEvent.getUser(),\n            appAddedEvent.getIsAppRecovering());\n      }\n      break;\n    case APP_REMOVED:\n      if (!(event instanceof AppRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      removeApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n      break;\n    case NODE_RESOURCE_UPDATE:\n      if (!(event instanceof NodeResourceUpdateSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent = \n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeResource(nodeResourceUpdatedEvent.getRMNode(),\n            nodeResourceUpdatedEvent.getResourceOption());\n      break;\n    case APP_ATTEMPT_ADDED:\n      if (!(event instanceof AppAttemptAddedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n      break;\n    case APP_ATTEMPT_REMOVED:\n      if (!(event instanceof AppAttemptRemovedSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      removeApplicationAttempt(\n          appAttemptRemovedEvent.getApplicationAttemptID(),\n          appAttemptRemovedEvent.getFinalAttemptState(),\n          appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n      break;\n    case RELEASE_CONTAINER:\n      if (!(event instanceof ReleaseContainerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      RMContainer container = ((ReleaseContainerEvent) event).getContainer();\n      completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n              container.getContainerId(),\n              SchedulerUtils.RELEASED_CONTAINER),\n          RMContainerEventType.RELEASED);\n      break;\n    case CONTAINER_EXPIRED:\n      if (!(event instanceof ContainerExpiredSchedulerEvent)) {\n        throw new RuntimeException(\"Unexpected event type: \" + event);\n      }\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent)event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      super.completedContainer(getRMContainer(containerId),\n          SchedulerUtils.createAbnormalContainerStatus(\n              containerId,\n              SchedulerUtils.EXPIRED_CONTAINER),\n          RMContainerEventType.EXPIRE);\n      break;\n    default:\n      LOG.error(\"Unknown event arrived at FairScheduler: \" + event.toString());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addNode": "  private void addNode(List<NMContainerStatus> containerReports,\n      RMNode node) {\n    try {\n      writeLock.lock();\n      FSSchedulerNode schedulerNode = new FSSchedulerNode(node,\n          usePortForNodeName);\n      nodeTracker.addNode(schedulerNode);\n\n      triggerUpdate();\n\n      Resource clusterResource = getClusterResource();\n      queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n      queueMgr.getRootQueue().recomputeSteadyShares();\n      LOG.info(\"Added node \" + node.getNodeAddress() + \" cluster capacity: \"\n          + clusterResource);\n\n      recoverContainersOnNode(containerReports, node);\n      updateRootQueueMetrics();\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication": "  protected void addApplication(ApplicationId applicationId,\n      String queueName, String user, boolean isAppRecovering) {\n    if (queueName == null || queueName.isEmpty()) {\n      String message =\n          \"Reject application \" + applicationId + \" submitted by user \" + user\n              + \" with an empty queue name.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n              message));\n      return;\n    }\n\n    if (queueName.startsWith(\".\") || queueName.endsWith(\".\")) {\n      String message =\n          \"Reject application \" + applicationId + \" submitted by user \" + user\n              + \" with an illegal queue name \" + queueName + \". \"\n              + \"The queue name cannot start/end with period.\";\n      LOG.info(message);\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n              message));\n      return;\n    }\n\n    try {\n      writeLock.lock();\n      RMApp rmApp = rmContext.getRMApps().get(applicationId);\n      FSLeafQueue queue = assignToQueue(rmApp, queueName, user);\n      if (queue == null) {\n        return;\n      }\n\n      // Enforce ACLs\n      UserGroupInformation userUgi = UserGroupInformation.createRemoteUser(\n          user);\n\n      if (!queue.hasAccess(QueueACL.SUBMIT_APPLICATIONS, userUgi) && !queue\n          .hasAccess(QueueACL.ADMINISTER_QUEUE, userUgi)) {\n        String msg = \"User \" + userUgi.getUserName()\n            + \" cannot submit applications to queue \" + queue.getName()\n            + \"(requested queuename is \" + queueName + \")\";\n        LOG.info(msg);\n        rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED, msg));\n        return;\n      }\n\n      SchedulerApplication<FSAppAttempt> application =\n          new SchedulerApplication<FSAppAttempt>(queue, user);\n      applications.put(applicationId, application);\n      queue.getMetrics().submitApp(user);\n\n        LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n            + \", in queue: \" + queue.getName()\n            + \", currently num of applications: \" + applications.size());\n      if (isAppRecovering) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(applicationId\n              + \" is recovering. Skip notifying APP_ACCEPTED\");\n        }\n      } else{\n        rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt": "  private void removeApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    try {\n      writeLock.lock();\n      LOG.info(\"Application \" + applicationAttemptId + \" is done. finalState=\"\n              + rmAppAttemptFinalState);\n      FSAppAttempt attempt = getApplicationAttempt(applicationAttemptId);\n\n      if (attempt == null) {\n        LOG.info(\n            \"Unknown application \" + applicationAttemptId + \" has completed!\");\n        return;\n      }\n\n      // Check if the attempt is already stopped and don't stop it twice.\n      if (attempt.isStopped()) {\n        LOG.info(\"Application \" + applicationAttemptId + \" has already been \"\n            + \"stopped!\");\n        return;\n      }\n\n      // Release all the running containers\n      for (RMContainer rmContainer : attempt.getLiveContainers()) {\n        if (keepContainers && rmContainer.getState().equals(\n            RMContainerState.RUNNING)) {\n          // do not kill the running container in the case of work-preserving AM\n          // restart.\n          LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n          continue;\n        }\n        super.completedContainer(rmContainer, SchedulerUtils\n                .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                    SchedulerUtils.COMPLETED_APPLICATION),\n            RMContainerEventType.KILL);\n      }\n\n      // Release all reserved containers\n      for (RMContainer rmContainer : attempt.getReservedContainers()) {\n        super.completedContainer(rmContainer, SchedulerUtils\n            .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                \"Application Complete\"), RMContainerEventType.KILL);\n      }\n      // Clean up pending requests, metrics etc.\n      attempt.stop(rmAppAttemptFinalState);\n\n      // Inform the queue\n      FSLeafQueue queue = queueMgr.getLeafQueue(\n          attempt.getQueue().getQueueName(), false);\n      boolean wasRunnable = queue.removeApp(attempt);\n\n      if (wasRunnable) {\n        maxRunningEnforcer.untrackRunnableApp(attempt);\n        maxRunningEnforcer.updateRunnabilityOnAppRemoval(attempt,\n            attempt.getQueue());\n      } else{\n        maxRunningEnforcer.untrackNonRunnableApp(attempt);\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication": "  private void removeApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    SchedulerApplication<FSAppAttempt> application = applications.remove(\n        applicationId);\n    if (application == null) {\n      LOG.warn(\"Couldn't find application \" + applicationId);\n    } else{\n      application.stop(finalState);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.resolveReservationQueueName": "  private String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID,\n      boolean isRecovering) {\n    try {\n      readLock.lock();\n      FSQueue queue = queueMgr.getQueue(queueName);\n      if ((queue == null) || !allocConf.isReservable(queue.getQueueName())) {\n        return queueName;\n      }\n      // Use fully specified name from now on (including root. prefix)\n      queueName = queue.getQueueName();\n      if (reservationID != null) {\n        String resQName = queueName + \".\" + reservationID.toString();\n        queue = queueMgr.getQueue(resQName);\n        if (queue == null) {\n          // reservation has terminated during failover\n          if (isRecovering && allocConf.getMoveOnExpiry(queueName)) {\n            // move to the default child queue of the plan\n            return getDefaultQueueForPlanQueue(queueName);\n          }\n          String message = \"Application \" + applicationId\n              + \" submitted to a reservation which is not yet \"\n              + \"currently active: \" + resQName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        if (!queue.getParent().getQueueName().equals(queueName)) {\n          String message =\n              \"Application: \" + applicationId + \" submitted to a reservation \"\n                  + resQName + \" which does not belong to the specified queue: \"\n                  + queueName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        // use the reservation queue to run the app\n        queueName = resQName;\n      } else{\n        // use the default child queue of the plan for unreserved apps\n        queueName = getDefaultQueueForPlanQueue(queueName);\n      }\n      return queueName;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.updateNodeResource": "  public void updateNodeResource(RMNode nm,\n      ResourceOption resourceOption) {\n    try {\n      writeLock.lock();\n      super.updateNodeResource(nm, resourceOption);\n      updateRootQueueMetrics();\n      queueMgr.getRootQueue().setSteadyFairShare(getClusterResource());\n      queueMgr.getRootQueue().recomputeSteadyShares();\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplicationAttempt": "  protected void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FSAppAttempt> application = applications.get(\n          applicationAttemptId.getApplicationId());\n      String user = application.getUser();\n      FSLeafQueue queue = (FSLeafQueue) application.getQueue();\n\n      FSAppAttempt attempt = new FSAppAttempt(this, applicationAttemptId, user,\n          queue, new ActiveUsersManager(getRootQueueMetrics()), rmContext);\n      if (transferStateFromPreviousAttempt) {\n        attempt.transferStateFromPreviousAttempt(\n            application.getCurrentAppAttempt());\n      }\n      application.setCurrentAppAttempt(attempt);\n\n      boolean runnable = maxRunningEnforcer.canAppBeRunnable(queue, attempt);\n      queue.addApp(attempt, runnable);\n      if (runnable) {\n        maxRunningEnforcer.trackRunnableApp(attempt);\n      } else{\n        maxRunningEnforcer.trackNonRunnableApp(attempt);\n      }\n\n      queue.getMetrics().submitAppAttempt(user);\n\n      LOG.info(\"Added Application Attempt \" + applicationAttemptId\n          + \" to scheduler from user: \" + user);\n\n      if (isAttemptRecovering) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(applicationAttemptId\n              + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n        }\n      } else{\n        rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppAttemptEvent(applicationAttemptId,\n                RMAppAttemptEventType.ATTEMPT_ADDED));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeNode": "  private void removeNode(RMNode rmNode) {\n    try {\n      writeLock.lock();\n      NodeId nodeId = rmNode.getNodeID();\n      FSSchedulerNode node = nodeTracker.getNode(nodeId);\n      if (node == null) {\n        LOG.error(\"Attempting to remove non-existent node \" + nodeId);\n        return;\n      }\n\n      // Remove running containers\n      List<RMContainer> runningContainers =\n          node.getCopiedListOfRunningContainers();\n      for (RMContainer container : runningContainers) {\n        super.completedContainer(container, SchedulerUtils\n            .createAbnormalContainerStatus(container.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      // Remove reservations, if any\n      RMContainer reservedContainer = node.getReservedContainer();\n      if (reservedContainer != null) {\n        super.completedContainer(reservedContainer, SchedulerUtils\n            .createAbnormalContainerStatus(reservedContainer.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      nodeTracker.removeNode(nodeId);\n      Resource clusterResource = getClusterResource();\n      queueMgr.getRootQueue().setSteadyFairShare(clusterResource);\n      queueMgr.getRootQueue().recomputeSteadyShares();\n      updateRootQueueMetrics();\n      triggerUpdate();\n\n      LOG.info(\"Removed node \" + rmNode.getNodeAddress() + \" cluster capacity: \"\n          + clusterResource);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.EventDispatcher.run": "    public void run() {\n\n      T event;\n\n      while (!stopped && !Thread.currentThread().isInterrupted()) {\n        try {\n          event = eventQueue.take();\n        } catch (InterruptedException e) {\n          LOG.error(\"Returning, interrupted : \" + e);\n          return; // TODO: Kill RM.\n        }\n\n        try {\n          handler.handle(event);\n        } catch (Throwable t) {\n          // An error occurred, but we are shutting down anyway.\n          // If it was an InterruptedException, the very act of\n          // shutdown could have caused it and is probably harmless.\n          if (stopped) {\n            LOG.warn(\"Exception during shutdown: \", t);\n            break;\n          }\n          LOG.fatal(\"Error in handling event type \" + event.getType()\n              + \" to the Event Dispatcher\", t);\n          if (shouldExitOnError\n              && !ShutdownHookManager.get().isShutdownInProgress()) {\n            LOG.info(\"Exiting, bbye..\");\n            System.exit(-1);\n          }\n        }\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.EventDispatcher.handle": "  public void handle(T event) {\n    try {\n      int qSize = eventQueue.size();\n      if (qSize !=0 && qSize %1000 == 0) {\n        LOG.info(\"Size of \" + getName() + \" event-queue is \" + qSize);\n      }\n      int remCapacity = eventQueue.remainingCapacity();\n      if (remCapacity < 1000) {\n        LOG.info(\"Very low remaining capacity on \" + getName() + \"\" +\n            \"event queue: \" + remCapacity);\n      }\n      this.eventQueue.put(event);\n    } catch (InterruptedException e) {\n      LOG.info(\"Interrupted. Trying to exit gracefully.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignReservedContainer": "  boolean assignReservedContainer(FSSchedulerNode node) {\n    RMContainer rmContainer = node.getReservedContainer();\n    SchedulerRequestKey reservedSchedulerKey =\n        rmContainer.getReservedSchedulerKey();\n\n    if (!isValidReservation(node)) {\n      // Don't hold the reservation if app can no longer use it\n      LOG.info(\"Releasing reservation that cannot be satisfied for \" +\n          \"application \" + getApplicationAttemptId() + \" on node \" + node);\n      unreserve(reservedSchedulerKey, node);\n      return false;\n    }\n\n    // Reservation valid; try to fulfill the reservation\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Trying to fulfill reservation for application \"\n          + getApplicationAttemptId() + \" on node: \" + node);\n    }\n\n    // Fail early if the reserved container won't fit.\n    // Note that we have an assumption here that\n    // there's only one container size per priority.\n    if (Resources.fitsIn(node.getReservedContainer().getReservedResource(),\n        node.getUnallocatedResource())) {\n      assignContainer(node, true);\n    }\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.isValidReservation": "  private boolean isValidReservation(FSSchedulerNode node) {\n    SchedulerRequestKey schedulerKey = node.getReservedContainer().\n        getReservedSchedulerKey();\n    return hasContainerForNode(schedulerKey, node) &&\n        !isOverAMShareLimit();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.getReservedAppSchedulable": "  synchronized FSAppAttempt getReservedAppSchedulable() {\n    return reservedAppSchedulable;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.fsOpDurations.addNodeUpdateDuration": "  public void addNodeUpdateDuration(long value) {\n    nodeUpdateCall.add(value);\n  }"
        },
        "bug_report": {
            "Title": "NoSuchElementException in FairScheduler after failover causes RM crash",
            "Description": "While running an MR job (e.g. sleep) and an RM failover occurs, once the maps gets to 100%, the now active RM will crash due to:\r\n{noformat}\r\n2017-10-18 15:02:05,347 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1508361403235_0001_01_000002 Container Transitioned from RUNNING to COMPLETED\r\n2017-10-18 15:02:05,347 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=systest  OPERATION=AM Released Container TARGET=SchedulerApp     RESULT=SUCCESS  APPID=application_1508361403235_0001    CONTAINERID=container_1508361403235_0001_01_000002      RESOURCE=<memory:1024, vCores:1>\r\n2017-10-18 15:02:05,349 FATAL org.apache.hadoop.yarn.event.EventDispatcher: Error in handling event type NODE_UPDATE to the Event Dispatcher\r\njava.util.NoSuchElementException\r\n        at java.util.concurrent.ConcurrentSkipListMap.firstKey(ConcurrentSkipListMap.java:2036)\r\n        at java.util.concurrent.ConcurrentSkipListSet.first(ConcurrentSkipListSet.java:396)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.getNextPendingAsk(AppSchedulingInfo.java:371)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.isOverAMShareLimit(FSAppAttempt.java:901)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:1326)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:371)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:221)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:221)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1019)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:887)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1104)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:128)\r\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n2017-10-18 15:02:05,360 INFO org.apache.hadoop.yarn.event.EventDispatcher: Exiting, bbye..\r\n{noformat}\r\nThis leaves the cluster with no RMs!"
        }
    },
    {
        "filename": "YARN-1094.json",
        "creation_time": "2013-08-23T19:06:17.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.setTimerForTokenRenewal(DelegationTokenRenewer.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.addApplication(DelegationTokenRenewer.java:307)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:819)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:613)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:832)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication": "  protected void submitApplication(\n      ApplicationSubmissionContext submissionContext, long submitTime,\n      boolean isRecovered, String user) throws YarnException {\n    ApplicationId applicationId = submissionContext.getApplicationId();\n\n    // Validation of the ApplicationSubmissionContext needs to be completed\n    // here. Only those fields that are dependent on RM's configuration are\n    // checked here as they have to be validated whether they are part of new\n    // submission or just being recovered.\n\n    // Check whether AM resource requirements are within required limits\n    if (!submissionContext.getUnmanagedAM()) {\n      ResourceRequest amReq = BuilderUtils.newResourceRequest(\n          RMAppAttemptImpl.AM_CONTAINER_PRIORITY, ResourceRequest.ANY,\n          submissionContext.getResource(), 1);\n      try {\n        SchedulerUtils.validateResourceRequest(amReq,\n            scheduler.getMaximumResourceCapability());\n      } catch (InvalidResourceRequestException e) {\n        LOG.warn(\"RM app submission failed in validating AM resource request\"\n            + \" for application \" + applicationId, e);\n        throw e;\n      }\n    }\n\n    // Create RMApp\n    RMApp application =\n        new RMAppImpl(applicationId, rmContext, this.conf,\n            submissionContext.getApplicationName(), user,\n            submissionContext.getQueue(),\n            submissionContext, this.scheduler, this.masterService,\n            submitTime, submissionContext.getApplicationType());\n\n    // Concurrent app submissions with same applicationId will fail here\n    // Concurrent app submissions with different applicationIds will not\n    // influence each other\n    if (rmContext.getRMApps().putIfAbsent(applicationId, application) !=\n        null) {\n      String message = \"Application with id \" + applicationId\n          + \" is already present! Cannot add a duplicate!\";\n      LOG.warn(message);\n      throw RPCUtil.getRemoteException(message);\n    }\n\n    // Inform the ACLs Manager\n    this.applicationACLsManager.addApplication(applicationId,\n        submissionContext.getAMContainerSpec().getApplicationACLs());\n\n    try {\n      // Setup tokens for renewal\n      if (UserGroupInformation.isSecurityEnabled()) {\n        this.rmContext.getDelegationTokenRenewer().addApplication(\n            applicationId,parseCredentials(submissionContext),\n            submissionContext.getCancelTokensWhenComplete()\n            );\n      }\n    } catch (IOException ie) {\n      LOG.warn(\n          \"Unable to add the application to the delegation token renewer.\",\n          ie);\n      // Sending APP_REJECTED is fine, since we assume that the\n      // RMApp is in NEW state and thus we havne't yet informed the\n      // Scheduler about the existence of the application\n      this.rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppRejectedEvent(applicationId, ie.getMessage()));\n      throw RPCUtil.getRemoteException(ie);\n    }\n\n    // All done, start the RMApp\n    this.rmContext.getDispatcher().getEventHandler().handle(\n        new RMAppEvent(applicationId, isRecovered ? RMAppEventType.RECOVER:\n            RMAppEventType.START));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.parseCredentials": "  private Credentials parseCredentials(ApplicationSubmissionContext application) \n      throws IOException {\n    Credentials credentials = new Credentials();\n    DataInputByteBuffer dibb = new DataInputByteBuffer();\n    ByteBuffer tokens = application.getAMContainerSpec().getTokens();\n    if (tokens != null) {\n      dibb.reset(tokens);\n      credentials.readTokenStorageStream(dibb);\n      tokens.rewind();\n    }\n    return credentials;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle": "  public void handle(RMAppManagerEvent event) {\n    ApplicationId applicationId = event.getApplicationId();\n    LOG.debug(\"RMAppManager processing event for \" \n        + applicationId + \" of type \" + event.getType());\n    switch(event.getType()) {\n      case APP_COMPLETED: \n      {\n        finishApplication(applicationId);\n        ApplicationSummary.logAppSummary(\n            rmContext.getRMApps().get(applicationId));\n        checkAppNumCompletedLimit(); \n      } \n      break;\n      default:\n        LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n      }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover": "  public void recover(RMState state) throws Exception {\n    RMStateStore store = rmContext.getStateStore();\n    assert store != null;\n    // recover applications\n    Map<ApplicationId, ApplicationState> appStates = state.getApplicationState();\n    LOG.info(\"Recovering \" + appStates.size() + \" applications\");\n    for(ApplicationState appState : appStates.values()) {\n      boolean shouldRecover = true;\n      if(appState.getApplicationSubmissionContext().getUnmanagedAM()) {\n        // do not recover unmanaged applications since current recovery \n        // mechanism of restarting attempts does not work for them.\n        // This will need to be changed in work preserving recovery in which \n        // RM will re-connect with the running AM's instead of restarting them\n        LOG.info(\"Not recovering unmanaged application \" + appState.getAppId());\n        shouldRecover = false;\n      }\n      int individualMaxAppAttempts = appState.getApplicationSubmissionContext()\n          .getMaxAppAttempts();\n      int maxAppAttempts;\n      if (individualMaxAppAttempts <= 0 ||\n          individualMaxAppAttempts > globalMaxAppAttempts) {\n        maxAppAttempts = globalMaxAppAttempts;\n        LOG.warn(\"The specific max attempts: \" + individualMaxAppAttempts\n            + \" for application: \" + appState.getAppId()\n            + \" is invalid, because it is out of the range [1, \"\n            + globalMaxAppAttempts + \"]. Use the global max attempts instead.\");\n      } else {\n        maxAppAttempts = individualMaxAppAttempts;\n      }\n      // In work-preserve restart, if attemptCount == maxAttempts, the job still\n      // needs to be recovered because the last attempt may still be running.\n      if(appState.getAttemptCount() >= maxAppAttempts) {\n        LOG.info(\"Not recovering application \" + appState.getAppId() +\n            \" due to recovering attempt is beyond maxAppAttempt limit\");\n        shouldRecover = false;\n      }\n\n      // re-submit the application\n      // this is going to send an app start event but since the async dispatcher\n      // has not started that event will be queued until we have completed re\n      // populating the state\n      if(shouldRecover) {\n        LOG.info(\"Recovering application \" + appState.getAppId());\n        submitApplication(appState.getApplicationSubmissionContext(), \n                        appState.getSubmitTime(), true, appState.getUser());\n        // re-populate attempt information in application\n        RMAppImpl appImpl = (RMAppImpl) rmContext.getRMApps().get(\n                                                        appState.getAppId());\n        appImpl.recover(state);\n      }\n      else {\n        store.removeApplication(appState);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover": "  public void recover(RMState state) throws Exception {\n    // recover RMdelegationTokenSecretManager\n    rmDTSecretManager.recover(state);\n\n    // recover applications\n    rmAppManager.recover(state);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart": "  protected void serviceStart() throws Exception {\n    try {\n      doSecureLogin();\n    } catch(IOException ie) {\n      throw new YarnRuntimeException(\"Failed to login\", ie);\n    }\n\n    this.amRmTokenSecretManager.start();\n    this.containerTokenSecretManager.start();\n    this.nmTokenSecretManager.start();\n\n    RMStateStore rmStore = rmContext.getStateStore();\n    // The state store needs to start irrespective of recoveryEnabled as apps\n    // need events to move to further states.\n    rmStore.start();\n\n    if(recoveryEnabled) {\n      try {\n        RMState state = rmStore.loadState();\n        recover(state);\n      } catch (Exception e) {\n        // the Exception from loadState() needs to be handled for \n        // HA and we need to give up master status if we got fenced\n        LOG.error(\"Failed to load/recover state\", e);\n        ExitUtil.terminate(1, e);\n      }\n    }\n\n    startWepApp();\n    try {\n      rmDTSecretManager.startThreads();\n    } catch(IOException ie) {\n      throw new YarnRuntimeException(\"Failed to start secret manager threads\", ie);\n    }\n\n    if (getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      String hostname = getConfig().get(YarnConfiguration.RM_WEBAPP_ADDRESS,\n                                        YarnConfiguration.DEFAULT_RM_WEBAPP_ADDRESS);\n      hostname = (hostname.contains(\":\")) ? hostname.substring(0, hostname.indexOf(\":\")) : hostname;\n      int port = webApp.port();\n      String resolvedAddress = hostname + \":\" + port;\n      conf.set(YarnConfiguration.RM_WEBAPP_ADDRESS, resolvedAddress);\n    }\n    \n    super.serviceStart();\n\n    /*synchronized(shutdown) {\n      try {\n        while(!shutdown.get()) {\n          shutdown.wait();\n        }\n      } catch(InterruptedException ie) {\n        LOG.info(\"Interrupted while waiting\", ie);\n      }\n    }*/\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.doSecureLogin": "  protected void doSecureLogin() throws IOException {\n    SecurityUtil.login(this.conf, YarnConfiguration.RM_KEYTAB,\n        YarnConfiguration.RM_PRINCIPAL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp": "  protected void startWepApp() {\n    Builder<ApplicationMasterService> builder = \n      WebApps.$for(\"cluster\", ApplicationMasterService.class, masterService, \"ws\").at(\n          this.conf.get(YarnConfiguration.RM_WEBAPP_ADDRESS,\n          YarnConfiguration.DEFAULT_RM_WEBAPP_ADDRESS)); \n    String proxyHostAndPort = YarnConfiguration.getProxyHostAndPort(conf);\n    if(YarnConfiguration.getRMWebAppHostAndPort(conf).\n        equals(proxyHostAndPort)) {\n      AppReportFetcher fetcher = new AppReportFetcher(conf, getClientRMService());\n      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME, \n          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);\n      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);\n      String[] proxyParts = proxyHostAndPort.split(\":\");\n      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);\n\n    }\n    webApp = builder.start(new RMWebApp(this));\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.start": "  public void start() {\n    if (isInState(STATE.STARTED)) {\n      return;\n    }\n    //enter the started state\n    synchronized (stateChangeLock) {\n      if (stateModel.enterState(STATE.STARTED) != STATE.STARTED) {\n        try {\n          startTime = System.currentTimeMillis();\n          serviceStart();\n          if (isInState(STATE.STARTED)) {\n            //if the service started (and isn't now in a later state), notify\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Service \" + getName() + \" is started\");\n            }\n            notifyListeners();\n          }\n        } catch (Exception e) {\n          noteFailure(e);\n          ServiceOperations.stopQuietly(LOG, this);\n          throw ServiceStateException.convert(e);\n        }\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.isInState": "  public final boolean isInState(Service.STATE expected) {\n    return stateModel.isInState(expected);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.serviceStart": "  protected void serviceStart() throws Exception {\n\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.getName": "  public String getName() {\n    return name;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.notifyListeners": "  private void notifyListeners() {\n    try {\n      listeners.notifyListeners(this);\n      globalListeners.notifyListeners(this);\n    } catch (Throwable e) {\n      LOG.warn(\"Exception while notifying listeners of \" + this + \": \" + e,\n               e);\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.noteFailure": "  protected final void noteFailure(Exception exception) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"noteFailure \" + exception, null);\n    }\n    if (exception == null) {\n      //make sure failure logic doesn't itself cause problems\n      return;\n    }\n    //record the failure details, and log it\n    synchronized (this) {\n      if (failureCause == null) {\n        failureCause = exception;\n        failureState = getServiceState();\n        LOG.info(\"Service \" + getName()\n                 + \" failed in state \" + failureState\n                 + \"; cause: \" + exception,\n                 exception);\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.AbstractService.enterState": "  private STATE enterState(STATE newState) {\n    assert stateModel != null : \"null state in \" + name + \" \" + this.getClass();\n    STATE oldState = stateModel.enterState(newState);\n    if (oldState != newState) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n          \"Service: \" + getName() + \" entered state \" + getServiceState());\n      }\n      recordLifecycleEvent();\n    }\n    return oldState;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main": "  public static void main(String argv[]) {\n    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n    StringUtils.startupShutdownMessage(ResourceManager.class, argv, LOG);\n    try {\n      Configuration conf = new YarnConfiguration();\n      ResourceManager resourceManager = new ResourceManager();\n      ShutdownHookManager.get().addShutdownHook(\n        new CompositeServiceShutdownHook(resourceManager),\n        SHUTDOWN_HOOK_PRIORITY);\n      resourceManager.init(conf);\n      resourceManager.start();\n    } catch (Throwable t) {\n      LOG.fatal(\"Error starting ResourceManager\", t);\n      System.exit(-1);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getRMApps": "  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<String, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getStateStore": "  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<String, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n}",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stopQuietly": "  public static Exception stopQuietly(Log log, Service service) {\n    try {\n      stop(service);\n    } catch (Exception e) {\n      log.warn(\"When stopping the service \" + service.getName()\n               + \" : \" + e,\n               e);\n      return e;\n    }\n    return null;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceOperations.stop": "  public static void stop(Service service) {\n    if (service != null) {\n      service.stop();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.service.ServiceStateException.convert": "  public static RuntimeException convert(String text, Throwable fault) {\n    if (fault instanceof RuntimeException) {\n      return (RuntimeException) fault;\n    } else {\n      return new ServiceStateException(text, fault);\n    }\n  }"
        },
        "bug_report": {
            "Title": "RM restart throws Null pointer Exception in Secure Env",
            "Description": "Enable rmrestart feature And restart Resorce Manager while a job is running.\n\nResorce Manager fails to start with below error\n\n2013-08-23 17:57:40,705 INFO  resourcemanager.RMAppManager (RMAppManager.java:recover(370)) - Recovering application application_1377280618693_0001\n2013-08-23 17:57:40,763 ERROR resourcemanager.ResourceManager (ResourceManager.java:serviceStart(617)) - Failed to load/recover state\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.setTimerForTokenRenewal(DelegationTokenRenewer.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.addApplication(DelegationTokenRenewer.java:307)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:819)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:613)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:832)\n2013-08-23 17:57:40,766 INFO  util.ExitUtil (ExitUtil.java:terminate(124)) - Exiting with status 1\n                                                                                                    \n\n"
        }
    },
    {
        "filename": "YARN-7269.json",
        "creation_time": "2017-09-28T23:56:42.000+0000",
        "stack_trace": "```\njavax.servlet.ServletException: Could not determine the proxy server for redirection\n\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.findRedirectUrl(AmIpFilter.java:199)\n\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:141)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1426)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.findRedirectUrl": "  public String findRedirectUrl() throws ServletException {\n    String addr = null;\n    if (proxyUriBases.size() == 1) {\n      // external proxy or not RM HA\n      addr = proxyUriBases.values().iterator().next();\n    } else {\n      // RM HA\n      YarnConfiguration conf = new YarnConfiguration();\n      for (String rmId : getRmIds(conf)) {\n        String url = getUrlByRmId(conf, rmId);\n        if (isValidUrl(url)) {\n          addr = url;\n          break;\n        }\n      }\n    }\n\n    if (addr == null) {\n      throw new ServletException(\n          \"Could not determine the proxy server for redirection\");\n    }\n    return addr;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.isValidUrl": "  private boolean isValidUrl(String url) {\n    boolean isValid = false;\n    try {\n      HttpURLConnection conn =\n          (HttpURLConnection) new URL(url).openConnection();\n      conn.connect();\n      isValid = conn.getResponseCode() == HttpURLConnection.HTTP_OK;\n    } catch (Exception e) {\n      LOG.debug(\"Failed to connect to \" + url + \": \" + e.toString());\n    }\n    return isValid;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.getRmIds": "  Collection<String> getRmIds(YarnConfiguration conf) {\n    return conf.getStringCollection(YarnConfiguration.RM_HA_IDS);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.getUrlByRmId": "  String getUrlByRmId(YarnConfiguration conf, String rmId) {\n    String addressPropertyPrefix = YarnConfiguration.useHttps(conf) ?\n        YarnConfiguration.RM_WEBAPP_HTTPS_ADDRESS :\n        YarnConfiguration.RM_WEBAPP_ADDRESS;\n    String host = conf.get(HAUtil.addSuffix(addressPropertyPrefix, rmId));\n    return proxyUriBases.get(host);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse resp,\n      FilterChain chain) throws IOException, ServletException {\n    ProxyUtils.rejectNonHttpRequests(req);\n\n    HttpServletRequest httpReq = (HttpServletRequest)req;\n    HttpServletResponse httpResp = (HttpServletResponse)resp;\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Remote address for request is: {}\", httpReq.getRemoteAddr());\n    }\n\n    if (!getProxyAddresses().contains(httpReq.getRemoteAddr())) {\n      StringBuilder redirect = new StringBuilder(findRedirectUrl());\n\n      redirect.append(httpReq.getRequestURI());\n\n      int insertPoint = redirect.indexOf(PROXY_PATH);\n\n      if (insertPoint >= 0) {\n        // Add /redirect as the second component of the path so that the RM web\n        // proxy knows that this request was a redirect.\n        insertPoint += PROXY_PATH.length();\n        redirect.insert(insertPoint, \"/redirect\");\n      }\n      // add the query parameters on the redirect if there were any\n      String queryString = httpReq.getQueryString();\n      if (queryString != null && !queryString.isEmpty()) {\n        redirect.append(\"?\");\n        redirect.append(queryString);\n      }\n\n      ProxyUtils.sendRedirect(httpReq, httpResp, redirect.toString());\n    } else {\n      String user = null;\n\n      if (httpReq.getCookies() != null) {\n        for(Cookie c: httpReq.getCookies()) {\n          if(WebAppProxyServlet.PROXY_USER_COOKIE_NAME.equals(c.getName())){\n            user = c.getValue();\n            break;\n          }\n        }\n      }\n      if (user == null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Could not find \"\n              + WebAppProxyServlet.PROXY_USER_COOKIE_NAME\n              + \" cookie, so user will not be set\");\n        }\n\n        chain.doFilter(req, resp);\n      } else {\n        AmIpPrincipal principal = new AmIpPrincipal(user);\n        ServletRequest requestWrapper = new AmIpServletRequestWrapper(httpReq,\n            principal);\n\n        chain.doFilter(requestWrapper, resp);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-web-proxy.src.main.java.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.getProxyAddresses": "  protected Set<String> getProxyAddresses() throws ServletException {\n    long now = System.currentTimeMillis();\n    synchronized(this) {\n      if (proxyAddresses == null || (lastUpdate + UPDATE_INTERVAL) >= now) {\n        proxyAddresses = new HashSet<>();\n        for (String proxyHost : proxyHosts) {\n          try {\n              for(InetAddress add : InetAddress.getAllByName(proxyHost)) {\n                if (LOG.isDebugEnabled()) {\n                  LOG.debug(\"proxy address is: {}\", add.getHostAddress());\n                }\n                proxyAddresses.add(add.getHostAddress());\n              }\n              lastUpdate = now;\n            } catch (UnknownHostException e) {\n              LOG.warn(\"Could not locate {} - skipping\", proxyHost, e);\n            }\n          }\n        if (proxyAddresses.isEmpty()) {\n          throw new ServletException(\"Could not locate any of the proxy hosts\");\n        }\n      }\n      return proxyAddresses;\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.doFilter": "    public void doFilter(ServletRequest request,\n                         ServletResponse response,\n                         FilterChain chain\n                         ) throws IOException, ServletException {\n      HttpServletRequestWrapper quoted =\n        new RequestQuoter((HttpServletRequest) request);\n      HttpServletResponse httpResponse = (HttpServletResponse) response;\n\n      String mime = inferMimeType(request);\n      if (mime == null) {\n        httpResponse.setContentType(\"text/plain; charset=utf-8\");\n      } else if (mime.startsWith(\"text/html\")) {\n        // HTML with unspecified encoding, we want to\n        // force HTML with utf-8 encoding\n        // This is to avoid the following security issue:\n        // http://openmya.hacker.jp/hasegawa/security/utf7cs.html\n        httpResponse.setContentType(\"text/html; charset=utf-8\");\n      } else if (mime.startsWith(\"application/xml\")) {\n        httpResponse.setContentType(\"text/xml; charset=utf-8\");\n      }\n\n      if(Boolean.valueOf(this.config.getInitParameter(X_FRAME_ENABLED))) {\n        httpResponse.addHeader(\"X-FRAME-OPTIONS\",\n            this.config.getInitParameter(X_FRAME_VALUE));\n      }\n      chain.doFilter(quoted, httpResponse);\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.HttpServer2.inferMimeType": "    private String inferMimeType(ServletRequest request) {\n      String path = ((HttpServletRequest)request).getRequestURI();\n      ServletContextHandler.Context sContext =\n          (ServletContextHandler.Context)config.getServletContext();\n      String mime = sContext.getMimeType(path);\n      return (mime == null) ? null : mime;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.http.NoCacheFilter.doFilter": "  public void doFilter(ServletRequest req, ServletResponse res,\n                       FilterChain chain)\n    throws IOException, ServletException {\n    HttpServletResponse httpRes = (HttpServletResponse) res;\n    httpRes.setHeader(\"Cache-Control\", \"no-cache\");\n    long now = System.currentTimeMillis();\n    httpRes.addDateHeader(\"Expires\", now);\n    httpRes.addDateHeader(\"Date\", now);\n    httpRes.addHeader(\"Pragma\", \"no-cache\");\n    chain.doFilter(req, res);\n  }"
        },
        "bug_report": {
            "Title": "Tracking URL in the app state does not get redirected to ApplicationMaster for Running applications",
            "Description": "Tracking URL in the app state does not get redirected to ApplicationMaster for Running applications. It gives following exception\n{code}\n org.mortbay.log: /ws/v1/mapreduce/info\njavax.servlet.ServletException: Could not determine the proxy server for redirection\n\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.findRedirectUrl(AmIpFilter.java:199)\n\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:141)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1426)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n{code}"
        }
    },
    {
        "filename": "YARN-7249.json",
        "creation_time": "2017-09-25T16:49:46.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer(LeafQueue.java:1308) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal(CapacityScheduler.java:1469) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer(AbstractYarnScheduler.java:497) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.killReservedContainer(CapacityScheduler.java:1505) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1341) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:127) \nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:705) \n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer": "  public void completedContainer(Resource clusterResource, \n      FiCaSchedulerApp application, FiCaSchedulerNode node, RMContainer rmContainer, \n      ContainerStatus containerStatus, RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues) {\n    // Update SchedulerHealth for released / preempted container\n    updateSchedulerHealthForCompletedContainer(rmContainer, containerStatus);\n\n    if (application != null) {\n      boolean removed = false;\n\n      // Careful! Locking order is important!\n      try {\n        writeLock.lock();\n        Container container = rmContainer.getContainer();\n\n        // Inform the application & the node\n        // Note: It's safe to assume that all state changes to RMContainer\n        // happen under scheduler's lock...\n        // So, this is, in effect, a transaction across application & node\n        if (rmContainer.getState() == RMContainerState.RESERVED) {\n          removed = application.unreserve(rmContainer.getReservedSchedulerKey(),\n              node, rmContainer);\n        } else{\n          removed = application.containerCompleted(rmContainer, containerStatus,\n              event, node.getPartition());\n\n          node.releaseContainer(rmContainer.getContainerId(), false);\n        }\n\n        // Book-keeping\n        if (removed) {\n\n          // Inform the ordering policy\n          orderingPolicy.containerReleased(application, rmContainer);\n\n          releaseResource(clusterResource, application, container.getResource(),\n              node.getPartition(), rmContainer);\n        }\n      } finally {\n        writeLock.unlock();\n      }\n\n\n      if (removed) {\n        // Inform the parent queue _outside_ of the leaf-queue lock\n        getParent().completedContainer(clusterResource, application, node,\n          rmContainer, null, event, this, sortQueues);\n      }\n    }\n\n    // Notify PreemptionManager\n    csContext.getPreemptionManager().removeKillableContainer(\n        new KillableContainer(rmContainer, node.getPartition(), queueName));\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.releaseResource": "  void releaseResource(Resource clusterResource,\n      FiCaSchedulerApp application, Resource resource, String nodePartition,\n      RMContainer rmContainer) {\n    try {\n      writeLock.lock();\n      super.releaseResource(clusterResource, resource, nodePartition);\n\n      // handle ignore exclusivity container\n      if (null != rmContainer && rmContainer.getNodeLabelExpression().equals(\n          RMNodeLabelsManager.NO_LABEL) && !nodePartition.equals(\n          RMNodeLabelsManager.NO_LABEL)) {\n        if (ignorePartitionExclusivityRMContainers.containsKey(nodePartition)) {\n          Set<RMContainer> rmContainers =\n              ignorePartitionExclusivityRMContainers.get(nodePartition);\n          rmContainers.remove(rmContainer);\n          if (rmContainers.isEmpty()) {\n            ignorePartitionExclusivityRMContainers.remove(nodePartition);\n          }\n        }\n      }\n\n      // Update user metrics\n      String userName = application.getUser();\n      User user = usersManager.updateUserResourceUsage(userName, resource,\n          nodePartition, false);\n\n      metrics.setAvailableResourcesToUser(nodePartition,\n          userName, application.getHeadroom());\n\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            getQueueName() + \" used=\" + queueUsage.getUsed() + \" numContainers=\"\n                + numContainers + \" user=\" + userName + \" user-resources=\"\n                + user.getUsed());\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.updateSchedulerHealthForCompletedContainer": "  private void updateSchedulerHealthForCompletedContainer(\n      RMContainer rmContainer, ContainerStatus containerStatus) {\n    // Update SchedulerHealth for released / preempted container\n    SchedulerHealth schedulerHealth = csContext.getSchedulerHealth();\n    if (null == schedulerHealth) {\n      // Only do update if we have schedulerHealth\n      return;\n    }\n\n    if (containerStatus.getExitStatus() == ContainerExitStatus.PREEMPTED) {\n      schedulerHealth.updatePreemption(Time.now(), rmContainer.getAllocatedNode(),\n          rmContainer.getContainerId(), getQueuePath());\n      schedulerHealth.updateSchedulerPreemptionCounts(1);\n    } else {\n      schedulerHealth.updateRelease(csContext.getLastNodeUpdateTime(),\n          rmContainer.getAllocatedNode(), rmContainer.getContainerId(),\n          getQueuePath());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal": "  protected void completedContainerInternal(\n      RMContainer rmContainer, ContainerStatus containerStatus,\n      RMContainerEventType event) {\n    Container container = rmContainer.getContainer();\n    ContainerId containerId = container.getId();\n\n    // Get the application for the finished container\n    FiCaSchedulerApp application = getCurrentAttemptForContainer(\n        container.getId());\n    ApplicationId appId =\n        containerId.getApplicationAttemptId().getApplicationId();\n    if (application == null) {\n      LOG.info(\n          \"Container \" + container + \" of\" + \" finished application \" + appId\n              + \" completed with event \" + event);\n      return;\n    }\n\n    // Get the node on which the container was allocated\n    FiCaSchedulerNode node = getNode(container.getNodeId());\n    if (null == node) {\n      LOG.info(\"Container \" + container + \" of\" + \" removed node \" + container\n          .getNodeId() + \" completed with event \" + event);\n      return;\n    }\n\n    // Inform the queue\n    LeafQueue queue = (LeafQueue) application.getQueue();\n    queue.completedContainer(getClusterResource(), application, node,\n        rmContainer, containerStatus, event, null, true);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getNode": "  public FiCaSchedulerNode getNode(NodeId nodeId) {\n    return nodeTracker.getNode(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.getQueue": "  public CSQueue getQueue(String queueName) {\n    if (queueName == null) {\n      return null;\n    }\n    return this.queueManager.getQueue(queueName);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer": "  public void completedContainer(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event) {\n\n    if (rmContainer == null) {\n      LOG.info(\"Container \" + containerStatus.getContainerId()\n          + \" completed with event \" + event\n          + \", but corresponding RMContainer doesn't exist.\");\n      return;\n    }\n\n    if (rmContainer.getExecutionType() == ExecutionType.GUARANTEED) {\n      completedContainerInternal(rmContainer, containerStatus, event);\n      completeOustandingUpdatesWhichAreReserved(\n          rmContainer, containerStatus, event);\n    } else {\n      ContainerId containerId = rmContainer.getContainerId();\n      // Inform the container\n      rmContainer.handle(\n          new RMContainerFinishedEvent(containerId, containerStatus, event));\n      SchedulerApplicationAttempt schedulerAttempt =\n          getCurrentAttemptForContainer(containerId);\n      if (schedulerAttempt != null) {\n        schedulerAttempt.removeRMContainer(containerId);\n      }\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Completed container: \" + rmContainer.getContainerId() +\n            \" in state: \" + rmContainer.getState() + \" event:\" + event);\n      }\n      getSchedulerNode(rmContainer.getNodeId()).releaseContainer(\n          rmContainer.getContainerId(), false);\n    }\n\n    // If the container is getting killed in ACQUIRED state, the requester (AM\n    // for regular containers and RM itself for AM container) will not know what\n    // happened. Simply add the ResourceRequest back again so that requester\n    // doesn't need to do anything conditionally.\n    recoverResourceRequestForContainer(rmContainer);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainerInternal": "  protected abstract void completedContainerInternal(RMContainer rmContainer,\n      ContainerStatus containerStatus, RMContainerEventType event);\n\n  protected void releaseContainers(List<ContainerId> containers,\n      SchedulerApplicationAttempt attempt) {\n    for (ContainerId containerId : containers) {\n      RMContainer rmContainer = getRMContainer(containerId);\n      if (rmContainer == null) {\n        if (System.currentTimeMillis() - ResourceManager.getClusterTimeStamp()\n            < nmExpireInterval) {\n          LOG.info(containerId + \" doesn't exist. Add the container\"\n              + \" to the release request cache as it maybe on recovery.\");\n          attempt.getPendingRelease().add(containerId);\n        } else {\n          RMAuditLogger.logFailure(attempt.getUser(),\n            AuditConstants.RELEASE_CONTAINER,\n            \"Unauthorized access or invalid container\", \"Scheduler\",\n            \"Trying to release container not owned by app or with invalid id.\",\n            attempt.getApplicationId(), containerId, null);\n        }\n      }\n      completedContainer(rmContainer,\n        SchedulerUtils.createAbnormalContainerStatus(containerId,\n          SchedulerUtils.RELEASED_CONTAINER), RMContainerEventType.RELEASED);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getCurrentAttemptForContainer": "  public T getCurrentAttemptForContainer(ContainerId containerId) {\n    return getApplicationAttempt(containerId.getApplicationAttemptId());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getSchedulerNode": "  public N getSchedulerNode(NodeId nodeId) {\n    return nodeTracker.getNode(nodeId);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.recoverResourceRequestForContainer": "  private void recoverResourceRequestForContainer(RMContainer rmContainer) {\n    List<ResourceRequest> requests = rmContainer.getResourceRequests();\n\n    // If container state is moved to ACQUIRED, request will be empty.\n    if (requests == null) {\n      return;\n    }\n\n    // Add resource request back to Scheduler ApplicationAttempt.\n\n    // We lookup the application-attempt here again using\n    // getCurrentApplicationAttempt() because there is only one app-attempt at\n    // any point in the scheduler. But in corner cases, AMs can crash,\n    // corresponding containers get killed and recovered to the same-attempt,\n    // but because the app-attempt is extinguished right after, the recovered\n    // requests don't serve any purpose, but that's okay.\n    SchedulerApplicationAttempt schedulerAttempt =\n        getCurrentAttemptForContainer(rmContainer.getContainerId());\n    if (schedulerAttempt != null) {\n      schedulerAttempt.recoverResourceRequestsForContainer(requests);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completeOustandingUpdatesWhichAreReserved": "  private void completeOustandingUpdatesWhichAreReserved(\n      RMContainer rmContainer, ContainerStatus containerStatus,\n      RMContainerEventType event) {\n    N schedulerNode = getSchedulerNode(rmContainer.getNodeId());\n    if (schedulerNode != null &&\n        schedulerNode.getReservedContainer() != null) {\n      RMContainer resContainer = schedulerNode.getReservedContainer();\n      if (resContainer.getReservedSchedulerKey() != null) {\n        ContainerId containerToUpdate = resContainer\n            .getReservedSchedulerKey().getContainerToUpdate();\n        if (containerToUpdate != null &&\n            containerToUpdate.equals(containerStatus.getContainerId())) {\n          completedContainerInternal(resContainer,\n              ContainerStatus.newInstance(resContainer.getContainerId(),\n                  containerStatus.getState(), containerStatus\n                      .getDiagnostics(),\n                  containerStatus.getExitStatus()), event);\n        }\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.killReservedContainer": "  public void killReservedContainer(RMContainer container) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.KILL_RESERVED_CONTAINER + \":\"\n          + container.toString());\n    }\n    // To think: What happens if this is no longer a reserved container, for\n    // e.g if the reservation became an allocation.\n    super.completedContainer(container,\n        SchedulerUtils.createAbnormalContainerStatus(\n            container.getContainerId(),\n            SchedulerUtils.UNRESERVED_CONTAINER),\n        RMContainerEventType.KILL);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle": "  public void handle(SchedulerEvent event) {\n    switch(event.getType()) {\n    case NODE_ADDED:\n    {\n      NodeAddedSchedulerEvent nodeAddedEvent = (NodeAddedSchedulerEvent)event;\n      addNode(nodeAddedEvent.getAddedRMNode());\n      recoverContainersOnNode(nodeAddedEvent.getContainerReports(),\n        nodeAddedEvent.getAddedRMNode());\n    }\n    break;\n    case NODE_REMOVED:\n    {\n      NodeRemovedSchedulerEvent nodeRemovedEvent = (NodeRemovedSchedulerEvent)event;\n      removeNode(nodeRemovedEvent.getRemovedRMNode());\n    }\n    break;\n    case NODE_RESOURCE_UPDATE:\n    {\n      NodeResourceUpdateSchedulerEvent nodeResourceUpdatedEvent =\n          (NodeResourceUpdateSchedulerEvent)event;\n      updateNodeAndQueueResource(nodeResourceUpdatedEvent.getRMNode(),\n        nodeResourceUpdatedEvent.getResourceOption());\n    }\n    break;\n    case NODE_LABELS_UPDATE:\n    {\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent =\n          (NodeLabelsUpdateSchedulerEvent) event;\n      \n      updateNodeLabelsAndQueueResource(labelUpdateEvent);\n    }\n    break;\n    case NODE_UPDATE:\n    {\n      NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;\n      nodeUpdate(nodeUpdatedEvent.getRMNode());\n    }\n    break;\n    case APP_ADDED:\n    {\n      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;\n      String queueName = resolveReservationQueueName(appAddedEvent.getQueue(),\n          appAddedEvent.getApplicationId(), appAddedEvent.getReservationID(),\n          appAddedEvent.getIsAppRecovering());\n      if (queueName != null) {\n        if (!appAddedEvent.getIsAppRecovering()) {\n          addApplication(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        } else {\n          addApplicationOnRecovery(appAddedEvent.getApplicationId(), queueName,\n              appAddedEvent.getUser(), appAddedEvent.getApplicatonPriority());\n        }\n      }\n    }\n    break;\n    case APP_REMOVED:\n    {\n      AppRemovedSchedulerEvent appRemovedEvent = (AppRemovedSchedulerEvent)event;\n      doneApplication(appRemovedEvent.getApplicationID(),\n        appRemovedEvent.getFinalState());\n    }\n    break;\n    case APP_ATTEMPT_ADDED:\n    {\n      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =\n          (AppAttemptAddedSchedulerEvent) event;\n      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),\n        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),\n        appAttemptAddedEvent.getIsAttemptRecovering());\n    }\n    break;\n    case APP_ATTEMPT_REMOVED:\n    {\n      AppAttemptRemovedSchedulerEvent appAttemptRemovedEvent =\n          (AppAttemptRemovedSchedulerEvent) event;\n      doneApplicationAttempt(appAttemptRemovedEvent.getApplicationAttemptID(),\n        appAttemptRemovedEvent.getFinalAttemptState(),\n        appAttemptRemovedEvent.getKeepContainersAcrossAppAttempts());\n    }\n    break;\n    case CONTAINER_EXPIRED:\n    {\n      ContainerExpiredSchedulerEvent containerExpiredEvent =\n          (ContainerExpiredSchedulerEvent) event;\n      ContainerId containerId = containerExpiredEvent.getContainerId();\n      if (containerExpiredEvent.isIncrease()) {\n        rollbackContainerUpdate(containerId);\n      } else {\n        completedContainer(getRMContainer(containerId),\n            SchedulerUtils.createAbnormalContainerStatus(\n                containerId,\n                SchedulerUtils.EXPIRED_CONTAINER),\n            RMContainerEventType.EXPIRE);\n      }\n    }\n    break;\n    case RELEASE_CONTAINER:\n    {\n      RMContainer container = ((ReleaseContainerEvent) event).getContainer();\n      completedContainer(container,\n          SchedulerUtils.createAbnormalContainerStatus(\n            container.getContainerId(),\n            SchedulerUtils.RELEASED_CONTAINER),\n          RMContainerEventType.RELEASED);\n    }\n    break;\n    case KILL_RESERVED_CONTAINER:\n    {\n      ContainerPreemptEvent killReservedContainerEvent =\n          (ContainerPreemptEvent) event;\n      RMContainer container = killReservedContainerEvent.getContainer();\n      killReservedContainer(container);\n    }\n    break;\n    case MARK_CONTAINER_FOR_PREEMPTION:\n    {\n      ContainerPreemptEvent preemptContainerEvent =\n          (ContainerPreemptEvent)event;\n      ApplicationAttemptId aid = preemptContainerEvent.getAppId();\n      RMContainer containerToBePreempted = preemptContainerEvent.getContainer();\n      markContainerForPreemption(aid, containerToBePreempted);\n    }\n    break;\n    case MARK_CONTAINER_FOR_KILLABLE:\n    {\n      ContainerPreemptEvent containerKillableEvent = (ContainerPreemptEvent)event;\n      RMContainer killableContainer = containerKillableEvent.getContainer();\n      markContainerForKillable(killableContainer);\n    }\n    break;\n    case MARK_CONTAINER_FOR_NONKILLABLE:\n    {\n      if (isLazyPreemptionEnabled) {\n        ContainerPreemptEvent cancelKillContainerEvent =\n            (ContainerPreemptEvent) event;\n        markContainerForNonKillable(cancelKillContainerEvent.getContainer());\n      }\n    }\n    break;\n    default:\n      LOG.error(\"Invalid eventtype \" + event.getType() + \". Ignoring!\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addNode": "  private void addNode(RMNode nodeManager) {\n    try {\n      writeLock.lock();\n      FiCaSchedulerNode schedulerNode = new FiCaSchedulerNode(nodeManager,\n          usePortForNodeName, nodeManager.getNodeLabels());\n      nodeTracker.addNode(schedulerNode);\n\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.activateNode(nodeManager.getNodeID(),\n            schedulerNode.getTotalResource());\n      }\n\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n\n      LOG.info(\n          \"Added node \" + nodeManager.getNodeAddress() + \" clusterResource: \"\n              + clusterResource);\n\n      if (scheduleAsynchronously && getNumClusterNodes() == 1) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.beginSchedule();\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplication": "  private void addApplication(ApplicationId applicationId,\n      String queueName, String user, Priority priority) {\n    try {\n      writeLock.lock();\n      if (isSystemAppsLimitReached()) {\n        String message = \"Maximum system application limit reached,\"\n            + \"cannot accept submission of application: \" + applicationId;\n        this.rmContext.getDispatcher().getEventHandler().handle(new RMAppEvent(\n            applicationId, RMAppEventType.APP_REJECTED, message));\n        return;\n      }\n      // Sanity checks.\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to unknown queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      if (!(queue instanceof LeafQueue)) {\n        String message =\n            \"Application \" + applicationId + \" submitted by user \" + user\n                + \" to non-leaf queue: \" + queueName;\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                message));\n        return;\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        LOG.info(\"Failed to submit application \" + applicationId + \" to queue \"\n            + queueName + \" from user \" + user, ace);\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                ace.toString()));\n        return;\n      }\n      // update the metrics\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      rmContext.getDispatcher().getEventHandler().handle(\n          new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeLabelsAndQueueResource": "  private void updateNodeLabelsAndQueueResource(\n      NodeLabelsUpdateSchedulerEvent labelUpdateEvent) {\n    try {\n      writeLock.lock();\n      for (Entry<NodeId, Set<String>> entry : labelUpdateEvent\n          .getUpdatedNodeToLabels().entrySet()) {\n        NodeId id = entry.getKey();\n        Set<String> labels = entry.getValue();\n        updateLabelsOnNode(id, labels);\n      }\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplication": "  private void doneApplication(ApplicationId applicationId,\n      RMAppState finalState) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationId);\n      if (application == null) {\n        // The AppRemovedSchedulerEvent maybe sent on recovery for completed\n        // apps, ignore it.\n        LOG.warn(\"Couldn't find application \" + applicationId);\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\"Cannot finish application \" + \"from non-leaf queue: \" + queue\n            .getQueueName());\n      } else{\n        queue.finishApplication(applicationId, application.getUser());\n      }\n      application.stop(finalState);\n      applications.remove(applicationId);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate": "  protected void nodeUpdate(RMNode rmNode) {\n    try {\n      readLock.lock();\n      setLastNodeUpdateTime(Time.now());\n      super.nodeUpdate(rmNode);\n    } finally {\n      readLock.unlock();\n    }\n\n    // Try to do scheduling\n    if (!scheduleAsynchronously) {\n      try {\n        writeLock.lock();\n        ActivitiesLogger.NODE.startNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n\n        // reset allocation and reservation stats before we start doing any\n        // work\n        updateSchedulerHealth(lastNodeUpdateTime, rmNode.getNodeID(),\n            CSAssignment.NULL_ASSIGNMENT);\n\n        allocateContainersToNode(rmNode.getNodeID(), true);\n        ActivitiesLogger.NODE.finishNodeUpdateRecording(activitiesManager,\n            rmNode.getNodeID());\n      } finally {\n        writeLock.unlock();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.resolveReservationQueueName": "  private String resolveReservationQueueName(String queueName,\n      ApplicationId applicationId, ReservationId reservationID,\n      boolean isRecovering) {\n    try {\n      readLock.lock();\n      CSQueue queue = getQueue(queueName);\n      // Check if the queue is a plan queue\n      if ((queue == null) || !(queue instanceof PlanQueue)) {\n        return queueName;\n      }\n      if (reservationID != null) {\n        String resQName = reservationID.toString();\n        queue = getQueue(resQName);\n        if (queue == null) {\n          // reservation has terminated during failover\n          if (isRecovering && conf.getMoveOnExpiry(\n              getQueue(queueName).getQueuePath())) {\n            // move to the default child queue of the plan\n            return getDefaultReservationQueueName(queueName);\n          }\n          String message = \"Application \" + applicationId\n              + \" submitted to a reservation which is not currently active: \"\n              + resQName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        if (!queue.getParent().getQueueName().equals(queueName)) {\n          String message =\n              \"Application: \" + applicationId + \" submitted to a reservation \"\n                  + resQName + \" which does not belong to the specified queue: \"\n                  + queueName;\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.APP_REJECTED,\n                  message));\n          return null;\n        }\n        // use the reservation queue to run the app\n        queueName = resQName;\n      } else{\n        // use the default child queue of the plan for unreserved apps\n        queueName = getDefaultReservationQueueName(queueName);\n      }\n      return queueName;\n    } finally {\n      readLock.unlock();\n    }\n\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt": "  private void doneApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      RMAppAttemptState rmAppAttemptFinalState, boolean keepContainers) {\n    try {\n      writeLock.lock();\n      LOG.info(\"Application Attempt \" + applicationAttemptId + \" is done.\"\n          + \" finalState=\" + rmAppAttemptFinalState);\n\n      FiCaSchedulerApp attempt = getApplicationAttempt(applicationAttemptId);\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n\n      if (application == null || attempt == null) {\n        LOG.info(\n            \"Unknown application \" + applicationAttemptId + \" has completed!\");\n        return;\n      }\n\n      // Release all the allocated, acquired, running containers\n      for (RMContainer rmContainer : attempt.getLiveContainers()) {\n        if (keepContainers && rmContainer.getState().equals(\n            RMContainerState.RUNNING)) {\n          // do not kill the running container in the case of work-preserving AM\n          // restart.\n          LOG.info(\"Skip killing \" + rmContainer.getContainerId());\n          continue;\n        }\n        super.completedContainer(rmContainer, SchedulerUtils\n                .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                    SchedulerUtils.COMPLETED_APPLICATION),\n            RMContainerEventType.KILL);\n      }\n\n      // Release all reserved containers\n      for (RMContainer rmContainer : attempt.getReservedContainers()) {\n        super.completedContainer(rmContainer, SchedulerUtils\n            .createAbnormalContainerStatus(rmContainer.getContainerId(),\n                \"Application Complete\"), RMContainerEventType.KILL);\n      }\n\n      // Clean up pending requests, metrics etc.\n      attempt.stop(rmAppAttemptFinalState);\n\n      // Inform the queue\n      String queueName = attempt.getQueue().getQueueName();\n      CSQueue queue = this.getQueue(queueName);\n      if (!(queue instanceof LeafQueue)) {\n        LOG.error(\n            \"Cannot finish application \" + \"from non-leaf queue: \" + queueName);\n      } else{\n        queue.finishApplicationAttempt(attempt, queue.getQueueName());\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationOnRecovery": "  private void addApplicationOnRecovery(\n      ApplicationId applicationId, String queueName, String user,\n      Priority priority) {\n    try {\n      writeLock.lock();\n      CSQueue queue = getQueue(queueName);\n      if (queue == null) {\n        //During a restart, this indicates a queue was removed, which is\n        //not presently supported\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName + \" which no longer exists after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" missing during application recovery.\"\n              + \" Queue removal during recovery is not presently \"\n              + \"supported by the capacity scheduler, please \"\n              + \"restart with all queues configured\"\n              + \" which were present before shutdown/restart.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      if (!(queue instanceof LeafQueue)) {\n        // During RM restart, this means leaf queue was converted to a parent\n        // queue, which is not supported for running apps.\n        if (!YarnConfiguration.shouldRMFailFast(getConfig())) {\n          this.rmContext.getDispatcher().getEventHandler().handle(\n              new RMAppEvent(applicationId, RMAppEventType.KILL,\n                  \"Application killed on recovery as it was submitted to queue \"\n                      + queueName\n                      + \" which is no longer a leaf queue after restart.\"));\n          return;\n        } else{\n          String queueErrorMsg = \"Queue named \" + queueName\n              + \" is no longer a leaf queue during application recovery.\"\n              + \" Changing a leaf queue to a parent queue during recovery is\"\n              + \" not presently supported by the capacity scheduler. Please\"\n              + \" restart with leaf queues before shutdown/restart continuing\"\n              + \" as leaf queues.\";\n          LOG.fatal(queueErrorMsg);\n          throw new QueueInvalidException(queueErrorMsg);\n        }\n      }\n      // Submit to the queue\n      try {\n        queue.submitApplication(applicationId, user, queueName);\n      } catch (AccessControlException ace) {\n        // Ignore the exception for recovered app as the app was previously\n        // accepted.\n      }\n      queue.getMetrics().submitApp(user);\n      SchedulerApplication<FiCaSchedulerApp> application =\n          new SchedulerApplication<FiCaSchedulerApp>(queue, user, priority);\n      applications.put(applicationId, application);\n      LOG.info(\"Accepted application \" + applicationId + \" from user: \" + user\n          + \", in queue: \" + queueName);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            applicationId + \" is recovering. Skip notifying APP_ACCEPTED\");\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForKillable": "  public void markContainerForKillable(\n      RMContainer killableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_KILLABLE + \": container\"\n            + killableContainer.toString());\n      }\n\n      if (!isLazyPreemptionEnabled) {\n        super.completedContainer(killableContainer, SchedulerUtils\n            .createPreemptedContainerStatus(killableContainer.getContainerId(),\n                SchedulerUtils.PREEMPTED_CONTAINER), RMContainerEventType.KILL);\n      } else{\n        FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n            killableContainer.getAllocatedNode());\n\n        FiCaSchedulerApp application = getCurrentAttemptForContainer(\n            killableContainer.getContainerId());\n\n        node.markContainerToKillable(killableContainer.getContainerId());\n\n        // notify PreemptionManager\n        // Get the application for the finished container\n        if (null != application) {\n          String leafQueueName = application.getCSLeafQueue().getQueueName();\n          getPreemptionManager().addKillableContainer(\n              new KillableContainer(killableContainer, node.getPartition(),\n                  leafQueueName));\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForNonKillable": "  private void markContainerForNonKillable(\n      RMContainer nonKillableContainer) {\n    try {\n      writeLock.lock();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            SchedulerEventType.MARK_CONTAINER_FOR_NONKILLABLE + \": container\"\n                + nonKillableContainer.toString());\n      }\n\n      FiCaSchedulerNode node = (FiCaSchedulerNode) getSchedulerNode(\n          nonKillableContainer.getAllocatedNode());\n\n      FiCaSchedulerApp application = getCurrentAttemptForContainer(\n          nonKillableContainer.getContainerId());\n\n      node.markContainerToNonKillable(nonKillableContainer.getContainerId());\n\n      // notify PreemptionManager\n      // Get the application for the finished container\n      if (null != application) {\n        String leafQueueName = application.getCSLeafQueue().getQueueName();\n        getPreemptionManager().removeKillableContainer(\n            new KillableContainer(nonKillableContainer, node.getPartition(),\n                leafQueueName));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.markContainerForPreemption": "  public void markContainerForPreemption(ApplicationAttemptId aid,\n      RMContainer cont) {\n    if(LOG.isDebugEnabled()){\n      LOG.debug(SchedulerEventType.MARK_CONTAINER_FOR_PREEMPTION\n            + \": appAttempt:\" + aid.toString() + \" container: \"\n            + cont.toString());\n    }\n    FiCaSchedulerApp app = getApplicationAttempt(aid);\n    if (app != null) {\n      app.markContainerForPreemption(cont.getContainerId());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.updateNodeAndQueueResource": "  private void updateNodeAndQueueResource(RMNode nm,\n      ResourceOption resourceOption) {\n    try {\n      writeLock.lock();\n      updateNodeResource(nm, resourceOption);\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt": "  private void addApplicationAttempt(\n      ApplicationAttemptId applicationAttemptId,\n      boolean transferStateFromPreviousAttempt,\n      boolean isAttemptRecovering) {\n    try {\n      writeLock.lock();\n      SchedulerApplication<FiCaSchedulerApp> application = applications.get(\n          applicationAttemptId.getApplicationId());\n      if (application == null) {\n        LOG.warn(\"Application \" + applicationAttemptId.getApplicationId()\n            + \" cannot be found in scheduler.\");\n        return;\n      }\n      CSQueue queue = (CSQueue) application.getQueue();\n\n      FiCaSchedulerApp attempt = new FiCaSchedulerApp(applicationAttemptId,\n          application.getUser(), queue, queue.getAbstractUsersManager(),\n          rmContext, application.getPriority(), isAttemptRecovering,\n          activitiesManager);\n      if (transferStateFromPreviousAttempt) {\n        attempt.transferStateFromPreviousAttempt(\n            application.getCurrentAppAttempt());\n      }\n      application.setCurrentAppAttempt(attempt);\n\n      // Update attempt priority to the latest to avoid race condition i.e\n      // SchedulerApplicationAttempt is created with old priority but it is not\n      // set to SchedulerApplication#setCurrentAppAttempt.\n      // Scenario would occur is\n      // 1. SchdulerApplicationAttempt is created with old priority.\n      // 2. updateApplicationPriority() updates SchedulerApplication. Since\n      // currentAttempt is null, it just return.\n      // 3. ScheduelerApplcationAttempt is set in\n      // SchedulerApplication#setCurrentAppAttempt.\n      attempt.setPriority(application.getPriority());\n\n      queue.submitApplicationAttempt(attempt, application.getUser());\n      LOG.info(\"Added Application Attempt \" + applicationAttemptId\n          + \" to scheduler from user \" + application.getUser() + \" in queue \"\n          + queue.getQueueName());\n      if (isAttemptRecovering) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(applicationAttemptId\n              + \" is recovering. Skipping notifying ATTEMPT_ADDED\");\n        }\n      } else{\n        rmContext.getDispatcher().getEventHandler().handle(\n            new RMAppAttemptEvent(applicationAttemptId,\n                RMAppAttemptEventType.ATTEMPT_ADDED));\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.removeNode": "  private void removeNode(RMNode nodeInfo) {\n    try {\n      writeLock.lock();\n      // update this node to node label manager\n      if (labelManager != null) {\n        labelManager.deactivateNode(nodeInfo.getNodeID());\n      }\n\n      NodeId nodeId = nodeInfo.getNodeID();\n      FiCaSchedulerNode node = nodeTracker.getNode(nodeId);\n      if (node == null) {\n        LOG.error(\"Attempting to remove non-existent node \" + nodeId);\n        return;\n      }\n\n      // Remove running containers\n      List<RMContainer> runningContainers =\n          node.getCopiedListOfRunningContainers();\n      for (RMContainer container : runningContainers) {\n        super.completedContainer(container, SchedulerUtils\n            .createAbnormalContainerStatus(container.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      // Remove reservations, if any\n      RMContainer reservedContainer = node.getReservedContainer();\n      if (reservedContainer != null) {\n        super.completedContainer(reservedContainer, SchedulerUtils\n            .createAbnormalContainerStatus(reservedContainer.getContainerId(),\n                SchedulerUtils.LOST_CONTAINER), RMContainerEventType.KILL);\n      }\n\n      nodeTracker.removeNode(nodeId);\n      Resource clusterResource = getClusterResource();\n      getRootQueue().updateClusterResource(clusterResource,\n          new ResourceLimits(clusterResource));\n      int numNodes = nodeTracker.nodeCount();\n\n      if (scheduleAsynchronously && numNodes == 0) {\n        for (AsyncScheduleThread t : asyncSchedulerThreads) {\n          t.suspendSchedule();\n        }\n      }\n\n      LOG.info(\n          \"Removed node \" + nodeInfo.getNodeAddress() + \" clusterResource: \"\n              + getClusterResource());\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.run": "      public Void run() throws Exception {\n        try {\n          startActiveServices();\n          return null;\n        } catch (Exception e) {\n          reinitialize(true);\n          throw e;\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.reinitialize": "  void reinitialize(boolean initialize) {\n    ClusterMetrics.destroy();\n    QueueMetrics.clearQueueMetrics();\n    if (initialize) {\n      resetRMContext();\n      createAndInitActiveServices(true);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices": "  void startActiveServices() throws Exception {\n    if (activeServices != null) {\n      clusterTimeStamp = System.currentTimeMillis();\n      activeServices.start();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToStandby": "  synchronized void transitionToStandby(boolean initialize)\n      throws Exception {\n    if (rmContext.getHAServiceState() ==\n        HAServiceProtocol.HAServiceState.STANDBY) {\n      LOG.info(\"Already in standby state\");\n      return;\n    }\n\n    LOG.info(\"Transitioning to standby state\");\n    HAServiceState state = rmContext.getHAServiceState();\n    rmContext.setHAServiceState(HAServiceProtocol.HAServiceState.STANDBY);\n    if (state == HAServiceProtocol.HAServiceState.ACTIVE) {\n      stopActiveServices();\n      reinitialize(initialize);\n    }\n    LOG.info(\"Transitioned to standby state\");\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue.completedContainer": "  public void completedContainer(Resource clusterResource,\n      FiCaSchedulerApp application, FiCaSchedulerNode node, \n      RMContainer container, ContainerStatus containerStatus, \n      RMContainerEventType event, CSQueue childQueue,\n      boolean sortQueues);\n\n  /**\n   * Get the number of applications in the queue.\n   * @return number of applications\n   */\n  public int getNumApplications();\n\n  \n  /**\n   * Reinitialize the queue.\n   * @param newlyParsedQueue new queue to re-initalize from\n   * @param clusterResource resources in the cluster\n   */\n  public void reinitialize(CSQueue newlyParsedQueue, Resource clusterResource) \n  throws IOException;\n\n   /**\n   * Update the cluster resource for queues as we add/remove nodes\n   * @param clusterResource the current cluster resource\n   * @param resourceLimits the current ResourceLimits\n   */\n  public void updateClusterResource(Resource clusterResource,\n      ResourceLimits resourceLimits);\n  \n  /**\n   * Get the {@link AbstractUsersManager} for the queue.",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.removeRMContainer": "  public void removeRMContainer(ContainerId containerId) {\n    try {\n      writeLock.lock();\n      RMContainer rmContainer = liveContainers.remove(containerId);\n      if (rmContainer != null) {\n        if (rmContainer.getExecutionType() == ExecutionType.OPPORTUNISTIC) {\n          this.attemptOpportunisticResourceUsage\n              .decUsed(rmContainer.getAllocatedResource());\n        }\n        if (rmContainer.isRemotelyAllocated()) {\n          this.attemptResourceUsageAllocatedRemotely\n              .decUsed(rmContainer.getAllocatedResource());\n        }\n      }\n    } finally {\n      writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.isHAEnabled": "  boolean isHAEnabled();\n\n  HAServiceState getHAServiceState();\n\n  RMStateStore getStateStore();\n\n  ConcurrentMap<ApplicationId, RMApp> getRMApps();\n  \n  ConcurrentMap<ApplicationId, ByteBuffer> getSystemCredentialsForApps();\n\n  ConcurrentMap<NodeId, RMNode> getInactiveRMNodes();\n\n  ConcurrentMap<NodeId, RMNode> getRMNodes();\n\n  AMLivelinessMonitor getAMLivelinessMonitor();\n\n  AMLivelinessMonitor getAMFinishingMonitor();\n\n  ContainerAllocationExpirer getContainerAllocationExpirer();\n  \n  DelegationTokenRenewer getDelegationTokenRenewer();\n\n  AMRMTokenSecretManager getAMRMTokenSecretManager();\n\n  RMContainerTokenSecretManager getContainerTokenSecretManager();\n  \n  NMTokenSecretManagerInRM getNMTokenSecretManager();\n\n  ResourceScheduler getScheduler();\n\n  NodesListManager getNodesListManager();\n\n  ClientToAMTokenSecretManagerInRM getClientToAMTokenSecretManager();\n\n  AdminService getRMAdminService();\n\n  ClientRMService getClientRMService();\n\n  ApplicationMasterService getApplicationMasterService();\n\n  ResourceTrackerService getResourceTrackerService();\n\n  void setClientRMService(ClientRMService clientRMService);\n\n  RMDelegationTokenSecretManager getRMDelegationTokenSecretManager();\n\n  void setRMDelegationTokenSecretManager(\n      RMDelegationTokenSecretManager delegationTokenSecretManager);\n\n  RMApplicationHistoryWriter getRMApplicationHistoryWriter();\n\n  void setRMApplicationHistoryWriter(\n      RMApplicationHistoryWriter rmApplicationHistoryWriter);\n\n  void setSystemMetricsPublisher(SystemMetricsPublisher systemMetricsPublisher);\n\n  SystemMetricsPublisher getSystemMetricsPublisher();\n\n  void setRMTimelineCollectorManager(\n      RMTimelineCollectorManager timelineCollectorManager);\n\n  RMTimelineCollectorManager getRMTimelineCollectorManager();\n\n  ConfigurationProvider getConfigurationProvider();\n\n  boolean isWorkPreservingRecoveryEnabled();\n  \n  RMNodeLabelsManager getNodeLabelManager();\n  \n  public void setNodeLabelManager(RMNodeLabelsManager mgr);\n\n  RMDelegatedNodeLabelsUpdater getRMDelegatedNodeLabelsUpdater();\n\n  void setRMDelegatedNodeLabelsUpdater(\n      RMDelegatedNodeLabelsUpdater nodeLabelsUpdater);\n\n  long getEpoch();\n\n  ReservationSystem getReservationSystem();\n\n  boolean isSchedulerReadyForAllocatingContainers();\n  \n  Configuration getYarnConfiguration();\n  \n  PlacementManager getQueuePlacementManager();\n  \n  void setQueuePlacementManager(PlacementManager placementMgr);\n\n  void setLeaderElectorService(EmbeddedElector elector);\n\n  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.rmContext.getLeaderElectorService": "  EmbeddedElector getLeaderElectorService();\n\n  QueueLimitCalculator getNodeManagerQueueLimitCalculator();\n\n  void setRMAppLifetimeMonitor(RMAppLifetimeMonitor rmAppLifetimeMonitor);\n\n  RMAppLifetimeMonitor getRMAppLifetimeMonitor();\n\n  String getHAZookeeperConnectionState();\n\n  ResourceManager getResourceManager();\n\n  ResourceProfilesManager getResourceProfilesManager();\n\n  void setResourceProfilesManager(ResourceProfilesManager mgr);\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-resourcemanager.src.main.java.org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElector.rejoinElection": "  void rejoinElection();\n\n  /**\n   * Get information about the elector's connection to Zookeeper.\n   *\n   * @return zookeeper connection state\n   */\n  String getZookeeperConnectionState();\n}"
        },
        "bug_report": {
            "Title": "Fix CapacityScheduler NPE issue when a container preempted while the node is being removed",
            "Description": "This issue could happen when 3 conditions satisfied:\n\n1) A node is removing from scheduler.\n2) A container running on the node is being preempted. \n3) A rare race condition causes scheduler pass a null node to leaf queue.\n\nFix of the problem is to add a null node check inside CapacityScheduler.\n\nStack trace:\n{code}\n2017-08-31 02:51:24,748 FATAL resourcemanager.ResourceManager (ResourceManager.java:run(714)) - Error in handling event type KILL_RESERVED_CONTAINER to the scheduler \njava.lang.NullPointerException \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer(LeafQueue.java:1308) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal(CapacityScheduler.java:1469) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer(AbstractYarnScheduler.java:497) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.killReservedContainer(CapacityScheduler.java:1505) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1341) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:127) \nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:705) \n{code}\n\nThis is an issue only existed in 2.8.x"
        }
    },
    {
        "filename": "YARN-4598.json",
        "creation_time": "2016-01-15T06:48:48.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: RESOURCE_FAILED at CONTAINER_CLEANEDUP_AFTER_KILL                                       \n    at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)                                                                  \n    at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)                                                                     \n    at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)                                             \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1127)                                           \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:83)                                             \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1078)              \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1071)              \n    at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:175)                                                                              \n    at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:108)                                                                                 \n    at java.lang.Thread.run(Thread.java:744)                                                                                                                        \n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitionException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle": "  public void handle(ContainerEvent event) {\n    try {\n      this.writeLock.lock();\n\n      ContainerId containerID = event.getContainerID();\n      LOG.debug(\"Processing \" + containerID + \" of type \" + event.getType());\n\n      ContainerState oldState = stateMachine.getCurrentState();\n      ContainerState newState = null;\n      try {\n        newState =\n            stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitionException e) {\n        LOG.warn(\"Can't handle this event at current state: Current: [\"\n            + oldState + \"], eventType: [\" + event.getType() + \"]\", e);\n      }\n      if (oldState != newState) {\n        LOG.info(\"Container \" + containerID + \" transitioned from \"\n            + oldState\n            + \" to \" + newState);\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.getCurrentState": "  public org.apache.hadoop.yarn.api.records.ContainerState getCurrentState() {\n    switch (stateMachine.getCurrentState()) {\n    case NEW:\n    case LOCALIZING:\n    case LOCALIZATION_FAILED:\n    case LOCALIZED:\n    case RUNNING:\n    case EXITED_WITH_SUCCESS:\n    case EXITED_WITH_FAILURE:\n    case KILLING:\n    case CONTAINER_CLEANEDUP_AFTER_KILL:\n    case CONTAINER_RESOURCES_CLEANINGUP:\n      return org.apache.hadoop.yarn.api.records.ContainerState.RUNNING;\n    case DONE:\n    default:\n      return org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE;\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        String diagnostic = \"\";\n        if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Application killed on shutdown\";\n        } else if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Application killed by ResourceManager\";\n        }\n        try {\n          this.context.getNMStateStore().storeFinishedApplication(appID);\n        } catch (IOException e) {\n          LOG.error(\"Unable to update application state in store\", e);\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                diagnostic));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId container : containersFinishedEvent\n          .getContainersToCleanup()) {\n          this.dispatcher.getEventHandler().handle(\n              new ContainerKillEvent(container,\n                  ContainerExitStatus.KILLED_BY_RESOURCEMANAGER,\n                  \"Container Killed by ResourceManager\"));\n      }\n      break;\n    case DECREASE_CONTAINERS_RESOURCE:\n      CMgrDecreaseContainersResourceEvent containersDecreasedEvent =\n          (CMgrDecreaseContainersResourceEvent) event;\n      for (org.apache.hadoop.yarn.api.records.Container container\n          : containersDecreasedEvent.getContainersToDecrease()) {\n        try {\n          changeContainerResourceInternal(container.getId(),\n              container.getResource(), false);\n        } catch (YarnException e) {\n          LOG.error(\"Unable to decrease container resource\", e);\n        } catch (IOException e) {\n          LOG.error(\"Unable to update container resource in store\", e);\n        }\n      }\n      break;\n    case SIGNAL_CONTAINERS:\n      CMgrSignalContainersEvent containersSignalEvent =\n          (CMgrSignalContainersEvent) event;\n      for (SignalContainerRequest request : containersSignalEvent\n          .getContainersToSignal()) {\n        ContainerId containerId = request.getContainerId();\n        Container container = this.context.getContainers().get(containerId);\n        if (container != null) {\n          LOG.info(containerId + \" signal request by ResourceManager.\");\n          this.dispatcher.getEventHandler().handle(\n              new SignalContainersLauncherEvent(container,\n                  request.getCommand()));\n        } else {\n          LOG.info(\"Container \" + containerId + \" no longer exists\");\n        }\n      }\n      break;\n    default:\n        throw new YarnRuntimeException(\n            \"Got an unknown ContainerManagerEvent type: \" + event.getType());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.changeContainerResourceInternal": "  private void changeContainerResourceInternal(\n      ContainerId containerId, Resource targetResource, boolean increase)\n          throws YarnException, IOException {\n    Container container = context.getContainers().get(containerId);\n    // Check container existence\n    if (container == null) {\n      if (nodeStatusUpdater.isContainerRecentlyStopped(containerId)) {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" was recently stopped on node manager.\");\n      } else {\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" is not handled by this NodeManager\");\n      }\n    }\n    // Check container state\n    org.apache.hadoop.yarn.server.nodemanager.\n        containermanager.container.ContainerState currentState =\n        container.getContainerState();\n    if (currentState != org.apache.hadoop.yarn.server.\n        nodemanager.containermanager.container.ContainerState.RUNNING) {\n      throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n          + \" is in \" + currentState.name() + \" state.\"\n          + \" Resource can only be changed when a container is in\"\n          + \" RUNNING state\");\n    }\n    // Check validity of the target resource.\n    Resource currentResource = container.getResource();\n    if (currentResource.equals(targetResource)) {\n      LOG.warn(\"Unable to change resource for container \"\n          + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is the same as the current resource\");\n      return;\n    }\n    if (increase && !Resources.fitsIn(currentResource, targetResource)) {\n      throw RPCUtil.getRemoteException(\"Unable to increase resource for \"\n          + \"container \" + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is smaller than the current resource \"\n          + currentResource.toString());\n    }\n    if (!increase &&\n        (!Resources.fitsIn(Resources.none(), targetResource)\n            || !Resources.fitsIn(targetResource, currentResource))) {\n      throw RPCUtil.getRemoteException(\"Unable to decrease resource for \"\n          + \"container \" + containerId.toString()\n          + \". The target resource \"\n          + targetResource.toString()\n          + \" is not smaller than the current resource \"\n          + currentResource.toString());\n    }\n    if (increase) {\n      org.apache.hadoop.yarn.api.records.Container increasedContainer =\n          org.apache.hadoop.yarn.api.records.Container.newInstance(\n              containerId, null, null, targetResource, null, null);\n      if (context.getIncreasedContainers().putIfAbsent(containerId,\n          increasedContainer) != null){\n        throw RPCUtil.getRemoteException(\"Container \" + containerId.toString()\n            + \" resource is being increased.\");\n      }\n    }\n    this.readLock.lock();\n    try {\n      if (!serviceStopped) {\n        // Persist container resource change for recovery\n        this.context.getNMStateStore().storeContainerResourceChanged(\n            containerId, targetResource);\n        getContainersMonitor().handle(\n            new ChangeMonitoringContainerResourceEvent(\n                containerId, targetResource));\n      } else {\n        throw new YarnException(\n            \"Unable to change container resource as the NodeManager is \"\n                + \"in the process of shutting down\");\n      }\n    } finally {\n      this.readLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    } catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      // If serviceStop is called, we should exit this thread gracefully.\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false\n          && stopped == false) {\n        Thread shutDownThread = new Thread(createShutDownThread());\n        shutDownThread.setName(\"AsyncDispatcher ShutDown handler\");\n        shutDownThread.start();\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.createShutDownThread": "  Runnable createShutDownThread() {\n    return new Runnable() {\n      @Override\n      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    };\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "Invalid event: RESOURCE_FAILED at CONTAINER_CLEANEDUP_AFTER_KILL",
            "Description": "In our cluster, I found that the container has some problems in state transition\uff0cthis is my log\n{noformat}\n2016-01-12 17:42:50,088 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1452588902899_0001_01_000087 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n2016-01-12 17:42:50,088 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Can't handle this event at current state: Current: \n[CONTAINER_CLEANEDUP_AFTER_KILL], eventType: [RESOURCE_FAILED]\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: RESOURCE_FAILED at CONTAINER_CLEANEDUP_AFTER_KILL                                       \n    at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)                                                                  \n    at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)                                                                     \n    at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)                                             \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1127)                                           \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:83)                                             \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1078)              \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1071)              \n    at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:175)                                                                              \n    at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:108)                                                                                 \n    at java.lang.Thread.run(Thread.java:744)                                                                                                                        \n2016-01-12 17:42:50,089 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1452588902899_0001_01_000094 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to null\n2016-01-12 17:42:50,089 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=hadoop   OPERATION=Container Finished - Killed   TARGET=ContainerImpl    \nRESULT=SUCCESS  APPID=application_1452588902899_0001    CONTAINERID=container_1452588902899_0001_01_000094                                                          \n2016-01-12 17:42:50,089 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1452588902899_0001_01_000094 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE \n{noformat}"
        }
    },
    {
        "filename": "YARN-1149.json",
        "creation_time": "2013-09-04T21:46:58.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FINISHED at RUNNING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305) \n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:425)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:59)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:697)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:689)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:134)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:81)   \n        at java.lang.Thread.run(Thread.java:662)\n```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.state.StateMachineFactory.doTransition": "    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)\n         throws InvalidStateTransitonException  {\n      currentState = StateMachineFactory.this.doTransition\n          (operand, currentState, eventType, event);\n      return currentState;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle": "  public void handle(ApplicationEvent event) {\n\n    this.writeLock.lock();\n\n    try {\n      ApplicationId applicationID = event.getApplicationID();\n      LOG.debug(\"Processing \" + applicationID + \" of type \" + event.getType());\n\n      ApplicationState oldState = stateMachine.getCurrentState();\n      ApplicationState newState = null;\n      try {\n        // queue event requesting init of the same app\n        newState = stateMachine.doTransition(event.getType(), event);\n      } catch (InvalidStateTransitonException e) {\n        LOG.warn(\"Can't handle this event at current state\", e);\n      }\n      if (oldState != newState) {\n        LOG.info(\"Application \" + applicationID + \" transitioned from \"\n            + oldState + \" to \" + newState);\n      }\n    } finally {\n      this.writeLock.unlock();\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle": "  public void handle(ContainerManagerEvent event) {\n    switch (event.getType()) {\n    case FINISH_APPS:\n      CMgrCompletedAppsEvent appsFinishedEvent =\n          (CMgrCompletedAppsEvent) event;\n      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {\n        this.dispatcher.getEventHandler().handle(\n            new ApplicationFinishEvent(appID,\n                \"Application Killed by ResourceManager\"));\n      }\n      break;\n    case FINISH_CONTAINERS:\n      CMgrCompletedContainersEvent containersFinishedEvent =\n          (CMgrCompletedContainersEvent) event;\n      for (ContainerId container : containersFinishedEvent\n          .getContainersToCleanup()) {\n        String diagnostic = \"\";\n        if (containersFinishedEvent.getReason() == \n            CMgrCompletedContainersEvent.Reason.ON_SHUTDOWN) {\n          diagnostic = \"Container Killed on Shutdown\";\n        } else if (containersFinishedEvent.getReason() == \n            CMgrCompletedContainersEvent.Reason.BY_RESOURCEMANAGER) {\n          diagnostic = \"Container Killed by ResourceManager\";\n        }\n        this.dispatcher.getEventHandler().handle(\n            new ContainerKillEvent(container, diagnostic));\n      }\n      break;\n    default:\n      LOG.warn(\"Invalid event \" + event.getType() + \". Ignoring.\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch": "  protected void dispatch(Event event) {\n    //all events go thru this loop\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Dispatching the event \" + event.getClass().getName() + \".\"\n          + event.toString());\n    }\n\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\n\n    try{\n      EventHandler handler = eventDispatchers.get(type);\n      if(handler != null) {\n        handler.handle(event);\n      } else {\n        throw new Exception(\"No handler for registered for \" + type);\n      }\n    }\n    catch (Throwable t) {\n      //TODO Maybe log the state of the queue\n      LOG.fatal(\"Error in dispatcher thread\", t);\n      if (exitOnDispatchException\n          && (ShutdownHookManager.get().isShutdownInProgress()) == false) {\n        LOG.info(\"Exiting, bbye..\");\n        System.exit(-1);\n      }\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.handle": "    public void handle(Event event) {\n      for (EventHandler<Event> handler: listofHandlers) {\n        handler.handle(event);\n      }\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.AsyncDispatcher.run": "      public void run() {\n        while (!stopped && !Thread.currentThread().isInterrupted()) {\n          Event event;\n          try {\n            event = eventQueue.take();\n          } catch(InterruptedException ie) {\n            if (!stopped) {\n              LOG.warn(\"AsyncDispatcher thread interrupted\", ie);\n            }\n            return;\n          }\n          if (event != null) {\n            dispatch(event);\n          }\n        }\n      }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.getType": "  TYPE getType();\n  long getTimestamp();\n  String toString();\n}",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-common.src.main.java.org.apache.hadoop.yarn.event.Event.toString": "  String toString();\n}"
        },
        "bug_report": {
            "Title": "NM throws InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FINISHED at RUNNING",
            "Description": "When nodemanager receives a kill signal when an application has finished execution but log aggregation has not kicked in, InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FINISHED at RUNNING is thrown\n\n{noformat}\n2013-08-25 20:45:00,875 INFO  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:finishLogAggregation(254)) - Application just finished : application_1377459190746_0118\n2013-08-25 20:45:00,876 INFO  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:uploadLogsForContainer(105)) - Starting aggregate log-file for app application_1377459190746_0118 at /app-logs/foo/logs/application_1377459190746_0118/<host>_45454.tmp\n2013-08-25 20:45:00,876 INFO  logaggregation.LogAggregationService (LogAggregationService.java:stopAggregators(151)) - Waiting for aggregation to complete for application_1377459190746_0118\n2013-08-25 20:45:00,891 INFO  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:uploadLogsForContainer(122)) - Uploading logs for container container_1377459190746_0118_01_000004. Current good log dirs are /tmp/yarn/local\n2013-08-25 20:45:00,915 INFO  logaggregation.AppLogAggregatorImpl (AppLogAggregatorImpl.java:doAppLogAggregation(182)) - Finished aggregate log-file for app application_1377459190746_0118\n2013-08-25 20:45:00,925 WARN  application.Application (ApplicationImpl.java:handle(427)) - Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FINISHED at RUNNING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305) \n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:425)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:59)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:697)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:689)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:134)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:81)   \n        at java.lang.Thread.run(Thread.java:662)\n2013-08-25 20:45:00,926 INFO  application.Application (ApplicationImpl.java:handle(430)) - Application application_1377459190746_0118 transitioned from RUNNING to null\n2013-08-25 20:45:00,927 WARN  monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:run(463)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.\n2013-08-25 20:45:00,938 INFO  ipc.Server (Server.java:stop(2437)) - Stopping server on 8040\n{noformat}\n\n"
        }
    },
    {
        "filename": "YARN-7818.json",
        "creation_time": "2018-01-25T18:42:55.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=143:\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:180)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.launchContainer(DefaultLinuxContainerRuntime.java:124)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.launchContainer(DelegatingLinuxContainerRuntime.java:152)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:549)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:465)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:285)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:95)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\nCaused by: ExitCodeException exitCode=143:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)```",
        "source_code": {
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation": "  public String executePrivilegedOperation(PrivilegedOperation operation,\n      boolean grabOutput) throws PrivilegedOperationException {\n    return executePrivilegedOperation(null, operation, null, null, grabOutput,\n        false);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.getPrivilegedOperationExecutionCommand": "  public String[] getPrivilegedOperationExecutionCommand(List<String>\n      prefixCommands,\n      PrivilegedOperation operation) {\n    List<String> fullCommand = new ArrayList<String>();\n\n    if (prefixCommands != null && !prefixCommands.isEmpty()) {\n      fullCommand.addAll(prefixCommands);\n    }\n\n    fullCommand.add(containerExecutorExe);\n\n    String cliSwitch = operation.getOperationType().getOption();\n\n    if (!cliSwitch.isEmpty()) {\n      fullCommand.add(cliSwitch);\n    }\n\n    fullCommand.addAll(operation.getArguments());\n\n    String[] fullCommandArray =\n        fullCommand.toArray(new String[fullCommand.size()]);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Privileged Execution Command Array: \" +\n          Arrays.toString(fullCommandArray));\n    }\n\n    return fullCommandArray;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.launchContainer": "  public void launchContainer(ContainerRuntimeContext ctx)\n      throws ContainerExecutionException {\n    PrivilegedOperation launchOp = new PrivilegedOperation(\n        PrivilegedOperation.OperationType.LAUNCH_CONTAINER);\n\n    //All of these arguments are expected to be available in the runtime context\n    launchOp.appendArgs(ctx.getExecutionAttribute(RUN_AS_USER),\n        ctx.getExecutionAttribute(USER),\n        Integer.toString(PrivilegedOperation.\n            RunAsUserCommand.LAUNCH_CONTAINER.getValue()),\n        ctx.getExecutionAttribute(APPID),\n        ctx.getExecutionAttribute(CONTAINER_ID_STR),\n        ctx.getExecutionAttribute(CONTAINER_WORK_DIR).toString(),\n        ctx.getExecutionAttribute(NM_PRIVATE_CONTAINER_SCRIPT_PATH).toUri()\n            .getPath(),\n        ctx.getExecutionAttribute(NM_PRIVATE_TOKENS_PATH).toUri().getPath(),\n        ctx.getExecutionAttribute(PID_FILE_PATH).toString(),\n        StringUtils.join(PrivilegedOperation.LINUX_FILE_PATH_SEPARATOR,\n            ctx.getExecutionAttribute(LOCAL_DIRS)),\n        StringUtils.join(PrivilegedOperation.LINUX_FILE_PATH_SEPARATOR,\n            ctx.getExecutionAttribute(LOG_DIRS)),\n        ctx.getExecutionAttribute(RESOURCES_OPTIONS));\n\n    String tcCommandFile = ctx.getExecutionAttribute(TC_COMMAND_FILE);\n\n    if (tcCommandFile != null) {\n      launchOp.appendArgs(tcCommandFile);\n    }\n\n    //List<String> -> stored as List -> fetched/converted to List<String>\n    //we can't do better here thanks to type-erasure\n    @SuppressWarnings(\"unchecked\")\n    List<String> prefixCommands = (List<String>) ctx.getExecutionAttribute(\n        CONTAINER_LAUNCH_PREFIX_COMMANDS);\n\n    try {\n      privilegedOperationExecutor.executePrivilegedOperation(prefixCommands,\n            launchOp, null, null, false, false);\n    } catch (PrivilegedOperationException e) {\n      LOG.warn(\"Launch container failed. Exception: \", e);\n\n      throw new ContainerExecutionException(\"Launch container failed\", e\n          .getExitCode(), e.getOutput(), e.getErrorOutput());\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.launchContainer": "  public void launchContainer(ContainerRuntimeContext ctx)\n      throws ContainerExecutionException {\n    Container container = ctx.getContainer();\n    LinuxContainerRuntime runtime = pickContainerRuntime(container);\n\n    runtime.launchContainer(ctx);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.pickContainerRuntime": "  private LinuxContainerRuntime pickContainerRuntime(Container container)\n      throws ContainerExecutionException {\n    return pickContainerRuntime(container.getLaunchContext().getEnvironment());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer": "  public int launchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    Container container = ctx.getContainer();\n    String user = ctx.getUser();\n\n    verifyUsernamePattern(user);\n\n    ContainerId containerId = container.getContainerId();\n\n    resourcesHandler.preExecute(containerId,\n            container.getResource());\n    String resourcesOptions = resourcesHandler.getResourcesOption(containerId);\n    String tcCommandFile = null;\n\n    try {\n      if (resourceHandlerChain != null) {\n        List<PrivilegedOperation> ops = resourceHandlerChain\n            .preStart(container);\n\n        if (ops != null) {\n          List<PrivilegedOperation> resourceOps = new ArrayList<>();\n\n          resourceOps.add(new PrivilegedOperation(\n              PrivilegedOperation.OperationType.ADD_PID_TO_CGROUP,\n                  resourcesOptions));\n\n          for (PrivilegedOperation op : ops) {\n            switch (op.getOperationType()) {\n            case ADD_PID_TO_CGROUP:\n              resourceOps.add(op);\n              break;\n            case TC_MODIFY_STATE:\n              tcCommandFile = op.getArguments().get(0);\n              break;\n            default:\n              LOG.warn(\"PrivilegedOperation type unsupported in launch: \"\n                  + op.getOperationType());\n            }\n          }\n\n          if (resourceOps.size() > 1) {\n            //squash resource operations\n            try {\n              PrivilegedOperation operation = PrivilegedOperationExecutor\n                  .squashCGroupOperations(resourceOps);\n              resourcesOptions = operation.getArguments().get(0);\n            } catch (PrivilegedOperationException e) {\n              LOG.error(\"Failed to squash cgroup operations!\", e);\n              throw new ResourceHandlerException(\n                  \"Failed to squash cgroup operations!\");\n            }\n          }\n        }\n      }\n    } catch (ResourceHandlerException e) {\n      LOG.error(\"ResourceHandlerChain.preStart() failed!\", e);\n      throw new IOException(\"ResourceHandlerChain.preStart() failed!\", e);\n    }\n\n    try {\n      Path pidFilePath = getPidFilePath(containerId);\n      if (pidFilePath != null) {\n\n        ContainerRuntimeContext runtimeContext = buildContainerRuntimeContext(\n            ctx, pidFilePath, resourcesOptions, tcCommandFile);\n\n        linuxContainerRuntime.launchContainer(runtimeContext);\n      } else {\n        LOG.info(\n            \"Container was marked as inactive. Returning terminated error\");\n        return ContainerExecutor.ExitCode.TERMINATED.getExitCode();\n      }\n    } catch (ContainerExecutionException e) {\n      int exitCode = e.getExitCode();\n      LOG.warn(\"Exit code from container \" + containerId + \" is : \" + exitCode);\n      // 143 (SIGTERM) and 137 (SIGKILL) exit codes means the container was\n      // terminated/killed forcefully. In all other cases, log the\n      // output\n      if (exitCode != ContainerExecutor.ExitCode.FORCE_KILLED.getExitCode()\n          && exitCode != ContainerExecutor.ExitCode.TERMINATED.getExitCode()) {\n        LOG.warn(\"Exception from container-launch with container ID: \"\n            + containerId + \" and exit code: \" + exitCode, e);\n\n        StringBuilder builder = new StringBuilder();\n        builder.append(\"Exception from container-launch.\\n\");\n        builder.append(\"Container id: \" + containerId + \"\\n\");\n        builder.append(\"Exit code: \" + exitCode + \"\\n\");\n        if (!Optional.fromNullable(e.getErrorOutput()).or(\"\").isEmpty()) {\n          builder.append(\"Exception message: \" + e.getErrorOutput() + \"\\n\");\n        }\n        //Skip stack trace\n        String output = e.getOutput();\n        if (output != null && !e.getOutput().isEmpty()) {\n          builder.append(\"Shell output: \" + output + \"\\n\");\n        }\n        String diagnostics = builder.toString();\n        logOutput(diagnostics);\n        container.handle(new ContainerDiagnosticsUpdateEvent(containerId,\n            diagnostics));\n        if (exitCode ==\n                ExitCode.INVALID_CONTAINER_EXEC_PERMISSIONS.getExitCode() ||\n            exitCode ==\n                ExitCode.INVALID_CONFIG_FILE.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_SCRIPT_COPY.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_CREDENTIALS_FILE.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_WORK_DIRECTORIES.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_APP_LOG_DIRECTORIES.getExitCode() ||\n            exitCode ==\n                ExitCode.COULD_NOT_CREATE_TMP_DIRECTORIES.getExitCode()) {\n          throw new ConfigurationException(\n              \"Linux Container Executor reached unrecoverable exception\", e);\n        }\n      } else {\n        container.handle(new ContainerDiagnosticsUpdateEvent(containerId,\n            \"Container killed on request. Exit code is \" + exitCode));\n      }\n      return exitCode;\n    } finally {\n      resourcesHandler.postExecute(containerId);\n\n      try {\n        if (resourceHandlerChain != null) {\n          resourceHandlerChain.postComplete(containerId);\n        }\n      } catch (ResourceHandlerException e) {\n        LOG.warn(\"ResourceHandlerChain.postComplete failed for \" +\n            \"containerId: \" + containerId + \". Exception: \" + e);\n      }\n    }\n\n    return 0;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.getExitCode": "    public int getExitCode() {\n      return code;\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.buildContainerRuntimeContext": "  private ContainerRuntimeContext buildContainerRuntimeContext(\n      ContainerStartContext ctx, Path pidFilePath,\n      String resourcesOptions, String tcCommandFile) {\n\n    List<String> prefixCommands = new ArrayList<>();\n    addSchedPriorityCommand(prefixCommands);\n\n    Container container = ctx.getContainer();\n\n    ContainerRuntimeContext.Builder builder = new ContainerRuntimeContext\n            .Builder(container);\n    if (prefixCommands.size() > 0) {\n      builder.setExecutionAttribute(CONTAINER_LAUNCH_PREFIX_COMMANDS,\n              prefixCommands);\n    }\n\n    builder.setExecutionAttribute(LOCALIZED_RESOURCES,\n        ctx.getLocalizedResources())\n      .setExecutionAttribute(RUN_AS_USER, getRunAsUser(ctx.getUser()))\n      .setExecutionAttribute(USER, ctx.getUser())\n      .setExecutionAttribute(APPID, ctx.getAppId())\n      .setExecutionAttribute(CONTAINER_ID_STR,\n        container.getContainerId().toString())\n      .setExecutionAttribute(CONTAINER_WORK_DIR, ctx.getContainerWorkDir())\n      .setExecutionAttribute(NM_PRIVATE_CONTAINER_SCRIPT_PATH,\n        ctx.getNmPrivateContainerScriptPath())\n      .setExecutionAttribute(NM_PRIVATE_TOKENS_PATH,\n        ctx.getNmPrivateTokensPath())\n      .setExecutionAttribute(PID_FILE_PATH, pidFilePath)\n      .setExecutionAttribute(LOCAL_DIRS, ctx.getLocalDirs())\n      .setExecutionAttribute(LOG_DIRS, ctx.getLogDirs())\n      .setExecutionAttribute(FILECACHE_DIRS, ctx.getFilecacheDirs())\n      .setExecutionAttribute(USER_LOCAL_DIRS, ctx.getUserLocalDirs())\n      .setExecutionAttribute(CONTAINER_LOCAL_DIRS, ctx.getContainerLocalDirs())\n      .setExecutionAttribute(CONTAINER_LOG_DIRS, ctx.getContainerLogDirs())\n      .setExecutionAttribute(RESOURCES_OPTIONS, resourcesOptions);\n\n    if (tcCommandFile != null) {\n      builder.setExecutionAttribute(TC_COMMAND_FILE, tcCommandFile);\n    }\n\n    return builder.build();\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.toString": "    public String toString() {\n      return String.valueOf(code);\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.verifyUsernamePattern": "  void verifyUsernamePattern(String user) {\n    if (!UserGroupInformation.isSecurityEnabled() &&\n        !nonsecureLocalUserPattern.matcher(user).matches()) {\n      throw new IllegalArgumentException(\"Invalid user name '\" + user + \"',\" +\n          \" it must match '\" + nonsecureLocalUserPattern.pattern() + \"'\");\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer": "  protected int launchContainer(ContainerStartContext ctx)\n      throws IOException, ConfigurationException {\n    ContainerId containerId = container.getContainerId();\n    if (container.isMarkedForKilling()) {\n      LOG.info(\"Container \" + containerId + \" not launched as it has already \"\n          + \"been marked for Killing\");\n      this.killedBeforeStart = true;\n      return ExitCode.TERMINATED.getExitCode();\n    }\n    // LaunchContainer is a blocking call. We are here almost means the\n    // container is launched, so send out the event.\n    dispatcher.getEventHandler().handle(new ContainerEvent(\n        containerId,\n        ContainerEventType.CONTAINER_LAUNCHED));\n    context.getNMStateStore().storeContainerLaunched(containerId);\n\n    // Check if the container is signalled to be killed.\n    if (!containerAlreadyLaunched.compareAndSet(false, true)) {\n      LOG.info(\"Container \" + containerId + \" not launched as \"\n          + \"cleanup already called\");\n      return ExitCode.TERMINATED.getExitCode();\n    } else {\n      exec.activateContainer(containerId, pidFilePath);\n      return exec.launchContainer(ctx);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call": "  public Integer call() {\n    if (!validateContainerState()) {\n      return 0;\n    }\n\n    final ContainerLaunchContext launchContext = container.getLaunchContext();\n    ContainerId containerID = container.getContainerId();\n    String containerIdStr = containerID.toString();\n    final List<String> command = launchContext.getCommands();\n    int ret = -1;\n\n    Path containerLogDir;\n    try {\n      Map<Path, List<String>> localResources = getLocalizedResources();\n\n      final String user = container.getUser();\n      // /////////////////////////// Variable expansion\n      // Before the container script gets written out.\n      List<String> newCmds = new ArrayList<String>(command.size());\n      String appIdStr = app.getAppId().toString();\n      String relativeContainerLogDir = ContainerLaunch\n          .getRelativeContainerLogDir(appIdStr, containerIdStr);\n      containerLogDir =\n          dirsHandler.getLogPathForWrite(relativeContainerLogDir, false);\n      recordContainerLogDir(containerID, containerLogDir.toString());\n      for (String str : command) {\n        // TODO: Should we instead work via symlinks without this grammar?\n        newCmds.add(expandEnvironment(str, containerLogDir));\n      }\n      launchContext.setCommands(newCmds);\n\n      Map<String, String> environment = launchContext.getEnvironment();\n      // Make a copy of env to iterate & do variable expansion\n      for (Entry<String, String> entry : environment.entrySet()) {\n        String value = entry.getValue();\n        value = expandEnvironment(value, containerLogDir);\n        entry.setValue(value);\n      }\n      // /////////////////////////// End of variable expansion\n\n      FileContext lfs = FileContext.getLocalFSFileContext();\n\n      Path nmPrivateContainerScriptPath = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n              + CONTAINER_SCRIPT);\n      Path nmPrivateTokensPath = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n              + String.format(ContainerLocalizer.TOKEN_FILE_NAME_FMT,\n              containerIdStr));\n      Path nmPrivateClasspathJarDir = dirsHandler.getLocalPathForWrite(\n          getContainerPrivateDir(appIdStr, containerIdStr));\n\n      // Select the working directory for the container\n      Path containerWorkDir = deriveContainerWorkDir();\n      recordContainerWorkDir(containerID, containerWorkDir.toString());\n\n      String pidFileSubpath = getPidFileSubpath(appIdStr, containerIdStr);\n      // pid file should be in nm private dir so that it is not\n      // accessible by users\n      pidFilePath = dirsHandler.getLocalPathForWrite(pidFileSubpath);\n      List<String> localDirs = dirsHandler.getLocalDirs();\n      List<String> logDirs = dirsHandler.getLogDirs();\n      List<String> filecacheDirs = getNMFilecacheDirs(localDirs);\n      List<String> userLocalDirs = getUserLocalDirs(localDirs);\n      List<String> containerLocalDirs = getContainerLocalDirs(localDirs);\n      List<String> containerLogDirs = getContainerLogDirs(logDirs);\n\n      if (!dirsHandler.areDisksHealthy()) {\n        ret = ContainerExitStatus.DISKS_FAILED;\n        throw new IOException(\"Most of the disks failed. \"\n            + dirsHandler.getDisksHealthReport(false));\n      }\n      List<Path> appDirs = new ArrayList<Path>(localDirs.size());\n      for (String localDir : localDirs) {\n        Path usersdir = new Path(localDir, ContainerLocalizer.USERCACHE);\n        Path userdir = new Path(usersdir, user);\n        Path appsdir = new Path(userdir, ContainerLocalizer.APPCACHE);\n        appDirs.add(new Path(appsdir, appIdStr));\n      }\n\n      // Set the token location too.\n      environment.put(\n          ApplicationConstants.CONTAINER_TOKEN_FILE_ENV_NAME,\n          new Path(containerWorkDir,\n              FINAL_CONTAINER_TOKENS_FILE).toUri().getPath());\n\n      // /////////// Write out the container-script in the nmPrivate space.\n      try (DataOutputStream containerScriptOutStream =\n               lfs.create(nmPrivateContainerScriptPath,\n                   EnumSet.of(CREATE, OVERWRITE))) {\n        // Sanitize the container's environment\n        sanitizeEnv(environment, containerWorkDir, appDirs, userLocalDirs,\n            containerLogDirs, localResources, nmPrivateClasspathJarDir);\n\n        prepareContainer(localResources, containerLocalDirs);\n\n        // Write out the environment\n        exec.writeLaunchEnv(containerScriptOutStream, environment,\n            localResources, launchContext.getCommands(),\n            containerLogDir, user);\n      }\n      // /////////// End of writing out container-script\n\n      // /////////// Write out the container-tokens in the nmPrivate space.\n      try (DataOutputStream tokensOutStream =\n               lfs.create(nmPrivateTokensPath, EnumSet.of(CREATE, OVERWRITE))) {\n        Credentials creds = container.getCredentials();\n        creds.writeTokenStorageToStream(tokensOutStream);\n      }\n      // /////////// End of writing out container-tokens\n\n      ret = launchContainer(new ContainerStartContext.Builder()\n          .setContainer(container)\n          .setLocalizedResources(localResources)\n          .setNmPrivateContainerScriptPath(nmPrivateContainerScriptPath)\n          .setNmPrivateTokensPath(nmPrivateTokensPath)\n          .setUser(user)\n          .setAppId(appIdStr)\n          .setContainerWorkDir(containerWorkDir)\n          .setLocalDirs(localDirs)\n          .setLogDirs(logDirs)\n          .setFilecacheDirs(filecacheDirs)\n          .setUserLocalDirs(userLocalDirs)\n          .setContainerLocalDirs(containerLocalDirs)\n          .setContainerLogDirs(containerLogDirs).build());\n    } catch (ConfigurationException e) {\n      LOG.error(\"Failed to launch container due to configuration error.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerID, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      // Mark the node as unhealthy\n      context.getNodeStatusUpdater().reportException(e);\n      return ret;\n    } catch (Throwable e) {\n      LOG.warn(\"Failed to launch container.\", e);\n      dispatcher.getEventHandler().handle(new ContainerExitEvent(\n          containerID, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,\n          e.getMessage()));\n      return ret;\n    } finally {\n      setContainerCompletedStatus(ret);\n    }\n\n    handleContainerExitCode(ret, containerLogDir);\n    return ret;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerPrivateDir": "  protected String getContainerPrivateDir(String appIdStr,\n      String containerIdStr) {\n    return getAppPrivateDir(appIdStr) + Path.SEPARATOR + containerIdStr\n        + Path.SEPARATOR;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getPidFileSubpath": "  protected String getPidFileSubpath(String appIdStr, String containerIdStr) {\n    return getContainerPrivateDir(appIdStr, containerIdStr) + Path.SEPARATOR\n        + String.format(ContainerLaunch.PID_FILE_NAME_FMT, containerIdStr);\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerLogDirs": "  protected List<String> getContainerLogDirs(List<String> logDirs) {\n    List<String> containerLogDirs = new ArrayList<>(logDirs.size());\n    String appIdStr = app.getAppId().toString();\n    String containerIdStr = container.getContainerId().toString();\n    String relativeContainerLogDir = ContainerLaunch\n        .getRelativeContainerLogDir(appIdStr, containerIdStr);\n\n    for (String logDir : logDirs) {\n      containerLogDirs.add(logDir + Path.SEPARATOR + relativeContainerLogDir);\n    }\n\n    return containerLogDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.prepareContainer": "  private void prepareContainer(Map<Path, List<String>> localResources,\n      List<String> containerLocalDirs) throws IOException {\n\n    exec.prepareContainer(new ContainerPrepareContext.Builder()\n        .setContainer(container)\n        .setLocalizedResources(localResources)\n        .setUser(container.getUser())\n        .setContainerLocalDirs(containerLocalDirs)\n        .setCommands(container.getLaunchContext().getCommands())\n        .build());\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.setContainerCompletedStatus": "  protected void setContainerCompletedStatus(int exitCode) {\n    ContainerId containerId = container.getContainerId();\n    completed.set(true);\n    exec.deactivateContainer(containerId);\n    try {\n      if (!container.shouldRetry(exitCode)) {\n        context.getNMStateStore().storeContainerCompleted(containerId,\n            exitCode);\n      }\n    } catch (IOException e) {\n      LOG.error(\"Unable to set exit code for container \" + containerId);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.deriveContainerWorkDir": "  private Path deriveContainerWorkDir() throws IOException {\n\n    final String containerWorkDirPath =\n        ContainerLocalizer.USERCACHE +\n        Path.SEPARATOR +\n        container.getUser() +\n        Path.SEPARATOR +\n        ContainerLocalizer.APPCACHE +\n        Path.SEPARATOR +\n        app.getAppId().toString() +\n        Path.SEPARATOR +\n        container.getContainerId().toString();\n\n    final Path containerWorkDir =\n        dirsHandler.getLocalPathForWrite(\n          containerWorkDirPath,\n          LocalDirAllocator.SIZE_UNKNOWN, false);\n\n    return containerWorkDir;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.toString": "    public String toString() {\n      return sb.toString();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getLocalizedResources": "  protected Map<Path, List<String>> getLocalizedResources()\n      throws YarnException {\n    Map<Path, List<String>> localResources = container.getLocalizedResources();\n    if (localResources == null) {\n      throw RPCUtil.getRemoteException(\n          \"Unable to get local resources when Container \" + container\n              + \" is at \" + container.getContainerState());\n    }\n    return localResources;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.recordContainerLogDir": "  private void recordContainerLogDir(ContainerId containerId,\n      String logDir) throws IOException{\n    container.setLogDir(logDir);\n    if (container.isRetryContextSet()) {\n      context.getNMStateStore().storeContainerLogDir(containerId, logDir);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.expandEnvironment": "  public static String expandEnvironment(String var,\n      Path containerLogDir) {\n    var = var.replace(ApplicationConstants.LOG_DIR_EXPANSION_VAR,\n      containerLogDir.toString());\n    var = var.replace(ApplicationConstants.CLASS_PATH_SEPARATOR,\n      File.pathSeparator);\n\n    // replace parameter expansion marker. e.g. {{VAR}} on Windows is replaced\n    // as %VAR% and on Linux replaced as \"$VAR\"\n    if (Shell.WINDOWS) {\n      var = var.replaceAll(\"(\\\\{\\\\{)|(\\\\}\\\\})\", \"%\");\n    } else {\n      var = var.replace(ApplicationConstants.PARAMETER_EXPANSION_LEFT, \"$\");\n      var = var.replace(ApplicationConstants.PARAMETER_EXPANSION_RIGHT, \"\");\n    }\n    return var;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getNMFilecacheDirs": "  protected List<String> getNMFilecacheDirs(List<String> localDirs) {\n    List<String> filecacheDirs = new ArrayList<>(localDirs.size());\n\n    for (String localDir : localDirs) {\n      String filecacheDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.FILECACHE;\n\n      filecacheDirs.add(filecacheDir);\n    }\n\n    return filecacheDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.sanitizeEnv": "  public void sanitizeEnv(Map<String, String> environment, Path pwd,\n      List<Path> appDirs, List<String> userLocalDirs, List<String>\n      containerLogDirs,\n      Map<Path, List<String>> resources,\n      Path nmPrivateClasspathJarDir) throws IOException {\n    /**\n     * Non-modifiable environment variables\n     */\n\n    environment.put(Environment.CONTAINER_ID.name(), container\n        .getContainerId().toString());\n\n    environment.put(Environment.NM_PORT.name(),\n      String.valueOf(this.context.getNodeId().getPort()));\n\n    environment.put(Environment.NM_HOST.name(), this.context.getNodeId()\n      .getHost());\n\n    environment.put(Environment.NM_HTTP_PORT.name(),\n      String.valueOf(this.context.getHttpPort()));\n\n    environment.put(Environment.LOCAL_DIRS.name(),\n        StringUtils.join(\",\", appDirs));\n\n    environment.put(Environment.LOCAL_USER_DIRS.name(), StringUtils.join(\",\",\n        userLocalDirs));\n\n    environment.put(Environment.LOG_DIRS.name(),\n      StringUtils.join(\",\", containerLogDirs));\n\n    environment.put(Environment.USER.name(), container.getUser());\n    \n    environment.put(Environment.LOGNAME.name(), container.getUser());\n\n    environment.put(Environment.HOME.name(),\n        conf.get(\n            YarnConfiguration.NM_USER_HOME_DIR, \n            YarnConfiguration.DEFAULT_NM_USER_HOME_DIR\n            )\n        );\n    \n    environment.put(Environment.PWD.name(), pwd.toString());\n    \n    putEnvIfAbsent(environment, Environment.HADOOP_CONF_DIR.name());\n\n    if (!Shell.WINDOWS) {\n      environment.put(\"JVM_PID\", \"$$\");\n    }\n\n    // variables here will be forced in, even if the container has specified them.\n    Apps.setEnvFromInputString(environment, conf.get(\n      YarnConfiguration.NM_ADMIN_USER_ENV,\n      YarnConfiguration.DEFAULT_NM_ADMIN_USER_ENV), File.pathSeparator);\n\n    // TODO: Remove Windows check and use this approach on all platforms after\n    // additional testing.  See YARN-358.\n    if (Shell.WINDOWS) {\n\n      sanitizeWindowsEnv(environment, pwd,\n          resources, nmPrivateClasspathJarDir);\n    }\n    // put AuxiliaryService data to environment\n    for (Map.Entry<String, ByteBuffer> meta : containerManager\n        .getAuxServiceMetaData().entrySet()) {\n      AuxiliaryServiceHelper.setServiceDataIntoEnv(\n          meta.getKey(), meta.getValue(), environment);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitCode": "  protected void handleContainerExitCode(int exitCode, Path containerLogDir) {\n    ContainerId containerId = container.getContainerId();\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Container \" + containerId + \" completed with exit code \"\n          + exitCode);\n    }\n\n    StringBuilder diagnosticInfo =\n        new StringBuilder(\"Container exited with a non-zero exit code \");\n    diagnosticInfo.append(exitCode);\n    diagnosticInfo.append(\". \");\n    if (exitCode == ExitCode.FORCE_KILLED.getExitCode()\n        || exitCode == ExitCode.TERMINATED.getExitCode()) {\n      // If the process was killed, Send container_cleanedup_after_kill and\n      // just break out of this method.\n\n      // If Container was killed before starting... NO need to do this.\n      if (!killedBeforeStart) {\n        dispatcher.getEventHandler().handle(\n            new ContainerExitEvent(containerId,\n                ContainerEventType.CONTAINER_KILLED_ON_REQUEST, exitCode,\n                diagnosticInfo.toString()));\n      }\n    } else if (exitCode != 0) {\n      handleContainerExitWithFailure(containerId, exitCode, containerLogDir,\n          diagnosticInfo);\n    } else {\n      LOG.info(\"Container \" + containerId + \" succeeded \");\n      dispatcher.getEventHandler().handle(\n          new ContainerEvent(containerId,\n              ContainerEventType.CONTAINER_EXITED_WITH_SUCCESS));\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.validateContainerState": "  protected boolean validateContainerState() {\n    // CONTAINER_KILLED_ON_REQUEST should not be missed if the container\n    // is already at KILLING\n    if (container.getContainerState() == ContainerState.KILLING) {\n      dispatcher.getEventHandler().handle(\n          new ContainerExitEvent(container.getContainerId(),\n              ContainerEventType.CONTAINER_KILLED_ON_REQUEST,\n              Shell.WINDOWS ? ExitCode.FORCE_KILLED.getExitCode() :\n                  ExitCode.TERMINATED.getExitCode(),\n              \"Container terminated before launch.\"));\n      return false;\n    }\n\n    return true;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.create": "    public static ShellScriptBuilder create() {\n      return Shell.WINDOWS ? new WindowsShellScriptBuilder() :\n        new UnixShellScriptBuilder();\n    }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerLocalDirs": "  protected List<String> getContainerLocalDirs(List<String> localDirs) {\n    List<String> containerLocalDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n    String appIdStr = app.getAppId().toString();\n    String relativeContainerLocalDir = ContainerLocalizer.USERCACHE\n        + Path.SEPARATOR + user + Path.SEPARATOR + ContainerLocalizer.APPCACHE\n        + Path.SEPARATOR + appIdStr + Path.SEPARATOR;\n\n    for (String localDir : localDirs) {\n      containerLocalDirs.add(localDir + Path.SEPARATOR\n          + relativeContainerLocalDir);\n    }\n\n    return containerLocalDirs;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.recordContainerWorkDir": "  private void recordContainerWorkDir(ContainerId containerId,\n      String workDir) throws IOException{\n    container.setWorkDir(workDir);\n    if (container.isRetryContextSet()) {\n      context.getNMStateStore().storeContainerWorkDir(containerId, workDir);\n    }\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getRelativeContainerLogDir": "  public static String getRelativeContainerLogDir(String appIdStr,\n      String containerIdStr) {\n    return appIdStr + Path.SEPARATOR + containerIdStr;\n  }",
            "hadoop-yarn-project.hadoop-yarn.hadoop-yarn-server.hadoop-yarn-server-nodemanager.src.main.java.org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getUserLocalDirs": "  protected List<String> getUserLocalDirs(List<String> localDirs) {\n    List<String> userLocalDirs = new ArrayList<>(localDirs.size());\n    String user = container.getUser();\n\n    for (String localDir : localDirs) {\n      String userLocalDir = localDir + Path.SEPARATOR +\n          ContainerLocalizer.USERCACHE + Path.SEPARATOR + user\n          + Path.SEPARATOR;\n\n      userLocalDirs.add(userLocalDir);\n    }\n\n    return userLocalDirs;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.runCommand": "  private void runCommand() throws IOException {\n    ProcessBuilder builder = new ProcessBuilder(getExecString());\n    Timer timeOutTimer = null;\n    ShellTimeoutTimerTask timeoutTimerTask = null;\n    timedOut.set(false);\n    completed.set(false);\n\n    // Remove all env vars from the Builder to prevent leaking of env vars from\n    // the parent process.\n    if (!inheritParentEnv) {\n      builder.environment().clear();\n    }\n\n    if (environment != null) {\n      builder.environment().putAll(this.environment);\n    }\n\n    if (dir != null) {\n      builder.directory(this.dir);\n    }\n\n    builder.redirectErrorStream(redirectErrorStream);\n\n    if (Shell.WINDOWS) {\n      synchronized (WindowsProcessLaunchLock) {\n        // To workaround the race condition issue with child processes\n        // inheriting unintended handles during process launch that can\n        // lead to hangs on reading output and error streams, we\n        // serialize process creation. More info available at:\n        // http://support.microsoft.com/kb/315939\n        process = builder.start();\n      }\n    } else {\n      process = builder.start();\n    }\n\n    waitingThread = Thread.currentThread();\n    CHILD_SHELLS.put(this, null);\n\n    if (timeOutInterval > 0) {\n      timeOutTimer = new Timer(\"Shell command timeout\");\n      timeoutTimerTask = new ShellTimeoutTimerTask(\n          this);\n      //One time scheduling.\n      timeOutTimer.schedule(timeoutTimerTask, timeOutInterval);\n    }\n    final BufferedReader errReader =\n            new BufferedReader(new InputStreamReader(\n                process.getErrorStream(), Charset.defaultCharset()));\n    BufferedReader inReader =\n            new BufferedReader(new InputStreamReader(\n                process.getInputStream(), Charset.defaultCharset()));\n    final StringBuffer errMsg = new StringBuffer();\n\n    // read error and input streams as this would free up the buffers\n    // free the error stream buffer\n    Thread errThread = new Thread() {\n      @Override\n      public void run() {\n        try {\n          String line = errReader.readLine();\n          while((line != null) && !isInterrupted()) {\n            errMsg.append(line);\n            errMsg.append(System.getProperty(\"line.separator\"));\n            line = errReader.readLine();\n          }\n        } catch(IOException ioe) {\n          // Its normal to observe a \"Stream closed\" I/O error on\n          // command timeouts destroying the underlying process\n          // so only log a WARN if the command didn't time out\n          if (!isTimedOut()) {\n            LOG.warn(\"Error reading the error stream\", ioe);\n          } else {\n            LOG.debug(\"Error reading the error stream due to shell \"\n                + \"command timeout\", ioe);\n          }\n        }\n      }\n    };\n    try {\n      errThread.start();\n    } catch (IllegalStateException ise) {\n    } catch (OutOfMemoryError oe) {\n      LOG.error(\"Caught \" + oe + \". One possible reason is that ulimit\"\n          + \" setting of 'max user processes' is too low. If so, do\"\n          + \" 'ulimit -u <largerNum>' and try again.\");\n      throw oe;\n    }\n    try {\n      parseExecResult(inReader); // parse the output\n      // clear the input stream buffer\n      String line = inReader.readLine();\n      while(line != null) {\n        line = inReader.readLine();\n      }\n      // wait for the process to finish and check the exit code\n      exitCode  = process.waitFor();\n      // make sure that the error thread exits\n      joinThread(errThread);\n      completed.set(true);\n      //the timeout thread handling\n      //taken care in finally block\n      if (exitCode != 0) {\n        throw new ExitCodeException(exitCode, errMsg.toString());\n      }\n    } catch (InterruptedException ie) {\n      InterruptedIOException iie = new InterruptedIOException(ie.toString());\n      iie.initCause(ie);\n      throw iie;\n    } finally {\n      if (timeOutTimer != null) {\n        timeOutTimer.cancel();\n      }\n      // close the input stream\n      try {\n        // JDK 7 tries to automatically drain the input streams for us\n        // when the process exits, but since close is not synchronized,\n        // it creates a race if we close the stream first and the same\n        // fd is recycled.  the stream draining thread will attempt to\n        // drain that fd!!  it may block, OOM, or cause bizarre behavior\n        // see: https://bugs.openjdk.java.net/browse/JDK-8024521\n        //      issue is fixed in build 7u60\n        InputStream stdout = process.getInputStream();\n        synchronized (stdout) {\n          inReader.close();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Error while closing the input stream\", ioe);\n      }\n      if (!completed.get()) {\n        errThread.interrupt();\n        joinThread(errThread);\n      }\n      try {\n        InputStream stderr = process.getErrorStream();\n        synchronized (stderr) {\n          errReader.close();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Error while closing the error stream\", ioe);\n      }\n      process.destroy();\n      waitingThread = null;\n      CHILD_SHELLS.remove(this);\n      lastTime = Time.monotonicNow();\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.parseExecResult": "    protected void parseExecResult(BufferedReader lines) throws IOException {\n      output = new StringBuffer();\n      char[] buf = new char[512];\n      int nRead;\n      while ( (nRead = lines.read(buf, 0, buf.length)) > 0 ) {\n        output.append(buf, 0, nRead);\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.close": "    public void close() {\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.joinThread": "  private static void joinThread(Thread t) {\n    while (t.isAlive()) {\n      try {\n        t.join();\n      } catch (InterruptedException ie) {\n        if (LOG.isWarnEnabled()) {\n          LOG.warn(\"Interrupted while joining on: \" + t, ie);\n        }\n        t.interrupt(); // propagate interrupt\n      }\n    }\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.toString": "    public String toString() {\n      StringBuilder builder = new StringBuilder();\n      String[] args = getExecString();\n      for (String s : args) {\n        if (s.indexOf(' ') >= 0) {\n          builder.append('\"').append(s).append('\"');\n        } else {\n          builder.append(s);\n        }\n        builder.append(' ');\n      }\n      return builder.toString();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.getExecString": "    public String[] getExecString() {\n      return command;\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.isTimedOut": "  public boolean isTimedOut() {\n    return timedOut.get();\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.run": "    public void run() {\n      Process p = shell.getProcess();\n      try {\n        p.exitValue();\n      } catch (Exception e) {\n        //Process has not terminated.\n        //So check if it has completed\n        //if not just destroy it.\n        if (p != null && !shell.completed.get()) {\n          shell.setTimedOut();\n          p.destroy();\n        }\n      }\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.setTimedOut": "  private void setTimedOut() {\n    this.timedOut.set(true);\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.getProcess": "  public Process getProcess() {\n    return process;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Shell.execute": "    public void execute() throws IOException {\n      for (String s : command) {\n        if (s == null) {\n          throw new IOException(\"(null) entry in command string: \"\n              + StringUtils.join(\" \", command));\n        }\n      }\n      this.run();\n    }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.Time.monotonicNow": "  public static long monotonicNow() {\n    return System.nanoTime() / NANOSECONDS_PER_MILLISECOND;\n  }",
            "hadoop-common-project.hadoop-common.src.main.java.org.apache.hadoop.util.StringUtils.join": "  public static String join(char separator, String[] strings) {\n    return join(separator + \"\", strings);\n  }"
        },
        "bug_report": {
            "Title": "Remove privileged operation warnings during container launch for the ContainerRuntimes",
            "Description": "steps:\r\n 1) Run Dshell Application\r\n{code:java}\r\nyarn  org.apache.hadoop.yarn.applications.distributedshell.Client -jar /usr/hdp/3.0.0.0-751/hadoop-yarn/hadoop-yarn-applications-distributedshell-*.jar -keep_containers_across_application_attempts -timeout 900000 -shell_command \"sleep 110\" -num_containers 4{code}\r\n2) Find out host where AM is running. \r\n 3) Find Containers launched by application\r\n 4) Restart NM where AM is running\r\n 5) Validate that new attempt is not started and containers launched before restart are in RUNNING state.\r\n\r\nIn this test, step#5 fails because containers failed to launch with error 143\r\n{code:java}\r\n2018-01-24 09:48:30,547 INFO  container.ContainerImpl (ContainerImpl.java:handle(2108)) - Container container_e04_1516787230461_0001_01_000003 transitioned from RUNNING to KILLING\r\n2018-01-24 09:48:30,547 INFO  launcher.ContainerLaunch (ContainerLaunch.java:cleanupContainer(668)) - Cleaning up container container_e04_1516787230461_0001_01_000003\r\n2018-01-24 09:48:30,552 WARN  privileged.PrivilegedOperationExecutor (PrivilegedOperationExecutor.java:executePrivilegedOperation(174)) - Shell execution returned exit code: 143. Privileged Execution Operation Stderr:\r\n\r\nStdout: main : command provided 1\r\nmain : run as user is hrt_qa\r\nmain : requested yarn user is hrt_qa\r\nGetting exit code file...\r\nCreating script paths...\r\nWriting pid file...\r\nWriting to tmp file /grid/0/hadoop/yarn/local/nmPrivate/application_1516787230461_0001/container_e04_1516787230461_0001_01_000003/container_e04_1516787230461_0001_01_000003.pid.tmp\r\nWriting to cgroup task files...\r\nCreating local dirs...\r\nLaunching container...\r\nGetting exit code file...\r\nCreating script paths...\r\n\r\nFull command array for failed execution:\r\n[/usr/hdp/3.0.0.0-751/hadoop-yarn/bin/container-executor, hrt_qa, hrt_qa, 1, application_1516787230461_0001, container_e04_1516787230461_0001_01_000003, /grid/0/hadoop/yarn/local/usercache/hrt_qa/appcache/application_1516787230461_0001/container_e04_1516787230461_0001_01_000003, /grid/0/hadoop/yarn/local/nmPrivate/application_1516787230461_0001/container_e04_1516787230461_0001_01_000003/launch_container.sh, /grid/0/hadoop/yarn/local/nmPrivate/application_1516787230461_0001/container_e04_1516787230461_0001_01_000003/container_e04_1516787230461_0001_01_000003.tokens, /grid/0/hadoop/yarn/local/nmPrivate/application_1516787230461_0001/container_e04_1516787230461_0001_01_000003/container_e04_1516787230461_0001_01_000003.pid, /grid/0/hadoop/yarn/local, /grid/0/hadoop/yarn/log, cgroups=none]\r\n2018-01-24 09:48:30,553 WARN  runtime.DefaultLinuxContainerRuntime (DefaultLinuxContainerRuntime.java:launchContainer(127)) - Launch container failed. Exception:\r\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=143:\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:180)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.launchContainer(DefaultLinuxContainerRuntime.java:124)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.launchContainer(DelegatingLinuxContainerRuntime.java:152)\r\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:549)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:465)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:285)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:95)\r\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\nCaused by: ExitCodeException exitCode=143:\r\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)\r\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\r\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\r\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\r\n        ... 10 more\r\n2018-01-24 09:48:30,553 WARN  nodemanager.LinuxContainerExecutor (LinuxContainerExecutor.java:launchContainer(557)) - Exit code from container container_e04_1516787230461_0001_01_000003 is : 143\r\n2018-01-24 09:48:30,582 INFO  containermanager.ContainerManagerImpl (ContainerManagerImpl.java:stopContainerInternal(1365)) - Stopping container with container Id: container_e04_1516787230461_0001_01_000005\r\n2018-01-24 09:48:31,093 INFO  impl.TimelineV2ClientImpl (TimelineV2ClientImpl.java:setTimelineCollectorInfo(172)) - Updated timeline service address to xxxxxx:40757\r\n2018-01-24 09:48:32,675 INFO  container.ContainerImpl (ContainerImpl.java:handle(2108)) - Container container_e04_1516787230461_0001_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL{code}"
        }
    }
]