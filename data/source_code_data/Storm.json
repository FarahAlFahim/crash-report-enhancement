[
    {
        "filename": "STORM-2443.json",
        "creation_time": "2017-03-31T08:09:04.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException: null\n        at org.apache.storm.daemon.nimbus.Nimbus.setLogConfig(Nimbus.java:2688) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3295) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3280) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_66]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_66]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_66]\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.send_setLogConfig": "    public void send_setLogConfig(String name, LogConfig config) throws org.apache.thrift.TException\n    {\n      setLogConfig_args args = new setLogConfig_args();\n      args.set_name(name);\n      args.set_config(config);\n      sendBase(\"setLogConfig\", args);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setLogConfig": "    public void recv_setLogConfig() throws org.apache.thrift.TException\n    {\n      setLogConfig_result result = new setLogConfig_result();\n      receiveBase(result, \"setLogConfig\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public getTopologyHistory_result getResult(I iface, getTopologyHistory_args args) throws org.apache.thrift.TException {\n        getTopologyHistory_result result = new getTopologyHistory_result();\n        try {\n          result.success = iface.getTopologyHistory(args.user);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(String location, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deleteBlob": "    public void recv_deleteBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      deleteBlob_result result = new deleteBlob_result();\n      receiveBase(result, \"deleteBlob\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_createStateInZookeeper": "    public void recv_createStateInZookeeper() throws org.apache.thrift.TException\n    {\n      createStateInZookeeper_result result = new createStateInZookeeper_result();\n      receiveBase(result, \"createStateInZookeeper\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadChunk": "    public void recv_uploadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadChunk_result result = new uploadChunk_result();\n      receiveBase(result, \"uploadChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setWorkerProfiler": "    public void recv_setWorkerProfiler() throws org.apache.thrift.TException\n    {\n      setWorkerProfiler_result result = new setWorkerProfiler_result();\n      receiveBase(result, \"setWorkerProfiler\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(String user, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(String key, int replication, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishBlobUpload": "    public void recv_finishBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishBlobUpload_result result = new finishBlobUpload_result();\n      receiveBase(result, \"finishBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_rebalance": "    public void recv_rebalance() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      rebalance_result result = new rebalance_result();\n      receiveBase(result, \"rebalance\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopology": "    public void recv_submitTopology() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopology_result result = new submitTopology_result();\n      receiveBase(result, \"submitTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(String location, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopology": "    public void recv_killTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopology_result result = new killTopology_result();\n      receiveBase(result, \"killTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(String name, String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadBlobChunk": "    public void recv_uploadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadBlobChunk_result result = new uploadBlobChunk_result();\n      receiveBase(result, \"uploadBlobChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_activate": "    public void recv_activate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      activate_result result = new activate_result();\n      receiveBase(result, \"activate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(String file, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(String session, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(String id, String host, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishFileUpload": "    public void recv_finishFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishFileUpload_result result = new finishFileUpload_result();\n      receiveBase(result, \"finishFileUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setBlobMeta": "    public void recv_setBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      setBlobMeta_result result = new setBlobMeta_result();\n      receiveBase(result, \"setBlobMeta\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopologyWithOpts": "    public void recv_killTopologyWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n      receiveBase(result, \"killTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_debug": "    public void recv_debug() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      debug_result result = new debug_result();\n      receiveBase(result, \"debug\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadNewCredentials": "    public void recv_uploadNewCredentials() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      uploadNewCredentials_result result = new uploadNewCredentials_result();\n      receiveBase(result, \"uploadNewCredentials\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deactivate": "    public void recv_deactivate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      deactivate_result result = new deactivate_result();\n      receiveBase(result, \"deactivate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_cancelBlobUpload": "    public void recv_cancelBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      cancelBlobUpload_result result = new cancelBlobUpload_result();\n      receiveBase(result, \"cancelBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(String id, String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context \n            ReqContext req_context = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            if (trans instanceof TMemoryInputTransport) {\n                try {\n                    req_context.setRemoteAddress(InetAddress.getLocalHost());\n                } catch (UnknownHostException e) {\n                    throw new RuntimeException(e);\n                }                                \n            } else if (trans instanceof TSocket) {\n                TSocket tsocket = (TSocket)trans;\n                //remote address\n                Socket socket = tsocket.getSocket();\n                req_context.setRemoteAddress(socket.getInetAddress());                \n            } \n\n            //anonymous user\n            Subject s = getDefaultSubject();\n            if (s == null) {\n              final String user = (String)storm_conf.get(\"debug.simple.transport.user\");\n              if (user != null) {\n                HashSet<Principal> principals = new HashSet<>();\n                principals.add(new Principal() {\n                  public String getName() { return user; }\n                  public String toString() { return user; }\n                });\n                s = new Subject(true, principals, new HashSet<>(), new HashSet<>());\n              }\n            }\n            req_context.setSubject(s);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-core.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.getDefaultSubject": "    protected Subject getDefaultSubject() {\n        return null;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setSubject": "    public void setSubject(Subject subject) {\n        _subject = subject;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.context": "    public static ReqContext context() {\n        return ctxt.get();\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setRemoteAddress": "    public void setRemoteAddress(InetAddress addr) {\n        _remoteAddr = addr;\n    }"
        },
        "bug_report": {
            "Title": "Nimbus throws error when changing log level on UI topology page",
            "Description": "Here's stacktrace from Nimbus log:\n\n{code}\n2017-03-30 16:53:26.954 o.a.s.d.n.Nimbus pool-14-thread-56 [WARN] set log config topology exception. (topology id='rolling-1-1490860365')\njava.lang.NullPointerException: null\n        at org.apache.storm.daemon.nimbus.Nimbus.setLogConfig(Nimbus.java:2688) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3295) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3280) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_66]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_66]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_66]\n{code}"
        }
    },
    {
        "filename": "STORM-3213.json",
        "creation_time": "2018-09-05T16:16:45.000+0000",
        "stack_trace": "```\norg.apache.storm.thrift.TApplicationException: Internal error processing getComponentPageInfo\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:79)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1359)\n\tat org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1343)\n\tat org.apache.storm.daemon.ui.UIHelpers.getComponentPage(UIHelpers.java:1559)\n\tat org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent(StormApiResource.java:438)\n\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4238) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4577) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4556) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:169) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources(ResourceUtils.java:37) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4192) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.is_set_success": "    public boolean is_set_success() {\n      return org.apache.storm.thrift.EncodingUtils.testBit(__isset_bitfield, __SUCCESS_ISSET_ID);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_getComponentPageInfo": "    public void send_getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys) throws org.apache.storm.thrift.TException\n    {\n      getComponentPageInfo_args args = new getComponentPageInfo_args();\n      args.set_topology_id(topology_id);\n      args.set_component_id(component_id);\n      args.set_window(window);\n      args.set_is_include_sys(is_include_sys);\n      sendBase(\"getComponentPageInfo\", args);\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.ui.UIHelpers.getComponentPage": "    public static Map<String, Object> getComponentPage(\n            Nimbus.Iface client, String id, String component,\n            String window, boolean sys, String user, Map config) throws TException {\n        Map<String, Object> result = new HashMap();\n        ComponentPageInfo componentPageInfo = client.getComponentPageInfo(\n                id, component, window, sys\n        );\n        result.put(\"user\", user);\n        result.put(\"id\" , component);\n        result.put(\"encodedId\", URLEncoder.encode(component));\n        result.put(\"name\", componentPageInfo.get_topology_name());\n        result.put(\"executors\", componentPageInfo.get_num_executors());\n        result.put(\"tasks\", componentPageInfo.get_num_tasks());\n        result.put(\"requestedMemOnHeap\",\n                componentPageInfo.get_resources_map().get(Constants.COMMON_ONHEAP_MEMORY_RESOURCE_NAME));\n        result.put(\"requestedMemOffHeap\",\n                componentPageInfo.get_resources_map().get(Constants.COMMON_OFFHEAP_MEMORY_RESOURCE_NAME));\n        result.put(\"requestedCpu\",\n                componentPageInfo.get_resources_map().get(Constants.COMMON_CPU_RESOURCE_NAME));\n\n        result.put(\"schedulerDisplayResource\", config.get(DaemonConfig.SCHEDULER_DISPLAY_RESOURCE));\n        result.put(\"topologyId\", id);\n        result.put(\"topologyStatus\", componentPageInfo.get_topology_status());\n        result.put(\"encodedTopologyId\", URLEncoder.encode(id));\n        result.put(\"window\", window);\n        result.put(\"componentType\", componentPageInfo.get_component_type().toString().toLowerCase());\n        result.put(\"windowHint\", getWindowHint(window));\n        result.put(\"debug\", componentPageInfo.is_set_debug_options() && componentPageInfo.get_debug_options().is_enable());\n        double samplingPct = 10;\n        if (componentPageInfo.is_set_debug_options()) {\n            samplingPct = componentPageInfo.get_debug_options().get_samplingpct();\n        }\n        result.put(\"samplingPct\", samplingPct);\n        result.put(\"eventLogLink\", getLogviewerLink(componentPageInfo.get_eventlog_host(),\n                WebAppUtils.eventLogsFilename(id, String.valueOf(componentPageInfo.get_eventlog_port())),\n                config, componentPageInfo.get_eventlog_port()));\n        result.put(\"profilingAndDebuggingCapable\", !Utils.isOnWindows());\n        result.put(\"profileActionEnabled\", config.get(DaemonConfig.WORKER_PROFILER_ENABLED));\n\n\n        result.put(\"profilerActive\", getActiveProfileActions(client, id, component, config));\n        return result;\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.ui.UIHelpers.getActiveProfileActions": "    public static List getActiveProfileActions(Nimbus.Iface client, String id, String component, Map config) throws TException {\n        List<ProfileRequest> profileRequests =\n                client.getComponentPendingProfileActions(id, component, ProfileAction.JPROFILE_STOP);\n        return profileRequests.stream().map(x -> UIHelpers.getActiveAction(x, config, id)).collect(Collectors.toList());\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.ui.UIHelpers.getLogviewerLink": "    public static String getLogviewerLink(String host, String fname,\n                                          Map<String, Object> config, int port) {\n        if (isSecureLogviewer(config)) {\n            return UIHelpers.urlFormat(\"https://%s:%s/api/v1/log?file=%s\",\n                    host, config.get(DaemonConfig.LOGVIEWER_HTTPS_PORT), fname);\n        } else {\n            return UIHelpers.urlFormat(\"http://%s:%s/api/v1/log?file=%s\",\n                    host, config.get(DaemonConfig.LOGVIEWER_PORT), fname);\n        }\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.ui.UIHelpers.getWindowHint": "    public static String getWindowHint(String window) {\n        if (window.equals(\":all-time\")) {\n            return \"All time\";\n        }\n        return UIHelpers.prettyUptimeSec(window);\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent": "    public Response getTopologyComponent(@PathParam(\"id\") String id,\n                                         @PathParam(\"component\") String component,\n                                         @QueryParam(\"sys\") boolean sys,\n                                         @QueryParam(callbackParameterName) String callback,\n                                         @DefaultValue(\":all-time\") @QueryParam(\"window\") String window\n                                         ) throws TException {\n        componentPageRequestMeter.mark();\n        try (NimbusClient nimbusClient = NimbusClient.getConfiguredClient(config)) {\n            String user = servletRequest.getRemoteUser();\n            return UIHelpers.makeStandardResponse(\n                    UIHelpers.getComponentPage(\n                            nimbusClient.getClient(), id, component,\n                            window, sys, user, config\n                    ),\n                    callback\n            );\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public isRemoteBlobExists_result getResult(I iface, isRemoteBlobExists_args args) throws org.apache.storm.thrift.TException {\n        isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n        try {\n          result.success = iface.isRemoteBlobExists(args.blobKey);\n          result.set_success_isSet(true);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.storm.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(java.lang.String location, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(java.lang.String name, KillOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public java.lang.String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.storm.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(java.lang.String user, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(java.lang.String key, int replication, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(java.lang.String name, LogConfig config, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getOwnerResourceSummaries": "    public java.util.List<OwnerResourceSummary> recv_getOwnerResourceSummaries() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n      receiveBase(result, \"getOwnerResourceSummaries\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorAssignments": "    public void getSupervisorAssignments(java.lang.String node, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorAssignments_call method_call = new getSupervisorAssignments_call(node, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public java.lang.String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public java.nio.ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeat": "    public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeat_call method_call = new sendSupervisorWorkerHeartbeat_call(heatbeat, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeats": "    public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeats_call method_call = new sendSupervisorWorkerHeartbeats_call(heartbeats, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.storm.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.processWorkerMetrics": "    public void processWorkerMetrics(WorkerMetrics metrics, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      processWorkerMetrics_call method_call = new processWorkerMetrics_call(metrics, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isRemoteBlobExists": "    public boolean recv_isRemoteBlobExists() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n      receiveBase(result, \"isRemoteBlobExists\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isRemoteBlobExists failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public java.nio.ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public java.lang.String recv_getNimbusConf() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(java.lang.String name, Credentials creds, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isRemoteBlobExists": "    public void isRemoteBlobExists(java.lang.String blobKey, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isRemoteBlobExists_call method_call = new isRemoteBlobExists_call(blobKey, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getOwnerResourceSummaries": "    public void getOwnerResourceSummaries(java.lang.String owner, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorAssignments": "    public SupervisorAssignments recv_getSupervisorAssignments() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n      receiveBase(result, \"getSupervisorAssignments\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorAssignments failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(java.lang.String name, RebalanceOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public java.lang.String recv_beginFileUpload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public java.util.List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.storm.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public java.lang.String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context \n            ReqContext req_context = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            if (trans instanceof TMemoryInputTransport) {\n                try {\n                    req_context.setRemoteAddress(InetAddress.getLocalHost());\n                } catch (UnknownHostException e) {\n                    throw new RuntimeException(e);\n                }\n            } else if (trans instanceof TSocket) {\n                TSocket tsocket = (TSocket) trans;\n                //remote address\n                Socket socket = tsocket.getSocket();\n                req_context.setRemoteAddress(socket.getInetAddress());\n            }\n\n            //anonymous user\n            Subject s = getDefaultSubject();\n            if (s == null) {\n                final String user = (String) topoConf.get(\"debug.simple.transport.user\");\n                if (user != null) {\n                    HashSet<Principal> principals = new HashSet<>();\n                    principals.add(new Principal() {\n                        public String getName() {\n                            return user;\n                        }\n\n                        public String toString() {\n                            return user;\n                        }\n                    });\n                    s = new Subject(true, principals, new HashSet<>(), new HashSet<>());\n                }\n            }\n            req_context.setSubject(s);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-client.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.getDefaultSubject": "    protected Subject getDefaultSubject() {\n        return null;\n    }",
            "storm-server.src.main.java.org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources": "    public static NormalizedResourceRequest getBoltResources(StormTopology topology, Map<String, Object> topologyConf,\n                                                             String componentId) {\n        if (topology.get_bolts() != null) {\n            Bolt bolt = topology.get_bolts().get(componentId);\n            return new NormalizedResourceRequest(bolt.get_common(), topologyConf, componentId);\n        }\n        return null;\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.setSubject": "    public void setSubject(Subject subject) {\n        _subject = subject;\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.context": "    public static ReqContext context() {\n        return ctxt.get();\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.setRemoteAddress": "    public void setRemoteAddress(InetAddress addr) {\n        _remoteAddr = addr;\n    }"
        },
        "bug_report": {
            "Title": "500 Server Error on __acker component page on Storm UI",
            "Description": "\r\n{code:java}\r\norg.apache.storm.thrift.TApplicationException: Internal error processing getComponentPageInfo\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:79)\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1359)\r\n\tat org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1343)\r\n\tat org.apache.storm.daemon.ui.UIHelpers.getComponentPage(UIHelpers.java:1559)\r\n\tat org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent(StormApiResource.java:438)\r\n{code}\r\n\r\n\r\n\r\n{code:java}\r\n2018-09-05 16:15:24.927 o.a.s.t.ProcessFunction pool-21-thread-55 [ERROR] Internal error processing getComponentPageInfo\r\njava.lang.RuntimeException: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4238) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4577) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4556) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:169) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources(ResourceUtils.java:37) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4192) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        ... 10 more\r\n{code}\r\n"
        }
    },
    {
        "filename": "STORM-2496.json",
        "creation_time": "2017-04-28T08:17:47.000+0000",
        "stack_trace": "```\norg.apache.storm.generated.AuthorizationException: null\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n\njava.util.concurrent.ExecutionException: AuthorizationException(msg:<user> does not have READ access to dep-org.apache.curator-curator-framework-jar-2.10.0.jar)\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_112]\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_112]\n\tat org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:380) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:275) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:740) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\nCaused by: org.apache.storm.generated.AuthorizationException\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n\njava.lang.RuntimeException: Halting process: Error when processing an event\n\tat org.apache.storm.utils.Utils.exitProcess(Utils.java:1774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n```",
        "source_code": {
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.downloadBlob": "  private LocalizedResource downloadBlob(Map conf, String key, File localFile,\n      String user, boolean uncompress, boolean isUpdate)\n      throws AuthorizationException, KeyNotFoundException, IOException {\n    ClientBlobStore blobstore = null;\n    try {\n      blobstore = getClientBlobStore();\n      long nimbusBlobVersion = ServerUtils.nimbusVersionOfBlob(key, blobstore);\n      long oldVersion = ServerUtils.localVersionOfBlob(localFile.toString());\n      FileOutputStream out = null;\n      PrintWriter writer = null;\n      int numTries = 0;\n      String localizedPath = localFile.toString();\n      String localFileWithVersion = ServerUtils.constructBlobWithVersionFileName(localFile.toString(),\n              nimbusBlobVersion);\n      String localVersionFile = ServerUtils.constructVersionFileName(localFile.toString());\n      String downloadFile = localFileWithVersion;\n      if (uncompress) {\n        // we need to download to temp file and then unpack into the one requested\n        downloadFile = new File(localFile.getParent(), TO_UNCOMPRESS + localFile.getName()).toString();\n      }\n      while (numTries < _blobDownloadRetries) {\n        out = new FileOutputStream(downloadFile);\n        numTries++;\n        try {\n          if (!ServerUtils.canUserReadBlob(blobstore.getBlobMeta(key), user)) {\n            throw new AuthorizationException(user + \" does not have READ access to \" + key);\n          }\n          InputStreamWithMeta in = blobstore.getBlob(key);\n          byte[] buffer = new byte[1024];\n          int len;\n          while ((len = in.read(buffer)) >= 0) {\n            out.write(buffer, 0, len);\n          }\n          out.close();\n          in.close();\n          if (uncompress) {\n            ServerUtils.unpack(new File(downloadFile), new File(localFileWithVersion));\n            LOG.debug(\"uncompressed \" + downloadFile + \" to: \" + localFileWithVersion);\n          }\n\n          // Next write the version.\n          LOG.info(\"Blob: \" + key + \" updated with new Nimbus-provided version: \" +\n              nimbusBlobVersion + \" local version was: \" + oldVersion);\n          // The false parameter ensures overwriting the version file, not appending\n          writer = new PrintWriter(\n              new BufferedWriter(new FileWriter(localVersionFile, false)));\n          writer.println(nimbusBlobVersion);\n          writer.close();\n\n          try {\n            setBlobPermissions(conf, user, localFileWithVersion);\n            setBlobPermissions(conf, user, localVersionFile);\n\n            // Update the key.current symlink. First create tmp symlink and do\n            // move of tmp to current so that the operation is atomic.\n            String tmp_uuid_local = java.util.UUID.randomUUID().toString();\n            LOG.debug(\"Creating a symlink @\" + localFile + \".\" + tmp_uuid_local + \" , \" +\n                \"linking to: \" + localFile + \".\" + nimbusBlobVersion);\n            File uuid_symlink = new File(localFile + \".\" + tmp_uuid_local);\n\n            Files.createSymbolicLink(uuid_symlink.toPath(),\n                Paths.get(ServerUtils.constructBlobWithVersionFileName(localFile.toString(),\n                        nimbusBlobVersion)));\n            File current_symlink = new File(ServerUtils.constructBlobCurrentSymlinkName(\n                    localFile.toString()));\n            Files.move(uuid_symlink.toPath(), current_symlink.toPath(), ATOMIC_MOVE);\n          } catch (IOException e) {\n            // if we fail after writing the version file but before we move current link we need to\n            // restore the old version to the file\n            try {\n              PrintWriter restoreWriter = new PrintWriter(\n                  new BufferedWriter(new FileWriter(localVersionFile, false)));\n              restoreWriter.println(oldVersion);\n              restoreWriter.close();\n            } catch (IOException ignore) {}\n            throw e;\n          }\n\n          String oldBlobFile = localFile + \".\" + oldVersion;\n          try {\n            // Remove the old version. Note that if a number of processes have that file open,\n            // the OS will keep the old blob file around until they all close the handle and only\n            // then deletes it. No new process will open the old blob, since the users will open the\n            // blob through the \"blob.current\" symlink, which always points to the latest version of\n            // a blob. Remove the old version after the current symlink is updated as to not affect\n            // anyone trying to read it.\n            if ((oldVersion != -1) && (oldVersion != nimbusBlobVersion)) {\n              LOG.info(\"Removing an old blob file:\" + oldBlobFile);\n              Files.delete(Paths.get(oldBlobFile));\n            }\n          } catch (IOException e) {\n            // At this point we have downloaded everything and moved symlinks.  If the remove of\n            // old fails just log an error\n            LOG.error(\"Exception removing old blob version: \" + oldBlobFile);\n          }\n\n          break;\n        } catch (AuthorizationException ae) {\n          // we consider this non-retriable exceptions\n          if (out != null) {\n            out.close();\n          }\n          new File(downloadFile).delete();\n          throw ae;\n        } catch (IOException | KeyNotFoundException e) {\n          if (out != null) {\n            out.close();\n          }\n          if (writer != null) {\n            writer.close();\n          }\n          new File(downloadFile).delete();\n          if (uncompress) {\n            try {\n              FileUtils.deleteDirectory(new File(localFileWithVersion));\n            } catch (IOException ignore) {}\n          }\n          if (!isUpdate) {\n            // don't want to remove existing version file if its an update\n            new File(localVersionFile).delete();\n          }\n\n          if (numTries < _blobDownloadRetries) {\n            LOG.error(\"Failed to download blob, retrying\", e);\n          } else {\n            throw e;\n          }\n        }\n      }\n      return new LocalizedResource(key, localizedPath, uncompress);\n    } finally {\n      if(blobstore != null) {\n        blobstore.shutdown();\n      }\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.shutdown": "  public void shutdown() {\n    if (_cacheCleanupService != null) {\n      _cacheCleanupService.shutdown();\n    }\n    if (_execService != null) {\n      _execService.shutdown();\n    }\n    if (_updateExecService != null) {\n      _updateExecService.shutdown();\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.setBlobPermissions": "  public void setBlobPermissions(Map conf, String user, String path)\n      throws IOException {\n\n    if (!ObjectReader.getBoolean(conf.get(Config.SUPERVISOR_RUN_WORKER_AS_USER), false)) {\n      return;\n    }\n    String wlCommand = ObjectReader.getString(conf.get(Config.SUPERVISOR_WORKER_LAUNCHER), \"\");\n    if (wlCommand.isEmpty()) {\n      String stormHome = System.getProperty(\"storm.home\");\n      wlCommand = stormHome + \"/bin/worker-launcher\";\n    }\n    List<String> command = new ArrayList<String>(Arrays.asList(wlCommand, user, \"blob\", path));\n\n    String[] commandArray = command.toArray(new String[command.size()]);\n    ShellCommandExecutor shExec = new ShellCommandExecutor(commandArray);\n    LOG.info(\"Setting blob permissions, command: {}\", Arrays.toString(commandArray));\n\n    try {\n      shExec.execute();\n      LOG.debug(\"output: {}\", shExec.getOutput());\n    } catch (ExitCodeException e) {\n      int exitCode = shExec.getExitCode();\n      LOG.warn(\"Exit code from worker-launcher is : \" + exitCode, e);\n      LOG.debug(\"output: {}\", shExec.getOutput());\n      throw new IOException(\"Setting blob permissions failed\" +\n          \" (exitCode=\" + exitCode + \") with output: \" + shExec.getOutput(), e);\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.getClientBlobStore": "  protected ClientBlobStore getClientBlobStore() {\n    return ServerUtils.getClientBlobStoreForSupervisor(_conf);\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.getBlob": "  public LocalizedResource getBlob(LocalResource localResource, String user, String topo,\n       File userFileDir) throws AuthorizationException, KeyNotFoundException, IOException {\n    ArrayList<LocalResource> arr = new ArrayList<LocalResource>();\n    arr.add(localResource);\n    List<LocalizedResource> results = getBlobs(arr, user, topo, userFileDir);\n    if (results.isEmpty() || results.size() != 1) {\n      throw new IOException(\"Unknown error getting blob: \" + localResource + \", for user: \" + user +\n          \", topo: \" + topo);\n    }\n    return results.get(0);\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.call": "    public LocalizedResource call()\n        throws AuthorizationException, KeyNotFoundException, IOException  {\n      return _localizer.downloadBlob(_conf, _key, _localFile, _user, _uncompress,\n        _isUpdate);\n    }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocalDownloadedResource.get": "        public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {\n            return _wrapped.get(timeout, unit);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization": "    static DynamicState handleWaitingForBlobLocalization(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.pendingLocalization != null);\n        assert(dynamicState.pendingDownload != null);\n        assert(dynamicState.container == null);\n        \n        //Ignore changes to scheduling while downloading the topology blobs\n        // We don't support canceling the download through the future yet,\n        // so to keep everything in sync, just wait\n        try {\n            dynamicState.pendingDownload.get(1000, TimeUnit.MILLISECONDS);\n            //Downloading of all blobs finished.\n            if (!equivalent(dynamicState.newAssignment, dynamicState.pendingLocalization)) {\n                //Scheduling changed\n                staticState.localizer.releaseSlotFor(dynamicState.pendingLocalization, staticState.port);\n                return prepareForNewAssignmentNoWorkersRunning(dynamicState, staticState);\n            }\n            Container c = staticState.containerLauncher.launchContainer(staticState.port, dynamicState.pendingLocalization, staticState.localState);\n            return dynamicState.withCurrentAssignment(c, dynamicState.pendingLocalization).withState(MachineState.WAITING_FOR_WORKER_START).withPendingLocalization(null, null);\n        } catch (TimeoutException e) {\n            //We waited for 1 second loop around and try again....\n            return dynamicState;\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.equivalent": "    static boolean equivalent(LocalAssignment a, LocalAssignment b) {\n        if (a == null && b == null) {\n            return true;\n        }\n        if (a != null && b != null) {\n            if (a.get_topology_id().equals(b.get_topology_id())) {\n                Set<ExecutorInfo> aexec = new HashSet<>(a.get_executors());\n                Set<ExecutorInfo> bexec = new HashSet<>(b.get_executors());\n                if (aexec.equals(bexec)) {\n                    boolean aHasResources = a.is_set_resources();\n                    boolean bHasResources = b.is_set_resources();\n                    if (!aHasResources && !bHasResources) {\n                        return true;\n                    }\n                    if (aHasResources && bHasResources) {\n                        if (a.get_resources().equals(b.get_resources())) {\n                            return true;\n                        }\n                    }\n                }\n            }\n        }\n        return false;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withCurrentAssignment": "        public DynamicState withCurrentAssignment(final Container container, final LocalAssignment currentAssignment) {\n            return new DynamicState(this.state, this.newAssignment,\n                    container, currentAssignment,\n                    this.pendingLocalization, this.startTime,\n                    this.pendingDownload, this.profileActions,\n                    this.pendingStopProfileActions);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withState": "        public DynamicState withState(final MachineState state) {\n            long newStartTime = Time.currentTimeMillis();\n            return new DynamicState(state, this.newAssignment,\n                    this.container, this.currentAssignment,\n                    this.pendingLocalization, newStartTime,\n                    this.pendingDownload, this.profileActions,\n                    this.pendingStopProfileActions);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withPendingLocalization": "        public DynamicState withPendingLocalization(Future<Void> pendingDownload) {\n            return withPendingLocalization(this.pendingLocalization, pendingDownload);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.prepareForNewAssignmentNoWorkersRunning": "    static DynamicState prepareForNewAssignmentNoWorkersRunning(DynamicState dynamicState, StaticState staticState) throws IOException {\n        assert(dynamicState.container == null);\n        \n        if (dynamicState.newAssignment == null) {\n            return dynamicState.withState(MachineState.EMPTY);\n        }\n        Future<Void> pendingDownload = staticState.localizer.requestDownloadBaseTopologyBlobs(dynamicState.newAssignment, staticState.port);\n        return dynamicState.withPendingLocalization(dynamicState.newAssignment, pendingDownload).withState(MachineState.WAITING_FOR_BASIC_LOCALIZATION);\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.stateMachineStep": "    static DynamicState stateMachineStep(DynamicState dynamicState, StaticState staticState) throws Exception {\n        LOG.debug(\"STATE {}\", dynamicState.state);\n        switch (dynamicState.state) {\n            case EMPTY:\n                return handleEmpty(dynamicState, staticState);\n            case RUNNING:\n                return handleRunning(dynamicState, staticState);\n            case WAITING_FOR_WORKER_START:\n                return handleWaitingForWorkerStart(dynamicState, staticState);\n            case KILL_AND_RELAUNCH:\n                return handleKillAndRelaunch(dynamicState, staticState);\n            case KILL:\n                return handleKill(dynamicState, staticState);\n            case WAITING_FOR_BASIC_LOCALIZATION:\n                return handleWaitingForBasicLocalization(dynamicState, staticState);\n            case WAITING_FOR_BLOB_LOCALIZATION:\n                return handleWaitingForBlobLocalization(dynamicState, staticState);\n            default:\n                throw new IllegalStateException(\"Code not ready to handle a state of \"+dynamicState.state);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleKillAndRelaunch": "    static DynamicState handleKillAndRelaunch(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        if (dynamicState.container.areAllProcessesDead()) {\n            if (equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n                dynamicState.container.cleanUpForRestart();\n                dynamicState.container.relaunch();\n                return dynamicState.withState(MachineState.WAITING_FOR_WORKER_START);\n            }\n            //Scheduling changed after we killed all of the processes\n            return prepareForNewAssignmentNoWorkersRunning(cleanupCurrentContainer(dynamicState, staticState, null), staticState);\n        }\n        //The child processes typically exit in < 1 sec.  If 2 mins later they are still around something is wrong\n        if ((Time.currentTimeMillis() - dynamicState.startTime) > 120_000) {\n            throw new RuntimeException(\"Not all processes in \" + dynamicState.container + \" exited after 120 seconds\");\n        }\n        dynamicState.container.forceKill();\n        Time.sleep(staticState.killSleepMs);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleWaitingForWorkerStart": "    static DynamicState handleWaitingForWorkerStart(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        LSWorkerHeartbeat hb = dynamicState.container.readHeartbeat();\n        if (hb != null) {\n            long hbAgeMs = (Time.currentTimeSecs() - hb.get_time_secs()) * 1000;\n            if (hbAgeMs <= staticState.hbTimeoutMs) {\n                return dynamicState.withState(MachineState.RUNNING);\n            }\n        }\n        \n        if (!equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n            //We were rescheduled while waiting for the worker to come up\n            LOG.warn(\"SLOT {}: Assignment Changed from {} to {}\", staticState.port, dynamicState.currentAssignment, dynamicState.newAssignment);\n            return killContainerForChangedAssignment(dynamicState, staticState);\n        }\n        \n        long timeDiffms = (Time.currentTimeMillis() - dynamicState.startTime);\n        if (timeDiffms > staticState.firstHbTimeoutMs) {\n            LOG.warn(\"SLOT {}: Container {} failed to launch in {} ms.\", staticState.port, dynamicState.container, staticState.firstHbTimeoutMs);\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        Time.sleep(1000);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleRunning": "    static DynamicState handleRunning(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        if (!equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n            LOG.warn(\"SLOT {}: Assignment Changed from {} to {}\", staticState.port, dynamicState.currentAssignment, dynamicState.newAssignment);\n            //Scheduling changed while running...\n            return killContainerForChangedAssignment(dynamicState, staticState);\n        }\n        if (dynamicState.container.didMainProcessExit()) {\n            LOG.warn(\"SLOT {}: main process has exited\", staticState.port);\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        \n        LSWorkerHeartbeat hb = dynamicState.container.readHeartbeat();\n        if (hb == null) {\n            LOG.warn(\"SLOT {}: HB returned as null\", staticState.port);\n            //This can happen if the supervisor crashed after launching a\n            // worker that never came up.\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        \n        long timeDiffMs = (Time.currentTimeSecs() - hb.get_time_secs()) * 1000;\n        if (timeDiffMs > staticState.hbTimeoutMs) {\n            LOG.warn(\"SLOT {}: HB is too old {} > {}\", staticState.port, timeDiffMs, staticState.hbTimeoutMs);\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        \n        //The worker is up and running check for profiling requests\n        if (!dynamicState.profileActions.isEmpty()) {\n            HashSet<TopoProfileAction> mod = new HashSet<>(dynamicState.profileActions);\n            HashSet<TopoProfileAction> modPending = new HashSet<>(dynamicState.pendingStopProfileActions);\n            Iterator<TopoProfileAction> iter = mod.iterator();\n            while (iter.hasNext()) {\n                TopoProfileAction action = iter.next();\n                if (!action.topoId.equals(dynamicState.currentAssignment.get_topology_id())) {\n                    iter.remove();\n                    LOG.warn(\"Dropping {} wrong topology is running\", action);\n                    //Not for this topology so skip it\n                } else {\n                    if (modPending.contains(action)) {\n                        boolean isTimeForStop = Time.currentTimeMillis() > action.request.get_time_stamp();\n                        if (isTimeForStop) {\n                            if (dynamicState.container.runProfiling(action.request, true)) {\n                                LOG.debug(\"Stopped {} action finished\", action);\n                                iter.remove();\n                                modPending.remove(action);\n                            } else {\n                                LOG.warn(\"Stopping {} failed, will be retried\", action);\n                            }\n                        } else {\n                            LOG.debug(\"Still pending {} now: {}\", action, Time.currentTimeMillis());\n                        }\n                    } else {\n                        //J_PROFILE_START is not used.  When you see a J_PROFILE_STOP\n                        // start profiling and save it away to stop when timeout happens\n                        if (action.request.get_action() == ProfileAction.JPROFILE_STOP) {\n                            if (dynamicState.container.runProfiling(action.request, false)) {\n                                modPending.add(action);\n                                LOG.debug(\"Started {} now: {}\", action, Time.currentTimeMillis());\n                            } else {\n                                LOG.warn(\"Starting {} failed, will be retried\", action);\n                            }\n                        } else {\n                            if (dynamicState.container.runProfiling(action.request, false)) {\n                                LOG.debug(\"Started {} action finished\", action);\n                                iter.remove();\n                            } else {\n                                LOG.warn(\"Starting {} failed, will be retried\", action);\n                            }\n                        }\n                    }\n                }\n            }\n            dynamicState = dynamicState.withProfileActions(mod, modPending);\n        }\n        Time.sleep(staticState.monitorFreqMs);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleEmpty": "    static DynamicState handleEmpty(DynamicState dynamicState, StaticState staticState) throws InterruptedException, IOException {\n        if (!equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n            return prepareForNewAssignmentNoWorkersRunning(dynamicState, staticState);\n        }\n        //Both assignments are null, just wait\n        if (dynamicState.profileActions != null && !dynamicState.profileActions.isEmpty()) {\n            //Nothing is scheduled here so throw away all of the profileActions\n            LOG.warn(\"Dropping {} no topology is running\", dynamicState.profileActions);\n            dynamicState = dynamicState.withProfileActions(Collections.<TopoProfileAction> emptySet(), Collections.<TopoProfileAction> emptySet());\n        }\n        Time.sleep(1000);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleWaitingForBasicLocalization": "    static DynamicState handleWaitingForBasicLocalization(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.pendingLocalization != null);\n        assert(dynamicState.pendingDownload != null);\n        assert(dynamicState.container == null);\n        \n        //Ignore changes to scheduling while downloading the topology code\n        // We don't support canceling the download through the future yet,\n        // so to keep everything in sync, just wait\n        try {\n            dynamicState.pendingDownload.get(1000, TimeUnit.MILLISECONDS);\n            Future<Void> pendingDownload = staticState.localizer.requestDownloadTopologyBlobs(dynamicState.pendingLocalization, staticState.port);\n            return dynamicState.withPendingLocalization(pendingDownload).withState(MachineState.WAITING_FOR_BLOB_LOCALIZATION);\n        } catch (TimeoutException e) {\n            return dynamicState;\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleKill": "    static DynamicState handleKill(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        if (dynamicState.container.areAllProcessesDead()) {\n            LOG.warn(\"SLOT {} all processes are dead...\", staticState.port);\n            return cleanupCurrentContainer(dynamicState, staticState, \n                    dynamicState.pendingLocalization == null ? MachineState.EMPTY : MachineState.WAITING_FOR_BASIC_LOCALIZATION);\n        }\n\n        LOG.warn(\"SLOT {} force kill and wait...\", staticState.port);\n        dynamicState.container.forceKill();\n        Time.sleep(staticState.killSleepMs);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.run": "    public void run() {\n        try {\n            while(!done) {\n                Set<TopoProfileAction> origProfileActions = new HashSet<>(profiling.get());\n                Set<TopoProfileAction> removed = new HashSet<>(origProfileActions);\n                \n                DynamicState nextState = \n                        stateMachineStep(dynamicState.withNewAssignment(newAssignment.get())\n                                .withProfileActions(origProfileActions, dynamicState.pendingStopProfileActions), staticState);\n\n                if (LOG.isDebugEnabled() || dynamicState.state != nextState.state) {\n                    LOG.info(\"STATE {} -> {}\", dynamicState, nextState);\n                }\n                //Save the current state for recovery\n                if (!equivalent(nextState.currentAssignment, dynamicState.currentAssignment)) {\n                    LOG.info(\"SLOT {}: Changing current assignment from {} to {}\", staticState.port, dynamicState.currentAssignment, nextState.currentAssignment);\n                    saveNewAssignment(nextState.currentAssignment);\n                }\n                \n                // clean up the profiler actions that are not being processed\n                removed.removeAll(dynamicState.profileActions);\n                removed.removeAll(dynamicState.pendingStopProfileActions);\n                for (TopoProfileAction action: removed) {\n                    try {\n                        clusterState.deleteTopologyProfileRequests(action.topoId, action.request);\n                    } catch (Exception e) {\n                        LOG.error(\"Error trying to remove profiling request, it will be retried\", e);\n                    }\n                }\n                Set<TopoProfileAction> orig, copy;\n                do {\n                    orig = profiling.get();\n                    copy = new HashSet<>(orig);\n                    copy.removeAll(removed);\n                } while (!profiling.compareAndSet(orig, copy));\n                dynamicState = nextState;\n            }\n        } catch (Throwable e) {\n            if (!Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e)) {\n                LOG.error(\"Error when processing event\", e);\n                Utils.exitProcess(20, \"Error when processing an event\");\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.saveNewAssignment": "    private void saveNewAssignment(LocalAssignment assignment) {\n        synchronized(staticState.localState) {\n            Map<Integer, LocalAssignment> assignments = staticState.localState.getLocalAssignmentsMap();\n            if (assignments == null) {\n                assignments = new HashMap<>();\n            }\n            if (assignment == null) {\n                assignments.remove(staticState.port);\n            } else {\n                assignments.put(staticState.port, assignment);\n            }\n            staticState.localState.setLocalAssignmentsMap(assignments);\n        }\n        Map<Long, LocalAssignment> update = null;\n        Map<Long, LocalAssignment> orig = null;\n        do {\n            Long lport = new Long(staticState.port);\n            orig = cachedCurrentAssignments.get();\n            update = new HashMap<>(orig);\n            if (assignment == null) {\n                update.remove(lport);\n            } else {\n                update.put(lport, assignment);\n            }\n        } while (!cachedCurrentAssignments.compareAndSet(orig, update));\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withProfileActions": "        public DynamicState withProfileActions(Set<TopoProfileAction> profileActions, Set<TopoProfileAction> pendingStopProfileActions) {\n            return new DynamicState(this.state, this.newAssignment,\n                    this.container, this.currentAssignment,\n                    this.pendingLocalization, this.startTime,\n                    this.pendingDownload, profileActions,\n                    pendingStopProfileActions);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withNewAssignment": "        public DynamicState withNewAssignment(LocalAssignment newAssignment) {\n            return new DynamicState(this.state, newAssignment,\n                    this.container, this.currentAssignment,\n                    this.pendingLocalization, this.startTime,\n                    this.pendingDownload, this.profileActions,\n                    this.pendingStopProfileActions);\n        }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess (int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }"
        },
        "bug_report": {
            "Title": "Dependency artifacts should be uploaded to blobstore with READ permission for all",
            "Description": "When we submit topology via specific user with dependency artifacts, submitter uploads artifacts to the blobstore with user which runs the submission.\n\nSince uploaded artifacts are uploaded once and shared globally, other user might need to use uploaded artifact. (This is completely fine for non-secured cluster.) In this case, Supervisor fails to get artifact and crashes in result.\n\n{code}\n2017-04-28 04:56:46.594 o.a.s.l.AsyncLocalizer Async Localizer [WARN] Caught Exception While Downloading (rethrowing)...\norg.apache.storm.generated.AuthorizationException: null\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n2017-04-28 04:56:46.597 o.a.s.d.s.Slot SLOT_6701 [ERROR] Error when processing event\njava.util.concurrent.ExecutionException: AuthorizationException(msg:<user> does not have READ access to dep-org.apache.curator-curator-framework-jar-2.10.0.jar)\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_112]\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_112]\n\tat org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:380) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:275) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:740) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\nCaused by: org.apache.storm.generated.AuthorizationException\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n2017-04-28 04:56:46.597 o.a.s.u.Utils SLOT_6701 [ERROR] Halting process: Error when processing an event\njava.lang.RuntimeException: Halting process: Error when processing an event\n\tat org.apache.storm.utils.Utils.exitProcess(Utils.java:1774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n2017-04-28 04:56:46.599 o.a.s.d.s.Supervisor Thread-7 [INFO] Shutting down supervisor 775c158b-0a2d-40be-9e02-a9662d8bc5c4\n{code}\n\nSo we need to upload artifacts with READ permission to all, or at least supervisor should be able to read them at all."
        }
    },
    {
        "filename": "STORM-2879.json",
        "creation_time": "2018-01-03T07:07:49.000+0000",
        "stack_trace": "```\norg.apache.storm.generated.KeyNotFoundException: null\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\n\norg.apache.storm.generated.KeyNotFoundException: null\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\n\norg.apache.storm.generated.KeyNotFoundException: null\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:124) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\n\norg.apache.storm.generated.KeyNotFoundException: null\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:125) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\n\njava.io.FileNotFoundException: File '/opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785/stormconf.ser' does not exist\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:292) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1815) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfGivenPath(ConfigUtils.java:264) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfImpl(ConfigUtils.java:376) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConf(ConfigUtils.java:370) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:226) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:213) ~[storm-core-1.1.2-mt001.jar:?]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\n```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.read": "      public void read(org.apache.thrift.protocol.TProtocol prot, getOwnerResourceSummaries_result struct) throws org.apache.thrift.TException {\n        TTupleProtocol iprot = (TTupleProtocol) prot;\n        BitSet incoming = iprot.readBitSet(2);\n        if (incoming.get(0)) {\n          {\n            org.apache.thrift.protocol.TList _list879 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());\n            struct.success = new ArrayList<OwnerResourceSummary>(_list879.size);\n            OwnerResourceSummary _elem880;\n            for (int _i881 = 0; _i881 < _list879.size; ++_i881)\n            {\n              _elem880 = new OwnerResourceSummary();\n              _elem880.read(iprot);\n              struct.success.add(_elem880);\n            }\n          }\n          struct.set_success_isSet(true);\n        }\n        if (incoming.get(1)) {\n          struct.aze = new AuthorizationException();\n          struct.aze.read(iprot);\n          struct.set_aze_isSet(true);\n        }\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_ite_isSet": "    public void set_ite_isSet(boolean value) {\n      if (!value) {\n        this.ite = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_id_isSet": "    public void set_id_isSet(boolean value) {\n      if (!value) {\n        this.id = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_location_isSet": "    public void set_location_isSet(boolean value) {\n      if (!value) {\n        this.location = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_is_include_sys_isSet": "    public void set_is_include_sys_isSet(boolean value) {\n      __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __IS_INCLUDE_SYS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_meta_isSet": "    public void set_meta_isSet(boolean value) {\n      if (!value) {\n        this.meta = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_user_isSet": "    public void set_user_isSet(boolean value) {\n      if (!value) {\n        this.user = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_action_isSet": "    public void set_action_isSet(boolean value) {\n      if (!value) {\n        this.action = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_name_isSet": "    public void set_name_isSet(boolean value) {\n      if (!value) {\n        this.name = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_component_isSet": "    public void set_component_isSet(boolean value) {\n      if (!value) {\n        this.component = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_host_isSet": "    public void set_host_isSet(boolean value) {\n      if (!value) {\n        this.host = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_e_isSet": "    public void set_e_isSet(boolean value) {\n      if (!value) {\n        this.e = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_file_isSet": "    public void set_file_isSet(boolean value) {\n      if (!value) {\n        this.file = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.validate": "    public void validate() throws org.apache.thrift.TException {\n      // check for required fields\n      // check for sub-struct validity\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_enable_isSet": "    public void set_enable_isSet(boolean value) {\n      __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __ENABLE_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_key_isSet": "    public void set_key_isSet(boolean value) {\n      if (!value) {\n        this.key = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_aze_isSet": "    public void set_aze_isSet(boolean value) {\n      if (!value) {\n        this.aze = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_options_isSet": "    public void set_options_isSet(boolean value) {\n      if (!value) {\n        this.options = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_samplingPercentage_isSet": "    public void set_samplingPercentage_isSet(boolean value) {\n      __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __SAMPLINGPERCENTAGE_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_config_isSet": "    public void set_config_isSet(boolean value) {\n      if (!value) {\n        this.config = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_component_id_isSet": "    public void set_component_id_isSet(boolean value) {\n      if (!value) {\n        this.component_id = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_uploadedJarLocation_isSet": "    public void set_uploadedJarLocation_isSet(boolean value) {\n      if (!value) {\n        this.uploadedJarLocation = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_kae_isSet": "    public void set_kae_isSet(boolean value) {\n      if (!value) {\n        this.kae = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_owner_isSet": "    public void set_owner_isSet(boolean value) {\n      if (!value) {\n        this.owner = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_creds_isSet": "    public void set_creds_isSet(boolean value) {\n      if (!value) {\n        this.creds = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_topology_id_isSet": "    public void set_topology_id_isSet(boolean value) {\n      if (!value) {\n        this.topology_id = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getScheme": "      public getOwnerResourceSummaries_resultTupleScheme getScheme() {\n        return new getOwnerResourceSummaries_resultTupleScheme();\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_session_isSet": "    public void set_session_isSet(boolean value) {\n      if (!value) {\n        this.session = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_replication_isSet": "    public void set_replication_isSet(boolean value) {\n      __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __REPLICATION_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_chunk_isSet": "    public void set_chunk_isSet(boolean value) {\n      if (!value) {\n        this.chunk = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_window_isSet": "    public void set_window_isSet(boolean value) {\n      if (!value) {\n        this.window = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_jsonConf_isSet": "    public void set_jsonConf_isSet(boolean value) {\n      if (!value) {\n        this.jsonConf = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_knf_isSet": "    public void set_knf_isSet(boolean value) {\n      if (!value) {\n        this.knf = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_topology_isSet": "    public void set_topology_isSet(boolean value) {\n      if (!value) {\n        this.topology = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_profileRequest_isSet": "    public void set_profileRequest_isSet(boolean value) {\n      if (!value) {\n        this.profileRequest = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.is_set_success": "    public boolean is_set_success() {\n      return this.success != null;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_beginBlobDownload": "    public void send_beginBlobDownload(String key) throws org.apache.thrift.TException\n    {\n      beginBlobDownload_args args = new beginBlobDownload_args();\n      args.set_key(key);\n      sendBase(\"beginBlobDownload\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.NimbusBlobStore.getBlob": "    public InputStreamWithMeta getBlob(String key) throws AuthorizationException, KeyNotFoundException {\n        try {\n            synchronized(client) {\n                return new NimbusDownloadInputStream(client.getClient().beginBlobDownload(key));\n            }\n        } catch (AuthorizationException | KeyNotFoundException exp) {\n            throw exp;\n        } catch (TException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.ConfigUtils.readSupervisorStormConfGivenPath": "    public static Map<String, Object> readSupervisorStormConfGivenPath(Map<String, Object> conf, String topoConfPath) throws IOException {\n        Map<String, Object> ret = new HashMap<>(conf);\n        ret.putAll(Utils.fromCompressedJsonConf(FileUtils.readFileToByteArray(new File(topoConfPath))));\n        return ret;\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.ConfigUtils.readSupervisorStormConfImpl": "    public Map<String, Object> readSupervisorStormConfImpl(Map<String, Object> conf, String stormId) throws IOException {\n        String stormRoot = supervisorStormDistRoot(conf, stormId);\n        String confPath = supervisorStormConfPath(stormRoot);\n        return readSupervisorStormConfGivenPath(conf, confPath);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.ConfigUtils.supervisorStormConfPath": "    public static String supervisorStormConfPath(String stormRoot) {\n        return (concatIfNotNull(stormRoot) + FILE_SEPARATOR + \"stormconf.ser\");\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.ConfigUtils.supervisorStormDistRoot": "    public static String supervisorStormDistRoot(Map<String, Object> conf, String stormId) throws IOException {\n        return _instance.supervisorStormDistRootImpl(conf, stormId);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.ConfigUtils.readSupervisorStormConf": "    public static Map<String, Object> readSupervisorStormConf(Map<String, Object> conf, String stormId) throws IOException {\n        return _instance.readSupervisorStormConfImpl(conf, stormId);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.fromCompressedJsonConf": "    public static Map<String, Object> fromCompressedJsonConf(byte[] serialized) {\n        try {\n            ByteArrayInputStream bis = new ByteArrayInputStream(serialized);\n            InputStreamReader in = new InputStreamReader(new GZIPInputStream(bis));\n            Object ret = JSONValue.parseWithException(in);\n            in.close();\n            return (Map<String,Object>)ret;\n        } catch (IOException | ParseException e) {\n            throw new RuntimeException(e);\n        }\n    }"
        },
        "bug_report": {
            "Title": "Supervisor collapse continuously when there is a expired assignment for overdue storm",
            "Description": "For now, when a topology is reassigned or killed for a cluster, supervisor will delete 4 files for an overdue storm:\r\n- storm-code\r\n- storm-ser\r\n- storm-jar\r\n- LocalAssignment\r\n\r\nSlot.java\r\nstatic DynamicState cleanupCurrentContainer(DynamicState dynamicState, StaticState staticState, MachineState nextState) throws Exception {\r\n        assert(dynamicState.container != null);\r\n        assert(dynamicState.currentAssignment != null);\r\n        assert(dynamicState.container.areAllProcessesDead());\r\n        \r\n        dynamicState.container.cleanUp();\r\n        staticState.localizer.releaseSlotFor(dynamicState.currentAssignment, staticState.port);\r\n        DynamicState ret = dynamicState.withCurrentAssignment(null, null);\r\n        if (nextState != null) {\r\n            ret = ret.withState(nextState);\r\n        }\r\n        return ret;\r\n    }\r\n\r\nBut we do not make a transaction to do this, if an exception occurred during deleting storm-code/ser/jar, an overdue local assignment will be left on disk.\r\n\r\nThen when supervisor restart from the exception above, the slots will be initial and container will be recovered from LocalAssignments, the blob store will fetch the files from Nimbus/Master, but will get a KeyNotFoundException, and supervisor collapses again.\r\n\r\nThis will happens continuously and supervisor will never recover until we clean up all the local assignments manually.\r\n\r\nThis is the stack:\r\n2017-12-27 14:15:04.434 o.a.s.l.AsyncLocalizer [INFO] Cleaning up unused topologies in /opt/meituan/storm/data/supervisor/stormdist\r\n2017-12-27 14:15:04.434 o.a.s.d.s.AdvancedFSOps [INFO] Deleting path /opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785\r\n2017-12-27 14:15:04.445 o.a.s.d.s.Slot [INFO] STATE EMPTY msInState: 109 -> WAITING_FOR_BASIC_LOCALIZATION msInState: 1\r\n2017-12-27 14:15:04.471 o.a.s.d.s.Supervisor [INFO] Starting supervisor with id 255d3fed-f3ee-4c7e-8a08-b693c9a6a072 at host gq-data-rt48.gq.sankuai.com.\r\n2017-12-27 14:15:04.502 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.611 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.718 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormcode.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:124) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.825 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormcode.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:124) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.932 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormconf.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:125) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:05.039 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormconf.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:125) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:05.140 o.a.s.u.Utils [INFO] Could not extract resources from /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar\r\n2017-12-27 14:15:05.142 o.a.s.d.s.Slot [INFO] STATE WAITING_FOR_BASIC_LOCALIZATION msInState: 697 -> WAITING_FOR_BLOB_LOCALIZATION msInState: 0\r\n2017-12-27 14:15:05.142 o.a.s.l.AsyncLocalizer [WARN] Caught Exception While Downloading (rethrowing)... \r\njava.io.FileNotFoundException: File '/opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785/stormconf.ser' does not exist\r\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:292) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1815) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfGivenPath(ConfigUtils.java:264) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfImpl(ConfigUtils.java:376) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConf(ConfigUtils.java:370) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:226) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:213) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]"
        }
    },
    {
        "filename": "STORM-3012.json",
        "creation_time": "2018-03-27T15:30:32.000+0000",
        "stack_trace": "```\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2508) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:195) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClient.waitUntilReady": "    private void waitUntilReady() throws PacemakerConnectionException, InterruptedException {\n        // Wait for 'ready' (channel connected and maybe authentication)\n        if(!ready.get() || channelRef.get() == null) {\n            synchronized(this) {\n                if(!ready.get()) {\n                    LOG.debug(\"Waiting for netty channel to be ready.\");\n                    this.wait(1000);\n                    if(!ready.get() || channelRef.get() == null) {\n                        throw new PacemakerConnectionException(\"Timed out waiting for channel ready.\");\n                    }\n                }\n            }\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClient.send": "    public HBMessage send(HBMessage m) throws InterruptedException {\n        LOG.debug(\"Sending message: {}\", m.toString());\n\n        int next = availableMessageSlots.take();\n        synchronized (m) {\n            m.set_message_id(next);\n            messages[next] = m;\n            LOG.debug(\"Put message in slot: {}\", Integer.toString(next));\n            do {\n                try {\n                    waitUntilReady();\n                    Channel channel = channelRef.get();\n                    if (channel != null) {\n                        channel.write(m);\n                        m.wait(1000);\n                    }\n                } catch (PacemakerConnectionException exp) {\n                    LOG.error(\"error attempting to write to a channel {}\", exp);\n                }\n            } while (messages[next] == m);\n        }\n\n        HBMessage ret = messages[next];\n        if(ret == null) {\n            // This can happen if we lost the connection and subsequently reconnected or timed out.\n            send(m);\n        }\n        messages[next] = null;\n        LOG.debug(\"Got Response: {}\", ret);\n        return ret;\n\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClientPool.sendAll": "    public List<HBMessage> sendAll(HBMessage m) throws PacemakerConnectionException, InterruptedException {\n        List<HBMessage> responses = new ArrayList<HBMessage>();\n        LOG.debug(\"Using servers: {}\", servers);\n        for(String s : servers) {\n            HBMessage response = getClientForServer(s).send(m);\n            responses.add(response);\n\n        }\n        if(responses.size() == 0) {\n            throw new PacemakerConnectionException(\"Failed to connect to any Pacemaker.\");\n        }\n        return responses;\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClientPool.getClientForServer": "    private PacemakerClient getClientForServer(String server) {\n        PacemakerClient client = clientForServer.get(server);\n        if(client == null) {\n            client = new PacemakerClient(config, server);\n            clientForServer.put(server, client);\n        }\n        return client;\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClientPool.send": "    public HBMessage send(HBMessage m) throws InterruptedException {\n            return getWriteClient().send(m);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children": "    public List<String> get_worker_hb_children(String path, boolean watch) {\n        int retry = maxRetries;\n        while (true) {\n            try {\n                HashSet<String> retSet = new HashSet<>();\n\n                HBMessage message = new HBMessage(HBServerMessageType.GET_ALL_NODES_FOR_PATH, HBMessageData.path(path));\n                List<HBMessage> responses = pacemakerClientPool.sendAll(message);\n                for(HBMessage response : responses) {\n                    if (response.get_type() != HBServerMessageType.GET_ALL_NODES_FOR_PATH_RESPONSE) {\n                        LOG.error(\"get_worker_hb_children: Invalid Response Type\");\n                        continue;\n                    }\n                    if(response.get_data().get_nodes().get_pulseIds() != null) {\n                        retSet.addAll(response.get_data().get_nodes().get_pulseIds());\n                    }\n                }\n\n                LOG.debug(\"Successful get_worker_hb_children\");\n                return new ArrayList<>(retSet);\n            } catch (PacemakerConnectionException e) {\n                if (retry <= 0) {\n                    throw new RuntimeException(e);\n                }\n                retry--;\n                LOG.error(\"{} Failed to get_worker_hb_children. Will make {} more attempts.\", e.getMessage(), retry);\n            } catch (InterruptedException e) {\n                LOG.debug(\"get_worker_hb_children got interrupted: {}\", e);\n                throw new RuntimeException(e);\n            }\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.PaceMakerStateStorage.get_data": "    public byte[] get_data(String path, boolean watch) {\n        return stateStorage.get_data(path, watch);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms": "    public List<String> heartbeatStorms() {\n        return stateStorage.get_worker_hb_children(ClusterUtils.WORKERBEATS_SUBTREE, false);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "            public void run() {\n                func.run();\n                // This avoids a race condition with cancel-timer.\n                schedule(recurSecs, this, false, jitterMs);\n            }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }"
        },
        "bug_report": {
            "Title": "Nimbus will crash if pacemaker is restarted",
            "Description": "Below is the nimbus.log when I restarted pacemaker. Nimbus crashed because of NPE.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\n2018-03-26 21:39:18.404 main o.a.s.z.LeaderElectorImp [INFO] Queued up for leader lock.\r\n2018-03-26 21:39:18.458 main o.a.s.d.m.MetricsUtils [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableRepor\r\nter\r\n2018-03-26 21:39:18.461 main o.a.s.d.m.r.JmxPreparableReporter [INFO] Preparing...\r\n2018-03-26 21:39:18.527 main o.a.s.m.StormMetricsRegistry [INFO] Started statistics report plugin...\r\n2018-03-26 21:39:18.710 main o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:18.738 Refresh-TGT o.a.s.m.n.Login [INFO] TGT refresh thread started.\r\n2018-03-26 21:39:18.739 main o.a.s.z.ClientZookeeper [INFO] Staring ZK Curator\r\n2018-03-26 21:39:18.739 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Starting\r\n2018-03-26 21:39:18.747 Refresh-TGT o.a.s.m.n.Login [INFO] TGT valid starting at:        Mon Mar 26 21:39:18 UTC 2018\r\n2018-03-26 21:39:18.747 Refresh-TGT o.a.s.m.n.Login [INFO] TGT expires:                  Tue Mar 27 21:39:18 UTC 2018\r\n2018-03-26 21:39:18.747 Refresh-TGT o.a.s.m.n.Login [INFO] TGT refresh sleeping until: Tue Mar 27 17:39:22 UTC 2018\r\n2018-03-26 21:39:18.756 main o.a.z.ZooKeeper [INFO] Initiating client connection, connectString=openqe74blue-gw.blue.ygrid.yahoo.com:2181 sessionTimeout\r\n=60000 watcher=org.apache.curator.ConnectionState@148c7c4b\r\n2018-03-26 21:39:18.807 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Default schema\r\n2018-03-26 21:39:18.814 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.c.ZooKeeperSaslClient [INFO] Client will use GSSAPI as SASL mec\r\nhanism.\r\n2018-03-26 21:39:18.815 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Opening socket connection to server openqe74b\r\nlue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181. Will attempt to SASL-authenticate using Login Context section 'Client'\r\n2018-03-26 21:39:18.816 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Socket connection established to openqe74blue\r\n-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, initiating session\r\n2018-03-26 21:39:18.817 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Session establishment complete on server open\r\nqe74blue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, sessionid = 0x1624f6d49dd0cdd, negotiated timeout = 40000\r\n2018-03-26 21:39:18.818 main-EventThread o.a.c.f.s.ConnectionStateManager [INFO] State change: CONNECTED\r\n2018-03-26 21:39:18.839 Curator-Framework-0 o.a.c.f.i.CuratorFrameworkImpl [INFO] backgroundOperationsLoop exiting\r\n2018-03-26 21:39:18.841 main o.a.z.ZooKeeper [INFO] Session: 0x1624f6d49dd0cdd closed\r\n2018-03-26 21:39:18.842 main-EventThread o.a.z.ClientCnxn [INFO] EventThread shut down\r\n2018-03-26 21:39:18.844 main o.a.s.z.ClientZookeeper [INFO] Staring ZK Curator\r\n2018-03-26 21:39:18.844 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Starting\r\n2018-03-26 21:39:18.875 main o.a.z.ZooKeeper [INFO] Initiating client connection, connectString=openqe74blue-gw.blue.ygrid.yahoo.com:2181/storm_ystormQE\r\n_CI sessionTimeout=60000 watcher=org.apache.curator.ConnectionState@211febf3\r\n2018-03-26 21:39:18.908 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.c.ZooKeeperSaslClient [INFO] Client will use GSSAPI as SASL mec\r\nhanism.\r\n2018-03-26 21:39:18.909 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Opening socket connection to server openqe74b\r\nlue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181. Will attempt to SASL-authenticate using Login Context section 'Client'\r\n2018-03-26 21:39:18.910 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Socket connection established to openqe74blue\r\n-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, initiating session\r\n2018-03-26 21:39:18.911 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Session establishment complete on server open\r\nqe74blue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, sessionid = 0x1624f6d49dd0cde, negotiated timeout = 40000\r\n2018-03-26 21:39:18.920 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Default schema\r\n2018-03-26 21:39:18.923 main-EventThread o.a.c.f.s.ConnectionStateManager [INFO] State change: CONNECTED\r\n2018-03-26 21:39:18.986 main o.a.s.d.n.Nimbus [INFO] Starting nimbus server for storm version '2.0.0.y'\r\n2018-03-26 21:39:19.931 main-EventThread o.a.s.z.Zookeeper [INFO] active-topology-blobs [] local-topology-blobs [] diff-topology-blobs []\r\n2018-03-26 21:39:19.932 main-EventThread o.a.s.z.Zookeeper [INFO] active-topology-dependencies [] local-blobs [] diff-topology-dependencies []\r\n2018-03-26 21:39:19.932 main-EventThread o.a.s.z.Zookeeper [INFO] Accepting leadership, all active topologies and corresponding dependencies found local\r\nly.\r\n2018-03-26 21:39:20.636 timer o.a.s.d.n.Nimbus [INFO] Scheduling took 1381 ms for 0 topologies\r\n2018-03-26 21:39:20.901 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: open\r\nqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:20.901 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 101ms (NOT MAX)\r\n2018-03-26 21:39:21.003 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: open\r\nqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.003 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 102ms (NOT MAX)\r\n2018-03-26 21:39:21.106 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.106 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 106ms (NOT MAX)\r\n2018-03-26 21:39:21.214 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.214 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 115ms (NOT MAX)\r\n2018-03-26 21:39:21.331 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.331 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 129ms (NOT MAX)\r\n2018-03-26 21:39:21.462 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.462 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 162ms (NOT MAX)\r\n2018-03-26 21:39:21.626 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.626 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 176ms (NOT MAX)\r\n2018-03-26 21:39:21.807 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.807 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 319ms (NOT MAX)\r\n2018-03-26 21:39:21.888 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:22.128 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:22.128 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 603ms (NOT MAX)\r\n2018-03-26 21:39:22.733 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:22.733 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 868ms (NOT MAX)\r\n2018-03-26 21:39:22.888 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:23.603 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:23.603 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 1494ms (NOT MAX)\r\n2018-03-26 21:39:23.888 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:24.889 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:25.100 client-worker-4 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:36922 to openqe74blue-n1.b        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:25.100 client-worker-4 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:36922 to openqe74blue-n1.b\r\nlue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:25.107 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n2018-03-26 21:39:25.116 client-worker-4 o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:25.121 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Got Client: com.sun.security.sasl.gsskerb.GssKrb5Client@116ce525\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:37614 to openqe74blue-n2.blue.ygrid.yahoo.com/10.215.76.243:6699\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:24.889 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:25.100 client-worker-4 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:36922 to openqe74blue-n1.b\r\nlue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:25.107 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n2018-03-26 21:39:25.116 client-worker-4 o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:25.121 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Got Client: com.sun.security.sasl.gsskerb.GssKrb5Client@116ce525\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:37614 to openqe74blue-n2.b\r\nlue.ygrid.yahoo.com/10.215.76.243:6699\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n2018-03-26 21:39:25.763 client-worker-1 o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:25.765 client-worker-1 o.a.s.m.n.KerberosSaslNettyClient [INFO] Got Client: com.sun.security.sasl.gsskerb.GssKrb5Client@493cfe64\r\n2018-03-26 21:39:26.596 timer o.a.s.d.n.Nimbus [ERROR] Error while processing event\r\njava.lang.RuntimeException: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2508) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:195) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-03-26 21:39:26.596 timer o.a.s.u.Utils [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$23(Nimbus.java:1154) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:106) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:26.600 Thread-16 o.a.s.u.Utils [INFO] Halting after 5 seconds\r\n2018-03-26 21:39:26.606 Thread-15 o.a.s.d.n.Nimbus [INFO] Shutting down master\r\n2018-03-26 21:39:31.600 Thread-16 o.a.s.u.Utils [WARN] Forcing Halt...\r\n{code}\r\n\u00a0\r\n\r\n\u00a0\r\n\r\nThis is because when [https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/pacemaker/PacemakerClient.java#L195-L198]\u00a0happens,\r\n\r\n\u00a0\r\n{code:java}\r\nHBMessage ret = messages[next];\r\nif(ret == null) {\r\n// This can happen if we lost the connection and subsequently reconnected or timed out.\r\nsend(m);\r\n}\r\nmessages[next] = null;\r\nLOG.debug(\"Got Response: {}\", ret);\r\nreturn ret;\r\n{code}\r\nit returns null result. And the null result is inserted into [https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/pacemaker/PacemakerClientPool.java#L65-L66]\r\n{code:java}\r\nfor(String s : servers) {\r\nHBMessage response = getClientForServer(s).send(m);\r\nresponses.add(response);\r\n}\r\n{code}\r\nwhich leads to [https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/cluster/PaceMakerStateStorage.java#L195]\r\n\r\n\u00a0\r\n{code:java}\r\nfor(HBMessage response : responses) {\r\nif (response.get_type() != HBServerMessageType.GET_ALL_NODES_FOR_PATH_RESPONSE) {\r\nLOG.error(\"get_worker_hb_children: Invalid Response Type\");\r\ncontinue;\r\n}\r\nif(response.get_data().get_nodes().get_pulseIds() != null) {\r\nretSet.addAll(response.get_data().get_nodes().get_pulseIds());\r\n}\r\n}\r\n{code}\r\n\u00a0\r\n\r\nand this is where NPE\u00a0happens\u00a0"
        }
    },
    {
        "filename": "STORM-3073.json",
        "creation_time": "2018-05-15T11:12:21.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.IllegalStateException: Queue full\n\tat org.apache.storm.executor.Executor.accept(Executor.java:282) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:133) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:110) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:101) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:168) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:157) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.Utils$2.run(Utils.java:349) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]\nCaused by: java.lang.IllegalStateException: Queue full\n\tat java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:1.8.0_144]\n\tat org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:516) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:66) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg(SpoutOutputCollectorImpl.java:140) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit(SpoutOutputCollectorImpl.java:70) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.spout.SpoutOutputCollector.emit(SpoutOutputCollector.java:42) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.loadgen.LoadSpout.fail(LoadSpout.java:135) ~[stormjar.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor.failSpoutMsg(SpoutExecutor.java:360) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:120) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.RotatingMap.rotate(RotatingMap.java:63) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor.tupleActionFn(SpoutExecutor.java:295) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.Executor.accept(Executor.java:278) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.executor.Executor.accept": "    public void accept(Object event) {\n        if (event == JCQueue.INTERRUPT) {\n            throw new RuntimeException(new InterruptedException(\"JCQ processing interrupted\"));\n        }\n        AddressedTuple addressedTuple = (AddressedTuple) event;\n        int taskId = addressedTuple.getDest();\n\n        TupleImpl tuple = (TupleImpl) addressedTuple.getTuple();\n        if (isDebug) {\n            LOG.info(\"Processing received message FOR {} TUPLE: {}\", taskId, tuple);\n        }\n\n        try {\n            if (taskId != AddressedTuple.BROADCAST_DEST) {\n                tupleActionFn(taskId, tuple);\n            } else {\n                for (Integer t : taskIds) {\n                    tupleActionFn(t, tuple);\n                }\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.Executor.tupleActionFn": "    public abstract void tupleActionFn(int taskId, TupleImpl tuple) throws Exception;\n\n    @Override\n    public void accept(Object event) {\n        if (event == JCQueue.INTERRUPT) {\n            throw new RuntimeException(new InterruptedException(\"JCQ processing interrupted\"));\n        }\n        AddressedTuple addressedTuple = (AddressedTuple) event;\n        int taskId = addressedTuple.getDest();\n\n        TupleImpl tuple = (TupleImpl) addressedTuple.getTuple();\n        if (isDebug) {\n            LOG.info(\"Processing received message FOR {} TUPLE: {}\", taskId, tuple);\n        }\n\n        try {\n            if (taskId != AddressedTuple.BROADCAST_DEST) {\n                tupleActionFn(taskId, tuple);\n            } else {\n                for (Integer t : taskIds) {\n                    tupleActionFn(t, tuple);\n                }\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.JCQueue.consumeImpl": "    private int consumeImpl(Consumer consumer, ExitCondition exitCond) throws InterruptedException {\n        int drainCount = 0;\n        while (exitCond.keepRunning()) {\n            Object tuple = recvQueue.poll();\n            if (tuple == null) {\n                break;\n            }\n            consumer.accept(tuple);\n            ++drainCount;\n        }\n\n        int overflowDrainCount = 0;\n        int limit = overflowQ.size();\n        while (exitCond.keepRunning() && (overflowDrainCount < limit)) { // 2nd cond prevents staying stuck with consuming overflow\n            Object tuple = overflowQ.poll();\n            ++overflowDrainCount;\n            consumer.accept(tuple);\n        }\n        int total = drainCount + overflowDrainCount;\n        if (total > 0) {\n            consumer.flush();\n        }\n        return total;\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.JCQueue.flush": "        public void flush() throws InterruptedException {\n            if (currentBatch.isEmpty()) {\n                return;\n            }\n            int publishCount = q.tryPublishInternal(currentBatch);\n            int retryCount = 0;\n            while (publishCount == 0) { // retry till at least 1 element is drained\n                q.metrics.notifyInsertFailure();\n                if (retryCount == 0) { // check avoids multiple log msgs when in a idle loop\n                    LOG.debug(\"Experiencing Back Pressure when flushing batch to Q: {}. Entering BackPressure Wait.\", q.getName());\n                }\n                retryCount = q.backPressureWaitStrategy.idle(retryCount);\n                if (Thread.interrupted()) {\n                    throw new InterruptedException();\n                }\n                publishCount = q.tryPublishInternal(currentBatch);\n            }\n            currentBatch.subList(0, publishCount).clear();\n        }",
            "storm-client.src.jvm.org.apache.storm.utils.JCQueue.keepRunning": "        boolean keepRunning();\n    }\n\n    /* Thread safe. Same instance can be used across multiple threads */\n    private static class DirectInserter implements Inserter {",
            "storm-client.src.jvm.org.apache.storm.utils.JCQueue.accept": "        void accept(Object event);\n\n        void flush() throws InterruptedException;\n    }\n\n    public interface ExitCondition {",
            "storm-client.src.jvm.org.apache.storm.utils.JCQueue.size": "    public int size() {\n        return recvQueue.size() + overflowQ.size();\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.JCQueue.consume": "    public int consume(JCQueue.Consumer consumer, ExitCondition exitCond) {\n        try {\n            return consumeImpl(consumer, exitCond);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.call": "            public Long call() throws Exception {\n                int receiveCount = 0;\n                if (recvqCheckSkips++ == recvqCheckSkipCountMax) {\n                    receiveCount = receiveQueue.consume(SpoutExecutor.this);\n                    recvqCheckSkips = 0;\n                }\n                long currCount = emittedCount.get();\n                boolean reachedMaxSpoutPending = (maxSpoutPending != 0) && (pending.size() >= maxSpoutPending);\n                boolean isActive = stormActive.get();\n\n                if (!isActive) {\n                    inactiveExecute();\n                    return 0L;\n                }\n\n                if (!lastActive.get()) {\n                    lastActive.set(true);\n                    activateSpouts();\n                }\n                boolean pendingEmitsIsEmpty = tryFlushPendingEmits();\n                boolean noEmits = true;\n                long emptyStretch = 0;\n\n                if (!reachedMaxSpoutPending && pendingEmitsIsEmpty) {\n                    for (int j = 0; j < spouts.size(); j++) { // in critical path. don't use iterators.\n                        spouts.get(j).nextTuple();\n                    }\n                    noEmits = (currCount == emittedCount.get());\n                    if (noEmits) {\n                        emptyEmitStreak.increment();\n                    } else {\n                        emptyStretch = emptyEmitStreak.get();\n                        emptyEmitStreak.set(0);\n                    }\n                }\n                if (reachedMaxSpoutPending) {\n                    if (rmspCount == 0) {\n                        LOG.debug(\"Reached max spout pending\");\n                    }\n                    rmspCount++;\n                } else {\n                    if (rmspCount > 0) {\n                        LOG.debug(\"Ended max spout pending stretch of {} iterations\", rmspCount);\n                    }\n                    rmspCount = 0;\n                }\n\n                if (receiveCount > 1) {\n                    // continue without idling\n                    return 0L;\n                }\n                if (!pendingEmits.isEmpty()) { // then facing backpressure\n                    backPressureWaitStrategy();\n                    return 0L;\n                }\n                bpIdleCount = 0;\n                if (noEmits) {\n                    spoutWaitStrategy(reachedMaxSpoutPending, emptyStretch);\n                    return 0L;\n                }\n                swIdleCount = 0;\n                return 0L;\n            }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.spoutWaitStrategy": "            private void spoutWaitStrategy(boolean reachedMaxSpoutPending, long emptyStretch) throws InterruptedException {\n                emptyEmitStreak.increment();\n                long start = Time.currentTimeMillis();\n                swIdleCount = spoutWaitStrategy.idle(swIdleCount);\n                if (reachedMaxSpoutPending) {\n                    spoutThrottlingMetrics.skippedMaxSpoutMs(Time.currentTimeMillis() - start);\n                } else {\n                    if (emptyStretch > 0) {\n                        LOG.debug(\"Ending Spout Wait Stretch of {}\", emptyStretch);\n                    }\n                }\n            }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.getSpoutRecvqCheckSkipCount": "    public int getSpoutRecvqCheckSkipCount() {\n        if (ackingEnabled) {\n            return 0; // always check recQ if ACKing enabled\n        }\n        return ObjectReader.getInt(conf.get(Config.TOPOLOGY_SPOUT_RECVQ_SKIPS), 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.backPressureWaitStrategy": "            private void backPressureWaitStrategy() throws InterruptedException {\n                long start = Time.currentTimeMillis();\n                if (bpIdleCount == 0) { // check avoids multiple log msgs when in a idle loop\n                    LOG.debug(\"Experiencing Back Pressure from downstream components. Entering BackPressure Wait.\");\n                }\n                bpIdleCount = backPressureWaitStrategy.idle(bpIdleCount);\n                spoutThrottlingMetrics.skippedBackPressureMs(Time.currentTimeMillis() - start);\n            }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.init": "    public void init(final ArrayList<Task> idToTask, int idToTaskBase) {\n        this.threadId = Thread.currentThread().getId();\n        executorTransfer.initLocalRecvQueues();\n        while (!stormActive.get()) {\n            Utils.sleep(100);\n        }\n\n        LOG.info(\"Opening spout {}:{}\", componentId, taskIds);\n        this.idToTask = idToTask;\n        this.maxSpoutPending = ObjectReader.getInt(topoConf.get(Config.TOPOLOGY_MAX_SPOUT_PENDING), 0) * idToTask.size();\n        this.spouts = new ArrayList<>();\n        for (Task task : idToTask) {\n            if (task != null) {\n                this.spouts.add((ISpout) task.getTaskObject());\n            }\n        }\n        this.pending = new RotatingMap<>(2, new RotatingMap.ExpiredCallback<Long, TupleInfo>() {\n            @Override\n            public void expire(Long key, TupleInfo tupleInfo) {\n                Long timeDelta = null;\n                if (tupleInfo.getTimestamp() != 0) {\n                    timeDelta = Time.deltaMs(tupleInfo.getTimestamp());\n                }\n                failSpoutMsg(SpoutExecutor.this, idToTask.get(tupleInfo.getTaskId() - idToTaskBase), timeDelta, tupleInfo, \"TIMEOUT\");\n            }\n        });\n\n        this.spoutThrottlingMetrics.registerAll(topoConf, idToTask.get(taskIds.get(0) - idToTaskBase).getUserContext());\n        this.errorReportingMetrics.registerAll(topoConf, idToTask.get(taskIds.get(0) - idToTaskBase).getUserContext());\n        this.outputCollectors = new ArrayList<>();\n        for (int i = 0; i < idToTask.size(); ++i) {\n            Task taskData = idToTask.get(i);\n            if (taskData == null) {\n                continue;\n            }\n            ISpout spoutObject = (ISpout) taskData.getTaskObject();\n            spoutOutputCollector = new SpoutOutputCollectorImpl(\n                spoutObject, this, taskData, emittedCount,\n                hasAckers, rand, hasEventLoggers, isDebug, pending);\n            SpoutOutputCollector outputCollector = new SpoutOutputCollector(spoutOutputCollector);\n            this.outputCollectors.add(outputCollector);\n\n            builtInMetrics.registerAll(topoConf, taskData.getUserContext());\n            Map<String, JCQueue> map = ImmutableMap.of(\"receive\", receiveQueue);\n            BuiltinMetricsUtil.registerQueueMetrics(map, topoConf, taskData.getUserContext());\n\n            if (spoutObject instanceof ICredentialsListener) {\n                ((ICredentialsListener) spoutObject).setCredentials(credentials);\n            }\n            spoutObject.open(topoConf, taskData.getUserContext(), outputCollector);\n        }\n        openOrPrepareWasCalled.set(true);\n        LOG.info(\"Opened spout {}:{}\", componentId, taskIds);\n        setupTicks(true);\n        setupMetrics();\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.inactiveExecute": "    private void inactiveExecute() throws InterruptedException {\n        if (lastActive.get()) {\n            lastActive.set(false);\n            deactivateSpouts();\n        }\n        long start = Time.currentTimeMillis();\n        Time.sleep(100);\n        spoutThrottlingMetrics.skippedInactiveMs(Time.currentTimeMillis() - start);\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.tryFlushPendingEmits": "            private boolean tryFlushPendingEmits() {\n                for (AddressedTuple t = pendingEmits.peek(); t != null; t = pendingEmits.peek()) {\n                    if (executorTransfer.tryTransfer(t, null)) {\n                        pendingEmits.poll();\n                    } else { // to avoid reordering of emits, stop at first failure\n                        return false;\n                    }\n                }\n                return true;\n            }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.activateSpouts": "    private void activateSpouts() {\n        LOG.info(\"Activating spout {}:{}\", componentId, taskIds);\n        for (ISpout spout : spouts) {\n            spout.activate();\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.run": "            public void run() {\n                exitProcess(1, \"Worker died\");\n            }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess(int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exceptionCauseIsInstanceOf": "    public static boolean exceptionCauseIsInstanceOf(Class klass, Throwable throwable) {\n        return unwrapTo(klass, throwable) != null;\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.sleep": "    public static void sleep(long millis) {\n        try {\n            Time.sleep(millis);\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote": "    public boolean tryTransferRemote(AddressedTuple addressedTuple, Queue<AddressedTuple> pendingEmits, ITupleSerializer serializer) {\n        if (pendingEmits != null && !pendingEmits.isEmpty()) {\n            pendingEmits.add(addressedTuple);\n            return false;\n        }\n\n        if (!remoteBackPressureStatus[addressedTuple.dest].get()) {\n            TaskMessage tm = new TaskMessage(addressedTuple.getDest(), serializer.serialize(addressedTuple.getTuple()));\n            if (transferQueue.tryPublish(tm)) {\n                return true;\n            }\n        } else {\n            LOG.debug(\"Noticed Back Pressure in remote task {}\", addressedTuple.dest);\n        }\n        if (pendingEmits != null) {\n            pendingEmits.add(addressedTuple);\n        }\n        return false;\n    }",
            "storm-client.src.jvm.org.apache.storm.daemon.worker.WorkerState.tryTransferRemote": "    public boolean tryTransferRemote(AddressedTuple tuple, Queue<AddressedTuple> pendingEmits, ITupleSerializer serializer) {\n        return workerTransfer.tryTransferRemote(tuple, pendingEmits, serializer);\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.ExecutorTransfer.tryTransfer": "    public boolean tryTransfer(AddressedTuple addressedTuple, Queue<AddressedTuple> pendingEmits) {\n        if (isDebug) {\n            LOG.info(\"TRANSFERRING tuple {}\", addressedTuple);\n        }\n\n        JCQueue localQueue = getLocalQueue(addressedTuple);\n        if (localQueue != null) {\n            return tryTransferLocal(addressedTuple, localQueue, pendingEmits);\n        }\n        return workerData.tryTransferRemote(addressedTuple, pendingEmits, serializer);\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.ExecutorTransfer.getLocalQueue": "    public JCQueue getLocalQueue(AddressedTuple tuple) {\n        if ((tuple.dest - indexingBase) >= localReceiveQueues.size()) {\n            return null;\n        }\n        return localReceiveQueues.get(tuple.dest - indexingBase);\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.ExecutorTransfer.tryTransferLocal": "    public boolean tryTransferLocal(AddressedTuple tuple, JCQueue localQueue, Queue<AddressedTuple> pendingEmits) {\n        workerData.checkSerialize(serializer, tuple);\n        if (pendingEmits != null) {\n            if (pendingEmits.isEmpty() && localQueue.tryPublish(tuple)) {\n                queuesToFlush.set(tuple.dest - indexingBase, localQueue);\n                return true;\n            } else {\n                pendingEmits.add(tuple);\n                return false;\n            }\n        } else {\n            return localQueue.tryPublish(tuple);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg": "    private List<Integer> sendSpoutMsg(String stream, List<Object> values, Object messageId, Integer outTaskId) throws\n        InterruptedException {\n        emittedCount.increment();\n\n        List<Integer> outTasks;\n        if (outTaskId != null) {\n            outTasks = taskData.getOutgoingTasks(outTaskId, stream, values);\n        } else {\n            outTasks = taskData.getOutgoingTasks(stream, values);\n        }\n\n        final boolean needAck = (messageId != null) && hasAckers;\n\n        final List<Long> ackSeq = needAck ? new ArrayList<>() : null;\n\n        final long rootId = needAck ? MessageId.generateId(random) : 0;\n\n        for (int i = 0; i < outTasks.size(); i++) { // perf critical path. don't use iterators.\n            Integer t = outTasks.get(i);\n            MessageId msgId;\n            if (needAck) {\n                long as = MessageId.generateId(random);\n                msgId = MessageId.makeRootId(rootId, as);\n                ackSeq.add(as);\n            } else {\n                msgId = MessageId.makeUnanchored();\n            }\n\n            final TupleImpl tuple =\n                new TupleImpl(executor.getWorkerTopologyContext(), values, executor.getComponentId(), this.taskId, stream, msgId);\n            AddressedTuple adrTuple = new AddressedTuple(t, tuple);\n            executor.getExecutorTransfer().tryTransfer(adrTuple, executor.getPendingEmits());\n        }\n        if (isEventLoggers) {\n            taskData.sendToEventLogger(executor, values, executor.getComponentId(), messageId, random, executor.getPendingEmits());\n        }\n\n        if (needAck) {\n            boolean sample = executor.samplerCheck();\n            TupleInfo info = new TupleInfo();\n            info.setTaskId(this.taskId);\n            info.setStream(stream);\n            info.setMessageId(messageId);\n            if (isDebug) {\n                info.setValues(values);\n            }\n            if (sample) {\n                info.setTimestamp(System.currentTimeMillis());\n            }\n\n            pending.put(rootId, info);\n            List<Object> ackInitTuple = new Values(rootId, Utils.bitXorVals(ackSeq), this.taskId);\n            taskData.sendUnanchored(Acker.ACKER_INIT_STREAM_ID, ackInitTuple, executor.getExecutorTransfer(), executor.getPendingEmits());\n        } else if (messageId != null) {\n            // Reusing TupleInfo object as we directly call executor.ackSpoutMsg() & are not sending msgs. perf critical\n            if (isDebug) {\n                if (spoutExecutorThdId != Thread.currentThread().getId()) {\n                    throw new RuntimeException(\"Detected background thread emitting tuples for the spout. \" +\n                                               \"Spout Output Collector should only emit from the main spout executor thread.\");\n                }\n            }\n            globalTupleInfo.clear();\n            globalTupleInfo.setStream(stream);\n            globalTupleInfo.setValues(values);\n            globalTupleInfo.setMessageId(messageId);\n            globalTupleInfo.setTimestamp(0);\n            globalTupleInfo.setId(\"0:\");\n            Long timeDelta = 0L;\n            executor.ackSpoutMsg(executor, taskData, timeDelta, globalTupleInfo);\n        }\n        return outTasks;\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit": "    public List<Integer> emit(String streamId, List<Object> tuple, Object messageId) {\n        try {\n            return sendSpoutMsg(streamId, tuple, messageId, null);\n        } catch (InterruptedException e) {\n            LOG.warn(\"Spout thread interrupted during emit().\");\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.spout.SpoutOutputCollector.emit": "    public List<Integer> emit(String streamId, List<Object> tuple) {\n        return emit(streamId, tuple, null);\n    }",
            "examples.storm-loadgen.src.main.java.org.apache.storm.loadgen.LoadSpout.fail": "    public void fail(Object id) {\n        SentWithTime swt = (SentWithTime)id;\n        collector.emit(swt.streamName, swt.keyValue, swt);\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.failSpoutMsg": "    public void failSpoutMsg(SpoutExecutor executor, Task taskData, Long timeDelta, TupleInfo tupleInfo, String reason) {\n        try {\n            ISpout spout = (ISpout) taskData.getTaskObject();\n            int taskId = taskData.getTaskId();\n            if (executor.getIsDebug()) {\n                LOG.info(\"SPOUT Failing {} : {} REASON: {}\", tupleInfo.getId(), tupleInfo, reason);\n            }\n            spout.fail(tupleInfo.getMessageId());\n            new SpoutFailInfo(tupleInfo.getMessageId(), taskId, timeDelta).applyOn(taskData.getUserContext());\n            if (timeDelta != null) {\n                executor.getStats().spoutFailedTuple(tupleInfo.getStream(), timeDelta,\n                                                     taskData.getTaskMetrics().getFailed(tupleInfo.getStream()));\n            }\n        } catch (Exception e) {\n            throw Utils.wrapInRuntime(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.getStats": "    public SpoutExecutorStats getStats() {\n        return stats;\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.expire": "            public void expire(Long key, TupleInfo tupleInfo) {\n                Long timeDelta = null;\n                if (tupleInfo.getTimestamp() != 0) {\n                    timeDelta = Time.deltaMs(tupleInfo.getTimestamp());\n                }\n                failSpoutMsg(SpoutExecutor.this, idToTask.get(tupleInfo.getTaskId() - idToTaskBase), timeDelta, tupleInfo, \"TIMEOUT\");\n            }",
            "storm-client.src.jvm.org.apache.storm.utils.RotatingMap.rotate": "    public Map<K, V> rotate() {\n        Map<K, V> dead = _buckets.removeLast();\n        _buckets.addFirst(new HashMap<K, V>());\n        if (_callback != null) {\n            for (Entry<K, V> entry : dead.entrySet()) {\n                _callback.expire(entry.getKey(), entry.getValue());\n            }\n        }\n        return dead;\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.RotatingMap.expire": "        void expire(K key, V val);\n    }\n}",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.tupleActionFn": "    public void tupleActionFn(int taskId, TupleImpl tuple) throws Exception {\n        String streamId = tuple.getSourceStreamId();\n        if (Constants.SYSTEM_FLUSH_STREAM_ID.equals(streamId)) {\n            spoutOutputCollector.flush();\n        } else if (streamId.equals(Constants.SYSTEM_TICK_STREAM_ID)) {\n            pending.rotate();\n        } else if (streamId.equals(Constants.METRICS_TICK_STREAM_ID)) {\n            metricsTick(idToTask.get(taskId - idToTaskBase), tuple);\n        } else if (streamId.equals(Constants.CREDENTIALS_CHANGED_STREAM_ID)) {\n            Object spoutObj = idToTask.get(taskId - idToTaskBase).getTaskObject();\n            if (spoutObj instanceof ICredentialsListener) {\n                ((ICredentialsListener) spoutObj).setCredentials((Map<String, String>) tuple.getValue(0));\n            }\n        } else if (streamId.equals(Acker.ACKER_RESET_TIMEOUT_STREAM_ID)) {\n            Long id = (Long) tuple.getValue(0);\n            TupleInfo pendingForId = pending.get(id);\n            if (pendingForId != null) {\n                pending.put(id, pendingForId);\n            }\n        } else {\n            Long id = (Long) tuple.getValue(0);\n            Long timeDeltaMs = (Long) tuple.getValue(1);\n            TupleInfo tupleInfo = pending.remove(id);\n            if (tupleInfo != null && tupleInfo.getMessageId() != null) {\n                if (taskId != tupleInfo.getTaskId()) {\n                    throw new RuntimeException(\"Fatal error, mismatched task ids: \" + taskId + \" \" + tupleInfo.getTaskId());\n                }\n                Long timeDelta = null;\n                if (hasAckers) {\n                    long startTimeMs = tupleInfo.getTimestamp();\n                    if (startTimeMs != 0) {\n                        timeDelta = timeDeltaMs;\n                    }\n                }\n                if (streamId.equals(Acker.ACKER_ACK_STREAM_ID)) {\n                    ackSpoutMsg(this, idToTask.get(taskId - idToTaskBase), timeDelta, tupleInfo);\n                } else if (streamId.equals(Acker.ACKER_FAIL_STREAM_ID)) {\n                    failSpoutMsg(this, idToTask.get(taskId - idToTaskBase), timeDelta, tupleInfo, \"FAIL-STREAM\");\n                }\n            }\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.executor.spout.SpoutExecutor.ackSpoutMsg": "    public void ackSpoutMsg(SpoutExecutor executor, Task taskData, Long timeDelta, TupleInfo tupleInfo) {\n        try {\n            ISpout spout = (ISpout) taskData.getTaskObject();\n            int taskId = taskData.getTaskId();\n            if (executor.getIsDebug()) {\n                LOG.info(\"SPOUT Acking message {} {}\", tupleInfo.getId(), tupleInfo.getMessageId());\n            }\n            spout.ack(tupleInfo.getMessageId());\n            if (!taskData.getUserContext().getHooks().isEmpty()) { // avoid allocating SpoutAckInfo obj if not necessary\n                new SpoutAckInfo(tupleInfo.getMessageId(), taskId, timeDelta).applyOn(taskData.getUserContext());\n            }\n            if (hasAckers && timeDelta != null) {\n                executor.getStats().spoutAckedTuple(tupleInfo.getStream(), timeDelta,\n                                                    taskData.getTaskMetrics().getAcked(tupleInfo.getStream()));\n            }\n        } catch (Exception e) {\n            throw Utils.wrapInRuntime(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Time.sleepSecs": "    public static void sleepSecs(long secs) throws InterruptedException {\n        if (secs > 0) {\n            sleep(secs * 1000);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Time.sleep": "    public static void sleep(long ms) throws InterruptedException {\n        if (ms > 0) {\n            sleepUntil(currentTimeMillis() + ms);\n        }\n    }"
        },
        "bug_report": {
            "Title": "In some cases workers may crash because pendingEmits is full",
            "Description": "Saw this while running the https://github.com/apache/storm/blob/master/examples/storm-loadgen/src/main/java/org/apache/storm/loadgen/ThroughputVsLatency.java topology.\r\n\r\n{code}\r\n2018-05-15 11:35:28.365 o.a.s.u.Utils Thread-16-spout-executor[8, 8] [ERROR] Async loop died!\r\njava.lang.RuntimeException: java.lang.IllegalStateException: Queue full\r\n\tat org.apache.storm.executor.Executor.accept(Executor.java:282) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:133) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:110) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:101) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:168) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:157) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.Utils$2.run(Utils.java:349) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]\r\nCaused by: java.lang.IllegalStateException: Queue full\r\n\tat java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:1.8.0_144]\r\n\tat org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:516) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:66) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg(SpoutOutputCollectorImpl.java:140) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit(SpoutOutputCollectorImpl.java:70) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.spout.SpoutOutputCollector.emit(SpoutOutputCollector.java:42) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.loadgen.LoadSpout.fail(LoadSpout.java:135) ~[stormjar.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor.failSpoutMsg(SpoutExecutor.java:360) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:120) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.RotatingMap.rotate(RotatingMap.java:63) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor.tupleActionFn(SpoutExecutor.java:295) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.Executor.accept(Executor.java:278) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\t... 7 more\r\n{code}\r\n\r\nThe executor's pendingEmits queue is full, and the executor then tries to add another tuple. It looks to me like we're preventing the queue from filling by emptying it between calls to nextTuple at https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/executor/spout/SpoutExecutor.java#L184.\r\n\r\nThe TVL topology reemits failed tuples directly from the fail method, which can be triggered by tick tuples. If the pendingEmits queue is already close to full when this happens, we might hit the error above. I think it can also happen if nextTuple emits too many tuples in a call, or if too many metrics ticks happen between pendingEmit flushes, since metrics ticks also trigger emits."
        }
    },
    {
        "filename": "STORM-1672.json",
        "creation_time": "2016-03-31T19:24:18.000+0000",
        "stack_trace": "```\njava.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map\n        at org.apache.storm.stats.StatsUtil.filterSysStreams(StatsUtil.java:1696)\n        at org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt(StatsUtil.java:240)\n        at org.apache.storm.stats.StatsUtil.aggCompExecStats(StatsUtil.java:1130)\n        at org.apache.storm.stats.StatsUtil.aggregateCompStats(StatsUtil.java:1108)\n        at org.apache.storm.stats.StatsUtil.aggCompExecsStats(StatsUtil.java:1236)\n        at org.apache.storm.daemon.nimbus$fn__3490$exec_fn__789__auto__$reify__3519.getComponentPageInfo(nimbus.clj:2130)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3826)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3810)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:158)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:744)\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.filterSysStreams": "    private static <K, V> Map<String, Map<K, V>> filterSysStreams(Map<String, Map<K, V>> stats, boolean includeSys) {\n        if (!includeSys) {\n            for (Iterator<String> itr = stats.keySet().iterator(); itr.hasNext(); ) {\n                String winOrStream = itr.next();\n                Map<K, V> stream2stat = stats.get(winOrStream);\n                for (Iterator subItr = stream2stat.keySet().iterator(); subItr.hasNext(); ) {\n                    Object key = subItr.next();\n                    if (key instanceof String && Utils.isSystemId((String) key)) {\n                        subItr.remove();\n                    }\n                }\n            }\n        }\n        return stats;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.remove": "    private static void remove(Map map, String k) {\n        map.remove(k);\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt": "    public static Map<String, Object> aggPreMergeCompPageBolt(Map<String, Object> beat, String window, boolean includeSys) {\n        Map<String, Object> ret = new HashMap<>();\n\n        putKV(ret, EXECUTOR_ID, getByKey(beat, \"exec-id\"));\n        putKV(ret, HOST, getByKey(beat, HOST));\n        putKV(ret, PORT, getByKey(beat, PORT));\n        putKV(ret, UPTIME, getByKey(beat, UPTIME));\n        putKV(ret, NUM_EXECUTORS, 1);\n        putKV(ret, NUM_TASKS, getByKey(beat, NUM_TASKS));\n\n        Map stat2win2sid2num = getMapByKey(beat, STATS);\n        putKV(ret, CAPACITY, computeAggCapacity(stat2win2sid2num, getByKeyOr0(beat, UPTIME).intValue()));\n\n        // calc cid+sid->input_stats\n        Map inputStats = new HashMap();\n        Map sid2acked = (Map) windowSetConverter(getMapByKey(stat2win2sid2num, ACKED), TO_STRING).get(window);\n        Map sid2failed = (Map) windowSetConverter(getMapByKey(stat2win2sid2num, FAILED), TO_STRING).get(window);\n        putKV(inputStats, ACKED, sid2acked != null ? sid2acked : new HashMap());\n        putKV(inputStats, FAILED, sid2failed != null ? sid2failed : new HashMap());\n\n        inputStats = swapMapOrder(inputStats);\n\n        Map sid2execLat = (Map) windowSetConverter(getMapByKey(stat2win2sid2num, EXEC_LATENCIES), TO_STRING).get(window);\n        Map sid2procLat = (Map) windowSetConverter(getMapByKey(stat2win2sid2num, PROC_LATENCIES), TO_STRING).get(window);\n        Map sid2exec = (Map) windowSetConverter(getMapByKey(stat2win2sid2num, EXECUTED), TO_STRING).get(window);\n        mergeMaps(inputStats, aggBoltStreamsLatAndCount(sid2execLat, sid2procLat, sid2exec));\n        putKV(ret, CID_SID_TO_IN_STATS, inputStats);\n\n        // calc sid->output_stats\n        Map outputStats = new HashMap();\n        Map sid2emitted = (Map) windowSetConverter(getMapByKey(stat2win2sid2num, EMITTED), TO_STRING).get(window);\n        Map sid2transferred = (Map) windowSetConverter(getMapByKey(stat2win2sid2num, TRANSFERRED), TO_STRING).get(window);\n        if (sid2emitted != null) {\n            putKV(outputStats, EMITTED, filterSysStreams(sid2emitted, includeSys));\n        } else {\n            putKV(outputStats, EMITTED, new HashMap());\n        }\n        if (sid2transferred != null) {\n            putKV(outputStats, TRANSFERRED, filterSysStreams(sid2transferred, includeSys));\n        } else {\n            putKV(outputStats, TRANSFERRED, new HashMap());\n        }\n        outputStats = swapMapOrder(outputStats);\n        putKV(ret, SID_TO_OUT_STATS, outputStats);\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.computeAggCapacity": "    private static double computeAggCapacity(Map m, Integer uptime) {\n        if (uptime != null) {\n            Map execAvg = (Map) ((Map) getByKey(m, EXEC_LATENCIES)).get(TEN_MIN_IN_SECONDS_STR);\n            Map exec = (Map) ((Map) getByKey(m, EXECUTED)).get(TEN_MIN_IN_SECONDS_STR);\n\n            Set<Object> allKeys = new HashSet<>();\n            if (execAvg != null) {\n                allKeys.addAll(execAvg.keySet());\n            }\n            if (exec != null) {\n                allKeys.addAll(exec.keySet());\n            }\n\n            double totalAvg = 0;\n            for (Object k : allKeys) {\n                double avg = getOr0(execAvg, k).doubleValue();\n                long cnt = getOr0(exec, k).longValue();\n                totalAvg += avg * cnt;\n            }\n            return totalAvg / (Math.min(uptime, TEN_MIN_IN_SECONDS) * 1000);\n        }\n        return 0.0;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.windowSetConverter": "    public static <K1, K2> Map windowSetConverter(\n            Map stats, KeyTransformer<K2> secKeyFunc, KeyTransformer<K1> firstKeyFunc) {\n        Map ret = new HashMap();\n\n        for (Object o : stats.entrySet()) {\n            Map.Entry entry = (Map.Entry) o;\n            K1 key1 = firstKeyFunc.transform(entry.getKey());\n\n            Map subRetMap = (Map) ret.get(key1);\n            if (subRetMap == null) {\n                subRetMap = new HashMap();\n            }\n            ret.put(key1, subRetMap);\n\n            Map value = (Map) entry.getValue();\n            for (Object oo : value.entrySet()) {\n                Map.Entry subEntry = (Map.Entry) oo;\n                K2 key2 = secKeyFunc.transform(subEntry.getKey());\n                subRetMap.put(key2, subEntry.getValue());\n            }\n        }\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.getMapByKey": "    public static Map getMapByKey(Map map, String key) {\n        if (map == null) {\n            return null;\n        }\n        return (Map) map.get(key);\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.putKV": "    public static void putKV(Map map, String k, Object v) {\n        map.put(k, v);\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.swapMapOrder": "    private static Map swapMapOrder(Map m) {\n        if (m.size() == 0) {\n            return m;\n        }\n\n        Map ret = new HashMap();\n        for (Object k1 : m.keySet()) {\n            Map v = (Map) m.get(k1);\n            if (v != null) {\n                for (Object k2 : v.keySet()) {\n                    Map subRet = (Map) ret.get(k2);\n                    if (subRet == null) {\n                        subRet = new HashMap();\n                        ret.put(k2, subRet);\n                    }\n                    subRet.put(k1, v.get(k2));\n                }\n            }\n        }\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.mergeMaps": "    private static Map mergeMaps(Map m1, Map m2) {\n        if (m2 == null) {\n            return m1;\n        }\n        for (Object o : m2.entrySet()) {\n            Map.Entry entry = (Map.Entry) o;\n            Object k = entry.getKey();\n\n            Map existing = (Map) m1.get(k);\n            if (existing == null) {\n                m1.put(k, entry.getValue());\n            } else {\n                existing.putAll((Map) m2.get(k));\n            }\n        }\n        return m1;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggBoltStreamsLatAndCount": "    public static <K> Map<K, Map> aggBoltStreamsLatAndCount(Map<K, Double> id2execAvg,\n                                                            Map<K, Double> id2procAvg,\n                                                            Map<K, Long> id2numExec) {\n        Map<K, Map> ret = new HashMap<>();\n        if (id2execAvg == null || id2procAvg == null || id2numExec == null) {\n            return ret;\n        }\n        for (K k : id2execAvg.keySet()) {\n            Map<String, Object> subMap = new HashMap<>();\n            putKV(subMap, EXEC_LAT_TOTAL, weightAvg(id2execAvg, id2numExec, k));\n            putKV(subMap, PROC_LAT_TOTAL, weightAvg(id2procAvg, id2numExec, k));\n            putKV(subMap, EXECUTED, id2numExec.get(k));\n            ret.put(k, subMap);\n        }\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.getByKeyOr0": "    private static Number getByKeyOr0(Map m, String k) {\n        if (m == null) {\n            return 0;\n        }\n\n        Number n = (Number) m.get(k);\n        if (n == null) {\n            return 0;\n        }\n        return n;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.getByKey": "    public static Object getByKey(Map map, String key) {\n        return map.get(key);\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggCompExecStats": "    public static Map<String, Object> aggCompExecStats(String window, boolean includeSys, Map<String, Object> accStats,\n                                                       Map<String, Object> beat, String compType) {\n        Map<String, Object> ret = new HashMap<>();\n        if (SPOUT.equals(compType)) {\n            ret.putAll(aggSpoutExecWinStats(accStats, getMapByKey(beat, STATS), includeSys));\n            putKV(ret, STATS, mergeAggCompStatsCompPageSpout(\n                    getMapByKey(accStats, STATS),\n                    aggPreMergeCompPageSpout(beat, window, includeSys)));\n        } else {\n            ret.putAll(aggBoltExecWinStats(accStats, getMapByKey(beat, STATS), includeSys));\n            putKV(ret, STATS, mergeAggCompStatsCompPageBolt(\n                    getMapByKey(accStats, STATS),\n                    aggPreMergeCompPageBolt(beat, window, includeSys)));\n        }\n        putKV(ret, TYPE, compType);\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggPreMergeCompPageSpout": "    public static Map<String, Object> aggPreMergeCompPageSpout(Map<String, Object> beat, String window, boolean includeSys) {\n        Map<String, Object> ret = new HashMap<>();\n        putKV(ret, EXECUTOR_ID, getByKey(beat, \"exec-id\"));\n        putKV(ret, HOST, getByKey(beat, HOST));\n        putKV(ret, PORT, getByKey(beat, PORT));\n        putKV(ret, UPTIME, getByKey(beat, UPTIME));\n        putKV(ret, NUM_EXECUTORS, 1);\n        putKV(ret, NUM_TASKS, getByKey(beat, NUM_TASKS));\n\n        Map stat2win2sid2num = getMapByKey(beat, STATS);\n\n        // calc sid->output-stats\n        Map outputStats = new HashMap();\n        Map win2sid2acked = windowSetConverter(getMapByKey(stat2win2sid2num, ACKED), TO_STRING);\n        Map win2sid2failed = windowSetConverter(getMapByKey(stat2win2sid2num, FAILED), TO_STRING);\n        Map win2sid2emitted = windowSetConverter(getMapByKey(stat2win2sid2num, EMITTED), TO_STRING);\n        Map win2sid2transferred = windowSetConverter(getMapByKey(stat2win2sid2num, TRANSFERRED), TO_STRING);\n        Map win2sid2compLat = windowSetConverter(getMapByKey(stat2win2sid2num, COMP_LATENCIES), TO_STRING);\n\n        putKV(outputStats, ACKED, win2sid2acked.get(window));\n        putKV(outputStats, FAILED, win2sid2failed.get(window));\n        putKV(outputStats, EMITTED, filterSysStreams((Map) win2sid2emitted.get(window), includeSys));\n        putKV(outputStats, TRANSFERRED, filterSysStreams((Map) win2sid2transferred.get(window), includeSys));\n        outputStats = swapMapOrder(outputStats);\n\n        Map sid2compLat = (Map) win2sid2compLat.get(window);\n        Map sid2acked = (Map) win2sid2acked.get(window);\n        mergeMaps(outputStats, aggSpoutStreamsLatAndCount(sid2compLat, sid2acked));\n        putKV(ret, SID_TO_OUT_STATS, outputStats);\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggSpoutExecWinStats": "    public static Map<String, Object> aggSpoutExecWinStats(\n            Map<String, Object> accStats, Map<String, Object> beat, boolean includeSys) {\n        Map<String, Object> ret = new HashMap<>();\n\n        Map<String, Map<String, Number>> m = new HashMap<>();\n        for (Object win : getMapByKey(beat, ACKED).keySet()) {\n            m.put((String) win, aggSpoutLatAndCount(\n                    (Map<String, Double>) (getMapByKey(beat, COMP_LATENCIES)).get(win),\n                    (Map<String, Long>) (getMapByKey(beat, ACKED)).get(win)));\n        }\n        m = swapMapOrder(m);\n\n        Map<String, Double> win2compLatWgtAvg = getMapByKey(m, COMP_LAT_TOTAL);\n        Map<String, Long> win2acked = getMapByKey(m, ACKED);\n\n        Map<String, Map<String, Long>> emitted = getMapByKey(beat, EMITTED);\n        Map<String, Long> win2emitted = mergeWithSumLong(aggregateCountStreams(filterSysStreams(emitted, includeSys)),\n                getMapByKey(accStats, WIN_TO_EMITTED));\n        putKV(ret, WIN_TO_EMITTED, win2emitted);\n\n        Map<String, Map<String, Long>> transferred = getMapByKey(beat, TRANSFERRED);\n        Map<String, Long> win2transferred = mergeWithSumLong(aggregateCountStreams(filterSysStreams(transferred, includeSys)),\n                getMapByKey(accStats, WIN_TO_TRANSFERRED));\n        putKV(ret, WIN_TO_TRANSFERRED, win2transferred);\n\n        putKV(ret, WIN_TO_COMP_LAT_WGT_AVG, mergeWithSumDouble(\n                getMapByKey(accStats, WIN_TO_COMP_LAT_WGT_AVG), win2compLatWgtAvg));\n        putKV(ret, WIN_TO_ACKED, mergeWithSumLong(\n                getMapByKey(accStats, WIN_TO_ACKED), win2acked));\n        putKV(ret, WIN_TO_FAILED, mergeWithSumLong(\n                aggregateCountStreams(getMapByKey(beat, FAILED)), getMapByKey(accStats, WIN_TO_FAILED)));\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.mergeAggCompStatsCompPageSpout": "    public static Map<String, Object> mergeAggCompStatsCompPageSpout(\n            Map<String, Object> accSpoutStats, Map<String, Object> spoutStats) {\n        Map<String, Object> ret = new HashMap<>();\n\n        // {stream id -> metric -> value}, note that sid->out-stats may contain both long and double values\n        Map<String, Map<String, ?>> accOut = getMapByKey(accSpoutStats, SID_TO_OUT_STATS);\n        Map<String, Map<String, ?>> spoutOut = getMapByKey(spoutStats, SID_TO_OUT_STATS);\n\n        int numExecutors = getByKeyOr0(accSpoutStats, NUM_EXECUTORS).intValue();\n        putKV(ret, NUM_EXECUTORS, numExecutors + 1);\n        putKV(ret, NUM_TASKS, sumOr0(\n                getByKeyOr0(accSpoutStats, NUM_TASKS), getByKeyOr0(spoutStats, NUM_TASKS)));\n        putKV(ret, SID_TO_OUT_STATS, fullMergeWithSum(accOut, spoutOut));\n\n        Map executorStats = new HashMap();\n        putKV(executorStats, EXECUTOR_ID, getByKey(spoutStats, EXECUTOR_ID));\n        putKV(executorStats, UPTIME, getByKey(spoutStats, UPTIME));\n        putKV(executorStats, HOST, getByKey(spoutStats, HOST));\n        putKV(executorStats, PORT, getByKey(spoutStats, PORT));\n\n        putKV(executorStats, EMITTED, sumStreamsLong(spoutOut, EMITTED));\n        putKV(executorStats, TRANSFERRED, sumStreamsLong(spoutOut, TRANSFERRED));\n        putKV(executorStats, FAILED, sumStreamsLong(spoutOut, FAILED));\n        long acked = sumStreamsLong(spoutOut, ACKED);\n        putKV(executorStats, ACKED, acked);\n        if (acked > 0) {\n            putKV(executorStats, COMP_LATENCY, sumStreamsDouble(spoutOut, COMP_LAT_TOTAL) / acked);\n        } else {\n            putKV(executorStats, COMP_LATENCY, null);\n        }\n        List executorStatsList = ((List) getByKey(accSpoutStats, EXECUTOR_STATS));\n        executorStatsList.add(executorStats);\n        putKV(ret, EXECUTOR_STATS, executorStatsList);\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.mergeAggCompStatsCompPageBolt": "    public static Map<String, Object> mergeAggCompStatsCompPageBolt(\n            Map<String, Object> accBoltStats, Map<String, Object> boltStats) {\n        Map<String, Object> ret = new HashMap<>();\n\n        Map<List<String>, Map<String, ?>> accIn = getMapByKey(accBoltStats, CID_SID_TO_IN_STATS);\n        Map<String, Map<String, ?>> accOut = getMapByKey(accBoltStats, SID_TO_OUT_STATS);\n        Map<List<String>, Map<String, ?>> boltIn = getMapByKey(boltStats, CID_SID_TO_IN_STATS);\n        Map<String, Map<String, ?>> boltOut = getMapByKey(boltStats, SID_TO_OUT_STATS);\n\n        int numExecutors = getByKeyOr0(accBoltStats, NUM_EXECUTORS).intValue();\n        putKV(ret, NUM_EXECUTORS, numExecutors + 1);\n        putKV(ret, NUM_TASKS, sumOr0(\n                getByKeyOr0(accBoltStats, NUM_TASKS), getByKeyOr0(boltStats, NUM_TASKS)));\n\n        // (merge-with (partial merge-with sum-or-0) acc-out spout-out)\n        putKV(ret, SID_TO_OUT_STATS, fullMergeWithSum(accOut, boltOut));\n        // {component id -> metric -> value}, note that input may contain both long and double values\n        putKV(ret, CID_SID_TO_IN_STATS, fullMergeWithSum(accIn, boltIn));\n\n        long executed = sumStreamsLong(boltIn, EXECUTED);\n        putKV(ret, EXECUTED, executed);\n\n        Map<String, Object> executorStats = new HashMap<>();\n        putKV(executorStats, EXECUTOR_ID, boltStats.get(EXECUTOR_ID));\n        putKV(executorStats, UPTIME, boltStats.get(UPTIME));\n        putKV(executorStats, HOST, boltStats.get(HOST));\n        putKV(executorStats, PORT, boltStats.get(PORT));\n        putKV(executorStats, CAPACITY, boltStats.get(CAPACITY));\n\n        putKV(executorStats, EMITTED, sumStreamsLong(boltOut, EMITTED));\n        putKV(executorStats, TRANSFERRED, sumStreamsLong(boltOut, TRANSFERRED));\n        putKV(executorStats, ACKED, sumStreamsLong(boltIn, ACKED));\n        putKV(executorStats, FAILED, sumStreamsLong(boltIn, FAILED));\n        putKV(executorStats, EXECUTED, executed);\n\n        if (executed > 0) {\n            putKV(executorStats, EXEC_LATENCY, sumStreamsDouble(boltIn, EXEC_LAT_TOTAL) / executed);\n            putKV(executorStats, PROC_LATENCY, sumStreamsDouble(boltIn, PROC_LAT_TOTAL) / executed);\n        } else {\n            putKV(executorStats, EXEC_LATENCY, null);\n            putKV(executorStats, PROC_LATENCY, null);\n        }\n        List executorStatsList = ((List) getByKey(accBoltStats, EXECUTOR_STATS));\n        executorStatsList.add(executorStats);\n        putKV(ret, EXECUTOR_STATS, executorStatsList);\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggBoltExecWinStats": "    public static Map<String, Object> aggBoltExecWinStats(\n            Map<String, Object> accStats, Map<String, Object> newStats, boolean includeSys) {\n        Map<String, Object> ret = new HashMap<>();\n\n        Map<String, Map<String, Number>> m = new HashMap<>();\n        for (Object win : getMapByKey(newStats, EXECUTED).keySet()) {\n            m.put((String) win, aggBoltLatAndCount(\n                    (Map) (getMapByKey(newStats, EXEC_LATENCIES)).get(win),\n                    (Map) (getMapByKey(newStats, PROC_LATENCIES)).get(win),\n                    (Map) (getMapByKey(newStats, EXECUTED)).get(win)));\n        }\n        m = swapMapOrder(m);\n\n        Map<String, Double> win2execLatWgtAvg = getMapByKey(m, EXEC_LAT_TOTAL);\n        Map<String, Double> win2procLatWgtAvg = getMapByKey(m, PROC_LAT_TOTAL);\n        Map<String, Long> win2executed = getMapByKey(m, EXECUTED);\n\n        Map<String, Map<String, Long>> emitted = getMapByKey(newStats, EMITTED);\n        Map<String, Long> win2emitted = mergeWithSumLong(aggregateCountStreams(filterSysStreams(emitted, includeSys)),\n                getMapByKey(accStats, WIN_TO_EMITTED));\n        putKV(ret, WIN_TO_EMITTED, win2emitted);\n\n        Map<String, Map<String, Long>> transferred = getMapByKey(newStats, TRANSFERRED);\n        Map<String, Long> win2transferred = mergeWithSumLong(aggregateCountStreams(filterSysStreams(transferred, includeSys)),\n                getMapByKey(accStats, WIN_TO_TRANSFERRED));\n        putKV(ret, WIN_TO_TRANSFERRED, win2transferred);\n\n        putKV(ret, WIN_TO_EXEC_LAT_WGT_AVG, mergeWithSumDouble(\n                getMapByKey(accStats, WIN_TO_EXEC_LAT_WGT_AVG), win2execLatWgtAvg));\n        putKV(ret, WIN_TO_PROC_LAT_WGT_AVG, mergeWithSumDouble(\n                getMapByKey(accStats, WIN_TO_PROC_LAT_WGT_AVG), win2procLatWgtAvg));\n        putKV(ret, WIN_TO_EXECUTED, mergeWithSumLong(\n                getMapByKey(accStats, WIN_TO_EXECUTED), win2executed));\n        putKV(ret, WIN_TO_ACKED, mergeWithSumLong(\n                aggregateCountStreams(getMapByKey(newStats, ACKED)), getMapByKey(accStats, WIN_TO_ACKED)));\n        putKV(ret, WIN_TO_FAILED, mergeWithSumLong(\n                aggregateCountStreams(getMapByKey(newStats, FAILED)), getMapByKey(accStats, WIN_TO_FAILED)));\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggregateCompStats": "    public static Map<String, Object> aggregateCompStats(\n            String window, boolean includeSys, List<Map<String, Object>> beats, String compType) {\n        boolean isSpout = SPOUT.equals(compType);\n\n        Map<String, Object> initVal = new HashMap<>();\n        putKV(initVal, WIN_TO_ACKED, new HashMap());\n        putKV(initVal, WIN_TO_FAILED, new HashMap());\n        putKV(initVal, WIN_TO_EMITTED, new HashMap());\n        putKV(initVal, WIN_TO_TRANSFERRED, new HashMap());\n\n        Map<String, Object> stats = new HashMap();\n        putKV(stats, EXECUTOR_STATS, new ArrayList());\n        putKV(stats, SID_TO_OUT_STATS, new HashMap());\n        if (isSpout) {\n            putKV(initVal, TYPE, SPOUT);\n            putKV(initVal, WIN_TO_COMP_LAT_WGT_AVG, new HashMap());\n        } else {\n            putKV(initVal, TYPE, BOLT);\n            putKV(initVal, WIN_TO_EXECUTED, new HashMap());\n            putKV(stats, CID_SID_TO_IN_STATS, new HashMap());\n            putKV(initVal, WIN_TO_EXEC_LAT_WGT_AVG, new HashMap());\n            putKV(initVal, WIN_TO_PROC_LAT_WGT_AVG, new HashMap());\n        }\n        putKV(initVal, STATS, stats);\n\n        // iterate through all executor heartbeats\n        for (Map<String, Object> beat : beats) {\n            initVal = aggCompExecStats(window, includeSys, initVal, beat, compType);\n        }\n\n        return initVal;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.aggCompExecsStats": "    public static ComponentPageInfo aggCompExecsStats(\n            Map exec2hostPort, Map task2component, Map<List<Integer>, Map<String, Object>> beats,\n            String window, boolean includeSys, String topologyId, StormTopology topology, String componentId) {\n\n        List<Map<String, Object>> beatList =\n                extractDataFromHb(exec2hostPort, task2component, beats, includeSys, topology, componentId);\n        Map<String, Object> compStats = aggregateCompStats(window, includeSys, beatList, componentType(topology, componentId));\n        compStats = postAggregateCompStats(compStats);\n        return thriftifyCompPageData(topologyId, topology, componentId, compStats);\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.postAggregateCompStats": "    public static Map<String, Object> postAggregateCompStats(Map<String, Object> compStats) {\n        Map<String, Object> ret = new HashMap<>();\n\n        String compType = (String) compStats.get(TYPE);\n        Map stats = getMapByKey(compStats, STATS);\n        Integer numTasks = getByKeyOr0(stats, NUM_TASKS).intValue();\n        Integer numExecutors = getByKeyOr0(stats, NUM_EXECUTORS).intValue();\n        Map outStats = getMapByKey(stats, SID_TO_OUT_STATS);\n\n        putKV(ret, TYPE, compType);\n        putKV(ret, NUM_TASKS, numTasks);\n        putKV(ret, NUM_EXECUTORS, numExecutors);\n        putKV(ret, EXECUTOR_STATS, getByKey(stats, EXECUTOR_STATS));\n        putKV(ret, WIN_TO_EMITTED, mapKeyStr(getMapByKey(compStats, WIN_TO_EMITTED)));\n        putKV(ret, WIN_TO_TRANSFERRED, mapKeyStr(getMapByKey(compStats, WIN_TO_TRANSFERRED)));\n        putKV(ret, WIN_TO_ACKED, mapKeyStr(getMapByKey(compStats, WIN_TO_ACKED)));\n        putKV(ret, WIN_TO_FAILED, mapKeyStr(getMapByKey(compStats, WIN_TO_FAILED)));\n\n        if (BOLT.equals(compType)) {\n            Map inStats = getMapByKey(stats, CID_SID_TO_IN_STATS);\n\n            Map inStats2 = new HashMap();\n            for (Object o : inStats.entrySet()) {\n                Map.Entry e = (Map.Entry) o;\n                Object k = e.getKey();\n                Map v = (Map) e.getValue();\n                long executed = getByKeyOr0(v, EXECUTED).longValue();\n                if (executed > 0) {\n                    double executeLatencyTotal = getByKeyOr0(v, EXEC_LAT_TOTAL).doubleValue();\n                    double processLatencyTotal = getByKeyOr0(v, PROC_LAT_TOTAL).doubleValue();\n                    putKV(v, EXEC_LATENCY, executeLatencyTotal / executed);\n                    putKV(v, PROC_LATENCY, processLatencyTotal / executed);\n                } else {\n                    putKV(v, EXEC_LATENCY, 0.0);\n                    putKV(v, PROC_LATENCY, 0.0);\n                }\n                remove(v, EXEC_LAT_TOTAL);\n                remove(v, PROC_LAT_TOTAL);\n                inStats2.put(k, v);\n            }\n            putKV(ret, CID_SID_TO_IN_STATS, inStats2);\n\n            putKV(ret, SID_TO_OUT_STATS, outStats);\n            putKV(ret, WIN_TO_EXECUTED, mapKeyStr(getMapByKey(compStats, WIN_TO_EXECUTED)));\n            putKV(ret, WIN_TO_EXEC_LAT, computeWeightedAveragesPerWindow(\n                    compStats, WIN_TO_EXEC_LAT_WGT_AVG, WIN_TO_EXECUTED));\n            putKV(ret, WIN_TO_PROC_LAT, computeWeightedAveragesPerWindow(\n                    compStats, WIN_TO_PROC_LAT_WGT_AVG, WIN_TO_EXECUTED));\n        } else {\n            Map outStats2 = new HashMap();\n            for (Object o : outStats.entrySet()) {\n                Map.Entry e = (Map.Entry) o;\n                Object k = e.getKey();\n                Map v = (Map) e.getValue();\n                long acked = getByKeyOr0(v, ACKED).longValue();\n                if (acked > 0) {\n                    double compLatencyTotal = getByKeyOr0(v, COMP_LAT_TOTAL).doubleValue();\n                    putKV(v, COMP_LATENCY, compLatencyTotal / acked);\n                } else {\n                    putKV(v, COMP_LATENCY, 0.0);\n                }\n                remove(v, COMP_LAT_TOTAL);\n                outStats2.put(k, v);\n            }\n            putKV(ret, SID_TO_OUT_STATS, outStats2);\n            putKV(ret, WIN_TO_COMP_LAT, computeWeightedAveragesPerWindow(\n                    compStats, WIN_TO_COMP_LAT_WGT_AVG, WIN_TO_ACKED));\n        }\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.thriftifyCompPageData": "    private static ComponentPageInfo thriftifyCompPageData(\n            String topologyId, StormTopology topology, String compId, Map<String, Object> data) {\n        ComponentPageInfo ret = new ComponentPageInfo();\n        ret.set_component_id(compId);\n\n        Map win2stats = new HashMap();\n        putKV(win2stats, EMITTED, getMapByKey(data, WIN_TO_EMITTED));\n        putKV(win2stats, TRANSFERRED, getMapByKey(data, WIN_TO_TRANSFERRED));\n        putKV(win2stats, ACKED, getMapByKey(data, WIN_TO_ACKED));\n        putKV(win2stats, FAILED, getMapByKey(data, WIN_TO_FAILED));\n\n        String compType = (String) data.get(TYPE);\n        if (compType.equals(SPOUT)) {\n            ret.set_component_type(ComponentType.SPOUT);\n            putKV(win2stats, COMP_LATENCY, getMapByKey(data, WIN_TO_COMP_LAT));\n        } else {\n            ret.set_component_type(ComponentType.BOLT);\n            putKV(win2stats, EXEC_LATENCY, getMapByKey(data, WIN_TO_EXEC_LAT));\n            putKV(win2stats, PROC_LATENCY, getMapByKey(data, WIN_TO_PROC_LAT));\n            putKV(win2stats, EXECUTED, getMapByKey(data, WIN_TO_EXECUTED));\n        }\n        win2stats = swapMapOrder(win2stats);\n\n        List<ExecutorAggregateStats> execStats = new ArrayList<>();\n        List executorStats = (List) getByKey(data, EXECUTOR_STATS);\n        if (executorStats != null) {\n            for (Object o : executorStats) {\n                execStats.add(thriftifyExecAggStats(compId, compType, (Map) o));\n            }\n        }\n\n        Map gsid2inputStats, sid2outputStats;\n        if (compType.equals(SPOUT)) {\n            Map tmp = new HashMap();\n            for (Object k : win2stats.keySet()) {\n                tmp.put(k, thriftifySpoutAggStats((Map) win2stats.get(k)));\n            }\n            win2stats = tmp;\n            gsid2inputStats = null;\n            sid2outputStats = thriftifySpoutOutputStats(getMapByKey(data, SID_TO_OUT_STATS));\n        } else {\n            Map tmp = new HashMap();\n            for (Object k : win2stats.keySet()) {\n                tmp.put(k, thriftifyBoltAggStats((Map) win2stats.get(k)));\n            }\n            win2stats = tmp;\n            gsid2inputStats = thriftifyBoltInputStats(getMapByKey(data, CID_SID_TO_IN_STATS));\n            sid2outputStats = thriftifyBoltOutputStats(getMapByKey(data, SID_TO_OUT_STATS));\n        }\n        ret.set_num_executors(getByKeyOr0(data, NUM_EXECUTORS).intValue());\n        ret.set_num_tasks(getByKeyOr0(data, NUM_TASKS).intValue());\n        ret.set_topology_id(topologyId);\n        ret.set_topology_name(null);\n        ret.set_window_to_stats(win2stats);\n        ret.set_sid_to_output_stats(sid2outputStats);\n        ret.set_exec_stats(execStats);\n        ret.set_gsid_to_input_stats(gsid2inputStats);\n\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.extractDataFromHb": "    public static List<Map<String, Object>> extractDataFromHb(Map executor2hostPort, Map task2component,\n                                                              Map<List<Integer>, Map<String, Object>> beats,\n                                                              boolean includeSys, StormTopology topology, String compId) {\n        List<Map<String, Object>> ret = new ArrayList<>();\n        if (executor2hostPort == null || beats == null) {\n            return ret;\n        }\n        for (Object o : executor2hostPort.entrySet()) {\n            Map.Entry entry = (Map.Entry) o;\n            List executor = (List) entry.getKey();\n            List hostPort = (List) entry.getValue();\n\n            Integer start = ((Number) executor.get(0)).intValue();\n            Integer end = ((Number) executor.get(1)).intValue();\n\n            String host = (String) hostPort.get(0);\n            Integer port = ((Number) hostPort.get(1)).intValue();\n\n            Map<String, Object> beat = beats.get(convertExecutor(executor));\n            if (beat == null) {\n                continue;\n            }\n            String id = (String) task2component.get(start);\n\n            Map<String, Object> m = new HashMap<>();\n            if ((compId == null || compId.equals(id)) && (includeSys || !Utils.isSystemId(id))) {\n                putKV(m, \"exec-id\", entry.getKey());\n                putKV(m, \"comp-id\", id);\n                putKV(m, NUM_TASKS, end - start + 1);\n                putKV(m, HOST, host);\n                putKV(m, PORT, port);\n\n                Map hb = getMapByKey(beat, HEARTBEAT);\n                if (hb != null) {\n                    Map stats = getMapByKey(hb, STATS);\n                    putKV(m, UPTIME, hb.get(UPTIME));\n                    putKV(m, STATS, stats);\n\n                    String type = componentType(topology, compId);\n                    if (type != null) {\n                        putKV(m, TYPE, type);\n                    } else {\n                        putKV(m, TYPE, stats.get(TYPE));\n                    }\n                    ret.add(m);\n                }\n            }\n        }\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.stats.StatsUtil.componentType": "    public static String componentType(StormTopology topology, String compId) {\n        if (compId == null) {\n            return null;\n        }\n\n        Map<String, Bolt> bolts = topology.get_bolts();\n        if (Utils.isSystemId(compId) || bolts.containsKey(compId)) {\n            return BOLT;\n        }\n        return SPOUT;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public getTopologyHistory_result getResult(I iface, getTopologyHistory_args args) throws org.apache.thrift.TException {\n        getTopologyHistory_result result = new getTopologyHistory_result();\n        try {\n          result.success = iface.getTopologyHistory(args.user);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setLogConfig": "    public void recv_setLogConfig() throws org.apache.thrift.TException\n    {\n      setLogConfig_result result = new setLogConfig_result();\n      receiveBase(result, \"setLogConfig\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(String location, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deleteBlob": "    public void recv_deleteBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      deleteBlob_result result = new deleteBlob_result();\n      receiveBase(result, \"deleteBlob\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_createStateInZookeeper": "    public void recv_createStateInZookeeper() throws org.apache.thrift.TException\n    {\n      createStateInZookeeper_result result = new createStateInZookeeper_result();\n      receiveBase(result, \"createStateInZookeeper\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadChunk": "    public void recv_uploadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadChunk_result result = new uploadChunk_result();\n      receiveBase(result, \"uploadChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setWorkerProfiler": "    public void recv_setWorkerProfiler() throws org.apache.thrift.TException\n    {\n      setWorkerProfiler_result result = new setWorkerProfiler_result();\n      receiveBase(result, \"setWorkerProfiler\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(String user, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(String key, int replication, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishBlobUpload": "    public void recv_finishBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishBlobUpload_result result = new finishBlobUpload_result();\n      receiveBase(result, \"finishBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_rebalance": "    public void recv_rebalance() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      rebalance_result result = new rebalance_result();\n      receiveBase(result, \"rebalance\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopology": "    public void recv_submitTopology() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopology_result result = new submitTopology_result();\n      receiveBase(result, \"submitTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(String location, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopology": "    public void recv_killTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopology_result result = new killTopology_result();\n      receiveBase(result, \"killTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(String name, String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadBlobChunk": "    public void recv_uploadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadBlobChunk_result result = new uploadBlobChunk_result();\n      receiveBase(result, \"uploadBlobChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_activate": "    public void recv_activate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      activate_result result = new activate_result();\n      receiveBase(result, \"activate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(String file, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(String session, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishFileUpload": "    public void recv_finishFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishFileUpload_result result = new finishFileUpload_result();\n      receiveBase(result, \"finishFileUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setBlobMeta": "    public void recv_setBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      setBlobMeta_result result = new setBlobMeta_result();\n      receiveBase(result, \"setBlobMeta\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopologyWithOpts": "    public void recv_killTopologyWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n      receiveBase(result, \"killTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_debug": "    public void recv_debug() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      debug_result result = new debug_result();\n      receiveBase(result, \"debug\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadNewCredentials": "    public void recv_uploadNewCredentials() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      uploadNewCredentials_result result = new uploadNewCredentials_result();\n      receiveBase(result, \"uploadNewCredentials\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deactivate": "    public void recv_deactivate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      deactivate_result result = new deactivate_result();\n      receiveBase(result, \"deactivate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_cancelBlobUpload": "    public void recv_cancelBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      cancelBlobUpload_result result = new cancelBlobUpload_result();\n      receiveBase(result, \"cancelBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(String id, String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context \n            ReqContext req_context = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            if (trans instanceof TMemoryInputTransport) {\n                try {\n                    req_context.setRemoteAddress(InetAddress.getLocalHost());\n                } catch (UnknownHostException e) {\n                    throw new RuntimeException(e);\n                }                                \n            } else if (trans instanceof TSocket) {\n                TSocket tsocket = (TSocket)trans;\n                //remote address\n                Socket socket = tsocket.getSocket();\n                req_context.setRemoteAddress(socket.getInetAddress());                \n            } \n\n            //anonymous user\n            Subject s = getDefaultSubject();\n            if (s == null) {\n              final String user = (String)storm_conf.get(\"debug.simple.transport.user\");\n              if (user != null) {\n                HashSet<Principal> principals = new HashSet<>();\n                principals.add(new Principal() {\n                  public String getName() { return user; }\n                  public String toString() { return user; }\n                });\n                s = new Subject(true, principals, new HashSet<>(), new HashSet<>());\n              }\n            }\n            req_context.setSubject(s);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-core.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.getDefaultSubject": "    protected Subject getDefaultSubject() {\n        return null;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setSubject": "    public void setSubject(Subject subject) {\n        _subject = subject;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.context": "    public static ReqContext context() {\n        return ctxt.get();\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setRemoteAddress": "    public void setRemoteAddress(InetAddress addr) {\n        _remoteAddr = addr;\n    }"
        },
        "bug_report": {
            "Title": "Stats not get class cast exception",
            "Description": "Component page in UI\n{code}\n2016-03-31 14:21:44.576 o.a.s.t.s.AbstractNonblockingServer$FrameBuffer [ERROR] Unexpected throwable while invoking!\njava.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map\n        at org.apache.storm.stats.StatsUtil.filterSysStreams(StatsUtil.java:1696)\n        at org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt(StatsUtil.java:240)\n        at org.apache.storm.stats.StatsUtil.aggCompExecStats(StatsUtil.java:1130)\n        at org.apache.storm.stats.StatsUtil.aggregateCompStats(StatsUtil.java:1108)\n        at org.apache.storm.stats.StatsUtil.aggCompExecsStats(StatsUtil.java:1236)\n        at org.apache.storm.daemon.nimbus$fn__3490$exec_fn__789__auto__$reify__3519.getComponentPageInfo(nimbus.clj:2130)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3826)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3810)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:158)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:744)\n{code}"
        }
    },
    {
        "filename": "STORM-1520.json",
        "creation_time": "2016-02-03T02:48:58.000+0000",
        "stack_trace": "```\njava.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)\n\tat org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {},
        "bug_report": {
            "Title": "Nimbus Clojure/Zookeeper issue (\"stateChanged\" method not found)",
            "Description": "Placeholder until I can gather more information for reproducing the issue.\n\nThe following appears in nimbus.log after deploying/undeploying topologies:\n\n{code}\n2016-02-02 21:34:04.308 o.a.s.s.o.a.c.f.l.ListenerContainer [ERROR] Listener (org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660@22587507) threw an exception\njava.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)\n\tat org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}\n\n-Basic functionality does not seem to be affected.-\n\nNimbus becomes unresponsive and needs to be manually restarted.\n"
        }
    },
    {
        "filename": "STORM-1977.json",
        "creation_time": "2016-07-17T09:07:06.000+0000",
        "stack_trace": "```\nKeyNotFoundException(msg:production-topology-2-1468745167-stormcode.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:268)\n        ...\n        at org.apache.storm.daemon.nimbus$get_blob_replication_count.invoke(nimbus.clj:498)\n        at org.apache.storm.daemon.nimbus$get_cluster_info$iter__9520__9524$fn__9525.invoke(nimbus.clj:1427)\n        ...\n        at org.apache.storm.daemon.nimbus$get_cluster_info.invoke(nimbus.clj:1401)\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9612.getClusterInfo(nimbus.clj:1838)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3724)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3708)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\nKeyNotFoundException(msg:production-topology-2-1468745167-stormconf.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:239)\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:271)\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:300)\n        ...\n        at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n        at org.apache.storm.daemon.nimbus$read_storm_conf_as_nimbus.invoke(nimbus.clj:548)\n        at org.apache.storm.daemon.nimbus$read_topology_details.invoke(nimbus.clj:555)\n        at org.apache.storm.daemon.nimbus$mk_assignments$iter__9205__9209$fn__9210.invoke(nimbus.clj:912)\n        ...\n        at org.apache.storm.daemon.nimbus$mk_assignments.doInvoke(nimbus.clj:911)\n        at clojure.lang.RestFn.invoke(RestFn.java:410)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770$fn__9781$fn__9782.invoke(nimbus.clj:2216)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770.invoke(nimbus.clj:2215)\n        at org.apache.storm.timer$schedule_recurring$this__1732.invoke(timer.clj:105)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:50)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n\njava.lang.RuntimeException: (\"Error when processing an event\")\n        at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n        at clojure.lang.RestFn.invoke(RestFn.java:423)\n        at org.apache.storm.daemon.nimbus$nimbus_data$fn__8727.invoke(nimbus.clj:205)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:71)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n        at clojure.lang.AFn.run(AFn.java:22)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta": "    private SettableBlobMeta getStoredBlobMeta(String key) throws KeyNotFoundException {\n        InputStream in = null;\n        try {\n            LocalFsBlobStoreFile pf = fbs.read(META_PREFIX+key);\n            try {\n                in = pf.getInputStream();\n            } catch (FileNotFoundException fnf) {\n                throw new KeyNotFoundException(key);\n            }\n            ByteArrayOutputStream out = new ByteArrayOutputStream();\n            byte [] buffer = new byte[2048];\n            int len;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n            in.close();\n            in = null;\n            return Utils.thriftDeserialize(SettableBlobMeta.class, out.toByteArray());\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        } finally {\n            if (in != null) {\n                try {\n                    in.close();\n                } catch (IOException e) {\n                    //Ignored\n                }\n            }\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication": "    public int getBlobReplication(String key, Subject who) throws Exception {\n        int replicationCount = 0;\n        validateKey(key);\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.hasPermissions(meta.get_acl(), READ, who, key);\n        if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) == null) {\n            return 0;\n        }\n        replicationCount = zkClient.getChildren().forPath(BLOBSTORE_SUBTREE + key).size();\n        return replicationCount;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public getTopologyHistory_result getResult(I iface, getTopologyHistory_args args) throws org.apache.thrift.TException {\n        getTopologyHistory_result result = new getTopologyHistory_result();\n        try {\n          result.success = iface.getTopologyHistory(args.user);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setLogConfig": "    public void recv_setLogConfig() throws org.apache.thrift.TException\n    {\n      setLogConfig_result result = new setLogConfig_result();\n      receiveBase(result, \"setLogConfig\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(String location, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deleteBlob": "    public void recv_deleteBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      deleteBlob_result result = new deleteBlob_result();\n      receiveBase(result, \"deleteBlob\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_createStateInZookeeper": "    public void recv_createStateInZookeeper() throws org.apache.thrift.TException\n    {\n      createStateInZookeeper_result result = new createStateInZookeeper_result();\n      receiveBase(result, \"createStateInZookeeper\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadChunk": "    public void recv_uploadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadChunk_result result = new uploadChunk_result();\n      receiveBase(result, \"uploadChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setWorkerProfiler": "    public void recv_setWorkerProfiler() throws org.apache.thrift.TException\n    {\n      setWorkerProfiler_result result = new setWorkerProfiler_result();\n      receiveBase(result, \"setWorkerProfiler\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(String user, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(String key, int replication, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishBlobUpload": "    public void recv_finishBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishBlobUpload_result result = new finishBlobUpload_result();\n      receiveBase(result, \"finishBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_rebalance": "    public void recv_rebalance() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      rebalance_result result = new rebalance_result();\n      receiveBase(result, \"rebalance\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopology": "    public void recv_submitTopology() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopology_result result = new submitTopology_result();\n      receiveBase(result, \"submitTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(String location, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopology": "    public void recv_killTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopology_result result = new killTopology_result();\n      receiveBase(result, \"killTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(String name, String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadBlobChunk": "    public void recv_uploadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadBlobChunk_result result = new uploadBlobChunk_result();\n      receiveBase(result, \"uploadBlobChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_activate": "    public void recv_activate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      activate_result result = new activate_result();\n      receiveBase(result, \"activate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(String file, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(String session, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishFileUpload": "    public void recv_finishFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishFileUpload_result result = new finishFileUpload_result();\n      receiveBase(result, \"finishFileUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setBlobMeta": "    public void recv_setBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      setBlobMeta_result result = new setBlobMeta_result();\n      receiveBase(result, \"setBlobMeta\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopologyWithOpts": "    public void recv_killTopologyWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n      receiveBase(result, \"killTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_debug": "    public void recv_debug() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      debug_result result = new debug_result();\n      receiveBase(result, \"debug\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadNewCredentials": "    public void recv_uploadNewCredentials() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      uploadNewCredentials_result result = new uploadNewCredentials_result();\n      receiveBase(result, \"uploadNewCredentials\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deactivate": "    public void recv_deactivate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      deactivate_result result = new deactivate_result();\n      receiveBase(result, \"deactivate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_cancelBlobUpload": "    public void recv_cancelBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      cancelBlobUpload_result result = new cancelBlobUpload_result();\n      receiveBase(result, \"cancelBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(String id, String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.getBlob": "    public InputStreamWithMeta getBlob(String key, Subject who) throws AuthorizationException, KeyNotFoundException {\n        validateKey(key);\n        if(!checkForBlobOrDownload(key)) {\n            checkForBlobUpdate(key);\n        }\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.hasPermissions(meta.get_acl(), READ, who, key);\n        try {\n            return new BlobStoreFileInputStream(fbs.read(DATA_PREFIX+key));\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobUpdate": "    public synchronized void checkForBlobUpdate(String key) {\n        BlobStoreUtils.updateKeyForBlobStore(conf, this, zkClient, key, nimbusInfo);\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobOrDownload": "    public synchronized boolean checkForBlobOrDownload(String key) {\n        boolean checkBlobDownload = false;\n        try {\n            List<String> keyList = BlobStoreUtils.getKeyListFromBlobStore(this);\n            if (!keyList.contains(key)) {\n                if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) != null) {\n                    Set<NimbusInfo> nimbusSet = BlobStoreUtils.getNimbodesWithLatestSequenceNumberOfBlob(zkClient, key);\n                    if (BlobStoreUtils.downloadMissingBlob(conf, this, key, nimbusSet)) {\n                        LOG.debug(\"Updating blobs state\");\n                        BlobStoreUtils.createStateInZookeeper(conf, key, nimbusInfo);\n                        checkBlobDownload = true;\n                    }\n                }\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n        return checkBlobDownload;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStore.readBlobTo": "    public void readBlobTo(String key, OutputStream out, Subject who) throws IOException, KeyNotFoundException, AuthorizationException {\n        InputStreamWithMeta in = getBlob(key, who);\n        if (in == null) {\n            throw new IOException(\"Could not find \" + key);\n        }\n        byte[] buffer = new byte[2048];\n        int len = 0;\n        try{\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n        } finally {\n            in.close();\n            out.flush();\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStore.close": "        public void close() throws IOException {\n            in.close();\n        }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStore.getBlob": "    public abstract InputStreamWithMeta getBlob(String key, Subject who) throws AuthorizationException, KeyNotFoundException;\n\n    /**\n     * Returns an iterator with all the list of\n     * keys currently available on the blob store.\n     * @return Iterator<String>\n     */\n    public abstract Iterator<String> listKeys();\n\n    /**\n     * Gets the replication factor of the blob.\n     * @param key Key for the blob.\n     * @param who Is the subject having the read privilege for the blob.\n     * @return BlobReplication object containing the\n     * replication factor for the blob.\n     * @throws Exception\n     */\n    public abstract int getBlobReplication(String key, Subject who) throws Exception;\n\n    /**\n     * Modifies the replication factor of the blob.\n     * @param key Key for the blob.\n     * @param replication The replication factor the\n     * blob has to be set.\n     * @param who Is the subject having the update privilege for the blob\n     * @return BlobReplication object containing the\n     * updated replication factor for the blob.\n     * @throws AuthorizationException\n     * @throws KeyNotFoundException\n     * @throws IOException\n     */\n    public abstract int updateBlobReplication(String key, int replication, Subject who) throws AuthorizationException, KeyNotFoundException, IOException;\n\n    /**\n     * Filters keys based on the KeyFilter\n     * passed as the argument.\n     * @param filter KeyFilter\n     * @param <R> Type\n     * @return Set of filtered keys\n     */\n    public <R> Set<R> filterAndListKeys(KeyFilter<R> filter) {\n        Set<R> ret = new HashSet<R>();\n        Iterator<String> keys = listKeys();\n        while (keys.hasNext()) {\n            String key = keys.next();\n            R filtered = filter.filter(key);\n            if (filtered != null) {\n                ret.add(filtered);\n            }\n        }\n        return ret;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStore.write": "        public void write(byte []b, int offset, int len) throws IOException {\n            out.write(b, offset, len);\n        }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStore.read": "        public int read(byte[] b) throws IOException {\n            return in.read(b);\n        }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStore.readBlob": "    public byte[] readBlob(String key, Subject who) throws IOException, KeyNotFoundException, AuthorizationException {\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        readBlobTo(key, out, who);\n        byte[] bytes = out.toByteArray();\n        out.close();\n        return bytes;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStoreFile.getInputStream": "    public InputStream getInputStream() throws IOException {\n        if (isTmp()) {\n            throw new IllegalStateException(\"Cannot read from a temporary part file.\");\n        }\n        return new FileInputStream(_path);\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStoreFile.isTmp": "    public boolean isTmp() {\n        return _isTmp;\n    }"
        },
        "bug_report": {
            "Title": "Leader Nimbus crashes with getClusterInfo when it doesn't have one or more replicated topology codes",
            "Description": "While investigating STORM-1976, I found that there're cases for nimbus to not having topology codes. \nBefore BlobStore, only nimbuses which is having all topology codes can gain leadership, otherwise they give up leadership immediately. While introducing BlobStore, this logic is removed.\n\nI don't know it's intended or not, but it incurs one of nimbus to gain leadership which doesn't have replicated topology code, and the nimbus will be crashed when getClusterInfo is requested.\n\nEasiest way to reproduce is:\n\n1. comment cleanup-corrupt-topologies! from nimbus.clj (It's a quick workaround for resolving STORM-1976), and patch Storm cluster\n2. Launch Nimbus 1 (leader)\n3. Run topology\n4. Kill Nimbus 1\n5. Launch Nimbus 2 from different node\n6. Nimbus 2 gains leadership \n7. getClusterInfo is requested to Nimbus 2, and Nimbus 2 gets crashed\n\nLog:\n\n{code}\n2016-07-17 08:47:48.378 o.a.s.b.FileBlobStoreImpl [INFO] Creating new blob store based in /grid/0/hadoop/storm/blobs\n...\n2016-07-17 08:47:48.619 o.a.s.zookeeper [INFO] Queued up for leader lock.\n2016-07-17 08:47:48.651 o.a.s.zookeeper [INFO] <node1> gained leadership\n...\n2016-07-17 08:47:48.833 o.a.s.d.nimbus [INFO] Starting nimbus server for storm version '1.1.1-SNAPSHOT'\n2016-07-17 08:47:49.295 o.a.s.t.ProcessFunction [ERROR] Internal error processing getClusterInfo\nKeyNotFoundException(msg:production-topology-2-1468745167-stormcode.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:268)\n...\n        at org.apache.storm.daemon.nimbus$get_blob_replication_count.invoke(nimbus.clj:498)\n        at org.apache.storm.daemon.nimbus$get_cluster_info$iter__9520__9524$fn__9525.invoke(nimbus.clj:1427)\n...\n        at org.apache.storm.daemon.nimbus$get_cluster_info.invoke(nimbus.clj:1401)\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9612.getClusterInfo(nimbus.clj:1838)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3724)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3708)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n...\n2016-07-17 08:47:49.397 o.a.s.b.BlobStoreUtils [ERROR] Could not download blob with keyproduction-topology-2-1468745167-stormconf.ser\n2016-07-17 08:47:49.400 o.a.s.b.BlobStoreUtils [ERROR] Could not update the blob with keyproduction-topology-2-1468745167-stormconf.ser\n2016-07-17 08:47:49.402 o.a.s.d.nimbus [ERROR] Error when processing event\nKeyNotFoundException(msg:production-topology-2-1468745167-stormconf.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:239)\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:271)\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:300)\n...\n       at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n        at org.apache.storm.daemon.nimbus$read_storm_conf_as_nimbus.invoke(nimbus.clj:548)\n        at org.apache.storm.daemon.nimbus$read_topology_details.invoke(nimbus.clj:555)\n        at org.apache.storm.daemon.nimbus$mk_assignments$iter__9205__9209$fn__9210.invoke(nimbus.clj:912)\n...\n        at org.apache.storm.daemon.nimbus$mk_assignments.doInvoke(nimbus.clj:911)\n        at clojure.lang.RestFn.invoke(RestFn.java:410)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770$fn__9781$fn__9782.invoke(nimbus.clj:2216)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770$fn__9781.invoke(nimbus.clj:2215)\n        at org.apache.storm.timer$schedule_recurring$this__1732.invoke(timer.clj:105)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:50)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n...\n2016-07-17 08:47:49.408 o.a.s.util [ERROR] Halting process: (\"Error when processing an event\")\njava.lang.RuntimeException: (\"Error when processing an event\")\n        at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n        at clojure.lang.RestFn.invoke(RestFn.java:423)\n        at org.apache.storm.daemon.nimbus$nimbus_data$fn__8727.invoke(nimbus.clj:205)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:71)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n        at clojure.lang.AFn.run(AFn.java:22)\n        at java.lang.Thread.run(Thread.java:745)\n2016-07-17 08:47:49.410 o.a.s.d.nimbus [INFO] Shutting down master\n{code}\n"
        }
    },
    {
        "filename": "STORM-2988.json",
        "creation_time": "2018-03-07T14:55:22.000+0000",
        "stack_trace": "```\njava.lang.IllegalArgumentException: Don't know how to convert {\"class\" \"org.apache.storm.metrics2.reporters.JmxStormReporter\", \"daemons\" [\"supervisor\" \"nimbus\" \"worker\"], \"report.period\" 10, \"report.period.units\" \"SECONDS\"} + to String\n\tat org.apache.storm.utils.Utils.getString(Utils.java:848) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain(JmxStormReporter.java:70) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.prepare(JmxStormReporter.java:51) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.StormMetricRegistry.startReporter(StormMetricRegistry.java:119) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.StormMetricRegistry.start(StormMetricRegistry.java:102) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.daemon.worker$fn__5545$exec_fn__1369__auto____5546.invoke(worker.clj:611) ~[storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.AFn.applyToHelper(AFn.java:178) ~[clojure-1.7.0.jar:?]\n\tat clojure.lang.AFn.applyTo(AFn.java:144) ~[clojure-1.7.0.jar:?]\n\tat clojure.core$apply.invoke(core.clj:630) ~[clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]\njava.lang.RuntimeException: (\"Error on initialization\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]\n```",
        "source_code": {},
        "bug_report": {
            "Title": "\"Error on initialization of server mk-worker\" when using org.apache.storm.metrics2.reporters.JmxStormReporter on worker",
            "Description": "As per documentation, I configured metrics v2 in my storm.yaml using the following configuration:\r\n\u00a0\r\n{code:yaml}\r\nstorm.metrics.reporters:\r\n\r\n  - class: \"org.apache.storm.metrics2.reporters.JmxStormReporter\"\r\n    daemons:\r\n        - \"supervisor\"\r\n        - \"nimbus\"\r\n        - \"worker\"\r\n    report.period: 10\r\n    report.period.units: \"SECONDS\"\r\n{code}\r\n\r\nWhen I start nimbus and supervisors everything works properly, I can see metrics reported to JMX, and logs (for nimbus in this example) report:\r\n\r\n{code}\r\n2018-03-07 15:35:22.201 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter\r\n2018-03-07 15:35:22.203 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...\r\n2018-03-07 15:35:22.221 o.a.s.d.common main [INFO] Started statistics report plugin...\r\n{code}\r\n\r\nWhen I submit a topology, workers cannot initialize and report this error\r\n\r\n{code:java}\r\n2018-03-07 15:39:19.136 o.a.s.d.worker main [INFO] Launching worker for stp_topology-1-1520433551 on [... cut ...]\r\n2018-03-07 15:39:19.169 o.a.s.m.StormMetricRegistry main [INFO] Starting metrics reporters...\r\n2018-03-07 15:39:19.172 o.a.s.m.StormMetricRegistry main [INFO] Attempting to instantiate reporter class: org.apache.storm.metrics2.reporters.JmxStormReporter\r\n2018-03-07 15:39:19.175 o.a.s.m.r.JmxStormReporter main [INFO] Preparing...\r\n2018-03-07 15:39:19.182 o.a.s.d.worker main [ERROR] Error on initialization of server mk-worker\r\njava.lang.IllegalArgumentException: Don't know how to convert {\"class\" \"org.apache.storm.metrics2.reporters.JmxStormReporter\", \"daemons\" [\"supervisor\" \"nimbus\" \"worker\"], \"report.period\" 10, \"report.period.units\" \"SECONDS\"} + to String\r\n\tat org.apache.storm.utils.Utils.getString(Utils.java:848) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain(JmxStormReporter.java:70) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.prepare(JmxStormReporter.java:51) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.StormMetricRegistry.startReporter(StormMetricRegistry.java:119) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.StormMetricRegistry.start(StormMetricRegistry.java:102) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.daemon.worker$fn__5545$exec_fn__1369__auto____5546.invoke(worker.clj:611) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:178) ~[clojure-1.7.0.jar:?]\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144) ~[clojure-1.7.0.jar:?]\r\n\tat clojure.core$apply.invoke(core.clj:630) ~[clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]\r\n2018-03-07 15:39:19.195 o.a.s.util main [ERROR] Halting process: (\"Error on initialization\")\r\njava.lang.RuntimeException: (\"Error on initialization\")\r\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]\r\n{code}\r\n\r\nLooking at org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain() I found that it passes \"reporterConf\" map to Utils.getString() instead of a string:\r\n{code:java}\r\n    public static String getMetricsJMXDomain(Map reporterConf) {\r\n        return Utils.getString(reporterConf, JMX_DOMAIN);\r\n}\r\n{code}\r\n\r\nThe \"prepare\" method in org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter used by nimbus and supervisor correctly passes a string to Utils.getString():\r\n\r\n{code:java}\r\npublic void prepare(MetricRegistry metricsRegistry, Map stormConf) {\r\n        LOG.info(\"Preparing...\");\r\n        JmxReporter.Builder builder = JmxReporter.forRegistry(metricsRegistry);\r\n        String domain = Utils.getString(stormConf.get(Config.STORM_DAEMON_METRICS_REPORTER_PLUGIN_DOMAIN), null);\r\n        if (domain != null) {\r\n            builder.inDomain(domain);\r\n}\r\n[...]\r\n{code}\r\n\r\nIs this a bug or am I missing something in configuration?\r\n\r\nRegards,\r\nFederico Chiacchiaretta"
        }
    },
    {
        "filename": "STORM-2321.json",
        "creation_time": "2017-01-24T04:18:07.000+0000",
        "stack_trace": "```\norg.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /blobstore/KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:200)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:149)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.util.NoSuchElementException\n\tat java.util.TreeMap.key(TreeMap.java:1327)\n\tat java.util.TreeMap.lastKey(TreeMap.java:297)\n\tat java.util.TreeSet.last(TreeSet.java:401)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:206)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:92)\n\tat org.apache.storm.daemon.nimbus$fn__9373.invoke(nimbus.clj:1452)\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:233)\n\tat org.apache.storm.daemon.nimbus$fn__9770$exec_fn__3656__auto____9771$fn__9786.invoke(nimbus.clj:2452)\n\tat org.apache.storm.timer$schedule_recurring$this__2188.invoke(timer.clj:105)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:50)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:114)\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:76)\n\t... 8 more\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:252)\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:111)\n\t... 9 more\nCaused by: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:349)\n\tat org.apache.storm.blobstore.BlobStoreUtils.createStateInZookeeper(BlobStoreUtils.java:217)\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:249)\n\t... 10 more\nCaused by: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:376)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:453)\n\tat org.apache.storm.thrift.transport.TSaslTransport.read(TSaslTransport.java:435)\n\tat org.apache.storm.thrift.transport.TSaslClientTransport.readAll(TSaslClientTransport.java:37)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_createStateInZookeeper(Nimbus.java:1000)\n\tat org.apache.storm.generated.Nimbus$Client.createStateInZookeeper(Nimbus.java:987)\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:346)\n\t... 12 more\n\njava.lang.RuntimeException: (\"Error when processing an event\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$nimbus_data$fn__8579.invoke(nimbus.clj:212)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:71)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber": "    public synchronized int getKeySequenceNumber(Map conf) {\n        TreeSet<Integer> sequenceNumbers = new TreeSet<Integer>();\n        CuratorFramework zkClient = BlobStoreUtils.createZKClient(conf);\n        try {\n            // Key has not been created yet and it is the first time it is being created\n            if(zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + \"/\" + key) == null) {\n                zkClient.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT)\n                        .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE).forPath(BLOBSTORE_MAX_KEY_SEQUENCE_SUBTREE + \"/\" + key);\n                zkClient.setData().forPath(BLOBSTORE_MAX_KEY_SEQUENCE_SUBTREE + \"/\" + key,\n                        ByteBuffer.allocate(INT_CAPACITY).putInt(INITIAL_SEQUENCE_NUMBER).array());\n                return INITIAL_SEQUENCE_NUMBER;\n            }\n\n            // When all nimbodes go down and one or few of them come up\n            // Unfortunately there might not be an exact way to know which one contains the most updated blob,\n            // if all go down which is unlikely. Hence there might be a need to update the blob if all go down.\n            List<String> stateInfoList = zkClient.getChildren().forPath(BLOBSTORE_SUBTREE + \"/\" + key);\n            LOG.debug(\"stateInfoList-size {} stateInfoList-data {}\", stateInfoList.size(), stateInfoList);\n            if(stateInfoList.isEmpty()) {\n                return getMaxSequenceNumber(zkClient);\n            }\n\n            LOG.debug(\"stateInfoSize {}\", stateInfoList.size());\n            // In all other cases check for the latest update sequence of the blob on the nimbus\n            // and assign the appropriate number. Check if all are have same sequence number,\n            // if not assign the highest sequence number.\n            for (String stateInfo:stateInfoList) {\n                sequenceNumbers.add(Integer.parseInt(BlobStoreUtils.normalizeNimbusHostPortSequenceNumberInfo(stateInfo)\n                        .getSequenceNumber()));\n            }\n\n            // Update scenario 2 and 3 explain the code logic written here\n            // especially when nimbus crashes and comes up after and before update\n            // respectively.\n            int currentSeqNumber = getMaxSequenceNumber(zkClient);\n            if (!checkIfStateContainsCurrentNimbusHost(stateInfoList, nimbusInfo) && !nimbusInfo.isLeader()) {\n                if (sequenceNumbers.last() < currentSeqNumber) {\n                    return currentSeqNumber;\n                } else {\n                    return INITIAL_SEQUENCE_NUMBER - 1;\n                }\n            }\n\n            // It covers scenarios expalined in scenario 3 when nimbus-1 holding the latest\n            // update goes down before it is downloaded by nimbus-2. Nimbus-2 gets elected as a leader\n            // after which nimbus-1 comes back up and a read or update is performed.\n            if (!checkIfStateContainsCurrentNimbusHost(stateInfoList, nimbusInfo) && nimbusInfo.isLeader()) {\n                incrementMaxSequenceNumber(zkClient, currentSeqNumber);\n                return currentSeqNumber + 1;\n            }\n\n            // This code logic covers the update scenarios in 2 when the nimbus-1 goes down\n            // before syncing the blob to nimbus-2 and an update happens.\n            // If seq-num for nimbus-2 is 2 and max-seq-number is 3 then next sequence number is 4\n            // (max-seq-number + 1).\n            // Other scenario it covers is when max-seq-number and nimbus seq number are equal.\n            if (sequenceNumbers.size() == 1) {\n                if (sequenceNumbers.first() < currentSeqNumber) {\n                    incrementMaxSequenceNumber(zkClient, currentSeqNumber);\n                    return currentSeqNumber + 1;\n                } else {\n                    incrementMaxSequenceNumber(zkClient, currentSeqNumber);\n                    return sequenceNumbers.first() + 1;\n                }\n            }\n        } catch(Exception e) {\n            LOG.error(\"Exception {}\", e);\n        } finally {\n            if (zkClient != null) {\n                zkClient.close();\n            }\n        }\n        // Normal create update sync scenario returns the greatest sequence number in the set\n        return sequenceNumbers.last();\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.KeySequenceNumber.getMaxSequenceNumber": "    private int getMaxSequenceNumber(CuratorFramework zkClient) throws Exception {\n        return ByteBuffer.wrap(zkClient.getData()\n                .forPath(BLOBSTORE_MAX_KEY_SEQUENCE_SUBTREE + \"/\" + key)).getInt();\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.KeySequenceNumber.checkIfStateContainsCurrentNimbusHost": "    private boolean checkIfStateContainsCurrentNimbusHost(List<String> stateInfoList, NimbusInfo nimbusInfo) {\n        boolean containsNimbusHost = false;\n        for(String stateInfo:stateInfoList) {\n            if(stateInfo.contains(nimbusInfo.getHost())) {\n                containsNimbusHost = true;\n                break;\n            }\n        }\n        return containsNimbusHost;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.KeySequenceNumber.incrementMaxSequenceNumber": "    private void incrementMaxSequenceNumber(CuratorFramework zkClient, int count) throws Exception {\n        zkClient.setData().forPath(BLOBSTORE_MAX_KEY_SEQUENCE_SUBTREE + \"/\" + key,\n                ByteBuffer.allocate(INT_CAPACITY).putInt(count + 1).array());\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public getTopologyHistory_result getResult(I iface, getTopologyHistory_args args) throws org.apache.thrift.TException {\n        getTopologyHistory_result result = new getTopologyHistory_result();\n        try {\n          result.success = iface.getTopologyHistory(args.user);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setLogConfig": "    public void recv_setLogConfig() throws org.apache.thrift.TException\n    {\n      setLogConfig_result result = new setLogConfig_result();\n      receiveBase(result, \"setLogConfig\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(String location, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deleteBlob": "    public void recv_deleteBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      deleteBlob_result result = new deleteBlob_result();\n      receiveBase(result, \"deleteBlob\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_createStateInZookeeper": "    public void recv_createStateInZookeeper() throws org.apache.thrift.TException\n    {\n      createStateInZookeeper_result result = new createStateInZookeeper_result();\n      receiveBase(result, \"createStateInZookeeper\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadChunk": "    public void recv_uploadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadChunk_result result = new uploadChunk_result();\n      receiveBase(result, \"uploadChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setWorkerProfiler": "    public void recv_setWorkerProfiler() throws org.apache.thrift.TException\n    {\n      setWorkerProfiler_result result = new setWorkerProfiler_result();\n      receiveBase(result, \"setWorkerProfiler\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(String user, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(String key, int replication, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishBlobUpload": "    public void recv_finishBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishBlobUpload_result result = new finishBlobUpload_result();\n      receiveBase(result, \"finishBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_rebalance": "    public void recv_rebalance() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      rebalance_result result = new rebalance_result();\n      receiveBase(result, \"rebalance\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopology": "    public void recv_submitTopology() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopology_result result = new submitTopology_result();\n      receiveBase(result, \"submitTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(String location, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopology": "    public void recv_killTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopology_result result = new killTopology_result();\n      receiveBase(result, \"killTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(String name, String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadBlobChunk": "    public void recv_uploadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadBlobChunk_result result = new uploadBlobChunk_result();\n      receiveBase(result, \"uploadBlobChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_activate": "    public void recv_activate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      activate_result result = new activate_result();\n      receiveBase(result, \"activate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(String file, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(String session, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(String id, String host, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishFileUpload": "    public void recv_finishFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishFileUpload_result result = new finishFileUpload_result();\n      receiveBase(result, \"finishFileUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setBlobMeta": "    public void recv_setBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      setBlobMeta_result result = new setBlobMeta_result();\n      receiveBase(result, \"setBlobMeta\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopologyWithOpts": "    public void recv_killTopologyWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n      receiveBase(result, \"killTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_debug": "    public void recv_debug() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      debug_result result = new debug_result();\n      receiveBase(result, \"debug\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadNewCredentials": "    public void recv_uploadNewCredentials() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      uploadNewCredentials_result result = new uploadNewCredentials_result();\n      receiveBase(result, \"uploadNewCredentials\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deactivate": "    public void recv_deactivate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      deactivate_result result = new deactivate_result();\n      receiveBase(result, \"deactivate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_cancelBlobUpload": "    public void recv_cancelBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      cancelBlobUpload_result result = new cancelBlobUpload_result();\n      receiveBase(result, \"cancelBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(String id, String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.SaslTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context\n            ReqContext req_context = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            //Sasl transport\n            TSaslServerTransport saslTrans = (TSaslServerTransport)trans;\n\n            if(trans instanceof NoOpTTrasport) {\n                return false;\n            }\n\n            //remote address\n            TSocket tsocket = (TSocket)saslTrans.getUnderlyingTransport();\n            Socket socket = tsocket.getSocket();\n            req_context.setRemoteAddress(socket.getInetAddress());\n\n            //remote subject\n            SaslServer saslServer = saslTrans.getSaslServer();\n            String authId = saslServer.getAuthorizationID();\n            Subject remoteUser = new Subject();\n            remoteUser.getPrincipals().add(new User(authId));\n            req_context.setSubject(remoteUser);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobSynchronizer.syncBlobs": "    public synchronized void syncBlobs() {\n        try {\n            LOG.debug(\"Sync blobs - blobstore keys {}, zookeeper keys {}\",getBlobStoreKeySet(), getZookeeperKeySet());\n            zkClient = BlobStoreUtils.createZKClient(conf);\n            deleteKeySetFromBlobStoreNotOnZookeeper(getBlobStoreKeySet(), getZookeeperKeySet());\n            updateKeySetForBlobStore(getBlobStoreKeySet());\n            Set<String> keySetToDownload = getKeySetToDownload(getBlobStoreKeySet(), getZookeeperKeySet());\n            LOG.debug(\"Key set Blobstore-> Zookeeper-> DownloadSet {}-> {}-> {}\", getBlobStoreKeySet(), getZookeeperKeySet(), keySetToDownload);\n\n            for (String key : keySetToDownload) {\n                Set<NimbusInfo> nimbusInfoSet = BlobStoreUtils.getNimbodesWithLatestSequenceNumberOfBlob(zkClient, key);\n                if(BlobStoreUtils.downloadMissingBlob(conf, blobStore, key, nimbusInfoSet)) {\n                    BlobStoreUtils.createStateInZookeeper(conf, key, nimbusInfo);\n                }\n            }\n            if (zkClient !=null) {\n                zkClient.close();\n            }\n        } catch(InterruptedException | ClosedByInterruptException exp) {\n            LOG.error(\"Interrupt Exception {}\", exp);\n        } catch(Exception exp) {\n            throw new RuntimeException(exp);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobSynchronizer.deleteKeySetFromBlobStoreNotOnZookeeper": "    public void deleteKeySetFromBlobStoreNotOnZookeeper(Set<String> keySetBlobStore, Set<String> keySetZookeeper) throws Exception {\n        if (keySetBlobStore.removeAll(keySetZookeeper)\n                || (keySetZookeeper.isEmpty() && !keySetBlobStore.isEmpty())) {\n            LOG.debug(\"Key set to delete in blobstore {}\", keySetBlobStore);\n            for (String key : keySetBlobStore) {\n                blobStore.deleteBlob(key, BlobStoreUtils.getNimbusSubject());\n            }\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobSynchronizer.getBlobStoreKeySet": "    public Set<String> getBlobStoreKeySet() {\n        Set<String> keySet = new HashSet<String>();\n        keySet.addAll(blobStoreKeySet);\n        return keySet;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobSynchronizer.getZookeeperKeySet": "    public Set<String> getZookeeperKeySet() {\n        Set<String> keySet = new HashSet<String>();\n        keySet.addAll(zookeeperKeySet);\n        return keySet;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobSynchronizer.getKeySetToDownload": "    public Set<String> getKeySetToDownload(Set<String> blobStoreKeySet, Set<String> zookeeperKeySet) {\n        zookeeperKeySet.removeAll(blobStoreKeySet);\n        LOG.debug(\"Key list to download {}\", zookeeperKeySet);\n        return zookeeperKeySet;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore": "    public void updateKeySetForBlobStore(Set<String> keySetBlobStore) {\n        try {\n            for (String key : keySetBlobStore) {\n                LOG.debug(\"updating blob\");\n                BlobStoreUtils.updateKeyForBlobStore(conf, blobStore, zkClient, key, nimbusInfo);\n            }\n        } catch (Exception exp) {\n            throw new RuntimeException(exp);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore": "    public static void updateKeyForBlobStore (Map<String, Object> conf, BlobStore blobStore, CuratorFramework zkClient, String key, NimbusInfo nimbusDetails) {\n        try {\n            // Most of clojure tests currently try to access the blobs using getBlob. Since, updateKeyForBlobStore\n            // checks for updating the correct version of the blob as a part of nimbus ha before performing any\n            // operation on it, there is a necessity to stub several test cases to ignore this method. It is a valid\n            // trade off to return if nimbusDetails which include the details of the current nimbus host port data are\n            // not initialized as a part of the test. Moreover, this applies to only local blobstore when used along with\n            // nimbus ha.\n            if (nimbusDetails == null) {\n                return;\n            }\n            boolean isListContainsCurrentNimbusInfo = false;\n            List<String> stateInfo;\n            if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + \"/\" + key) == null) {\n                return;\n            }\n            stateInfo = zkClient.getChildren().forPath(BLOBSTORE_SUBTREE + \"/\" + key);\n\n            LOG.debug(\"StateInfo for update {}\", stateInfo);\n            Set<NimbusInfo> nimbusInfoList = getNimbodesWithLatestSequenceNumberOfBlob(zkClient, key);\n\n            for (NimbusInfo nimbusInfo:nimbusInfoList) {\n                if (nimbusInfo.getHost().equals(nimbusDetails.getHost())) {\n                    isListContainsCurrentNimbusInfo = true;\n                    break;\n                }\n            }\n\n            if (!isListContainsCurrentNimbusInfo && downloadUpdatedBlob(conf, blobStore, key, nimbusInfoList)) {\n                LOG.debug(\"Updating state inside zookeeper for an update\");\n                createStateInZookeeper(conf, key, nimbusDetails);\n            }\n        } catch (NoNodeException e) {\n            //race condition with a delete\n            return;\n        } catch (Exception exp) {\n            throw new RuntimeException(exp);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.getNimbodesWithLatestSequenceNumberOfBlob": "    public static Set<NimbusInfo> getNimbodesWithLatestSequenceNumberOfBlob(CuratorFramework zkClient, String key) throws Exception {\n        List<String> stateInfoList = zkClient.getChildren().forPath(\"/blobstore/\" + key);\n        Set<NimbusInfo> nimbusInfoSet = new HashSet<NimbusInfo>();\n        int latestSeqNumber = getLatestSequenceNumber(stateInfoList);\n        LOG.debug(\"getNimbodesWithLatestSequenceNumberOfBlob stateInfo {} version {}\", stateInfoList, latestSeqNumber);\n        // Get the nimbodes with the latest version\n        for(String state : stateInfoList) {\n            BlobKeySequenceInfo sequenceInfo = normalizeNimbusHostPortSequenceNumberInfo(state);\n            if (latestSeqNumber == Integer.parseInt(sequenceInfo.getSequenceNumber())) {\n                nimbusInfoSet.add(NimbusInfo.parse(sequenceInfo.getNimbusHostPort()));\n            }\n        }\n        LOG.debug(\"nimbusInfoList {}\", nimbusInfoSet);\n        return nimbusInfoSet;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.downloadUpdatedBlob": "    public static boolean downloadUpdatedBlob(Map<String, Object> conf, BlobStore blobStore, String key, Set<NimbusInfo> nimbusInfos)\n            throws TTransportException {\n        ClientBlobStore remoteBlobStore;\n        InputStreamWithMeta in;\n        AtomicOutputStream out;\n        boolean isSuccess = false;\n        LOG.debug(\"Download blob NimbusInfos {}\", nimbusInfos);\n        for (NimbusInfo nimbusInfo : nimbusInfos) {\n            if (isSuccess) {\n                break;\n            }\n            try(NimbusClient client = new NimbusClient(conf, nimbusInfo.getHost(), nimbusInfo.getPort(), null)) {\n                remoteBlobStore = new NimbusBlobStore();\n                remoteBlobStore.setClient(conf, client);\n                in = remoteBlobStore.getBlob(key);\n                out = blobStore.updateBlob(key, getNimbusSubject());\n                byte[] buffer = new byte[2048];\n                int len = 0;\n                while ((len = in.read(buffer)) > 0) {\n                    out.write(buffer, 0, len);\n                }\n                if (out != null) {\n                    out.close();\n                }\n                isSuccess = true;\n            } catch (IOException | AuthorizationException exception) {\n                throw new RuntimeException(exception);\n            } catch (KeyNotFoundException knf) {\n                // Catching and logging KeyNotFoundException because, if\n                // there is a subsequent update and delete, the non-leader\n                // nimbodes might throw an exception.\n                LOG.info(\"KeyNotFoundException {}\", knf);\n            } catch (Exception exp) {\n                // Logging an exception while client is connecting\n                LOG.error(\"Exception {}\", exp);\n            }\n        }\n\n        if (!isSuccess) {\n            LOG.error(\"Could not update the blob with key: {}\", key);\n        }\n        return isSuccess;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.createStateInZookeeper": "    public static void createStateInZookeeper(Map<String, Object> conf, String key, NimbusInfo nimbusInfo) throws TTransportException {\n        ClientBlobStore cb = new NimbusBlobStore();\n        cb.setClient(conf, new NimbusClient(conf, nimbusInfo.getHost(), nimbusInfo.getPort(), null));\n        cb.createStateInZookeeper(key);\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper": "    public void createStateInZookeeper(String key) {\n        try {\n            synchronized(client) {\n                client.getClient().createStateInZookeeper(key);\n            }\n        } catch (TException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.normalizeNimbusHostPortSequenceNumberInfo": "    public static BlobKeySequenceInfo normalizeNimbusHostPortSequenceNumberInfo(String nimbusSeqNumberInfo) {\n        BlobKeySequenceInfo keySequenceInfo = new BlobKeySequenceInfo();\n        int lastIndex = nimbusSeqNumberInfo.lastIndexOf(\"-\");\n        keySequenceInfo.setNimbusHostPort(nimbusSeqNumberInfo.substring(0, lastIndex));\n        keySequenceInfo.setSequenceNumber(nimbusSeqNumberInfo.substring(lastIndex + 1));\n        return keySequenceInfo;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.createZKClient": "    public static CuratorFramework createZKClient(Map<String, Object> conf) {\n        @SuppressWarnings(\"unchecked\")\n        List<String> zkServers = (List<String>) conf.get(Config.STORM_ZOOKEEPER_SERVERS);\n        Object port = conf.get(Config.STORM_ZOOKEEPER_PORT);\n        ZookeeperAuthInfo zkAuthInfo = new ZookeeperAuthInfo(conf);\n        CuratorFramework zkClient = Utils.newCurator(conf, zkServers, port, (String) conf.get(Config.STORM_ZOOKEEPER_ROOT), zkAuthInfo);\n        zkClient.start();\n        return zkClient;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setSubject": "    public void setSubject(Subject subject) {\n        _subject = subject;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.context": "    public static ReqContext context() {\n        return ctxt.get();\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setRemoteAddress": "    public void setRemoteAddress(InetAddress addr) {\n        _remoteAddr = addr;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.downloadMissingBlob": "    public static boolean downloadMissingBlob(Map<String, Object> conf, BlobStore blobStore, String key, Set<NimbusInfo> nimbusInfos)\n            throws TTransportException {\n        ReadableBlobMeta rbm;\n        ClientBlobStore remoteBlobStore;\n        InputStreamWithMeta in;\n        boolean isSuccess = false;\n        LOG.debug(\"Download blob NimbusInfos {}\", nimbusInfos);\n        for (NimbusInfo nimbusInfo : nimbusInfos) {\n            if(isSuccess) {\n                break;\n            }\n            try(NimbusClient client = new NimbusClient(conf, nimbusInfo.getHost(), nimbusInfo.getPort(), null)) {\n                rbm = client.getClient().getBlobMeta(key);\n                remoteBlobStore = new NimbusBlobStore();\n                remoteBlobStore.setClient(conf, client);\n                in = remoteBlobStore.getBlob(key);\n                blobStore.createBlob(key, in, rbm.get_settable(), getNimbusSubject());\n                // if key already exists while creating the blob else update it\n                Iterator<String> keyIterator = blobStore.listKeys();\n                while (keyIterator.hasNext()) {\n                    if (keyIterator.next().equals(key)) {\n                        LOG.debug(\"Success creating key, {}\", key);\n                        isSuccess = true;\n                        break;\n                    }\n                }\n            } catch (IOException | AuthorizationException exception) {\n                throw new RuntimeException(exception);\n            } catch (KeyAlreadyExistsException kae) {\n                LOG.info(\"KeyAlreadyExistsException Key: {} {}\", key, kae);\n            } catch (KeyNotFoundException knf) {\n                // Catching and logging KeyNotFoundException because, if\n                // there is a subsequent update and delete, the non-leader\n                // nimbodes might throw an exception.\n                LOG.info(\"KeyNotFoundException Key: {} {}\", key, knf);\n            } catch (Exception exp) {\n                // Logging an exception while client is connecting\n                LOG.error(\"Exception {}\", exp);\n            }\n        }\n\n        if (!isSuccess) {\n            LOG.error(\"Could not download the blob with key: {}\", key);\n        }\n        return isSuccess;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.BlobStoreUtils.getNimbusSubject": "    public static Subject getNimbusSubject() {\n        Subject subject = new Subject();\n        subject.getPrincipals().add(new NimbusPrincipal());\n        return subject;\n    }"
        },
        "bug_report": {
            "Title": "Nimbus did not come up after restart",
            "Description": "The nimbus was restarted during HA testing. After the restart the nimbus failed to come up. \n{code}\n2017-01-18 04:57:58.231 o.a.s.s.o.a.c.f.s.ConnectionStateManager [INFO] State change: CONNECTED\n2017-01-18 04:57:58.247 o.a.s.b.BlobStoreUtils [ERROR] Could not update the blob with keyKillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar\n2017-01-18 04:57:58.273 o.a.s.b.KeySequenceNumber [ERROR] Exception {}\norg.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /blobstore/KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:200)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:149)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n2017-01-18 04:57:58.274 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl [INFO] backgroundOperationsLoop exiting\n2017-01-18 04:57:58.296 o.a.s.m.n.Login [INFO] successfully logged in.\n2017-01-18 04:57:58.309 o.a.s.s.o.a.z.ZooKeeper [INFO] Session: 0x359afc1eaa2009b closed\n2017-01-18 04:57:58.309 o.a.s.s.o.a.z.ClientCnxn [INFO] EventThread shut down\n2017-01-18 04:57:58.310 o.a.s.t.s.TThreadPoolServer [ERROR] Error occurred during processing of message.\njava.util.NoSuchElementException\n\tat java.util.TreeMap.key(TreeMap.java:1327)\n\tat java.util.TreeMap.lastKey(TreeMap.java:297)\n\tat java.util.TreeSet.last(TreeSet.java:401)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:206)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n2017-01-18 04:57:58.311 o.a.s.d.nimbus [ERROR] Error when processing event\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:92)\n\tat org.apache.storm.daemon.nimbus$fn__9373.invoke(nimbus.clj:1452)\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:233)\n\tat org.apache.storm.daemon.nimbus$fn__9770$exec_fn__3656__auto____9771$fn__9786.invoke(nimbus.clj:2452)\n\tat org.apache.storm.timer$schedule_recurring$this__2188.invoke(timer.clj:105)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:50)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:114)\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:76)\n\t... 8 more\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:252)\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:111)\n\t... 9 more\nCaused by: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:349)\n\tat org.apache.storm.blobstore.BlobStoreUtils.createStateInZookeeper(BlobStoreUtils.java:217)\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:249)\n\t... 10 more\nCaused by: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:376)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:453)\n\tat org.apache.storm.thrift.transport.TSaslTransport.read(TSaslTransport.java:435)\n\tat org.apache.storm.thrift.transport.TSaslClientTransport.read(TSaslClientTransport.java:37)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_createStateInZookeeper(Nimbus.java:1000)\n\tat org.apache.storm.generated.Nimbus$Client.createStateInZookeeper(Nimbus.java:987)\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:346)\n\t... 12 more\n2017-01-18 04:57:58.314 o.a.s.util [ERROR] Halting process: (\"Error when processing an event\")\njava.lang.RuntimeException: (\"Error when processing an event\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$nimbus_data$fn__8579.invoke(nimbus.clj:212)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:71)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)\n2017-01-18 04:57:58,317 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,317 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,317 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,318 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,318 FATAL Ignoring log event after log4j was shut down\n{code}"
        }
    },
    {
        "filename": "STORM-3013.json",
        "creation_time": "2018-03-28T04:47:28.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.IllegalStateException: This consumer has already been closed.\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.utils.DisruptorQueue.consumeBatch(DisruptorQueue.java:477) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.disruptor$consume_batch.invoke(disruptor.clj:70) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$fn__4975$fn__4990$fn__5021.invoke(executor.clj:634) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) [storm-core-1.2.1.jar:1.2.1]\nat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\nat java.lang.Thread.run(Thread.java:745) [?:1.8.0_45]\nCaused by: java.lang.IllegalStateException: This consumer has already been closed.\nat org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:1787) ~[stormjar.jar:?]\nat org.apache.kafka.clients.consumer.KafkaConsumer.beginningOffsets(KafkaConsumer.java:1622) ~[stormjar.jar:?]\nat org.apache.storm.kafka.spout.metrics.KafkaOffsetMetric.getValueAndReset(KafkaOffsetMetric.java:79) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$metrics_tick$fn__4899.invoke(executor.clj:345) ~[storm-core-1.2.1.jar:1.2.1]\nat clojure.core$map$fn__4553.invoke(core.clj:2622) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\nat clojure.lang.RT.seq(RT.java:507) ~[clojure-1.7.0.jar:?]\nat clojure.core$seq__4128.invoke(core.clj:137) ~[clojure-1.7.0.jar:?]\nat clojure.core$filter$fn__4580.invoke(core.clj:2679) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\nat clojure.lang.Cons.next(Cons.java:39) ~[clojure-1.7.0.jar:?]\nat clojure.lang.RT.next(RT.java:674) ~[clojure-1.7.0.jar:?]\nat clojure.core$next__4112.invoke(core.clj:64) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6523.invoke(protocols.clj:170) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6478$G__6473__6487.invoke(protocols.clj:19) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$seq_reduce.invoke(protocols.clj:31) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6506.invoke(protocols.clj:101) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6452$G__6447__6465.invoke(protocols.clj:13) ~[clojure-1.7.0.jar:?]\nat clojure.core$reduce.invoke(core.clj:6519) ~[clojure-1.7.0.jar:?]\nat clojure.core$into.invoke(core.clj:6600) ~[clojure-1.7.0.jar:?]\nat org.apache.storm.daemon.executor$metrics_tick.invoke(executor.clj:349) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$fn__4975$tuple_action_fn__4981.invoke(executor.clj:522) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$mk_task_receiver$fn__4964.invoke(executor.clj:471) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.disruptor$clojure_handler$reify__4475.onEvent(disruptor.clj:41) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.1.jar:1.2.1]```",
        "source_code": {
            "external.storm-kafka-client.src.main.java.org.apache.storm.kafka.spout.metrics.KafkaOffsetMetric.getValueAndReset": "    public Object getValueAndReset() {\n\n        Map<TopicPartition, OffsetManager> offsetManagers = offsetManagerSupplier.get();\n        KafkaConsumer kafkaConsumer = consumerSupplier.get();\n\n        if (offsetManagers == null || offsetManagers.isEmpty() || kafkaConsumer == null) {\n            LOG.debug(\"Metrics Tick: offsetManagers or kafkaConsumer is null.\");\n            return null;\n        }\n\n        Map<String,TopicMetrics> topicMetricsMap = new HashMap<>();\n        Set<TopicPartition> topicPartitions = offsetManagers.keySet();\n\n        Map<TopicPartition, Long> beginningOffsets = kafkaConsumer.beginningOffsets(topicPartitions);\n        Map<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(topicPartitions);\n        //map to hold partition level and topic level metrics\n        Map<String, Long> result = new HashMap<>();\n\n        for (Map.Entry<TopicPartition, OffsetManager> entry : offsetManagers.entrySet()) {\n            TopicPartition topicPartition = entry.getKey();\n            OffsetManager offsetManager = entry.getValue();\n\n            long latestTimeOffset = endOffsets.get(topicPartition);\n            long earliestTimeOffset = beginningOffsets.get(topicPartition);\n\n            long latestEmittedOffset = offsetManager.getLatestEmittedOffset();\n            long latestCompletedOffset = offsetManager.getCommittedOffset();\n            long spoutLag = latestTimeOffset - latestCompletedOffset;\n            long recordsInPartition =  latestTimeOffset - earliestTimeOffset;\n\n            String metricPath = topicPartition.topic()  + \"/partition_\" + topicPartition.partition();\n            result.put(metricPath + \"/\" + \"spoutLag\", spoutLag);\n            result.put(metricPath + \"/\" + \"earliestTimeOffset\", earliestTimeOffset);\n            result.put(metricPath + \"/\" + \"latestTimeOffset\", latestTimeOffset);\n            result.put(metricPath + \"/\" + \"latestEmittedOffset\", latestEmittedOffset);\n            result.put(metricPath + \"/\" + \"latestCompletedOffset\", latestCompletedOffset);\n            result.put(metricPath + \"/\" + \"recordsInPartition\", recordsInPartition);\n\n            TopicMetrics topicMetrics = topicMetricsMap.get(topicPartition.topic());\n            if (topicMetrics == null) {\n                topicMetrics = new TopicMetrics();\n                topicMetricsMap.put(topicPartition.topic(), topicMetrics);\n            }\n\n            topicMetrics.totalSpoutLag += spoutLag;\n            topicMetrics.totalEarliestTimeOffset += earliestTimeOffset;\n            topicMetrics.totalLatestTimeOffset += latestTimeOffset;\n            topicMetrics.totalLatestEmittedOffset += latestEmittedOffset;\n            topicMetrics.totalLatestCompletedOffset += latestCompletedOffset;\n            topicMetrics.totalRecordsInPartitions += recordsInPartition;\n        }\n\n        for (Map.Entry<String, TopicMetrics> e : topicMetricsMap.entrySet()) {\n            String topic = e.getKey();\n            TopicMetrics topicMetrics = e.getValue();\n            result.put(topic + \"/\" + \"totalSpoutLag\", topicMetrics.totalSpoutLag);\n            result.put(topic + \"/\" + \"totalEarliestTimeOffset\", topicMetrics.totalEarliestTimeOffset);\n            result.put(topic + \"/\" + \"totalLatestTimeOffset\", topicMetrics.totalLatestTimeOffset);\n            result.put(topic + \"/\" + \"totalLatestEmittedOffset\", topicMetrics.totalLatestEmittedOffset);\n            result.put(topic + \"/\" + \"totalLatestCompletedOffset\", topicMetrics.totalLatestCompletedOffset);\n            result.put(topic + \"/\" + \"totalRecordsInPartitions\", topicMetrics.totalRecordsInPartitions);\n        }\n\n        LOG.debug(\"Metrics Tick: value : {}\", result);\n        return result;\n    }"
        },
        "bug_report": {
            "Title": "Deactivated topology restarts if data flows into Kafka",
            "Description": "Hi, I have deactivated the storm topology & then if I produce any records into Kafka, Storm throws an exception. Exception follows,\r\n{code:java}\r\n2018-03-28 09:50:23.804 o.a.s.d.executor Thread-83-kafkaLogs-executor[130 130] [INFO] Deactivating spout kafkaLogs:(130)\r\n2018-03-28 09:51:01.289 o.a.s.util Thread-17-kafkaLogs-executor[139 139] [ERROR] Async loop died!\r\njava.lang.RuntimeException: java.lang.IllegalStateException: This consumer has already been closed.\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatch(DisruptorQueue.java:477) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.disruptor$consume_batch.invoke(disruptor.clj:70) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.daemon.executor$fn__4975$fn__4990$fn__5021.invoke(executor.clj:634) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) [storm-core-1.2.1.jar:1.2.1]\r\nat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\r\nat java.lang.Thread.run(Thread.java:745) [?:1.8.0_45]\r\nCaused by: java.lang.IllegalStateException: This consumer has already been closed.\r\nat org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:1787) ~[stormjar.jar:?]\r\nat org.apache.kafka.clients.consumer.KafkaConsumer.beginningOffsets(KafkaConsumer.java:1622) ~[stormjar.jar:?]\r\nat org.apache.storm.kafka.spout.metrics.KafkaOffsetMetric.getValueAndReset(KafkaOffsetMetric.java:79) ~[stormjar.jar:?]\r\nat org.apache.storm.daemon.executor$metrics_tick$fn__4899.invoke(executor.clj:345) ~[storm-core-1.2.1.jar:1.2.1]\r\nat clojure.core$map$fn__4553.invoke(core.clj:2622) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.RT.seq(RT.java:507) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$seq__4128.invoke(core.clj:137) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$filter$fn__4580.invoke(core.clj:2679) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.Cons.next(Cons.java:39) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.RT.next(RT.java:674) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$next__4112.invoke(core.clj:64) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6523.invoke(protocols.clj:170) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6478$G__6473__6487.invoke(protocols.clj:19) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$seq_reduce.invoke(protocols.clj:31) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6506.invoke(protocols.clj:101) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6452$G__6447__6465.invoke(protocols.clj:13) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$reduce.invoke(core.clj:6519) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$into.invoke(core.clj:6600) ~[clojure-1.7.0.jar:?]\r\nat org.apache.storm.daemon.executor$metrics_tick.invoke(executor.clj:349) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.daemon.executor$fn__4975$tuple_action_fn__4981.invoke(executor.clj:522) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.daemon.executor$mk_task_receiver$fn__4964.invoke(executor.clj:471) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.disruptor$clojure_handler$reify__4475.onEvent(disruptor.clj:41) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.1.jar:1.2.1]\r\n... 7 more\r\n{code}"
        }
    },
    {
        "filename": "STORM-3117.json",
        "creation_time": "2018-06-20T21:37:56.000+0000",
        "stack_trace": "```\norg.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormjar.jar\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta(LocalFsBlobStore.java:286) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:4011) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:3990) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n\njava.lang.RuntimeException: KeyNotFoundException(msg:wc-topology-test-1-1529509694-stormcode.ser)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2822) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormcode.ser\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:420) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1517) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.getClusterInfoImpl(Nimbus.java:2675) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.sendClusterMetricsToExecutors(Nimbus.java:2686) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2819) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:468) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:488) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) [storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.Error: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:603) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:582) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.utils.Utils$5.uncaughtException(Utils.java:931) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1057) [?:1.8.0_131]\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1052) [?:1.8.0_131]\n        at java.lang.Thread.dispatchUncaughtException(Thread.java:1959) [?:1.8.0_131]\nCaused by: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\n        at org.apache.storm.zookeeper.AclEnforcement.getTopoAcl(AclEnforcement.java:194) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithTopoChildren(AclEnforcement.java:250) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithReadOnlyTopoChildren(AclEnforcement.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.AclEnforcement.verifyAcls(AclEnforcement.java:136) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1155) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1162) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n```",
        "source_code": {
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta": "    private SettableBlobMeta getStoredBlobMeta(String key) throws KeyNotFoundException {\n        InputStream in = null;\n        try {\n            LocalFsBlobStoreFile pf = fbs.read(META_PREFIX + key);\n            try {\n                in = pf.getInputStream();\n            } catch (FileNotFoundException fnf) {\n                throw new WrappedKeyNotFoundException(key);\n            }\n            ByteArrayOutputStream out = new ByteArrayOutputStream();\n            byte[] buffer = new byte[2048];\n            int len;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n            in.close();\n            in = null;\n            return Utils.thriftDeserialize(SettableBlobMeta.class, out.toByteArray());\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        } finally {\n            if (in != null) {\n                try {\n                    in.close();\n                } catch (IOException e) {\n                    //Ignored\n                }\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta": "    public ReadableBlobMeta getBlobMeta(String key, Subject who) throws AuthorizationException, KeyNotFoundException {\n        validateKey(key);\n        if (!checkForBlobOrDownload(key)) {\n            checkForBlobUpdate(key);\n        }\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.validateUserCanReadMeta(meta.get_acl(), who, key);\n        ReadableBlobMeta rbm = new ReadableBlobMeta();\n        rbm.set_settable(meta);\n        try {\n            LocalFsBlobStoreFile pf = fbs.read(DATA_PREFIX + key);\n            rbm.set_version(pf.getModTime());\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n        return rbm;\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobUpdate": "    public synchronized void checkForBlobUpdate(String key) {\n        BlobStoreUtils.updateKeyForBlobStore(conf, this, zkClient, key, nimbusInfo);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobOrDownload": "    public synchronized boolean checkForBlobOrDownload(String key) throws KeyNotFoundException {\n        boolean checkBlobDownload = false;\n        try {\n            List<String> keyList = BlobStoreUtils.getKeyListFromBlobStore(this);\n            if (!keyList.contains(key)) {\n                if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) != null) {\n                    Set<NimbusInfo> nimbusSet = BlobStoreUtils.getNimbodesWithLatestSequenceNumberOfBlob(zkClient, key);\n                    nimbusSet.remove(this.nimbusInfo);\n                    if (BlobStoreUtils.downloadMissingBlob(conf, this, key, nimbusSet)) {\n                        LOG.debug(\"Updating blobs state\");\n                        BlobStoreUtils.createStateInZookeeper(conf, key, nimbusInfo);\n                        checkBlobDownload = true;\n                    }\n                }\n            }\n        } catch (KeyNotFoundException e) {\n            throw e;\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n        return checkBlobDownload;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_getBlobMeta": "    public void send_getBlobMeta(java.lang.String key) throws org.apache.storm.thrift.TException\n    {\n      getBlobMeta_args args = new getBlobMeta_args();\n      args.set_key(key);\n      sendBase(\"getBlobMeta\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public isRemoteBlobExists_result getResult(I iface, isRemoteBlobExists_args args) throws org.apache.storm.thrift.TException {\n        isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n        try {\n          result.success = iface.isRemoteBlobExists(args.blobKey);\n          result.set_success_isSet(true);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.storm.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(java.lang.String location, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public java.lang.String recv_beginFileDownload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(java.lang.String name, KillOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public java.lang.String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.storm.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(java.lang.String user, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(java.lang.String key, int replication, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(java.lang.String name, LogConfig config, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getOwnerResourceSummaries": "    public java.util.List<OwnerResourceSummary> recv_getOwnerResourceSummaries() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n      receiveBase(result, \"getOwnerResourceSummaries\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorAssignments": "    public void getSupervisorAssignments(java.lang.String node, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorAssignments_call method_call = new getSupervisorAssignments_call(node, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public java.lang.String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public java.nio.ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeat": "    public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeat_call method_call = new sendSupervisorWorkerHeartbeat_call(heatbeat, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeats": "    public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeats_call method_call = new sendSupervisorWorkerHeartbeats_call(heartbeats, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.storm.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(java.lang.String file, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.processWorkerMetrics": "    public void processWorkerMetrics(WorkerMetrics metrics, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      processWorkerMetrics_call method_call = new processWorkerMetrics_call(metrics, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isRemoteBlobExists": "    public boolean recv_isRemoteBlobExists() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n      receiveBase(result, \"isRemoteBlobExists\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isRemoteBlobExists failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public java.nio.ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public java.lang.String recv_getNimbusConf() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(java.lang.String name, Credentials creds, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isRemoteBlobExists": "    public void isRemoteBlobExists(java.lang.String blobKey, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isRemoteBlobExists_call method_call = new isRemoteBlobExists_call(blobKey, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getOwnerResourceSummaries": "    public void getOwnerResourceSummaries(java.lang.String owner, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorAssignments": "    public SupervisorAssignments recv_getSupervisorAssignments() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n      receiveBase(result, \"getSupervisorAssignments\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorAssignments failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(java.lang.String name, RebalanceOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public java.lang.String recv_beginFileUpload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public java.util.List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.storm.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public java.lang.String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.sasl.SaslTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context\n            ReqContext reqContext = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            //Sasl transport\n            TSaslServerTransport saslTrans = (TSaslServerTransport) trans;\n\n            if (trans instanceof NoOpTTrasport) {\n                return false;\n            }\n\n            //remote address\n            TSocket tsocket = (TSocket) saslTrans.getUnderlyingTransport();\n            Socket socket = tsocket.getSocket();\n            reqContext.setRemoteAddress(socket.getInetAddress());\n\n            //remote subject\n            SaslServer saslServer = saslTrans.getSaslServer();\n            String authId = saslServer.getAuthorizationID();\n            Subject remoteUser = new Subject();\n            remoteUser.getPrincipals().add(new User(authId));\n            reqContext.setSubject(remoteUser);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "        public void run() {\n            while (this.active.get()) {\n                QueueEntry queueEntry = null;\n                try {\n                    queueEntry = this.queue.peek();\n                    if ((queueEntry != null) && (Time.currentTimeMillis() >= queueEntry.endTimeMs)) {\n                        // It is imperative to not run the function\n                        // inside the timer lock. Otherwise, it is\n                        // possible to deadlock if the fn deals with\n                        // other locks, like the submit lock.\n                        this.queue.remove(queueEntry);\n                        queueEntry.func.run();\n                    } else if (queueEntry != null) {\n                        //  If any events are scheduled, sleep until\n                        // event generation. If any recurring events\n                        // are scheduled then we will always go\n                        // through this branch, sleeping only the\n                        // exact necessary amount of time. We give\n                        // an upper bound, e.g. 1000 millis, to the\n                        // sleeping time, to limit the response time\n                        // for detecting any new event within 1 secs.\n                        Time.sleep(Math.min(1000, (queueEntry.endTimeMs - Time.currentTimeMillis())));\n                    } else {\n                        // Otherwise poll to see if any new event\n                        // was scheduled. This is, in essence, the\n                        // response time for detecting any new event\n                        // schedulings when there are no scheduled\n                        // events.\n                        Time.sleep(1000);\n                    }\n                    if (Thread.interrupted()) {\n                        this.active.set(false);\n                    }\n                } catch (Throwable e) {\n                    if (!(Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e))\n                        && !(Utils.exceptionCauseIsInstanceOf(ClosedByInterruptException.class, e))) {\n                        // need to set active false before calling onKill() - current implementation does not return.\n                        this.setActive(false);\n                        this.onKill.uncaughtException(this, e);\n                    }\n                }\n            }\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication": "    public int getBlobReplication(String key, Subject who) throws Exception {\n        int replicationCount = 0;\n        validateKey(key);\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.hasPermissions(meta.get_acl(), READ, who, key);\n        if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) == null) {\n            return 0;\n        }\n        try {\n            replicationCount = zkClient.getChildren().forPath(BLOBSTORE_SUBTREE + key).size();\n        } catch (KeeperException.NoNodeException e) {\n            //Race with delete\n            //If it is not here the replication is 0 \n        }\n        return replicationCount;\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess(int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.handleUncaughtException": "    public static void handleUncaughtException(Throwable t, Set<Class> allowedExceptions) {\n        if (t != null) {\n            if (t instanceof OutOfMemoryError) {\n                try {\n                    System.err.println(\"Halting due to Out Of Memory Error...\" + Thread.currentThread().getName());\n                } catch (Throwable err) {\n                    //Again we don't want to exit because of logging issues.\n                }\n                Runtime.getRuntime().halt(-1);\n            }\n        }\n\n        if (allowedExceptions.contains(t.getClass())) {\n            LOG.info(\"Swallowing {} {}\", t.getClass(), t);\n            return;\n        }\n\n        //Running in daemon mode, we would pass Error to calling thread.\n        throw new Error(t);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.uncaughtException": "            public void uncaughtException(Thread thread, Throwable thrown) {\n                try {\n                    handleUncaughtException(thrown);\n                } catch (Error err) {\n                    LOG.error(\"Received error in main thread.. terminating server...\", err);\n                    Runtime.getRuntime().exit(-2);\n                }\n            }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.getTopoAcl": "    private static List<ACL> getTopoAcl(String path, String topoId, Map<String, Id> topoToZkCreds, ACL superAcl, boolean fixUp, int perms) {\n        Id id = topoToZkCreds.get(topoId);\n        if (id == null) {\n            String error = \"Could not find credentials for topology \" + topoId + \" at path \" + path + \".\";\n            if (fixUp) {\n                error += \" Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\";\n            }\n            throw new IllegalStateException(error);\n        }\n        List<ACL> ret = new ArrayList<>(2);\n        ret.add(superAcl);\n        ret.add(new ACL(perms, id));\n        return ret;\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.verifyParentWithTopoChildren": "    private static void verifyParentWithTopoChildren(CuratorFramework zk, ACL superUserAcl, String path,\n                                                     Map<String, Id> topoToZkCreds, boolean fixUp, int perms) throws Exception {\n        if (zk.checkExists().forPath(path) != null) {\n            verifyAclStrict(zk, Arrays.asList(superUserAcl), path, fixUp);\n            for (String topoId : zk.getChildren().forPath(path)) {\n                String childPath = path + ClusterUtils.ZK_SEPERATOR + topoId;\n                List<ACL> rwAcl = getTopoAcl(path, topoId, topoToZkCreds, superUserAcl, fixUp, perms);\n                verifyAclStrictRecursive(zk, rwAcl, childPath, fixUp);\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.verifyAclStrictRecursive": "    private static void verifyAclStrictRecursive(CuratorFramework zk, List<ACL> strictAcl, String path, boolean fixUp) throws Exception {\n        verifyAclStrict(zk, strictAcl, path, fixUp);\n        for (String child : zk.getChildren().forPath(path)) {\n            String newPath = path + ClusterUtils.ZK_SEPERATOR + child;\n            verifyAclStrictRecursive(zk, strictAcl, newPath, fixUp);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.verifyAclStrict": "    private static void verifyAclStrict(CuratorFramework zk, List<ACL> strictAcl, String path, boolean fixUp) throws Exception {\n        try {\n            List<ACL> foundAcl = zk.getACL().forPath(path);\n            if (!equivalent(foundAcl, strictAcl)) {\n                if (fixUp) {\n                    LOG.warn(\"{} expected to have ACL {}, but has {}.  Fixing...\", path, strictAcl, foundAcl);\n                    zk.setACL().withACL(strictAcl).forPath(path);\n                } else {\n                    throw new IllegalStateException(path + \" did not have the correct ACL found \" + foundAcl + \" expected \" + strictAcl);\n                }\n            }\n        } catch (KeeperException.NoNodeException ne) {\n            LOG.debug(\"{} removed in the middle of checking it\", ne);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.verifyParentWithReadOnlyTopoChildren": "    private static void verifyParentWithReadOnlyTopoChildren(CuratorFramework zk, ACL superUserAcl, String path,\n                                                             Map<String, Id> topoToZkCreds, boolean fixUp) throws Exception {\n        verifyParentWithTopoChildren(zk, superUserAcl, path, topoToZkCreds, fixUp, ZooDefs.Perms.READ);\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.verifyAcls": "    public static void verifyAcls(Map<String, Object> conf, final boolean fixUp) throws Exception {\n        if (!Utils.isZkAuthenticationConfiguredStormServer(conf)) {\n            LOG.info(\"SECURITY IS DISABLED NO FURTHER CHECKS...\");\n            //There is no security so we are done.\n            return;\n        }\n        ACL superUserAcl = Utils.getSuperUserAcl(conf);\n        List<ACL> superAcl = new ArrayList<>(1);\n        superAcl.add(superUserAcl);\n\n        List<ACL> drpcFullAcl = new ArrayList<>(2);\n        drpcFullAcl.add(superUserAcl);\n\n        String drpcAclString = (String) conf.get(Config.STORM_ZOOKEEPER_DRPC_ACL);\n        if (drpcAclString != null) {\n            Id drpcAclId = Utils.parseZkId(drpcAclString, Config.STORM_ZOOKEEPER_DRPC_ACL);\n            ACL drpcUserAcl = new ACL(ZooDefs.Perms.READ, drpcAclId);\n            drpcFullAcl.add(drpcUserAcl);\n        }\n\n        List<String> zkServers = (List<String>) conf.get(Config.STORM_ZOOKEEPER_SERVERS);\n        int port = ObjectReader.getInt(conf.get(Config.STORM_ZOOKEEPER_PORT));\n        String stormRoot = (String) conf.get(Config.STORM_ZOOKEEPER_ROOT);\n\n        try (CuratorFramework zk = ClientZookeeper.mkClient(conf, zkServers, port, \"\",\n                                                            new DefaultWatcherCallBack(), conf, DaemonType.NIMBUS)) {\n            if (zk.checkExists().forPath(stormRoot) != null) {\n                //First off we want to verify that ROOT is good\n                verifyAclStrict(zk, superAcl, stormRoot, fixUp);\n            } else {\n                LOG.warn(\"{} does not exist no need to check any more...\", stormRoot);\n                return;\n            }\n        }\n\n        // Now that the root is fine we can start to look at the other paths under it.\n        try (CuratorFramework zk = ClientZookeeper.mkClient(conf, zkServers, port, stormRoot,\n                                                            new DefaultWatcherCallBack(), conf, DaemonType.NIMBUS)) {\n            //Next verify that the blob store is correct before we start it up.\n            if (zk.checkExists().forPath(ClusterUtils.BLOBSTORE_SUBTREE) != null) {\n                verifyAclStrictRecursive(zk, superAcl, ClusterUtils.BLOBSTORE_SUBTREE, fixUp);\n            }\n\n            if (zk.checkExists().forPath(ClusterUtils.BLOBSTORE_MAX_KEY_SEQUENCE_NUMBER_SUBTREE) != null) {\n                verifyAclStrict(zk, superAcl, ClusterUtils.BLOBSTORE_MAX_KEY_SEQUENCE_NUMBER_SUBTREE, fixUp);\n            }\n\n            //The blobstore is good, now lets get the list of all topo Ids\n            Set<String> topoIds = new HashSet<>();\n            if (zk.checkExists().forPath(ClusterUtils.STORMS_SUBTREE) != null) {\n                topoIds.addAll(zk.getChildren().forPath(ClusterUtils.STORMS_SUBTREE));\n            }\n\n            Map<String, Id> topoToZkCreds = new HashMap<>();\n            //Now lets get the creds for the topos so we can verify those as well.\n            BlobStore bs = ServerUtils.getNimbusBlobStore(conf, NimbusInfo.fromConf(conf), null);\n            try {\n                Subject nimbusSubject = new Subject();\n                nimbusSubject.getPrincipals().add(new NimbusPrincipal());\n                for (String topoId : topoIds) {\n                    try {\n                        String blobKey = topoId + \"-stormconf.ser\";\n                        Map<String, Object> topoConf = Utils.fromCompressedJsonConf(bs.readBlob(blobKey, nimbusSubject));\n                        String payload = (String) topoConf.get(Config.STORM_ZOOKEEPER_TOPOLOGY_AUTH_PAYLOAD);\n                        try {\n                            topoToZkCreds.put(topoId, new Id(\"digest\", DigestAuthenticationProvider.generateDigest(payload)));\n                        } catch (NoSuchAlgorithmException e) {\n                            throw new RuntimeException(e);\n                        }\n                    } catch (KeyNotFoundException knf) {\n                        LOG.debug(\"topo removed {}\", topoId, knf);\n                    }\n                }\n            } finally {\n                if (bs != null) {\n                    bs.shutdown();\n                }\n            }\n\n            verifyParentWithReadOnlyTopoChildren(zk, superUserAcl, ClusterUtils.STORMS_SUBTREE, topoToZkCreds, fixUp);\n            verifyParentWithReadOnlyTopoChildren(zk, superUserAcl, ClusterUtils.ASSIGNMENTS_SUBTREE, topoToZkCreds, fixUp);\n            //There is a race on credentials where they can be leaked in some versions of storm.\n            verifyParentWithReadOnlyTopoChildrenDeleteDead(zk, superUserAcl, ClusterUtils.CREDENTIALS_SUBTREE, topoToZkCreds, fixUp);\n            //There is a race on logconfig where they can be leaked in some versions of storm.\n            verifyParentWithReadOnlyTopoChildrenDeleteDead(zk, superUserAcl, ClusterUtils.LOGCONFIG_SUBTREE, topoToZkCreds, fixUp);\n            //There is a race on backpressure too...\n            verifyParentWithReadWriteTopoChildrenDeleteDead(zk, superUserAcl, ClusterUtils.BACKPRESSURE_SUBTREE, topoToZkCreds, fixUp);\n\n            if (zk.checkExists().forPath(ClusterUtils.ERRORS_SUBTREE) != null) {\n                //errors is a bit special because in older versions of storm the worker created the parent directories lazily\n                // because of this it means we need to auto create at least the topo-id directory for all running topos.\n                for (String topoId : topoToZkCreds.keySet()) {\n                    String path = ClusterUtils.errorStormRoot(topoId);\n                    if (zk.checkExists().forPath(path) == null) {\n                        LOG.warn(\"Creating missing errors location {}\", path);\n                        zk.create().withACL(getTopoReadWrite(path, topoId, topoToZkCreds, superUserAcl, fixUp)).forPath(path);\n                    }\n                }\n            }\n            //Error should not be leaked according to the code, but they are not important enough to fail the build if\n            // for some odd reason they are leaked.\n            verifyParentWithReadWriteTopoChildrenDeleteDead(zk, superUserAcl, ClusterUtils.ERRORS_SUBTREE, topoToZkCreds, fixUp);\n\n            if (zk.checkExists().forPath(ClusterUtils.SECRET_KEYS_SUBTREE) != null) {\n                verifyAclStrict(zk, superAcl, ClusterUtils.SECRET_KEYS_SUBTREE, fixUp);\n                verifyAclStrictRecursive(zk, superAcl, ClusterUtils.secretKeysPath(WorkerTokenServiceType.NIMBUS), fixUp);\n                verifyAclStrictRecursive(zk, drpcFullAcl, ClusterUtils.secretKeysPath(WorkerTokenServiceType.DRPC), fixUp);\n            }\n\n            if (zk.checkExists().forPath(ClusterUtils.NIMBUSES_SUBTREE) != null) {\n                verifyAclStrictRecursive(zk, superAcl, ClusterUtils.NIMBUSES_SUBTREE, fixUp);\n            }\n\n            if (zk.checkExists().forPath(\"/leader-lock\") != null) {\n                verifyAclStrictRecursive(zk, superAcl, \"/leader-lock\", fixUp);\n            }\n\n            if (zk.checkExists().forPath(ClusterUtils.PROFILERCONFIG_SUBTREE) != null) {\n                verifyAclStrictRecursive(zk, superAcl, ClusterUtils.PROFILERCONFIG_SUBTREE, fixUp);\n            }\n\n            if (zk.checkExists().forPath(ClusterUtils.SUPERVISORS_SUBTREE) != null) {\n                verifyAclStrictRecursive(zk, superAcl, ClusterUtils.SUPERVISORS_SUBTREE, fixUp);\n            }\n\n            // When moving to pacemaker workerbeats can be leaked too...\n            verifyParentWithReadWriteTopoChildrenDeleteDead(zk, superUserAcl, ClusterUtils.WORKERBEATS_SUBTREE, topoToZkCreds, fixUp);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.getTopoReadWrite": "    private static List<ACL> getTopoReadWrite(String path, String topoId, Map<String, Id> topoToZkCreds, ACL superAcl, boolean fixUp) {\n        return getTopoAcl(path, topoId, topoToZkCreds, superAcl, fixUp, ZooDefs.Perms.ALL);\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.verifyParentWithReadWriteTopoChildrenDeleteDead": "    private static void verifyParentWithReadWriteTopoChildrenDeleteDead(CuratorFramework zk, ACL superUserAcl, String path,\n                                                                        Map<String, Id> topoToZkCreds, boolean fixUp) throws Exception {\n        verifyParentWithTopoChildrenDeleteDead(zk, superUserAcl, path, topoToZkCreds, fixUp, ZooDefs.Perms.ALL);\n    }",
            "storm-server.src.main.java.org.apache.storm.zookeeper.AclEnforcement.verifyParentWithReadOnlyTopoChildrenDeleteDead": "    private static void verifyParentWithReadOnlyTopoChildrenDeleteDead(CuratorFramework zk, ACL superUserAcl, String path,\n                                                                       Map<String, Id> topoToZkCreds, boolean fixUp) throws Exception {\n        verifyParentWithTopoChildrenDeleteDead(zk, superUserAcl, path, topoToZkCreds, fixUp, ZooDefs.Perms.READ);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStoreFile.getInputStream": "    public InputStream getInputStream() throws IOException {\n        if (isTmp()) {\n            throw new IllegalStateException(\"Cannot read from a temporary part file.\");\n        }\n        return new FileInputStream(_path);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStoreFile.isTmp": "    public boolean isTmp() {\n        return _isTmp;\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStoreFile.getModTime": "    public long getModTime() throws IOException {\n        if (_modTime == null) {\n            _modTime = _path.lastModified();\n        }\n        return _modTime;\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.mkClient": "    public static CuratorFramework mkClient(Map<String, Object> conf, List<String> servers, Object port,\n                                            String root, final WatcherCallBack watcher, Map<String, Object> authConf, DaemonType type) {\n        return _instance.mkClientImpl(conf, servers, port, root, watcher, authConf, type);\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.mkClientImpl": "    public CuratorFramework mkClientImpl(Map<String, Object> conf, List<String> servers, Object port, String root,\n                                         final WatcherCallBack watcher, Map<String, Object> authConf, DaemonType type) {\n        CuratorFramework fk;\n        if (authConf != null) {\n            fk = CuratorUtils.newCurator(conf, servers, port, root, new ZookeeperAuthInfo(authConf), type.getDefaultZkAcls(conf));\n        } else {\n            fk = CuratorUtils.newCurator(conf, servers, port, root, null, type.getDefaultZkAcls(conf));\n        }\n\n        fk.getCuratorListenable().addListener((unused, e) -> {\n            if (e.getType().equals(CuratorEventType.WATCHED)) {\n                WatchedEvent event = e.getWatchedEvent();\n                watcher.execute(event.getState(), event.getType(), event.getPath());\n            }\n        });\n        LOG.info(\"Staring ZK Curator\");\n        fk.start();\n        return fk;\n    }"
        },
        "bug_report": {
            "Title": "Deleting blobs for running topologies hoses Nimbus",
            "Description": "The following test pseudo-code causes issues:\r\n{code:java}\r\ncluster.submitTopology(cluster.getTopologiesJarFile(), topoName, config, topology);\r\ncluster.waitTopologyUp(topoName);\r\ncluster.deleteAllBlobs();\r\n{code}\r\nThis causes nimbus to get stuck and restart:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-06-20 15:48:14.273 o.a.s.d.n.Nimbus pool-27-thread-694 [INFO] Received topology submission for wc-topology-test (storm-0.10.2.y.251 JDK-1.8.0_131) \r\n2018-06-20 15:48:14.629 o.a.s.d.n.Nimbus pool-27-thread-694 [INFO] Activating wc-topology-test: wc-topology-test-1-1529509694\r\n2018-06-20 15:48:14.724 o.a.s.d.n.Nimbus pool-27-thread-703 [INFO] TRANSITION: wc-topology-test-1-1529509694 KILL null true\r\n2018-06-20 15:48:14.812 o.a.s.d.n.Nimbus pool-27-thread-704 [INFO] Deleted blob for key wc-topology-test-1-1529509694-stormconf.ser\r\n2018-06-20 15:48:14.830 o.a.s.d.n.Nimbus pool-27-thread-704 [INFO] Deleted blob for key wc-topology-test-1-1529509694-stormcode.ser\r\n2018-06-20 15:48:14.863 o.a.s.d.n.Nimbus pool-27-thread-704 [INFO] Deleted blob for key wc-topology-test-1-1529509694-stormjar.jar\r\n2018-06-20 15:48:18.449 o.a.s.s.r.s.p.DefaultSchedulingPriorityStrategy timer [INFO] SIM Scheduling wc-topology-test-1-1529509694 with score of 0.3125\r\n2018-06-20 15:48:18.492 o.a.s.s.Cluster timer [INFO] STATUS - wc-topology-test-1-1529509694 Running - Fully Scheduled by DefaultResourceAwareStrategy\r\n2018-06-20 15:48:18.527 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id wc-topology-test-1-1529509694:\r\n\r\n2018-06-20 15:48:18.979 o.a.s.d.n.Nimbus pool-27-thread-722 [WARN] get blob meta exception.\r\norg.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormjar.jar\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta(LocalFsBlobStore.java:286) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:4011) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:3990) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n\r\n2018-06-20 15:48:22.884 o.a.s.d.n.Nimbus timer [INFO] Renewing Creds For wc-topology-test-1-1529509694 with org.apache.storm.security.auth.kerberos.AutoTGT@4482469c owned by hadoopqa@DEV.YGRID.YAHOO.COM\r\n\r\n\r\n2018-06-20 15:48:37.947 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event\r\njava.lang.RuntimeException: KeyNotFoundException(msg:wc-topology-test-1-1529509694-stormcode.ser)\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2822) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormcode.ser\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:420) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1517) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getClusterInfoImpl(Nimbus.java:2675) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.sendClusterMetricsToExecutors(Nimbus.java:2686) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2819) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-06-20 15:48:37.948 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:468) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:488) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-06-20 15:48:37.950 o.a.s.d.n.Nimbus Thread-11 [INFO] Shutting down master\r\n2018-06-20 15:48:37.950 o.a.s.u.Utils Thread-12 [INFO] Halting after 10 seconds\r\n\r\n2018-06-20 15:48:46.672 o.a.s.d.n.Nimbus pool-27-thread-798 [WARN] get blob meta exception.\r\norg.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormconf.ser\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta(LocalFsBlobStore.java:286) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:4011) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:3990) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n2018-06-20 15:48:47.950 o.a.s.u.Utils Thread-12 [WARN] Forcing Halt...\r\n\r\n{code}\r\nNimbus then continually restarts:\r\n{code:java}\r\n2018-06-20 15:48:54.635 o.a.s.u.Utils main [ERROR] Received error in main thread.. terminating server...\r\njava.lang.Error: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\r\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:603) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:582) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.utils.Utils$5.uncaughtException(Utils.java:931) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1057) [?:1.8.0_131]\r\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1052) [?:1.8.0_131]\r\n        at java.lang.Thread.dispatchUncaughtException(Thread.java:1959) [?:1.8.0_131]\r\nCaused by: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\r\n        at org.apache.storm.zookeeper.AclEnforcement.getTopoAcl(AclEnforcement.java:194) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithTopoChildren(AclEnforcement.java:250) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithReadOnlyTopoChildren(AclEnforcement.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.AclEnforcement.verifyAcls(AclEnforcement.java:136) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1155) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1162) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n{code}"
        }
    },
    {
        "filename": "STORM-2993.json",
        "creation_time": "2018-03-12T19:04:16.000+0000",
        "stack_trace": "```\njava.nio.channels.ClosedChannelException: null\n    at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73) ~[stormjar.jar:?]\n    at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153) ~[stormjar.jar:?]\n    at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105) ~[stormjar.jar:?]\n    at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57) ~[stormjar.jar:?]\n    at java.io.DataOutputStream.write(DataOutputStream.java:107) ~[?:1.8.0_161]\n    at java.io.FilterOutputStream.write(FilterOutputStream.java:97) ~[?:1.8.0_161]\n    at org.apache.storm.hdfs.common.HDFSWriter.doWrite(HDFSWriter.java:48) ~[stormjar.jar:?]\n    at org.apache.storm.hdfs.common.AbstractHDFSWriter.write(AbstractHDFSWriter.java:40) ~[stormjar.jar:?]\n    at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:158) [stormjar.jar:?]\n    at org.apache.storm.daemon.executor$fn__10189$tuple_action_fn__10191.invoke(executor.clj:745) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.daemon.executor$mk_task_receiver$fn__10108.invoke(executor.clj:473) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.disruptor$clojure_handler$reify__4115.onEvent(disruptor.clj:41) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.daemon.executor$fn__10189$fn__10202$fn__10257.invoke(executor.clj:868) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.util$async_loop$fn__1221.invoke(util.clj:484) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\n    at java.lang.Thread.run(Thread.java:748) [?:1.8.0_161]\n```",
        "source_code": {
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.common.HDFSWriter.doWrite": "    protected void doWrite(Tuple tuple) throws IOException {\n        byte[] bytes = this.format.format(tuple);\n        out.write(bytes);\n        this.offset += bytes.length;\n    }",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.common.AbstractHDFSWriter.write": "    final public long write(Tuple tuple) throws IOException {\n        doWrite(tuple);\n        this.needsRotation = rotationPolicy.mark(tuple, offset);\n\n        return this.offset;\n    }",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.common.AbstractHDFSWriter.doWrite": "    abstract protected void doWrite(Tuple tuple) throws IOException;\n\n    abstract protected void doSync() throws IOException;\n\n    abstract protected void doClose() throws IOException;\n\n}",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute": "    public final void execute(Tuple tuple) {\n\n        synchronized (this.writeLock) {\n            boolean forceSync = false;\n            Writer writer = null;\n            String writerKey = null;\n\n            if (TupleUtils.isTick(tuple)) {\n                LOG.debug(\"TICK! forcing a file system flush\");\n                this.collector.ack(tuple);\n                forceSync = true;\n            } else {\n\n                writerKey = getHashKeyForTuple(tuple);\n\n                try {\n                    writer = getOrCreateWriter(writerKey, tuple);\n                    this.offset = writer.write(tuple);\n                    tupleBatch.add(tuple);\n                } catch (IOException e) {\n                    //If the write failed, try to sync anything already written\n                    LOG.info(\"Tuple failed to write, forcing a flush of existing data.\");\n                    this.collector.reportError(e);\n                    forceSync = true;\n                    this.collector.fail(tuple);\n                }\n            }\n\n            if (this.syncPolicy.mark(tuple, this.offset) || (forceSync && tupleBatch.size() > 0)) {\n                int attempts = 0;\n                boolean success = false;\n                IOException lastException = null;\n                // Make every attempt to sync the data we have.  If it can't be done then kill the bolt with\n                // a runtime exception.  The filesystem is presumably in a very bad state.\n                while (success == false && attempts < fileRetryCount) {\n                    attempts += 1;\n                    try {\n                        syncAllWriters();\n                        LOG.debug(\"Data synced to filesystem. Ack'ing [{}] tuples\", tupleBatch.size());\n                        for (Tuple t : tupleBatch) {\n                            this.collector.ack(t);\n                        }\n                        tupleBatch.clear();\n                        syncPolicy.reset();\n                        success = true;\n                    } catch (IOException e) {\n                        LOG.warn(\"Data could not be synced to filesystem on attempt [{}]\", attempts);\n                        this.collector.reportError(e);\n                        lastException = e;\n                    }\n                }\n\n                // If unsuccesful fail the pending tuples\n                if (success == false) {\n                    LOG.warn(\"Data could not be synced to filesystem, failing this batch of tuples\");\n                    for (Tuple t : tupleBatch) {\n                        this.collector.fail(t);\n                    }\n                    tupleBatch.clear();\n\n                    throw new RuntimeException(\"Sync failed [\" + attempts + \"] times.\", lastException);\n                }\n            }\n\n            if (writer != null && writer.needsRotation()) {\n                doRotationAndRemoveWriter(writerKey, writer);\n            }\n        }\n    }",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.bolt.AbstractHdfsBolt.syncAllWriters": "    private void syncAllWriters() throws IOException {\n        for (Writer writer : writers.values()) {\n            writer.sync();\n        }\n    }",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.bolt.AbstractHdfsBolt.getHashKeyForTuple": "    private String getHashKeyForTuple(Tuple tuple) {\n        final String boltKey = getWriterKey(tuple);\n        final String partitionDir = this.partitioner.getPartitionPath(tuple);\n        return boltKey + \"****\" + partitionDir;\n    }",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.bolt.AbstractHdfsBolt.doRotationAndRemoveWriter": "    void doRotationAndRemoveWriter(String writerKey, Writer writer) {\n        try {\n            rotateOutputFile(writer);\n        } catch (IOException e) {\n            this.collector.reportError(e);\n            LOG.error(\"File could not be rotated\");\n            //At this point there is nothing to do.  In all likelihood any filesystem operations will fail.\n            //The next tuple will almost certainly fail to write and/or sync, which force a rotation.  That\n            //will give rotateAndReset() a chance to work which includes creating a fresh file handle.\n        } finally {\n            //rotateOutputFile(writer) has closed the writer. It's safe to remove the writer from the map here.\n            writers.remove(writerKey);\n        }\n    }",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.bolt.AbstractHdfsBolt.getOrCreateWriter": "    private Writer getOrCreateWriter(String writerKey, Tuple tuple) throws IOException {\n        Writer writer;\n\n        writer = writers.get(writerKey);\n        if (writer == null) {\n            Path pathForNextFile = getBasePathForNextFile(tuple);\n            writer = makeNewWriter(pathForNextFile, tuple);\n            writers.put(writerKey, writer);\n        }\n        return writer;\n    }",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.bolt.Writer.needsRotation": "    boolean needsRotation();\n\n    Path getFilePath();\n}",
            "external.storm-hdfs.src.main.java.org.apache.storm.hdfs.bolt.Writer.write": "    long write(Tuple tuple) throws IOException;\n\n    void sync() throws IOException;\n\n    void close() throws IOException;\n\n    boolean needsRotation();\n\n    Path getFilePath();\n}"
        },
        "bug_report": {
            "Title": "Storm HDFS bolt throws ClosedChannelException when Time rotation policy is used",
            "Description": "Storm connector throws below error in the worker logs.\r\n\r\n\u00a0\r\n\r\n2018-03-12 18:14:58.123 o.a.s.h.c.r.MoveFileAction Timer-3 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-3-0-1520878438104.txt to /tmp/dest2/my-bolt-3-0-15 20878438104.txt 2018-03-12 18:14:58.123 o.a.s.h.c.r.MoveFileAction Timer-0 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-6-0-1520878438104.txt to /tmp/dest2/my-bolt-6-0-15 20878438104.txt 2018-03-12 18:14:58.123 o.a.s.h.c.r.MoveFileAction Timer-1 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-5-0-1520878438104.txt to /tmp/dest2/my-bolt-5-0-15 20878438104.txt 2018-03-12 18:14:58.124 o.a.s.h.c.r.MoveFileAction Timer-2 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-4-0-1520878438104.txt to /tmp/dest2/my-bolt-4-0-15 20878438104.txt 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-2 [INFO] File rotation took 28 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-0 [INFO] File rotation took 29 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-3 [INFO] File rotation took 28 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-1 [INFO] File rotation took 28 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Thread-12-my-bolt-executor[6 6] [INFO] Tuple failed to write, forcing a flush of existing data. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Thread-8-my-bolt-executor[3 3] [INFO] Tuple failed to write, forcing a flush of existing data. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Thread-16-my-bolt-executor[5 5] [INFO] Tuple failed to write, forcing a flush of existing data. 2018-03-12 18:14:58.132 o.a.s.d.executor Thread-8-my-bolt-executor[3 3] [ERROR] java.nio.channels.ClosedChannelException: null at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73) ~[stormjar.jar:?] at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153) ~[stormjar.jar:?] at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105) ~[stormjar.jar:?] at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57) ~[stormjar.jar:?] at java.io.DataOutputStream.write(DataOutputStream.java:107) ~[?:1.8.0_161] at java.io.FilterOutputStream.write(FilterOutputStream.java:97) ~[?:1.8.0_161] at org.apache.storm.hdfs.common.HDFSWriter.doWrite(HDFSWriter.java:48) ~[stormjar.jar:?] at org.apache.storm.hdfs.common.AbstractHDFSWriter.write(AbstractHDFSWriter.java:40) ~[stormjar.jar:?] at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:158) [stormjar.jar:?] at org.apache.storm.daemon.executor$fn__10189$tuple_action_fn__10191.invoke(executor.clj:745) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.daemon.executor$mk_task_receiver$fn__10108.invoke(executor.clj:473) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.disruptor$clojure_handler$reify__4115.onEvent(disruptor.clj:41) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.daemon.executor$fn__10189$fn__10202$fn__10257.invoke(executor.clj:868) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.util$async_loop$fn__1221.invoke(util.clj:484) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_161] 2018-03-12 18:14:58.133 o.a.s.d.executor Thread-16-my-bolt-executor[5 5]\u00a0\r\n\r\n\u00a0\r\n----\r\n\u00a0\r\n\r\nApparently the Timed rotation policy does not synchronize properly so its possible that the HDFS bolt code can\u00a0attempt to write to a closed writer.\r\n\r\n\u00a0"
        }
    },
    {
        "filename": "STORM-1540.json",
        "creation_time": "2016-02-11T22:55:05.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:448) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:414) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_loop_STAR_$fn__7651.invoke(disruptor.clj:83) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.util$async_loop$fn__554.invoke(util.clj:484) [storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_72]\nCaused by: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:?]\n\tat org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.worker$mk_transfer_fn$transfer_fn__8346.invoke(worker.clj:186) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__8037.invoke(executor.clj:309) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$clojure_handler$reify__7634.onEvent(disruptor.clj:40) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:435) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor": "    private void consumeBatchToCursor(long cursor, EventHandler<Object> handler) {\n        for (long curr = _consumer.get() + 1; curr <= cursor; curr++) {\n            try {\n                AtomicReference<Object> mo = _buffer.get(curr);\n                Object o = mo.getAndSet(null);\n                if (o == INTERRUPT) {\n                    throw new InterruptedException(\"Disruptor processing interrupted\");\n                } else if (o == null) {\n                    LOG.error(\"NULL found in {}:{}\", this.getName(), cursor);\n                } else {\n                    handler.onEvent(o, curr, curr == cursor);\n                    if (_enableBackpressure && _cb != null && (_metrics.writePos() - curr + _overflowCount.get()) <= _lowWaterMark) {\n                        try {\n                            if (_throttleOn) {\n                                _throttleOn = false;\n                                _cb.lowWaterMark();\n                            }\n                        } catch (Exception e) {\n                            throw new RuntimeException(\"Exception during calling lowWaterMark callback!\");\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                throw new RuntimeException(e);\n            }\n        }\n        _consumer.set(cursor);\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.getName": "    public String getName() {\n        return _queueName;\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.writePos": "        public long writePos() {\n            return _buffer.getCursor();\n        }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable": "    public void consumeBatchWhenAvailable(EventHandler<Object> handler) {\n        try {\n            final long nextSequence = _consumer.get() + 1;\n            long availableSequence = _barrier.waitFor(nextSequence);\n\n            if (availableSequence >= nextSequence) {\n                consumeBatchToCursor(availableSequence, handler);\n            }\n        } catch (TimeoutException te) {\n            //Ignored\n        } catch (AlertException e) {\n            throw new RuntimeException(e);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.serialization.SerializableSerializer.write": "    public void write(Kryo kryo, Output output, Object object) {\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n        try {\n            ObjectOutputStream oos = new ObjectOutputStream(bos);\n            oos.writeObject(object);\n            oos.flush();\n        } catch(IOException e) {\n            throw new RuntimeException(e);\n        }\n        byte[] ser = bos.toByteArray();\n        output.writeInt(ser.length);\n        output.writeBytes(ser);\n    }",
            "storm-core.src.jvm.org.apache.storm.serialization.KryoValuesSerializer.serializeInto": "    public void serializeInto(List<Object> values, Output out) throws IOException {\n        // this ensures that list of values is always written the same way, regardless\n        // of whether it's a java collection or one of clojure's persistent collections \n        // (which have different serializers)\n        // Doing this lets us deserialize as ArrayList and avoid writing the class here\n        _delegate.setDelegate(values);\n        _kryo.writeObject(out, _delegate); \n    }",
            "storm-core.src.jvm.org.apache.storm.serialization.KryoTupleSerializer.serialize": "    public byte[] serialize(Tuple tuple) {\n        try {\n            \n            _kryoOut.clear();\n            _kryoOut.writeInt(tuple.getSourceTask(), true);\n            _kryoOut.writeInt(_ids.getStreamId(tuple.getSourceComponent(), tuple.getSourceStreamId()), true);\n            tuple.getMessageId().serialize(_kryoOut);\n            _kryo.serializeInto(tuple.getValues(), _kryoOut);\n            return _kryoOut.toBytes();\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }"
        },
        "bug_report": {
            "Title": "Topology Debug/Sampling Breaks Trident Topologies",
            "Description": "Steps to reproduce:\n\n1. Deploy a Trident topology.\n2. Turn on debug/sampling.\n\nWorkers will crash with the following error:\n\n2016-02-11 14:13:23.617 o.a.s.util [ERROR] Async loop died!\njava.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:448) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:414) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_loop_STAR_$fn__7651.invoke(disruptor.clj:83) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.util$async_loop$fn__554.invoke(util.clj:484) [storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_72]\nCaused by: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:?]\n\tat org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.worker$mk_transfer_fn$transfer_fn__8346.invoke(worker.clj:186) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__8037.invoke(executor.clj:309) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$clojure_handler$reify__7634.onEvent(disruptor.clj:40) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:435) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\t... 6 more\n"
        }
    },
    {
        "filename": "STORM-2275.json",
        "creation_time": "2017-01-04T23:21:06.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1174)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:83)\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.transition(Nimbus.java:1215)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1172)\n        ... 1 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1792)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$15(Nimbus.java:1107)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:104)\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.StormTimer.run": "            public void run() {\n                func.run();\n                // This avoids a race condition with cancel-timer.\n                schedule(recurSecs, this, false, jitterMs);\n            }",
            "storm-core.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-core.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess (int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }"
        },
        "bug_report": {
            "Title": "Nimbus crashed during state transition of topology",
            "Description": "I am copying last few lines of the nimbus logs including stack trace.\n{code}\n2017-01-04 22:18:10.106 pool-15-thread-47 o.a.s.d.n.Nimbus [INFO] Activating DemoTest: DemoTest-21-1483568289\n2017-01-04 22:18:11.646 timer o.a.s.s.EvenScheduler [INFO] Available slots: [f0ea57ab-86d6-401f-9429-52f479b1d69f:6704, f0ea57ab-86d6-401f-9429-52f479b1d69f:6705, f0ea57ab-86d6-401f-9429-52f479b1d69f:670\\\n6, f0ea57ab-86d6-401f-9429-52f479b1d69f:6707, f0ea57ab-86d6-401f-9429-52f479b1d69f:6708, f0ea57ab-86d6-401f-9429-52f479b1d69f:6709, f0ea57ab-86d6-401f-9429-52f479b1d69f:6700, f0ea57ab-86d6-401f-9429-52f4\\\n79b1d69f:6701, f0ea57ab-86d6-401f-9429-52f479b1d69f:6702, f0ea57ab-86d6-401f-9429-52f479b1d69f:6703]\n2017-01-04 22:18:11.648 timer o.a.s.d.n.Nimbus [INFO] Setting new assignment for topology id DemoTest-21-1483568289: Assignment(master_code_dir:storm-local, node_host:{f0ea57ab-86d6-401f-9429-52f479b1d69\\\nf=node1}, executor_node_port:{[10, 10]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [14, 14]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [16, 16]=NodeInfo(node:\\\nf0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [12, 12]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [8, 8]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [6,\\\n 6]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [20, 20]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [4, 4]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f,\\\n port:[6700]), [2, 2]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [18, 18]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [11, 11]=NodeInfo(node:f0ea57ab-86d6-401\\\nf-9429-52f479b1d69f, port:[6701]), [15, 15]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [7, 7]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [9, 9]=NodeInfo(node\\\n:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [21, 21]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [5, 5]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [3\\\n, 3]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [19, 19]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [17, 17]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d6\\\n9f, port:[6701]), [1, 1]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [13, 13]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700])}, executor_start_time_secs:{[12, 12]=1\\\n483568291, [6, 6]=1483568291, [18, 18]=1483568291, [2, 2]=1483568291, [8, 8]=1483568291, [14, 14]=1483568291, [16, 16]=1483568291, [20, 20]=1483568291, [4, 4]=1483568291, [10, 10]=1483568291, [9, 9]=1483\\\n568291, [3, 3]=1483568291, [15, 15]=1483568291, [21, 21]=1483568291, [5, 5]=1483568291, [11, 11]=1483568291, [13, 13]=1483568291, [17, 17]=1483568291, [19, 19]=1483568291, [1, 1]=1483568291, [7, 7]=14835\\\n68291}, worker_resources:{NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702])=WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f,\\\n port:[6701])=WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700])=WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0)})\n2017-01-04 22:18:11.660 timer o.a.s.d.n.Nimbus [INFO] Cleaning up DemoTest-20-1483567429\n2017-01-04 22:18:11.668 timer o.a.s.d.n.Nimbus [INFO] Removing dependency jars from blobs - []\n2017-01-04 22:18:12.420 pool-15-thread-51 o.a.s.d.n.Nimbus [INFO] Created download session for DemoTest-21-1483568289-stormjar.jar\n2017-01-04 22:18:12.990 pool-15-thread-38 o.a.s.d.n.Nimbus [INFO] Created download session for DemoTest-21-1483568289-stormcode.ser\n2017-01-04 22:18:12.995 pool-15-thread-59 o.a.s.d.n.Nimbus [INFO] Created download session for DemoTest-21-1483568289-stormconf.ser\n2017-01-04 22:18:20.303 timer o.a.s.d.n.Nimbus [INFO] TRANSITION: DemoTest-20-1483567429 REMOVE null false\n2017-01-04 22:18:20.304 timer o.a.s.d.n.Nimbus [ERROR] Error while processing event\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1174)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:83)\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.transition(Nimbus.java:1215)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1172)\n        ... 1 more\n2017-01-04 22:18:20.304 timer o.a.s.u.Utils [ERROR] Halting process: Error while processing event\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1792)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$15(Nimbus.java:1107)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:104)\n2017-01-04 22:18:20.315 Thread-9 o.a.s.d.n.Nimbus [INFO] Shutting down master\n{code}\n\nThe problem is that we are assuming that the base will be non-null which is incorrect leading to NPE."
        }
    },
    {
        "filename": "STORM-2873.json",
        "creation_time": "2017-12-29T18:44:56.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\n\tat backtype.storm.util$wrap_in_runtime.invoke(util.clj:52) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:110) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat clojure.lang.RestFn.invoke(RestFn.java:464) ~[clojure-1.6.0.jar:?]\n\tat backtype.storm.zookeeper$delete_recursive.invoke(zookeeper.clj:189) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.cluster_state.zookeeper_state_factory$_mkState$reify__4207.delete_node(zookeeper_state_factory.clj:117) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat sun.reflect.GeneratedMethodAccessor860.invoke(Unknown Source) ~[?:?]\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\n\tat org.apache.storm.pacemaker.pacemaker_state_factory$_mkState$reify__4254.delete_node(pacemaker_state_factory.clj:174) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat sun.reflect.GeneratedMethodAccessor859.invoke(Unknown Source) ~[?:?]\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\n\tat backtype.storm.cluster$mk_storm_cluster_state$reify__3873.worker_backpressure_BANG_(cluster.clj:421) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat sun.reflect.GeneratedMethodAccessor857.invoke(Unknown Source) ~[?:?]\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\n\tat backtype.storm.daemon.worker$mk_backpressure_handler$fn__7117.invoke(worker.clj:161) [storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.disruptor$worker_backpressure_handler$reify__6432.onEvent(disruptor.clj:57) [storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.utils.WorkerBackpressureThread.run(WorkerBackpressureThread.java:64) [storm-core-0.10.2.y.jar:0.10.2.y]\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:113) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.utils.WorkerBackpressureThread.run": "    public void run() {\n        while (running) {\n            try {\n                synchronized (trigger) {\n                    trigger.wait(100);\n                }\n                callback.onEvent(workerData); // check all executors and update zk backpressure throttle for the worker if needed\n            } catch (InterruptedException interEx) {\n                // ignored, we are shutting down.\n            }\n        }\n    }"
        },
        "bug_report": {
            "Title": "Backpressure implentation delete ephemeral too frequently",
            "Description": "The backpressure implementation deletes the znode when not relevant but that hits zookeeper issue of too frequent deletion and creation or same path for ephemeral znode. Below is exception we get when zk hits this issue:\r\n\r\n{code}\r\n017-09-18 15:00:34.980 b.s.util WorkerBackpressureThread [WARN] Expecting exception of class: class org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException, but exception chain only contains: (#<NoAuthException org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721>)\r\n2017-09-18 15:00:34.980 b.s.d.worker WorkerBackpressureThread [ERROR] workerBackpressure update failed when connecting to ZK ... will retry\r\njava.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\r\n\tat backtype.storm.util$wrap_in_runtime.invoke(util.clj:52) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:110) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:464) ~[clojure-1.6.0.jar:?]\r\n\tat backtype.storm.zookeeper$delete_recursive.invoke(zookeeper.clj:189) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.cluster_state.zookeeper_state_factory$_mkState$reify__4207.delete_node(zookeeper_state_factory.clj:117) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat sun.reflect.GeneratedMethodAccessor860.invoke(Unknown Source) ~[?:?]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\r\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\r\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\r\n\tat org.apache.storm.pacemaker.pacemaker_state_factory$_mkState$reify__4254.delete_node(pacemaker_state_factory.clj:174) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat sun.reflect.GeneratedMethodAccessor859.invoke(Unknown Source) ~[?:?]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\r\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\r\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\r\n\tat backtype.storm.cluster$mk_storm_cluster_state$reify__3873.worker_backpressure_BANG_(cluster.clj:421) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat sun.reflect.GeneratedMethodAccessor857.invoke(Unknown Source) ~[?:?]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\r\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\r\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\r\n\tat backtype.storm.daemon.worker$mk_backpressure_handler$fn__7117.invoke(worker.clj:161) [storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.disruptor$worker_backpressure_handler$reify__6432.onEvent(disruptor.clj:57) [storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.utils.WorkerBackpressureThread.run(WorkerBackpressureThread.java:64) [storm-core-0.10.2.y.jar:0.10.2.y]\r\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\r\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:113) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\t... 23 more\r\n{code}"
        }
    },
    {
        "filename": "STORM-2279.json",
        "creation_time": "2017-01-05T20:59:11.000+0000",
        "stack_trace": "```\norg.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.storm.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1369)\n\tat org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1353)\n\tat org.apache.storm.ui.core$component_page.invoke(core.clj:1026)\n\tat org.apache.storm.ui.core$fn__4308.invoke(core.clj:1214)\n\tat org.apache.storm.shade.compojure.core$make_route$fn__789.invoke(core.clj:100)\n\tat org.apache.storm.shade.compojure.core$if_route$fn__777.invoke(core.clj:46)\n\tat org.apache.storm.shade.compojure.core$if_method$fn__770.invoke(core.clj:31)\n\tat org.apache.storm.shade.compojure.core$routing$fn__795.invoke(core.clj:113)\n\tat clojure.core$some.invoke(core.clj:2570)\n\tat org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:113)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:139)\n\tat clojure.core$apply.invoke(core.clj:632)\n\tat org.apache.storm.shade.compojure.core$routes$fn__799.invoke(core.clj:118)\n\tat org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__3573.invoke(json.clj:56)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)\n\tat org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__3102.invoke(reload.clj:22)\n\tat org.apache.storm.ui.helpers$requests_middleware$fn__2152.invoke(helpers.clj:54)\n\tat org.apache.storm.ui.core$catch_errors$fn__4474.invoke(core.clj:1460)\n\tat org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__1844.invoke(keyword_params.clj:35)\n\tat org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__1887.invoke(nested_params.clj:84)\n\tat org.apache.storm.shade.ring.middleware.params$wrap_params$fn__1816.invoke(params.clj:64)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)\n\tat org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__2139.invoke(flash.clj:35)\n\tat org.apache.storm.shade.ring.middleware.session$wrap_session$fn__2125.invoke(session.clj:98)\n\tat org.apache.storm.shade.ring.util.servlet$make_service_method$fn__1674.invoke(servlet.clj:127)\n\tat org.apache.storm.shade.ring.util.servlet$servlet$fn__1678.invoke(servlet.clj:136)\n\tat org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)\n```\n\n```\njava.lang.ArrayIndexOutOfBoundsException: -2\n        at java.util.ArrayList.elementData(ArrayList.java:418)\n        at java.util.ArrayList.get(ArrayList.java:431)\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:3606)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4097)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4081)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.is_set_success": "    public boolean is_set_success() {\n      return this.success != null;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.send_getComponentPageInfo": "    public void send_getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys) throws org.apache.thrift.TException\n    {\n      getComponentPageInfo_args args = new getComponentPageInfo_args();\n      args.set_topology_id(topology_id);\n      args.set_component_id(component_id);\n      args.set_window(window);\n      args.set_is_include_sys(is_include_sys);\n      sendBase(\"getComponentPageInfo\", args);\n    }",
            "storm-core.src.jvm.org.apache.storm.logging.filters.AccessLoggingFilter.handle": "  public void handle(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException{\n    if (request != null) {\n      LOG.info(\"Access from: {} url: {} principal: {}\", request.getRemoteAddr(), request.getRequestURL(),\n              (request.getUserPrincipal() == null ? \"\" : request.getUserPrincipal().getName()));\n    }\n    chain.doFilter(request, response);\n  }",
            "storm-core.src.jvm.org.apache.storm.logging.filters.AccessLoggingFilter.doFilter": "  public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n    handle((HttpServletRequest)request, (HttpServletResponse)response, chain);\n  }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public getTopologyHistory_result getResult(I iface, getTopologyHistory_args args) throws org.apache.thrift.TException {\n        getTopologyHistory_result result = new getTopologyHistory_result();\n        try {\n          result.success = iface.getTopologyHistory(args.user);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setLogConfig": "    public void recv_setLogConfig() throws org.apache.thrift.TException\n    {\n      setLogConfig_result result = new setLogConfig_result();\n      receiveBase(result, \"setLogConfig\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(String location, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deleteBlob": "    public void recv_deleteBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      deleteBlob_result result = new deleteBlob_result();\n      receiveBase(result, \"deleteBlob\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_createStateInZookeeper": "    public void recv_createStateInZookeeper() throws org.apache.thrift.TException\n    {\n      createStateInZookeeper_result result = new createStateInZookeeper_result();\n      receiveBase(result, \"createStateInZookeeper\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadChunk": "    public void recv_uploadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadChunk_result result = new uploadChunk_result();\n      receiveBase(result, \"uploadChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setWorkerProfiler": "    public void recv_setWorkerProfiler() throws org.apache.thrift.TException\n    {\n      setWorkerProfiler_result result = new setWorkerProfiler_result();\n      receiveBase(result, \"setWorkerProfiler\");\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(String user, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(String key, int replication, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishBlobUpload": "    public void recv_finishBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishBlobUpload_result result = new finishBlobUpload_result();\n      receiveBase(result, \"finishBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_rebalance": "    public void recv_rebalance() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      rebalance_result result = new rebalance_result();\n      receiveBase(result, \"rebalance\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopology": "    public void recv_submitTopology() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopology_result result = new submitTopology_result();\n      receiveBase(result, \"submitTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(String location, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopology": "    public void recv_killTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopology_result result = new killTopology_result();\n      receiveBase(result, \"killTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(String name, String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadBlobChunk": "    public void recv_uploadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadBlobChunk_result result = new uploadBlobChunk_result();\n      receiveBase(result, \"uploadBlobChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_activate": "    public void recv_activate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      activate_result result = new activate_result();\n      receiveBase(result, \"activate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(String file, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(String session, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(String id, String host, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_finishFileUpload": "    public void recv_finishFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishFileUpload_result result = new finishFileUpload_result();\n      receiveBase(result, \"finishFileUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_setBlobMeta": "    public void recv_setBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      setBlobMeta_result result = new setBlobMeta_result();\n      receiveBase(result, \"setBlobMeta\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopologyWithOpts": "    public void recv_killTopologyWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n      receiveBase(result, \"killTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_debug": "    public void recv_debug() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      debug_result result = new debug_result();\n      receiveBase(result, \"debug\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadNewCredentials": "    public void recv_uploadNewCredentials() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      uploadNewCredentials_result result = new uploadNewCredentials_result();\n      receiveBase(result, \"uploadNewCredentials\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_deactivate": "    public void recv_deactivate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      deactivate_result result = new deactivate_result();\n      receiveBase(result, \"deactivate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_cancelBlobUpload": "    public void recv_cancelBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      cancelBlobUpload_result result = new cancelBlobUpload_result();\n      receiveBase(result, \"cancelBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(String id, String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context \n            ReqContext req_context = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            if (trans instanceof TMemoryInputTransport) {\n                try {\n                    req_context.setRemoteAddress(InetAddress.getLocalHost());\n                } catch (UnknownHostException e) {\n                    throw new RuntimeException(e);\n                }                                \n            } else if (trans instanceof TSocket) {\n                TSocket tsocket = (TSocket)trans;\n                //remote address\n                Socket socket = tsocket.getSocket();\n                req_context.setRemoteAddress(socket.getInetAddress());                \n            } \n\n            //anonymous user\n            Subject s = getDefaultSubject();\n            if (s == null) {\n              final String user = (String)storm_conf.get(\"debug.simple.transport.user\");\n              if (user != null) {\n                HashSet<Principal> principals = new HashSet<>();\n                principals.add(new Principal() {\n                  public String getName() { return user; }\n                  public String toString() { return user; }\n                });\n                s = new Subject(true, principals, new HashSet<>(), new HashSet<>());\n              }\n            }\n            req_context.setSubject(s);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-core.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.getDefaultSubject": "    protected Subject getDefaultSubject() {\n        return null;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setSubject": "    public void setSubject(Subject subject) {\n        _subject = subject;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.context": "    public static ReqContext context() {\n        return ctxt.get();\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ReqContext.setRemoteAddress": "    public void setRemoteAddress(InetAddress addr) {\n        _remoteAddr = addr;\n    }"
        },
        "bug_report": {
            "Title": "Unable to open bolt page of storm ui",
            "Description": "With latest storm code, I am unable to open ui and see bolt information. I am using the vagrant setup. On the ui page that open, I see the following error.\n{code}\nInternal Server Error\norg.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.storm.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1369)\n\tat org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1353)\n\tat org.apache.storm.ui.core$component_page.invoke(core.clj:1026)\n\tat org.apache.storm.ui.core$fn__4308.invoke(core.clj:1214)\n\tat org.apache.storm.shade.compojure.core$make_route$fn__789.invoke(core.clj:100)\n\tat org.apache.storm.shade.compojure.core$if_route$fn__777.invoke(core.clj:46)\n\tat org.apache.storm.shade.compojure.core$if_method$fn__770.invoke(core.clj:31)\n\tat org.apache.storm.shade.compojure.core$routing$fn__795.invoke(core.clj:113)\n\tat clojure.core$some.invoke(core.clj:2570)\n\tat org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:113)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:139)\n\tat clojure.core$apply.invoke(core.clj:632)\n\tat org.apache.storm.shade.compojure.core$routes$fn__799.invoke(core.clj:118)\n\tat org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__3573.invoke(json.clj:56)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)\n\tat org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__3102.invoke(reload.clj:22)\n\tat org.apache.storm.ui.helpers$requests_middleware$fn__2152.invoke(helpers.clj:54)\n\tat org.apache.storm.ui.core$catch_errors$fn__4474.invoke(core.clj:1460)\n\tat org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__1844.invoke(keyword_params.clj:35)\n\tat org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__1887.invoke(nested_params.clj:84)\n\tat org.apache.storm.shade.ring.middleware.params$wrap_params$fn__1816.invoke(params.clj:64)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)\n\tat org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__2139.invoke(flash.clj:35)\n\tat org.apache.storm.shade.ring.middleware.session$wrap_session$fn__2125.invoke(session.clj:98)\n\tat org.apache.storm.shade.ring.util.servlet$make_service_method$fn__1674.invoke(servlet.clj:127)\n\tat org.apache.storm.shade.ring.util.servlet$servlet$fn__1678.invoke(servlet.clj:136)\n\tat org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}\nUrl: http://node1:8080/component.html?id=SlidingTimeCorrectness-winSec1slideSec1VerificationBolt&topology_id=SlidingWindowTestw1s1-2-1483646178\n\nThere is a stacktrace corresponding to this in nimbus.log showing IndexOutOfBound error:\n{code}\n2017-01-05 19:57:26.934 pool-15-thread-41 o.a.s.d.n.Nimbus [WARN] getComponentPageInfo exception. (topo id='SlidingWindowTestw1s1-2-1483646178')\njava.lang.ArrayIndexOutOfBoundsException: -2\n        at java.util.ArrayList.elementData(ArrayList.java:418)\n        at java.util.ArrayList.get(ArrayList.java:431)\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:3606)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4097)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4081)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n{code}\n\nThe problem is that we expect the index to be positive, but since it is a mod of hashcode it can be negative.\n{code}\n                int taskIndex = TupleUtils.listHashCode(Arrays.asList(componentId)) %\n                        tasks.size();\n                int taskId = tasks.get(taskIndex);\n{code}\nhttps://github.com/apache/storm/blob/2b82fc8b5328fd4fbd680998c6051d9496c102d7/storm-core/src/jvm/org/apache/storm/daemon/nimbus/Nimbus.java#L3605\n"
        }
    },
    {
        "filename": "STORM-3079.json",
        "creation_time": "2018-05-17T19:29:10.000+0000",
        "stack_trace": "```\norg.apache.storm.generated.KeyNotFoundException: null\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:393) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:670) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2333) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2387) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2674) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n```",
        "source_code": {
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta": "    private SettableBlobMeta getStoredBlobMeta(String key) throws KeyNotFoundException {\n        InputStream in = null;\n        try {\n            LocalFsBlobStoreFile pf = fbs.read(META_PREFIX + key);\n            try {\n                in = pf.getInputStream();\n            } catch (FileNotFoundException fnf) {\n                throw new KeyNotFoundException(key);\n            }\n            ByteArrayOutputStream out = new ByteArrayOutputStream();\n            byte[] buffer = new byte[2048];\n            int len;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n            in.close();\n            in = null;\n            return Utils.thriftDeserialize(SettableBlobMeta.class, out.toByteArray());\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        } finally {\n            if (in != null) {\n                try {\n                    in.close();\n                } catch (IOException e) {\n                    //Ignored\n                }\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getBlob": "    public InputStreamWithMeta getBlob(String key, Subject who) throws AuthorizationException, KeyNotFoundException {\n        validateKey(key);\n        if (!checkForBlobOrDownload(key)) {\n            checkForBlobUpdate(key);\n        }\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.hasPermissions(meta.get_acl(), READ, who, key);\n        try {\n            return new BlobStoreFileInputStream(fbs.read(DATA_PREFIX + key));\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobUpdate": "    public synchronized void checkForBlobUpdate(String key) {\n        BlobStoreUtils.updateKeyForBlobStore(conf, this, zkClient, key, nimbusInfo);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobOrDownload": "    public synchronized boolean checkForBlobOrDownload(String key) throws KeyNotFoundException {\n        boolean checkBlobDownload = false;\n        try {\n            List<String> keyList = BlobStoreUtils.getKeyListFromBlobStore(this);\n            if (!keyList.contains(key)) {\n                if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) != null) {\n                    Set<NimbusInfo> nimbusSet = BlobStoreUtils.getNimbodesWithLatestSequenceNumberOfBlob(zkClient, key);\n                    nimbusSet.remove(this.nimbusInfo);\n                    if (BlobStoreUtils.downloadMissingBlob(conf, this, key, nimbusSet)) {\n                        LOG.debug(\"Updating blobs state\");\n                        BlobStoreUtils.createStateInZookeeper(conf, key, nimbusInfo);\n                        checkBlobDownload = true;\n                    }\n                }\n            }\n        } catch (KeyNotFoundException e) {\n            throw e;\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n        return checkBlobDownload;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.readBlobTo": "    public void readBlobTo(String key, OutputStream out, Subject who) throws IOException, KeyNotFoundException, AuthorizationException {\n        InputStreamWithMeta in = getBlob(key, who);\n        if (in == null) {\n            throw new IOException(\"Could not find \" + key);\n        }\n        byte[] buffer = new byte[2048];\n        int len = 0;\n        try {\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n        } finally {\n            in.close();\n            out.flush();\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.close": "        public void close() throws IOException {\n            in.close();\n        }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.getBlob": "    public abstract InputStreamWithMeta getBlob(String key, Subject who) throws AuthorizationException, KeyNotFoundException;\n\n    /**\n     * Returns an iterator with all the list of keys currently available on the blob store.\n     *\n     * @return Iterator<String>\n     */\n    public abstract Iterator<String> listKeys();\n\n    /**\n     * Gets the replication factor of the blob.\n     *\n     * @param key Key for the blob.\n     * @param who Is the subject having the read privilege for the blob.\n     * @return BlobReplication object containing the replication factor for the blob.\n     *\n     * @throws Exception\n     */\n    public abstract int getBlobReplication(String key, Subject who) throws Exception;\n\n    /**\n     * Modifies the replication factor of the blob.\n     *\n     * @param key         Key for the blob.\n     * @param replication The replication factor the blob has to be set.\n     * @param who         Is the subject having the update privilege for the blob\n     * @return BlobReplication object containing the updated replication factor for the blob.\n     *\n     * @throws AuthorizationException\n     * @throws KeyNotFoundException\n     * @throws IOException\n     */\n    public abstract int updateBlobReplication(String key, int replication, Subject who) throws AuthorizationException, KeyNotFoundException,\n        IOException;\n\n    /**\n     * Filters keys based on the KeyFilter passed as the argument.\n     *\n     * @param filter KeyFilter\n     * @param <R>    Type\n     * @return Set of filtered keys\n     */\n    public <R> Set<R> filterAndListKeys(KeyFilter<R> filter) {\n        Set<R> ret = new HashSet<R>();\n        Iterator<String> keys = listKeys();\n        while (keys.hasNext()) {\n            String key = keys.next();\n            R filtered = filter.filter(key);\n            if (filtered != null) {\n                ret.add(filtered);\n            }\n        }\n        return ret;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.write": "        public void write(byte[] b, int offset, int len) throws IOException {\n            out.write(b, offset, len);\n        }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.read": "        public int read(byte[] b) throws IOException {\n            return in.read(b);\n        }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.readBlob": "    public byte[] readBlob(String key, Subject who) throws IOException, KeyNotFoundException, AuthorizationException {\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        readBlobTo(key, out, who);\n        byte[] bytes = out.toByteArray();\n        out.close();\n        return bytes;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.nimbus.TopoCache.readTopology": "    public StormTopology readTopology(final String topoId, final Subject who)\n        throws KeyNotFoundException, AuthorizationException, IOException {\n        final String key = ConfigUtils.masterStormCodeKey(topoId);\n        WithAcl<StormTopology> cached = topos.get(topoId);\n        if (cached == null) {\n            //We need to read a new one\n            StormTopology topo = Utils.deserialize(store.readBlob(key, who), StormTopology.class);\n            ReadableBlobMeta meta = store.getBlobMeta(key, who);\n            cached = new WithAcl<>(meta.get_settable().get_acl(), topo);\n            WithAcl<StormTopology> previous = topos.putIfAbsent(topoId, cached);\n            if (previous != null) {\n                cached = previous;\n            }\n        } else {\n            //Check if the user is allowed to read this\n            aclHandler.hasPermissions(cached.acl, READ, who, key);\n        }\n        return cached.data;\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "        public void run() {\n            while (this.active.get()) {\n                QueueEntry queueEntry = null;\n                try {\n                    queueEntry = this.queue.peek();\n                    if ((queueEntry != null) && (Time.currentTimeMillis() >= queueEntry.endTimeMs)) {\n                        // It is imperative to not run the function\n                        // inside the timer lock. Otherwise, it is\n                        // possible to deadlock if the fn deals with\n                        // other locks, like the submit lock.\n                        this.queue.remove(queueEntry);\n                        queueEntry.func.run();\n                    } else if (queueEntry != null) {\n                        //  If any events are scheduled, sleep until\n                        // event generation. If any recurring events\n                        // are scheduled then we will always go\n                        // through this branch, sleeping only the\n                        // exact necessary amount of time. We give\n                        // an upper bound, e.g. 1000 millis, to the\n                        // sleeping time, to limit the response time\n                        // for detecting any new event within 1 secs.\n                        Time.sleep(Math.min(1000, (queueEntry.endTimeMs - Time.currentTimeMillis())));\n                    } else {\n                        // Otherwise poll to see if any new event\n                        // was scheduled. This is, in essence, the\n                        // response time for detecting any new event\n                        // schedulings when there are no scheduled\n                        // events.\n                        Time.sleep(1000);\n                    }\n                    if (Thread.interrupted()) {\n                        this.active.set(false);\n                    }\n                } catch (Throwable e) {\n                    if (!(Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e))\n                        && !(Utils.exceptionCauseIsInstanceOf(ClosedByInterruptException.class, e))) {\n                        this.onKill.uncaughtException(this, e);\n                        this.setActive(false);\n                    }\n                }\n            }\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStoreFile.getInputStream": "    public InputStream getInputStream() throws IOException {\n        if (isTmp()) {\n            throw new IllegalStateException(\"Cannot read from a temporary part file.\");\n        }\n        return new FileInputStream(_path);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStoreFile.isTmp": "    public boolean isTmp() {\n        return _isTmp;\n    }"
        },
        "bug_report": {
            "Title": "improve getMessage support for ThriftExceptions",
            "Description": "I've seen error callstacks similar to this and been confused as to the null message.\u00a0 The generated thrift code does not support getMessage().\u00a0 We should try and improve the log messages.\r\n\r\n\u00a0\r\n2018-05-16 21:15:04.596 o.a.s.d.n.Nimbus timer [INFO] Exception {}\r\norg.apache.storm.generated.KeyNotFoundException: null        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:393) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:670) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2333) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2387) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2674) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
        }
    },
    {
        "filename": "STORM-3096.json",
        "creation_time": "2018-06-05T18:39:44.000+0000",
        "stack_trace": "```\norg.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:394) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:680) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2389) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2443) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2730) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.StormTimer$1.run(StormTimer.java:111) [storm-client-2.0.0.y.jar:2.0.0.y]\n\norg.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) [storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]\n at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [libthrift-0.11.0.jar:0.11.0]\n at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [libthrift-0.11.0.jar:0.11.0]\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n\norg.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) [storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0]\n at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]\n at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [libthrift-0.11.0.jar:0.11.0]\n at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [libthrift-0.11.0.jar:0.11.0]\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n```",
        "source_code": {
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta": "    private SettableBlobMeta getStoredBlobMeta(String key) throws KeyNotFoundException {\n        InputStream in = null;\n        try {\n            LocalFsBlobStoreFile pf = fbs.read(META_PREFIX + key);\n            try {\n                in = pf.getInputStream();\n            } catch (FileNotFoundException fnf) {\n                throw new WrappedKeyNotFoundException(key);\n            }\n            ByteArrayOutputStream out = new ByteArrayOutputStream();\n            byte[] buffer = new byte[2048];\n            int len;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n            in.close();\n            in = null;\n            return Utils.thriftDeserialize(SettableBlobMeta.class, out.toByteArray());\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        } finally {\n            if (in != null) {\n                try {\n                    in.close();\n                } catch (IOException e) {\n                    //Ignored\n                }\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getBlob": "    public InputStreamWithMeta getBlob(String key, Subject who) throws AuthorizationException, KeyNotFoundException {\n        validateKey(key);\n        if (!checkForBlobOrDownload(key)) {\n            checkForBlobUpdate(key);\n        }\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.hasPermissions(meta.get_acl(), READ, who, key);\n        try {\n            return new BlobStoreFileInputStream(fbs.read(DATA_PREFIX + key));\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobUpdate": "    public synchronized void checkForBlobUpdate(String key) {\n        BlobStoreUtils.updateKeyForBlobStore(conf, this, zkClient, key, nimbusInfo);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobOrDownload": "    public synchronized boolean checkForBlobOrDownload(String key) throws KeyNotFoundException {\n        boolean checkBlobDownload = false;\n        try {\n            List<String> keyList = BlobStoreUtils.getKeyListFromBlobStore(this);\n            if (!keyList.contains(key)) {\n                if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) != null) {\n                    Set<NimbusInfo> nimbusSet = BlobStoreUtils.getNimbodesWithLatestSequenceNumberOfBlob(zkClient, key);\n                    nimbusSet.remove(this.nimbusInfo);\n                    if (BlobStoreUtils.downloadMissingBlob(conf, this, key, nimbusSet)) {\n                        LOG.debug(\"Updating blobs state\");\n                        BlobStoreUtils.createStateInZookeeper(conf, key, nimbusInfo);\n                        checkBlobDownload = true;\n                    }\n                }\n            }\n        } catch (KeyNotFoundException e) {\n            throw e;\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n        return checkBlobDownload;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.readBlobTo": "    public void readBlobTo(String key, OutputStream out, Subject who) throws IOException, KeyNotFoundException, AuthorizationException {\n        InputStreamWithMeta in = getBlob(key, who);\n        if (in == null) {\n            throw new IOException(\"Could not find \" + key);\n        }\n        byte[] buffer = new byte[2048];\n        int len = 0;\n        try {\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n        } finally {\n            in.close();\n            out.flush();\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.close": "        public void close() throws IOException {\n            in.close();\n        }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.getBlob": "    public abstract InputStreamWithMeta getBlob(String key, Subject who) throws AuthorizationException, KeyNotFoundException;\n\n    /**\n     * Returns an iterator with all the list of keys currently available on the blob store.\n     *\n     * @return Iterator<String>\n     */\n    public abstract Iterator<String> listKeys();\n\n    /**\n     * Gets the replication factor of the blob.\n     *\n     * @param key Key for the blob.\n     * @param who Is the subject having the read privilege for the blob.\n     * @return BlobReplication object containing the replication factor for the blob.\n     *\n     * @throws Exception\n     */\n    public abstract int getBlobReplication(String key, Subject who) throws Exception;\n\n    /**\n     * Modifies the replication factor of the blob.\n     *\n     * @param key         Key for the blob.\n     * @param replication The replication factor the blob has to be set.\n     * @param who         Is the subject having the update privilege for the blob\n     * @return BlobReplication object containing the updated replication factor for the blob.\n     *\n     * @throws AuthorizationException\n     * @throws KeyNotFoundException\n     * @throws IOException\n     */\n    public abstract int updateBlobReplication(String key, int replication, Subject who) throws AuthorizationException, KeyNotFoundException,\n        IOException;\n\n    /**\n     * Filters keys based on the KeyFilter passed as the argument.\n     *\n     * @param filter KeyFilter\n     * @param <R>    Type\n     * @return Set of filtered keys\n     */\n    public <R> Set<R> filterAndListKeys(KeyFilter<R> filter) {\n        Set<R> ret = new HashSet<R>();\n        Iterator<String> keys = listKeys();\n        while (keys.hasNext()) {\n            String key = keys.next();\n            R filtered = filter.filter(key);\n            if (filtered != null) {\n                ret.add(filtered);\n            }\n        }\n        return ret;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.write": "        public void write(byte[] b, int offset, int len) throws IOException {\n            out.write(b, offset, len);\n        }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.read": "        public int read(byte[] b) throws IOException {\n            return in.read(b);\n        }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStore.readBlob": "    public byte[] readBlob(String key, Subject who) throws IOException, KeyNotFoundException, AuthorizationException {\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        readBlobTo(key, out, who);\n        byte[] bytes = out.toByteArray();\n        out.close();\n        return bytes;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.nimbus.TopoCache.readTopology": "    public StormTopology readTopology(final String topoId, final Subject who)\n        throws KeyNotFoundException, AuthorizationException, IOException {\n        final String key = ConfigUtils.masterStormCodeKey(topoId);\n        WithAcl<StormTopology> cached = topos.get(topoId);\n        if (cached == null) {\n            //We need to read a new one\n            StormTopology topo = Utils.deserialize(store.readBlob(key, who), StormTopology.class);\n            ReadableBlobMeta meta = store.getBlobMeta(key, who);\n            cached = new WithAcl<>(meta.get_settable().get_acl(), topo);\n            WithAcl<StormTopology> previous = topos.putIfAbsent(topoId, cached);\n            if (previous != null) {\n                cached = previous;\n            }\n        } else {\n            //Check if the user is allowed to read this\n            aclHandler.hasPermissions(cached.acl, READ, who, key);\n        }\n        return cached.data;\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "        public void run() {\n            while (this.active.get()) {\n                QueueEntry queueEntry = null;\n                try {\n                    queueEntry = this.queue.peek();\n                    if ((queueEntry != null) && (Time.currentTimeMillis() >= queueEntry.endTimeMs)) {\n                        // It is imperative to not run the function\n                        // inside the timer lock. Otherwise, it is\n                        // possible to deadlock if the fn deals with\n                        // other locks, like the submit lock.\n                        this.queue.remove(queueEntry);\n                        queueEntry.func.run();\n                    } else if (queueEntry != null) {\n                        //  If any events are scheduled, sleep until\n                        // event generation. If any recurring events\n                        // are scheduled then we will always go\n                        // through this branch, sleeping only the\n                        // exact necessary amount of time. We give\n                        // an upper bound, e.g. 1000 millis, to the\n                        // sleeping time, to limit the response time\n                        // for detecting any new event within 1 secs.\n                        Time.sleep(Math.min(1000, (queueEntry.endTimeMs - Time.currentTimeMillis())));\n                    } else {\n                        // Otherwise poll to see if any new event\n                        // was scheduled. This is, in essence, the\n                        // response time for detecting any new event\n                        // schedulings when there are no scheduled\n                        // events.\n                        Time.sleep(1000);\n                    }\n                    if (Thread.interrupted()) {\n                        this.active.set(false);\n                    }\n                } catch (Throwable e) {\n                    if (!(Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e))\n                        && !(Utils.exceptionCauseIsInstanceOf(ClosedByInterruptException.class, e))) {\n                        this.onKill.uncaughtException(this, e);\n                        this.setActive(false);\n                    }\n                }\n            }\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication": "    public int getBlobReplication(String key, Subject who) throws Exception {\n        int replicationCount = 0;\n        validateKey(key);\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.hasPermissions(meta.get_acl(), READ, who, key);\n        if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) == null) {\n            return 0;\n        }\n        try {\n            replicationCount = zkClient.getChildren().forPath(BLOBSTORE_SUBTREE + key).size();\n        } catch (NoNodeException e) {\n            //Race with delete\n            //If it is not here the replication is 0 \n        }\n        return replicationCount;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_submitTopologyWithOpts": "    public void send_submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options) throws org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_args args = new submitTopologyWithOpts_args();\n      args.set_name(name);\n      args.set_uploadedJarLocation(uploadedJarLocation);\n      args.set_jsonConf(jsonConf);\n      args.set_topology(topology);\n      args.set_options(options);\n      sendBase(\"submitTopologyWithOpts\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public isRemoteBlobExists_result getResult(I iface, isRemoteBlobExists_args args) throws org.apache.thrift.TException {\n        isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n        try {\n          result.success = iface.isRemoteBlobExists(args.blobKey);\n          result.set_success_isSet(true);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(java.lang.String location, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public java.lang.String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(java.lang.String session, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(java.lang.String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(java.lang.String id, org.apache.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(java.lang.String name, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public java.lang.String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(java.lang.String session, org.apache.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(java.lang.String user, org.apache.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(java.lang.String key, int replication, org.apache.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(java.lang.String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getOwnerResourceSummaries": "    public java.util.List<OwnerResourceSummary> recv_getOwnerResourceSummaries() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n      receiveBase(result, \"getOwnerResourceSummaries\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorAssignments": "    public void getSupervisorAssignments(java.lang.String node, org.apache.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getSupervisorAssignments_call method_call = new getSupervisorAssignments_call(node, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public java.lang.String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(java.lang.String key, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public java.nio.ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(java.lang.String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(java.lang.String id, org.apache.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeat": "    public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeat_call method_call = new sendSupervisorWorkerHeartbeat_call(heatbeat, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeats": "    public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeats_call method_call = new sendSupervisorWorkerHeartbeats_call(heartbeats, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(java.lang.String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(java.lang.String file, org.apache.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(java.lang.String name, org.apache.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.processWorkerMetrics": "    public void processWorkerMetrics(WorkerMetrics metrics, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      processWorkerMetrics_call method_call = new processWorkerMetrics_call(metrics, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(java.lang.String name, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(java.lang.String key, org.apache.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isRemoteBlobExists": "    public boolean recv_isRemoteBlobExists() throws AuthorizationException, org.apache.thrift.TException\n    {\n      isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n      receiveBase(result, \"isRemoteBlobExists\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"isRemoteBlobExists failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public java.nio.ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public java.lang.String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(java.lang.String key, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(java.lang.String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(java.lang.String id, org.apache.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isRemoteBlobExists": "    public void isRemoteBlobExists(java.lang.String blobKey, org.apache.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      isRemoteBlobExists_call method_call = new isRemoteBlobExists_call(blobKey, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getOwnerResourceSummaries": "    public void getOwnerResourceSummaries(java.lang.String owner, org.apache.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(java.lang.String key, org.apache.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(java.lang.String session, org.apache.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorAssignments": "    public SupervisorAssignments recv_getSupervisorAssignments() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n      receiveBase(result, \"getSupervisorAssignments\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorAssignments failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(java.lang.String session, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(java.lang.String key, org.apache.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      __isset_bitfield = org.apache.thrift.EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(java.lang.String name, org.apache.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(java.lang.String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(java.lang.String key, org.apache.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public java.lang.String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public java.util.List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public java.lang.String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(java.lang.String id, org.apache.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(java.lang.String name, org.apache.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(java.lang.String id, org.apache.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.sasl.SaslTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context\n            ReqContext reqContext = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            //Sasl transport\n            TSaslServerTransport saslTrans = (TSaslServerTransport) trans;\n\n            if (trans instanceof NoOpTTrasport) {\n                return false;\n            }\n\n            //remote address\n            TSocket tsocket = (TSocket) saslTrans.getUnderlyingTransport();\n            Socket socket = tsocket.getSocket();\n            reqContext.setRemoteAddress(socket.getInetAddress());\n\n            //remote subject\n            SaslServer saslServer = saslTrans.getSaslServer();\n            String authId = saslServer.getAuthorizationID();\n            Subject remoteUser = new Subject();\n            remoteUser.getPrincipals().add(new User(authId));\n            reqContext.setSubject(remoteUser);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStoreFile.getInputStream": "    public InputStream getInputStream() throws IOException {\n        if (isTmp()) {\n            throw new IllegalStateException(\"Cannot read from a temporary part file.\");\n        }\n        return new FileInputStream(_path);\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStoreFile.isTmp": "    public boolean isTmp() {\n        return _isTmp;\n    }"
        },
        "bug_report": {
            "Title": "blobstores deleted before topologies can be submitted",
            "Description": "STORM-3053 attempted to fix the race condition where a nimbus timer causes doCleanup() to delete the blobs during topology submission.\u00a0 After the fix went in, we still see the error occurring.\u00a0 I tracked the problem down to\u00a0idsOfTopologiesWithPrivateWorkerKeys() at [https://github.com/apache/storm/blob/master/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L893.]\u00a0\r\n\r\n\u00a0\r\n\r\nThe previous change to wait to delete topologies is useful, but should be moved after all the topologies are discovered.\r\n\r\n\u00a0\r\n{code:java}\r\n\r\n 018-06-03 11:53:42.581 o.a.s.d.n.Nimbus pool-37-thread-1014 [INFO] Received topology submission for topology-testHardCoreFaultTolerance-4 (storm-0.10.2.y.248 JDK-1.8.0_131) with conf {topology.users=[hadoopqa@DEV.YGRID.YAHOO.COM, hadoopqa], topology.acker.executors=0, storm.zookeeper.superACL=sasl:gstorm, topology.workers=3, topology.submitter.principal=hadoopqa@DEV.YGRID.YAHOO.COM, topology.debug=true, topology.disable.loadaware.messaging=true, storm.zookeeper.topology.auth.payload=#########################################, topology.name=topology-testHardCoreFaultTolerance-4, storm.zookeeper.topology.auth.scheme=digest, topology.kryo.register={}, nimbus.task.timeout.secs=200, storm.id=topology-testHardCoreFaultTolerance-4-18-1528026822, topology.kryo.decorators=[], topology.eventlogger.executors=0, topology.submitter.user=hadoopqa, topology.max.task.parallelism=null}\r\n 2018-06-03 11:53:42.591 o.a.s.d.n.Nimbus timer [INFO] Cleaning up topology-testHardCoreFaultTolerance-4-18-1528026822\r\n 2018-06-03 11:53:42.597 o.a.s.d.n.Nimbus pool-37-thread-1014 [INFO] uploadedJar /home/y/var/storm/nimbus/inbox/stormjar-3c73de98-ced7-4fd0-86d9-8fba3e5100f1.jar\r\n 2018-06-03 11:53:42.601 o.a.s.c.StormClusterStateImpl pool-37-thread-1014 [INFO] set-path: /blobstore/topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar/openqe82blue-n1.blue.ygrid.yahoo.com:50560-1\r\n 2018-06-03 11:53:42.621 o.a.s.d.n.Nimbus timer [INFO] Exception {}\r\n org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:394) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:680) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2389) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2443) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2730) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.StormTimer$1.run(StormTimer.java:111) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n 2018-06-03 11:53:42.871 o.a.s.c.StormClusterStateImpl pool-37-thread-1014 [INFO] set-path: /blobstore/topology-testHardCoreFaultTolerance-4-18-1528026822-stormconf.ser/openqe82blue-n1.blue.ygrid.yahoo.com:50560-1\r\n 2018-06-03 11:53:42.881 o.a.s.c.StormClusterStateImpl pool-37-thread-1014 [INFO] set-path: /blobstore/topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser/openqe82blue-n1.blue.ygrid.yahoo.com:50560-1\r\n 2018-06-03 11:53:42.886 o.a.s.d.n.Nimbus pool-37-thread-1023 [INFO] Created download session dd7fa916-e489-47a5-beea-ac3eba6ed905 for topology-testHardCoreFaultTolerance-0-14-1528026818-stormjar.jar\r\n 2018-06-03 11:53:42.888 o.a.s.d.n.Nimbus pool-37-thread-1014 [WARN] Topology submission exception. (topology name='topology-testHardCoreFaultTolerance-4')\r\n org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [libthrift-0.11.0.jar:0.11.0]\r\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n 2018-06-03 11:53:42.888 o.a.t.ProcessFunction pool-37-thread-1014 [ERROR] Internal error processing submitTopologyWithOpts\r\n org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [libthrift-0.11.0.jar:0.11.0]\r\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]{code}"
        }
    },
    {
        "filename": "STORM-1642.json",
        "creation_time": "2016-03-21T07:34:06.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n\njava.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n\njava.lang.RuntimeException: (\"Worker died\")\n        at backtype.storm.util$exit_process_BANG_.doInvoke(util.clj:336) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.6.0.jar:?]\n        at backtype.storm.daemon.worker$fn__7188$fn__7189.invoke(worker.clj:536) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_executor_data$fn__5523$fn__5524.invoke(executor.clj:261) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:489) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor": "    private void consumeBatchToCursor(long cursor, EventHandler<Object> handler) {\n        for (long curr = _consumer.get() + 1; curr <= cursor; curr++) {\n            try {\n                AtomicReference<Object> mo = _buffer.get(curr);\n                Object o = mo.getAndSet(null);\n                if (o == INTERRUPT) {\n                    throw new InterruptedException(\"Disruptor processing interrupted\");\n                } else if (o == null) {\n                    LOG.error(\"NULL found in {}:{}\", this.getName(), cursor);\n                } else {\n                    handler.onEvent(o, curr, curr == cursor);\n                    if (_enableBackpressure && _cb != null && (_metrics.writePos() - curr + _overflowCount.get()) <= _lowWaterMark) {\n                        try {\n                            if (_throttleOn) {\n                                _throttleOn = false;\n                                _cb.lowWaterMark();\n                            }\n                        } catch (Exception e) {\n                            throw new RuntimeException(\"Exception during calling lowWaterMark callback!\");\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                throw new RuntimeException(e);\n            }\n        }\n        _consumer.set(cursor);\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.getName": "    public String getName() {\n        return _queueName;\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.writePos": "        public long writePos() {\n            return _buffer.getCursor();\n        }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable": "    public void consumeBatchWhenAvailable(EventHandler<Object> handler) {\n        try {\n            final long nextSequence = _consumer.get() + 1;\n            long availableSequence = _barrier.waitFor(nextSequence);\n\n            if (availableSequence >= nextSequence) {\n                consumeBatchToCursor(availableSequence, handler);\n            }\n        } catch (TimeoutException te) {\n            //Ignored\n        } catch (AlertException e) {\n            throw new RuntimeException(e);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.serialization.KryoTupleDeserializer.deserialize": "    public Tuple deserialize(byte[] ser) {\n        try {\n            _kryoInput.setBuffer(ser);\n            int taskId = _kryoInput.readInt(true);\n            int streamId = _kryoInput.readInt(true);\n            String componentName = _context.getComponentId(taskId);\n            String streamName = _ids.getStreamName(componentName, streamId);\n            MessageId id = MessageId.deserialize(_kryoInput);\n            List<Object> values = _kryo.deserializeFrom(_kryoInput);\n            return new TupleImpl(_context, values, taskId, streamName, id);\n        } catch(IOException e) {\n            throw new RuntimeException(e);\n        }\n    }"
        },
        "bug_report": {
            "Title": "NullPointerException when deserialize",
            "Description": "Hi:\nI've encountered the following NPE when storm tries to deserialize. I did not use OutputCollector concurrently in my code.  The only object we are passing between bolts are a thrift object, and we have written a serializer for it. I've attached the code of serializer and please help to check whether there are any potential bugs there.\n\n2016-03-04 17:17:43.583 b.s.util [ERROR] Async loop died!\njava.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n2016-03-04 17:17:43.584 b.s.d.executor [ERROR]\njava.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n2016-03-04 17:17:43.648 b.s.util [ERROR] Halting process: (\"Worker died\")\njava.lang.RuntimeException: (\"Worker died\")\n        at backtype.storm.util$exit_process_BANG_.doInvoke(util.clj:336) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.6.0.jar:?]\n        at backtype.storm.daemon.worker$fn__7188$fn__7189.invoke(worker.clj:536) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_executor_data$fn__5523$fn__5524.invoke(executor.clj:261) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:489) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]"
        }
    },
    {
        "filename": "STORM-2700.json",
        "creation_time": "2017-08-21T14:09:50.000+0000",
        "stack_trace": "```\njava.util.concurrent.ExecutionException: AuthorizationException(msg:ethan does not have READ access to key1)\n        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_131]\n        at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_131]\n        at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:410) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:305) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:789) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nCaused by: org.apache.storm.generated.AuthorizationException\n        at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:527) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer.access$000(Localizer.java:68) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:497) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:473) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:437) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:823) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n```",
        "source_code": {
            "storm-server.src.main.java.org.apache.storm.localizer.LocalDownloadedResource.get": "        public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {\n            return _wrapped.get(timeout, unit);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization": "    static DynamicState handleWaitingForBlobLocalization(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.pendingLocalization != null);\n        assert(dynamicState.pendingDownload != null);\n        assert(dynamicState.container == null);\n        \n        //Ignore changes to scheduling while downloading the topology blobs\n        // We don't support canceling the download through the future yet,\n        // so to keep everything in sync, just wait\n        try {\n            dynamicState.pendingDownload.get(1000, TimeUnit.MILLISECONDS);\n            //Downloading of all blobs finished.\n            if (!equivalent(dynamicState.newAssignment, dynamicState.pendingLocalization)) {\n                //Scheduling changed\n                staticState.localizer.releaseSlotFor(dynamicState.pendingLocalization, staticState.port);\n                return prepareForNewAssignmentNoWorkersRunning(dynamicState, staticState);\n            }\n            dynamicState = updateAssignmentIfNeeded(dynamicState);\n            numWorkersLaunched.mark();\n            Container c = staticState.containerLauncher.launchContainer(staticState.port, dynamicState.pendingLocalization, staticState.localState);\n            return dynamicState.withCurrentAssignment(c, dynamicState.pendingLocalization).withState(MachineState.WAITING_FOR_WORKER_START).withPendingLocalization(null, null);\n        } catch (TimeoutException e) {\n            //We waited for 1 second loop around and try again....\n            return dynamicState;\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.equivalent": "    static boolean equivalent(LocalAssignment a, LocalAssignment b) {\n        if (a == null && b == null) {\n            return true;\n        }\n        if (a != null && b != null) {\n            if (a.get_topology_id().equals(b.get_topology_id())) {\n                Set<ExecutorInfo> aexec = new HashSet<>(a.get_executors());\n                Set<ExecutorInfo> bexec = new HashSet<>(b.get_executors());\n                if (aexec.equals(bexec)) {\n                    boolean aHasResources = a.is_set_resources();\n                    boolean bHasResources = b.is_set_resources();\n                    if (!aHasResources && !bHasResources) {\n                        return true;\n                    }\n                    if (aHasResources && bHasResources) {\n                        if (a.get_resources().equals(b.get_resources())) {\n                            return true;\n                        }\n                    }\n                }\n            }\n        }\n        return false;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withCurrentAssignment": "        public DynamicState withCurrentAssignment(final Container container, final LocalAssignment currentAssignment) {\n            return new DynamicState(this.state, this.newAssignment,\n                    container, currentAssignment,\n                    this.pendingLocalization, this.startTime,\n                    this.pendingDownload, this.profileActions,\n                    this.pendingStopProfileActions);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withState": "        public DynamicState withState(final MachineState state) {\n            long newStartTime = Time.currentTimeMillis();\n            return new DynamicState(state, this.newAssignment,\n                    this.container, this.currentAssignment,\n                    this.pendingLocalization, newStartTime,\n                    this.pendingDownload, this.profileActions,\n                    this.pendingStopProfileActions);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withPendingLocalization": "        public DynamicState withPendingLocalization(Future<Void> pendingDownload) {\n            return withPendingLocalization(this.pendingLocalization, pendingDownload);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.prepareForNewAssignmentNoWorkersRunning": "    static DynamicState prepareForNewAssignmentNoWorkersRunning(DynamicState dynamicState, StaticState staticState) throws IOException {\n        assert(dynamicState.container == null);\n        \n        if (dynamicState.newAssignment == null) {\n            return dynamicState.withState(MachineState.EMPTY);\n        }\n        Future<Void> pendingDownload = staticState.localizer.requestDownloadBaseTopologyBlobs(dynamicState.newAssignment, staticState.port);\n        return dynamicState.withPendingLocalization(dynamicState.newAssignment, pendingDownload).withState(MachineState.WAITING_FOR_BASIC_LOCALIZATION);\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.updateAssignmentIfNeeded": "    private static DynamicState updateAssignmentIfNeeded(DynamicState dynamicState) {\n        if (dynamicState.newAssignment != null\n            && !dynamicState.newAssignment.equals(dynamicState.currentAssignment)) {\n            dynamicState =\n                dynamicState.withCurrentAssignment(dynamicState.container, dynamicState.newAssignment);\n        }\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.stateMachineStep": "    static DynamicState stateMachineStep(DynamicState dynamicState, StaticState staticState) throws Exception {\n        LOG.debug(\"STATE {}\", dynamicState.state);\n        switch (dynamicState.state) {\n            case EMPTY:\n                return handleEmpty(dynamicState, staticState);\n            case RUNNING:\n                return handleRunning(dynamicState, staticState);\n            case WAITING_FOR_WORKER_START:\n                return handleWaitingForWorkerStart(dynamicState, staticState);\n            case KILL_AND_RELAUNCH:\n                return handleKillAndRelaunch(dynamicState, staticState);\n            case KILL:\n                return handleKill(dynamicState, staticState);\n            case WAITING_FOR_BASIC_LOCALIZATION:\n                return handleWaitingForBasicLocalization(dynamicState, staticState);\n            case WAITING_FOR_BLOB_LOCALIZATION:\n                return handleWaitingForBlobLocalization(dynamicState, staticState);\n            default:\n                throw new IllegalStateException(\"Code not ready to handle a state of \"+dynamicState.state);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleKillAndRelaunch": "    static DynamicState handleKillAndRelaunch(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        if (dynamicState.container.areAllProcessesDead()) {\n            if (equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n                dynamicState.container.cleanUpForRestart();\n                dynamicState.container.relaunch();\n                return dynamicState.withState(MachineState.WAITING_FOR_WORKER_START);\n            }\n            //Scheduling changed after we killed all of the processes\n            return prepareForNewAssignmentNoWorkersRunning(cleanupCurrentContainer(dynamicState, staticState, null), staticState);\n        }\n        //The child processes typically exit in < 1 sec.  If 2 mins later they are still around something is wrong\n        if ((Time.currentTimeMillis() - dynamicState.startTime) > 120_000) {\n            throw new RuntimeException(\"Not all processes in \" + dynamicState.container + \" exited after 120 seconds\");\n        }\n        numForceKill.mark();\n        dynamicState.container.forceKill();\n        Time.sleep(staticState.killSleepMs);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleWaitingForWorkerStart": "    static DynamicState handleWaitingForWorkerStart(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        LSWorkerHeartbeat hb = dynamicState.container.readHeartbeat();\n        if (hb != null) {\n            long hbAgeMs = (Time.currentTimeSecs() - hb.get_time_secs()) * 1000;\n            if (hbAgeMs <= staticState.hbTimeoutMs) {\n                return dynamicState.withState(MachineState.RUNNING);\n            }\n        }\n        \n        if (!equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n            //We were rescheduled while waiting for the worker to come up\n            LOG.warn(\"SLOT {}: Assignment Changed from {} to {}\", staticState.port, dynamicState.currentAssignment, dynamicState.newAssignment);\n            return killContainerForChangedAssignment(dynamicState, staticState);\n        }\n        dynamicState = updateAssignmentIfNeeded(dynamicState);\n\n        long timeDiffms = (Time.currentTimeMillis() - dynamicState.startTime);\n        if (timeDiffms > staticState.firstHbTimeoutMs) {\n            LOG.warn(\"SLOT {}: Container {} failed to launch in {} ms.\", staticState.port, dynamicState.container, staticState.firstHbTimeoutMs);\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        Time.sleep(1000);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleRunning": "    static DynamicState handleRunning(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        if (!equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n            LOG.warn(\"SLOT {}: Assignment Changed from {} to {}\", staticState.port, dynamicState.currentAssignment, dynamicState.newAssignment);\n            //Scheduling changed while running...\n            return killContainerForChangedAssignment(dynamicState, staticState);\n        }\n        dynamicState = updateAssignmentIfNeeded(dynamicState);\n\n        if (dynamicState.container.didMainProcessExit()) {\n            numWorkersKilledProcessExit.mark();\n            LOG.warn(\"SLOT {}: main process has exited\", staticState.port);\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n\n        if (dynamicState.container.isMemoryLimitViolated(dynamicState.currentAssignment)) {\n            numWorkersKilledMemoryViolation.mark();\n            LOG.warn(\"SLOT {}: violated memory limits\", staticState.port);\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        \n        LSWorkerHeartbeat hb = dynamicState.container.readHeartbeat();\n        if (hb == null) {\n            numWorkersKilledHBNull.mark();\n            LOG.warn(\"SLOT {}: HB returned as null\", staticState.port);\n            //This can happen if the supervisor crashed after launching a\n            // worker that never came up.\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        \n        long timeDiffMs = (Time.currentTimeSecs() - hb.get_time_secs()) * 1000;\n        if (timeDiffMs > staticState.hbTimeoutMs) {\n            numWorkersKilledHBTimeout.mark();\n            LOG.warn(\"SLOT {}: HB is too old {} > {}\", staticState.port, timeDiffMs, staticState.hbTimeoutMs);\n            return killAndRelaunchContainer(dynamicState, staticState);\n        }\n        \n        //The worker is up and running check for profiling requests\n        if (!dynamicState.profileActions.isEmpty()) {\n            HashSet<TopoProfileAction> mod = new HashSet<>(dynamicState.profileActions);\n            HashSet<TopoProfileAction> modPending = new HashSet<>(dynamicState.pendingStopProfileActions);\n            Iterator<TopoProfileAction> iter = mod.iterator();\n            while (iter.hasNext()) {\n                TopoProfileAction action = iter.next();\n                if (!action.topoId.equals(dynamicState.currentAssignment.get_topology_id())) {\n                    iter.remove();\n                    LOG.warn(\"Dropping {} wrong topology is running\", action);\n                    //Not for this topology so skip it\n                } else {\n                    if (modPending.contains(action)) {\n                        boolean isTimeForStop = Time.currentTimeMillis() > action.request.get_time_stamp();\n                        if (isTimeForStop) {\n                            if (dynamicState.container.runProfiling(action.request, true)) {\n                                LOG.debug(\"Stopped {} action finished\", action);\n                                iter.remove();\n                                modPending.remove(action);\n                            } else {\n                                LOG.warn(\"Stopping {} failed, will be retried\", action);\n                            }\n                        } else {\n                            LOG.debug(\"Still pending {} now: {}\", action, Time.currentTimeMillis());\n                        }\n                    } else {\n                        //J_PROFILE_START is not used.  When you see a J_PROFILE_STOP\n                        // start profiling and save it away to stop when timeout happens\n                        if (action.request.get_action() == ProfileAction.JPROFILE_STOP) {\n                            if (dynamicState.container.runProfiling(action.request, false)) {\n                                modPending.add(action);\n                                LOG.debug(\"Started {} now: {}\", action, Time.currentTimeMillis());\n                            } else {\n                                LOG.warn(\"Starting {} failed, will be retried\", action);\n                            }\n                        } else {\n                            if (dynamicState.container.runProfiling(action.request, false)) {\n                                LOG.debug(\"Started {} action finished\", action);\n                                iter.remove();\n                            } else {\n                                LOG.warn(\"Starting {} failed, will be retried\", action);\n                            }\n                        }\n                    }\n                }\n            }\n            dynamicState = dynamicState.withProfileActions(mod, modPending);\n        }\n        Time.sleep(staticState.monitorFreqMs);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleEmpty": "    static DynamicState handleEmpty(DynamicState dynamicState, StaticState staticState) throws InterruptedException, IOException {\n        if (!equivalent(dynamicState.newAssignment, dynamicState.currentAssignment)) {\n            return prepareForNewAssignmentNoWorkersRunning(dynamicState, staticState);\n        }\n        dynamicState = updateAssignmentIfNeeded(dynamicState);\n        \n        //Both assignments are null, just wait\n        if (dynamicState.profileActions != null && !dynamicState.profileActions.isEmpty()) {\n            //Nothing is scheduled here so throw away all of the profileActions\n            LOG.warn(\"Dropping {} no topology is running\", dynamicState.profileActions);\n            dynamicState = dynamicState.withProfileActions(Collections.<TopoProfileAction> emptySet(), Collections.<TopoProfileAction> emptySet());\n        }\n        Time.sleep(1000);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleWaitingForBasicLocalization": "    static DynamicState handleWaitingForBasicLocalization(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.pendingLocalization != null);\n        assert(dynamicState.pendingDownload != null);\n        assert(dynamicState.container == null);\n        \n        //Ignore changes to scheduling while downloading the topology code\n        // We don't support canceling the download through the future yet,\n        // so to keep everything in sync, just wait\n        try {\n            dynamicState.pendingDownload.get(1000, TimeUnit.MILLISECONDS);\n            Future<Void> pendingDownload = staticState.localizer.requestDownloadTopologyBlobs(dynamicState.pendingLocalization, staticState.port);\n            return dynamicState.withPendingLocalization(pendingDownload).withState(MachineState.WAITING_FOR_BLOB_LOCALIZATION);\n        } catch (TimeoutException e) {\n            return dynamicState;\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.handleKill": "    static DynamicState handleKill(DynamicState dynamicState, StaticState staticState) throws Exception {\n        assert(dynamicState.container != null);\n        assert(dynamicState.currentAssignment != null);\n        \n        if (dynamicState.container.areAllProcessesDead()) {\n            LOG.warn(\"SLOT {} all processes are dead...\", staticState.port);\n            return cleanupCurrentContainer(dynamicState, staticState, \n                    dynamicState.pendingLocalization == null ? MachineState.EMPTY : MachineState.WAITING_FOR_BASIC_LOCALIZATION);\n        }\n\n        LOG.warn(\"SLOT {} force kill and wait...\", staticState.port);\n        numForceKill.mark();\n        dynamicState.container.forceKill();\n        Time.sleep(staticState.killSleepMs);\n        return dynamicState;\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.run": "    public void run() {\n        try {\n            while(!done) {\n                Set<TopoProfileAction> origProfileActions = new HashSet<>(profiling.get());\n                Set<TopoProfileAction> removed = new HashSet<>(origProfileActions);\n                \n                DynamicState nextState = \n                        stateMachineStep(dynamicState.withNewAssignment(newAssignment.get())\n                                .withProfileActions(origProfileActions, dynamicState.pendingStopProfileActions), staticState);\n\n                if (LOG.isDebugEnabled() || dynamicState.state != nextState.state) {\n                    LOG.info(\"STATE {} -> {}\", dynamicState, nextState);\n                }\n                //Save the current state for recovery\n                if ((nextState.currentAssignment != null && !nextState.currentAssignment.equals(dynamicState.currentAssignment)) ||\n                        (dynamicState.currentAssignment != null && !dynamicState.currentAssignment.equals(nextState.currentAssignment))) {\n                    LOG.info(\"SLOT {}: Changing current assignment from {} to {}\", staticState.port, dynamicState.currentAssignment, nextState.currentAssignment);\n                    saveNewAssignment(nextState.currentAssignment);\n                }\n\n                if (equivalent(nextState.newAssignment, nextState.currentAssignment)\n                    && nextState.currentAssignment != null && nextState.currentAssignment.get_owner() == null\n                    && nextState.newAssignment != null && nextState.newAssignment.get_owner() != null) {\n                    //This is an odd case for a rolling upgrade where the user on the old assignment may be null,\n                    // but not on the new one.  Although in all other ways they are the same.\n                    // If this happens we want to use the assignment with the owner.\n                    LOG.info(\"Updating assignment to save owner {}\", nextState.newAssignment.get_owner());\n                    saveNewAssignment(nextState.newAssignment);\n                    nextState = nextState.withCurrentAssignment(nextState.container, nextState.newAssignment);\n                }\n                \n                // clean up the profiler actions that are not being processed\n                removed.removeAll(dynamicState.profileActions);\n                removed.removeAll(dynamicState.pendingStopProfileActions);\n                for (TopoProfileAction action: removed) {\n                    try {\n                        clusterState.deleteTopologyProfileRequests(action.topoId, action.request);\n                    } catch (Exception e) {\n                        LOG.error(\"Error trying to remove profiling request, it will be retried\", e);\n                    }\n                }\n                Set<TopoProfileAction> orig, copy;\n                do {\n                    orig = profiling.get();\n                    copy = new HashSet<>(orig);\n                    copy.removeAll(removed);\n                } while (!profiling.compareAndSet(orig, copy));\n                dynamicState = nextState;\n            }\n        } catch (Throwable e) {\n            if (!Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e)) {\n                LOG.error(\"Error when processing event\", e);\n                Utils.exitProcess(20, \"Error when processing an event\");\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.saveNewAssignment": "    private void saveNewAssignment(LocalAssignment assignment) {\n        synchronized(staticState.localState) {\n            Map<Integer, LocalAssignment> assignments = staticState.localState.getLocalAssignmentsMap();\n            if (assignments == null) {\n                assignments = new HashMap<>();\n            }\n            if (assignment == null) {\n                assignments.remove(staticState.port);\n            } else {\n                assignments.put(staticState.port, assignment);\n            }\n            staticState.localState.setLocalAssignmentsMap(assignments);\n        }\n        Map<Long, LocalAssignment> update = null;\n        Map<Long, LocalAssignment> orig = null;\n        do {\n            Long lport = new Long(staticState.port);\n            orig = cachedCurrentAssignments.get();\n            update = new HashMap<>(orig);\n            if (assignment == null) {\n                update.remove(lport);\n            } else {\n                update.put(lport, assignment);\n            }\n        } while (!cachedCurrentAssignments.compareAndSet(orig, update));\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withProfileActions": "        public DynamicState withProfileActions(Set<TopoProfileAction> profileActions, Set<TopoProfileAction> pendingStopProfileActions) {\n            return new DynamicState(this.state, this.newAssignment,\n                    this.container, this.currentAssignment,\n                    this.pendingLocalization, this.startTime,\n                    this.pendingDownload, profileActions,\n                    pendingStopProfileActions);\n        }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.Slot.withNewAssignment": "        public DynamicState withNewAssignment(LocalAssignment newAssignment) {\n            return new DynamicState(this.state, newAssignment,\n                    this.container, this.currentAssignment,\n                    this.pendingLocalization, this.startTime,\n                    this.pendingDownload, this.profileActions,\n                    this.pendingStopProfileActions);\n        }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.downloadBlob": "  private LocalizedResource downloadBlob(Map<String, Object> conf, String key, File localFile,\n      String user, boolean uncompress, boolean isUpdate)\n      throws AuthorizationException, KeyNotFoundException, IOException {\n    ClientBlobStore blobstore = null;\n    try {\n      blobstore = getClientBlobStore();\n      long nimbusBlobVersion = ServerUtils.nimbusVersionOfBlob(key, blobstore);\n      long oldVersion = ServerUtils.localVersionOfBlob(localFile.toString());\n      FileOutputStream out = null;\n      PrintWriter writer = null;\n      int numTries = 0;\n      String localizedPath = localFile.toString();\n      String localFileWithVersion = ServerUtils.constructBlobWithVersionFileName(localFile.toString(),\n              nimbusBlobVersion);\n      String localVersionFile = ServerUtils.constructVersionFileName(localFile.toString());\n      String downloadFile = localFileWithVersion;\n      if (uncompress) {\n        // we need to download to temp file and then unpack into the one requested\n        downloadFile = new File(localFile.getParent(), TO_UNCOMPRESS + localFile.getName()).toString();\n      }\n      while (numTries < _blobDownloadRetries) {\n        out = new FileOutputStream(downloadFile);\n        numTries++;\n        try {\n          if (!ServerUtils.canUserReadBlob(blobstore.getBlobMeta(key), user)) {\n            throw new AuthorizationException(user + \" does not have READ access to \" + key);\n          }\n          InputStreamWithMeta in = blobstore.getBlob(key);\n          byte[] buffer = new byte[1024];\n          int len;\n          while ((len = in.read(buffer)) >= 0) {\n            out.write(buffer, 0, len);\n          }\n          out.close();\n          in.close();\n          if (uncompress) {\n            ServerUtils.unpack(new File(downloadFile), new File(localFileWithVersion));\n            LOG.debug(\"uncompressed \" + downloadFile + \" to: \" + localFileWithVersion);\n          }\n\n          // Next write the version.\n          LOG.info(\"Blob: \" + key + \" updated with new Nimbus-provided version: \" +\n              nimbusBlobVersion + \" local version was: \" + oldVersion);\n          // The false parameter ensures overwriting the version file, not appending\n          writer = new PrintWriter(\n              new BufferedWriter(new FileWriter(localVersionFile, false)));\n          writer.println(nimbusBlobVersion);\n          writer.close();\n\n          try {\n            setBlobPermissions(conf, user, localFileWithVersion);\n            setBlobPermissions(conf, user, localVersionFile);\n\n            // Update the key.current symlink. First create tmp symlink and do\n            // move of tmp to current so that the operation is atomic.\n            String tmp_uuid_local = java.util.UUID.randomUUID().toString();\n            LOG.debug(\"Creating a symlink @\" + localFile + \".\" + tmp_uuid_local + \" , \" +\n                \"linking to: \" + localFile + \".\" + nimbusBlobVersion);\n            File uuid_symlink = new File(localFile + \".\" + tmp_uuid_local);\n\n            Files.createSymbolicLink(uuid_symlink.toPath(),\n                Paths.get(ServerUtils.constructBlobWithVersionFileName(localFile.toString(),\n                        nimbusBlobVersion)));\n            File current_symlink = new File(ServerUtils.constructBlobCurrentSymlinkName(\n                    localFile.toString()));\n            Files.move(uuid_symlink.toPath(), current_symlink.toPath(), ATOMIC_MOVE);\n          } catch (IOException e) {\n            // if we fail after writing the version file but before we move current link we need to\n            // restore the old version to the file\n            try {\n              PrintWriter restoreWriter = new PrintWriter(\n                  new BufferedWriter(new FileWriter(localVersionFile, false)));\n              restoreWriter.println(oldVersion);\n              restoreWriter.close();\n            } catch (IOException ignore) {}\n            throw e;\n          }\n\n          String oldBlobFile = localFile + \".\" + oldVersion;\n          try {\n            // Remove the old version. Note that if a number of processes have that file open,\n            // the OS will keep the old blob file around until they all close the handle and only\n            // then deletes it. No new process will open the old blob, since the users will open the\n            // blob through the \"blob.current\" symlink, which always points to the latest version of\n            // a blob. Remove the old version after the current symlink is updated as to not affect\n            // anyone trying to read it.\n            if ((oldVersion != -1) && (oldVersion != nimbusBlobVersion)) {\n              LOG.info(\"Removing an old blob file:\" + oldBlobFile);\n              Files.delete(Paths.get(oldBlobFile));\n            }\n          } catch (IOException e) {\n            // At this point we have downloaded everything and moved symlinks.  If the remove of\n            // old fails just log an error\n            LOG.error(\"Exception removing old blob version: \" + oldBlobFile);\n          }\n\n          break;\n        } catch (AuthorizationException ae) {\n          // we consider this non-retriable exceptions\n          if (out != null) {\n            out.close();\n          }\n          new File(downloadFile).delete();\n          throw ae;\n        } catch (IOException | KeyNotFoundException e) {\n          if (out != null) {\n            out.close();\n          }\n          if (writer != null) {\n            writer.close();\n          }\n          new File(downloadFile).delete();\n          if (uncompress) {\n            try {\n              FileUtils.deleteDirectory(new File(localFileWithVersion));\n            } catch (IOException ignore) {}\n          }\n          if (!isUpdate) {\n            // don't want to remove existing version file if its an update\n            new File(localVersionFile).delete();\n          }\n\n          if (numTries < _blobDownloadRetries) {\n            LOG.error(\"Failed to download blob, retrying\", e);\n          } else {\n            throw e;\n          }\n        }\n      }\n      return new LocalizedResource(key, localizedPath, uncompress);\n    } finally {\n      if(blobstore != null) {\n        blobstore.shutdown();\n      }\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.shutdown": "  public void shutdown() {\n    if (_cacheCleanupService != null) {\n      _cacheCleanupService.shutdown();\n    }\n    if (_execService != null) {\n      _execService.shutdown();\n    }\n    if (_updateExecService != null) {\n      _updateExecService.shutdown();\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.setBlobPermissions": "  public void setBlobPermissions(Map<String, Object> conf, String user, String path)\n      throws IOException {\n\n    if (!ObjectReader.getBoolean(conf.get(Config.SUPERVISOR_RUN_WORKER_AS_USER), false)) {\n      return;\n    }\n    String wlCommand = ObjectReader.getString(conf.get(Config.SUPERVISOR_WORKER_LAUNCHER), \"\");\n    if (wlCommand.isEmpty()) {\n      String stormHome = System.getProperty(\"storm.home\");\n      wlCommand = stormHome + \"/bin/worker-launcher\";\n    }\n    List<String> command = new ArrayList<String>(Arrays.asList(wlCommand, user, \"blob\", path));\n\n    String[] commandArray = command.toArray(new String[command.size()]);\n    ShellCommandExecutor shExec = new ShellCommandExecutor(commandArray);\n    LOG.info(\"Setting blob permissions, command: {}\", Arrays.toString(commandArray));\n\n    try {\n      shExec.execute();\n      LOG.debug(\"output: {}\", shExec.getOutput());\n    } catch (ExitCodeException e) {\n      int exitCode = shExec.getExitCode();\n      LOG.warn(\"Exit code from worker-launcher is : \" + exitCode, e);\n      LOG.debug(\"output: {}\", shExec.getOutput());\n      throw new IOException(\"Setting blob permissions failed\" +\n          \" (exitCode=\" + exitCode + \") with output: \" + shExec.getOutput(), e);\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.getClientBlobStore": "  protected ClientBlobStore getClientBlobStore() {\n    return ServerUtils.getClientBlobStoreForSupervisor(_conf);\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.getBlob": "  public LocalizedResource getBlob(LocalResource localResource, String user, String topo,\n       File userFileDir) throws AuthorizationException, KeyNotFoundException, IOException {\n    ArrayList<LocalResource> arr = new ArrayList<LocalResource>();\n    arr.add(localResource);\n    List<LocalizedResource> results = getBlobs(arr, user, topo, userFileDir);\n    if (results.isEmpty() || results.size() != 1) {\n      throw new IOException(\"Unknown error getting blob: \" + localResource + \", for user: \" + user +\n          \", topo: \" + topo);\n    }\n    return results.get(0);\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.call": "    public LocalizedResource call()\n        throws AuthorizationException, KeyNotFoundException, IOException  {\n      return _localizer.downloadBlob(_conf, _key, _localFile, _user, _uncompress,\n        _isUpdate);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess (int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }"
        },
        "bug_report": {
            "Title": "Blobstore shouldn't check ACL when Blobstore Acl validation disabled",
            "Description": "When \n{code:java}\nstorm.blobstore.acl.validation.enabled: false\n{code}\nis set, blobstore still checks ACL.\n\n\n{code:java}\n2017-08-21 13:56:19.800 o.a.s.d.s.Slot SLOT_6702 [ERROR] Error when processing event\njava.util.concurrent.ExecutionException: AuthorizationException(msg:ethan does not have READ access to key1)\n        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_131]\n        at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_131]\n        at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:410) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:305) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:789) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nCaused by: org.apache.storm.generated.AuthorizationException\n        at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:527) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer.access$000(Localizer.java:68) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:497) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:473) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n2017-08-21 13:56:19.800 o.a.s.u.Utils SLOT_6702 [ERROR] Halting process: Error when processing an event\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:437) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:823) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n2017-08-21 13:56:19.802 o.a.s.d.s.Supervisor Thread-6 [INFO] Shutting down supervisor b350cfb4-b333-4ea5-965e-b0698aaea80f-10.88.214.182\n2017-08-21 13:56:19.803 o.a.s.e.EventManagerImp Thread-5 [INFO] Event manager interrupted\n{code}\n\n\nReproduce:\n\n1. Create a blobstore with permission set to one user (e.g mapredqa).\n{code:java}\nsudo -u mapredqa storm blobstore create --file test-blobstore.txt --acl u:mapredqa:rwa key1\n{code}\n\n2. Submit a topology with topology.blobstore.map config as someone else (e.g. ethan).\n{code:java}\nsudo -u ethan storm jar /tmp/storm-starter-2.0.0-SNAPSHOT.jar org.apache.storm.starter.WordCountTopology wc -c topology.blobstore.map='{\"key1\":{\"localname\":\"test-blobstore.txt\", \"uncompress\":false}}'\n{code}\n"
        }
    },
    {
        "filename": "STORM-1663.json",
        "creation_time": "2016-03-29T06:07:27.000+0000",
        "stack_trace": "```\norg.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.storm.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getTopologyPageInfo(Nimbus.java:1243)\n\tat org.apache.storm.generated.Nimbus$Client.getTopologyPageInfo(Nimbus.java:1228)\n\tat org.apache.storm.ui.core$topology_page.invoke(core.clj:638)\n\tat org.apache.storm.ui.core$fn__3662.invoke(core.clj:987)\n\tat org.apache.storm.shade.compojure.core$make_route$fn__302.invoke(core.clj:93)\n\tat org.apache.storm.shade.compojure.core$if_route$fn__290.invoke(core.clj:39)\n\tat org.apache.storm.shade.compojure.core$if_method$fn__283.invoke(core.clj:24)\n\tat org.apache.storm.shade.compojure.core$routing$fn__308.invoke(core.clj:106)\n\tat clojure.core$some.invoke(core.clj:2570)\n\tat org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:106)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:139)\n\tat clojure.core$apply.invoke(core.clj:632)\n\tat org.apache.storm.shade.compojure.core$routes$fn__312.invoke(core.clj:111)\n\tat org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__1204.invoke(json.clj:56)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__724.invoke(reload.clj:22)\n\tat org.apache.storm.ui.helpers$requests_middleware$fn__3091.invoke(helpers.clj:50)\n\tat org.apache.storm.ui.core$catch_errors$fn__3837.invoke(core.clj:1250)\n\tat org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__2852.invoke(keyword_params.clj:27)\n\tat org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__2892.invoke(nested_params.clj:65)\n\tat org.apache.storm.shade.ring.middleware.params$wrap_params$fn__2823.invoke(params.clj:55)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__3075.invoke(flash.clj:14)\n\tat org.apache.storm.shade.ring.middleware.session$wrap_session$fn__3063.invoke(session.clj:43)\n\tat org.apache.storm.shade.ring.middleware.cookies$wrap_cookies$fn__2991.invoke(cookies.clj:160)\n\tat org.apache.storm.shade.ring.util.servlet$make_service_method$fn__2729.invoke(servlet.clj:127)\n\tat org.apache.storm.shade.ring.util.servlet$servlet$fn__2733.invoke(servlet.clj:136)\n\tat org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.is_set_success": "    public boolean is_set_success() {\n      return this.success != null;\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-core.src.jvm.org.apache.storm.generated.Nimbus.send_getTopologyPageInfo": "    public void send_getTopologyPageInfo(String id, String window, boolean is_include_sys) throws org.apache.thrift.TException\n    {\n      getTopologyPageInfo_args args = new getTopologyPageInfo_args();\n      args.set_id(id);\n      args.set_window(window);\n      args.set_is_include_sys(is_include_sys);\n      sendBase(\"getTopologyPageInfo\", args);\n    }",
            "storm-core.src.jvm.org.apache.storm.logging.filters.AccessLoggingFilter.handle": "  public void handle(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException{\n    if (request != null) {\n      LOG.info(\"Access from: {} url: {} principal: {}\", request.getRemoteAddr(), request.getRequestURL(),\n              (request.getUserPrincipal() == null ? \"\" : request.getUserPrincipal().getName()));\n    }\n    chain.doFilter(request, response);\n  }",
            "storm-core.src.jvm.org.apache.storm.logging.filters.AccessLoggingFilter.doFilter": "  public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n    handle((HttpServletRequest)request, (HttpServletResponse)response, chain);\n  }"
        },
        "bug_report": {
            "Title": "Clicking on an active topology from storm ui home page and then refreshing the page throws exception",
            "Description": "The exception thrown is:\n\norg.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.storm.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getTopologyPageInfo(Nimbus.java:1243)\n\tat org.apache.storm.generated.Nimbus$Client.getTopologyPageInfo(Nimbus.java:1228)\n\tat org.apache.storm.ui.core$topology_page.invoke(core.clj:638)\n\tat org.apache.storm.ui.core$fn__3662.invoke(core.clj:987)\n\tat org.apache.storm.shade.compojure.core$make_route$fn__302.invoke(core.clj:93)\n\tat org.apache.storm.shade.compojure.core$if_route$fn__290.invoke(core.clj:39)\n\tat org.apache.storm.shade.compojure.core$if_method$fn__283.invoke(core.clj:24)\n\tat org.apache.storm.shade.compojure.core$routing$fn__308.invoke(core.clj:106)\n\tat clojure.core$some.invoke(core.clj:2570)\n\tat org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:106)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:139)\n\tat clojure.core$apply.invoke(core.clj:632)\n\tat org.apache.storm.shade.compojure.core$routes$fn__312.invoke(core.clj:111)\n\tat org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__1204.invoke(json.clj:56)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__724.invoke(reload.clj:22)\n\tat org.apache.storm.ui.helpers$requests_middleware$fn__3091.invoke(helpers.clj:50)\n\tat org.apache.storm.ui.core$catch_errors$fn__3837.invoke(core.clj:1250)\n\tat org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__2852.invoke(keyword_params.clj:27)\n\tat org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__2892.invoke(nested_params.clj:65)\n\tat org.apache.storm.shade.ring.middleware.params$wrap_params$fn__2823.invoke(params.clj:55)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__3075.invoke(flash.clj:14)\n\tat org.apache.storm.shade.ring.middleware.session$wrap_session$fn__3063.invoke(session.clj:43)\n\tat org.apache.storm.shade.ring.middleware.cookies$wrap_cookies$fn__2991.invoke(cookies.clj:160)\n\tat org.apache.storm.shade.ring.util.servlet$make_service_method$fn__2729.invoke(servlet.clj:127)\n\tat org.apache.storm.shade.ring.util.servlet$servlet$fn__2733.invoke(servlet.clj:136)\n\tat org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "STORM-2518.json",
        "creation_time": "2017-05-17T06:26:37.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException: null\n        at org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser(BlobStoreAclHandler.java:382) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs(BlobStoreAclHandler.java:357) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta(BlobStoreAclHandler.java:306) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.LocalFsBlobStore.createBlob(LocalFsBlobStore.java:103) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_112]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_112]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]\n        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]\n        at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.7.0.jar:?]\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.7.0.jar:?]\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9064.beginCreateBlob(nimbus.clj:2047) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3430) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3414) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser": "    private void fixACLsForUser(List<AccessControl> acls, String user, int mask) {\n        boolean foundUserACL = false;\n        for (AccessControl control : acls) {\n            if (control.get_type() == AccessControlType.USER && control.get_name().equals(user)) {\n                int currentAccess = control.get_access();\n                if ((currentAccess & mask) != mask) {\n                    control.set_access(currentAccess | mask);\n                }\n                foundUserACL = true;\n                break;\n            }\n        }\n        if (!foundUserACL) {\n            AccessControl userACL = new AccessControl();\n            userACL.set_type(AccessControlType.USER);\n            userACL.set_name(user);\n            userACL.set_access(mask);\n            acls.add(userACL);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs": "    private final List<AccessControl> normalizeSettableACLs(String key, List<AccessControl> acls, Subject who,\n                                                            int opMask) {\n        List<AccessControl> cleanAcls = removeBadACLs(acls);\n        Set<String> userNames = getUserNamesFromSubject(who);\n        for (String user : userNames) {\n            fixACLsForUser(cleanAcls, user, opMask);\n        }\n        if ((who == null || userNames.isEmpty()) && !worldEverything(acls)) {\n            cleanAcls.addAll(BlobStoreAclHandler.WORLD_EVERYTHING);\n            LOG.debug(\"Access Control for key {} is normalized to world everything {}\", key, cleanAcls);\n            if (!acls.isEmpty())\n                LOG.warn(\"Access control for blob with key {} is normalized to WORLD_EVERYTHING\", key);\n        }\n        return cleanAcls;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStoreAclHandler.removeBadACLs": "    private List<AccessControl> removeBadACLs(List<AccessControl> accessControls) {\n        List<AccessControl> resultAcl = new ArrayList<AccessControl>();\n        for (AccessControl control : accessControls) {\n            if(control.get_type().equals(AccessControlType.OTHER) && (control.get_access() == 0 )) {\n                LOG.debug(\"Removing invalid blobstore world ACL \" +\n                        BlobStoreAclHandler.accessControlToString(control));\n                continue;\n            }\n            resultAcl.add(control);\n        }\n        return resultAcl;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStoreAclHandler.getUserNamesFromSubject": "    private Set<String> getUserNamesFromSubject(Subject who) {\n        Set<String> user = new HashSet<String>();\n        if (who != null) {\n            for(Principal p: who.getPrincipals()) {\n                user.add(_ptol.toLocal(p));\n            }\n        }\n        return user;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStoreAclHandler.worldEverything": "    private boolean worldEverything(List<AccessControl> acls) {\n        boolean isWorldEverything = false;\n        for (AccessControl acl : acls) {\n            if (acl.get_type() == AccessControlType.OTHER && acl.get_access() == (READ|WRITE|ADMIN)) {\n                isWorldEverything = true;\n                break;\n            }\n        }\n        return isWorldEverything;\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta": "    public void normalizeSettableBlobMeta(String key, SettableBlobMeta meta, Subject who, int opMask) {\n        meta.set_acl(normalizeSettableACLs(key, meta.get_acl(), who, opMask));\n    }",
            "storm-server.src.main.java.org.apache.storm.blobstore.LocalFsBlobStore.createBlob": "    public AtomicOutputStream createBlob(String key, SettableBlobMeta meta, Subject who) throws AuthorizationException, KeyAlreadyExistsException {\n        LOG.debug(\"Creating Blob for key {}\", key);\n        validateKey(key);\n        _aclHandler.normalizeSettableBlobMeta(key, meta, who, allPermissions);\n        BlobStoreAclHandler.validateSettableACLs(key, meta.get_acl());\n        _aclHandler.hasPermissions(meta.get_acl(), allPermissions, who, key);\n        if (fbs.exists(DATA_PREFIX+key)) {\n            throw new KeyAlreadyExistsException(key);\n        }\n        BlobStoreFileOutputStream mOut = null;\n        try {\n            mOut = new BlobStoreFileOutputStream(fbs.write(META_PREFIX+key, true));\n            mOut.write(Utils.thriftSerialize(meta));\n            mOut.close();\n            mOut = null;\n            return new BlobStoreFileOutputStream(fbs.write(DATA_PREFIX+key, true));\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        } finally {\n            if (mOut != null) {\n                try {\n                    mOut.cancel();\n                } catch (IOException e) {\n                    //Ignored\n                }\n            }\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public getTopologyHistory_result getResult(I iface, getTopologyHistory_args args) throws org.apache.thrift.TException {\n        getTopologyHistory_result result = new getTopologyHistory_result();\n        try {\n          result.success = iface.getTopologyHistory(args.user);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_setLogConfig": "    public void recv_setLogConfig() throws org.apache.thrift.TException\n    {\n      setLogConfig_result result = new setLogConfig_result();\n      receiveBase(result, \"setLogConfig\");\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(String location, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_deleteBlob": "    public void recv_deleteBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      deleteBlob_result result = new deleteBlob_result();\n      receiveBase(result, \"deleteBlob\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_createStateInZookeeper": "    public void recv_createStateInZookeeper() throws org.apache.thrift.TException\n    {\n      createStateInZookeeper_result result = new createStateInZookeeper_result();\n      receiveBase(result, \"createStateInZookeeper\");\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadChunk": "    public void recv_uploadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadChunk_result result = new uploadChunk_result();\n      receiveBase(result, \"uploadChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_setWorkerProfiler": "    public void recv_setWorkerProfiler() throws org.apache.thrift.TException\n    {\n      setWorkerProfiler_result result = new setWorkerProfiler_result();\n      receiveBase(result, \"setWorkerProfiler\");\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(String user, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(String key, int replication, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_finishBlobUpload": "    public void recv_finishBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishBlobUpload_result result = new finishBlobUpload_result();\n      receiveBase(result, \"finishBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_rebalance": "    public void recv_rebalance() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      rebalance_result result = new rebalance_result();\n      receiveBase(result, \"rebalance\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopology": "    public void recv_submitTopology() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopology_result result = new submitTopology_result();\n      receiveBase(result, \"submitTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(String location, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopology": "    public void recv_killTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopology_result result = new killTopology_result();\n      receiveBase(result, \"killTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(String name, String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadBlobChunk": "    public void recv_uploadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadBlobChunk_result result = new uploadBlobChunk_result();\n      receiveBase(result, \"uploadBlobChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_activate": "    public void recv_activate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      activate_result result = new activate_result();\n      receiveBase(result, \"activate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(String file, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(String session, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(String id, String host, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_finishFileUpload": "    public void recv_finishFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishFileUpload_result result = new finishFileUpload_result();\n      receiveBase(result, \"finishFileUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_setBlobMeta": "    public void recv_setBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      setBlobMeta_result result = new setBlobMeta_result();\n      receiveBase(result, \"setBlobMeta\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopologyWithOpts": "    public void recv_killTopologyWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n      receiveBase(result, \"killTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_debug": "    public void recv_debug() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      debug_result result = new debug_result();\n      receiveBase(result, \"debug\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadNewCredentials": "    public void recv_uploadNewCredentials() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      uploadNewCredentials_result result = new uploadNewCredentials_result();\n      receiveBase(result, \"uploadNewCredentials\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_deactivate": "    public void recv_deactivate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      deactivate_result result = new deactivate_result();\n      receiveBase(result, \"deactivate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_cancelBlobUpload": "    public void recv_cancelBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      cancelBlobUpload_result result = new cancelBlobUpload_result();\n      receiveBase(result, \"cancelBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(String id, String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.SaslTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context\n            ReqContext req_context = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            //Sasl transport\n            TSaslServerTransport saslTrans = (TSaslServerTransport)trans;\n\n            if(trans instanceof NoOpTTrasport) {\n                return false;\n            }\n\n            //remote address\n            TSocket tsocket = (TSocket)saslTrans.getUnderlyingTransport();\n            Socket socket = tsocket.getSocket();\n            req_context.setRemoteAddress(socket.getInetAddress());\n\n            //remote subject\n            SaslServer saslServer = saslTrans.getSaslServer();\n            String authId = saslServer.getAuthorizationID();\n            Subject remoteUser = new Subject();\n            remoteUser.getPrincipals().add(new User(authId));\n            req_context.setSubject(remoteUser);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-client.src.jvm.org.apache.storm.blobstore.BlobStoreAclHandler.validateSettableACLs": "    public static void validateSettableACLs(String key, List<AccessControl> acls) throws AuthorizationException {\n        Set<String> aclUsers = new HashSet<>();\n        List<String> duplicateUsers = new ArrayList<>();\n        for (AccessControl acl : acls) {\n            String aclUser = acl.get_name();\n            if (!StringUtils.isEmpty(aclUser) && !aclUsers.add(aclUser)) {\n                LOG.error(\"'{}' user can't appear more than once in the ACLs\", aclUser);\n                duplicateUsers.add(aclUser);\n            }\n        }\n        if (duplicateUsers.size() > 0) {\n            String errorMessage  = \"user \" + Arrays.toString(duplicateUsers.toArray())\n                    + \" can't appear more than once in the ACLs for key [\" + key +\"].\";\n            throw new AuthorizationException(errorMessage);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.setSubject": "    public void setSubject(Subject subject) {\n        _subject = subject;\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.context": "    public static ReqContext context() {\n        return ctxt.get();\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.setRemoteAddress": "    public void setRemoteAddress(InetAddress addr) {\n        _remoteAddr = addr;\n    }"
        },
        "bug_report": {
            "Title": "NPE during uploading dependency artifacts with secured cluster",
            "Description": "While adding ACL to USER from uploading artifacts, \"name\" field is actually optional for thrift specification, but Nimbus reads the value without checking null while fixing ACL.\n\n{code}\n2017-05-16 14:57:02.527 o.a.s.t.s.TThreadPoolServer pool-45-thread-136 [ERROR] Error occurred during processing of message.\njava.lang.NullPointerException: null\n        at org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser(BlobStoreAclHandler.java:382) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs(BlobStoreAclHandler.java:357) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta(BlobStoreAclHandler.java:306) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.LocalFsBlobStore.createBlob(LocalFsBlobStore.java:103) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_112]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_112]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]\n        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]\n        at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.7.0.jar:?]\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.7.0.jar:?]\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9064.beginCreateBlob(nimbus.clj:2047) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3430) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3414) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n{code}\n\nUploading artifacts fails and topology submission also fails."
        }
    },
    {
        "filename": "STORM-3124.json",
        "creation_time": "2018-06-27T13:28:01.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2773) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:110) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:226) [storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:214) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\nCaused by: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:71) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:199) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:470) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:490) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:253) [storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.IllegalStateException: instance must be started before calling this method\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3024) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3511) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3490) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\nCaused by: java.lang.IllegalStateException: instance must be started before calling this method\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3024) ~[storm-server-2.0.0.y.jar:2.0.0.y]```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "        public void run() {\n            while (this.active.get()) {\n                QueueEntry queueEntry = null;\n                try {\n                    queueEntry = this.queue.peek();\n                    if ((queueEntry != null) && (Time.currentTimeMillis() >= queueEntry.endTimeMs)) {\n                        // It is imperative to not run the function\n                        // inside the timer lock. Otherwise, it is\n                        // possible to deadlock if the fn deals with\n                        // other locks, like the submit lock.\n                        this.queue.remove(queueEntry);\n                        queueEntry.func.run();\n                    } else if (queueEntry != null) {\n                        //  If any events are scheduled, sleep until\n                        // event generation. If any recurring events\n                        // are scheduled then we will always go\n                        // through this branch, sleeping only the\n                        // exact necessary amount of time. We give\n                        // an upper bound, e.g. 1000 millis, to the\n                        // sleeping time, to limit the response time\n                        // for detecting any new event within 1 secs.\n                        Time.sleep(Math.min(1000, (queueEntry.endTimeMs - Time.currentTimeMillis())));\n                    } else {\n                        // Otherwise poll to see if any new event\n                        // was scheduled. This is, in essence, the\n                        // response time for detecting any new event\n                        // schedulings when there are no scheduled\n                        // events.\n                        Time.sleep(1000);\n                    }\n                    if (Thread.interrupted()) {\n                        this.active.set(false);\n                    }\n                } catch (Throwable e) {\n                    if (!(Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e))\n                        && !(Utils.exceptionCauseIsInstanceOf(ClosedByInterruptException.class, e))) {\n                        // need to set active false before calling onKill() - current implementation does not return.\n                        this.setActive(false);\n                        this.onKill.uncaughtException(this, e);\n                    }\n                }\n            }\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children": "    public List<String> get_worker_hb_children(String path, boolean watch) {\n        int retry = maxRetries;\n        while (true) {\n            try {\n                HashSet<String> retSet = new HashSet<>();\n\n                HBMessage message = new HBMessage(HBServerMessageType.GET_ALL_NODES_FOR_PATH, HBMessageData.path(path));\n                List<HBMessage> responses = pacemakerClientPool.sendAll(message);\n                for (HBMessage response : responses) {\n                    if (response.get_type() != HBServerMessageType.GET_ALL_NODES_FOR_PATH_RESPONSE) {\n                        LOG.error(\"get_worker_hb_children: Invalid Response Type\");\n                        continue;\n                    }\n                    if (response.get_data().get_nodes().get_pulseIds() != null) {\n                        retSet.addAll(response.get_data().get_nodes().get_pulseIds());\n                    }\n                }\n\n                LOG.debug(\"Successful get_worker_hb_children\");\n                return new ArrayList<>(retSet);\n            } catch (PacemakerConnectionException e) {\n                if (retry <= 0) {\n                    throw new RuntimeException(e);\n                }\n                retry--;\n                LOG.error(\"{} Failed to get_worker_hb_children. Will make {} more attempts.\", e.getMessage(), retry);\n            } catch (InterruptedException e) {\n                LOG.debug(\"get_worker_hb_children got interrupted: {}\", e);\n                throw new RuntimeException(e);\n            }\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.PaceMakerStateStorage.get_data": "    public byte[] get_data(String path, boolean watch) {\n        return stateStorage.get_data(path, watch);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms": "    public List<String> heartbeatStorms() {\n        return stateStorage.get_worker_hb_children(ClusterUtils.WORKERBEATS_SUBTREE, false);\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClientPool.sendAll": "    public List<HBMessage> sendAll(HBMessage m) throws PacemakerConnectionException, InterruptedException {\n        List<HBMessage> responses = new ArrayList<HBMessage>();\n        LOG.debug(\"Using servers: {}\", servers);\n        for (String s : servers) {\n            try {\n                HBMessage response = getClientForServer(s).send(m);\n                responses.add(response);\n            } catch (PacemakerConnectionException e) {\n                LOG.warn(\"Failed to connect to the pacemaker server {}\", s);\n            }\n        }\n        if (responses.size() == 0) {\n            throw new PacemakerConnectionException(\"Failed to connect to any Pacemaker.\");\n        }\n        return responses;\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClientPool.getClientForServer": "    private PacemakerClient getClientForServer(String server) {\n        PacemakerClient client = clientForServer.get(server);\n        if (client == null) {\n            client = new PacemakerClient(config, server);\n            clientForServer.put(server, client);\n        }\n        return client;\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.PacemakerClientPool.send": "    public HBMessage send(HBMessage m) throws PacemakerConnectionException, InterruptedException {\n        try {\n            return getWriteClient().send(m);\n        } catch (PacemakerConnectionException e) {\n            rotateClients();\n            throw e;\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess(int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.existsNode": "    public static boolean existsNode(CuratorFramework zk, String path, boolean watch) {\n        Stat stat = null;\n        try {\n            if (watch) {\n                stat = zk.checkExists().watched().forPath(normalizePath(path));\n            } else {\n                stat = zk.checkExists().forPath(normalizePath(path));\n            }\n        } catch (Exception e) {\n            throw Utils.wrapInRuntime(e);\n        }\n        return stat != null;\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.normalizePath": "    public static String normalizePath(String path) {\n        String rtn = toksToPath(tokenizePath(path));\n        return rtn;\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl": "    public void mkdirsImpl(CuratorFramework zk, String path, List<ACL> acls) {\n        String npath = ClientZookeeper.normalizePath(path);\n        if (npath.equals(\"/\")) {\n            return;\n        }\n        if (ClientZookeeper.existsNode(zk, npath, false)) {\n            return;\n        }\n        byte[] byteArray = new byte[1];\n        byteArray[0] = (byte) 7;\n        try {\n            ClientZookeeper.createNode(zk, npath, byteArray, CreateMode.PERSISTENT, acls);\n        } catch (Exception e) {\n            if (Utils.exceptionCauseIsInstanceOf(KeeperException.NodeExistsException.class, e)) {\n                // this can happen when multiple clients doing mkdir at same time\n            }\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.createNode": "    public static String createNode(CuratorFramework zk, String path, byte[] data, List<ACL> acls) {\n        return createNode(zk, path, data, CreateMode.PERSISTENT, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.mkdirs": "    public static void mkdirs(CuratorFramework zk, String path, List<ACL> acls) {\n        _instance.mkdirsImpl(zk, path, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.ZKStateStorage.mkdirs": "    public void mkdirs(String path, List<ACL> acls) {\n        ClientZookeeper.mkdirs(zkWriter, path, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.PaceMakerStateStorage.mkdirs": "    public void mkdirs(String path, List<ACL> acls) {\n        stateStorage.mkdirs(path, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats": "    public void setupHeatbeats(String stormId, Map<String, Object> topoConf) {\n        stateStorage.mkdirs(ClusterUtils.WORKERBEATS_SUBTREE, defaultAcls);\n        stateStorage.mkdirs(ClusterUtils.workerbeatStormRoot(stormId), ClusterUtils.mkTopoReadWriteAcls(topoConf));\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_submitTopologyWithOpts": "    public void send_submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options) throws org.apache.storm.thrift.TException\n    {\n      submitTopologyWithOpts_args args = new submitTopologyWithOpts_args();\n      args.set_name(name);\n      args.set_uploadedJarLocation(uploadedJarLocation);\n      args.set_jsonConf(jsonConf);\n      args.set_topology(topology);\n      args.set_options(options);\n      sendBase(\"submitTopologyWithOpts\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public isRemoteBlobExists_result getResult(I iface, isRemoteBlobExists_args args) throws org.apache.storm.thrift.TException {\n        isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n        try {\n          result.success = iface.isRemoteBlobExists(args.blobKey);\n          result.set_success_isSet(true);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.storm.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(java.lang.String location, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public java.lang.String recv_beginFileDownload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(java.lang.String name, KillOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public java.lang.String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.storm.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(java.lang.String user, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(java.lang.String key, int replication, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(java.lang.String name, LogConfig config, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getOwnerResourceSummaries": "    public java.util.List<OwnerResourceSummary> recv_getOwnerResourceSummaries() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n      receiveBase(result, \"getOwnerResourceSummaries\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorAssignments": "    public void getSupervisorAssignments(java.lang.String node, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorAssignments_call method_call = new getSupervisorAssignments_call(node, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public java.lang.String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public java.nio.ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeat": "    public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeat_call method_call = new sendSupervisorWorkerHeartbeat_call(heatbeat, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeats": "    public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeats_call method_call = new sendSupervisorWorkerHeartbeats_call(heartbeats, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.storm.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(java.lang.String file, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.processWorkerMetrics": "    public void processWorkerMetrics(WorkerMetrics metrics, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      processWorkerMetrics_call method_call = new processWorkerMetrics_call(metrics, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isRemoteBlobExists": "    public boolean recv_isRemoteBlobExists() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n      receiveBase(result, \"isRemoteBlobExists\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isRemoteBlobExists failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public java.nio.ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public java.lang.String recv_getNimbusConf() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(java.lang.String name, Credentials creds, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isRemoteBlobExists": "    public void isRemoteBlobExists(java.lang.String blobKey, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isRemoteBlobExists_call method_call = new isRemoteBlobExists_call(blobKey, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getOwnerResourceSummaries": "    public void getOwnerResourceSummaries(java.lang.String owner, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorAssignments": "    public SupervisorAssignments recv_getSupervisorAssignments() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n      receiveBase(result, \"getSupervisorAssignments\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorAssignments failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(java.lang.String name, RebalanceOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public java.lang.String recv_beginFileUpload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public java.util.List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.storm.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public java.lang.String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.sasl.SaslTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context\n            ReqContext reqContext = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            //Sasl transport\n            TSaslServerTransport saslTrans = (TSaslServerTransport) trans;\n\n            if (trans instanceof NoOpTTrasport) {\n                return false;\n            }\n\n            //remote address\n            TSocket tsocket = (TSocket) saslTrans.getUnderlyingTransport();\n            Socket socket = tsocket.getSocket();\n            reqContext.setRemoteAddress(socket.getInetAddress());\n\n            //remote subject\n            SaslServer saslServer = saslTrans.getSaslServer();\n            String authId = saslServer.getAuthorizationID();\n            Subject remoteUser = new Subject();\n            remoteUser.getPrincipals().add(new User(authId));\n            reqContext.setSubject(remoteUser);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-client.src.jvm.org.apache.storm.cluster.ClusterUtils.mkTopoReadWriteAcls": "    public static List<ACL> mkTopoReadWriteAcls(Map<String, Object> topoConf) {\n        return mkTopoAcls(topoConf, ZooDefs.Perms.ALL);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.ClusterUtils.mkTopoAcls": "    private static List<ACL> mkTopoAcls(Map<String, Object> topoConf, int perms) {\n        List<ACL> aclList = null;\n        String payload = (String) topoConf.get(Config.STORM_ZOOKEEPER_TOPOLOGY_AUTH_PAYLOAD);\n        if (Utils.isZkAuthenticationConfiguredTopology(topoConf)) {\n            aclList = new ArrayList<>();\n            ACL acl1 = ZooDefs.Ids.CREATOR_ALL_ACL.get(0);\n            aclList.add(acl1);\n            try {\n                ACL acl2 = new ACL(perms, new Id(\"digest\", DigestAuthenticationProvider.generateDigest(payload)));\n                aclList.add(acl2);\n            } catch (NoSuchAlgorithmException e) {\n                //Should only happen on a badly configured system\n                throw new RuntimeException(e);\n            }\n        }\n        return aclList;\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.ClusterUtils.workerbeatStormRoot": "    public static String workerbeatStormRoot(String stormId) {\n        return WORKERBEATS_SUBTREE + ZK_SEPERATOR + stormId;\n    }"
        },
        "bug_report": {
            "Title": "Failures talking to Pacemaker",
            "Description": "{code:java}\r\n2018-06-25 20:21:05.220 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 7 more attempts.\r\n2018-06-25 20:21:06.220 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:06.220 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 6 more attempts.\r\n2018-06-25 20:21:07.220 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:07.221 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 5 more attempts.\r\n2018-06-25 20:21:08.221 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:08.221 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 4 more attempts.\r\n2018-06-25 20:21:09.222 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:09.222 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 3 more attempts.\r\n2018-06-25 20:21:10.222 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:10.222 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 2 more attempts.\r\n2018-06-25 20:21:11.223 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:11.223 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 1 more attempts.\r\n2018-06-25 20:21:12.223 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:12.223 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 0 more attempts.\r\n2018-06-25 20:21:13.224 o.a.s.p.PacemakerClientPool timer [WARN] Failed to connect to the pacemaker server openqe74blue-n2.blue.ygrid.yahoo.com\r\n2018-06-25 20:21:13.229 o.a.s.d.n.Nimbus pool-37-thread-481 [INFO] uploadedJar /home/y/var/storm/nimbus/inbox/stormjar-c5893ba3-21c6-4397-84e2-54aab8e091a9.jar\r\n2018-06-25 20:21:13.225 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event\r\njava.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2773) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:110) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:226) [storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:214) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\nCaused by: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:71) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:199) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-06-25 20:21:13.231 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:470) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:490) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:253) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-06-25 20:21:13.232 o.a.s.d.n.Nimbus Thread-12 [INFO] Shutting down master\r\n2018-06-25 20:21:13.232 o.a.s.u.Utils Thread-13 [INFO] Halting after 10 seconds\r\n\r\n\r\n2018-06-25 20:21:13.677 o.a.s.d.n.Nimbus pool-37-thread-481 [INFO] desired replication count 1 achieved, current-replication-count for conf key = 1, current-replication-count for code key = 1, current-replication-count for jar key = 1\r\n2018-06-25 20:21:13.678 o.a.s.d.n.Nimbus pool-37-thread-481 [WARN] Topology submission exception. (topology name='run')\r\njava.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3024) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3511) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3490) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n2018-06-25 20:21:13.680 o.a.s.t.ProcessFunction pool-37-thread-481 [ERROR] Internal error processing submitTopologyWithOpts\r\njava.lang.RuntimeException: java.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3049) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3511) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3490) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3024) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 9 more\r\n\r\n{code}\r\nWe're having sporadic failures talking to Pacemaker.\u00a0 This callstack shows us unable to launch topologies."
        }
    },
    {
        "filename": "STORM-2095.json",
        "creation_time": "2016-09-14T16:00:30.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:229)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.daemon.nimbus$setup_blobstore.invoke(nimbus.clj:1196)\n\tat org.apache.storm.daemon.nimbus$fn__7064$exec_fn__2461__auto____7065.invoke(nimbus.clj:1416)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat clojure.core$apply.invoke(core.clj:630)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)\nCaused by: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:242)\n\tat sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)\n\tat java.nio.file.Files.deleteIfExists(Files.java:1165)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.delete(FileBlobStoreImpl.java:239)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.deleteKey(FileBlobStoreImpl.java:178)\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:226)\n\t... 19 more\n\njava.lang.RuntimeException: (\"Error on initialization\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob": "    public void deleteBlob(String key, Subject who) throws AuthorizationException, KeyNotFoundException {\n        validateKey(key);\n        checkForBlobOrDownload(key);\n        SettableBlobMeta meta = getStoredBlobMeta(key);\n        _aclHandler.hasPermissions(meta.get_acl(), WRITE, who, key);\n        try {\n            fbs.deleteKey(DATA_PREFIX+key);\n            fbs.deleteKey(META_PREFIX+key);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta": "    private SettableBlobMeta getStoredBlobMeta(String key) throws KeyNotFoundException {\n        InputStream in = null;\n        try {\n            LocalFsBlobStoreFile pf = fbs.read(META_PREFIX+key);\n            try {\n                in = pf.getInputStream();\n            } catch (FileNotFoundException fnf) {\n                throw new KeyNotFoundException(key);\n            }\n            ByteArrayOutputStream out = new ByteArrayOutputStream();\n            byte [] buffer = new byte[2048];\n            int len;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n            in.close();\n            in = null;\n            return Utils.thriftDeserialize(SettableBlobMeta.class, out.toByteArray());\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        } finally {\n            if (in != null) {\n                try {\n                    in.close();\n                } catch (IOException e) {\n                    //Ignored\n                }\n            }\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.LocalFsBlobStore.checkForBlobOrDownload": "    public synchronized boolean checkForBlobOrDownload(String key) {\n        boolean checkBlobDownload = false;\n        try {\n            List<String> keyList = BlobStoreUtils.getKeyListFromBlobStore(this);\n            if (!keyList.contains(key)) {\n                if (zkClient.checkExists().forPath(BLOBSTORE_SUBTREE + key) != null) {\n                    Set<NimbusInfo> nimbusSet = BlobStoreUtils.getNimbodesWithLatestSequenceNumberOfBlob(zkClient, key);\n                    if (BlobStoreUtils.downloadMissingBlob(conf, this, key, nimbusSet)) {\n                        LOG.debug(\"Updating blobs state\");\n                        BlobStoreUtils.createStateInZookeeper(conf, key, nimbusInfo);\n                        checkBlobDownload = true;\n                    }\n                }\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n        return checkBlobDownload;\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.FileBlobStoreImpl.delete": "    protected void delete(File path) throws IOException {\n        Files.deleteIfExists(path.toPath());\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.FileBlobStoreImpl.deleteKey": "    public void deleteKey(String key) throws IOException {\n        File keyDir = getKeyDir(key);\n        LocalFsBlobStoreFile pf = new LocalFsBlobStoreFile(keyDir, BlobStoreFile.BLOBSTORE_DATA_FILE);\n        pf.delete();\n        delete(keyDir);\n    }",
            "storm-core.src.jvm.org.apache.storm.blobstore.FileBlobStoreImpl.getKeyDir": "    private File getKeyDir(String key) {\n        String hash = String.valueOf(Math.abs((long)key.hashCode()) % BUCKETS);\n        File ret = new File(new File(fullPath, hash), key);\n        LOG.debug(\"{} Looking for {} in {}\", new Object[]{fullPath, key, hash});\n        return ret;\n    }"
        },
        "bug_report": {
            "Title": "Nimbus dies and never recovers due to java.nio.file.DirectoryNotEmptyException",
            "Description": "To Recreate:\n--------------------------------------\n1) Create a blobstore key for a large file (1 or 2 GB). Size of the file does not matter if nimbus can be killed while the blob is being created.\n2) while the blob is being created, restart nimbus (this is easiest way to regenerate, there can be various reasons due to which a blob couldn't be successfully created in nimbus)\n3) When nimbus tries to start on restart, it will keep dying due to DirectoryNotEmptyException and never come up.\n\nExpected Behavior\n--------------------------------------\nPartial blobstore key is deleted cleanly and doesn't affect nimbus.\n\nThe actual, incorrect behavior.\n--------------------------------------\n2016-09-14 15:07:48.518 o.a.s.zookeeper [INFO] Queued up for leader lock.\n2016-09-14 15:07:48.576 o.a.s.zookeeper [INFO] xxx gained leadership\n2016-09-14 15:07:48.581 o.a.s.d.nimbus [ERROR] Error on initialization of server service-handler\njava.lang.RuntimeException: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:229)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.daemon.nimbus$setup_blobstore.invoke(nimbus.clj:1196)\n\tat org.apache.storm.daemon.nimbus$fn__7064$exec_fn__2461__auto____7065.invoke(nimbus.clj:1416)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat clojure.core$apply.invoke(core.clj:630)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)\nCaused by: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:242)\n\tat sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)\n\tat java.nio.file.Files.deleteIfExists(Files.java:1165)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.delete(FileBlobStoreImpl.java:239)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.deleteKey(FileBlobStoreImpl.java:178)\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:226)\n\t... 19 more\n2016-09-14 15:07:48.588 o.a.s.util [ERROR] Halting process: (\"Error on initialization\")\njava.lang.RuntimeException: (\"Error on initialization\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)\n\n\n[root]# ls -l  /opt/storm/storm-local/blobs/955/some_big_file\ntotal 591060\n-rw-r--r-- 1 storm storm 605241344 Sep 14 15:07 1473865562841.tmp"
        }
    },
    {
        "filename": "STORM-2847.json",
        "creation_time": "2017-12-07T16:51:01.000+0000",
        "stack_trace": "```\njava.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer. \nat org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262) \nat org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)\n```",
        "source_code": {
            "external.storm-kafka-client.src.main.java.org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples": "    private void commitOffsetsForAckedTuples() {\n        // Find offsets that are ready to be committed for every topic partition\n        final Map<TopicPartition, OffsetAndMetadata> nextCommitOffsets = new HashMap<>();\n        for (Map.Entry<TopicPartition, OffsetManager> tpOffset : offsetManagers.entrySet()) {\n            final OffsetAndMetadata nextCommitOffset = tpOffset.getValue().findNextCommitOffset();\n            if (nextCommitOffset != null) {\n                nextCommitOffsets.put(tpOffset.getKey(), nextCommitOffset);\n            }\n        }\n\n        // Commit offsets that are ready to be committed for every topic partition\n        if (!nextCommitOffsets.isEmpty()) {\n            kafkaConsumer.commitSync(nextCommitOffsets);\n            LOG.debug(\"Offsets successfully committed to Kafka [{}]\", nextCommitOffsets);\n            // Instead of iterating again, it would be possible to commit and update the state for each TopicPartition\n            // in the prior loop, but the multiple network calls should be more expensive than iterating twice over a small loop\n            for (Map.Entry<TopicPartition, OffsetAndMetadata> tpOffset : nextCommitOffsets.entrySet()) {\n                //Update the OffsetManager for each committed partition, and update numUncommittedOffsets\n                final TopicPartition tp = tpOffset.getKey();\n                long position = kafkaConsumer.position(tp);\n                long committedOffset = tpOffset.getValue().offset();\n                if (position < committedOffset) {\n                    /*\n                     * The position is behind the committed offset. This can happen in some cases, e.g. if a message failed,\n                     * lots of (more than max.poll.records) later messages were acked, and the failed message then gets acked. \n                     * The consumer may only be part way through \"catching up\" to where it was when it went back to retry the failed tuple. \n                     * Skip the consumer forward to the committed offset drop the current waiting to emit list,\n                     * since it'll likely contain committed offsets.\n                     */\n                    LOG.debug(\"Consumer fell behind committed offset. Catching up. Position was [{}], skipping to [{}]\",\n                        position, committedOffset);\n                    kafkaConsumer.seek(tp, committedOffset);\n                    waitingToEmit = null;\n                }\n                \n                \n                final OffsetManager offsetManager = offsetManagers.get(tp);\n                offsetManager.commit(tpOffset.getValue());\n                LOG.debug(\"[{}] uncommitted offsets for partition [{}] after commit\", offsetManager.getNumUncommittedOffsets(), tp);\n            }\n        } else {\n            LOG.trace(\"No offsets to commit. {}\", this);\n        }\n    }",
            "external.storm-kafka-client.src.main.java.org.apache.storm.kafka.spout.KafkaSpout.commit": "    private boolean commit() {\n        return isAtLeastOnceProcessing() && commitTimer.isExpiredResetOnTrue();    // timer != null for non auto commit mode\n    }"
        },
        "bug_report": {
            "Title": "Exception thrown after rebalance IllegalArgumentException",
            "Description": "After rebalance the storm-kafka-client spout attempts to check the current position of partitions that are no longer assigned to the current spout. This occurs in a topology with multiple spout instances.\r\n\r\njava.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer. at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262) at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)"
        }
    },
    {
        "filename": "STORM-1114.json",
        "creation_time": "2015-10-15T15:41:36.000+0000",
        "stack_trace": "```\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ignoreStoredMetadata\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:119) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:193) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.forPath(TransactionalState.java:83) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.createNode(TransactionalState.java:100) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.setData(TransactionalState.java:115) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        ... 9 more\n\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /rainbowHdfsPath\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.delete(TransactionalState.java:126) ~[storm-core-0.10.1.y.jar:0.10.1.y]```",
        "source_code": {
            "storm-core.src.jvm.backtype.storm.transactional.state.TransactionalState.forPath": "    protected static String forPath(PathAndBytesable<String> builder, \n            String path, byte[] data) throws Exception {\n        return (data == null) \n            ? builder.forPath(path) \n            : builder.forPath(path, data);\n    }",
            "storm-core.src.jvm.backtype.storm.transactional.state.TransactionalState.createNode": "    protected static void createNode(CuratorFramework curator, String path,\n            byte[] data, List<ACL> acls, CreateMode mode) throws Exception {\n        ProtectACLCreateModePathAndBytesable<String> builder =\n            curator.create().creatingParentsIfNeeded();\n    \n        if (acls == null) {\n            if (mode == null ) {\n                TransactionalState.forPath(builder, path, data);\n            } else {\n                TransactionalState.forPath(builder.withMode(mode), path, data);\n            }\n            return;\n        }\n\n        TransactionalState.forPath(builder.withACL(acls), path, data);\n    }",
            "storm-core.src.jvm.backtype.storm.transactional.state.TransactionalState.setData": "    public void setData(String path, Object obj) {\n        path = \"/\" + path;\n        byte[] ser = _ser.serializeObject(obj);\n        try {\n            if(_curator.checkExists().forPath(path)!=null) {\n                _curator.setData().forPath(path, ser);\n            } else {\n                TransactionalState.createNode(_curator, path, ser, _zkAcls,\n                        CreateMode.PERSISTENT);\n            }\n        } catch(Exception e) {\n            throw new RuntimeException(e);\n        }        \n    }",
            "storm-core.src.jvm.backtype.storm.transactional.state.TransactionalState.delete": "    public void delete(String path) {\n        path = \"/\" + path;\n        try {\n            _curator.delete().forPath(path);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }"
        },
        "bug_report": {
            "Title": "Racing condition in trident zookeeper zk-node create/delete",
            "Description": "In production for some trident topology, we met the bug that some workers are trying to create a zk-node that is already existent or delete a zk node that has already been deleted. This causes the worker process to die.\n \nWe dissect the problem and figure out that there exists racing condition in trident TransactionalState's zk-node create and delete codes.\n\nfailure stack trace in worker.log:\n{noformat}\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ignoreStoredMetadata\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:119) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:193) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.forPath(TransactionalState.java:83) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.createNode(TransactionalState.java:100) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.setData(TransactionalState.java:115) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        ... 9 more\n2015-10-14 18:10:43.786 b.s.util [ERROR] Halting process: (\"Worker died\")\n{noformat}\n\n\n{noformat}\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /rainbowHdfsPath\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.delete(TransactionalState.java:126) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        ... 12 more\n2015-10-14 18:10:28.799 b.s.util [ERROR] Halting process: (\"Worker died\")\njava.lang.RuntimeException: (\"Worker died\")\n{noformat}"
        }
    },
    {
        "filename": "STORM-2811.json",
        "creation_time": "2017-11-12T08:37:10.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException: null\n\tat org.apache.storm.cluster.IStormClusterState.getTopoId(IStormClusterState.java:171) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.nimbus.Nimbus.tryReadTopoConfFromName(Nimbus.java:1970) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.nimbus.Nimbus.killTopologyWithOpts(Nimbus.java:2760) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3226) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3210) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.10.0.jar:0.10.0]\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.10.0.jar:0.10.0]\n\tat org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:167) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[libthrift-0.10.0.jar:0.10.0]\n\tat org.apache.thrift.server.Invocation.run(Invocation.java:18) ~[libthrift-0.10.0.jar:0.10.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144]\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]\n```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.cluster.IStormClusterState.getTopoId": "    default Optional<String> getTopoId(final String topologyName) {\n        String ret = null;\n        for (String topoId: activeStorms()) {\n            String name = stormBase(topoId, null).get_name();\n            if (topologyName.equals(name)) {\n                ret = topoId;\n                break;\n            }\n        }\n        return Optional.ofNullable(ret);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.IStormClusterState.activeStorms": "    public List<String> activeStorms();\n\n    /**\n     * Get a storm base for a topology\n     * @param stormId the id of the topology\n     * @param callback something to call if the data changes (best effort)\n     * @return the StormBase or null if it is not alive.\n     */\n    public StormBase stormBase(String stormId, Runnable callback);\n\n    public ClusterWorkerHeartbeat getWorkerHeartbeat(String stormId, String node, Long port);\n\n    public List<ProfileRequest> getWorkerProfileRequests(String stormId, NodeInfo nodeInfo);\n\n    public List<ProfileRequest> getTopologyProfileRequests(String stormId);\n\n    public void setWorkerProfileRequest(String stormId, ProfileRequest profileRequest);\n\n    public void deleteTopologyProfileRequests(String stormId, ProfileRequest profileRequest);\n\n    public Map<ExecutorInfo, ExecutorBeat> executorBeats(String stormId, Map<List<Long>, NodeInfo> executorNodePort);\n\n    public List<String> supervisors(Runnable callback);\n\n    public SupervisorInfo supervisorInfo(String supervisorId); // returns nil if doesn't exist\n\n    public void setupHeatbeats(String stormId);\n\n    public void teardownHeartbeats(String stormId);\n\n    public void teardownTopologyErrors(String stormId);\n\n    public List<String> heartbeatStorms();\n\n    public List<String> errorTopologies();\n\n    public List<String> backpressureTopologies();\n\n    public void setTopologyLogConfig(String stormId, LogConfig logConfig);\n\n    public LogConfig topologyLogConfig(String stormId, Runnable cb);\n\n    public void workerHeartbeat(String stormId, String node, Long port, ClusterWorkerHeartbeat info);\n\n    public void removeWorkerHeartbeat(String stormId, String node, Long port);\n\n    public void supervisorHeartbeat(String supervisorId, SupervisorInfo info);\n\n    public void workerBackpressure(String stormId, String node, Long port, long timestamp);\n\n    public boolean topologyBackpressure(String stormId, long timeoutMs, Runnable callback);\n\n    public void setupBackpressure(String stormId);\n\n    public void removeBackpressure(String stormId);\n\n    public void removeWorkerBackpressure(String stormId, String node, Long port);\n\n    public void activateStorm(String stormId, StormBase stormBase);\n\n    public void updateStorm(String stormId, StormBase newElems);\n\n    public void removeStormBase(String stormId);\n\n    public void setAssignment(String stormId, Assignment info);\n\n    public void setupBlobstore(String key, NimbusInfo nimbusInfo, Integer versionInfo);\n\n    public List<String> activeKeys();\n\n    public List<String> blobstore(Runnable callback);\n\n    public void removeStorm(String stormId);\n\n    public void removeBlobstoreKey(String blobKey);\n\n    public void removeKeyVersion(String blobKey);\n\n    public void reportError(String stormId, String componentId, String node, Long port, Throwable error);\n\n    public List<ErrorInfo> errors(String stormId, String componentId);\n\n    public ErrorInfo lastError(String stormId, String componentId);\n\n    public void setCredentials(String stormId, Credentials creds, Map<String, Object> topoConf) throws NoSuchAlgorithmException;\n\n    public Credentials credentials(String stormId, Runnable callback);\n\n    public void disconnect();\n    \n    /**\n     * @return All of the supervisors with the ID as the key\n     */\n    default Map<String, SupervisorInfo> allSupervisorInfo() {\n        return allSupervisorInfo(null);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.IStormClusterState.stormBase": "    public StormBase stormBase(String stormId, Runnable callback);\n\n    public ClusterWorkerHeartbeat getWorkerHeartbeat(String stormId, String node, Long port);\n\n    public List<ProfileRequest> getWorkerProfileRequests(String stormId, NodeInfo nodeInfo);\n\n    public List<ProfileRequest> getTopologyProfileRequests(String stormId);\n\n    public void setWorkerProfileRequest(String stormId, ProfileRequest profileRequest);\n\n    public void deleteTopologyProfileRequests(String stormId, ProfileRequest profileRequest);\n\n    public Map<ExecutorInfo, ExecutorBeat> executorBeats(String stormId, Map<List<Long>, NodeInfo> executorNodePort);\n\n    public List<String> supervisors(Runnable callback);\n\n    public SupervisorInfo supervisorInfo(String supervisorId); // returns nil if doesn't exist\n\n    public void setupHeatbeats(String stormId);\n\n    public void teardownHeartbeats(String stormId);\n\n    public void teardownTopologyErrors(String stormId);\n\n    public List<String> heartbeatStorms();\n\n    public List<String> errorTopologies();\n\n    public List<String> backpressureTopologies();\n\n    public void setTopologyLogConfig(String stormId, LogConfig logConfig);\n\n    public LogConfig topologyLogConfig(String stormId, Runnable cb);\n\n    public void workerHeartbeat(String stormId, String node, Long port, ClusterWorkerHeartbeat info);\n\n    public void removeWorkerHeartbeat(String stormId, String node, Long port);\n\n    public void supervisorHeartbeat(String supervisorId, SupervisorInfo info);\n\n    public void workerBackpressure(String stormId, String node, Long port, long timestamp);\n\n    public boolean topologyBackpressure(String stormId, long timeoutMs, Runnable callback);\n\n    public void setupBackpressure(String stormId);\n\n    public void removeBackpressure(String stormId);\n\n    public void removeWorkerBackpressure(String stormId, String node, Long port);\n\n    public void activateStorm(String stormId, StormBase stormBase);\n\n    public void updateStorm(String stormId, StormBase newElems);\n\n    public void removeStormBase(String stormId);\n\n    public void setAssignment(String stormId, Assignment info);\n\n    public void setupBlobstore(String key, NimbusInfo nimbusInfo, Integer versionInfo);\n\n    public List<String> activeKeys();\n\n    public List<String> blobstore(Runnable callback);\n\n    public void removeStorm(String stormId);\n\n    public void removeBlobstoreKey(String blobKey);\n\n    public void removeKeyVersion(String blobKey);\n\n    public void reportError(String stormId, String componentId, String node, Long port, Throwable error);\n\n    public List<ErrorInfo> errors(String stormId, String componentId);\n\n    public ErrorInfo lastError(String stormId, String componentId);\n\n    public void setCredentials(String stormId, Credentials creds, Map<String, Object> topoConf) throws NoSuchAlgorithmException;\n\n    public Credentials credentials(String stormId, Runnable callback);\n\n    public void disconnect();\n    \n    /**\n     * @return All of the supervisors with the ID as the key\n     */\n    default Map<String, SupervisorInfo> allSupervisorInfo() {\n        return allSupervisorInfo(null);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(String name, KillOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_killTopologyWithOpts": "    public void send_killTopologyWithOpts(String name, KillOptions options) throws org.apache.thrift.TException\n    {\n      killTopologyWithOpts_args args = new killTopologyWithOpts_args();\n      args.set_name(name);\n      args.set_options(options);\n      sendBase(\"killTopologyWithOpts\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopologyWithOpts": "    public void recv_killTopologyWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopologyWithOpts_result result = new killTopologyWithOpts_result();\n      receiveBase(result, \"killTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public getOwnerResourceSummaries_result getResult(I iface, getOwnerResourceSummaries_args args) throws org.apache.thrift.TException {\n        getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n        try {\n          result.success = iface.getOwnerResourceSummaries(args.owner);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_setLogConfig": "    public void recv_setLogConfig() throws org.apache.thrift.TException\n    {\n      setLogConfig_result result = new setLogConfig_result();\n      receiveBase(result, \"setLogConfig\");\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(String location, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_deleteBlob": "    public void recv_deleteBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      deleteBlob_result result = new deleteBlob_result();\n      receiveBase(result, \"deleteBlob\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_createStateInZookeeper": "    public void recv_createStateInZookeeper() throws org.apache.thrift.TException\n    {\n      createStateInZookeeper_result result = new createStateInZookeeper_result();\n      receiveBase(result, \"createStateInZookeeper\");\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public String recv_beginFileDownload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(String id, ProfileRequest profileRequest, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadChunk": "    public void recv_uploadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadChunk_result result = new uploadChunk_result();\n      receiveBase(result, \"uploadChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_setWorkerProfiler": "    public void recv_setWorkerProfiler() throws org.apache.thrift.TException\n    {\n      setWorkerProfiler_result result = new setWorkerProfiler_result();\n      receiveBase(result, \"setWorkerProfiler\");\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(String user, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(String key, int replication, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(String name, LogConfig config, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getOwnerResourceSummaries": "    public List<OwnerResourceSummary> recv_getOwnerResourceSummaries() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n      receiveBase(result, \"getOwnerResourceSummaries\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_finishBlobUpload": "    public void recv_finishBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishBlobUpload_result result = new finishBlobUpload_result();\n      receiveBase(result, \"finishBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_rebalance": "    public void recv_rebalance() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      rebalance_result result = new rebalance_result();\n      receiveBase(result, \"rebalance\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopology": "    public void recv_submitTopology() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopology_result result = new submitTopology_result();\n      receiveBase(result, \"submitTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(String location, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_killTopology": "    public void recv_killTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      killTopology_result result = new killTopology_result();\n      receiveBase(result, \"killTopology\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(String name, String component, boolean enable, double samplingPercentage, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadBlobChunk": "    public void recv_uploadBlobChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      uploadBlobChunk_result result = new uploadBlobChunk_result();\n      receiveBase(result, \"uploadBlobChunk\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(String id, GetInfoOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(String id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, SubmitOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(String key, SettableBlobMeta meta, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_activate": "    public void recv_activate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      activate_result result = new activate_result();\n      receiveBase(result, \"activate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(String file, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(String session, ByteBuffer chunk, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(String name, String uploadedJarLocation, String jsonConf, StormTopology topology, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(String id, String host, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_finishFileUpload": "    public void recv_finishFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      finishFileUpload_result result = new finishFileUpload_result();\n      receiveBase(result, \"finishFileUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public String recv_getNimbusConf() throws AuthorizationException, org.apache.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_setBlobMeta": "    public void recv_setBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      setBlobMeta_result result = new setBlobMeta_result();\n      receiveBase(result, \"setBlobMeta\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(String topology_id, String component_id, String window, boolean is_include_sys, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(String name, Credentials creds, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_debug": "    public void recv_debug() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      debug_result result = new debug_result();\n      receiveBase(result, \"debug\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getOwnerResourceSummaries": "    public void getOwnerResourceSummaries(String owner, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(String session, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      if (!value) {\n        this.success = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_uploadNewCredentials": "    public void recv_uploadNewCredentials() throws NotAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      uploadNewCredentials_result result = new uploadNewCredentials_result();\n      receiveBase(result, \"uploadNewCredentials\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_deactivate": "    public void recv_deactivate() throws NotAliveException, AuthorizationException, org.apache.thrift.TException\n    {\n      deactivate_result result = new deactivate_result();\n      receiveBase(result, \"deactivate\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_cancelBlobUpload": "    public void recv_cancelBlobUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      cancelBlobUpload_result result = new cancelBlobUpload_result();\n      receiveBase(result, \"cancelBlobUpload\");\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(String name, RebalanceOptions options, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(String key, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public String recv_beginFileUpload() throws AuthorizationException, org.apache.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(String id, String component_id, ProfileAction action, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(String name, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(String id, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context \n            ReqContext req_context = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            if (trans instanceof TMemoryInputTransport) {\n                try {\n                    req_context.setRemoteAddress(InetAddress.getLocalHost());\n                } catch (UnknownHostException e) {\n                    throw new RuntimeException(e);\n                }                                \n            } else if (trans instanceof TSocket) {\n                TSocket tsocket = (TSocket)trans;\n                //remote address\n                Socket socket = tsocket.getSocket();\n                req_context.setRemoteAddress(socket.getInetAddress());                \n            } \n\n            //anonymous user\n            Subject s = getDefaultSubject();\n            if (s == null) {\n              final String user = (String)topoConf.get(\"debug.simple.transport.user\");\n              if (user != null) {\n                HashSet<Principal> principals = new HashSet<>();\n                principals.add(new Principal() {\n                  public String getName() { return user; }\n                  public String toString() { return user; }\n                });\n                s = new Subject(true, principals, new HashSet<>(), new HashSet<>());\n              }\n            }\n            req_context.setSubject(s);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-client.src.jvm.org.apache.storm.security.auth.SimpleTransportPlugin.getDefaultSubject": "    protected Subject getDefaultSubject() {\n        return null;\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.setSubject": "    public void setSubject(Subject subject) {\n        _subject = subject;\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.context": "    public static ReqContext context() {\n        return ctxt.get();\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.ReqContext.setRemoteAddress": "    public void setRemoteAddress(InetAddress addr) {\n        _remoteAddr = addr;\n    }"
        },
        "bug_report": {
            "Title": "Nimbus may throw NPE if the same topology is killed multiple times, and the integration test kills the same topology multiple times",
            "Description": "{quote}\r\n2017-11-12 08:45:50.353 o.a.s.d.n.Nimbus pool-14-thread-47 [WARN] Kill topology exception. (topology name='SlidingWindowTest-window20-slide10')\r\njava.lang.NullPointerException: null\r\n\tat org.apache.storm.cluster.IStormClusterState.getTopoId(IStormClusterState.java:171) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.daemon.nimbus.Nimbus.tryReadTopoConfFromName(Nimbus.java:1970) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.daemon.nimbus.Nimbus.killTopologyWithOpts(Nimbus.java:2760) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3226) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3210) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:167) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat org.apache.thrift.server.Invocation.run(Invocation.java:18) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144]\r\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]\r\n{quote}"
        }
    },
    {
        "filename": "STORM-2903.json",
        "creation_time": "2018-01-19T17:10:01.000+0000",
        "stack_trace": "```\nCaused by: java.lang.NullPointerException\n            at org.apache.storm.common.AbstractAutoCreds.addTokensToUGI(AbstractAutoCreds.java:219) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\n            at org.apache.storm.common.AbstractAutoCreds.populateSubject(AbstractAutoCreds.java:118) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\n            at org.apache.storm.security.auth.AuthUtils.populateSubject(AuthUtils.java:228) ~[storm-core-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.security.auth.AuthUtils.populateSubject": "    public static Subject populateSubject(Subject subject, Collection<IAutoCredentials> autos, Map<String,String> credentials) {\n        try {\n            if (subject == null) {\n                subject = new Subject();\n            }\n            for (IAutoCredentials autoCred : autos) {\n                autoCred.populateSubject(subject, credentials);\n            }\n            return subject;\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }"
        },
        "bug_report": {
            "Title": "Fix possible NullPointerException in AbstractAutoCreds",
            "Description": "Observed below exception while testing Hive token mechanism.\r\n\r\n\u00a0 \u00a0 ```\r\n\u00a0 \u00a0 Caused by: java.lang.NullPointerException\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.common.AbstractAutoCreds.addTokensToUGI(AbstractAutoCreds.java:219) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.common.AbstractAutoCreds.populateSubject(AbstractAutoCreds.java:118) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.security.auth.AuthUtils.populateSubject(AuthUtils.java:228) ~[storm-core-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ... 10 more\r\n\u00a0 \u00a0 2018-01-19 16:23:26.157 o.a.s.util main [ERROR] Halting process: (\"Error on initialization\")\r\n\u00a0 \u00a0 ```"
        }
    },
    {
        "filename": "STORM-3168.json",
        "creation_time": "2018-08-01T19:31:42.000+0000",
        "stack_trace": "```\njava.util.concurrent.ExecutionException: java.lang.RuntimeException: Could not download...\n\n        at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_131]\n\n        at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895) ~[?:1.8.0_131]\n\n        at org.apache.storm.localizer.AsyncLocalizer.updateBlobs(AsyncLocalizer.java:303) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]\n\n        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_131]\n\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n\nCaused by: java.lang.RuntimeException: Could not download...\n\n        at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:268) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]\n\n        ... 3 more\n\nCaused by: org.apache.storm.generated.KeyNotFoundException\n\n        at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25853) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25821) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$getBlobMeta_result.read(Nimbus.java:25752) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$Client.recv_getBlobMeta(Nimbus.java:798) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$Client.getBlobMeta(Nimbus.java:785) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.blobstore.NimbusBlobStore.getBlobMeta(NimbusBlobStore.java:85) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.localizer.LocallyCachedTopologyBlob.getRemoteVersion(LocallyCachedTopologyBlob.java:122) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:252) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]```",
        "source_code": {
            "storm-server.src.main.java.org.apache.storm.localizer.AsyncLocalizer.updateBlobs": "    void updateBlobs() {\n        List<CompletableFuture<?>> futures = new ArrayList<>();\n        futures.add(downloadOrUpdate(topologyBlobs.values()));\n        if (symlinksDisabled) {\n            LOG.warn(\"symlinks are disabled so blobs cannot be downloaded.\");\n        } else {\n            for (ConcurrentMap<String, LocalizedResource> map : userArchives.values()) {\n                futures.add(downloadOrUpdate(map.values()));\n            }\n\n            for (ConcurrentMap<String, LocalizedResource> map : userFiles.values()) {\n                futures.add(downloadOrUpdate(map.values()));\n            }\n        }\n        for (CompletableFuture<?> f : futures) {\n            try {\n                f.get();\n            } catch (Exception e) {\n                if (Utils.exceptionCauseIsInstanceOf(TTransportException.class, e)) {\n                    LOG.error(\"Network error while updating blobs, will retry again later\", e);\n                } else if (Utils.exceptionCauseIsInstanceOf(NimbusLeaderNotFoundException.class, e)) {\n                    LOG.error(\"Nimbus unavailable to update blobs, will retry again later\", e);\n                } else {\n                    LOG.error(\"Could not update blob, will retry again later\", e);\n                }\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.localizer.AsyncLocalizer.downloadOrUpdate": "    private CompletableFuture<Void> downloadOrUpdate(Collection<? extends LocallyCachedBlob> blobs) {\n        CompletableFuture<Void>[] all = new CompletableFuture[blobs.size()];\n        int i = 0;\n        for (final LocallyCachedBlob blob : blobs) {\n            all[i] = CompletableFuture.runAsync(() -> {\n                LOG.debug(\"STARTING download of {}\", blob);\n                try (ClientBlobStore blobStore = getClientBlobStore()) {\n                    boolean done = false;\n                    long failures = 0;\n                    while (!done) {\n                        try {\n                            synchronized (blob) {\n                                long localVersion = blob.getLocalVersion();\n                                long remoteVersion = blob.getRemoteVersion(blobStore);\n                                if (localVersion != remoteVersion || !blob.isFullyDownloaded()) {\n                                    try {\n                                        long newVersion = blob.fetchUnzipToTemp(blobStore);\n                                        blob.informAllOfChangeAndWaitForConsensus();\n                                        blob.commitNewVersion(newVersion);\n                                        blob.informAllChangeComplete();\n                                    } finally {\n                                        blob.cleanupOrphanedData();\n                                    }\n                                }\n                            }\n                            done = true;\n                        } catch (Exception e) {\n                            failures++;\n                            if (failures > blobDownloadRetries) {\n                                throw new RuntimeException(\"Could not download...\", e);\n                            }\n                            LOG.warn(\"Failed to download blob {} will try again in {} ms\", blob, ATTEMPTS_INTERVAL_TIME, e);\n                            Utils.sleep(ATTEMPTS_INTERVAL_TIME);\n                        }\n                    }\n                }\n                LOG.debug(\"FINISHED download of {}\", blob);\n            }, execService);\n            i++;\n        }\n        return CompletableFuture.allOf(all);\n    }",
            "storm-server.src.main.java.org.apache.storm.localizer.AsyncLocalizer.get": "        public Void get() {\n            try {\n                String topologyId = pna.getToplogyId();\n                String topoOwner = pna.getOwner();\n                String stormroot = ConfigUtils.supervisorStormDistRoot(conf, topologyId);\n                Map<String, Object> topoConf = ConfigUtils.readSupervisorStormConf(conf, topologyId);\n\n                @SuppressWarnings(\"unchecked\")\n                Map<String, Map<String, Object>> blobstoreMap =\n                    (Map<String, Map<String, Object>>) topoConf.get(Config.TOPOLOGY_BLOBSTORE_MAP);\n\n                List<LocalResource> localResourceList = getLocalResources(pna);\n                if (!localResourceList.isEmpty()) {\n                    File userDir = getLocalUserFileCacheDir(topoOwner);\n                    if (!fsOps.fileExists(userDir)) {\n                        fsOps.forceMkdir(userDir);\n                    }\n                    List<LocalizedResource> localizedResources = getBlobs(localResourceList, pna, cb);\n                    fsOps.setupBlobPermissions(userDir, topoOwner);\n                    if (!symlinksDisabled) {\n                        for (LocalizedResource localizedResource : localizedResources) {\n                            String keyName = localizedResource.getKey();\n                            //The sym link we are pointing to\n                            File rsrcFilePath = localizedResource.getCurrentSymlinkPath().toFile();\n\n                            String symlinkName = null;\n                            if (blobstoreMap != null) {\n                                Map<String, Object> blobInfo = blobstoreMap.get(keyName);\n                                if (blobInfo != null && blobInfo.containsKey(\"localname\")) {\n                                    symlinkName = (String) blobInfo.get(\"localname\");\n                                } else {\n                                    symlinkName = keyName;\n                                }\n                            } else {\n                                // all things are from dependencies\n                                symlinkName = keyName;\n                            }\n                            fsOps.createSymlink(new File(stormroot, symlinkName), rsrcFilePath);\n                        }\n                    }\n                }\n\n                return null;\n            } catch (Exception e) {\n                LOG.warn(\"Caught Exception While Downloading (rethrowing)... \", e);\n                throw new RuntimeException(e);\n            }\n        }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.read": "      public void read(org.apache.storm.thrift.protocol.TProtocol prot, isRemoteBlobExists_result struct) throws org.apache.storm.thrift.TException {\n        org.apache.storm.thrift.protocol.TTupleProtocol iprot = (org.apache.storm.thrift.protocol.TTupleProtocol) prot;\n        java.util.BitSet incoming = iprot.readBitSet(2);\n        if (incoming.get(0)) {\n          struct.success = iprot.readBool();\n          struct.set_success_isSet(true);\n        }\n        if (incoming.get(1)) {\n          struct.aze = new AuthorizationException();\n          struct.aze.read(iprot);\n          struct.set_aze_isSet(true);\n        }\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_id_isSet": "    public void set_id_isSet(boolean value) {\n      if (!value) {\n        this.id = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_metrics_isSet": "    public void set_metrics_isSet(boolean value) {\n      if (!value) {\n        this.metrics = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_meta_isSet": "    public void set_meta_isSet(boolean value) {\n      if (!value) {\n        this.meta = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_user_isSet": "    public void set_user_isSet(boolean value) {\n      if (!value) {\n        this.user = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_action_isSet": "    public void set_action_isSet(boolean value) {\n      if (!value) {\n        this.action = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.validate": "    public void validate() throws org.apache.storm.thrift.TException {\n      // check for required fields\n      // check for sub-struct validity\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_enable_isSet": "    public void set_enable_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __ENABLE_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_blobKey_isSet": "    public void set_blobKey_isSet(boolean value) {\n      if (!value) {\n        this.blobKey = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_aze_isSet": "    public void set_aze_isSet(boolean value) {\n      if (!value) {\n        this.aze = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_topology_id_isSet": "    public void set_topology_id_isSet(boolean value) {\n      if (!value) {\n        this.topology_id = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_chunk_isSet": "    public void set_chunk_isSet(boolean value) {\n      if (!value) {\n        this.chunk = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_is_include_sys_isSet": "    public void set_is_include_sys_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __IS_INCLUDE_SYS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_node_isSet": "    public void set_node_isSet(boolean value) {\n      if (!value) {\n        this.node = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_name_isSet": "    public void set_name_isSet(boolean value) {\n      if (!value) {\n        this.name = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_component_isSet": "    public void set_component_isSet(boolean value) {\n      if (!value) {\n        this.component = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_e_isSet": "    public void set_e_isSet(boolean value) {\n      if (!value) {\n        this.e = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_options_isSet": "    public void set_options_isSet(boolean value) {\n      if (!value) {\n        this.options = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_uploadedJarLocation_isSet": "    public void set_uploadedJarLocation_isSet(boolean value) {\n      if (!value) {\n        this.uploadedJarLocation = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_replication_isSet": "    public void set_replication_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __REPLICATION_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_window_isSet": "    public void set_window_isSet(boolean value) {\n      if (!value) {\n        this.window = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.scheme": "    private static <S extends org.apache.storm.thrift.scheme.IScheme> S scheme(org.apache.storm.thrift.protocol.TProtocol proto) {\n      return (org.apache.storm.thrift.scheme.StandardScheme.class.equals(proto.getScheme()) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY).getScheme();\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_profileRequest_isSet": "    public void set_profileRequest_isSet(boolean value) {\n      if (!value) {\n        this.profileRequest = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_heartbeats_isSet": "    public void set_heartbeats_isSet(boolean value) {\n      if (!value) {\n        this.heartbeats = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_location_isSet": "    public void set_location_isSet(boolean value) {\n      if (!value) {\n        this.location = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_host_isSet": "    public void set_host_isSet(boolean value) {\n      if (!value) {\n        this.host = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_key_isSet": "    public void set_key_isSet(boolean value) {\n      if (!value) {\n        this.key = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_component_id_isSet": "    public void set_component_id_isSet(boolean value) {\n      if (!value) {\n        this.component_id = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_kae_isSet": "    public void set_kae_isSet(boolean value) {\n      if (!value) {\n        this.kae = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_owner_isSet": "    public void set_owner_isSet(boolean value) {\n      if (!value) {\n        this.owner = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_knf_isSet": "    public void set_knf_isSet(boolean value) {\n      if (!value) {\n        this.knf = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_session_isSet": "    public void set_session_isSet(boolean value) {\n      if (!value) {\n        this.session = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_heatbeat_isSet": "    public void set_heatbeat_isSet(boolean value) {\n      if (!value) {\n        this.heatbeat = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_ite_isSet": "    public void set_ite_isSet(boolean value) {\n      if (!value) {\n        this.ite = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_ise_isSet": "    public void set_ise_isSet(boolean value) {\n      if (!value) {\n        this.ise = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_samplingPercentage_isSet": "    public void set_samplingPercentage_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SAMPLINGPERCENTAGE_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_config_isSet": "    public void set_config_isSet(boolean value) {\n      if (!value) {\n        this.config = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_creds_isSet": "    public void set_creds_isSet(boolean value) {\n      if (!value) {\n        this.creds = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_jsonConf_isSet": "    public void set_jsonConf_isSet(boolean value) {\n      if (!value) {\n        this.jsonConf = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_topology_isSet": "    public void set_topology_isSet(boolean value) {\n      if (!value) {\n        this.topology = null;\n      }\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.is_set_success": "    public boolean is_set_success() {\n      return org.apache.storm.thrift.EncodingUtils.testBit(__isset_bitfield, __SUCCESS_ISSET_ID);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_getBlobMeta": "    public void send_getBlobMeta(java.lang.String key) throws org.apache.storm.thrift.TException\n    {\n      getBlobMeta_args args = new getBlobMeta_args();\n      args.set_key(key);\n      sendBase(\"getBlobMeta\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.blobstore.NimbusBlobStore.getBlobMeta": "    public ReadableBlobMeta getBlobMeta(String key) throws AuthorizationException, KeyNotFoundException {\n        try {\n            synchronized (client) {\n                return client.getClient().getBlobMeta(key);\n            }\n        } catch (AuthorizationException | KeyNotFoundException exp) {\n            throw exp;\n        } catch (TException e) {\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocallyCachedTopologyBlob.getRemoteVersion": "    public long getRemoteVersion(ClientBlobStore store) throws KeyNotFoundException, AuthorizationException {\n        if (isLocalMode && type == TopologyBlobType.TOPO_JAR) {\n            LOG.debug(\"REMOTE VERSION LOCAL JAR {}\", LOCAL_MODE_JAR_VERSION);\n            return LOCAL_MODE_JAR_VERSION;\n        }\n        return store.getBlobMeta(type.getKey(topologyId)).get_version();\n    }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocallyCachedTopologyBlob.getKey": "        public String getKey(String topologyId) {\n            return topologyId + keySuffix;\n        }"
        },
        "bug_report": {
            "Title": "AsyncLocalizer cleanup appears to crash",
            "Description": "I was investigating these blobstore download messages which keep repeating for hours in the supervisor (and nimbus logs).\u00a0 I turned on debug logging, and was expecting a cleanup debug message every 30 seconds ([https://github.com/apache/storm/blob/master/storm-server/src/main/java/org/apache/storm/localizer/AsyncLocalizer.java#L606).]\u00a0 It did not log.\u00a0 I restarted the supervisor, and it started logging again.\u00a0 It appears to have crashed with some error.\u00a0\u00a0\r\n\r\nWe should make sure the cleanup runs continuously and logs any failures to investigate.\r\n\r\n\u00a0\r\n{code:java}\r\n2018-07-30 23:25:35.691 o.a.s.l.AsyncLocalizer AsyncLocalizer Executor - 2 [ERROR] Could not update blob, will retry again later\r\n\r\njava.util.concurrent.ExecutionException: java.lang.RuntimeException: Could not download...\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.AsyncLocalizer.updateBlobs(AsyncLocalizer.java:303) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n\r\nCaused by: java.lang.RuntimeException: Could not download...\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:268) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 ... 3 more\r\n\r\nCaused by: org.apache.storm.generated.KeyNotFoundException\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25853) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25821) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$getBlobMeta_result.read(Nimbus.java:25752) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$Client.recv_getBlobMeta(Nimbus.java:798) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$Client.getBlobMeta(Nimbus.java:785) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.blobstore.NimbusBlobStore.getBlobMeta(NimbusBlobStore.java:85) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.LocallyCachedTopologyBlob.getRemoteVersion(LocallyCachedTopologyBlob.java:122) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:252) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 ... 3 more\r\n{code}"
        }
    },
    {
        "filename": "STORM-2986.json",
        "creation_time": "2018-03-05T21:41:24.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException: null\nat java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\njava.lang.NullPointerException: null\nat java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n```",
        "source_code": {
            "storm-webapp.src.main.java.org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup": "    Set<File> selectDirsForCleanup(long nowMillis) {\n        FileFilter fileFilter = mkFileFilterForLogCleanup(nowMillis);\n\n        return Arrays.stream(logRootDir.listFiles())\n                .flatMap(topoDir -> Arrays.stream(topoDir.listFiles(fileFilter)))\n                .collect(toCollection(TreeSet::new));\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.logviewer.utils.LogCleaner.mkFileFilterForLogCleanup": "    FileFilter mkFileFilterForLogCleanup(long nowMillis) {\n        final long cutoffAgeMillis = cleanupCutoffAgeMillis(nowMillis);\n        return file -> !file.isFile() && lastModifiedTimeWorkerLogdir(file) <= cutoffAgeMillis;\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.logviewer.utils.LogCleaner.run": "    public void run() {\n        try {\n            int nowSecs = Time.currentTimeSecs();\n            Set<File> oldLogDirs = selectDirsForCleanup(nowSecs * 1000);\n\n            SortedSet<File> deadWorkerDirs = getDeadWorkerDirs(nowSecs, oldLogDirs);\n\n            LOG.debug(\"log cleanup: now={} old log dirs {} dead worker dirs {}\", nowSecs,\n                    oldLogDirs.stream().map(File::getName).collect(joining(\",\")),\n                    deadWorkerDirs.stream().map(File::getName).collect(joining(\",\")));\n\n            deadWorkerDirs.forEach(Unchecked.consumer(dir -> {\n                String path = dir.getCanonicalPath();\n                LOG.info(\"Cleaning up: Removing {}\", path);\n\n                try {\n                    Utils.forceDelete(path);\n                    cleanupEmptyTopoDirectory(dir);\n                } catch (Exception ex) {\n                    LOG.error(ex.getMessage(), ex);\n                }\n            }));\n\n            perWorkerDirCleanup(maxPerWorkerLogsSizeMb * 1024 * 1024);\n            globalLogCleanup(maxSumWorkerLogsSizeMb * 1024 * 1024);\n        } catch (Exception ex) {\n            LOG.error(\"Exception while cleaning up old log.\", ex);\n        }\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.logviewer.utils.LogCleaner.globalLogCleanup": "    int globalLogCleanup(long size) throws Exception {\n        List<File> workerDirs = new ArrayList<>(workerLogs.getAllWorkerDirs());\n        Set<String> aliveWorkerDirs = new HashSet<>(workerLogs.getAliveWorkerDirs());\n\n        return directoryCleaner.deleteOldestWhileTooLarge(workerDirs, size, false, aliveWorkerDirs);\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.logviewer.utils.LogCleaner.perWorkerDirCleanup": "    List<Integer> perWorkerDirCleanup(long size) {\n        return workerLogs.getAllWorkerDirs().stream()\n                .map(Unchecked.function(dir ->\n                        directoryCleaner.deleteOldestWhileTooLarge(Collections.singletonList(dir), size, true, null)))\n                .collect(toList());\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.logviewer.utils.LogCleaner.getDeadWorkerDirs": "    SortedSet<File> getDeadWorkerDirs(int nowSecs, Set<File> logDirs) throws Exception {\n        if (logDirs.isEmpty()) {\n            return new TreeSet<>();\n        } else {\n            Set<String> aliveIds = workerLogs.getAliveIds(nowSecs);\n            Map<String, File> idToDir = workerLogs.identifyWorkerLogDirs(logDirs);\n\n            return idToDir.entrySet().stream()\n                    .filter(entry -> !aliveIds.contains(entry.getKey()))\n                    .map(Map.Entry::getValue)\n                    .collect(toCollection(TreeSet::new));\n        }\n    }",
            "storm-webapp.src.main.java.org.apache.storm.daemon.logviewer.utils.LogCleaner.cleanupEmptyTopoDirectory": "    void cleanupEmptyTopoDirectory(File dir) throws IOException {\n        File topoDir = dir.getParentFile();\n        if (topoDir.listFiles().length == 0) {\n            Utils.forceDelete(topoDir.getCanonicalPath());\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "            public void run() {\n                func.run();\n                // This avoids a race condition with cancel-timer.\n                schedule(recurSecs, this, false, jitterMs);\n            }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }"
        },
        "bug_report": {
            "Title": "NPE from LogCleaner",
            "Description": "So I set\r\n{code:java}\r\nlogviewer.cleanup.interval.secs: 10\r\n{code}\r\nto start LogCleaner thread. But from logviewer.log:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-03-05 21:31:17.629 o.a.s.v.ConfigValidation main [WARN] storm.messaging.netty.max_retries is a deprecated config please see class org.apache.storm.Config.STORM_MESSAGING_NETTY_MAX_RETRIES for more information.\r\n2018-03-05 21:31:17.650 o.a.s.d.l.LogviewerServer main [INFO] Starting Logviewer HTTP servers...\r\n2018-03-05 21:31:17.684 o.e.j.u.log main [INFO] Logging initialized @2455ms to org.eclipse.jetty.util.log.Slf4jLog\r\n2018-03-05 21:31:17.877 o.a.s.d.l.u.LogCleaner main [INFO] configured max total size of worker logs: 2 MB, max total size of worker logs per directory: 1 MB\r\n2018-03-05 21:31:18.017 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter\r\n2018-03-05 21:31:18.022 o.a.s.d.l.u.LogCleaner logviewer-cleanup [ERROR] Exception while cleaning up old log.\r\njava.lang.NullPointerException: null\r\nat java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n2018-03-05 21:31:18.024 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...\r\n2018-03-05 21:31:18.031 o.a.s.m.StormMetricsRegistry main [INFO] Started statistics report plugin...\r\n2018-03-05 21:31:18.031 o.a.s.d.l.LogviewerServer main [INFO] Starting Logviewer...\r\n2018-03-05 21:31:18.041 o.e.j.s.Server main [INFO] jetty-9.4.7.v20170914\r\n2018-03-05 21:31:18.215 o.a.h.s.a.s.KerberosAuthenticationHandler main [INFO] Login using keytab /keytabs/HTTP.keytab, for principal HTTP/persistmist.corp.ne1.yahoo.com\r\n2018-03-05 21:31:20.832 o.h.v.i.u.Version main [INFO] HV000001: Hibernate Validator 5.3.4.Final\r\n2018-03-05 21:31:21.215 o.e.j.s.h.ContextHandler main [INFO] Started o.e.j.s.ServletContextHandler@65bb9029{/,file:///tmp/apache-storm-2.0.0-SNAPSHOT/public/,AVAILABLE}\r\n2018-03-05 21:31:21.287 o.e.j.s.AbstractConnector main [INFO] Started ServerConnector@30506c0d{HTTP/1.1,[http/1.1]}{0.0.0.0:8000}\r\n2018-03-05 21:31:21.288 o.e.j.s.Server main [INFO] Started @6060ms\r\n2018-03-05 21:31:28.038 o.a.s.d.l.u.LogCleaner logviewer-cleanup [ERROR] Exception while cleaning up old log.\r\njava.lang.NullPointerException: null\r\nat java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]{code}\r\n\u00a0\r\n\r\nIt's because there is no workers-artifacts directory at the very beginning before submitting any topologies.\u00a0 Users\u00a0can fix it by\u00a0manually creating the directory. But it's better to have it solve fixed.\u00a0"
        }
    },
    {
        "filename": "STORM-2197.json",
        "creation_time": "2016-11-10T03:57:30.000+0000",
        "stack_trace": "```\norg.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed\n\tat org.apache.thrift7.transport.TSaslTransport.receiveSaslMessage(TSaslTransport.java:199) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:277) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:145) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:141) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_60]\n\tat javax.security.auth.Subject.doAs(Subject.java:415) [?:1.7.0_60]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:140) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:48) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:103) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.<init>(ThriftClient.java:72) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.<init>(NimbusClient.java:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.getConfiguredClientAs(NimbusClient.java:82) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$nimbus_summary.invoke(core.clj:584) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$fn__10334.invoke(core.clj:1009) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$make_route$fn__7476.invoke(core.clj:93) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_route$fn__7464.invoke(core.clj:39) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_method$fn__7457.invoke(core.clj:24) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$routing$fn__7482.invoke(core.clj:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat clojure.core$some.invoke(core.clj:2515) [clojure-1.6.0.jar:?]\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.run": "                    public TTransport run() {\n                        try {\n                            return wrapped.getTransport(trans);\n                        }\n                        catch (Exception e) {\n                            LOG.debug(\"Storm server failed to open transport \" +\n                                    \"to interact with a client during session initiation: \" + e, e);\n                            return new NoOpTTrasport(null);\n                        }\n                    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.getTransport": "        public TTransport getTransport(final TTransport trans) {\n            try {\n                return Subject.doAs(subject,\n                        new PrivilegedExceptionAction<TTransport>() {\n                    public TTransport run() {\n                        try {\n                            return wrapped.getTransport(trans);\n                        }\n                        catch (Exception e) {\n                            LOG.debug(\"Storm server failed to open transport \" +\n                                    \"to interact with a client during session initiation: \" + e, e);\n                            return new NoOpTTrasport(null);\n                        }\n                    }\n                });\n            } catch (PrivilegedActionException e) {\n                LOG.error(\"Storm server experienced a PrivilegedActionException exception while creating a transport using a JAAS principal context:\" + e, e);\n                return null;\n            }\n        }",
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect": "    public TTransport connect(TTransport transport, String serverHost, String asUser) throws TTransportException, IOException {\n        //create an authentication callback handler\n        ClientCallbackHandler client_callback_handler = new ClientCallbackHandler(login_conf);\n        \n        //login our user\n        Login login = null;\n        try { \n            //specify a configuration object to be used\n            Configuration.setConfiguration(login_conf); \n            //now login\n            login  = new Login(AuthUtils.LOGIN_CONTEXT_CLIENT, client_callback_handler);\n        } catch (LoginException ex) {\n            LOG.error(\"Server failed to login in principal:\" + ex, ex);\n            throw new RuntimeException(ex);\n        }\n\n        final Subject subject = login.getSubject();\n        if (subject.getPrivateCredentials(KerberosTicket.class).isEmpty()) { //error\n            throw new RuntimeException(\"Fail to verify user principal with section \\\"\"\n                        +AuthUtils.LOGIN_CONTEXT_CLIENT+\"\\\" in login configuration file \"+ login_conf);\n        }\n\n        final String principal = StringUtils.isBlank(asUser) ? getPrincipal(subject) : asUser;\n        String serviceName = AuthUtils.get(login_conf, AuthUtils.LOGIN_CONTEXT_CLIENT, \"serviceName\");\n        if (serviceName == null) {\n            serviceName = AuthUtils.SERVICE; \n        }\n        Map<String, String> props = new TreeMap<String,String>();\n        props.put(Sasl.QOP, \"auth\");\n        props.put(Sasl.SERVER_AUTH, \"false\");\n\n        LOG.debug(\"SASL GSSAPI client transport is being established\");\n        final TTransport sasalTransport = new TSaslClientTransport(KERBEROS, \n                principal, \n                serviceName, \n                serverHost,\n                props,\n                null, \n                transport);\n\n        //open Sasl transport with the login credential\n        try {\n            Subject.doAs(subject,\n                    new PrivilegedExceptionAction<Void>() {\n                public Void run() {\n                    try {\n                        LOG.debug(\"do as:\"+ principal);\n                        sasalTransport.open();\n                    }\n                    catch (Exception e) {\n                        LOG.error(\"Client failed to open SaslClientTransport to interact with a server during session initiation: \" + e, e);\n                    }\n                    return null;\n                }\n            });\n        } catch (PrivilegedActionException e) {\n            throw new RuntimeException(e);\n        }\n\n        return sasalTransport;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.getPrincipal": "    private String getPrincipal(Subject subject) {\n        Set<Principal> principals = (Set<Principal>)subject.getPrincipals();\n        if (principals==null || principals.size()<1) {\n            LOG.info(\"No principal found in login subject\");\n            return null;\n        }\n        return ((Principal)(principals.toArray()[0])).getName();\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.TBackoffConnect.doConnectWithRetry": "    public TTransport doConnectWithRetry(ITransportPlugin transportPlugin, TTransport underlyingTransport, String host, String asUser) throws IOException {\n        boolean connected = false;\n        TTransport transportResult = null;\n        while(!connected) {\n            try {\n                transportResult = transportPlugin.connect(underlyingTransport, host, asUser);\n                connected = true;\n            } catch (TTransportException ex) {\n                retryNext(ex);\n            }\n        }\n        return transportResult;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.TBackoffConnect.retryNext": "    private void retryNext(TTransportException ex) {\n        if(!canRetry()) {\n            throw new RuntimeException(ex);\n        }\n        try {\n            int sleeptime = waitGrabber.getSleepTimeMs(_completedRetries, 0);\n\n            LOG.debug(\"Failed to connect. Retrying... (\" + Integer.toString( _completedRetries) + \") in \" + Integer.toString(sleeptime) + \"ms\");\n\n            Thread.sleep(sleeptime);\n        } catch (InterruptedException e) {\n            LOG.info(\"Nimbus connection retry interrupted.\");\n        }\n\n        _completedRetries++;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ThriftClient.reconnect": "    public synchronized void reconnect() {\n        close();    \n        try {\n            TSocket socket = new TSocket(_host, _port);\n            if(_timeout!=null) {\n                socket.setTimeout(_timeout);\n            }\n\n            //locate login configuration \n            Configuration login_conf = AuthUtils.GetConfiguration(_conf);\n\n            //construct a transport plugin\n            ITransportPlugin transportPlugin = AuthUtils.GetTransportPlugin(_type, _conf, login_conf);\n\n            //TODO get this from type instead of hardcoding to Nimbus.\n            //establish client-server transport via plugin\n            //do retries if the connect fails\n            TBackoffConnect connectionRetry \n                = new TBackoffConnect(\n                                      Utils.getInt(_conf.get(Config.STORM_NIMBUS_RETRY_TIMES)),\n                                      Utils.getInt(_conf.get(Config.STORM_NIMBUS_RETRY_INTERVAL)),\n                                      Utils.getInt(_conf.get(Config.STORM_NIMBUS_RETRY_INTERVAL_CEILING)),\n                                      _retryForever);\n            _transport = connectionRetry.doConnectWithRetry(transportPlugin, socket, _host, _asUser);\n        } catch (IOException ex) {\n            throw new RuntimeException(ex);\n        }\n        _protocol = null;\n        if (_transport != null) {\n            _protocol = new  TBinaryProtocol(_transport);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ThriftClient.close": "    public synchronized void close() {\n        if (_transport != null) {\n            _transport.close();\n            _transport = null;\n            _protocol = null;\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.NimbusClient.getConfiguredClientAs": "    public static NimbusClient getConfiguredClientAs(Map conf, String asUser) {\n        if (conf.containsKey(Config.STORM_DO_AS_USER)) {\n            if (asUser != null && !asUser.isEmpty()) {\n                LOG.warn(\"You have specified a doAsUser as param {} and a doAsParam as config, config will take precedence.\"\n                        , asUser, conf.get(Config.STORM_DO_AS_USER));\n            }\n            asUser = (String) conf.get(Config.STORM_DO_AS_USER);\n        }\n\n        List<String> seeds;\n        if(conf.containsKey(Config.NIMBUS_HOST)) {\n            LOG.warn(\"Using deprecated config {} for backward compatibility. Please update your storm.yaml so it only has config {}\",\n                    Config.NIMBUS_HOST, Config.NIMBUS_SEEDS);\n            seeds = Lists.newArrayList(conf.get(Config.NIMBUS_HOST).toString());\n        } else {\n            seeds = (List<String>) conf.get(Config.NIMBUS_SEEDS);\n        }\n\n        for (String host : seeds) {\n            int port = Integer.parseInt(conf.get(Config.NIMBUS_THRIFT_PORT).toString());\n            ClusterSummary clusterInfo;\n            try (NimbusClient client = new NimbusClient(conf, host, port, null, asUser)) {\n                clusterInfo = client.getClient().getClusterInfo();\n            } catch (Exception e) {\n                LOG.warn(\"Ignoring exception while trying to get leader nimbus info from \" + host\n                        + \". will retry with a different seed host.\", e);\n                continue;\n            }\n            List<NimbusSummary> nimbuses = clusterInfo.get_nimbuses();\n            if (nimbuses != null) {\n                for (NimbusSummary nimbusSummary : nimbuses) {\n                    if (nimbusSummary.is_isLeader()) {\n                        String leaderNimbus = nimbusSummary.get_host() + \":\" + nimbusSummary.get_port();\n                        LOG.info(\"Found leader nimbus : {}\", leaderNimbus);\n\n                        try {\n                            return new NimbusClient(conf, nimbusSummary.get_host(), nimbusSummary.get_port(), null, asUser);\n                        } catch (TTransportException e) {\n                            throw new RuntimeException(\"Failed to create a nimbus client for the leader \" + leaderNimbus, e);\n                        }\n                    }\n                }\n                throw new NimbusLeaderNotFoundException(\n                        \"Found nimbuses \" + nimbuses + \" none of which is elected as leader, please try \" +\n                        \"again after some time.\");\n            }\n        }\n        throw new NimbusLeaderNotFoundException(\n                \"Could not find leader nimbus from seed hosts \" + seeds + \". \" +\n                \"Did you specify a valid list of nimbus hosts for config \" +\n                        Config.NIMBUS_SEEDS + \"?\");\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.NimbusClient.getClient": "    public Nimbus.Client getClient() {\n        return _client;\n    }"
        },
        "bug_report": {
            "Title": "NimbusClient connectins leak due to leakage in ThriftClient.",
            "Description": "Nimbus client connections are not closed when there are errors while connecting to nimbus. Created TSocket in ThriftClient should have been closed in case of errors.\n\n2016-11-03 08:09:37.766 b.s.s.a.k.KerberosSaslTransportPlugin [ERROR] Client failed to open SaslClientTransport to interact with a server during session initiation: org.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed\norg.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed\n\tat org.apache.thrift7.transport.TSaslTransport.receiveSaslMessage(TSaslTransport.java:199) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:277) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:145) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:141) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_60]\n\tat javax.security.auth.Subject.doAs(Subject.java:415) [?:1.7.0_60]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:140) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:48) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:103) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.<init>(ThriftClient.java:72) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.<init>(NimbusClient.java:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.getConfiguredClientAs(NimbusClient.java:82) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$nimbus_summary.invoke(core.clj:584) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$fn__10334.invoke(core.clj:1009) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$make_route$fn__7476.invoke(core.clj:93) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_route$fn__7464.invoke(core.clj:39) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_method$fn__7457.invoke(core.clj:24) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$routing$fn__7482.invoke(core.clj:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat clojure.core$some.invoke(core.clj:2515) [clojure-1.6.0.jar:?]"
        }
    },
    {
        "filename": "STORM-1596.json",
        "creation_time": "2016-03-02T23:42:56.000+0000",
        "stack_trace": "```\njavax.security.sasl.SaslException: GSS initiate failed\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) ~[?:1.8.0_40]\n        at org.apache.thrift7.transport.TSaslClientTransport.handleSaslStartMessage(TSaslClientTransport.java:94) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:271) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:195) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:191) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_40]\n        at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_40]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:190) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:54) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:109) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.DRPCInvocationsClient.reconnectClient(DRPCInvocationsClient.java:57) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.reconnectClient(ReturnResults.java:113) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.execute(ReturnResults.java:103) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$tuple_action_fn__6379.invoke(executor.clj:689) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__6301.invoke(executor.clj:448) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$clojure_handler$reify__6018.onEvent(disruptor.clj:40) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:437) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:416) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$fn__6390$fn__6441.invoke(executor.clj:801) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.util$async_loop$fn__742.invoke(util.clj:482) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]\nCaused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: The ticket isn't for us (35) - BAD TGS SERVER NAME)\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:770) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.KrbException: The ticket isn't for us (35) - BAD TGS SERVER NAME\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)\n        at sun.security.krb5.internal.KDCRep.init(KDCRep.java:140) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.init(TGSRep.java:65) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.run": "                    public TTransport run() {\n                        try {\n                            return wrapped.getTransport(trans);\n                        }\n                        catch (Exception e) {\n                            LOG.debug(\"Storm server failed to open transport \" +\n                                    \"to interact with a client during session initiation: \" + e, e);\n                            return new NoOpTTrasport(null);\n                        }\n                    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.getTransport": "        public TTransport getTransport(final TTransport trans) {\n            try {\n                return Subject.doAs(subject,\n                        new PrivilegedExceptionAction<TTransport>() {\n                    public TTransport run() {\n                        try {\n                            return wrapped.getTransport(trans);\n                        }\n                        catch (Exception e) {\n                            LOG.debug(\"Storm server failed to open transport \" +\n                                    \"to interact with a client during session initiation: \" + e, e);\n                            return new NoOpTTrasport(null);\n                        }\n                    }\n                });\n            } catch (PrivilegedActionException e) {\n                LOG.error(\"Storm server experienced a PrivilegedActionException exception while creating a transport using a JAAS principal context:\" + e, e);\n                return null;\n            }\n        }",
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect": "    public TTransport connect(TTransport transport, String serverHost, String asUser) throws TTransportException, IOException {\n        //create an authentication callback handler\n        ClientCallbackHandler client_callback_handler = new ClientCallbackHandler(login_conf);\n        \n        //login our user\n        Login login = null;\n        try { \n            //specify a configuration object to be used\n            Configuration.setConfiguration(login_conf); \n            //now login\n            login  = new Login(AuthUtils.LOGIN_CONTEXT_CLIENT, client_callback_handler);\n        } catch (LoginException ex) {\n            LOG.error(\"Server failed to login in principal:\" + ex, ex);\n            throw new RuntimeException(ex);\n        }\n\n        final Subject subject = login.getSubject();\n        if (subject.getPrivateCredentials(KerberosTicket.class).isEmpty()) { //error\n            throw new RuntimeException(\"Fail to verify user principal with section \\\"\"\n                        +AuthUtils.LOGIN_CONTEXT_CLIENT+\"\\\" in login configuration file \"+ login_conf);\n        }\n\n        final String principal = StringUtils.isBlank(asUser) ? getPrincipal(subject) : asUser;\n        String serviceName = AuthUtils.get(login_conf, AuthUtils.LOGIN_CONTEXT_CLIENT, \"serviceName\");\n        if (serviceName == null) {\n            serviceName = AuthUtils.SERVICE; \n        }\n        Map<String, String> props = new TreeMap<String,String>();\n        props.put(Sasl.QOP, \"auth\");\n        props.put(Sasl.SERVER_AUTH, \"false\");\n\n        LOG.debug(\"SASL GSSAPI client transport is being established\");\n        final TTransport sasalTransport = new TSaslClientTransport(KERBEROS, \n                principal, \n                serviceName, \n                serverHost,\n                props,\n                null, \n                transport);\n\n        //open Sasl transport with the login credential\n        try {\n            Subject.doAs(subject,\n                    new PrivilegedExceptionAction<Void>() {\n                public Void run() {\n                    try {\n                        LOG.debug(\"do as:\"+ principal);\n                        sasalTransport.open();\n                    }\n                    catch (Exception e) {\n                        LOG.error(\"Client failed to open SaslClientTransport to interact with a server during session initiation: \" + e, e);\n                    }\n                    return null;\n                }\n            });\n        } catch (PrivilegedActionException e) {\n            throw new RuntimeException(e);\n        }\n\n        return sasalTransport;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.kerberos.KerberosSaslTransportPlugin.getPrincipal": "    private String getPrincipal(Subject subject) {\n        Set<Principal> principals = (Set<Principal>)subject.getPrincipals();\n        if (principals==null || principals.size()<1) {\n            LOG.info(\"No principal found in login subject\");\n            return null;\n        }\n        return ((Principal)(principals.toArray()[0])).getName();\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.TBackoffConnect.doConnectWithRetry": "    public TTransport doConnectWithRetry(ITransportPlugin transportPlugin, TTransport underlyingTransport, String host, String asUser) throws IOException {\n        boolean connected = false;\n        TTransport transportResult = null;\n        while(!connected) {\n            try {\n                transportResult = transportPlugin.connect(underlyingTransport, host, asUser);\n                connected = true;\n            } catch (TTransportException ex) {\n                retryNext(ex);\n            }\n        }\n        return transportResult;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.TBackoffConnect.retryNext": "    private void retryNext(TTransportException ex) {\n        if(!canRetry()) {\n            throw new RuntimeException(ex);\n        }\n        try {\n            int sleeptime = waitGrabber.getSleepTimeMs(_completedRetries, 0);\n\n            LOG.debug(\"Failed to connect. Retrying... (\" + Integer.toString( _completedRetries) + \") in \" + Integer.toString(sleeptime) + \"ms\");\n\n            Thread.sleep(sleeptime);\n        } catch (InterruptedException e) {\n            LOG.info(\"Nimbus connection retry interrupted.\");\n        }\n\n        _completedRetries++;\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ThriftClient.reconnect": "    public synchronized void reconnect() {\n        close();    \n        try {\n            TSocket socket = new TSocket(_host, _port);\n            if(_timeout!=null) {\n                socket.setTimeout(_timeout);\n            }\n\n            //locate login configuration \n            Configuration login_conf = AuthUtils.GetConfiguration(_conf);\n\n            //construct a transport plugin\n            ITransportPlugin transportPlugin = AuthUtils.GetTransportPlugin(_type, _conf, login_conf);\n\n            //TODO get this from type instead of hardcoding to Nimbus.\n            //establish client-server transport via plugin\n            //do retries if the connect fails\n            TBackoffConnect connectionRetry \n                = new TBackoffConnect(\n                                      Utils.getInt(_conf.get(Config.STORM_NIMBUS_RETRY_TIMES)),\n                                      Utils.getInt(_conf.get(Config.STORM_NIMBUS_RETRY_INTERVAL)),\n                                      Utils.getInt(_conf.get(Config.STORM_NIMBUS_RETRY_INTERVAL_CEILING)),\n                                      _retryForever);\n            _transport = connectionRetry.doConnectWithRetry(transportPlugin, socket, _host, _asUser);\n        } catch (IOException ex) {\n            throw new RuntimeException(ex);\n        }\n        _protocol = null;\n        if (_transport != null) {\n            _protocol = new  TBinaryProtocol(_transport);\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.security.auth.ThriftClient.close": "    public synchronized void close() {\n        if (_transport != null) {\n            _transport.close();\n            _transport = null;\n            _protocol = null;\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.drpc.DRPCInvocationsClient.reconnectClient": "    public void reconnectClient() throws TException {\n        if (client.get() == null) {\n            reconnect();\n            client.set(new DistributedRPCInvocations.Client(_protocol));\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.drpc.ReturnResults.reconnectClient": "    private void reconnectClient(DRPCInvocationsClient client) {\n        if (client instanceof DRPCInvocationsClient) {\n            try {\n                LOG.info(\"reconnecting... \");\n                client.reconnectClient(); //Blocking call\n            } catch (TException e2) {\n                LOG.error(\"Failed to connect to DRPC server\", e2);\n            }\n        }\n    }",
            "storm-core.src.jvm.org.apache.storm.drpc.ReturnResults.execute": "    public void execute(Tuple input) {\n        String result = (String) input.getValue(0);\n        String returnInfo = (String) input.getValue(1);\n        if(returnInfo!=null) {\n            Map retMap = (Map) JSONValue.parse(returnInfo);\n            final String host = (String) retMap.get(\"host\");\n            final int port = Utils.getInt(retMap.get(\"port\"));\n            String id = (String) retMap.get(\"id\");\n            DistributedRPCInvocations.Iface client;\n            if(local) {\n                client = (DistributedRPCInvocations.Iface) ServiceRegistry.getService(host);\n            } else {\n                List server = new ArrayList() {{\n                    add(host);\n                    add(port);\n                }};\n            \n                if(!_clients.containsKey(server)) {\n                    try {\n                        _clients.put(server, new DRPCInvocationsClient(_conf, host, port));\n                    } catch (TTransportException ex) {\n                        throw new RuntimeException(ex);\n                    }\n                }\n                client = _clients.get(server);\n            }\n \n\n            int retryCnt = 0;\n            int maxRetries = 3;\n            while (retryCnt < maxRetries) {\n                retryCnt++;\n                try {\n                    client.result(id, result);\n                    _collector.ack(input);\n                    break;\n                } catch (AuthorizationException aze) {\n                    LOG.error(\"Not authorized to return results to DRPC server\", aze);\n                    _collector.fail(input);\n                    throw new RuntimeException(aze);\n                } catch (TException tex) {\n                    if (retryCnt >= maxRetries) {\n                        LOG.error(\"Failed to return results to DRPC server\", tex);\n                        _collector.fail(input);\n                    }\n                    reconnectClient((DRPCInvocationsClient) client);\n                }\n            }\n        }\n    }    ",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor": "    private void consumeBatchToCursor(long cursor, EventHandler<Object> handler) {\n        for (long curr = _consumer.get() + 1; curr <= cursor; curr++) {\n            try {\n                AtomicReference<Object> mo = _buffer.get(curr);\n                Object o = mo.getAndSet(null);\n                if (o == INTERRUPT) {\n                    throw new InterruptedException(\"Disruptor processing interrupted\");\n                } else if (o == null) {\n                    LOG.error(\"NULL found in {}:{}\", this.getName(), cursor);\n                } else {\n                    handler.onEvent(o, curr, curr == cursor);\n                    if (_enableBackpressure && _cb != null && (_metrics.writePos() - curr + _overflowCount.get()) <= _lowWaterMark) {\n                        try {\n                            if (_throttleOn) {\n                                _throttleOn = false;\n                                _cb.lowWaterMark();\n                            }\n                        } catch (Exception e) {\n                            throw new RuntimeException(\"Exception during calling lowWaterMark callback!\");\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                throw new RuntimeException(e);\n            }\n        }\n        _consumer.set(cursor);\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.getName": "    public String getName() {\n        return _queueName;\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.writePos": "        public long writePos() {\n            return _buffer.getCursor();\n        }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable": "    public void consumeBatchWhenAvailable(EventHandler<Object> handler) {\n        try {\n            final long nextSequence = _consumer.get() + 1;\n            long availableSequence = _barrier.waitFor(nextSequence);\n\n            if (availableSequence >= nextSequence) {\n                consumeBatchToCursor(availableSequence, handler);\n            }\n        } catch (TimeoutException te) {\n            //Ignored\n        } catch (AlertException e) {\n            throw new RuntimeException(e);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }"
        },
        "bug_report": {
            "Title": "Multiple Subject sharing Kerberos TGT - causes services to fail",
            "Description": "With multiple threads accessing same {{Subject}}, it can cause {{ServiceTicket}} in use be by one thread be destroyed by another thread.\n\nRunning BasicDRPCTopology with high parallelism in secure cluster would reproduce the issue.\n\nHere is sample log from such a scenarios:\n{code}\n2016-01-20 15:52:26.904 o.a.t.t.TSaslTransport [ERROR] SASL negotiation failure\njavax.security.sasl.SaslException: GSS initiate failed\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) ~[?:1.8.0_40]\n        at org.apache.thrift7.transport.TSaslClientTransport.handleSaslStartMessage(TSaslClientTransport.java:94) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:271) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:195) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:191) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_40]\n        at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_40]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:190) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:54) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:109) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.DRPCInvocationsClient.reconnectClient(DRPCInvocationsClient.java:57) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.reconnectClient(ReturnResults.java:113) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.execute(ReturnResults.java:103) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$tuple_action_fn__6379.invoke(executor.clj:689) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__6301.invoke(executor.clj:448) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$clojure_handler$reify__6018.onEvent(disruptor.clj:40) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:437) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:416) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$fn__6390$fn__6441.invoke(executor.clj:801) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.util$async_loop$fn__742.invoke(util.clj:482) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]\nCaused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: The ticket isn't for us (35) - BAD TGS SERVER NAME)\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:770) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.KrbException: The ticket isn't for us (35) - BAD TGS SERVER NAME\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)\n        at sun.security.krb5.internal.KDCRep.init(KDCRep.java:140) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.init(TGSRep.java:65) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\n\n\n{code}"
        }
    },
    {
        "filename": "STORM-2142.json",
        "creation_time": "2016-10-10T04:42:01.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n        at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:468) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nCaused by: java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_66]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_66]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_66]\n        at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_66]\n        at org.codehaus.janino.ScriptEvaluator.evaluate(ScriptEvaluator.java:982) ~[dep-janino-2.7.6-dcb5bd18-a5dd-4976-a967-0108dcf46df0.jar.1475903522000:2.7.6]\nCaused by: java.lang.RuntimeException: Cannot convert null to int\n        at org.apache.calcite.runtime.SqlFunctions.cannotConvert(SqlFunctions.java:1023) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at org.apache.calcite.runtime.SqlFunctions.toInt(SqlFunctions.java:1134) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at SC.eval0(Unknown Source) ~[?:?]\n```",
        "source_code": {
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor": "    private void consumeBatchToCursor(long cursor, EventHandler<Object> handler) {\n        for (long curr = _consumer.get() + 1; curr <= cursor; curr++) {\n            try {\n                AtomicReference<Object> mo = _buffer.get(curr);\n                Object o = mo.getAndSet(null);\n                if (o == INTERRUPT) {\n                    throw new InterruptedException(\"Disruptor processing interrupted\");\n                } else if (o == null) {\n                    LOG.error(\"NULL found in {}:{}\", this.getName(), cursor);\n                } else {\n                    handler.onEvent(o, curr, curr == cursor);\n                    if (_enableBackpressure && _cb != null && (_metrics.writePos() - curr + _overflowCount.get()) <= _lowWaterMark) {\n                        try {\n                            if (_throttleOn) {\n                                _throttleOn = false;\n                                _cb.lowWaterMark();\n                            }\n                        } catch (Exception e) {\n                            throw new RuntimeException(\"Exception during calling lowWaterMark callback!\");\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                throw new RuntimeException(e);\n            }\n        }\n        _consumer.set(cursor);\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.getName": "    public String getName() {\n        return _queueName;\n    }",
            "storm-core.src.jvm.org.apache.storm.utils.DisruptorQueue.writePos": "        public long writePos() {\n            return _buffer.getCursor();\n        }"
        },
        "bug_report": {
            "Title": "ReportErrorAndDie runs suicide function only when InterruptedException or InterruptedIOException is thrown",
            "Description": "When EvaluationFilter / EvaluationFunction throws Exception, async loop for the executor is died but others will continue to work.\n\n{code}\n2016-10-08 14:12:29.597 o.a.s.u.Utils Thread-23-b-0-LOGICALFILTER_6-LOGICALPROJECT_7-executor[5 5] [ERROR] Async loop died!\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n        at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:468) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n...\nCaused by: java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_66]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_66]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_66]\n        at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_66]\n        at org.codehaus.janino.ScriptEvaluator.evaluate(ScriptEvaluator.java:982) ~[dep-janino-2.7.6-dcb5bd18-a5dd-4976-a967-0108dcf46df0.jar.1475903522000:2.7.6]\n...\nCaused by: java.lang.RuntimeException: Cannot convert null to int\n        at org.apache.calcite.runtime.SqlFunctions.cannotConvert(SqlFunctions.java:1023) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at org.apache.calcite.runtime.SqlFunctions.toInt(SqlFunctions.java:1134) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at SC.eval0(Unknown Source) ~[?:?]\n{code}\n\nWhile looking into detail, I found that ReportErrorAndDie implementation seems odd - completely opposite behavior compared to 1.x :report-error-and-die.\nWhen InterruptedException or InterruptedIOException is thrown, it should just leave a log and shouldn't run suicide function. For others it should run suicide function."
        }
    },
    {
        "filename": "STORM-2400.json",
        "creation_time": "2017-03-08T04:32:34.000+0000",
        "stack_trace": "```\norg.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\nat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:304)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:293)\nat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:290)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:281)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:42)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.participantForPath(LeaderSelector.java:375)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.getLeader(LeaderSelector.java:346)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderLatch.getLeader(LeaderLatch.java:454)\n```",
        "source_code": {},
        "bug_report": {
            "Title": "Intermittent failure in nimbus because of errors from LeaderLatch#getLeader()",
            "Description": "This issue is reported to Curator with CURATOR-358. \n\norg.apache.curator.framework.recipes.leader.LeaderLatch#getLeader() throws KeeperException with Code#NONODE intermittently as mentioned in the stack trace below. It may be possible participant's ephemeral ZK node is removed because its connection/session is closed.\n\nYou can see the below code at https://github.com/apache/curator/blob/master/curator-recipes/src/main/java/org/apache/curator/framework/recipes/leader/LeaderLatch.java#L451\n\n{code}\npublic Participant getLeader() throws Exception\n{ \n  Collection<String> participantNodes = LockInternals.getParticipantNodes(client, latchPath, LOCK_NAME, sorter); \n  return LeaderSelector.getLeader(client, participantNodes); \n}\n{code}\n\nI guess it hits a race condition where a participant node is retrieved but when it invokes LeaderSelector#getLeader() it would have been removed because of session timeout and it throws KeeperException with NoNode code. It does not retry as the RetryLoop retries only for connection/session timeouts. But in this case, NoNode should have been retried. I could not find any APIs on CuratorClient to configure the kind of KeeperException codes to be retried. It may be good to have a way to take what kind of errors should be retried in org.apache.curator.framework.CuratorFrameworkFactory.Builder APIs.\nIntermittent Exception found with the stack trace:\n\n{noformat}\n2016-11-15 06:09:33.954 o.a.s.d.nimbus [ERROR] Error when processing event\norg.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\nat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:304)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:293)\nat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:290)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:281)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:42)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.participantForPath(LeaderSelector.java:375)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.getLeader(LeaderSelector.java:346)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderLatch.getLeader(LeaderLatch.java:454)\n{noformat}"
        }
    },
    {
        "filename": "STORM-3084.json",
        "creation_time": "2018-05-24T20:45:32.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.NullPointerException\n\tat org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.NullPointerException\n\tat org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\t... 2 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n\tat org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "        public void run() {\n            while (this.active.get()) {\n                QueueEntry queueEntry = null;\n                try {\n                    queueEntry = this.queue.peek();\n                    if ((queueEntry != null) && (Time.currentTimeMillis() >= queueEntry.endTimeMs)) {\n                        // It is imperative to not run the function\n                        // inside the timer lock. Otherwise, it is\n                        // possible to deadlock if the fn deals with\n                        // other locks, like the submit lock.\n                        this.queue.remove(queueEntry);\n                        queueEntry.func.run();\n                    } else if (queueEntry != null) {\n                        //  If any events are scheduled, sleep until\n                        // event generation. If any recurring events\n                        // are scheduled then we will always go\n                        // through this branch, sleeping only the\n                        // exact necessary amount of time. We give\n                        // an upper bound, e.g. 1000 millis, to the\n                        // sleeping time, to limit the response time\n                        // for detecting any new event within 1 secs.\n                        Time.sleep(Math.min(1000, (queueEntry.endTimeMs - Time.currentTimeMillis())));\n                    } else {\n                        // Otherwise poll to see if any new event\n                        // was scheduled. This is, in essence, the\n                        // response time for detecting any new event\n                        // schedulings when there are no scheduled\n                        // events.\n                        Time.sleep(1000);\n                    }\n                    if (Thread.interrupted()) {\n                        this.active.set(false);\n                    }\n                } catch (Throwable e) {\n                    if (!(Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e))\n                        && !(Utils.exceptionCauseIsInstanceOf(ClosedByInterruptException.class, e))) {\n                        this.onKill.uncaughtException(this, e);\n                        this.setActive(false);\n                    }\n                }\n            }\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess(int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }"
        },
        "bug_report": {
            "Title": "2.x NPE on Nimbus startup",
            "Description": "{code:java}\r\n2018-05-24 09:27:05.636 o.a.s.d.n.Nimbus main [INFO] Starting nimbus server for storm version '2.0.0.y' 2018-05-24 09:27:06.012 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event java.lang.RuntimeException: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y] at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y] Caused by: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y] ... 2 more 2018-05-24 09:27:06.023 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event java.lang.RuntimeException: Halting process: Error while processing event at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y] 2018-05-24 09:27:06.032 o.a.s.d.n.Nimbus Thread-12 [INFO] Shutting down master 2018-05-24 09:27:06.032 o.a.s.u.Utils Thread-13 [INFO] Halting after 5 seconds\r\n{code}"
        }
    },
    {
        "filename": "STORM-3118.json",
        "creation_time": "2018-06-21T13:46:08.000+0000",
        "stack_trace": "```\norg.apache.storm.shade.io.netty.handler.codec.EncoderException: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:106) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1066) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:305) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive(KerberosSaslClientHandler.java:65) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelInboundHandlerAdapter.java:64) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline$HeadContext.channelActive(DefaultChannelPipeline.java:1422) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.fireChannelActive(DefaultChannelPipeline.java:941) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:311) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:341) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:635) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\nCaused by: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:276) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.writeShort(AbstractByteBuf.java:966) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.messaging.netty.SaslMessageToken.write(SaslMessageToken.java:104) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encodeNettySerializable(ThriftEncoder.java:44) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encode(ThriftEncoder.java:77) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        ... 26 more\n\njava.lang.IllegalStateException: instance must be started before calling this method\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3009) [storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive": "    public void channelActive(ChannelHandlerContext ctx) {\n        // register the newly established channel\n        Channel channel = ctx.channel();\n\n        LOG.info(\"Connection established from {} to {}\",\n                 channel.localAddress(), channel.remoteAddress());\n\n        try {\n            KerberosSaslNettyClient saslNettyClient = channel.attr(KerberosSaslNettyClientState.KERBEROS_SASL_NETTY_CLIENT).get();\n\n            if (saslNettyClient == null) {\n                LOG.debug(\"Creating saslNettyClient now for channel: {}\",\n                          channel);\n                saslNettyClient = new KerberosSaslNettyClient(topoConf, jaas_section, host);\n                channel.attr(KerberosSaslNettyClientState.KERBEROS_SASL_NETTY_CLIENT).set(saslNettyClient);\n            }\n            LOG.debug(\"Going to initiate Kerberos negotiations.\");\n            byte[] initialChallenge = saslNettyClient.saslResponse(new SaslMessageToken(new byte[0]));\n            LOG.debug(\"Sending initial challenge: {}\", initialChallenge);\n            channel.writeAndFlush(new SaslMessageToken(initialChallenge), channel.voidPromise());\n        } catch (Exception e) {\n            LOG.error(\"Failed to authenticate with server due to error: \",\n                      e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.messaging.netty.SaslMessageToken.write": "    public void write(ByteBuf dest) {\n        int payload_len = 0;\n        if (token != null) {\n            payload_len = token.length;\n        }\n\n        dest.writeShort(IDENTIFIER);\n        dest.writeInt(payload_len);\n\n        if (payload_len > 0) {\n            dest.writeBytes(token);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.codec.ThriftEncoder.encodeNettySerializable": "    private HBMessage encodeNettySerializable(ByteBufAllocator alloc,\n        INettySerializable netty_message, HBServerMessageType mType) {\n\n        HBMessageData message_data = new HBMessageData();\n        HBMessage m = new HBMessage();\n        byte[] messageBuffer = new byte[netty_message.encodeLength()];\n        ByteBuf wrappedBuffer = Unpooled.wrappedBuffer(messageBuffer);\n        try {\n            netty_message.write(wrappedBuffer);\n            \n            message_data.set_message_blob(messageBuffer);\n            m.set_type(mType);\n            m.set_data(message_data);\n            return m;\n        } finally {\n            wrappedBuffer.release();\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.pacemaker.codec.ThriftEncoder.encode": "    protected void encode(ChannelHandlerContext channelHandlerContext, Object msg, List<Object> out) throws Exception {\n        if (msg == null) {\n            return;\n        }\n\n        LOG.debug(\"Trying to encode: \" + msg.getClass().toString() + \" : \" + msg.toString());\n\n        HBMessage m;\n        ByteBufAllocator alloc = channelHandlerContext.alloc();\n        if (msg instanceof INettySerializable) {\n            INettySerializable nettyMsg = (INettySerializable) msg;\n\n            HBServerMessageType type;\n            if (msg instanceof ControlMessage) {\n                type = HBServerMessageType.CONTROL_MESSAGE;\n            } else if (msg instanceof SaslMessageToken) {\n                type = HBServerMessageType.SASL_MESSAGE_TOKEN;\n            } else {\n                LOG.error(\"Didn't recognise INettySerializable: \" + nettyMsg.toString());\n                throw new RuntimeException(\"Unrecognized INettySerializable.\");\n            }\n            m = encodeNettySerializable(alloc, nettyMsg, type);\n        } else {\n            m = (HBMessage) msg;\n        }\n\n        try {\n            byte serialized[] = Utils.thriftSerialize(m);\n            ByteBuf ret = alloc.ioBuffer(serialized.length + 4);\n\n            ret.writeInt(serialized.length);\n            ret.writeBytes(serialized);\n\n            out.add(ret);\n        } catch (RuntimeException e) {\n            LOG.error(\"Failed to serialize.\", e);\n            throw e;\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.existsNode": "    public static boolean existsNode(CuratorFramework zk, String path, boolean watch) {\n        Stat stat = null;\n        try {\n            if (watch) {\n                stat = zk.checkExists().watched().forPath(normalizePath(path));\n            } else {\n                stat = zk.checkExists().forPath(normalizePath(path));\n            }\n        } catch (Exception e) {\n            throw Utils.wrapInRuntime(e);\n        }\n        return stat != null;\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.normalizePath": "    public static String normalizePath(String path) {\n        String rtn = toksToPath(tokenizePath(path));\n        return rtn;\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl": "    public void mkdirsImpl(CuratorFramework zk, String path, List<ACL> acls) {\n        String npath = ClientZookeeper.normalizePath(path);\n        if (npath.equals(\"/\")) {\n            return;\n        }\n        if (ClientZookeeper.existsNode(zk, npath, false)) {\n            return;\n        }\n        byte[] byteArray = new byte[1];\n        byteArray[0] = (byte) 7;\n        try {\n            ClientZookeeper.createNode(zk, npath, byteArray, CreateMode.PERSISTENT, acls);\n        } catch (Exception e) {\n            if (Utils.exceptionCauseIsInstanceOf(KeeperException.NodeExistsException.class, e)) {\n                // this can happen when multiple clients doing mkdir at same time\n            }\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.createNode": "    public static String createNode(CuratorFramework zk, String path, byte[] data, List<ACL> acls) {\n        return createNode(zk, path, data, CreateMode.PERSISTENT, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.zookeeper.ClientZookeeper.mkdirs": "    public static void mkdirs(CuratorFramework zk, String path, List<ACL> acls) {\n        _instance.mkdirsImpl(zk, path, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.ZKStateStorage.mkdirs": "    public void mkdirs(String path, List<ACL> acls) {\n        ClientZookeeper.mkdirs(zkWriter, path, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.PaceMakerStateStorage.mkdirs": "    public void mkdirs(String path, List<ACL> acls) {\n        stateStorage.mkdirs(path, acls);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats": "    public void setupHeatbeats(String stormId, Map<String, Object> topoConf) {\n        stateStorage.mkdirs(ClusterUtils.WORKERBEATS_SUBTREE, defaultAcls);\n        stateStorage.mkdirs(ClusterUtils.workerbeatStormRoot(stormId), ClusterUtils.mkTopoReadWriteAcls(topoConf));\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_submitTopologyWithOpts": "    public void send_submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options) throws org.apache.storm.thrift.TException\n    {\n      submitTopologyWithOpts_args args = new submitTopologyWithOpts_args();\n      args.set_name(name);\n      args.set_uploadedJarLocation(uploadedJarLocation);\n      args.set_jsonConf(jsonConf);\n      args.set_topology(topology);\n      args.set_options(options);\n      sendBase(\"submitTopologyWithOpts\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public isRemoteBlobExists_result getResult(I iface, isRemoteBlobExists_args args) throws org.apache.storm.thrift.TException {\n        isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n        try {\n          result.success = iface.isRemoteBlobExists(args.blobKey);\n          result.set_success_isSet(true);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.storm.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(java.lang.String location, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public java.lang.String recv_beginFileDownload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(java.lang.String name, KillOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public java.lang.String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.storm.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(java.lang.String user, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(java.lang.String key, int replication, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(java.lang.String name, LogConfig config, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getOwnerResourceSummaries": "    public java.util.List<OwnerResourceSummary> recv_getOwnerResourceSummaries() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n      receiveBase(result, \"getOwnerResourceSummaries\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorAssignments": "    public void getSupervisorAssignments(java.lang.String node, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorAssignments_call method_call = new getSupervisorAssignments_call(node, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public java.lang.String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public java.nio.ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeat": "    public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeat_call method_call = new sendSupervisorWorkerHeartbeat_call(heatbeat, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeats": "    public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeats_call method_call = new sendSupervisorWorkerHeartbeats_call(heartbeats, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.storm.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(java.lang.String file, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.processWorkerMetrics": "    public void processWorkerMetrics(WorkerMetrics metrics, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      processWorkerMetrics_call method_call = new processWorkerMetrics_call(metrics, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isRemoteBlobExists": "    public boolean recv_isRemoteBlobExists() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n      receiveBase(result, \"isRemoteBlobExists\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isRemoteBlobExists failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public java.nio.ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public java.lang.String recv_getNimbusConf() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(java.lang.String name, Credentials creds, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isRemoteBlobExists": "    public void isRemoteBlobExists(java.lang.String blobKey, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isRemoteBlobExists_call method_call = new isRemoteBlobExists_call(blobKey, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getOwnerResourceSummaries": "    public void getOwnerResourceSummaries(java.lang.String owner, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorAssignments": "    public SupervisorAssignments recv_getSupervisorAssignments() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n      receiveBase(result, \"getSupervisorAssignments\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorAssignments failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(java.lang.String name, RebalanceOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public java.lang.String recv_beginFileUpload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public java.util.List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.storm.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public java.lang.String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.sasl.SaslTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context\n            ReqContext reqContext = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            //Sasl transport\n            TSaslServerTransport saslTrans = (TSaslServerTransport) trans;\n\n            if (trans instanceof NoOpTTrasport) {\n                return false;\n            }\n\n            //remote address\n            TSocket tsocket = (TSocket) saslTrans.getUnderlyingTransport();\n            Socket socket = tsocket.getSocket();\n            reqContext.setRemoteAddress(socket.getInetAddress());\n\n            //remote subject\n            SaslServer saslServer = saslTrans.getSaslServer();\n            String authId = saslServer.getAuthorizationID();\n            Subject remoteUser = new Subject();\n            remoteUser.getPrincipals().add(new User(authId));\n            reqContext.setSubject(remoteUser);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }",
            "storm-client.src.jvm.org.apache.storm.messaging.netty.KerberosSaslNettyClient.saslResponse": "    public byte[] saslResponse(SaslMessageToken saslTokenMessage) {\n        try {\n            final SaslMessageToken fSaslTokenMessage = saslTokenMessage;\n            byte[] retval = Subject.doAs(subject, new PrivilegedExceptionAction<byte[]>() {\n                public byte[] run() {\n                    try {\n                        byte[] retval = saslClient.evaluateChallenge(fSaslTokenMessage\n                                                                         .getSaslToken());\n                        return retval;\n                    } catch (SaslException e) {\n                        LOG.error(\"saslResponse: Failed to respond to SASL server's token:\",\n                                  e);\n                        throw new RuntimeException(e);\n                    }\n                }\n            });\n            return retval;\n        } catch (PrivilegedActionException e) {\n            LOG.error(\"Failed to generate response for token: \", e);\n            throw new RuntimeException(e);\n        }\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.ClusterUtils.mkTopoReadWriteAcls": "    public static List<ACL> mkTopoReadWriteAcls(Map<String, Object> topoConf) {\n        return mkTopoAcls(topoConf, ZooDefs.Perms.ALL);\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.ClusterUtils.mkTopoAcls": "    private static List<ACL> mkTopoAcls(Map<String, Object> topoConf, int perms) {\n        List<ACL> aclList = null;\n        String payload = (String) topoConf.get(Config.STORM_ZOOKEEPER_TOPOLOGY_AUTH_PAYLOAD);\n        if (Utils.isZkAuthenticationConfiguredTopology(topoConf)) {\n            aclList = new ArrayList<>();\n            ACL acl1 = ZooDefs.Ids.CREATOR_ALL_ACL.get(0);\n            aclList.add(acl1);\n            try {\n                ACL acl2 = new ACL(perms, new Id(\"digest\", DigestAuthenticationProvider.generateDigest(payload)));\n                aclList.add(acl2);\n            } catch (NoSuchAlgorithmException e) {\n                //Should only happen on a badly configured system\n                throw new RuntimeException(e);\n            }\n        }\n        return aclList;\n    }",
            "storm-client.src.jvm.org.apache.storm.cluster.ClusterUtils.workerbeatStormRoot": "    public static String workerbeatStormRoot(String stormId) {\n        return WORKERBEATS_SUBTREE + ZK_SEPERATOR + stormId;\n    }"
        },
        "bug_report": {
            "Title": "Netty incompatibilities with Pacemaker",
            "Description": "Nimbus has issues with Pacemaker:\r\n{code:java}\r\n2018-06-21 08:55:17.762 o.a.s.p.PacemakerClientHandler client-worker-2 [ERROR] Exception occurred in Pacemaker.\r\norg.apache.storm.shade.io.netty.handler.codec.EncoderException: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\r\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:106) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1066) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:305) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive(KerberosSaslClientHandler.java:65) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelInboundHandlerAdapter.java:64) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline$HeadContext.channelActive(DefaultChannelPipeline.java:1422) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.fireChannelActive(DefaultChannelPipeline.java:941) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:311) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:341) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:635) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\r\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:276) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.writeShort(AbstractByteBuf.java:966) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.messaging.netty.SaslMessageToken.write(SaslMessageToken.java:104) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encodeNettySerializable(ThriftEncoder.java:44) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encode(ThriftEncoder.java:77) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        ... 26 more\r\n{code}\r\nPrevents topology submission:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-06-21 09:10:46.343 o.a.s.d.n.Nimbus pool-37-thread-250 [WARN] Topology submission exception. (topology name='testStormKafkaNewApi')\r\njava.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3009) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n{code}"
        }
    },
    {
        "filename": "STORM-2158.json",
        "creation_time": "2016-10-20T12:56:58.000+0000",
        "stack_trace": "```\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57) ~[?:1.8.0_92-internal]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335) ~[?:1.8.0_92-internal]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:371) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:203) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:207) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:158) [storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n```",
        "source_code": {},
        "bug_report": {
            "Title": "OutOfMemoryError in Nimbus' SimpleTransportPlugin",
            "Description": "{{OutOfMemoryError}} is thrown by Nimbus' {{SimpleTransportPlugin}} if malformed Thrift request is posted:\n{code}\necho \"Hello\" | nc localhost 6627\n{code}\n\nIn nimbus.log:\n{noformat}\n2016-10-20 12:54:09.978 b.s.d.nimbus [INFO] Starting Nimbus server...\n2016-10-20 12:54:42.926 o.a.t.s.THsHaServer [ERROR] run() exiting due to uncaught error\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57) ~[?:1.8.0_92-internal]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335) ~[?:1.8.0_92-internal]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:371) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:203) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:207) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:158) [storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n2016-10-20 12:54:42.942 b.s.d.nimbus [INFO] Shutting down master\n2016-10-20 12:54:43.003 b.s.d.nimbus [INFO] Shut down master\n{noformat}\n\nThe problem is caused by the lack of specification of the {{maxReadBufferBytes}} of {{THsHaServer}}'s arguments."
        }
    },
    {
        "filename": "STORM-2682.json",
        "creation_time": "2017-08-07T15:20:27.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException: null\n        at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:1.8.0_121]\n        at org.apache.storm.localizer.Localizer.updateBlobs(Localizer.java:332) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology(UpdateBlobs.java:99) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run(UpdateBlobs.java:72) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:54) ~[storm-core-1.0.4.jar:1.0.4]\n\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1750) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:63) ~[storm-core-1.0.4.jar:1.0.4]\n```",
        "source_code": {
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.updateBlobs": "  public List<LocalizedResource> updateBlobs(List<LocalResource> localResources,\n       String user) throws AuthorizationException, KeyNotFoundException, IOException {\n    LocalizedResourceSet lrsrcSet = _userRsrc.get(user);\n    ArrayList<LocalizedResource> results = new ArrayList<>();\n    ArrayList<Callable<LocalizedResource>> updates = new ArrayList<>();\n\n    if (lrsrcSet == null) {\n      // resource set must have been removed\n      return results;\n    }\n    ClientBlobStore blobstore = null;\n    try {\n      blobstore = getClientBlobStore();\n      for (LocalResource localResource: localResources) {\n        String key = localResource.getBlobName();\n        LocalizedResource lrsrc = lrsrcSet.get(key, localResource.shouldUncompress());\n        if (lrsrc == null) {\n          LOG.warn(\"blob requested for update doesn't exist: {}\", key);\n          continue;\n        } else if ((boolean)_conf.getOrDefault(Config.DISABLE_SYMLINKS, false)) {\n          LOG.warn(\"symlinks are disabled so blobs cannot be downloaded.\");\n          continue;\n        } else {\n          // update it if either the version isn't the latest or if any local blob files are missing\n          if (!isLocalizedResourceUpToDate(lrsrc, blobstore) ||\n              !isLocalizedResourceDownloaded(lrsrc)) {\n            LOG.debug(\"updating blob: {}\", key);\n            updates.add(new DownloadBlob(this, _conf, key, new File(lrsrc.getFilePath()), user,\n                lrsrc.isUncompressed(), true));\n          }\n        }\n      }\n    } finally {\n      if(blobstore != null) {\n        blobstore.shutdown();\n      }\n    }\n    try {\n      List<Future<LocalizedResource>> futures = _updateExecService.invokeAll(updates);\n      for (Future<LocalizedResource> futureRsrc : futures) {\n        try {\n          LocalizedResource lrsrc = futureRsrc.get();\n          // put the resource just in case it was removed at same time by the cleaner\n          LocalizedResourceSet newSet = new LocalizedResourceSet(user);\n          LocalizedResourceSet newlrsrcSet = _userRsrc.putIfAbsent(user, newSet);\n          if (newlrsrcSet == null) {\n            newlrsrcSet = newSet;\n          }\n          newlrsrcSet.putIfAbsent(lrsrc.getKey(), lrsrc, lrsrc.isUncompressed());\n          results.add(lrsrc);\n        }\n        catch (ExecutionException e) {\n          LOG.error(\"Error updating blob: \", e);\n          if (e.getCause() instanceof AuthorizationException) {\n            throw (AuthorizationException)e.getCause();\n          }\n          if (e.getCause() instanceof KeyNotFoundException) {\n            throw (KeyNotFoundException)e.getCause();\n          }\n        }\n      }\n    } catch (RejectedExecutionException re) {\n      LOG.error(\"Error updating blobs : \", re);\n    } catch (InterruptedException ie) {\n      throw new IOException(\"Interrupted Exception\", ie);\n    }\n    return results;\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.isLocalizedResourceDownloaded": "  protected boolean isLocalizedResourceDownloaded(LocalizedResource lrsrc) {\n    File rsrcFileCurrent = new File(lrsrc.getCurrentSymlinkPath());\n    File rsrcFileWithVersion = new File(lrsrc.getFilePathWithVersion());\n    File versionFile = new File(lrsrc.getVersionFilePath());\n    return (rsrcFileWithVersion.exists() && rsrcFileCurrent.exists() && versionFile.exists());\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.shutdown": "  public void shutdown() {\n    if (_cacheCleanupService != null) {\n      _cacheCleanupService.shutdown();\n    }\n    if (_execService != null) {\n      _execService.shutdown();\n    }\n    if (_updateExecService != null) {\n      _updateExecService.shutdown();\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.getClientBlobStore": "  protected ClientBlobStore getClientBlobStore() {\n    return ServerUtils.getClientBlobStoreForSupervisor(_conf);\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.Localizer.isLocalizedResourceUpToDate": "  protected boolean isLocalizedResourceUpToDate(LocalizedResource lrsrc,\n      ClientBlobStore blobstore) throws AuthorizationException, KeyNotFoundException {\n    String localFile = lrsrc.getFilePath();\n    long nimbusBlobVersion = ServerUtils.nimbusVersionOfBlob(lrsrc.getKey(), blobstore);\n    long currentBlobVersion = ServerUtils.localVersionOfBlob(localFile);\n    return (nimbusBlobVersion == currentBlobVersion);\n  }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology": "    private void updateBlobsForTopology(Map<String, Object> conf, String stormId, Localizer localizer, String user) throws IOException {\n        Map<String, Object> topoConf = ConfigUtils.readSupervisorStormConf(conf, stormId);\n        Map<String, Map<String, Object>> blobstoreMap = (Map<String, Map<String, Object>>) topoConf.get(Config.TOPOLOGY_BLOBSTORE_MAP);\n        List<LocalResource> localresources = SupervisorUtils.blobstoreMapToLocalresources(blobstoreMap);\n        try {\n            localizer.updateBlobs(localresources, user);\n        } catch (AuthorizationException authExp) {\n            LOG.error(\"AuthorizationException error\", authExp);\n        } catch (KeyNotFoundException knf) {\n            LOG.error(\"KeyNotFoundException error\", knf);\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run": "    public void run() {\n        try {\n            Map<String, Object> conf = supervisor.getConf();\n            Set<String> downloadedStormIds = SupervisorUtils.readDownloadedTopologyIds(conf);\n            AtomicReference<Map<Long, LocalAssignment>> newAssignment = supervisor.getCurrAssignment();\n            Map<String, LocalAssignment> assignedStormIds = new HashMap<>();\n            for (LocalAssignment localAssignment : newAssignment.get().values()) {\n                assignedStormIds.put(localAssignment.get_topology_id(), localAssignment);\n            }\n            for (String stormId : downloadedStormIds) {\n                LocalAssignment la = assignedStormIds.get(stormId);\n                if (la != null) {\n                    String stormRoot = ConfigUtils.supervisorStormDistRoot(conf, stormId);\n                    LOG.debug(\"Checking Blob updates for storm topology id {} With target_dir: {}\", stormId, stormRoot);\n                    updateBlobsForTopology(conf, stormId, supervisor.getLocalizer(), la.get_owner());\n                }\n            }\n        } catch (Exception e) {\n            if (Utils.exceptionCauseIsInstanceOf(TTransportException.class, e)) {\n                LOG.error(\"Network error while updating blobs, will retry again later\", e);\n            } else if (Utils.exceptionCauseIsInstanceOf(NimbusLeaderNotFoundException.class, e)) {\n                LOG.error(\"Nimbus unavailable to update blobs, will retry again later\", e);\n            } else {\n                throw Utils.wrapInRuntime(e);\n            }\n        }\n    }",
            "storm-server.src.main.java.org.apache.storm.event.EventManagerImp.run": "            public void run() {\n                while (running.get()) {\n                    try {\n                        Runnable r = queue.take();\n                        if (r == null) {\n                            return;\n                        }\n\n                        r.run();\n                        proccessInc();\n                    } catch (Throwable t) {\n                        if (Utils.exceptionCauseIsInstanceOf(InterruptedIOException.class, t) ) {\n                            LOG.info(\"Event manager interrupted while doing IO\");\n                        } else if (Utils.exceptionCauseIsInstanceOf(ClosedByInterruptException.class, t)) {\n                            LOG.info(\"Event manager interrupted while doing NIO\");\n                        } else if (Utils.exceptionCauseIsInstanceOf(InterruptedException.class, t)) {\n                            LOG.info(\"Event manager interrupted\");\n                        } else {\n                            LOG.error(\"{} Error when processing event\", t);\n                            Utils.exitProcess(20, \"Error when processing an event\");\n                        }\n                    }\n                }\n            }",
            "storm-server.src.main.java.org.apache.storm.event.EventManagerImp.proccessInc": "    public void proccessInc() {\n        processed.incrementAndGet();\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess (int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocalizedResourceSet.get": "  public LocalizedResource get(String name, boolean uncompress) {\n    if (uncompress) {\n      return _localrsrcArchives.get(name);\n    }\n    return _localrsrcFiles.get(name);\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.localResource.shouldUncompress": "  public boolean shouldUncompress() {\n    return _uncompress;\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocalizedResource.getKey": "  public String getKey() {\n    return _key;\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.localResource.getBlobName": "  public String getBlobName() {\n    return _blobKey;\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocalizedResource.isUncompressed": "  public boolean isUncompressed() {\n    return _uncompressed;\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocalizedResourceSet.putIfAbsent": "  public void putIfAbsent(String resourceName, LocalizedResource updatedResource,\n                            boolean uncompress) {\n    if (uncompress) {\n      _localrsrcArchives.putIfAbsent(resourceName, updatedResource);\n    } else {\n      _localrsrcFiles.putIfAbsent(resourceName, updatedResource);\n    }\n  }",
            "storm-server.src.main.java.org.apache.storm.localizer.LocalizedResource.getFilePath": "  public String getFilePath() {\n    return _localPath;\n  }"
        },
        "bug_report": {
            "Title": "Supervisor crashes with NullPointerException",
            "Description": "When supervisor is started, it dies after about 30s like so:\n\n{code:java}\n...\n2017-08-07 17:12:04.606 o.a.s.d.s.Slot main [WARN] SLOT 192.168.10.21:6701 Starting in state EMPTY - assignment null\n2017-08-07 17:12:04.607 o.a.s.d.s.Slot main [WARN] SLOT 192.168.10.21:6702 Starting in state EMPTY - assignment null\n2017-08-07 17:12:04.607 o.a.s.l.AsyncLocalizer main [INFO] Cleaning up unused topologies in /home/storm/data/supervisor/stormdist\n2017-08-07 17:12:04.617 o.a.s.d.s.Supervisor main [INFO] Starting supervisor with id 65a0f977-474c-4938-a4f5-bc99939e96ff at host 192.168.10.\n21.\n2017-08-07 17:12:04.619 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPrep\narableReporter\n2017-08-07 17:12:04.620 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...\n2017-08-07 17:12:04.624 o.a.s.m.StormMetricsRegistry main [INFO] Started statistics report plugin...\n2017-08-07 17:12:34.620 o.a.s.e.EventManagerImp Thread-4 [ERROR] {} Error when processing event\njava.lang.NullPointerException: null\n        at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:1.8.0_121]\n        at org.apache.storm.localizer.Localizer.updateBlobs(Localizer.java:332) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology(UpdateBlobs.java:99) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run(UpdateBlobs.java:72) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:54) ~[storm-core-1.0.4.jar:1.0.4]\n2017-08-07 17:12:34.620 o.a.s.u.Utils Thread-4 [ERROR] Halting process: Error when processing an event\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1750) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:63) ~[storm-core-1.0.4.jar:1.0.4]\n2017-08-07 17:12:34.631 o.a.s.d.s.Supervisor Thread-5 [INFO] Shutting down supervisor 65a0f977-474c-4938-a4f5-bc99939e96ff\n{code}"
        }
    },
    {
        "filename": "STORM-3103.json",
        "creation_time": "2018-06-13T18:23:11.000+0000",
        "stack_trace": "```\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.RuntimeException: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2961) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3454) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3438) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.3.jar:0.9.3]\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.3.jar:0.9.3]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[libthrift-0.9.3.jar:0.9.3]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\nCaused by: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\n        at org.apache.storm.daemon.nimbus.Nimbus.assertIsLeader(Nimbus.java:1311) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2807) ~[storm-server-2.0.0.y.jar:2.0.0.y]```",
        "source_code": {
            "storm-client.src.jvm.org.apache.storm.StormTimer.run": "        public void run() {\n            while (this.active.get()) {\n                QueueEntry queueEntry = null;\n                try {\n                    queueEntry = this.queue.peek();\n                    if ((queueEntry != null) && (Time.currentTimeMillis() >= queueEntry.endTimeMs)) {\n                        // It is imperative to not run the function\n                        // inside the timer lock. Otherwise, it is\n                        // possible to deadlock if the fn deals with\n                        // other locks, like the submit lock.\n                        this.queue.remove(queueEntry);\n                        queueEntry.func.run();\n                    } else if (queueEntry != null) {\n                        //  If any events are scheduled, sleep until\n                        // event generation. If any recurring events\n                        // are scheduled then we will always go\n                        // through this branch, sleeping only the\n                        // exact necessary amount of time. We give\n                        // an upper bound, e.g. 1000 millis, to the\n                        // sleeping time, to limit the response time\n                        // for detecting any new event within 1 secs.\n                        Time.sleep(Math.min(1000, (queueEntry.endTimeMs - Time.currentTimeMillis())));\n                    } else {\n                        // Otherwise poll to see if any new event\n                        // was scheduled. This is, in essence, the\n                        // response time for detecting any new event\n                        // schedulings when there are no scheduled\n                        // events.\n                        Time.sleep(1000);\n                    }\n                    if (Thread.interrupted()) {\n                        this.active.set(false);\n                    }\n                } catch (Throwable e) {\n                    if (!(Utils.exceptionCauseIsInstanceOf(InterruptedException.class, e))\n                        && !(Utils.exceptionCauseIsInstanceOf(ClosedByInterruptException.class, e))) {\n                        this.onKill.uncaughtException(this, e);\n                        this.setActive(false);\n                    }\n                }\n            }\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.setActive": "        public void setActive(boolean flag) {\n            this.active.set(flag);\n        }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.schedule": "    public void schedule(int delaySecs, Runnable func) {\n        schedule(delaySecs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.StormTimer.scheduleMs": "    public void scheduleMs(long delayMs, Runnable func) {\n        scheduleMs(delayMs, func, true, 0);\n    }",
            "storm-client.src.jvm.org.apache.storm.utils.Utils.exitProcess": "    public static void exitProcess(int val, String msg) {\n        String combinedErrorMessage = \"Halting process: \" + msg;\n        LOG.error(combinedErrorMessage, new RuntimeException(combinedErrorMessage));\n        Runtime.getRuntime().exit(val);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopologyWithOpts": "    public void submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopologyWithOpts_call method_call = new submitTopologyWithOpts_call(name, uploadedJarLocation, jsonConf, topology, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.send_submitTopologyWithOpts": "    public void send_submitTopologyWithOpts(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, SubmitOptions options) throws org.apache.storm.thrift.TException\n    {\n      submitTopologyWithOpts_args args = new submitTopologyWithOpts_args();\n      args.set_name(name);\n      args.set_uploadedJarLocation(uploadedJarLocation);\n      args.set_jsonConf(jsonConf);\n      args.set_topology(topology);\n      args.set_options(options);\n      sendBase(\"submitTopologyWithOpts\", args);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_submitTopologyWithOpts": "    public void recv_submitTopologyWithOpts() throws AlreadyAliveException, InvalidTopologyException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      submitTopologyWithOpts_result result = new submitTopologyWithOpts_result();\n      receiveBase(result, \"submitTopologyWithOpts\");\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.ite != null) {\n        throw result.ite;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      return;\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getResult": "      public isRemoteBlobExists_result getResult(I iface, isRemoteBlobExists_args args) throws org.apache.storm.thrift.TException {\n        isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n        try {\n          result.success = iface.isRemoteBlobExists(args.blobKey);\n          result.set_success_isSet(true);\n        } catch (AuthorizationException aze) {\n          result.aze = aze;\n        }\n        return result;\n      }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLeader": "    public void getLeader(org.apache.storm.thrift.async.AsyncMethodCallback<NimbusSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLeader_call method_call = new getLeader_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyPageInfo": "    public TopologyPageInfo recv_getTopologyPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyPageInfo_result result = new getTopologyPageInfo_result();\n      receiveBase(result, \"getTopologyPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_listBlobs": "    public ListBlobsResult recv_listBlobs() throws org.apache.storm.thrift.TException\n    {\n      listBlobs_result result = new listBlobs_result();\n      receiveBase(result, \"listBlobs\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"listBlobs failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishFileUpload": "    public void finishFileUpload(java.lang.String location, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishFileUpload_call method_call = new finishFileUpload_call(location, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopology": "    public StormTopology recv_getTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopology_result result = new getTopology_result();\n      receiveBase(result, \"getTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileDownload": "    public java.lang.String recv_beginFileDownload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileDownload_result result = new beginFileDownload_result();\n      receiveBase(result, \"beginFileDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.finishBlobUpload": "    public void finishBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      finishBlobUpload_call method_call = new finishBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopologyWithOpts": "    public void killTopologyWithOpts(java.lang.String name, KillOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopologyWithOpts_call method_call = new killTopologyWithOpts_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadChunk": "    public void downloadChunk(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadChunk_call method_call = new downloadChunk_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setWorkerProfiler": "    public void setWorkerProfiler(java.lang.String id, ProfileRequest profileRequest, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setWorkerProfiler_call method_call = new setWorkerProfiler_call(id, profileRequest, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.killTopology": "    public void killTopology(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      killTopology_call method_call = new killTopology_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginCreateBlob": "    public java.lang.String recv_beginCreateBlob() throws AuthorizationException, KeyAlreadyExistsException, org.apache.storm.thrift.TException\n    {\n      beginCreateBlob_result result = new beginCreateBlob_result();\n      receiveBase(result, \"beginCreateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.kae != null) {\n        throw result.kae;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginCreateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.downloadBlobChunk": "    public void downloadBlobChunk(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<java.nio.ByteBuffer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      downloadBlobChunk_call method_call = new downloadBlobChunk_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPageInfo": "    public ComponentPageInfo recv_getComponentPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getComponentPageInfo_result result = new getComponentPageInfo_result();\n      receiveBase(result, \"getComponentPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyHistory": "    public void getTopologyHistory(java.lang.String user, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyHistoryInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyHistory_call method_call = new getTopologyHistory_call(user, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.updateBlobReplication": "    public void updateBlobReplication(java.lang.String key, int replication, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      updateBlobReplication_call method_call = new updateBlobReplication_call(key, replication, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setLogConfig": "    public void setLogConfig(java.lang.String name, LogConfig config, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setLogConfig_call method_call = new setLogConfig_call(name, config, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getOwnerResourceSummaries": "    public java.util.List<OwnerResourceSummary> recv_getOwnerResourceSummaries() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getOwnerResourceSummaries_result result = new getOwnerResourceSummaries_result();\n      receiveBase(result, \"getOwnerResourceSummaries\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getOwnerResourceSummaries failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorAssignments": "    public void getSupervisorAssignments(java.lang.String node, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorAssignments> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorAssignments_call method_call = new getSupervisorAssignments_call(node, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyConf": "    public java.lang.String recv_getTopologyConf() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyConf_result result = new getTopologyConf_result();\n      receiveBase(result, \"getTopologyConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.createStateInZookeeper": "    public void createStateInZookeeper(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      createStateInZookeeper_call method_call = new createStateInZookeeper_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadBlobChunk": "    public java.nio.ByteBuffer recv_downloadBlobChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadBlobChunk_result result = new downloadBlobChunk_result();\n      receiveBase(result, \"downloadBlobChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadBlobChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadChunk": "    public void uploadChunk(java.lang.String location, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadChunk_call method_call = new uploadChunk_call(location, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileUpload": "    public void beginFileUpload(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileUpload_call method_call = new beginFileUpload_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.debug": "    public void debug(java.lang.String name, java.lang.String component, boolean enable, double samplingPercentage, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      debug_call method_call = new debug_call(name, component, enable, samplingPercentage, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginCreateBlob": "    public void beginCreateBlob(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginCreateBlob_call method_call = new beginCreateBlob_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfoWithOpts": "    public TopologyInfo recv_getTopologyInfoWithOpts() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfoWithOpts_result result = new getTopologyInfoWithOpts_result();\n      receiveBase(result, \"getTopologyInfoWithOpts\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfoWithOpts failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getUserTopology": "    public void getUserTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getUserTopology_call method_call = new getUserTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfoWithOpts": "    public void getTopologyInfoWithOpts(java.lang.String id, GetInfoOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfoWithOpts_call method_call = new getTopologyInfoWithOpts_call(id, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeat": "    public void sendSupervisorWorkerHeartbeat(SupervisorWorkerHeartbeat heatbeat, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeat_call method_call = new sendSupervisorWorkerHeartbeat_call(heatbeat, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyPageInfo": "    public void getTopologyPageInfo(java.lang.String id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyPageInfo_call method_call = new getTopologyPageInfo_call(id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.sendSupervisorWorkerHeartbeats": "    public void sendSupervisorWorkerHeartbeats(SupervisorWorkerHeartbeats heartbeats, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      sendSupervisorWorkerHeartbeats_call method_call = new sendSupervisorWorkerHeartbeats_call(heartbeats, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyHistory": "    public TopologyHistoryInfo recv_getTopologyHistory() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyHistory_result result = new getTopologyHistory_result();\n      receiveBase(result, \"getTopologyHistory\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyHistory failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.setBlobMeta": "    public void setBlobMeta(java.lang.String key, SettableBlobMeta meta, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      setBlobMeta_call method_call = new setBlobMeta_call(key, meta, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLogConfig": "    public LogConfig recv_getLogConfig() throws org.apache.storm.thrift.TException\n    {\n      getLogConfig_result result = new getLogConfig_result();\n      receiveBase(result, \"getLogConfig\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLogConfig failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getUserTopology": "    public StormTopology recv_getUserTopology() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getUserTopology_result result = new getUserTopology_result();\n      receiveBase(result, \"getUserTopology\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getUserTopology failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginFileDownload": "    public void beginFileDownload(java.lang.String file, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginFileDownload_call method_call = new beginFileDownload_call(file, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isTopologyNameAllowed": "    public void isTopologyNameAllowed(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isTopologyNameAllowed_call method_call = new isTopologyNameAllowed_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.processWorkerMetrics": "    public void processWorkerMetrics(WorkerMetrics metrics, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      processWorkerMetrics_call method_call = new processWorkerMetrics_call(metrics, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.activate": "    public void activate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      activate_call method_call = new activate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadBlobChunk": "    public void uploadBlobChunk(java.lang.String session, java.nio.ByteBuffer chunk, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadBlobChunk_call method_call = new uploadBlobChunk_call(session, chunk, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getLeader": "    public NimbusSummary recv_getLeader() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getLeader_result result = new getLeader_result();\n      receiveBase(result, \"getLeader\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getLeader failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.submitTopology": "    public void submitTopology(java.lang.String name, java.lang.String uploadedJarLocation, java.lang.String jsonConf, StormTopology topology, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      submitTopology_call method_call = new submitTopology_call(name, uploadedJarLocation, jsonConf, topology, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginUpdateBlob": "    public void beginUpdateBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginUpdateBlob_call method_call = new beginUpdateBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isRemoteBlobExists": "    public boolean recv_isRemoteBlobExists() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isRemoteBlobExists_result result = new isRemoteBlobExists_result();\n      receiveBase(result, \"isRemoteBlobExists\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isRemoteBlobExists failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_updateBlobReplication": "    public int recv_updateBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      updateBlobReplication_result result = new updateBlobReplication_result();\n      receiveBase(result, \"updateBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"updateBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getSupervisorPageInfo": "    public void getSupervisorPageInfo(java.lang.String id, java.lang.String host, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<SupervisorPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getSupervisorPageInfo_call method_call = new getSupervisorPageInfo_call(id, host, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_downloadChunk": "    public java.nio.ByteBuffer recv_downloadChunk() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      downloadChunk_result result = new downloadChunk_result();\n      receiveBase(result, \"downloadChunk\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"downloadChunk failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getClusterInfo": "    public ClusterSummary recv_getClusterInfo() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getClusterInfo_result result = new getClusterInfo_result();\n      receiveBase(result, \"getClusterInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getClusterInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getNimbusConf": "    public java.lang.String recv_getNimbusConf() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getNimbusConf_result result = new getNimbusConf_result();\n      receiveBase(result, \"getNimbusConf\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getNimbusConf failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPageInfo": "    public void getComponentPageInfo(java.lang.String topology_id, java.lang.String component_id, java.lang.String window, boolean is_include_sys, org.apache.storm.thrift.async.AsyncMethodCallback<ComponentPageInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPageInfo_call method_call = new getComponentPageInfo_call(topology_id, component_id, window, is_include_sys, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobReplication": "    public int recv_getBlobReplication() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobReplication_result result = new getBlobReplication_result();\n      receiveBase(result, \"getBlobReplication\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobReplication failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deleteBlob": "    public void deleteBlob(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deleteBlob_call method_call = new deleteBlob_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.uploadNewCredentials": "    public void uploadNewCredentials(java.lang.String name, Credentials creds, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      uploadNewCredentials_call method_call = new uploadNewCredentials_call(name, creds, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyConf": "    public void getTopologyConf(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyConf_call method_call = new getTopologyConf_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.isRemoteBlobExists": "    public void isRemoteBlobExists(java.lang.String blobKey, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Boolean> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      isRemoteBlobExists_call method_call = new isRemoteBlobExists_call(blobKey, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginBlobDownload": "    public BeginDownloadResult recv_beginBlobDownload() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginBlobDownload_result result = new beginBlobDownload_result();\n      receiveBase(result, \"beginBlobDownload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginBlobDownload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getTopologyInfo": "    public TopologyInfo recv_getTopologyInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getTopologyInfo_result result = new getTopologyInfo_result();\n      receiveBase(result, \"getTopologyInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getTopologyInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getOwnerResourceSummaries": "    public void getOwnerResourceSummaries(java.lang.String owner, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<OwnerResourceSummary>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getOwnerResourceSummaries_call method_call = new getOwnerResourceSummaries_call(owner, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorPageInfo": "    public SupervisorPageInfo recv_getSupervisorPageInfo() throws NotAliveException, AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorPageInfo_result result = new getSupervisorPageInfo_result();\n      receiveBase(result, \"getSupervisorPageInfo\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.e != null) {\n        throw result.e;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorPageInfo failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobMeta": "    public void getBlobMeta(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<ReadableBlobMeta> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobMeta_call method_call = new getBlobMeta_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.listBlobs": "    public void listBlobs(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<ListBlobsResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      listBlobs_call method_call = new listBlobs_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getSupervisorAssignments": "    public SupervisorAssignments recv_getSupervisorAssignments() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      getSupervisorAssignments_result result = new getSupervisorAssignments_result();\n      receiveBase(result, \"getSupervisorAssignments\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getSupervisorAssignments failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.cancelBlobUpload": "    public void cancelBlobUpload(java.lang.String session, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      cancelBlobUpload_call method_call = new cancelBlobUpload_call(session, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getBlobReplication": "    public void getBlobReplication(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.Integer> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getBlobReplication_call method_call = new getBlobReplication_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getClusterInfo": "    public void getClusterInfo(org.apache.storm.thrift.async.AsyncMethodCallback<ClusterSummary> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getClusterInfo_call method_call = new getClusterInfo_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.set_success_isSet": "    public void set_success_isSet(boolean value) {\n      __isset_bitfield = org.apache.storm.thrift.EncodingUtils.setBit(__isset_bitfield, __SUCCESS_ISSET_ID, value);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getBlobMeta": "    public ReadableBlobMeta recv_getBlobMeta() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      getBlobMeta_result result = new getBlobMeta_result();\n      receiveBase(result, \"getBlobMeta\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getBlobMeta failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getLogConfig": "    public void getLogConfig(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<LogConfig> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getLogConfig_call method_call = new getLogConfig_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.rebalance": "    public void rebalance(java.lang.String name, RebalanceOptions options, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      rebalance_call method_call = new rebalance_call(name, options, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.beginBlobDownload": "    public void beginBlobDownload(java.lang.String key, org.apache.storm.thrift.async.AsyncMethodCallback<BeginDownloadResult> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      beginBlobDownload_call method_call = new beginBlobDownload_call(key, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginFileUpload": "    public java.lang.String recv_beginFileUpload() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      beginFileUpload_result result = new beginFileUpload_result();\n      receiveBase(result, \"beginFileUpload\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginFileUpload failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getNimbusConf": "    public void getNimbusConf(org.apache.storm.thrift.async.AsyncMethodCallback<java.lang.String> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getNimbusConf_call method_call = new getNimbusConf_call(resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_getComponentPendingProfileActions": "    public java.util.List<ProfileRequest> recv_getComponentPendingProfileActions() throws org.apache.storm.thrift.TException\n    {\n      getComponentPendingProfileActions_result result = new getComponentPendingProfileActions_result();\n      receiveBase(result, \"getComponentPendingProfileActions\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"getComponentPendingProfileActions failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_beginUpdateBlob": "    public java.lang.String recv_beginUpdateBlob() throws AuthorizationException, KeyNotFoundException, org.apache.storm.thrift.TException\n    {\n      beginUpdateBlob_result result = new beginUpdateBlob_result();\n      receiveBase(result, \"beginUpdateBlob\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      if (result.knf != null) {\n        throw result.knf;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"beginUpdateBlob failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopology": "    public void getTopology(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<StormTopology> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopology_call method_call = new getTopology_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getComponentPendingProfileActions": "    public void getComponentPendingProfileActions(java.lang.String id, java.lang.String component_id, ProfileAction action, org.apache.storm.thrift.async.AsyncMethodCallback<java.util.List<ProfileRequest>> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getComponentPendingProfileActions_call method_call = new getComponentPendingProfileActions_call(id, component_id, action, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.recv_isTopologyNameAllowed": "    public boolean recv_isTopologyNameAllowed() throws AuthorizationException, org.apache.storm.thrift.TException\n    {\n      isTopologyNameAllowed_result result = new isTopologyNameAllowed_result();\n      receiveBase(result, \"isTopologyNameAllowed\");\n      if (result.is_set_success()) {\n        return result.success;\n      }\n      if (result.aze != null) {\n        throw result.aze;\n      }\n      throw new org.apache.storm.thrift.TApplicationException(org.apache.storm.thrift.TApplicationException.MISSING_RESULT, \"isTopologyNameAllowed failed: unknown result\");\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.deactivate": "    public void deactivate(java.lang.String name, org.apache.storm.thrift.async.AsyncMethodCallback<Void> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      deactivate_call method_call = new deactivate_call(name, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.generated.Nimbus.getTopologyInfo": "    public void getTopologyInfo(java.lang.String id, org.apache.storm.thrift.async.AsyncMethodCallback<TopologyInfo> resultHandler) throws org.apache.storm.thrift.TException {\n      checkReady();\n      getTopologyInfo_call method_call = new getTopologyInfo_call(id, resultHandler, this, ___protocolFactory, ___transport);\n      this.___currentMethod = method_call;\n      ___manager.call(method_call);\n    }",
            "storm-client.src.jvm.org.apache.storm.security.auth.sasl.SaslTransportPlugin.process": "        public boolean process(final TProtocol inProt, final TProtocol outProt) throws TException {\n            //populating request context\n            ReqContext reqContext = ReqContext.context();\n\n            TTransport trans = inProt.getTransport();\n            //Sasl transport\n            TSaslServerTransport saslTrans = (TSaslServerTransport) trans;\n\n            if (trans instanceof NoOpTTrasport) {\n                return false;\n            }\n\n            //remote address\n            TSocket tsocket = (TSocket) saslTrans.getUnderlyingTransport();\n            Socket socket = tsocket.getSocket();\n            reqContext.setRemoteAddress(socket.getInetAddress());\n\n            //remote subject\n            SaslServer saslServer = saslTrans.getSaslServer();\n            String authId = saslServer.getAuthorizationID();\n            Subject remoteUser = new Subject();\n            remoteUser.getPrincipals().add(new User(authId));\n            reqContext.setSubject(remoteUser);\n\n            //invoke service handler\n            return wrapped.process(inProt, outProt);\n        }"
        },
        "bug_report": {
            "Title": "nimbus stuck shutting down causing leadership issues on startup",
            "Description": "When debugging an Nimbus NPE that caused restarts, I noticed that a forced halt occurred:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-05-24 09:27:05.569 o.a.z.ClientCnxn main-SendThread(openqe82blue-gw.blue.ygrid.yahoo.com:2181) [INFO] Opening socket connection to server openqe82blue-gw.blue.ygrid.yahoo.com/10.215.77.115:2181. Will attempt to SASL-authenticate using Login Context section 'Client'\r\n2018-05-24 09:27:05.570 o.a.z.ClientCnxn main-SendThread(openqe82blue-gw.blue.ygrid.yahoo.com:2181) [INFO] Socket connection established to openqe82blue-gw.blue.ygrid.yahoo.com/10.215.77.115:2181, initiating session\r\n2018-05-24 09:27:05.571 o.a.z.ClientCnxn main-SendThread(openqe82blue-gw.blue.ygrid.yahoo.com:2181) [INFO] Session establishment complete on server openqe82blue-gw.blue.ygrid.yahoo.com/10.215.77.115:2181, sessionid = 0x1624a86300f7f6b, negotiated timeout = 40000\r\n2018-05-24 09:27:05.571 o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED\r\n2018-05-24 09:27:05.636 o.a.s.d.n.Nimbus main [INFO] Starting nimbus server for storm version '2.0.0.y'\r\n2018-05-24 09:27:06.012 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event\r\njava.lang.RuntimeException: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-05-24 09:27:06.023 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-05-24 09:27:06.032 o.a.s.d.n.Nimbus Thread-12 [INFO] Shutting down master\r\n2018-05-24 09:27:06.032 o.a.s.u.Utils Thread-13 [INFO] Halting after 5 seconds\r\n{code}\r\nAt times this would cause leadership confusion:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-05-24 09:27:21.762 o.a.s.z.LeaderElectorImp main [INFO] Queued up for leader lock.\r\n2018-05-24 09:27:22.604 o.a.s.d.n.Nimbus timer [INFO] not a leader, skipping assignments\r\n2018-05-24 09:27:22.604 o.a.s.d.n.Nimbus timer [INFO] not a leader, skipping cleanup\r\n2018-05-24 09:27:22.633 o.a.s.d.n.Nimbus timer [INFO] not a leader, skipping credential renewal.\r\n\r\n2018-05-24 09:27:40.771 o.a.s.d.n.Nimbus pool-37-thread-63 [WARN] Topology submission exception. (topology name='topology-testOverSubscribe-1')\r\njava.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\r\n        at org.apache.storm.daemon.nimbus.Nimbus.assertIsLeader(Nimbus.java:1311) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2807) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3454) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3438) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n2018-05-24 09:27:40.771 o.a.s.b.BlobStoreUtils Timer-1 [ERROR] Could not download the blob with key: topology-testOverCapacityScheduling-2-1519992333-stormcode.ser\r\n2018-05-24 09:27:40.771 o.a.t.s.TThreadPoolServer pool-37-thread-63 [ERROR] Error occurred during processing of message.\r\njava.lang.RuntimeException: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2961) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3454) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3438) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\r\n        at org.apache.storm.daemon.nimbus.Nimbus.assertIsLeader(Nimbus.java:1311) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2807) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 9 more\r\n{code}\r\nWe should endeavor to shutdown cleanly.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0"
        }
    }
]